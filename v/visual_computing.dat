254|278|Public
5|$|In post-production, {{the visual}} effects were handled by Tata Elxsi's <b>Visual</b> <b>Computing</b> Labs. The {{military}} aircraft they created was so realistic that the Indian Air Force called {{to check the}} producer's permission of using an actual MiG-21.|$|E
25|$|The {{instrument}} cluster and the infotainment panel {{are driven by}} separate Nvidia Tegra 3 3D <b>Visual</b> <b>Computing</b> Modules. Tesla was the first company to ship this technology. (Audi later delivered this technology in its 2013 model year in Europe, and in North America in 2014.) The Tegra {{system on a chip}} (SoC) integrates eight specialized processors, including a multi-core ARM CPU, a GPU, and dedicated audio, video and image processors. Nvidia claimed that it consumes 2% of the energy of a typical CPU.|$|E
500|$|In the narrative, Ambi is {{referred}} to the website, www.anniyan.com. Shankar envisioned that the website would take visitors through all the punishments that await sinners in hell. For designing the website, Shankar wanted to recreate hell and approached the <b>Visual</b> <b>Computing</b> Labs (VCL) of Tata Elxsi, a Mumbai-based company with which he had collaborated earlier for the song [...] "Girlfriend" [...] in Boys. The team at VCL conceptualised and created a 'hell' in 3d animation with the punishments taken from ancient scriptures. They also designed a grim reaper astride his bull who guides visitors through hell. Pankaj Khandpur, creative director of VCL said, [...] "We tried to stay true to the scriptures, while creating imagery that wasn’t too gory. [...] an interesting project since we had to visualise it all without any reference point." [...] The animation was done in a span of three months.|$|E
50|$|Amy Alexander is {{currently}} the Associate Professor of <b>Visual</b> Arts: <b>Computing</b> at the University of California, San Diego. Her teaching focuses on contemporary expanded cinema, visual performance, abstract cinema history, and process-based digital media art.|$|R
40|$|In this paper, {{we develop}} an {{algorithm}} for the navigation of a nonholonomic mobile robot using the visual potential. The robot {{is equipped with}} a camera system which dynamically captures the environment. The <b>visual</b> potential is <b>computed</b> from an image sequence and optical flow computed from successive images captured by the camera mounted on the robot. Our robot selects a local pathway using the <b>visual</b> potential <b>computed</b> from its vision system without any knowledge of a robot workspace. We present experimental results of the obstacle avoidance in the real environment...|$|R
50|$|To {{determine}} color, {{the visual}} system compares responses across {{a population of}} photoreceptors (specifically, the three different cones with differing absorption spectra). To determine intensity, the <b>visual</b> system <b>computes</b> how many photoreceptors are responding. This is the mechanism that allows trichromatic color vision in humans and some other animals.|$|R
500|$|Shiamak Davar choreographed {{the dance}} {{sequence}} of [...] "Bum Bum Bole," [...] {{and was given}} free rein over its design. He had intended to use 40students from his dance school, but Khan did not want trained dancers. Davar gave the children certain cues and a general idea of what to do, but left the style and final product {{up to them to}} avoid a choreographed appearance. Time constraints meant that while Khan was busy filming [...] "Bum Bum Bole," [...] Ram Madhvani took over as director for [...] "Bheja Kum". The latter sequence, containing a [...] "fun-filled" [...] song of rhythmic dialogue, allowed the audience to perceive how Ishaan sees the world and written languages. It was intended to represent [...] "a young boy's worst nightmare, in terms of... the worst thing that he can think of"; Madhvani based the visual concept on his son's fear of [...] "creepy-crawlies" [...] such as cockroaches, dragonflies, and lizards. Tata Elxsi's <b>Visual</b> <b>Computing</b> Labs made the creatures out of the English alphabet and numbers, although Khan insisted they include the Hindi alphabet as not all the audience would be familiar with English. The chalkboard writing's transformation into a snake was included to surprise the audience and [...] "end the song on a high note." ...|$|E
50|$|Visual Cloud is the {{implementation}} of <b>visual</b> <b>computing</b> applications that rely on cloud computing architectures, cloud-based graphics processing, and ubiquitous broadband connectivity between connected devices, network edge devices and cloud data centers. It is a model for providing <b>visual</b> <b>computing</b> services to consumers and business users, while allowing service providers to realize the general benefits of cloud computing, such as low cost, elastic scalability, and high availability while providing optimized infrastructure for <b>visual</b> <b>computing</b> application requirements.|$|E
5000|$|... #Subtitle level 4: Intel <b>Visual</b> <b>Computing</b> Tools Audience Award ...|$|E
50|$|Blaine A. Price; Ron M. Baecker and Ian S. Small (1992). A Taxonomy of Software Visualization. Journal of <b>Visual</b> Languages and <b>Computing,</b> Vol. 4, pp. 211-266.|$|R
40|$|A bimodal {{automatic}} {{speech recognition}} system, in which the speech signal is synchronously analyzed by an audio channel producing spectral-like parameters every 2 ms and by a <b>visual</b> channel <b>computing</b> lip and jaw kinematic parameters, is described and some results are given for various speaker independent phonetic recognition experiments regarding the Italian plosive class in different noisy conditions...|$|R
5000|$|Green, Thomas R. G., and Marian Petre. [...] "Usability {{analysis}} of visual programming environments: a ‘cognitive dimensions’ framework." [...] Journal of <b>Visual</b> Languages & <b>Computing</b> 7.2 (1996): 131-174.|$|R
50|$|Although many {{problems}} are considered solved within the scientific {{communities of the}} sub-disciplines making up <b>visual</b> <b>computing</b> (mostly under idealistic assumptions), one major challenge of <b>visual</b> <b>computing</b> {{as a whole is}} the integration of these partial solutions into applicable products. This includes dealing with many practical problems like addressing a multitude of hardware, the use of real data (that is often erroneous and/or gigantic in size), and the operation by untrained users. In this respect, <b>Visual</b> <b>computing</b> is more than just the sum of its sub-disciplines, it is the next step towards systems fit for real use in all areas using images or 3D objects on the computer.|$|E
50|$|<b>Visual</b> <b>Computing</b> for Medicine, Bernhard Preim and Charl Botha, 2013, San Francisco: Morgan Kaufmann.|$|E
50|$|Bimber's {{research}} interests include <b>visual</b> <b>computing</b> and optics {{in the context of}} next-generation display and imaging technologies.|$|E
5000|$|Christopher Hundhausen, Sarah Douglas, and John Stasko, [...] "A Meta-Study of Algorithm Visualization Effectiveness", Journal of <b>Visual</b> Languages and <b>Computing,</b> Vol. 13, No. 3, June 2002, pp. 259-290.|$|R
50|$|Thiruvananthapuram {{was rated}} {{as the best}} 2nd tier metro with IT/ITES infrastructure, and second in terms of {{availability}} of human talent http://www.ciol.com/content/news/2006/106072505.asp. The district contributes 80% of software exports from the state. Technopark also houses global majors like Oracle Corporation, Infosys, TCS, HCL, <b>Visual</b> Graphics <b>Computing</b> Services, Ernst & Young Global Shared Services Center, Allianz Cornhill, UST Global, Tata Elxsi, IBS Software Services, NeST Software, SunTec Business Solutions etc.|$|R
40|$|Abstract: In this paper, an {{overview}} of the problems associated with organizing searches of video data and the currently available methods for handling them are presented. A proposal for a project to create a digital video library is reported. Techniques for providing a user with the facility to formulate queries on the content of video material are studied. Content is conveyed in the narrative and in the image. Image properties are both simple <b>computed</b> <b>visual</b> features (like color histogram, texture measures, and motion parameters) and domain objects. The system will be based on collaborative using of combined source information and on image processing techniques developed for <b>visual</b> features <b>computing</b> and for domain object detection. Our approach to object detection in video infers the extension of the detection methods are already known for still images by taking into consideration dynamic information not available in still images. Note: Publication language:russia...|$|R
50|$|The Intel <b>Visual</b> <b>Computing</b> Institute will {{research}} {{basic and}} applied technologies {{that could be}} applied to Larrabee-based products.|$|E
50|$|Nvision, stylized as NVISION, is a {{stand-alone}} event organized by NVIDIA to promote <b>visual</b> <b>computing</b> among enthusiasts and journalists.|$|E
50|$|Its uses include {{development}} of digital virtual agents, predictive systems, cognitive process automation, <b>visual</b> <b>computing</b> applications, knowledge virtualization, robotics and drones.|$|E
40|$|Abstract—This paper {{describes}} an approach for mobile robot localization using a visual word based place recognition approach. In our approach we exploit {{the benefits of}} a stereo camera system for place recognition. <b>Visual</b> words <b>computed</b> from SIFT features are combined with VIP (viewpoint invariant patches) features that use depth information from the stereo setup. The approach was evaluated under the ImageCLEF@ICPR 2010 competition 1. The results achieved on the competition datasets are published in this paper. I...|$|R
40|$|We {{construct}} multi-modal concept repre-sentations by concatenating a skip-gram linguistic representation vector with a vi-sual concept representation vector com-puted {{using the}} feature extraction layers {{of a deep}} convolutional neural network (CNN) trained on a large labeled object recognition dataset. This transfer learn-ing approach brings a clear performance gain over features based on the traditional bag-of-visual-word approach. Experimen-tal results are reported on the WordSim 353 and MEN semantic relatedness evaluation tasks. We use <b>visual</b> features <b>computed</b> us-ing either ImageNet or ESP Game images. ...|$|R
50|$|Gaulon teaches several {{courses at}} the National College of Art and Design {{on topics such as}} <b>visual</b> programming, {{physical}} <b>computing,</b> new media art and digital art theory. His work can be found on recyclism.com Gaulon currently lives in Dublin with his wife and daughter.|$|R
50|$|At {{least the}} {{following}} disciplines are sub-fields of <b>visual</b> <b>computing.</b> More {{detailed descriptions of}} each of these fields {{can be found on the}} linked special pages.|$|E
50|$|In July 2005 {{he became}} vice {{president}} of mobile ecosystem at Nvidia where {{he is responsible for}} enabling and encouraging <b>visual</b> <b>computing</b> applications on non-PC platforms, including mobile phones.|$|E
5000|$|McCaffrey, J.D., [...] "An Empirical Study of Categorical Dataset Visualization using a Simulated Bee Colony Algorithm", Proceedings of the 5th International Symposium on <b>Visual</b> <b>Computing,</b> December 2009, pp. 179-188.|$|E
40|$|We propose an {{original}} bayesian approach to recognize human behaviors from video streams. Mobile objects and their <b>visual</b> features are <b>computed</b> by a vision module. Then, using a Recurrent Bayesian Network, {{behaviors of the}} mobile objects are recognized through the temporal evolution of their visual features...|$|R
40|$|We {{propose a}} model of <b>visual</b> {{interactive}} <b>computing</b> and define a family of visual languages which abstract some of its features. We prove that the problem whether or not successful communications exist is not decidable. (A human-computer communication {{by means of a}} visual language is successful when all human commands, in the form of pictures composed of icons, are correctly interpreted and answered by the computer.) The proof makes use of a codification of the Post Correspondence Problem by means of icons and pictures. This result warns about possible limitations of a purely algorithmic treatment of interactive <b>computing</b> via <b>visual</b> language...|$|R
40|$|International audienceThis paper {{describes}} {{the participation of}} the LIG-MRIM research team to the Lifelog Semantic Access sub-task of the NTCIR- 12 (2016). Our approach mainly relies on mapping the query terms to <b>visual</b> concepts <b>computed</b> on the Lifel-ogs images according to two separated learning schemes. A post-processing is then performed if the topic is related to temporal, location or activity information associated with the images. The results obtained are promising for a first participation to such a task, with event-based MAP above 29 % and an event-based nDCG value close to 39 %. Team Name MRIM Subtasks Lifelog Semantic Access Tas...|$|R
50|$|Professor Hassan Ugail is a {{mathematician}} {{and a computer}} scientist. He is currently working as a Professor of <b>Visual</b> <b>Computing</b> at the School of Engineering and Informatics; the University of Bradford. Professor Ugail is the first Maldivian to obtain a PhD in Mathematics. He is also the first and to date the only Maldivian to receive a professorship {{in the field of}} Science. Prof. Ugail's principal research interests are in the area of <b>Visual</b> <b>Computing</b> particularly in the area of 3D geometric design, 3D imaging and computer based simulations. Prof. Ugail is a leader in the field of <b>Visual</b> <b>Computing</b> and has greatly contributed {{to the development of the}} field by successfully delivering a number of high-profile research and innovation projects, publications and international lectures. He is a member of the UK Engineering and Physical Sciences Research Council (EPSRC) peer review college and also a peer reviewer for several related journals and conferences in his field of research.|$|E
50|$|CRS4 {{is one of}} {{the major}} Italian Computing Centers and is {{equipped}} with the first Genotyping and massive DNA Sequencing Platform in Italy and with a state-of-the-art <b>Visual</b> <b>Computing</b> laboratory.|$|E
50|$|Bernhard Preim (born 1969) is a {{specialist}} in human-computer interface design {{as well as in}} <b>visual</b> <b>computing</b> for medicine. He is currently professor of visualization at University of Magdeburg, Germany.|$|E
40|$|Although {{studies of}} {{categorization}} {{have been a}} staple of psy-chological research for decades, there continues to be substan-tial disagreement about how unique classes of objects are rep-resented in the brain. We present a neural architecture for categorizing visual stimuli based on the Neural Engineering Framework and the manipulation of semantic pointers. The model accounts for how the <b>visual</b> system <b>computes</b> semantic representations from raw images, and how those representa-tions are then manipulated to produce category judgments. All computations of the model are carried out in simulated spiking neurons. We demonstrate that the model matches human per-formance on two seminal behavioural studies of image-base...|$|R
50|$|Non-destructive {{examination}} (NDE) or {{nondestructive testing}} (NDT) {{is a family}} of technologies used during inspection to analyze materials, components and products for either inherent defects (such as fractures or cracks), or service induced defects (damage from use). Some common methods are <b>visual,</b> industrial <b>computed</b> tomography scanning, microscopy, dye penetrant inspection, magnetic-particle inspection, X-ray or radiographic testing, ultrasonic testing, eddy-current testing, acoustic emission testing, and thermographic inspection. In addition, many non-destructive inspections can be performed by a precision scale, or when in motion, a checkweigher. Stereo microscopes are often used for examining small products like circuit boards for product defects.|$|R
40|$|We {{present a}} case of {{sarcoidosis}} in a 14 -year-old girl who presented with a short history of <b>visual</b> disturbance. <b>Computed</b> tomography and magnetic resonance imaging (MRI) demonstrated enlargement of the optic chiasm and prechiasmic optic nerves. Post-contrast MRI showed marginal enhancement of the affected areas of the optic pathways. A diagnosis of optic nerve glioma and arachnoid gliomatosis was made; surgical confirmation was not sought due to the risk to vision associated with biopsy. A rapid clinical deterioration led to repeat MRI which demonstrated extensive enhancing soft tissue throughout the basal cisterns with extension into the brain. Biopsy confirmed a diagnosis of sarcoidosis...|$|R
