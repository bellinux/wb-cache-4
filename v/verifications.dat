2572|10000|Public
5|$|In two years, a {{very precise}} map, drawn on six sheets at a 1/200,000 scale, was produced. In March 1829, {{a base of}} 3,500 meters had been traced in the Argolis, from one angle at the ruins of Tiryns to an angle of a house in ruins {{in the village of}} Aria. This was {{intended}} to serve as a point of departure in all the triangulation operations for topographic and geodesic readings in the Peloponnese. Pierre Peytier and Puillon-Boblaye proceeded to perform numerous <b>verifications</b> on the base and on the rulers used. The margin of error was thus reduced to 1 meter for every 15 kilometers. The longitude and latitude of the base point at Tiryns were read and checked, so that again the margin of error was reduced as far as possible to an estimated 0.2 seconds. 134 geodesic stations were set up on the peninsula’s mountains, as well as on Aegina, Hydra and Nafplion. Thus, equilateral triangles whose sides measured about 20km were drawn. The angles were measured with theodolites by Gambey.|$|E
25|$|Medical staff {{residency}} {{training records}} and <b>verifications</b> have become {{available through the}} Federation Credentials Verification Service (FCVS) Closed Residency program records.|$|E
25|$|On 4 July, Almirante Irízar {{sailed to}} the Atlantic {{for the first}} time in ten years. After departing Buenos Aires, the vessel headed to a dry dock in the main base of Argentine Navy, Puerto Belgrano, where the {{icebreaker}} will undergo tests and <b>verifications</b> prior to ice trials in the Antarctic and return to full service.|$|E
50|$|Design <b>verification</b> - Design <b>verification</b> is {{the process}} that {{confirms}} that the design output conforms to the design input. Design <b>verification</b> should demonstrate that the specifications are the correct specifications for the design. Design <b>verification</b> must be documented in the DHF and include the <b>verification</b> date, participants, design version/revision verified, <b>verification</b> method and <b>verification</b> results.|$|R
40|$|Abstract. There {{has been}} {{significant}} progress in automated <b>verification</b> techniques based on model checking. However, scalable software model checking remains a challenging problem. We believe that this problem can be addressed using a design for <b>verification</b> approach based on design patterns that facilitate scalable automated <b>verification.</b> We have been investigating a design for <b>verification</b> approach based on the following principles: 1) use of stateful, behavioral interfaces which isolate the behavior and enable modular <b>verification,</b> 2) an assume-guarantee style <b>verification</b> strategy which separates <b>verification</b> of the behavior from the <b>verification</b> of the conformance to the interface specifications, 3) a general model checking technique for interface <b>verification,</b> and 4) domain specific and specialized <b>verification</b> techniques for behavior <b>verification.</b> So far we have applied this approach to <b>verification</b> of synchronization operations in concurrent programs and to <b>verification</b> of interactions among multiple peers in composite web services. The case studies we conducted indicate that scalable software <b>verification</b> is achievable in these application domains using our design for <b>verification</b> approach. ...|$|R
5000|$|A card {{security}} code (CSC; {{also called}} card <b>verification</b> data CVD or a card <b>verification</b> number, card <b>verification</b> value CVV, card <b>verification</b> value code, card <b>verification</b> code CVC, <b>verification</b> code or V code, card code <b>verification,</b> or signature panel code SPC) is a security feature for [...] "card not present" [...] payment card transactions instituted {{to reduce the}} incidence of credit card fraud.|$|R
25|$|The section also {{outlines}} {{supporting documentation}} and <b>verifications</b> that the goods being traded are, indeed, {{originating in the}} exporting country, {{as defined by the}} agreement. The responsibility for verification of the applicable conditions is given to the importer. Denial of preferential treatment and penalties may apply if proper verification is not provided by the importer upon request made by the importing country.|$|E
25|$|Clock-comparison {{experiments}} (periodic {{processes and}} frequencies {{can be considered}} as clocks) such as the Hughes–Drever experiments provide stringent tests of Lorentz invariance. They are not restricted to the photon sector as Michelson-Morley but directly determine any anisotropy of mass, energy, or space by measuring the ground state of nuclei. Upper limit of such anisotropies of 10−33 GeV have been provided. Thus these experiments are among the most precise <b>verifications</b> of Lorentz invariance ever conducted.|$|E
25|$|Nuedexta is a {{patented}} {{combination of}} these two generic drugs, and is the first FDA-approved drug {{for the treatment of}} PBA, approved on October 29, 2010. In December 2007, clinical study information for Nuedexta was first submitted to ClinicalTrials.gov, (a Web-based resource maintained by the National Library of Medicine (NLM) at the National Institutes of Health (NIH)). Sponsored by Avanir Pharmaceuticals, (with brief title, Safety and Efficacy of AVP-923 in PBA Patients With ALS or MS), the study was assigned NCT Number NCT00573443. Final updates and <b>verifications</b> occurred in June 2013 on the ClinicalTrials.gov site.|$|E
5000|$|Several <b>verification</b> {{algorithms}} combined: enumerative <b>verification,</b> on-the-fly <b>verification,</b> symbolic <b>verification</b> using {{binary decision}} diagrams, compositional minimization, partial orders, distributed model checking, etc.|$|R
40|$|Nested {{certificates}} {{are used}} to certify their subject certificates. In this way, the subject certificates can be verified via their nested certificates without using signature <b>verification</b> methods based on public key cryptosystems. Such a <b>verification</b> method is called as subject certificate <b>verification.</b> In this paper, subject certificate <b>verification</b> method will be introduced. It will be shown that subject certificate <b>verification</b> has the same confidence as the cryptographic certificate <b>verification</b> also. Moreover, subject certificate <b>verification</b> is faster than the cryptographic certificate <b>verification.</b> It will also be shown that a classical certificate can be verified via a sequence of nested certificates [...] called nested certificate path [...] and such <b>verification</b> has the same confidence as the cryptographic <b>verification</b> of the same certificate. Nested certificate path <b>verification</b> is faster than the classical certificate path <b>verification</b> also. Moreover in this paper, simulation re [...] ...|$|R
40|$|In this paper, {{we present}} Generic System Verilog Universal <b>Verification</b> Methodology based ReusableVerification Environment for {{efficient}} <b>verification</b> of Image Signal Processing IP’s/SoC’s. With the tightschedules on all projects {{it is important}} to have a strong <b>verification</b> methodology which contributes toFirst Silicon Success. Deploy methodologies which enforce full functional coverage and <b>verification</b> ofcorner cases through pseudo random test scenarios is required. Also, standardization of <b>verification</b> flow isneeded. Previously, inside imaging group of ST, Specman (e) /Verilog based <b>Verification</b> Environment forIP/Subsystem level <b>verification</b> and C/C++/Verilog based Directed <b>Verification</b> Environment for SoC LevelVerification was used for Functional <b>Verification.</b> Different <b>Verification</b> Environments were used at IPlevel and SoC level. Different Verification/Validation Methodologies were used for SoC <b>Verification</b> acrossmultiple sites. <b>Verification</b> teams were also looking for the ways how to catch bugs early in the designcycle? Thus, Generic System Verilog Universal <b>Verification</b> Methodology (UVM) based ReusableVerification Environment is required to avoid the problem of having so many methodologies and provides astandard unified solution which compiles on all tools...|$|R
25|$|Officials {{suspect that}} Muslim rebels from the troubled North Caucasus region that {{includes}} Chechnya {{are responsible for}} the attack. The link to the Caucasian group was immediate. According to preliminary reports, law enforcement were notified about possible terror acts through three telegrams indicating potential threats to Moscow's transport system, but the suicide bombers passed through the security. Unofficial reports the morning before the attacks took place indicate many female passengers of North Caucasian appearance were stopped and checked by Moscow security enforcement under pretence of routine ID <b>verifications,</b> and taken to local precincts.|$|E
25|$|Individually, some {{countries}} {{account for a}} large percentage of the total Skills Certificates issued. For instance between 1997 and July 2010, Guyana had issued 2,829 skills certificates. Up to June 2011, Jamaica had issued 2,113 skills certificates. And as of September 2013, Jamaica had issued 2,893 skills certificates. Data also indicated that the number of <b>verifications</b> and the number of certificates issued by other member states to Jamaicans for 2004 to 2010 amounted to 1,020. And between 2001 and 2006 Trinidad and Tobago issued 789 Skills Certificates. By 2008, Trinidad and Tobago had issued a total of 1,685 Skills Certificates.|$|E
25|$|Modifications {{to produce}} weapon-usable {{material}} {{in a commercial}} facility: The production potential is significant. But no fertile or fissile substances necessary {{for the production of}} weapon-usable materials needs to be present at a civil fusion system at all. If not shielded, a detection of these materials can be done by their characteristic gamma radiation. The underlying redesign could be detected by regular design information <b>verifications.</b> In the (technically more feasible) case of solid breeder blanket modules, it would be necessary for incoming components to be inspected for the presence of fertile material, otherwise plutonium for several weapons could be produced each year.|$|E
40|$|<b>Verification</b> {{is one of}} the {{important}} sections of producing a software system. Several factors can influence on <b>verification</b> result. In this research, we analyze important factors on <b>verification</b> results and then we explain some <b>verification</b> techniques and software systems briefly. As <b>verification</b> result is sensitive highly in multilayer systems, we present a solution. By this solution, we can guarantee correctness and accuracy of <b>verification</b> results in multilayer systems by using static and dynamic <b>verification</b> techniques and reduce probability of errors in <b>verification</b> results of multilayer systems widely...|$|R
50|$|Forms of <b>verification</b> {{available}} are: SMS <b>verification</b> and Landline Telephone verificationaddress <b>verification.</b>|$|R
40|$|This thesis {{focuses on}} <b>verification</b> of Intrusion Detection System and its IPv 6 support extension. Here are {{described}} posibilities of SystemVerilog for <b>verification,</b> choosen <b>verification</b> methodology, {{pros and cons}} of different <b>verification</b> and testing approaches. Here is designed structure of <b>verification</b> of key parts of Intrusion Detection System. The key component of <b>verification</b> system is Packet Generator...|$|R
25|$|In banning Uber, Delhi's {{transport}} department cited several {{rules that}} Uber had broken. According to New Delhi's Radio Taxi Scheme, 2006, all taxi licensees must {{be either a}} company under the Companies Act, 2013 (or the 1956 Act), or a society under the Societies Registration Act, 1860. Furthermore, taxi services must provide adequate parking space for all taxis, as well as sufficiently sized office space to accommodate the control room, {{the maintenance of a}} minimum fleet size per license (500 vehicles), and all vehicles must be fitted with GPS/GPRS tracking systems (to be in constant communication with the control room while on duty). The rules also stipulate that the taxi licensee is responsible for ensuring the quality of drivers, including police <b>verifications,</b> supervision, and employee behaviour.|$|E
500|$|By definition, {{the error}} in the {{measured}} value of the IPK's mass is exactly zero; the IPK is the kilogram. However, any changes in the IPK's mass over time can be deduced by comparing its mass to that of its official copies stored throughout the world, a rarely undertaken process called [...] "periodic verification". The only three <b>verifications</b> occurred in 1889, 1948, and 1989. For instance, the US owns four [...] 10%iridium (Pt10Ir) kilogram standards, two of which, K4 and K20, are from the original batch of 40 replicas delivered in 1884. The K20 prototype was designated as the primary national standard of mass for the US. Both of these, {{as well as those}} from other nations, are periodically returned to the BIPM for verification. Extraordinary care is exercised when transporting prototypes. In 1984, the K4 and K20 prototypes were hand-carried in the passenger section of separate commercial airliners.|$|E
500|$|Because {{the first}} forty {{official}} copies {{are made of}} the same alloy as the IPK and are stored under similar conditions, periodic <b>verifications</b> using {{a large number of}} replicas—especially the national primary standards, which are rarely used—can convincingly demonstrate the stability of the IPK. What has become clear after the third periodic verification performed between 1988 and 1992 is that masses of the entire worldwide ensemble of prototypes have been slowly but inexorably diverging from each other. It is also clear that the mass of the IPK lost perhaps 50µg over the last century, and possibly significantly more, in comparison to its official copies. The reason for this drift has eluded physicists who have dedicated their careers to the SI unit of mass. No plausible mechanism has been proposed to explain either a steady decrease in the mass of the IPK, or an increase in that of its replicas dispersed throughout the world. This relative nature of the changes amongst the world's kilogram prototypes is often misreported in the popular press, and even some notable scientific magazines, which often state that the IPK simply [...] "lost 50µg" [...] and omit the very important caveat of [...] "in comparison to its official copies".Even well respected organizations incorrectly represent the relative nature of the mass divergence as being one of mass loss, as exemplified by , and , and [...] The root of the problem is often the reporters' failure to correctly interpret or paraphrase nuanced scientific concepts, as exemplified by [...] by the Associated Press published on PhysOrg.com. In that AP story, Richard Davis—who used to be the NIST's kilogram specialist and now works for the BIPM in France—was correctly quoted by the AP when he stated that the mass change is a relative issue. Then the AP summarized the nature of issue with this lead-in to the story: [...] "A kilogram just isn't what it used to be. The 118-year-old cylinder that is the international prototype for the metric mass, kept tightly under lock and key outside Paris, is mysteriously losing weight— if ever so slightly". Like many of the above-linked sites, the AP also misreported the age of the IPK, using the date of its adoption as the mass prototype, not the date of the cylinder's manufacture. This is a mistake even Scientific American fell victim to in a print edition. Moreover, there are no technical means available {{to determine whether or not}} the entire worldwide ensemble of prototypes suffers from even greater long-term trends upwards or downwards because their mass [...] "relative to an invariant of nature is unknown at a level below 1000µg over a period of 100 or even 50 years". Given the lack of data identifying which of the world's kilogram prototypes has been most stable in absolute terms, it is equally valid to state that the first batch of replicas has, as a group, gained an average of about 25µg over one hundred years in comparison to the IPK.|$|E
5000|$|DVinsight: Design <b>Verification</b> Editor Checker for System Verilog [...] and Universal <b>Verification</b> Methodology, {{a product}} that {{provides}} Universal <b>Verification</b> Methodology editing and checking for functional <b>verification</b> engineers.|$|R
40|$|Over {{the last}} years, {{significant}} {{progress has been}} made both on static and runtime program <b>verification</b> techniques, focusing on increasing the quality of software. Within this track, we would like to investigate how we can leverage these techniques by combining them. Questions that will be addressed are for example: what can static <b>verification</b> bring to runtime <b>verification</b> to reduce impact on execution time and memory use, and what can runtime <b>verification</b> bring to static <b>verification</b> to take over where static <b>verification</b> fails to either scale or provide precise results? One can to some extent consider these two views (static <b>verification</b> supporting runtime <b>verification,</b> and runtime <b>verification</b> supporting static <b>verification)</b> as fundamentally representing the same scenario: prove what can be proved statically, and dynamically analyze the rest...|$|R
40|$|<b>Verification</b> of write {{operations}} {{is a crucial}} component of Byzantine fault-tolerant consistency protocols for storage. Lazy <b>verification</b> shifts this work out of the critical path of client operations. This shift enables the system to amortize <b>verification</b> effort over multiple operations, to perform <b>verification</b> during otherwise idle time, and to have only a subset of storage-nodes perform <b>verification.</b> This paper introduces lazy <b>verification</b> and describes implementation techniques for exploiting its potential. Measurements of lazy <b>verification</b> in a Byzantine fault-tolerant distributed storage system show {{that the cost of}} <b>verification</b> can be hidden from both the client read and write operation in workloads with idle periods. Furthermore, in workloads without idle periods, lazy <b>verification</b> amortizes the cost of <b>verification</b> over many versions and so provides a factor of four higher write bandwidth when compared to performing <b>verification</b> during each write operation. 1...|$|R
2500|$|North Korea will {{shut down}} and seal the Yongbyon nuclear facility, {{including}} the reprocessing facility and invite back IAEA personnel to conduct all necessary monitoring and <b>verifications</b> ...|$|E
2500|$|The {{definitions}} via universal morphisms {{are easy}} to state, and require minimal <b>verifications</b> when constructing an adjoint functor or proving two functors are adjoint. [...] They are also the most analogous to our intuition involving optimizations.|$|E
2500|$|Since 2011, Nestlé is {{the only}} infant formula {{manufacturer}} to have met the 104 criteria on the marketing of breastmilk substitutes (FTSE4Good BMS Criteria) of the FTSE4Good Responsible Investment Index. [...] Nestlé’s inclusion in the index is based on results of independent and transparent <b>verifications</b> conducted by Pricewaterhouse Coopers every 18 months. [...] Every year since 2009, Bureau Veritas conducts independent assurance of compliance with the Nestlé Policy and Instructions for Implementation of the WHO International Code of Marketing of Breastmilk Substitutes. Their Assurance Statements {{are available in the}} public domain.|$|E
5000|$|Discretionary data — {{may include}} Pin <b>Verification</b> Key Indicator (PVKI, 1 character), PIN <b>Verification</b> Value (PVV, 4 characters), Card <b>Verification</b> Value or Card <b>Verification</b> Code (CVV or CVC, 3 characters) ...|$|R
40|$|In this paper,we present Generic System Verilog Universal <b>Verification</b> Methodology based Reusable <b>Verification</b> Environment for {{efficient}} <b>verification</b> of Image Signal Processing IP's/SoC's. With {{the tight}} schedules on all projects {{it is important}} to have a strong <b>verification</b> methodology which contributes to First Silicon Success. Deploy methodologies which enforce full functional coverage and <b>verification</b> of corner cases through pseudo random test scenarios is required. Also, standardization of <b>verification</b> flow is needed. Previously, inside imaging group of ST, Specman (e) /Verilog based <b>Verification</b> Environment for IP/Subsystem level <b>verification</b> and C/C++/Verilog based Directed <b>Verification</b> Environment for SoC Level <b>Verification</b> was used for Functional <b>Verification.</b> Different <b>Verification</b> Environments were used at IP level and SoC level. Different Verification/Validation Methodologies were used for SoC <b>Verification</b> across multiple sites. <b>Verification</b> teams were also looking for the ways how to catch bugs early in the design cycle? Thus, Generic System Verilog Universal <b>Verification</b> Methodology (UVM) based Reusable <b>Verification</b> Environment is required to avoid the problem of having so many methodologies and provides a standard unified solution which compiles on all tools. The main aim of development of this Generic and automatic <b>verification</b> environment is to develop an efficient and unified <b>verification</b> environment (at IP/Subsystem/SoC Level) which reuses the already developed <b>Verification</b> components and also sequences written at IP/Subsystem level can be reused at SoC Level both with Host BFM and actual Core using Incisive Software Extension (ISX) and Virtual Register Interface (VRI) /Verification Abstraction Layer (VAL) approaches. IP-XACT based tools are used for automatically configuring the environment for various imaging IPs/SoCs. Comment: International journal of VLSI design & Communication Systems (VLSICS...|$|R
40|$|This {{bachelor}} thesis {{deals with}} presentation of capabilities of <b>verification</b> platform Questa Static from Mentor Graphics company. The basic {{information about the}} principles of assertion based <b>verification</b> is provided in the beginning.   The thesis describes Questa AutoCheck <b>verification</b> tool which is used for automatic <b>verification</b> of integrated circuits and Questa Formal <b>verification</b> tool which is used for static formal <b>verification</b> of integrated circuits. The set of examples is given to demonstrate various options of using these tools for <b>verification</b> of a concrete integrated circuit design. In conclusion, the thesis evaluates the possibilities of application of these tools in <b>verification</b> process...|$|R
2500|$|The French {{attorney}} general of Bobigny opened up an instruction in order [...] "to verify the presence in Le Bourget Airport, on 20 July 2005, of the plane numbered N50BH." [...] This instruction was opened following a complaint deposed in December 2005 by the Ligue des droits de l'homme (LDH) NGO ("Human Rights League") and the International Federation of Human Rights Leagues (FIDH) NGO on charges of [...] "arbitrary detention", [...] "crime of torture" [...] and [...] "non-respect {{of the rights of}} war prisoners". It has as objective to determine if the plane was used to transport CIA prisoners to Guantanamo Bay detainment camp and if the French authorities had knowledge of this stop. However, the lawyer defending the LDH declared that he was surprised that the instruction was only opened on 20 January 2006, and that no <b>verifications</b> had been done before.|$|E
2500|$|In the European context, safety {{effectiveness}} and quality is ensured through the [...] "Conformity Assessment" [...] that {{is defined as}} [...] "the method by which a manufacturer demonstrates that its device complies {{with the requirements of}} the European Medical Device Directive". The directive specifies different procedures according to the class of the device ranging from the simple Declaration of Conformity (Annex VII) for Class I devices to EC verification (Annex IV), Production quality assurance (Annex V), Product quality assurance (Annex VI) and Full quality assurance (Annex II). The Medical Device Directive specifies detailed procedures for Certification. In general terms, these procedures include tests and <b>verifications</b> that are to be contained in specific deliveries such as the risk management file, [...] the technical file and the quality system deliveries. [...] The risk management file is the first deliverable that conditions the following design and manufacturing steps. Risk management stage shall drive the product so that product risks are reduced at an acceptable level with respect to the benefits expected for the patients {{for the use of the}} device. The technical file contains all the documentation data and records supporting medical device certification. FDA technical file has similar content although organized in different structure. [...] The Quality System deliverables usually includes procedures that ensure quality throughout all product life cycle. The same standard (ISO EN 13485) is usually applied for quality management systems in US and worldwide.|$|E
2500|$|Pride and Prejudice, {{like most}} of Austen's other works, employs the {{narrative}} technique of free indirect speech, which {{has been defined as}} [...] "the free representation of a character's speech, by which one means, not words actually spoken by a character, but the words that typify the character's thoughts, or the way the character would think or speak, if she thought or spoke". Austen creates her characters with fully developed personalities and unique voices. Though Darcy and Elizabeth are very alike, they are also considerably different. By using narrative that adopts the tone and vocabulary of a particular character (in this case, Elizabeth), Austen invites the reader to follow events from Elizabeth's viewpoint, sharing her prejudices and misapprehensions. [...] "The learning curve, while undergone by both protagonists, is disclosed to us solely through Elizabeth's point of view and her free indirect speech is essential... for it is through it that we remain caught, if not stuck, within Elizabeth's misprisions." [...] The few times the reader is allowed to gain further knowledge of another character's feelings, is through the letters exchanged in this novel. Darcy's first letter to Elizabeth is an example of this as through his letter, the reader and Elizabeth are both given knowledge of Wickham's true character. Austen is known to use irony throughout the novel especially from viewpoint of the character of Elizabeth Bennet. She conveys the [...] "oppressive rules of femininity that actually dominate her life and work, and are covered by her beautifully carved trojan horse of ironic distance.". Beginning with a historical investigation of the development of a particular literary form and then transitioning into empirical <b>verifications,</b> it reveals FID as a tool that emerged over time as practical means for addressing the physical distinctness of minds. Seen in this way, FID is a distinctly literary response to an environmental concern, providing a scientific justification that does not reduce literature to a mechanical extension of biology, but takes its value to be its own original form.|$|E
40|$|Proper <b>verification</b> of FPGA-code {{requires}} knowledge, skills, {{tools and}} resources. ABB Robotics uses FPGA technology in their robot control system. The increasing complexity of their FPGA designs requires increasingly more advanced <b>verification</b> methods. This provides an appropriate research on methodologies, languages and tools for more detailed evaluation based on ABB Robotics requirements and possibilities. The thesis demonstrates the chosen methods, languages and tools for <b>verification</b> of a FPGA-design by <b>verification</b> methods that are {{state of the}} art. The <b>verification</b> environment such as functional <b>verification,</b> open source VHDL <b>verification</b> methodology (OSVVM), and universal <b>verification</b> methodology (UVM) were investigated in practical tests followed by an evaluation of {{advantages and disadvantages of}} the tests according the company requirements. This provides the <b>verification</b> teams with different test environments and presents available options for <b>verification</b> development and future work...|$|R
40|$|Abstract. We examine IBM’s {{exploitation}} of formal <b>verification</b> using RuleBase- a formal <b>verification</b> tool {{developed by the}} IBM Haifa Research Laboratory. The goal of the paper is methodological. We identify an integrated methodology for the deployment of formal <b>verification</b> which involves three complementary modes: architectural <b>verification,</b> block-level <b>verification,</b> and design exploration. ...|$|R
40|$|Abstract. We {{present a}} <b>verification</b> {{algorithm}} that can automatically switch from RAM based <b>verification</b> to disk based <b>verification</b> without discarding {{the work done}} during the RAM based <b>verification</b> phase. This avoids having to choose beforehand the proper <b>verification</b> algorithm. Our experimental results show that typically our integrated algorithm is as fast as (sometime faster than) the fastest of the two base (i. e. RAM based and disk based) <b>verification</b> algorithms. ...|$|R
