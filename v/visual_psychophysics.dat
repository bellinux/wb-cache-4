79|24|Public
5000|$|Vilayanur S. Ramachandran - Renowned neuroscientist {{known for}} his work in the fields of {{behavioral}} neurology and <b>visual</b> <b>psychophysics</b> ...|$|E
50|$|Sperling’s first publication, “Negative Afterimages Without Prior Positive Images,” was in <b>visual</b> <b>psychophysics.</b> He {{then went}} on to publish {{mathematical}} models for adaptation and flicker, contrast detection, binocular vision, and motion perception.|$|E
50|$|Floreano {{received}} an M.A. in <b>visual</b> <b>psychophysics</b> from the University of Trieste in 1988, an M.Sc. in neural computation from the University of Stirling in 1992, and a Ph.D. in cognitive systems and robotics from the University of Trieste in 1995.|$|E
50|$|Current {{research}} in <b>visual</b> neuroscience and <b>psychophysics</b> is investigating how microsaccades relate to fixation correction, control of binocular fixation disparity and attentional shifts. Recent {{research has found}} a direct correlation between illusory motion and microsaccades.|$|R
40|$|Legal {{status in}} Germany: Permanent {{resident}} Other: Overseas Citizenship of India (OCI) Research Interests: Theories and applications of human <b>visual</b> perception and <b>psychophysics.</b> Problems in low and mid level vision, including figure ground organization, natural image statistics, depth perception, perceptual organization, cu...|$|R
50|$|Dr. Faubert and the <b>Visual</b> Perception and <b>Psychophysics</b> Laboratory {{have been}} {{involved}} in transferring laboratory developments into the commercial domain since 1999. Several funding agencies {{have been involved}} in brokering this technology transfer. From the commercial domain, Essilor (an ophthalmic lens company) has partnered with the Natural Sciences and Engineering Research Council of Canada (NSERC). Together, their aim has been to explore the connection between aging, visual perception, and posture. Dr. Faubert has been a chairholder at the NSERC since 2003, at which time his laboratory received a five-year grant (renewed in 2008).|$|R
50|$|Vilayanur Subramanian Ramachandran (born August 10, 1951) is a neuroscientist known {{primarily}} {{for his work}} in the fields of behavioral neurology and <b>visual</b> <b>psychophysics.</b> He is currently a Professor in the Department of Psychology and the Graduate Program in Neurosciences at the University of California, San Diego.|$|E
5000|$|David Marr first {{coined the}} term [...] "Glass Patterns" [...] in his 1982 work on visual perception, {{resulting}} in an increased interest in the phenomenon. Because of their mathematical simplicity and physiological underpinnings, Glass patterns have subsequently been used in dozens of electrophysiology and <b>visual</b> <b>psychophysics</b> experiments, resulting in additional understanding of the physiology of visual perception.|$|E
50|$|As {{molecular}} biology became {{more dependent on}} biochemistry, Glaser again considered a career change. His experience automating visual tasks in physics and {{molecular biology}} led him to an interest in human vision and how the brain processes what is seen. He began to work on computational modeling of the visual system and <b>visual</b> <b>psychophysics,</b> and spent a sabbatical at the Rowland Institute.|$|E
40|$|We are {{surrounded}} by surfaces that we perceive by visual means. Understanding the basic principles behind this perceptual process is a central theme in <b>visual</b> psychology, <b>psychophysics</b> and computational vision. In many of the computational models employed in the past, it has been assumed that a metric representation of physical space can be derived by visual means. Psychophysical experiments, as well as computational considerations, can convince us that the perception of space and shape has a much more complicated nature, and that only a distorted version of actual, physical space can be computed. This paper develops a computational geometric model that explains why such distortion might take place. The basic idea is that, both in stereo and motion, we perceive the world from multiple views. Given the rigid transformation between the views and {{the properties of the}} image correspondence, the depth of the scene can be obtained. Even a slight error in the rigid transformation parameters c [...] ...|$|R
40|$|Primate visual {{systems support}} an {{elaborate}} specialization for processing color information. Concentrating on the hue component, we observe that, contrary to Mondrian-like assumptions, hue varies in a smooth manner for ecologically important natural imagery. To represent these smooth variations, {{and to support}} those information processing tasks that utilize hue, a piecewise smooth hue field is postulated. The geometry of hue-patch interactions is developed analogously to orientation-patch interactions in texture. The result is a model for long-range (horizontal) interactions in the color domain, the power of which is demonstrated {{on a number of}} examples. Implications for computer image processing, computer vision, <b>visual</b> neurophysiology and <b>psychophysics</b> are discussed...|$|R
40|$|Advances in {{computing}} {{and communications}} have brought about an increasing demand for visual information. Visual Computing addresses the principles behind visual technology, and provides readers {{with a good}} understanding of how the integration of computer graphics, visual perception and imaging is achieved. Included in the book is an overview of important research areas within this subject which will be useful for further work in the field. Foundations of <b>visual</b> perception and <b>psychophysics</b> are presented as well as basic methods of imaging and computer vision. This book serves as an excellent reference and textbook for those who wish to apply or study visual computing technology...|$|R
5000|$|More {{recent work}} {{concerns}} {{the characterization of}} fast adaptive mechanisms in {{the responses of the}} early visual system, a comparison with the properties of natural images [...] and a test of the resulting models in the responses to complex natural stimuli. Other recent research projects include the use of optical and electrical imaging of cortical responses, population coding of visual stimuli, and the improvement of techniques for <b>visual</b> <b>psychophysics</b> in mice.|$|E
50|$|He also {{connected}} {{advances in}} <b>visual</b> <b>psychophysics</b> and neuroscience {{with a wide}} range of matters in health science, national defense, child development, and transportation safety. He proposed that the hazards of night driving, for example, can be better understood through the neurological concept of two visual systems, explaining drivers’ over-confidence at night as resulting from sustained efficiency of visual guidance combined with selective degradation of focal recognition abilities (Leibowitz, Shupert & Post, 1985).|$|E
50|$|Leibowitz’s {{research}} investigated basic {{issues of}} <b>visual</b> <b>psychophysics,</b> perception of size, distance & motion, peripheral vision and oculomotor functioning. He also studied problems of aviation, traffic safety, motion sickness, postural instability (especially during stair descent), {{and the effects}} of stress on perception. Indeed, one of the striking characteristics of Leibowitz’s research was his symbiotic view of “basic” and “applied” science. In the early 1970s, for example, Leibowitz’s lab developed the laser optometer and used it to advance our basic understanding of the eyes’ focusing behavior (visual accommodation); these “basic” experiments simultaneously addressed real-world difficulties such as night myopia (Leibowitz & Owens, 1978) and visual fatigue (Tyrrell & Leibowitz, 1990).|$|E
30|$|Spectral {{image quality}} is {{influenced}} {{by a number of}} factors [25] and understanding their role and how different devices are used in the digital documentation workflow will help to define better procedures for acquisition and processing. Spectral image recording systems are first and foremost imaging devices, and so can be compared against the performance of more familiar digital cameras and scanners. The quality of the images acquired can be assessed by the well-established methods of <b>visual</b> scaling and <b>psychophysics,</b> with observers judging each image either in isolation or side-by-side with a reference image [26]. Various attributes of image quality can be distinguished and scaled, including tonal rendering, colour, sharpness, naturalness, freedom from defects, etc.|$|R
40|$|Abstract The color {{reproduction}} {{is based on}} <b>visual</b> perception. The <b>psychophysics</b> experiments present the light source; illuminants and view background affect the results of color matching. Paper is a typical substrate for printed color matching and effects printed color greatly. Now almost all of print papers contain optical brightening agents, which changes significantly the color appearance of printed color and makes color shifting of printed color matching. This paper used CAT 02 chromatic adaptation models to transform the measurements of printed color in paper with and without OBA, compared the effect of printed color matching between before and after transforming with display, present the method using chromatic adaptation transforms to improve the accurate of printed color matching...|$|R
40|$|To my Parentsiv The basic roadmap of {{the visual}} cortex starts with an early stage in which visual input is encoded {{primarily}} as edges. Information then flows through branching pathways into higher, more specialized regions of the brain. One such area is specialized in processing color, another area processes shape, etc. This encoding scheme poses some problems in explaining certain aspects of our daily experience of seeing. If the cortex processes the various visual features separately, how do we see all those elements integrated as unified objects? What mechanisms bind the features together? If the cortex encodes the visual scene {{in terms of its}} edges, then how do we see solid surfaces? What mechanisms fill-in the map of outlines? This thesis investigates the problems of binding and filling-in using the techniques of <b>visual</b> illusion <b>psychophysics</b> and transcranial magnetic stimulation (TMS). TMS is known to cause the perception of a brief visual flash, or phosphene. We find that the appearance of the phosphene is found to depend on concurrent and previously viewed visual stimuli. In particular, TMS can cause an instant replay effect whereby recently presented visual stimul...|$|R
5000|$|Eagleman & Sejnowski (2000abc) {{proposed}} a third alternative: visual awareness is neither predictive nor on-line, but is instead postdictive, {{such that the}} percept attributed {{to the time of}} the flash is a function of events that happen in the [...] following the flash. This postdictive framework is consistent with findings in other fields, such as backward masking in <b>visual</b> <b>psychophysics</b> (Bachmann, 1994), or the color phi phenomenon. In backward masking, a stimulus followed in rapid succession by a second stimulus can block or modify the perception of the first one. In the color phi phenomenon, two colored dots presented sequentially within a small time and distance will appear to have changed color {{in the middle of their}} apparent trajectory. Since the viewer cannot know what the color of the second dot will be until having seen the second dot, the only explanation is that the conscious percept attributed to the [...] "trajectory" [...] of the dots is formed after the second dot has [...] "arrived" [...] at its destination. Eagleman & Sejnowski found that the perception attributed to the time of the flash depends on events in the next [...] after the flash. In this way, they drew a correspondence between the flash-lag effect and the Fröhlich effect, wherein the first position of a moving object entering a window is misperceived.|$|E
40|$|AbstractOur {{understanding}} of how we see color has benefited from the long tradition of <b>visual</b> <b>psychophysics.</b> More recently, models and methods from psychophysics are guiding modern neuroimaging experiments on color vision. Combining the two techniques can lead to discoveries that neither can make alone...|$|E
40|$|The full-text of {{this book}} chapter is not {{available}} in ORA. Citation: Braddick, O. & Adlard, A. (1978). Apparent motion and the motion detector. In: Armington, J., Krauskopf, J. & Wooten, B. R. (eds.) <b>Visual</b> <b>psychophysics</b> and physiology: a volume dedicated to Lorrin Riggs. New York: Academic Press, pp. 417 - 426...|$|E
40|$|AbstractFirst level short- and {{long-range}} spatial {{interactions are}} considered to be processed in the primary <b>visual</b> cortex. In <b>psychophysics,</b> they are measured with two kinds of stimuli, Gabor patches and lines/points. Each has its own short- and long-range definitions. We show that first, in terms of visual angle separation, the two definitions do not correspond to identical scales of interactions and second, that Gabor data can be matched to the lines/points definition by properly considering the observed effects. As a consequence, three regimes of spatial interaction are present: a case where overlapping of stimuli is present, and two others for spatially separated stimuli which we define as the short- and long-range regimes. Both types of stimuli show compatible lateral interactions and, we think, permit the measurement of the same underlying mechanisms...|$|R
40|$|Abstract: Visually conspicuous, or {{so-called}} salient, stimuli {{often have}} the capability of attracting fo-cal visual attention towards their locations. Several computational architectures subserving this bottom-up, stimulus-driven, spatiotemporal deployment of attention are reviewed in this article. The resulting compu-tational models have applications {{not only to the}} prediction of <b>visual</b> search <b>psychophysics,</b> but also, in the domain of machine vision, to the rapid selection of regions of interest in complex, cluttered visual environ-ments. We describe an unusal such application, to the objective evaluation of advertising designs. One of the most important functions of selective visual attention is to rapidly direct our gaze towards ob-jects of interest in our visual environment. From an evolutionary standpoint, this rapid orienting capability is critical in allowing living systems to quickly become aware of possible preys, mates or predators in their cluttered visual world. It has become clear that attention guides where to look next based on both bottom-up (image-based) and top-down (task-dependent) cues (James, 1890 / 1981). As such, attention implements an information processing bottleneck, only allowing {{a small part of the}} incoming sensory information to reach short-term memory and visual awareness [Linking Attention to Learning, Expectation, Competi-tion and Consciousness]. That is, instead of attempting to fully process the massive sensory input in parallel, nature has devised a serial strategy to achieve near real-time performance despite limited compu...|$|R
40|$|Techniques are {{presented}} for analyzing data collected {{as a function}} of: a circular independent variable (e. g., angle, direction, or orientation) or an independent variable which is cyclical (e. g., months of the year). The procedures {{are presented}} in a tutorial manner, emphasizing their relationship to more traditional statistics in experimental psychology. Studies of <b>visual</b> physiology or <b>psychophysics</b> frequently employ dependent measures which are some function of angle or direction of motion. In this paper we shall outline a simple statistical approach to the special problems raised by such data. No claims are made for {{the uniqueness of the}} approach (Mardia, 1972); we seek only to present the procedure in as accessible a manner as we can, given the limitations of space. Consider some examples of the class of studies we address. Barlow, Hill, and Levick (1964) measured the responses of rabbit retinal ganglion cells to spots o...|$|R
40|$|Threshold drifts {{are a very}} {{disturbing}} phenomenon when doing detection experiments in <b>visual</b> <b>psychophysics.</b> Here, a model is presented describing these drifts {{as a result of}} transitions between different fixpoints for the dynamics of individual neurons. These transitions result from noise within the neurons as well as from interactions among the neurons. To model these interactions the Ising-model of ferromagnetism is employed. 2...|$|E
40|$|Dipper-shaped curves often {{accurately}} {{depict the}} relationship between a baseline or “pedestal ” magnitude and a just-noticeable difference in it. This tutorial traces the 45 year history of the dipper function in auditory and <b>visual</b> <b>psychophysics,</b> focusing on when they happen, and why. Popular theories for both positive and negative masking (i. e. the “handle” and “dip,” respectively) are described. Sometimes, but not always, negative masking disappears with an appropriate re-description of stimulus magnitude...|$|E
40|$|<b>Visual</b> <b>psychophysics</b> {{represent}} an invaluable way of studying the visual system aging process. First of all, the author considers the modifications induced by aging on the optic {{characteristics of the}} human eye. Subsequently, he outlines the specific reduction of visual acuity, contrast sensitivity, flicker fusion and color vision caused by optic nerve and visual pathway aging. He points to the role and importance of psychophysic investigations in the accurate definition of visual system aging...|$|E
40|$|We are {{surrounded}} by surfaces that we perceive by visual means. Understanding the basic principles behind this perceptual process is a central theme in <b>visual</b> psychology, <b>psychophysics</b> and computational vision. Metric descriptions of physical space encoding distances between features in the environment have been used throughout the ages for various purposes. Naturally, such descriptions were used by early theorists for modelling perceptual space; that is, surfaces may be represented in our brains by encoding the distance of each point on the surface from our eye. The development of technology has allowed empirical scientists to perform accurate experiments measuring properties of perceptual space. It turns out that humans estimate a distorted version of their extra-personal space. A large number of experiments have been performed to study stereoscopic depth perception using tasks that involve the judgment of depth at different distances [8, 9, 13, 22]. Recently, a few experiments have been conducted to compare aspects of depth judgment due to stereoscopic and monocular motion perception [24]. In these experiments, {{it has been shown}} that from stereo vision humans over-estimate depth (relative to fronto-parallel size) at near fixations and under-estimate it at far fixations, whereas human depth estimates from visual motion are not affected by the fixation point. On the other hand, the orientation of an object in space does not affect depth judgment in stereo vision while it has a strong effect in motion vision, for the class of motions tested. This paper develops a computational geometric model that explains why such distortion might take place. The basic idea is that, both in stereo and motion, we perceive the world from multiple views. Given the rigid transformation bet [...] ...|$|R
40|$|We {{will discuss}} our {{attempts}} to study neural correlates of the perceptual alternations experienced upon viewing of ambiguous figures, and relate them to new psychophysical evidence offering {{a new twist}} in the eye-versus-percept debate. Our studies {{over the last decade}} indicated that perception-responsive cells are concentrated in cortical areas {{near the top of the}} processing hierarchy, but that they can be found all along the <b>visual</b> pathway. Similarly, <b>psychophysics</b> has shown that both, monocular as well as binocular, percept based neural representations contribute to perceptual dominance. Our new psychophysical evidence suggests a time-dependence of eye and percept contributions in binocular rivalry: initially a given monocular channel has greater influence on dominance, regardless of the percept. Over time, this reverses, with percept-related (ie eye-independent) processes increasingly 'urging' for a perceptual switch. We suggest this may reflect a single process, where monocular as well as binocular neural stages affect each other in a feedback-loop that evolves over time. Understanding rivalry thus calls for the study of networks rather than single neurons...|$|R
40|$|Human and {{non-human}} primates {{excel at}} visual recognition tasks. The primate visual system exhibits a strong degree of selectivity {{while at the}} same time being robust to changes in the input image. We have developed a quantitative theory to account for the computations performed by the feedforward path in the ventral stream of the primate visual cortex. Here we review recent predictions by a model instantiating the theory about physiological observations in higher visual areas. We also show that the model can perform recognition on datasets of complex natural images at a level comparable to psychophysical measurements on human observers during rapid categorization tasks. In sum, the evidence suggests that the theory may provide a framework to explain the first 100 - 150 milliseconds of visual object recognition. The model also constitutes a vivid example of how computational models can interact with experimental observations in order to advance our understanding of a complex phenomenon. We conclude by suggesting a number of open questions, predictions and specific experiments for <b>visual</b> physiology and <b>psychophysics...</b>|$|R
40|$|Abstract. In this paper, a {{proposal}} which quantifies visual saliency {{based on an}} information theoretic definition is evaluated with respect to <b>visual</b> <b>psychophysics</b> paradigms. Analysis reveals that the proposal explains {{a broad range of}} results from classic visual search tasks, including many for which only specialized models have had success. As a whole, the results provide strong behavioral support for a model of visual saliency based on information, supplementing earlier work revealing the efficacy of the approach in predicting primate fixation data...|$|E
40|$|Visual categorization, {{or making}} sense of novel shapes and shape classes, is a {{computationally}} challenging and behaviorally important task, which is not widely addressed in computer vision or <b>visual</b> <b>psychophysics</b> (where the stress is rather on the generalization of recognition across changes of viewpoint). This paper examines the categorization abilities of four current approaches to object representation: structural descriptions, geometric models, multidimensional feature spaces, and similarities to reference shapes. It is proposed that a scheme combining features of all four approaches is a promising candidate for a comprehensive and computationally feasible theory of categorizatio...|$|E
40|$|Inexpensive {{circuit boards}} have {{appeared}} on the market which transform a normal microcomputer's disk drive into a video disk capable of playing extended video sequences in real time. This technology enables the performance of experiments which were previously impossible, or at least prohibitively expensive. The new technology achieves this capability using special purpose v hardware to compress and decompress individual video frames, which enables a video stream to be transferred over relatively low bandwidth disk interfaces. This paper will describe {{the use of such}} devices for <b>visual</b> <b>psychophysics</b> and present the technical issues that must be considered when evaluating individual products...|$|E
40|$|Animals (especially humans) have {{an amazing}} {{ability to learn}} new tasks quickly, and switch between them flexibly. How brains support this ability is largely unknown, both neuroscientifically and algorithmically. One {{reasonable}} supposition is that modules drawing on an underlying general-purpose sensory representation are dynamically allocated on a per-task basis. Recent results from neuroscience and artificial intelligence suggest {{the role of the}} general purpose visual representation may be played by a deep convolutional neural network, and give some clues how task modules based on such a representation might be discovered and constructed. In this work, we investigate module architectures in an embodied two-dimensional touchscreen environment, in which an agent's learning must occur via interactions with an environment that emits images and rewards, and accepts touches as input. This environment is designed to capture the physical structure of the task environments that are commonly deployed in <b>visual</b> neuroscience and <b>psychophysics.</b> We show that in this context, very simple changes in the nonlinear activations used by such a module can significantly influence how fast it is at learning visual tasks and how suitable it is for switching to new tasks...|$|R
40|$|Imagine you {{are going}} to meet a friend and watch a movie. You are running late, the movie has started and your friend sends you a message to say they have gone in. You walk into the movie theatre and search for your friend’s face but have trouble finding them in the dark. Suddenly the screen lights up {{and you can see the}} seat numbers and faces of the people in the theatre. You manage to spot your friend, they see you and flash you a smile – you are forgiven your lateness! You begin to squeeze your way along the row to them. The movie {{features}} characters speaking in unfamiliar accents to you and at times you find yourself struggling to understand what is being said. But at least your seats are near the front so you can clearly see everything that is going on. This everyday situation contains multiple instances of a relation between physical stimuli and psychological responses. How do you tell the difference between your friend’s face and other faces? How do you identify their emotional state? How much light do you need to be able to see and then read the seat numbers? How do you judge whether you can squeeze along the row to them? How loud does the volume on the movie need to be for you to discriminate the different words being spoken? How close do you need to sit to perceive different levels of detail in the <b>visual</b> images? <b>Psychophysics</b> provides us with a theory and set of methods to answer these types of questions, essentially, methods that determine the relation between the intensity of a stimulus, the transformations it undergoes in the external and internal environment, and the sensation and subsequent response of an observer. This chapter provides an overview of the history of psychophysics, its classical methods and contemporary approaches to understand the relationship between the stimulus, noise and observer response...|$|R
40|$|In early visual cortex, visual input is encoded {{primarily}} as edges. Information then flows into more specialized {{regions of the}} brain, which process visual features such as color, motion, etc. This encoding scheme poses some problems in explaining the experience of seeing. If the cortex processes various visual features separately, how do we see unified objects? What mechanisms bind the features together? If the cortex encodes the visual scene {{in terms of its}} edges, then how do we see solid surfaces? What mechanisms fill-in the map of outlines? This thesis investigates the problems of binding and filling-in using the techniques of <b>visual</b> illusion <b>psychophysics</b> and transcranial magnetic stimulation (TMS). We find that TMS can cause an instant replay effect, whereby recently presented visual stimuli are seen again. When TMS induces an instant replay shortly after the presentation of Cai’s asynchronous binding illusion, some subjects see an image of the actual visual stimulus, undistorted. It appears that TMS can selectively activate a hidden, accurate representation of the stimulus, revealing it without the distortion caused by other processes. We also find a number of cases in which visual features are decomposed and/or misbound. TMS-induced instant replay can cause the color of one object to be bound to the position and orientation of another. It can also separately replay the color and orientation of a grating. In a non-TMS experiment, we create a stimulus that induces a steady-state misbinding of color and motion—-a vivid, long-lasting misbinding effect ideal for neurophysiological investigation. These experiments confirm the separate encoding of visual features and the existence of an active binding mechanism. Finally, we study filling-in by manipulating an effect distilled from the artwork of Julian Stanczak, in which color is perceived to spread discretely among segregated patches of space. We find that color-filling is dependent on perceptual surfaces, such that overlaid surfaces can support separate filling processes. It appears possible that the neural mechanisms of binding and filling-in might be intimately related, both of them highly integrated with the process of surface segregation. </p...|$|R
