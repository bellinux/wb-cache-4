0|1267|Public
40|$|Rec. M. 560 1 [...] - two {{national}} systems, one {{at each end}} These may comprise one or more 4 -wire amplified national circuits with 4 -wire interconnection, and circuits with 2 -wire connection to terminal exchanges and subscribers. 2 Fascicle IV. 1 [...] - Rec. M. 560 Figure 1 /M. 560, (M), p. 2. 3 International telephone circuits, <b>virtual</b> analogue <b>switching</b> <b>points</b> and relative transmission levels 2. 3. 1 From a transmission planning point of view, an international telephone circuit is defined by its "virtual analogue switching points" in the international centre. 2. 3. 2 <b>Virtual</b> analogue <b>switching</b> <b>points</b> <b>Virtual</b> analogue <b>switching</b> <b>points</b> are theoretical points with specified relative levels. For circuits terminating at a digital international centre, the concept of <b>virtual</b> analogue <b>switching</b> <b>points</b> postulates the existence of ideal analogue-to-digital coders and digital-to-analogue decoders, via which the desired analogue points c...|$|R
30|$|The <b>virtual</b> <b>switches</b> can be broadly {{divided into}} hypervisor-based or {{hardware-based}} {{depending on the}} location of the implementation of <b>virtual</b> <b>switches.</b> The hypervisor-based <b>virtual</b> <b>switches</b> are typically written entirely in software. The hardware-based <b>virtual</b> <b>switch</b> is partly implemented on special hardware like NIC, NetFPGA etc. The basis of hypervisor-based <b>virtual</b> <b>switch</b> is Open vSwitch [71]. Open vSwitch resides within the management domain of hypervisor (e.g. Domain- 0 in Xen) and provides connectivity between virtual machines and physical interfaces. Open vSwitch uses VLANs and GRE tunnels for secured virtual network and virtual path respectively. It also supports basic ACL.|$|R
50|$|When {{the first}} VNIC is created on a system, a <b>virtual</b> <b>switch</b> is also created above the {{physical}} interface. Though not directly {{accessible to the}} user, the <b>virtual</b> <b>switch</b> provides connectivity between all VNICs configured on the same physical interface, enabling the virtual network in a box scenario. The <b>virtual</b> <b>switch</b> forwards packets between the system's VNICs. Thus, packets from an internal VNIC source never have to pass to the external network to reach an internal network destination.|$|R
30|$|Tseng et al. [74] {{proposed}} {{the integration of}} open-source hypervisor with software-based <b>virtual</b> <b>switch</b> and aims at secure network environment among VMs. Luo et al. [75] proposed hardware-based <b>virtual</b> <b>switch</b> using special NIC to provide network connectivity among VMs in the datacenter.|$|R
5000|$|The VEM {{uses the}} vDS API, which was {{developed}} by VMware and Cisco together Besides offering the NX-OS interface to configure, manage and monitor the <b>virtual</b> <b>switch</b> it also supports LACP link aggregation where the standard <b>virtual</b> <b>switches</b> only support static LAGs ...|$|R
30|$|Hardware-based <b>virtual</b> <b>switch</b> {{eliminates}} {{some limitations}} (like CPU or memory usage) of software-based <b>virtual</b> <b>switch.</b> Two hardware-based <b>virtual</b> <b>switch</b> implementations are <b>Virtual</b> Ethernet Port Aggregator (VEPA) [72] and VNTag [73]. The Virtual Ethernet Port Aggregator (VEPA) is a standardization led by HP Extreme, IBM, Brocade and Juniper etc. The VEPA allows traffic of VM to exit and re-enter the same port to enable switching among VMs. The VEPA has MACSec scheme to provision a secure connection between VEPA and bridges.|$|R
40|$|Recently <b>virtual</b> <b>switches</b> in {{data center}} hosts have been {{employed}} to interconnect virtual machines (VMs) within data center networks. Such a virtual network layer, however, faces performance challenges {{when the number}} of VMs and the line rates scale up. Motivated by the performance and programmability of intelligent network interface cards (NICs), we propose to offload the <b>virtual</b> <b>switching</b> onto such programmable NICs (PNICs) to achieve scalable VM networking. We describe the design and advantages of a novel PNIC-oriented data center network architecture. We then present a prototype of a PNIC based <b>virtual</b> <b>switch</b> that supports <b>virtual</b> NICs, OpenFlow <b>switching,</b> clock synchronization and flow monitoring. We finally introduce an efficient packet buffering mechanism enabled by such PNICs and OpenFlow-capable top-of-rack switches for reducing the congestion on network fabric...|$|R
5000|$|P+V Fabric â€” Leaf-spine {{physical}} Clos fabric plus <b>virtual</b> <b>switches</b> {{controlled by}} SDN Controller ...|$|R
40|$|This paper {{proposes a}} novel ATM {{multicast}} scheme which supports selective multimedia data transmission over ATM networks. The multicast scheme provides functions for receiver initialized resource reservation, end-to-end QOS guarantee and selective data transmission of hierarchical encoded multimedia data. These functions are achieved {{by using a}} centralized QOS negotiation and routing mechanism. In addition, the scheme also supports dynamic nodes joining / leaving. A simulation platform for validating the proposed scheme has been developed in a distributed CORBA environment. In this platform, ATM switches are modeled as <b>virtual</b> <b>switches</b> and implemented as concurrent threads running on the workstations. The data links between <b>virtual</b> <b>switches</b> are implemented by real AAL 5 virtual circuit which enables actual QOS reservation. Signaling of the <b>virtual</b> <b>switches</b> is implemented by the CORBA-links. The latter connects CORBA daemons that manage the <b>virtual</b> <b>switches.</b> Preliminary simulation results demonstrate the feasibility of implementing this multicast scheme in a real ATM switch network. 1. Introductio...|$|R
25|$|A <b>Virtual</b> <b>Switch</b> {{available}} in <b>Virtual</b> PC version 4.1 or earlier allows adding multiple network adapters.|$|R
50|$|A <b>Virtual</b> Layer-3 <b>Switch</b> is the software-emulated virtual IP router. Several <b>Virtual</b> Layer-3 <b>Switches</b> can {{be created}} on a single VPN Server instance. A <b>Virtual</b> Layer-3 <b>Switch</b> has <b>virtual</b> IP {{interfaces}} connected to Virtual Hubs. It also has several static routing table entries.|$|R
50|$|UT-VPN Server has <b>Virtual</b> L3 <b>switch</b> function. <b>Virtual</b> L3 <b>switch</b> does L3-switching between virtual HUB on the UT-VPN Server.|$|R
3000|$|There is no last <b>switching</b> <b>point</b> but, after {{a finite}} <b>switching</b> <b>point,</b> the {{sequence}} of all the <b>switching</b> <b>points</b> exceeding some sufficiently large finite one contains an infinite sequence of <b>switching</b> <b>points</b> to primary self-maps from [...]...|$|R
40|$|International audienceIn an SDN/NFV-enabled network, the {{behavior}} of <b>virtual</b> <b>switches</b> {{is a major concern}} in determining the overall network performance. The prominent open-source solution for <b>virtual</b> <b>switching</b> is Open vSwitch while the DPDK library has been developed to accelerate the packet processing. In this paper, we develop a general framework for the modeling and the analysis of DPDK-based <b>virtual</b> <b>switches,</b> taking into account the switch-over times (amount of time needed for a CPU core to switch from one input queue to another). Our model delivers performance metrics such as the buffer occupancy, the loss rate and the sojourn time of a packet in RX queues. We compare our new model with two existing models. Numerical results show that our model combines the accuracy of one model and the efficiency of the other...|$|R
5000|$|When {{using the}} {{advanced}} and extended network capabilities {{by using the}} Cisco Nexus 1000v distributed <b>virtual</b> <b>switch</b> the following network-related limitations apply: ...|$|R
3000|$|There is no last <b>switching</b> <b>point</b> {{but after}} a finite <b>switching</b> <b>points</b> all the <b>switching</b> <b>points</b> {{exceeding}} some sufficiently large finite one involve switches to asymptotically strictly contractive primary self-maps from [...]...|$|R
50|$|Originally {{created at}} Nicira {{before moving to}} VMWare (and {{eventually}} The Linux Foundation,) OvS is an open source <b>virtual</b> <b>switch</b> supporting standard management interfaces and protocols.|$|R
50|$|Switch Light vSwitch: A user space {{software}} module for KVM-based <b>virtual</b> <b>switches</b> that adds enhanced functionality and improved performance {{on top of}} the Open vSwitch kernel.|$|R
40|$|This paper {{proposes a}} novel ATM {{multicast}} scheme which allows receiver initialized resource reservation, end-to-end QoS guarantee, selective data transmission and dynamic member joining / leaving to a multicast group. These features are achieved {{by using an}} Open Signaling Architecture that allows centralized multicast agents to send signaling scripts to and receive link state information from the network switches. A simulation platform for validating the proposed scheme has been developed in CORBA environment. In this platform, ATM switches are modeled as <b>virtual</b> <b>switches</b> which are implemented as concurrent threads running on workstations. Signaling of the <b>virtual</b> <b>switches</b> is implemented by using the CORBA links which connect the multicast agents and the Open Signaling Interface of the <b>virtual</b> <b>switches.</b> The simulation results demonstrated the feasibility of implementing this multicast scheme in real ATM switch networks. 1. Introduction Multicast refers to the transmission of data to [...] ...|$|R
50|$|Virtual {{machines}} within enterprise server environments {{began to}} gain popularity in 2005 and quickly started {{to become a}} standard in the way companies deploy servers and applications. In order to deploy these servers within a virtual environment, a virtual network needed to be formed. As a result, companies such as VMware created a resource called a <b>virtual</b> <b>switch.</b> The purpose of the <b>virtual</b> <b>switch</b> was to provide network connectivity within the virtual environment so that virtual machines and applications could communicate within the virtual network {{as well as with}} the physical network.|$|R
50|$|This {{concept of}} a virtual network {{introduced}} a number of problems, as it related to security within virtual environment, due to only having <b>virtual</b> <b>switching</b> technology within the environment and not security technologies. Unlike physical networks that have switches with access control lists (ACLs), firewalls, antivirus gateways, or intrusion prevention devices, the virtual network was wide open. The <b>virtual</b> security <b>switch</b> concept is one where switching and security have joined forces, so that security controls could be placed within the <b>virtual</b> <b>switch</b> and provide per-port inspection and isolation within the virtual environment. This concept allowed security to get {{as close as possible}} to the end points that it intends to protect, without having to reside on the end points (host-based on virtual machines) themselves.|$|R
40|$|International audienceWith the {{development}} of NFV (Network Function Virtualization) paradigm, networking functions would gradually move from specialized and proprietary hardware to open-source software run over a virtual machine (VM) deployed on commodity hardware. Open vSwitch (OVS) is the most prominent open-source solution implementing a <b>virtual</b> <b>switch,</b> while DPDK (Data Plane Development Kit) {{is a set of}} specialized libraries to enhance the performance. In particular, DPDK allows packets to be processed by batches. In this paper, we address the issue of modeling the behavior of a DPDK-based <b>virtual</b> <b>switch.</b> First, we investigate the influence of batch services on the overall performance of a <b>virtual</b> <b>switch.</b> Second, we extend two former analytical models to include the processing of packets by batches. We propose a simple means to do it, and we evaluate the accuracy of our solution on two different scenarios. Numerical results show that, despite its simplicity, our approach provides fairly good results when compared to simulation...|$|R
30|$|Definition: {{horizontal}} IaaS federation The {{federated cloud}} service of virtual infrastructures {{of a set}} of virtual nodes (e.g. <b>virtual</b> <b>switches,</b> <b>virtual</b> routers), virtual links and virtual machines from a set of InPs (a virtual network infrastructure provider) and SePs (a IaaS cloud service provider) with transparent full server and network virtualization.|$|R
50|$|In January 2013, NEC {{unveiled}} a <b>virtual</b> <b>switch</b> for Microsoft's Windows Server 2012 Hyper-V hypervisor, {{which is designed}} to bring OpenFlow-based software-defined networking and network virtualisation to those Microsoft environments.|$|R
40|$|Abstract â€” High-performance <b>virtual</b> <b>switches</b> are {{critical}} for supporting Quality of Service (QoS) in real-time applications. This investigation of network virtualization techniques analyzed <b>virtual</b> <b>switch</b> traffic and network interface bridging characteristics. The characterizations investigation revealed the adjustment network interface capacity that is required to yield a specified QoS level. To examine the feasibility of the developed service model in this investigation, the NetFPGA platform was utilized to emulate it and to obtain comparative results for this potential useful virtual network. The proposed virtual network model has a 50 % higher system throughput in a NetFPGA-based emulator than does a traditional switching system...|$|R
50|$|Several {{competing}} network virtualization standards already existed by 2012. Neutron, the networking {{component of}} the open-source software OpenStack project, provides an application-level abstraction of network resources and includes an interface for configuring <b>virtual</b> <b>switches.</b>|$|R
50|$|Similar to VRF (virtual routing and {{forwarding}} instance) {{maintained in}} IP/MPLS routers to deliver layer 3 VPNs, IP VPNs, IP/MPLS <b>switches</b> maintain a <b>Virtual</b> <b>Switching</b> Instance (VSI) to deliver layer 2 VPNs, using VPLS.|$|R
50|$|The OpenVNet adds a Network Virtualization {{layer on}} top of the {{existing}} physical network and enables data center network administrators to tremendously simplify the creation and operation of multi-tenant networks. It is based on edge overlay network architecture and provides all the necessary components for network virtualization such as SDN controller, <b>virtual</b> <b>switch,</b> <b>virtual</b> router, and powerful APIs.|$|R
40|$|International audienceVirtual {{switches}} are a {{key elements}} within the new paradigms of Software Defined Networking (SDN) and Network Function Virtualization (NFV). Unlike proprietary networking appliances, <b>virtual</b> <b>switches</b> come {{with a high level}} of flexibility in the management of their physical resources such as the number of CPU cores, their allocation to the switching function, and the capacities of the RX queues, which gives the opportunity for an efficient sizing of the system resources. We propose a model for the performance evaluation of a <b>virtual</b> <b>switch.</b> Our model resorts to servers with vacation to capture the involved interactions between queues resulting from the implemented polling strategies. The solution to the model is found using a simple fixed-point iteration and it provides estimates for customary performance metrics such as the attained throughput, the packet latency, the buffer occupancy and the packet loss rate. In the tens of explored examples, the predictions of the model were found to be accurate, thereby allowing their use for the purpose of sizing problems. I. INTRODUCTION Computer networks are expected to undergo major changes with the development of Software Defined Networking (SDN) and Network Function Virtualization (NFV). SDN introduces a new architecture in which a single or a small set of centralized controller(s) replaces the control plane, formerly distributed on each router in traditional IP networks. As for NFV, it enables common network functions (e. g., packet forwarding, firewall, caching) to be done via software on industry-standard hardware (e. g., x 86 architecture). The expectations generated by combining SDN and NFV together are very high. Operators expect considerable gain in resource management flexibility (e. g., by dynamically reprogramming their network), while reducing their cost of operations by replacing dedicated and proprietary appliances by standard off the shelf hardware. Within SDN and NFV-based networks, nodes interconnecting the links are standard physical servers, with multiple CPU cores, running a <b>virtual</b> <b>switch</b> or <b>virtual</b> <b>switch</b> implementation. Analogously to routers in traditional IP networks, <b>virtual</b> <b>switches</b> are in charge of receiving, processing, switching, and transmitting packets flowing in the network. They handle incoming packets using a specialized library that largely defines their internal architecture. The DPDK library [1], which enables the processing of a packet in less than 80 CPU cycles, is becoming a prominent framework. Despite considerable progress, <b>virtual</b> <b>switches</b> are unlikely to be as fast their full hardware-based counterparts, and may be viewed as a critical spot when studying the performance of SDN/NFV networks...|$|R
50|$|The current {{direction}} in virtual firewall {{technology is a}} combination of security-capable <b>virtual</b> <b>switches,</b> and <b>virtual</b> security appliances. Some virtual firewalls integrate additional networking functions such as site-to-site and remote access VPN, QoS, URL filtering and more.|$|R
50|$|In February 2012, Big Switch Networks {{released}} Project Floodlight, an Apache-licensed open-source software OpenFlow Controller, {{and announced}} its OpenFlow-based SDN Suite in November of that year, which contains a commercial controller, and <b>virtual</b> <b>switching</b> and tap monitoring applications.|$|R
40|$|<b>Virtual</b> <b>switches</b> {{have become}} popular among cloud {{operating}} systems to interconnect virtual machines {{in a more}} flexible manner. However, this paper demonstrates that <b>virtual</b> <b>switches</b> introduce new attack surfaces in cloud setups, whose effects can be disastrous. Our analysis shows that these vulnerabilities are caused by: (1) inappropriate security assumptions (privileged <b>virtual</b> <b>switch</b> execution in kernel and user space), (2) the logical centralization of such networks (e. g., OpenStack or SDN), (3) the presence of bi-directional communication channels between data plane systems and the centralized controller, and (4) non-standard protocol parsers. Our work highlights the need to accommodate the data plane(s) in our threat models. In particular, it forces us to revisit today's assumption that the data plane can only be compromised by a sophisticated attacker: we show that compromising the data plane of modern computer networks can actually be performed by a very simple attacker with limited resources only and at low cost (i. e., {{at the cost of}} renting a virtual machine in the Cloud). As a case study, we fuzzed only 2 % of the code-base of a production quality <b>virtual</b> <b>switch's</b> packet processor (namely OvS), identifying serious vulnerabilities leading to unauthenticated remote code execution. In particular, we present the "rein worm" which allows us to fully compromise test-setups in less than 100 seconds. We also evaluate the performance overhead of existing mitigations such as ASLR, PIEs, and unconditional stack canaries on OvS. We find that while applying these countermeasures in kernel-space incurs a significant overhead, in user-space the performance overhead is negligible...|$|R
5000|$|... #Caption: This {{detail of}} a switch shows the pair of tapered {{moveable}} rails known as the <b>switch</b> <b>points</b> (<b>switch</b> rails or <b>point</b> blades) ...|$|R
5000|$|In telephony, {{a service}} <b>switching</b> <b>point</b> (SSP) is the {{telephone}} exchange that initially responds, when a telephone caller dials a number, {{by sending a}} query to a central database called a service control point (SCP) so that the call can be handled. The service <b>switching</b> <b>point</b> uses the Signalling System No. 7 (SS7) protocols which {{are responsible for the}} call setup, management, and termination with other service <b>switching</b> <b>points.</b>|$|R
40|$|Software Defined Networking {{has brought}} {{revolution}} {{to the world}} of Network technology which replaces most of the physical devices and control layer of the cloud computing reference model takes control of many Networking Devices. A <b>Virtual</b> <b>Switch</b> is a software by the virtue of which communication between several virtual machines take place. In contrast to physical switch is, it does not only forwards data packets but also checks the data for security before it is forwarded to other virtual machines. Interrelated components of software components work together to form a virtual network infrastructure. Out of the software components, the emphasis is targeted on <b>Virtual</b> <b>switch</b> functions and how it differs from the traditional switches...|$|R
40|$|There {{have been}} a lot of {{proposals}} to unify the control and management of packet and circuit networks but none have been deployed widely. In this paper, we propose a simple programmable architecture that abstracts a core transport node into a programmable <b>virtual</b> <b>switch,</b> that meshes well with the software-defined network paradigm while leveraging the OpenFlow protocol for control. A demonstration use-case of an OpenFlow-enabled optical <b>virtual</b> <b>switch</b> implementation managing a small optical transport network for big-data applications is described. With appropriate extensions to OpenFlow, we discuss how the programmability and flexibility SDN brings to packet-optical backbone networks will be substantial in solving some of the complex multivendor, multi-layer, multi-domain issues service providers face today...|$|R
