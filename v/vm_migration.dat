460|150|Public
2500|$|Hyper-V in Windows Server 2008 [...] {{does not}} support [...] "live migration" [...] of guest VMs (where [...] "live migration" [...] is defined as {{maintaining}} network connections and uninterrupted services during <b>VM</b> <b>migration</b> between physical hosts). [...] Instead, Hyper-V on Server 2008 Enterprise and Datacenter Editions supports [...] "quick migration", where a guest VM is suspended on one host and resumed on another host. [...] This operation happens {{in the time it}} takes to transfer the active memory of the guest VM over the network from the first host to the second host.|$|E
5000|$|Automatic {{migration}} {{and enforcement of}} network policies with <b>VM</b> <b>migration</b> ...|$|E
5000|$|A. Gupta, U. Mandal, P. Chowdhury, M. Tornatore, and B. Mukherjee, [...] "Cost-efficient live <b>VM</b> <b>migration</b> {{based on}} varying {{electricity}} cost in optical cloud networks," [...] Photonic Network Communications, vol. 30, no. 3, pp. 376-386, Dec. 2015.|$|E
30|$|In this paper, {{we address}} the {{limitation}} of MBFD; thereby proposing an enhancement to the OpenStack Neat consolidation to improve energy efficiency, lower <b>VM</b> <b>migrations</b> and SLA violation. To improve the energy efficiency, we propose a VM placement algorithms by modifying the bin-packing heuristics considering power efficiency of hosts. Moreover, we introduce a new bin-packing heuristic, medium-fit, to reduce SLA violations {{and the number of}} <b>VM</b> <b>migrations.</b> To evaluate the proposed algorithms, we have conducted an experiment using CloudSim simulator on three cloud data-center scenarios: homogeneous, heterogeneous and default. Twenty days of workloads that run on the three data-center scenarios have been generated from traces of PlanetLab and Bitbrains clouds [18, 19]. The proposed algorithms improve all three consolidation aspects: energy efficiency, SLA violation and amount of <b>VM</b> <b>migrations.</b> The results of the experiment show up-to 67 % improvement in energy consumption and up-to 78 % and 46 % reduction in SLA violation and amount of <b>VM</b> <b>migrations,</b> respectively.|$|R
30|$|In this research, we have {{addressed}} the problem of consolidation by improving the VM placement algorithm of OpenStack Neat framework. We have proposed VM placement algorithms by modifying bin-packing heuristics considering the power-efficiency of hosts. The proposed algorithms improve energy efficiency {{when compared with the}} baseline algorithms: MBFD and PABFD. The improvement in energy efficiency over MBFD can be up-to 67 %, depending on the data-center host types and workloads. Moreover, to avoid unnecessary SLA violation and <b>VM</b> <b>migrations,</b> we defined a new bin-packing rule called a medium-fit. Compared with other VM placement algorithms, the medium-fit power-efficient decreasing (MFPED), provides a lower SLA violation and number of <b>VM</b> <b>migrations.</b> MFPED improves SLA violation and number of <b>VM</b> <b>migrations</b> against MBFD by up-to 78 % and 46 %, respectively, depending on the cloud scenario.|$|R
30|$|In this paper, {{we address}} the {{limitation}} of the existing VM placement algorithms in OpenStack Neat framework with respect to energy-efficiency, <b>VM</b> <b>migrations</b> and SLA violation.|$|R
5000|$|Version 4.2, {{released}} March 2010, supports encryption {{during a}} <b>VM</b> <b>migration,</b> brings support for newer Itanium hardware and VM Guest OS versions, contains software allowing for VMs as Serviceguard packages and Serviceguard Nodes, {{and support for}} automatic memory reallocation.|$|E
5000|$|Live <b>VM</b> <b>migration</b> issues: Executing resource-intensive mobile {{application}} via Virtual Machine (VM) migration-based application ofﬂoading involves encapsulation of application in VM instance and migrating {{it to the}} cloud, which is a challenging task due to additional overhead of deploying and managing VM on mobile devices.|$|E
50|$|CAS for Windows is an {{application-aware}} file-based cache, {{which can}} be tuned by system administrators. Additionally, it integrates with the operating system's buffer cache, creating a multi-tier cache architecture. CAS is also aware of some virtualization technologies like vMotion, maintaining a hot SSD cache during a <b>VM</b> <b>migration.</b>|$|E
30|$|Thus, we {{conclude}} that, {{in case of}} the Default-scenario, the proposed algorithms improve all metrics (energy consumption, SLA violation and number of <b>VM</b> <b>migrations)</b> irrespective of the workload traces considered.|$|R
30|$|Energy {{efficiency}} {{usually has}} a trade-off with {{quality of service}} which is another concern of consolidation. From the cloud customer point of view, all that matter is the fulfillment of their applications resource demand. The resource demand is usually specified as Service Level Agreement (SLA). Thus, any good consolidation algorithm should provide a well-balanced energy efficiency and SLA assurance. In addition to these concerns, {{there is a third}} aspect of consolidation that deals with minimizing the amount of <b>VM</b> <b>migrations</b> [6]. Unnecessary <b>VM</b> <b>migrations</b> need to be avoided as it increases the network traffic and also incurs additional cost of energy [7, 8].|$|R
30|$|Markov {{overload}} detection: In this algorithm, a {{constraint on}} the overload time fraction value {{will be added}} as a parameter of the algorithm, while maximizing the time between <b>VM</b> <b>migrations,</b> thus {{improving the quality of}} VM consolidation but increase the computation [17].|$|R
5000|$|Version 4.1, {{released}} in April 2009, supports Online <b>VM</b> <b>Migration</b> which allows customers to migrate active guests from one VM Host to another VM Host without service interruption. It also provides support for SSH third-party alternatives for secure communications, accelerated virtual I/O (AVIO) for networking on Windows and Linux guests, support for ignite and VxVM backing stores.|$|E
50|$|Various application, middleware, OS, {{and other}} types of {{software}} load balancing approaches have been proposed to enable aggregate energy proportionality. For instance, if individual workloads are contained entirely within virtual machines (VMs), then the VMs can be migrated over the network to other nodes at runtime as consolidation and load balancing are performed. However, this can incur significant delay and energy costs, so the frequency of <b>VM</b> <b>migration</b> cannot be too high.|$|E
5000|$|Hyper-V in Windows Server 2008 {{does not}} support [...] "live migration" [...] of guest VMs (where [...] "live migration" [...] is defined as {{maintaining}} network connections and uninterrupted services during <b>VM</b> <b>migration</b> between physical hosts). Instead, Hyper-V on Server 2008 Enterprise and Datacenter Editions supports [...] "quick migration", where a guest VM is suspended on one host and resumed on another host. This operation happens {{in the time it}} takes to transfer the active memory of the guest VM over the network from the first host to the second host.|$|E
40|$|The {{dramatically}} increasing {{energy consumption}} of data centers {{is an important}} issue {{and one of the most}} efficient ways to tackle the issue is through server consolidation. The basic idea of server consolidation is to move all virtual machines (VMs) to as few energy efficient servers as possible, and then switch off unused servers. Many efficient server consolidation approaches have been proposed and one of the most efficient approaches is to use a Genetic Algorithm (GA) to find an optimal or near-optimal solution to the server consolidation problem. Aiming at reducing the computation time and the number of <b>VM</b> <b>migrations</b> incurred by server consolidation, this paper proposes a Decrease-and-Conquer Genetic Algorithm (DCGA). This DCGA adopts a decrease-and-conquer strategy to decrease the problem size and to decrease the number of <b>VM</b> <b>migrations</b> without significantly compromising the quality of solutions. The DCGA is compared with a classical GA and the most popular approach, namely FFD, for the server consolidation problem by experiments and the experimental results show that the DCGA can find a solution very close to the solution generated by the classical GA with much shorter computation time and incur much less <b>VM</b> <b>migrations</b> for all the test problems, and that the DCGA can generate a much better solution than the FFD...|$|R
5000|$|In late 2013 Cisco {{made their}} first {{announcement}} {{relating to the}} Intercloud. Their product Cisco Intercloud Fabric (ICF) [...] allows <b>VM</b> <b>migrations</b> {{between public and private}} clouds. Cisco went on in January 2014 detailing this hybrid cloud solution, and introduced the concept of the ‘World of Many Clouds'.|$|R
40|$|Abstract—In this work, {{we present}} a {{centralized}} monitoring entity that attempts to reduce power consumption in Internet Data Centers (IDCs) by employing live Virtual Machine (<b>VM)</b> <b>migrations</b> between blade servers. To perform live <b>VM</b> <b>migrations,</b> usage statistics collected by servers are evaluated and the servers that may be offloaded are selected. VMs that belong to the servers that may be offloaded are scattered to other active servers provided that the user-perceived performance is sustained. Overall, jobs submitted by users should be consolidated to as few servers as possible and the servers that host no job can be put in stand-by or hibernate mode, thus achieving an overall power reduction. Data Center management authorities may take advantage of such a monitoring entity in order to decrease energy consumption attributed to computing, storage and networking elements of data centers...|$|R
50|$|Post-copy <b>VM</b> <b>migration</b> is {{initiated}} by suspending the VM at the source. With the VM suspended, a minimal {{subset of the}} execution state of the VM (CPU state, registers and, optionally, non-pageable memory) is transferred to the target. The VM is then resumed at the target. Concurrently, the source actively pushes the remaining memory pages of the VM to the target - an activity known as pre-paging. At the target, if the VM tries to access a page {{that has not yet}} been transferred, it generates a page-fault. These faults, known as network faults, are trapped at the target and redirected to the source, which responds with the faulted page. Too many network faults can degrade performance of applications running inside the VM. Hence pre-paging can dynamically adapt the page transmission order to network faults by actively pushing pages {{in the vicinity of the}} last fault. An ideal pre-paging scheme would mask large majority of network faults, although its performance depends upon the memory access pattern of the VM's workload. Post-copy sends each page exactly once over the network. In contrast, pre-copy can transfer the same page multiple times if the page is dirtied repeatedly at the source during migration. On the other hand, pre-copy retains an up-to-date state of the VM at the source during migration, whereas with post-copy, the VM's state is distributed over both source and destination. If the destination fails during migration, pre-copy can recover the VM, whereas post-copy cannot.|$|E
30|$|Total <b>VM</b> <b>migration</b> time: The VM is {{migrated}} if the MD changes {{location and}} network coverage. The time duration the MD accesses the VM instance with high RTT latency and low throughput through WAN {{have to be}} as short as possible. This duration is tied to the <b>VM</b> <b>migration</b> process. The longer the <b>VM</b> <b>migration</b> time, the poorer the QoE. The total <b>VM</b> <b>migration</b> time has been collected. The <b>VM</b> <b>migration</b> is initiated using a Linux command, the time before and after the migration command completes is considered as the total <b>VM</b> <b>migration</b> time.|$|E
30|$|The {{algorithm}} considers {{three main}} parameters in making {{decision on the}} VM migration; the service initiation time, the <b>VM</b> <b>migration</b> time and the RTT during <b>VM</b> <b>migration.</b> If the RTT during migration is less than 150  msec, {{it means that the}} user is having a good QoE even through the WAN. Regardless of the total estimated <b>VM</b> <b>migration</b> time, the <b>VM</b> <b>migration</b> will be performed. There is no need to trigger <b>VM</b> <b>migration,</b> if the actual RTT during <b>VM</b> <b>migration</b> is greater than 1  s since the service becomes useless for the user.|$|E
30|$|Hybrid {{technique}}: This technique {{combines the}} pre-copy and post-copy algorithms. Besides transferring the VCPU registers and devices states in post-copy, a small subset of memory is also transferred which is frequently accessed by the VM. Advantages {{of both the}} pre-copy and post copy can be exploited in the hybrid algorithm which makes it more suitable for <b>VM</b> <b>migrations</b> [151].|$|R
40|$|Abstract—Consolidation through live <b>VM</b> <b>migrations</b> is a {{promising}} approach to improve server utilization. However, prior consolidation works have focused {{mostly on the}} perfor-mance impact of migration and neglected the associated energy overhead. Our research finds that energy impact of migration can offset over 12 % of the energy saved through energy-conscious workload packing. To address this limitation of {{the current state of}} research, in this paper we devise new schemes to pack applications that targets a joint optimization of energy and performance overhead of <b>VM</b> <b>migrations.</b> Additionally, we develop a statistical workload modeling technique for simulating consolidation problem in enterprise cloud contexts. Our experiments with statistically generated synthetic trace and Google’s production trace demonstrate that our schemes can improve energy savings up to 23 % compared to state of the art power-aware workload consolidation strategy. Keywords-VM migration energy; energy-efficient consolida-tion; cloud resource management. I...|$|R
40|$|Virtualization Technology (VT), re-invented {{to address}} {{most of the}} {{computer}} systems resource utilization challenges especially for Cloud Environment. An important feature of VT is live migration of the Virtual Machine (VM) that consists of Guest Operating Systems and applications running on it. Enabled by virtualization technologies, various multi-tier applications (such as web applications) are hosted by virtual machines (VMs) in cloud data centers. Live migration of multi-tier applications across geographically distributed data centers is important for load management, power saving, routine server maintenance and quality-of-service. Different from a single-VM <b>migration,</b> <b>VMs</b> in a multi-tier application are closely correlated, which results in a correlated <b>VM</b> <b>migrations</b> problem. Current live migration algorithms for single-VM cause significant application performance degradation because intermediate data exchange between different VMs suffers relatively low bandwidth and high latency across distributed data centers. In this paper, we design and implement a coordination system for correlated <b>VM</b> <b>migrations</b> in the cloud. Particularly, we propose an adaptive network bandwidth allocation algorithm to minimize the migration cost in terms of migration completion time, network traffic and migration downtime. Experiments using a public benchmark show that coordination system significantly reduces the performance degradation and migration cost of multi-tier applications...|$|R
30|$|In this section, {{we present}} a brief review on {{existing}} models of live <b>VM</b> <b>migration.</b> The term “model” {{is used for the}} theoretical representation of Phases involved in live <b>VM</b> <b>migration.</b> The models {{may or may not have}} been implemented. We further propose a generic model of live <b>VM</b> <b>migration,</b> which considers the required phases of live <b>VM</b> <b>migration,</b> based on existing models.|$|E
30|$|In the literature, few surveys {{highlight}} {{the importance of}} <b>VM</b> <b>migration</b> in a cloud environment. Soni and Kalra [38] reviewed different existing techniques which concentrate on minimization of total migration time and downtime to avoid service degradation. Kapil et al. [39] performed a summarized review of existing live migration techniques based on pre-copy and post-copy migration. They considered total migration time, service downtime, and amount of data transferred as a key performance metrics for comparison. They mention some research challenges like the type of network (LAN/WAN), link speed, page dirty rate, type of workload, address wrapping and available resources. Further different aspects of memory migration, process migration, and suspend/resume based <b>VM</b> <b>migration</b> techniques have been surveyed by Medina and Garcia [26]. In this, few <b>VM</b> <b>migration</b> techniques are included and no comparison is performed. The authors have not considered performance parameters of currently running applications under <b>VM</b> <b>migration,</b> network bandwidth optimization, and hybrid <b>VM</b> <b>migration</b> technique for improving migration process. Xu et al. [32] present a survey on performance overheads of <b>VM</b> <b>migration</b> within inter-CDC, intra-CDC, and servers. Their proposed classification does not consider different aspects of <b>VM</b> <b>migration,</b> timing metrics, migration pattern, and granularity of <b>VM</b> <b>migration</b> for highlighting the application performance and resource consumption trade-off. A comprehensive survey has performed by Ahmad et al. [40] covering different <b>VM</b> <b>migration</b> points like <b>VM</b> <b>migration</b> patterns, objective functions, application performance parameters, network links, bandwidth optimization, and migration granularity. They reviewed state-of-the-art live <b>VM</b> <b>migration</b> and non-live <b>VM</b> <b>migration</b> techniques. But the authors did not show any analysis based on performance parameters of <b>VM</b> <b>migration.</b> Moreover, they did not describe the weakness of reviewed techniques. In their extended survey work, Ahmad et al. [41] presented a review on state-of-the-art network bandwidth optimization approaches, server consolidation frameworks, Dynamic Voltage Frequency Scaling (DVFS)-enabled storage and power optimization methods over WAN connectivity. They proposed a thematic taxonomy to categorize the Live <b>VM</b> <b>migration</b> approaches. The critical aspects of <b>VM</b> <b>migration</b> is also explored by comprehensive analysis of existing approaches. A survey on mechanisms for live <b>VM</b> <b>migration</b> is presented by Yamada [42], covering existing software mechanisms that help and support in live migration. They reveal research issues that not covered by existing works like migration over high speed LAN, migration of nested VMM, and migration of VM attached to pass-through accelerator. The techniques are classified into two categories: performance and applicability. In a long-distance network, how the live migration and disaster recovery are performed with necessary operations is addressed by Kokkinos et al. [43]. They focus on new technologies and protocols used for live migration and disaster recovery in different evolving networks.|$|E
30|$|The {{paper is}} {{organized}} as follows: “Background” section presents {{the background of}} live <b>VM</b> <b>migration</b> and explain the various components, important features and limitations. In “Types of live virtual machine migration” section, types of live <b>VM</b> <b>migration</b> techniques - pre-cpoy, post-copy and hybrid techniques are presented. Brief overview of live <b>VM</b> <b>migration</b> models are presented and a generic model is proposed in “Live virtual machine migration models” section. A comprehensive and an exhaustive survey of the state-of-art live <b>VM</b> <b>migration</b> techniques is done in “Live virtual machine migration frameworks” section. Threats and security requirement in live <b>VM</b> <b>migration</b> is briefly discussed in “Threats in live virtual machine migration” section. Specific research gaps and open challenges in Live <b>VM</b> <b>migration</b> are described in “Research challenges” section. Finally, “Conclusion and future work” section, concludes the paper with future research directions.|$|E
40|$|In {{the present}} cloud {{computing}} environment, the scheduling approaches for VM (Virtual Machine) resources only {{focus on the}} current state of the entire system. Most often they fail to consider the system variation and historical behavioral data which causes system load imbalance. To present a better approach for solving the problem of VM resource scheduling in a cloud computing environment, this project demonstrates a genetic algorithm based VM resource scheduling strategy that focuses on system load balancing. The genetic algorithm approach computes the impact in advance, that it will have on the system after the new VM resource is deployed in the system, by utilizing historical data and current state of the system. It then picks up the solution, which will have the least effect on the system. By doing this it ensures the better load balancing and reduces the number of dynamic <b>VM</b> <b>migrations.</b> The approach presented in this project solves the problem of load imbalance and high migration costs. Usually load imbalance and high number of <b>VM</b> <b>migrations</b> occur if the scheduling is performed using the traditional algorithms...|$|R
30|$|To {{address the}} above {{consolidation}} issues, {{a number of}} research works are conducted [6, 9 – 14]. Not all researches deal with all aspects of consolidation. For example, the work in [12] particularly focuses on energy minimizing aspect of consolidation while the works in [9, 10] address minimizing SLA violation as well. Some of the works [6, 11, 13, 14] deal with all three aspects of consolidation including {{reducing the amount of}} <b>VM</b> <b>migrations.</b>|$|R
40|$|Virtualization {{is a very}} {{important}} technology in the IaaS of the cloud computing. User uses computing resource as a virtual machine (VM) provided from the system provider. The VM's performance is depended on physical machine. A VM should be deployed all required resources when it is created. If there is no more resource could be deployed, the VM should be move to another physical machine for getting higher performance by using <b>VM's</b> live <b>migration.</b> The overhead of a <b>VM's</b> live <b>migration</b> is 30 to 90 seconds. If there are many virtual machines which need live migration, the cost of overhead will be very much. This paper presents how to use cluster computing architecture to improve the VM's performance. It will enhance 15 % of per-formance compared with <b>VM's</b> live <b>migration.</b>  </p...|$|R
30|$|The {{throughput}} of TCP is {{inversely proportional}} to the <b>VM</b> <b>migration</b> time. As RTT increases between the cloudlets, the duration of <b>VM</b> <b>migration</b> would be unacceptable.|$|E
30|$|For {{the secure}} <b>VM</b> <b>migration,</b> much {{research}} has been accomplished {{with a focus on}} offline migration. However live <b>VM</b> <b>migration</b> still needs to be actively investigated.|$|E
30|$|Optimization {{will allow}} <b>VM</b> <b>{{migration}}</b> if power saving due to migration offsets {{the cost of}} migration. As a result, the optimization may result in partial <b>VM</b> <b>migration.</b>|$|E
3000|$|... 5 {{would be}} enough to serve request z=j+ 1 : however, this implies the {{capability}} of the federated cloud management system to know future requests in advance, which could be possible only if all the <b>VM</b> <b>migrations</b> are already planned and pre-scheduled. This would be a case of static load patterns, for which an optimization model such as the one in [12] would be a better choice, but it is out of the scope of this paper.|$|R
30|$|Actual average RTT: is {{the average}} RTT between VM 3 and VM 4 during <b>VM</b> 3 <b>migration</b> process from <b>VM</b> 1 to VM 2.|$|R
30|$|These {{reductions}} {{in the number of}} <b>VM</b> <b>migrations</b> and PM shutdowns result {{from the fact that the}} utility-based approach only migrates when it finds a VM-to-PM assignment for which an adaptation is expected to be beneficial. In contrast, the heuristics based approach migrates whenever there is a problem (i.e. host/PM overload or host under-load); however, a problem may be detected without there being a solution to which it is worthwhile to adapt, and hence the heuristic approach tends to over-adapt.|$|R
