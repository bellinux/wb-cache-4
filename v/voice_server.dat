12|34|Public
50|$|The {{prefecture}} of Ardèche {{has provided}} a <b>voice</b> <b>server</b> since June 2005 {{whose objective is to}} regularly disseminate information messages to allow monitoring of any significant event that might trigger a civil security crisis or standby alert. Precise information on the evolution of any flood is provided.|$|E
5000|$|After {{seven years}} of having a {{dedicated}} forum and gaming servers to use, for over two years, CyberSlam's Halo faithful resorted to a Facebook Group that {{was set up by}} a member known under the gaming alias Ducky. The 100-strong group used the page as an open-forum and attempted to organize Halo PC online scrimmages, though the lack of dedicated servers or a Ventrilo <b>voice</b> <b>server</b> made it hard to co-ordinate and ultimately the group lost interest. Fortunes changed in April 2013, when prominent CyberSlam community member hauningtoN, after obtaining CBN Media's blessing, assumed control of the CyberSlam nameplate and immediately started work on the 'Resurgence' project which he is funding completely off his own bat, though the website is accepting donations from a Donations Page ...|$|E
5000|$|In Austria, the {{speaking}} clock ("Zeitansage", which literally means [...] "time announcement") {{can be reached}} at 0810 00 1503 since 2009. A recorded female voice says (for instance): [...] "Es wird mit dem Summerton 15 Uhr, 53 Minuten und 10 Sekunden", meaning [...] "At the buzzing tone, the time will be 15 hours, 53 minutes and 10 seconds", followed by a short pause and a 1 kHz, 0.25 seconds long beep (even though the announcement [...] "buzzing tone" [...] suggests otherwise). The time is announced in 10 second intervals.Before 2009, {{the speaking}} clock was available by dialing 1503. Until there, the voice was generated by an Assmann ZAG500, which was also used in Australia. This {{has been replaced by a}} <b>voice</b> <b>server.</b>|$|E
50|$|EGN Australia was a {{computer}} games community operated and owned by volunteers, and {{sponsored by the}} ISP, EFTel. EGN ran a range {{of public and private}} games servers in both Perth, Western Australia, and Melbourne, Victoria. EGN also hosted a LAN gathering every 3 months in Perth. EGN hosted a collection of both public and leased, game and <b>voice</b> <b>servers.</b>|$|R
50|$|VPIM {{defines a}} subset of the Internet {{multimedia}} messaging protocols (MIME) for use between <b>voice</b> processing <b>server</b> platforms.|$|R
30|$|Scalable coders {{may also}} be used to {{optimize}} a multi-destination voice service in case of unequal or varying bandwidth allocations. Typically, <b>voice</b> <b>servers</b> have to produce the same data at different rates for users demanding the same voice signal [6]. This imposes an additional computational load on the server that may even result in congesting the network. A scalable coder can resolve this problem by adjusting the rate-quality balance and managing the number of optional bits allocated to each user.|$|R
40|$|SUMMARY We {{developed}} a Web-based education system called “Web-Com”. It supports synchronous and asynchronous learning. It {{consists of an}} interactive web browser and <b>voice</b> <b>server.</b> Web-Com provides a multi-layer drawable canvas on which the user can draw annotations. Each layer can be shared with other users in real-time via the Internet to enable synchronous learning. In conjunction with the <b>voice</b> <b>server,</b> Web-Com can support voice communication. It can also replay the process of annotation in order, which enables asynchronous learning. Finally, a subject experiment is conducted to evaluate the scheme’s workability and explore various issues that arise {{during the course of}} learning. The experimental results show that learners can learn fairly interactively with an instructor in a Web-Based class using Web-Com’s synchronous style. key words: web-based class, annotation, multiple layer, synchronous, asynchronou...|$|E
40|$|This {{project is}} {{embedded}} within an investigation Project named "Movilidad y Automoción para Redes de Transporte Avanzados" (MARTA). It has {{as a fundamental}} strategic goal to consolidate the scientifically and technological basis to 21 th century mobility to allow Spanish ITS ("Intelligent Transport Systems") sector to answer the challenges of efficiency, sustainability, etc. which European society and especially Spanish society has to confront in the next years. In this project Telefónica I+D (TID) {{is in charge of}} the study, specification and implementation of speech technology in automotive environment considering vehicle usability conditions. The work of the student in this project is to adapt a <b>voice</b> <b>server,</b> that contains speech tools, to automotive environment. Add new libraries that annex new functions and extend and develop the communication with XML to use these new functions...|$|E
40|$|Barriers such as unequal access, lack {{of digital}} skill, low income and {{disability}} constitute limiting factors for technology-mediated citizens and government interaction in developing countries. It is {{against this backdrop}} that this work explores the integration of Voice, Web and SMS technologies, in Nigeria’s democratic process. The proposed system {{takes advantage of the}} ubiquitous nature of mobile devices to explore the plausibility of increasing the level of citizens’ participation in democratic practices, particularly, those in rural areas with no Internet access and the physically challenged electorates. The server module for the e-democracy system was developed in PHP. Ozeki SMS server and Voxeo <b>Voice</b> <b>server</b> were used for SMS transaction code and VoiceXML code respectively. The prototype e-democracy system shows that developing nations can take advantage of their present level of technological development to give voice to the voiceless and improve their democratic system...|$|E
40|$|Following {{the demand}} {{of the speech}} {{technology}} market, {{a number of companies}} and research laboratories joined their forces in order to produce valuable and reusable resources, especially speech databases. Serving their purpose, the collected databases are used for developing, testing, enhancing and evaluating speech technology products, like interactive <b>voice</b> <b>servers,</b> listening typewriter, speaker verification and identification systems, etc. Especially for capturing intra-speaker variability, the PolyVar database was designed and recorded at IDIAP, as a complement to the Swiss French PolyPhone database, which adresses inter-speaker variability issues. We will detail in the following the specific problems of speech database collection (sampling the speaker population, selection of vocabulary items,...), and will present actual development we carried out at IDIAP throught the PolyPhone and PolyVar databases. 2 IDIAP [...] RR 96 - 01 Contents 1 Introduction 3 2 General overview 3 3 Da [...] ...|$|R
40|$|In {{the article}} is {{discussed}} {{the problem of the}} accessof broad masses of the population to information. The use of speech recognition in the interactive information systems is the most suitable way to make these systems more open and easily available for people. The purpose of our work was to create the functioning speech interfaces in Russian language to information and service systems and to analyze the results. Our efforts resulted in creation of the first <b>voice</b> <b>servers</b> for interactive information and services systems in Russia: computer reservation system Sirena, a system for dispatching of orders for taxi delivery, and a banking system. We developed several analytical models that allow dialogue optimization and control. One of our models, which enable the calculation of the mean number of retries and appropriate time losses in different conditions, is presented in this paper. 1...|$|R
5000|$|Yahoo! Voices, {{formerly}} Associated Content, was hacked in July 2012. The hack {{is supposed}} to have leaked approximately half a million email addresses and passwords associated with Yahoo! Contributor Network. The suspected hacker group, D33ds, used a method of SQL Injection to penetrate Yahoo! <b>Voice</b> <b>servers.</b> Security experts said that the passwords were not encrypted and the website did not use a HTTPS Protocol, {{which was one of the}} major reasons of the data breach. The email addresses and passwords are still available to download in a plaintext file on the hacker's website. The hacker group described the hack as a [...] "wake-up call" [...] for Yahoo! security experts. Joseph Bonneau, a security researcher and a former product analysis manager at Yahoo, said [...] "Yahoo can fairly be criticized in this case for not integrating the Associated Content accounts more quickly into the general Yahoo login system, for which I can tell you that password protection is much stronger." ...|$|R
40|$|ABSTRACT: An {{innovative}} {{application for}} communication platform based on SIP (VoIP) protocol {{is presented in}} this paper. The <b>Voice</b> <b>Server</b> is an Open-standards-based voice services framework that interprets the VoiceXML dialog markup language. It is designed {{to serve as a}} VoiceXML interpreter implementation for VoIP platform. Although it is perfectly suitable for PC desktop applications, it can be integrated with any telephony platform, messaging suite or communications solution intended to implement the VoiceXML functionality to execute feature rich voice enabled applications like: autoattendant, email-by-phone, voice dialing, message notification and reminders, contact book look-up, business transaction enablement, customer relationship management and utility applications (driving directions, flight tracking, audio newsmagazines, prescription refilling). It also allows input via speech recognition (SR) or "touch tone " DTMF and dialog prompting via synthesized speech (TTS) or recorded audio playback. And the experience with the platform shows that, it could be widely utilized in enterprises, groups and organizations with lowcost because of those improvements...|$|E
40|$|The main {{disadvantage}} of human {{presence in the}} Call centers of GSM service providers is poor response time. The preference of IVR services by Nigerian GSM subscribers can be attributed solely to this fact. A system has been developed on the VoiceXML platform {{to serve as a}} panacea for this problem. The developed system called ‘ASR 4 CRM’ obviates humanto- human interaction in the complaint lodging and solution provision process, by replacing it with humanto- system interactivity. ASR 4 CRM has a 3 -tier architecture. The telephone system constitutes the first tier; the VoiceXML gateway and the web server constitute the middleware, while the database constitutes the third tier. The system was tested with the top twentyfour FAQs from a leading Nigerian GSM carrier (MTN) and successfully deployed on Voxeo <b>voice</b> <b>server.</b> The system has succeeded in removing the human intermediaries in totality for system-activated responses with the attendant benefit of improved customer relationship management (CRM) ...|$|E
40|$|Part 7 : Privacy Attacks and Privacy-Enhancing TechnologiesInternational audienceMalicious {{intermediaries}} {{are able}} to detect the availability of VoIP conversation flows in a network and observe the IP addresses used by the conversation partners. However, it is insufficient to infer the calling records of a particular user in this way since the linkability between a user and a IP address is uncertain: users may regularly change or share IP addresses. Unfortunately, VoIP flows may contain humanspecific features. For example, users sometimes are required to provide Personal identification numbers (PINs) to a <b>voice</b> <b>server</b> for authentication and thus the key-click patterns of entering a PIN can be extracted from VoIP flows for user recognition. We invited 31 subjects to enter 4 -digital PINs on a virtual keypad of a popular VoIP user-agent with mouse clicking. Employing machine learning algorithms, we achieved average equal error rates of 10 - 29 % for user verification and a hitting rate up to 65 % with a false positive rate around 1 % for user classification...|$|E
5000|$|The Google Mobile App for iPhone {{currently}} incorporates Speex. [...] It {{has also}} been suggested that the new Google voice search iPhone app is using Speex to transmit <b>voice</b> to Google <b>servers</b> for interpretation.|$|R
50|$|In short, server {{provisioning}} configures servers {{based on}} resource requirements. The {{use of a}} hardware or software component (e.g. single/dual processor, RAM, HDD, RAID controller, a number of LAN cards, applications, OS, etc.) depends on the functionality of the server, such as ISP, virtualization, NOS, or <b>voice</b> processing. <b>Server</b> redundancy depends {{on the availability of}} servers in the organization. Critical applications have less downtime when using cluster servers, RAID, or a mirroring system.|$|R
40|$|E-learning through VSAT network {{consists}} of a HUB station, which is a satellite earth station and a Studio for video broadcasting of the lectures and many remote classrooms. The HUB will interconnect the VSATs at various geographical locations establishing the communication link in C or in Ku bands. The Studio room {{consists of}} Control Server, Agent Server, AV (Audio/Video) Streaming Server, Presentation Capture Server apart from other servers like Media Control Recording Server, Whiteboard Server, Text interaction <b>Server,</b> Live <b>Voice</b> Room <b>Server,</b> Private <b>Voice</b> Call <b>server</b> etc. The Control Server {{is at the heart}} of the E-learning through VSAT and it acts as a gateway to all remote classrooms. The remote virtual classroom is a receiving agent and must have registered students with computer systems along a dedicated Internet dial up line. The advantages are- video and audio output of the lecturer/teacher, return audio and video from the student for a unique teacher-student interaction, option for displaying animated content during the live lecture with unique interactive tools for making the lecture livelier, text chat option for students to ask questions and to get reply, audio chat for teacher-student interaction through audio mode, option for the student to join or leave a particular lecture session, whiteboard option for the teacher/lecture...|$|R
40|$|While most users {{currently}} access Web {{applications from}} Web browser interfaces, pervasive computing is emerging and offering {{new ways of}} accessing Internet applications from any device at any location, by utilizing various modes of interfaces to interact with their end users. The PC and its back-end servers remain important in a pervasive system, and the technology could involve new ways of interfacing with a PC and/or various types of gateways to back-end servers. In this research, cellular phone {{was used as the}} pervasive device for accessing an Internet application prototype, a multimodal Web system (MWS), through voice user interface technology. This paper describes how MWS was developed to provide a secure interactive voice channel using an Apache Web server, a <b>voice</b> <b>server,</b> and Java technology. Securing multimodal applications proves more challenging than securing traditional Internet applications. Various standards have been developed within a context of Java 2 Micro Edition (J 2 ME) platform to secure multimodal and wireless applications. In addition to covering these standards and their applicability to the MWS system implementation, this paper also shows that multimodal user-interface page can be generated by using XSLT stylesheet which transforms XML documents into various formats including XHTML, WML, and VoiceXML. (C) 2006 Elsevier B. V. All rights reserved...|$|E
40|$|This thesis has {{aimed to}} explore an {{application}} of Multibiometrics to secured wireless communications. The medium of study for this purpose included Wi-Fi, 3 G, and WiMAX, over which simulations and experimental {{studies were carried out}} to assess the performance. In specific, restriction of access to authorized users only is provided by a technique referred to hereafter as multibiometric cryptosystem. In brief, the system is built upon a complete challenge/response methodology in order to obtain a high level of security on the basis of user identification by fingerprint and further confirmation by verification of the user through text-dependent speaker recognition. First is the enrolment phase by which the database of watermarked fingerprints with memorable texts along with the voice features, based on the same texts, is created by sending them to the server through wireless channel. Later is the verification stage at which claimed users, ones who claim are genuine, are verified against the database, and it consists of five steps. Initially faced by the identification level, one is asked to first present one’s fingerprint and a memorable word, former is watermarked into latter, in order for system to authenticate the fingerprint and verify the validity of it by retrieving the challenge for accepted user. The following three steps then involve speaker recognition including the user responding to the challenge by text-dependent <b>voice,</b> <b>server</b> authenticating the response, and finally server accepting/rejecting the user. In order to implement fingerprint watermarking, i. e. incorporating the memorable word as a watermark message into the fingerprint image, an algorithm of five steps has been developed. The first three novel steps {{having to do with the}} fingerprint image enhancement (CLAHE with 'Clip Limit', standard deviation analysis and sliding neighborhood) have been followed with further two steps for embedding, and extracting the watermark into the enhanced fingerprint image utilising Discrete Wavelet Transform (DWT). In the speaker recognition stage, the limitations of this technique in wireless communication have been addressed by sending voice feature (cepstral coefficients) instead of raw sample. This scheme is to reap the advantages of reducing the transmission time and dependency of the data on communication channel, together with no loss of packet. Finally, the obtained results have verified the claims. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|This thesis was {{submitted}} for {{the degree of}} Doctor of Philosophy and awarded by Brunel University, 05 / 08 / 2010. This thesis has aimed to explore an application of Multibiometrics to secured wireless communications. The medium of study for this purpose included Wi-Fi, 3 G, and WiMAX, over which simulations and experimental {{studies were carried out}} to assess the performance. In specific, restriction of access to authorized users only is provided by a technique referred to hereafter as multibiometric cryptosystem. In brief, the system is built upon a complete challenge/response methodology in order to obtain a high level of security on the basis of user identification by fingerprint and further confirmation by verification of the user through text-dependent speaker recognition. First is the enrolment phase by which the database of watermarked fingerprints with memorable texts along with the voice features, based on the same texts, is created by sending them to the server through wireless channel. Later is the verification stage at which claimed users, ones who claim are genuine, are verified against the database, and it consists of five steps. Initially faced by the identification level, one is asked to first present one’s fingerprint and a memorable word, former is watermarked into latter, in order for system to authenticate the fingerprint and verify the validity of it by retrieving the challenge for accepted user. The following three steps then involve speaker recognition including the user responding to the challenge by text-dependent <b>voice,</b> <b>server</b> authenticating the response, and finally server accepting/rejecting the user. In order to implement fingerprint watermarking, i. e. incorporating the memorable word as a watermark message into the fingerprint image, an algorithm of five steps has been developed. The first three novel steps {{having to do with the}} fingerprint image enhancement (CLAHE with 'Clip Limit', standard deviation analysis and sliding neighborhood) have been followed with further two steps for embedding, and extracting the watermark into the enhanced fingerprint image utilising Discrete Wavelet Transform (DWT). In the speaker recognition stage, the limitations of this technique in wireless communication have been addressed by sending voice feature (cepstral coefficients) instead of raw sample. This scheme is to reap the advantages of reducing the transmission time and dependency of the data on communication channel, together with no loss of packet. Finally, the obtained results have verified the claims...|$|E
40|$|The {{internal}} {{structure of the}} applications has been evolving {{in tandem with the}} programming paradigms and ways of interacting with the machine. At the beginning the programs interfaced with the user in textual form, commonly based on menus, that was the time of structured programming and applications with ’serial’ architecture. Later came the graphical interfaces, accompanied by a boom in programming object-oriented architecture. From {{the point of view of}} end users, this was a step forward in terms of ease of use, particularly for inexperienced people in the management of computing applications. The next step could be to incorporate the Natural Language interaction, the Voice. Again, this change should introduce a different way of thinking about applications so that you can enhance the positive impact of this mode of interaction. Therefore, following with the company vision, the goal of this project will be investigating about possible voice services for Handsfree Bluetooth devices. Starting from simple interfaces to some existing services, the project will continue with new ones, designed by the student, in the field of social networking, blogging, email, news, etc. The design will imply some programming skills with HTML, XML, VXML, PHP, Perl, etc and knowledge about <b>voice</b> <b>servers</b> architectur...|$|R
50|$|A managed facilities-based voice network, or MFVN, is a {{physical}} network {{owned and operated by}} a voice service provider that delivers traditional telephone service via a loop start analog telephone interface. MFVNs are interconnected with the public switched telephone network (PSTN) and provide dialtone to end users. Historically, this was provided by equipment at Bell company central offices, however today's MFVNs can include a combination of access network (last mile network of copper, coaxial cable, or fiber optics), customer premises equipment (CPE), network switches and routers, network management systems, <b>voice</b> call <b>servers,</b> and gateways to the larger PSTN.|$|R
50|$|The HP OpenCall line of {{telecommunications}} platforms {{is offered by}} HP Communications & Media Solutions organization in four main areas—media server, service and charging control, signaling, and subscriber mobility. The HP OpenCall Media Platform is a <b>voice</b> and video <b>server</b> and media resource function platform used for developing and deploying messaging, portals and interactive services.|$|R
40|$|Over {{the last}} few years, the number of game players using voice {{communication}} {{to talk to each}} other while playing games has in-creased dramatically. In fact, many modern games and game con-soles have added voice support instead of expecting third-party companies to provide this technology. Unlike traditional voice-over-IP technology, where most conversations are between two peo-ple, voice communication in games often has 5 or more people talk-ing together as they play. We present the first measurement study on the characteristics of multiparty voice communications. Over a 3 month period, we mea-sured over 7, 000 sessions on an active multi-party <b>voice</b> communi-cation <b>server</b> to quantify the characteristics of communication gen-erated by game players, including overall server traffic, group sizes, sessions characteristics, and speaking (and silence) durations...|$|R
40|$|This {{document}} specifies an Internet standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "Internet Official Protocol Standards " (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2004). This document specifies a restricted profile of the Internet multimedia messaging protocols for use between <b>voice</b> processing <b>server</b> platforms. The profile {{is referred to as}} the Voice Profile for Internet Mail (VPIM) in this document. These platforms have historically been special-purpose computers and often do not have the same facilities normally associated with a traditional Internet Email-capable computer. As a result, VPIM also specifies additiona...|$|R
5000|$|A similar scheme {{involves}} forwarding {{an individual}} PBX extension to a long-distance or overseas number; the PBX owner must pay tolls {{for all of}} these calls. <b>Voice</b> over IP <b>servers</b> are often flooded with brute-force attempts to register bogus off-premises extensions (which may then be forwarded or used to make calls) or to directly call SIP addresses which request outside numbers on a gateway; as they are computers, they are targets for Internet system crackers.|$|R
50|$|The Real Time Streaming Protocol (RTSP) is {{a network}} control {{protocol}} {{designed for use}} in entertainment and communications systems to control streaming media servers. The protocol is used for establishing and controlling media sessions between end points. Clients of media servers issue VCR-style commands, such as play, record and pause, to facilitate real-time control of the media streaming from the server to a client (Video On Demand) or from a client to the <b>server</b> (<b>Voice</b> Recording).|$|R
40|$|Over {{the last}} few years, the number of game players using voice {{communication}} {{to talk to each}} other while playing games has increased dramatically. Unlike traditional voice-over-IP technology, where most conversations are between two people, voice communication in games often has 5 or more people talking together as they play. We present the first measurement study on the characteristics of multiparty voice communications and develop a model of the observed talking and silence periods that can be used for future research, simulation, network engineering, and game development. Over a 3 month period, we measured over 7, 000 sessions on an active multi-party <b>voice</b> communication <b>server</b> to quantify the characteristics of communication generated by game players, including group sizes, packet distributions, user and session frequencies, and speaking (and silence) durations. Unlike prior results, our measurements and models demonstrate that the speaking and silence periods fit a Weibull distribution. 1...|$|R
40|$|The paper {{deals with}} a design of an {{embedded}} <b>Voice</b> communication <b>server</b> which was developed {{within the scope of}} the BESIP project (Bright Embedded Solution for IP Telephony). The project brings a modular architecture with additional functionality such as a speech quality monitoring and a protection against security threats. The speech quality assessment is carried out in a simplified computational E-model and we implemented our proposal into the BESIP as an optional component. In the security module. We applied a standard approach to the intrusion detection and protection and in addition to the mentioned modules we come up with an idea of unified configuration based on the NETCONF protocol. We implemented ntegrated the complex support of NETCONF configuration protoco into OpenWRT and our modifications were accepted by OpenWRT community. The paper describes the inidvidual modules, their features and entire BESIP concept. Scopus 892 b 23322...|$|R
40|$|The Voice Mail Service (VMS) enables {{forwarding}} {{of calls}} to a dedicated <b>Voice</b> Mail <b>Server</b> (VMS) {{on behalf of}} the call receiving subscriber during certain conditions such as 'busy subscriber', 'no answer', 'always', etc. The standardization forum 3 GPP has specified the Global System for Mobile communication (GSM) while the standardization forum ITU-T has specified the Integrated Services Digital Networks  (ISDN) User Part (ISUP) call control protocol. Both of these standards rely on the use of Time Division Multiplex (TDM) as a media bearer and SS 7 as signalling bearer, where both bearers require use of very expensive telecom-specific hardware. The thesis proposes the solution to use RTP as media bearer and IP as signalling bearer towards the handset in GSM and only use TDM as media bearer and SS 7 as signalling bearer towards the VMS. The thesis demonstrates  the feasibility and the advantages provided, by creating an implementation in Erlang/OTP and testing it to check if it confirms to the specification...|$|R
40|$|The IP Multimedia Subsystem (IMS) {{framework}} as {{an architectural}} framework to deliver multimedia services is under rapid development, {{to become the}} nextgeneration telecommunication service framework. The objective of this work is to design an application server for the IMS framework to provide voice mail service to subscribed users. This master thesis contributes to this objective {{by the development of}} a prototype of a voicemail application server that integrates into the IMS architecture. Several communication protocols, among them SIP and MEGACO, were implemented for the integration of the application server with the IMS core network. All implementation was done using Erlang, a language widely used in telecom. After the prototype of the <b>voice</b> mail <b>server</b> was built, it was tested in an IMS simulation environment. The tests confirmed that the basic functionality of the voicemail was successfully implemented and that the integration with the IMS network was satisfactory. In future work the issue of QoS is one that needs to be addressed...|$|R
50|$|The Microsoft text-to-speech {{voices are}} speech synthesizers {{provided}} {{for use with}} applications that use the Microsoft Speech API (SAPI) or the Microsoft Speech Server Platform. There are client, server, and mobile versions of Microsoft text-to-speech voices. Client voices are shipped with Windows operating systems; <b>server</b> <b>voices</b> are available for download for use with server applications such as Speech Server, Lync etc. for both Windows client and server platforms, and mobile voices are often shipped with more recent versions of Windows Phone. Windows 10 also brings the mobile text to speech voices to the desktop starting with the Anniversary Update.|$|R
40|$|This article {{describes}} an age-annotated database of German telephone speech. All in all 47 hours of prompted and free text was recorded, uttered by 954 paid {{participants in a}} style typical for automated voice services. The participants were selected based on an equal distribution {{of males and females}} within four age cluster groups; children, youth, adults and seniors. Within the children, gender is not distinguished, because it doesn’t have a strong enough effect on the voice. The textual content was designed to be typical for automated voice services and consists mainly of short commands, single words and numbers. An additional database consists of 659 speakers (368 female and 291 male) that called an automated <b>voice</b> portal <b>server</b> and answered freely on one of the two questions “What is your favourite dish? ” and “What would you take to an island? ” (island set, 422 speakers). This data might be used for out-of domain testing. The data will be used to tune an age-detecting automated voice service and might be released to research institutes under controlled conditions as part of an open age and gender detection challenge...|$|R
40|$|Written {{language}} through now can be {{used for}} real time interchanges. Users want to convey their feelings and their personality on screen, without physical contact with the partner. To compensate the lack of paraverbal signals and personal features such as <b>voice</b> or handwriting, <b>servers</b> provide a wide panel of expressive resources: pseudonyms, avatars, font customisation, emoticons, spelling variation. The paper, based on French and English corpora of several kinds - chat, instant messenger dialogs and instant messenger profiles -, describes these resources and analyses some aspects of self-centred discourse. Anis Jacques. Approche sémiolinguistique des représentations de l'ego dans la Communication Médiée par Ordinateur. In: Langages, 35 ᵉ année, n° 144, 2001. Psycholinguistique et intelligence artificielle, sous la direction de Jean Vivier. pp. 20 - 38...|$|R
40|$|Nowadays {{portable}} {{devices such as}} smart phones {{can be used to}} capture the face of a user simultaneously with the <b>voice</b> input. <b>Server</b> based or even embedded dialogue system might utilize this additional information to detect whether the speaking user addresses the system or other parties or whether the listening user is focused on the display or not. Depending on these findings the dialogue system might change its strategy to interact with the user improving the overall communication between human and system. To develop and test methods for On/Off-Focus detection a multimodal corpus of user – machine interactions was recorded within the German SmartWeb project. The corpus comprises 99 recording sessions of a triad communication between the user, the system and a human companion. The user can address/watch/listen to the system but also talk to her companion, read from the display or simply talk to herself. Facial video is captured with a standard built-in video camera of a smart phone while voice input in being recorded by a high quality close microphone as well as over a realistic transmission line via Bluetooth and WCDMA. The resulting SmartWeb Video Corpus (SVC) can be obtained from the Bavarian Archive for Speech Signals (BAS). 1...|$|R
