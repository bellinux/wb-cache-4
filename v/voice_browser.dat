38|24|Public
5000|$|A <b>voice</b> <b>browser</b> {{presents}} information aurally, using pre-recorded {{audio file}} playback or text-to-speech synthesis software. A <b>voice</b> <b>browser</b> obtains information using speech recognition and keypad entry, such as DTMF detection.|$|E
50|$|The Call Control eXtensible Markup Language (CCXML) is a {{complementary}} W3C standard. A CCXML interpreter {{is used on}} some VoiceXML platforms to handle the initial call setup between the caller and the <b>voice</b> <b>browser,</b> and to provide telephony services like call transfer and disconnect to the <b>voice</b> <b>browser.</b> CCXML {{can also be used}} in non-VoiceXML contexts.|$|E
50|$|A <b>voice</b> <b>browser</b> is a {{software}} application that presents an interactive voice user interface {{to the user}} in a manner analogous to the functioning of a web browser interpreting Hypertext Markup Language (HTML). Dialog documents interpreted by <b>voice</b> <b>browser</b> are often encoded in standards-based markup languages, such as Voice Dialog Extensible Markup Language (VoiceXML), a standard by the World Wide Web Consortium.|$|E
40|$|AOPA is a universally {{accessible}} {{software platform}} that supports Chinese Web content development for displayless <b>voice</b> <b>browsers,</b> mobile mini-browsers and regular Web browsers in E-business services provision. Universal accessibility refers to accessibility through displayless <b>voice</b> <b>browsers</b> for telephones {{or for the}} elderly / visually impaired; mobile mini-browsers fo...|$|R
5000|$|ECMAScript - Scripting {{language}} {{supported by}} most <b>voice</b> <b>browsers</b> ...|$|R
50|$|A {{web browser}} {{is an example}} of a user agent (UA). Other types of user agent include the {{indexing}} software used by search providers (web crawlers), <b>voice</b> <b>browsers,</b> mobile apps, and other software that accesses, consumes, or displays web content.|$|R
50|$|Systems {{that present}} a <b>voice</b> <b>browser</b> to a user, {{typically}} provide interfaces {{to the public}} switched telephone network or to a private branch exchange.|$|E
5000|$|Call Control eXtensible Markup Language (CCXML) is an XML {{standard}} {{designed to}} provide asynchronous event-based telephony support to VoiceXML. Its current status is a W3C Proposed Recommendation, adopted May 10, 2011. Whereas VoiceXML is {{designed to provide}} a Voice User Interface to a <b>voice</b> <b>browser,</b> CCXML is designed to inform the <b>voice</b> <b>browser</b> how to handle the telephony control of the voice channel. The two XML applications are wholly separate and are not required by each other to be implemented - however, they have been designed with interoperability in mind ...|$|E
5000|$|VoiceXML has tags that {{instruct}} the <b>voice</b> <b>browser</b> to provide speech synthesis, automatic speech recognition, dialog management, and audio playback. The {{following is an}} example of a VoiceXML document: ...|$|E
50|$|Natural Language Semantics Markup Language is a markup {{language}} for providing systems (like <b>Voice</b> <b>Browsers)</b> with semantic interpretations {{for a variety}} of inputs, including speech and natural language text input. Natural Language Semantics Markup Language is currently a World Wide Web Consortium Working Draft.|$|R
40|$|There is a {{large amount}} of {{information}} on the World Wide Web that is at the fingertips of anyone with access to the internet. However, so far this information has primarily been used by people who connect to the web via traditional computer. This is about to change. Recent advances in wireless communication, speech recognition, and speech synthesis technologies have made it possible to access this information from any place, and at any time. In this paper, we discuss <b>voice</b> <b>browsers</b> as compared to current web browsers. Some of the primary techniques of universal accessible design are listed with their relation to <b>voice</b> <b>browsers</b> and some ideas are offered to help authors implementing these considerations when designing web pages. The new voice markup language is briefly discussed...|$|R
40|$|<b>Voice</b> {{controlled}} web <b>browsers</b> allow {{users to}} navigate by speaking {{the text of}} a link or an associated number instead of clicking with a mouse. One such browser is Conversa, by Conversational Computing. This within subjects study with 18 subjects compared voice browsing with traditional mouse-based browsing. It attempted to identify which of three common hypertext forms (linear slide show, grid/tiled map, and hierarchical menu) are well suited to voice navigation, and whether voice navigation is helped by numbering links. The study shows that voice control adds approximately 50 % to the performance time for certain types of tasks. Subjective satisfaction measures indicate that for voice browsing, textual links are preferable to numbered links. Keywords : Human-computer interaction, user interfaces, <b>voice</b> <b>browsers,</b> <b>voice</b> recognition, web browsing (Also cross-referenced as UMIACS-TR- 2000 - 69...|$|R
50|$|As speech {{recognition}} and web technologies have matured, voice applications are deployed commercially in many industries and voice browsers are supplanting traditional proprietary {{interactive voice response}} (IVR) systems. <b>Voice</b> <b>browser</b> software is delivered {{in a variety of}} implementations models.|$|E
5000|$|The Multimodal Architecture and Interfaces {{specification}} {{is based}} on the MVC design pattern, that proposes to organize the user interface structure in three parts: the Model, the View and the Controller. [...] This design pattern is also shown by the Data-Flow-Presentation architecture from the <b>Voice</b> <b>Browser</b> Working Group.|$|E
50|$|The Voxeo {{platform}} {{is based on}} open standards like VoiceXML, CCXML, and SIP and the company puts {{a strong emphasis on}} standards. Former Voxeo employee Dan Burnett chaired the W3C <b>Voice</b> <b>Browser</b> Working Group and was Co-Editor-In-Chief of VoiceXML 3. Former Voxeo CTO RJ Auburn, now with Sighthound, Inc., chaired the W3C CCXML working group.|$|E
40|$|Abstract—Nowadays, web-based {{technologies}} {{influence in}} people’s daily life {{such as in}} education, business and others. Therefore, many web developers are too eager to develop their web applications with fully animation graphics and forgetting its accessibility to its users. Their purpose is to make their web applications look impressive. Thus, this paper would highlight on the usability and accessibility of a <b>voice</b> recognition <b>browser</b> {{as a tool to}} facilitate the visually impaired and blind learners in accessing virtual learning environment. More specifically, the objectives of the study are (i) to explore the challenges faced by the visually impaired learners in accessing virtual learning environment (ii) to determine the suitable guidelines for developing a <b>voice</b> recognition <b>browser</b> that is accessible to the visually impaired. Furthermore, this study was prepared based on an observation conducted with the Malaysian visually impaired learners. Finally, the result of this study would underline on the development of an accessible <b>voice</b> recognition <b>browser</b> for the visually impaired...|$|R
5000|$|By {{building}} upon SRGS grammars, {{it allows}} <b>voice</b> <b>browsers</b> via ECMAScript to semantically interpret complex grammars {{and provide the}} information back to the application. For example, it allows utterances like [...] "I would like a Coca-cola and three large pizzas with pepperoni and mushrooms." [...] to be interpreted into an object that can be understood by an application. For example, the utterance could produce the following object named order: { drink: { liquid:"coke", drinksize:"medium" [...] }, pizza: { number: [...] "3", pizzasize: [...] "large", topping: [...] "pepperoni", [...] "mushrooms" [...] } }If used against this grammar that includes SISR markup {{in addition to the}} standard SRGS grammar in XML format: ...|$|R
50|$|Important {{approach}} of extensive research was Hidden Markov Model aimed to speech recognition tasks, by using small suchas big dictionaries {{and applied to}} many cases - e.g. {{the recognition of the}} children's <b>voice,</b> or <b>browser</b> navigation by <b>voice.</b> Other contributions include test and proposals in international communication standards, such as VoiceXML.|$|R
5000|$|It {{is common}} for [...] and [...] {{elements}} to carry [...] or [...] attributes in conjunction with CSS to apply layout, typographic, color, and other presentation attributes to parts of the content. CSS does not just apply to visual styling: when spoken out loud by a <b>voice</b> <b>browser,</b> CSS styling can affect speech-rate, stress, richness and even position within a stereophonic image.|$|E
50|$|Speech Synthesis Markup Language (SSML) is an XML-based markup {{language}} for speech synthesis applications. It is a {{recommendation of the}} W3C's <b>voice</b> <b>browser</b> working group. SSML is often embedded in VoiceXML scripts to drive interactive telephony systems. However, it also may be used alone, such as for creating audio books. For desktop applications, other {{markup language}}s are popular, including Apple's embedded speech commands, and Microsoft's SAPI Text to speech (TTS) markup, also an XML language.|$|E
5000|$|It was {{therefore}} {{felt that there}} was a need for enabling platforms for automatic voice telephone systems that are both scalable and easily programmable. To this end there was created a special working group to develop a <b>voice</b> <b>browser</b> prototype, to be shown to the public at SMAU 2000, with the name [...] "VoxNauta". It was such a success that Telecom Italia decided to close its original research labs and create Loquendo on 1 February 2001.|$|E
40|$|Traditionally, voice-based {{applications}} {{have been}} accessed using unintelligent telephone devices through <b>Voice</b> <b>Browsers</b> that reside on the server. With proliferation of pervasive devices {{and the increase}} in their processing capabilities, clientside speech processing is emerging as a viable alternative. As in SiMPE 2006 [2], we will further explore the various possibilities and issues that arise while enabling speech processing on resource-constrained, possibly mobile devices. In particular, this year’s theme will be SiMPE for developing regions. The workshop will highlight the many open areas that require research attention, identify key problems that need to be addressed, and also discuss a few approaches for solving some of them — not only to build the next generation of conversational systems, but also help create the next generation of IT users, thus extending the benefits of technology to a much wider populace...|$|R
40|$|We {{present a}} {{technique}} to automatically transform a voice application’s call flow, or interaction graph, into the set of application pages that encapsulate the call flow nodes and resources needed to run such application in a client-server environment. Our technique, called NOVA, performs this automatic partition by making use {{of a set of}} cost functions that model the latencies associated with the transmission of data and application resources through a network and their processing by the client components (e. g., <b>voice</b> <b>browsers,</b> grammar compilers and system engines). Our technique facilitates the existence of tools that permit application developers to focus on designing the call-flow of the application while leaving the task of segmenting and packaging the application into pages to our algorithm. The cost functions utilized by our algorithm can be dynamically computed allowing for runtime application optimization. We demonstrate the impact of our algorithm through simulation experiments. 1...|$|R
50|$|In {{addition}} to the MP3 player, SL45 offered other advanced features such as dictaphone with several hours of recording time, auto responder, voice dialing and <b>voice</b> commands,WAP <b>browser,</b> and context sensitive help in several languages.Other software include calendar/organizer, alarm clock, stopwatch, calculator, currency converter and games.While SL45 {{was one of the}} most advanced phones in its time, it was also one of the smallest.|$|R
50|$|VoiceXML can be {{combined}} with SMIL to provide a sequential reading of several pre-provided pages or slides in a <b>voice</b> <b>browser,</b> while combining SMIL with MusicXML would allow {{for the creation of}} infinitely-recombinable sequences of music sheets. Combining SMIL+VoiceXML or SMIL+MusicXML with RSS or Atom could be useful in the creation of an audible pseudo-podcast with embedded hyperlinks, while combining SMIL+SVG with VoiceXML and/or MusicXML would be useful in the creation of an automatically audio-enabled vector graphics animation with embedded hyperlinks.|$|E
50|$|VoiceXML (VXML) is {{a digital}} {{document}} standard for specifying interactive media and voice dialogs {{between humans and}} computers. It is used for developing audio and voice response applications, such as banking systems and automated customer service portals. VoiceXML applications are developed and deployed in a manner analogous to how a web browser interprets and visually renders the Hypertext Markup Language (HTML) it receives from a web server. VoiceXML documents are interpreted by a <b>voice</b> <b>browser</b> and in common deployment architectures, users interact with voice browsers via the {{public switched telephone network}} (PSTN).|$|E
40|$|In this paper, we {{introduce}} {{the construction of}} our VoiceXMLcompliant <b>voice</b> <b>browser</b> that is able to interpret and execute VoiceXML documents. The platform of our <b>voice</b> <b>browser</b> contains a VoiceXML interpreter, a speech recognition (SR) engine, a text-to-speech (TTS) engine, and a computertelephony-integrated (CTI) user interface. We adopt an open source called OpenVXI as the VoiceXML interpreter. Our main effort for developing the <b>voice</b> <b>browser</b> is to incorporate OpenVXI with our SR, TTS, and CTI modules. In order to test whether our <b>voice</b> <b>browser</b> conforms to the VoiceXML specifications we build three VoiceXML applications including stock quotes querying, automatic call-transfer, and news-reading systems. Besides, we develop a system that allows users to register their own VoiceXML documents in our voice gateway system via Web. They may then call to our voice gateway system and browse their VoiceXML documents by using our <b>voice</b> <b>browser.</b> 1...|$|E
40|$|Information on the World Wide Web is {{accessed}} {{not just}} visually, but also automatically by systems, such as search engines and alternative browsers (e. g. screen readers and <b>voice</b> <b>browsers),</b> which extract and present relevant data automatically from Web pages. In most cases extraction cannot be performed directly, since HTML documents of today lack adequate semantic markup. This thesis proposes {{a method that}} converts an HTML document to a semantically enhanced document representation, from which generic document components can be extracted for further knowledge exploration or alternative presentation. The document is parsed and iteratively smaller nodes are mapped to a classification ontology, which then are aggregated into larger segments, thereby creating a semantically enhanced parse tree. Segment boundaries are detected based on visual and document segments, such as images and headings. Experimental results of the implementation show that document components, such as headings and menus, can be extracted directly from the semantic parse tree. The heading extraction experiment achieved recall and precision rates of 88 % and 91 %. The recall and precision rates for the menu extraction experiment where 90 %...|$|R
50|$|Other {{software}} {{includes the}} GPS software {{that comes with}} this phone (LBS Route 66), Facebook, Twitter, social hub, mini diary, daily briefing, memo, video player, FM radio, media <b>browser,</b> <b>voice</b> recorder, e-mail and pre-installed Asphalt 5.|$|R
40|$|Since the {{integration}} of processed speech in parallel with manual pointing in the “Put That There ” system demonstrated by Richard Bolt in the 1980 ’s, web browsing has been gradually shifting from unimodal to multimodal interaction techniques which are supporting a combination of natural input modes such as speech, pen, touch, hand gestures, eyes gaze, and head movements. <b>Voice</b> controlled web <b>browsers</b> ar...|$|R
40|$|We {{report on}} the {{development}} of English-Chinese bilingual speech applications on a VXML platform. VXML support displayless voice browsing of Web content. We have developed the CU <b>Voice</b> <b>Browser</b> based on OpenVXI 2. 0. We have also integrated the <b>voice</b> <b>browser</b> with the OpenSpeech Recognizer (for English speech recognition), CU RSBB (for Chinese speech recognition), Speechify (for English speech synthesis) and CU VOCAL (for Chinese speech synthesis in order to support bilingual voice browsing. The CU <b>Voice</b> <b>Browser</b> includes an attribute for identifying the appropriate language for speech input/output, thereby invoking the appropriate speech engine for recognition / synthesis. We have developed two bilingual sample applications – CU Weather and CU News. This paper provides the associated VXML documents that specify these bilingual dialogs for browsing weather and news information respectively. 1...|$|E
40|$|Abstract: Interactive voice browsers {{offer an}} {{alternative}} paradigm that affords ubiquitous mobile access to the WWW using {{a wide range of}} consumer devices. This technology can facilitate a safe, ‘‘hands-free’ ’ browsing environment that is of importance both to car drivers and various mobile and technical professionals. This paper describes the challenges of architecting an interactive <b>voice</b> <b>browser</b> that combines digital audio with the features of a speech synthesizer to make structural elements of the document explicit to the listener. The aesthetics of the audio rendition can simultaneously help reduce the monotony factor and enhance comprehension. The evolution of the <b>voice</b> <b>browser</b> gave rise to a new conceptual model of the HTML document structure and its mapping to a 3 D audio space. A number of novel features are discussed for improving both the user’s comprehension of the HTML document structure and their orientation within it. These factors, in turn, can improve the effectiveness of the browsing experience...|$|E
40|$|Today {{web sites}} are {{designed}} in graphical mode for interaction with insufficient user assistance. Keen-sighted users {{can identify the}} content and quickly recognize relevant information in Web pages. On the contrary, individuals with visual disabilities have to use screen-readers to browse the Web. In this paper, we {{address the problem of}} information display in a non-visual Web interface. Access is made using the notion of context by assisting through the audio support and embodying our approach, by providing the standard features of a screen-reader along with browsing through <b>voice</b> <b>browser.</b> However, when a user follows a link, it captures the context of the link using a simple topic-boundary detection technique, and uses it to identify relevant information on the next page with the help of screen readers, and navigation is done through the <b>voice</b> <b>browser.</b> In order to aid the visually impaired users with a complete user friendly browsing approach we permit the content to be known by the screen-readers and voice browsers for the purpose of navigation...|$|E
40|$|Clarissa, an {{experimental}} <b>voice</b> enabled procedure <b>browser</b> that {{has recently been}} deployed on the International Space Station (ISS), is {{to the best of}} our knowledge the first spoken dialog system in space. This paper gives background on the system and the ISS procedures, then discusses the research developed to address three key problems: grammarbased speech recognition using the Regulus toolkit; SVM based methods for open microphone speech recognition; and robust side-effect free dialogue management for handling undos, corrections and confirmations. ...|$|R
50|$|Separation of {{formatting}} {{and content}} {{makes it possible}} to present the same markup page in different styles for different rendering methods, such as on-screen, in print, by <b>voice</b> (via speech-based <b>browser</b> or screen reader), and on Braille-based tactile devices. It can also display the web page differently depending on the screen size or viewing device. Readers can also specify a different style sheet, such as a CSS file stored on their own computer, to override the one the author specified.|$|R
40|$|Clarissa, an {{experimental}} <b>voice</b> enabled procedure <b>browser</b> that {{has recently been}} deployed on the International Space Station, {{is as far as}} we know the rst spoken dialog system in space. We describe the objectives of the Clarissa project and the system's architecture. In particular, we focus on four key problems: creating voice-navigable versions of formal procedure documents; grammar-based speech recognition using the Regulus toolkit; methods for accurate identication of cross-talk based on Support Vector Machines; and robust side-eect free dialogue management for handling undos, corrections and conrmations...|$|R
