28|6|Public
5000|$|Thór Stefánsson (reviewer, translator) : [...] "Toute littérature <b>valable</b> a une signification multiple", Bouria : Des mots dans la tourmente, Éditions du Cygne, Paris, 2014, pp. 13-18.|$|E
5000|$|... #Caption: M. le Colonel de Salis' CARTE DE SEMAINE, A PARIS <b>valable</b> jusqu'au AVRIL 23. No {{doubt he}} was there to visit his brother, William's stand for the Australian State of Victoria.|$|E
5000|$|... "Si je peux poser quelques pierre blanchespour baliser le sentier à inventer, je ne serais que très content, croyant que j'ai ainsi fait {{quelque chose}} de <b>valable</b> avec ma vie." [...] — Robert Dickson ...|$|E
40|$|In {{this short}} note, we mimic {{the proof of}} the {{simplicity}} of the theory ACFA of generic difference fields in order to provide a criterion, valid for certain theories of pure fields and fields equipped with operators, which shows that a complete theory is simple whenever its definable and algebraic closures are controlled by an underlying stable theory. Nous isolons des propriétés <b>valables</b> dans certaines théories de purs corps ou de corps munis d'opérateurs afin de montrer qu'une théorie est simple lorsque les clôtures définissables et algébriques sont contrôlées par une théorie stable associée...|$|R
5000|$|... "S’il me fallait résumer ce que l’essence de l’histoire économique peut apporter à la science économique, je dirais qu’il n’existe pas de « lois » ou règles en économie qui soient <b>valables</b> pour toutes les périodes de l’histoire ou pour chacun des systèmes économiques." [...] ("If I had to {{summarise}} {{the essence of}} what economic history can contribute to economic science, I would say that there exist no [...] "laws" [...] or rules in economics which are valid for all periods of history or for every economic system") - Paul Bairoch, Mythes et paradoxes de l'histoire économique (1993) ...|$|R
50|$|On the {{political}} front, the FLN worked to persuade—and to coerce—the Algerian masses {{to support the}} aims of the independence movement through contributions. FLN-influenced labor unions, professional associations, and students' and women's organizations were created to lead opinion in diverse segments of the population, but here too, violent coercion was widely used. Frantz Fanon, a psychiatrist from Martinique who became the FLN's leading political theorist, provided a sophisticated intellectual justification for the use of violence in achieving national liberation. From Cairo, Ahmed Ben Bella ordered the liquidation of potential interlocuteurs <b>valables,</b> those independent representatives of the Muslim community acceptable to the French through whom a compromise or reforms within the system might be achieved.|$|R
50|$|Eclipse {{supports}} a rich selection of extensions, adding support for Python via pydev, Android development via Google's ADT, JavaFX via e(fx)clipse, JavaScript, jQuery, {{and many others}} at the Eclipse Marketplace. <b>Valable</b> is a Vala plug-in for Eclipse.|$|E
40|$|We’d like {{to thank}} several people for their {{contributions}} to this book. First is Mike Horton, of Crossbow, Inc., who first proposed writing it. Second is Pablo Guerrero, who gave detailed comments and corrections. Third is Joe Polastre of Moteiv, who gave <b>valable</b> feedback on how to better introduce generic components. Fourth, we’d {{like to thank}} Phil’s father, who although he doesn’t program, read the entire thing! Fifth, John Regehr, Ben Greenstein and David Culler provided valuable feedback on this expanded edition. Last but not least, {{we would like to}} thank the TinyOS community and its developers. Many of the concepts in this book – power locks, tree routing, and interface type checking – are the work and ideas of others, which w...|$|E
40|$|One must {{sometimes}} {{follow the}} evolution of several individuals that cannot be distinguished. The author proposes a graphical estimator of individual evolution {{that can be used}} in such cases. She shows that this estimator is consistent and asymptotically normal. R ESUM E On doit parfois suivre l'evolution d'individus impossibles adi#erencier. L'auteure propose ici une estimation graphique d'evolution individuelle <b>valable</b> dans de telles situations. Elle montre que l'estimation obtenue est convergente et asymptotiquement normale. 1. INTRODUCTION Suppose that m individuals are held in captivity in order to study {{the evolution of}} a quantitative variable such as their length. The variable is expressed as a function of time, with f (1), [...] .,f (m) describing the evolution of the individuals. Assume also that marking the individuals is not feasible or possible, because the stress due to marking would a#ect our variable of interest. Without distinguishing individuals, we can measure them [...] ...|$|E
5000|$|Ultimately the Dodger {{is caught}} with a stolen silver snuff box and presumably {{sent to a}} penal colony in Australia (only alluded to in the novel). The absurdity of the master pickpocket being caught over {{something}} so small is remarked upon in the book.They've found the gentleman as owns the box; two or three more's a coming to 'dentify him; and the Artful's booked for a passage out,' replied Master Bates. 'I must have a full suit of mourning, Fagin, and a hatband, to wisit him in, afore he sets out upon his travels. To think of Jack Dawkins—lummy Jack—the Dodger—the Artful Dodger—going abroad for a common twopenny-halfpenny sneeze-box! I never thought he'd a done it under a gold watch, chain, and seals, at the lowest. Oh, why didn't he rob some rich old gentleman of all his <b>valables,</b> and go out as a gentleman, and not like a common prig, without no honour nor glory! ...|$|R
40|$|The {{main concern}} of this thesis {{deals with the}} study of {{solutions}} of several elliptic partial differential equations via the Morse index, including the stable solutions, i. e. when the Morse index is zero. The thesis has two independent parts. In the first part, under suplinear and subcritical assumptions on f, we establish firstly some explicit estimation for the L 1 norms of solutions to -Δu = f(u) avec u = 0 on the boundary, via its Morse index. We propose an approach more transparent and easier than the work of Yang [1998], which allow us to treat some nonlinearities {{very close to the}} critical growth. These results motivated us to consider the polyharmonic equations (-Δ) ku = f(x; u) with especially k = 2 and 3. With the hypothesis on f similar to Yang [1998] and appropriate boundary conditions, we obtain for the _rst time some explicit estimations of solution via its Morse index, for the polyharmonic equations. In the second part, we consider a Lane-Emden system -Δu = ρ(x) vp; -Δv = ρ(x) u_; u; v > 0; in RN; with 1 0; dans RN; avec 1 < p< θ et un poids radial ρ strictement positif. Nous montrons la non-existence de solution stable en petites dimensions N. Nos résultats améliorent les travaux précédents de Cowan & Fazly [2012]; Fazly [2012]; Hu [2015], et fournissent notamment des résultats du type Liouville pour solution stable, en petites dimensions N, <b>valables</b> pour tout 1 < ρ min(4 3; θ...|$|R
40|$| d’accentuer la présence de ces polluants organiques ou inorganiques dans le sol, dans la canne à sucre ou dans la nappe phréatique. Les études au {{laboratoire}} ont par contre démontré que la cendre de bagasse/charbon était capable de fortement immobiliser par adsorption, les herbicides atrazine et hexazinone avec des valeurs de Km (coefficients de sorption) de 0. 13 pour atrazine et 0. 32 pour hexazinone, rendant minime le risque de transfert de ces herbicides vers la nappe souterraine. Les analyses de sol ont confirmé que l’apport de la vinasse baissait le pH (de 5. 9 à 5. 4 en moyenne), mais cette baisse n’était que temporaire et pas assez significative pour affecter {{la croissance}} de la canne. Le pH du sol retournait à sa valeur initiale peu de temps après l’épandage de 100 m 3 /ha de la vinasse. La cendre de charbon avait eu un effet inverse en augmentant le pH du sol quoique cette hausse ne fût également pas significative pour la culture de la canne. Epandues à 100 m 3 /ha et à 100 T/ha la vinasse et la cendre de charbon, respectivement, avaient tendance à hausser la salinité du sol qui restait toutefois bien en dessous du seuil de 1700 RS/cm acceptable pour la culture de la canne à sucre. Si la vinasse à 100 m 3 /ha augmentait le carbone organique dans certains sols, tel ne fut cependant pas le cas pour la cendre de charbon à 100 T/ha. La vinasse comme la cendre de charbon avait un effet positif sur le niveau de calcium et de magnésium échangeables dans le sol. Ainsi à 100 T/ha la cendre de charbon augmentait dans le sol de Pamplemousses le Ca échangeable de 3. 40 à 6. 61 cmol+/kg après 12 mois, tandis que durant cette même période la vinasse à 100 m 3 /ha, et malgré sa forte teneur en potassium, portait le Ca échangeable de 1. 66 à 1. 83 cmol+/kg dans le sol de Union Park. Les essais aux champs établis dans quatre localités avec des doses croissantes de vinasse (25, 50 et 100 m 3 /ha) ont montré que le rendement de la canne à sucre que ce soit sous forme de canne ou de sucre n’était pas affecté de façon négative par ce déchet. Au contraire les résultats obtenus durant les trois années d’étude, qui ont permis de récolter une canne vierge et deux repousses, ont démontré que la vinasse avait donné un meilleur rendement en canne (moyenne de 84. 9 T/ha annuellement pour les quatre sites) que le traitement recevant NPK uniquement sous forme d’engrais minéraux (moyenne de 77. 3 T/ha annuellement pour les quatre sites). Puisque tous les traitements avaient reçu le même taux d’azote et de phosphate, ce rendement plus élevé de la vinasse était A part une meilleure nutrition potassique, probablement dû à une amélioration de la qualité du sol grâce aux matières organiques apportées par la vinasse. D’autre part, la cendre de charbon à 100 T/ha était définitivement néfaste à la canne à sucre comme indiqué par le rendement en canne plus faible (moyenne de 67. 5 T/ha annuellement pour les quatre sites). A 50 T/ha, l’effet de la cendre de charbon sur le rendement dépendait du type de sol, étant plus affecté dans les sols lessivés comme à Belle Rive que dans les sols moins lessivés de la zone sous humide comme à Pamplemousses. En raison de leur faible teneur en métaux lourds, la vinasse aussi bien que la cendre de charbon n’ont pas d’effet sur la concentration des métaux lourds présents dans la canne à sucre. Pour connaître l’effet de l’épandage de 100 m 3 /ha de vinasse et de 100 T/ha de cendre de bagasse sur la qualité des eaux souterraines, l’eau percolant après chaque grosse pluie à un mètre de profondeur sous des lysimètres établis sur deux sites avec une pluviométrie différente (1500 mm/an à Réduit et plus de 3500 mm/an à Belle Rive) avait été recueillie et analysée durant la période 2005 à 2008. Les résultats ont montré que la vinasse à 100 m 3 /ha n’accentuait pas les pertes d’azote sous forme de nitrate. Les métaux lourds les plus mobiles en l’occurrence le cuivre, le zinc et le nickel ont également été retrouvés dans les percolâts mais leurs teneurs restaient bien en dessous des seuils recommandés pour l’eau potable préconisé par l’Organisation Mondiale de la Santé, c'est-à-dire, 1 mg Cu/L, 5 mg Zn/L et 0. 02 mg Ni/L. Les résultats de quenching de fluorescence de la matière organique dissoute de la vinasse et de ses fractions (issues de la dialyse) avec le cuivre ont confirmé une bonne complexation entre cette matière organique dissoute et le cuivre. La cendre de bagasse n’avait pas engendré une présence plus prononcée des métaux lourds et des micropolluants organiques dans les eaux drainant à un mètre de profondeur des lysimètres. La seule différence remarquée entre la vinasse et la cendre de bagasse, était une capacité accrue de cette dernière à mobiliser le nitrate dans le sol. Ainsi suite à l’apport de 100 T/ha de cendre de bagasse, la concentration du nitrate dans les percolâts avait durant la période de novembre 2005 à février 2008 dépassé en de nombreuses occasions à Belle Rive et Réduit respectivement, le seuil de 10 mg N-NO 3 - /L recommandé pour l’eau potable par l’Organisation Mondiale de la Santé. En conclusion, cette étude a donné des résultats forts intéressants et <b>valables</b> qui indiquent que si l’épandage des fortes doses de vinasse peut être accepté, celle de la cendre de charbon est à éviter puisqu’elle n’est pas sans conséquence nuisible pour les sols ou les cultures et même les eaux souterraines. En effet, les fortes doses de cendre de charbon dans les champs de canne à l’île Maurice, conduiraient à une baisse de production et à une pollution plus accentuée de la nappe souterraine par le nitrat...|$|R
40|$|I owe a deep debt of {{gratitude}} to many people who helped contribute to the completion of this dissertation. First of all, I {{would like to thank}} my advisor, Glenn Pederson, for his flexibility, mentorship, and encouragement throughout my Ph. D. program. His practical advice for this project has been instrumental in my completion of this work. I am deeply grateful to my committee chair, Rob King, for his valuable comments and guidance at various stages of this research. This dissertation is incomparably better because of his substantial advice in simulation process and final stage of empirical results. My sincere appreciation goes to my other committee members, Qiuqiong Huang and Frederico Belo. Qiuqiong Huang provided me with <b>valable</b> guidance in econometric works. Frederico Belo served as a committee member during his busy schedule at the University of Pennsylvania. I am also indebted to Ward Nefstead and Clarissa Yeap, my former TA/RA supervisors, for their encouragement and financial support. I {{would also like to thank}} the Federal Reserve Bank of Minneapolis and th...|$|E
40|$|The paper {{focuses on}} the very {{important}} atopic of organizational transition and change resistance. It is divided in four parts. The first part deals with transition inevitability and its content in the change process. The {{second part of the}} paper refers to the change resistance. After a short presentation of a recent approach of this topic, elaborated by Rick Maurer, the authors present their point of view, identifying 14 main causes refering to the main factors involved in the organizational transition. In the third part, authors have formulated a set of key elements which should be taken into consideration in order to achieve a rapid and succesful organizational changes. These key elements are <b>valable</b> for any type of organization – entreprise, institution, locality, region, country a. s. a. The last part of the study deals with conflicts approach, which appear almost always during organizational transition. The conflicts are separated in three categories and for whom are presented the methodes recommended in order to solve them with good results...|$|E
40|$|Probabilistic {{assessment}} of urban runoff erosion potential J. A. Harris and B. J. Adams Abstract: At the planning or screening level of urban development, analytical modeling using derived probability distribution theory {{is a viable}} alternative to continuous simulation, offering considerably less computational effort. A new set of analytical probabilistic models is developed for predicting the erosion potential of urban stormwater runoff. The marginal probability distributions for the duration of a hydrograph in which the critical channel velocity is exceeded (termed exceedance duration) are computed using derived probability distribution theory. Exceedance duration and peak channel velocity are two random variables upon which erosion potential is functionally dependent. Reasonable agreement exists between the derived marginal probability distributions for exceedance duration and continuous EPA Stormwater Management Model (SWMM) simulations at more common return periods. It is these events of lower magnitude and higher frequency that are the most significant to erosion-potential prediction. Key words: erosion, stormwater management, derived probability distribution, exceedance duration. Résumé: Au niveau de la planification ou de la sélection en développement urbain, la modélisation analytique au moyen de la théorie de la distribution probabiliste dérivée est une alternative <b>valable</b> à la simulation continue car elle demande u...|$|E
40|$|L’article s’intéresse à l’interculturalité entre deux phénomènes culturels que sont le Gwo-ka et le Blues issus de la {{diaspora}} africaine aux Amériques. Le Gwo-ka est une expression culturelle née en Guadeloupe, île française située dans la mer des Caraïbes. Le Blues est également une expression culturelle née dans le Sud des États-Unis. À partir de l’analyse de leur « matrice » sociohistorique, il s’agira de mettre en évidence les rapprochements entre les différentes fonctions socioculturelles. Nous tenterons de comprendre si la théorie de l’Atlantique Noir de Paul Gilroy, reliant les communautés afro-diasporiques du Nouveau Monde, est <b>valable</b> {{dans le cadre de}} notre sujet d’étude. The article {{deals with}} the intercultural exchanges between two cultural movements rooted in the African Diasporas. In Guadeloupe, a French island in the Caribbean, Gwo-ka was born on the plantation in the 17 th century. Blues appeared in the southern United-States {{by the end of the}} 19 th century. In order to illustrate the similarities between these two afro-diasporic cultural phenomena, the article first examines the economic and social factors that prompted their emergence. Second, it compares their socio-cultural functions within their respective communities. Using Paul Gilroy’s theory of the Black Atlantic, the article concludes with a questioning of his thesis within the framework of the present study...|$|E
40|$|Abstract. Geochemical {{survey data}} have {{commonly}} been analysed combining methods from several disciplinesstatistics, geostatistics, geographic information technology, visualization. In {{initial stages of}} analysis, tables are often {{used to describe the}} data and present statistical measures. Far too often the original data are manipulated in one or another way, for example, using mathematical transformations, or interpolation of points to a surface. It is the author's opinion that raw geochemical data should be used in initial stages of data description, thus preserving the original details. This is not a simple task, as geochemical data are commonly complex, multivariate, and collected on irregular grid. Data contain outliers, element contents vary within thousands of ppm (parts per million), and different chemical elements may be correlated. In the present study a graphical approach has been used to study distribution of 5 heavy metals in glacial till. Using interactive visualization and multiple linked views of the data, the following issues were addressed: multi-element outliers, spatial trends, multi-element correlations and patterns. Interactive graphical techniques proved to be especially suitable for studying outliers and identifying and locating samples that are redundant and may be removed from data without loss of information. Visualization using linked views gave <b>valable</b> insights about metal correlations and spatial trends. As the development of appropriate tools for analysing multivariate spatial data are still in its early stages, visualization freeware seems to be a good alternative providing powerful, easy to use and intuitive techniques for exploratory data analysis. 1...|$|E
40|$|The {{first part}} of this Master's thesis is a story {{presented}} as an inner monologue where three periods of the narrator's life (the winter when she was nine years old, a recent trip to Ireland and her return to Montreal) interlace as three parallel miscarried lives. At times through entire episodes, at times through the echo of sentences once spoken or heard, Pamela's past lives contaminate the story of her forced return to Montreal to attend her father's funeral. They intermingle in a duplicate narrative, a fabled dialogue between times. In the second part, we intend to analyse the theme of the double in two of Romain Gary's novels: Au-dela de cette limite votre ticket n'est plus <b>valable</b> and Gros-Calin. The study demonstrates that the subject uses doubling to engender his self so that he can avoid the determinism that condemns him to a non-existence. Gary's hero refuses any god other than the one within himself: an infinite and immortal double from whom he has become seperated against his will at birth. He reinstates his unlimited potential as a creator by returning to a time before this world, a time not determined by external forces. He then undertakes to give life to his divine double by projecting him on others. The hero hopes that he will thus be endlessly reborn. The embodied ideal double, however, soon turns into the original which the hero imitates, becoming a double himself...|$|E
40|$|ABSTRACT. Tephrochronology, the {{reconstruction}} of past volcanic ash deposition, provides a valuable method for dating sediments and determining long-term volcanic history. Tephra layers are highly numerous in Alaska, but knowledge of their occurrence and distribution is incomplete. This study expands the regional tephrochronology for the Kenai Peninsula of south-central Alaska by investigating the tephrostratigraphy of two peatland sites. We located seven visible tephras and seven microtephras and investigated the particle size and geochemistry of the visible tephras. Radiocarbon dates were used to estimate the timescale of each core. Geochemical comparison showed that the visible tephras originated from late Holocene eruptions of Augustine, Crater Peak–Mt. Spurr, and Hayes volcanoes. Some of the tephras had been documented previously, and these new findings expand their known range. Others represent eruptions not previously reported, including a Crater Peak–Mt. Spurr eruption around 430 cal. BP. The results provide new tephra data for the region, illustrate the spatial heterogeneity of tephra deposition, and show the potential of microtephras for expanding the regional tephra record. Key words: tephra, cryptotephra, peatlands, Alaska, volcanoes, electron probe microanalysis RÉSUMÉ. La téphrochronologie, soit la reconstruction d’anciens dépôts de cendres volcaniques, constitue une méthode <b>valable</b> pour dater les sédiments et déterminer l’historique des volcans à long terme. En Alaska, les couches de téphra sont nombreuses, mais on ne sait pas tout sur leur occurrence et leur répartition. Cette étude a permis d’approfondir la téphrochronologie régionale de la péninsule de Kenai du centre-sud de l’Alaska grâce à la téphrostratigraphie de deux tourbières. Nous avons repéré sept téphra...|$|E
40|$|There {{is growing}} {{evidence}} concerning {{the value of}} studying the family in its natural habitat (Kantor and Lehr, 1975) for both understanding and explaining family interaction, as well as facilitating therapeutic intervention (White, 1976). This paper summarizes the existing literature {{on the importance of}} the family meal in analyzing family interaction, presents the results of a naturalistic observational study of a normal (non-pathological) family, and identifies the implications of the study for research and therapy. Résumé Il devient de plus en plus évident qu'il est très <b>valable</b> d'étudier la famille dans son milieu naturel (Kantor et Lehr, 1975) tant pour comprendre et expliquer l'interaction parmi les membres de la famille que pour faciliter une intervention thérapeutique (White, 1976). Cet article résume la littérature actuelle sur l'importance du repas pris en famille pour analyser la gamme des interactions. De plus, il présente les résultats de l'observation d'une famille normale (non-pathologique) et signale ce que cela peut apporter à la recherche et à la thérapie. The Issues Family research has a rich and varied history, both in volume and style. Most data about family relationships are obtained with questionnaires and interviews, typically from "captive " college students, or from wives, as if these family members could provide the most accurate descrip-tion of their families. Due to sharp criticism of this type of research, more recent studies have obtained survey data from several family members (Larson, 1974; Thomas, Peterson & Rollins, 1977). Social psychiatry, in contrast, has tended to emphasize observational and quasi-experimental studies of family interaction in hospital or laboratory settings (Winter & Ferreira, 1969...|$|E
40|$|Respiratory {{depression}} {{associated with}} patient-controlled analgesia: {{a review of}} eight cases Patient-controlled iv delivery of opioids for postoperative pain management is a popular alternative to the traditional im route of administration. However, occasional patients receiving opioids in this manner develop severe respiratory depression. The {{purpose of this paper}} is to determine the incidence of, and factors contributing to, the development of this compli-cation. To do this, the Office of Medical Quality Improvement retrospectively searched for reports of respiratory depression in a database compiled from the charts of approximately 1600 patients who had received PCA at the University of Alberta Hospitals in 1992. Eight cases of serious respiratory depression were detected. Factors associated with the occurrence of res-piratory depression included the concurrent use of a back-ground infusion, advanced age, concomitant administration of sedative I hypnotic medications, and pre-existing sleep apnoea syndrome. No cases were attributed to operator error or equip-ment malfunction. In conclusion, the risk of respiratory de-pression with patient-controlled opioid administration is similar to that observed when opioids are delivered by the traditional im or spinal routes. The safe and effective use of patient-controlled analgesia depends upon knowledgeable medical and nursing staff, clearly defined nursing policy and procedures, and frequent patient follow-up. L'administration controlee par le patient (PCA) de morphini-ques iv pour le traitement de la douleur postoperatoire est une alternative <b>valable</b> a la voie im traditionnelle. Cependant, a Voccasion, des malades sous morphiniques administres de cette facon souffrent de depression respiratoire grave. Cette etude vise a determiner son incidence et les facteurs qui contribuent a Key word...|$|E
40|$|CETTE ETUDE PORTE SUR LA MODELISATION ET LA SIMULATION NUMERIQUE DE L'EBULLITION PAR CONVECTION FORCEE DANS UN MILIEU POREUX AVEC GENERATION INTERNE DE CHALEUR. ON PRESENTE D'ABORD UNE REVUE DETAILLEE DE LA LITTERATURE TRAITANT DE LA CONVECTION FORCEE ET DE L'EBULLITION EN MILIEUX POREUX. LE PROBLEME EST ABORDE AVEC DEUX APPROCHES. LA PREMIERE EST BASEE SUR UN MODELE HOMOGENE DANS LEQUEL LE FLUIDE DIPHASIQUE EST CONSIDERE COMME UN MELANGE HOMOGENE OU LE GLISSEMENT ENTRE PHASES LIQUIDE ET VAPEUR EST NEGLIGE ALORS QUE LES EFFETS INERTIELS ET LA VARIATION DE POROSITE SONT INCLUS DANS LA FORMULATION MATHEMATIQUE. LA DEUXIEME APPROCHE EST BASEE SUR UN MODELE INHOMOGENE QUI ASSIMILE LE FLUIDE A UN MELANGE BINAIRE AVEC GLISSEMENT ENTRE PHASES ET CAPILLARITE. UN MODELE HEURISTIQUE A UNE EQUATION DE L'ENERGIE A EGALEMENT ETE DEVELOPPE. LE DESEQUILIBRE THERMIQUE LOCAL ENTRE LE FLUIDE EN ECOULEMENT ET LA MATRICE SOLIDE EST PRIS EN COMPTE DANS TOUS LES CAS. LES SIMULATIONS NUMERIQUES ONT ETE EFFECTUES EN UTILISANT UNE METHODE DE VOLUMES FINIS. ON ETUDIE L'INFLUENCE DES PARAMETRES CARACTERISTIQUES SUR L'ECOULEMENT ET LE TRANSFERT DE CHALEUR. LE DOMAINE DE VALIDITE DE L'HYPOTHESE DE L'EQUILIBRE THERMIQUE LOCAL EST DISCUTE. IL EST MONTRE QUE CETTE HYPOTHESE PEUT ETRE CONSIDEREE COMME <b>VALABLE</b> DANS LE CAS DE FAIBLES DIAMETRES DE PARTICULES ET/OU DE VITESSES ELEVEES. LA VARIATION DE POROSITE A POUR PRINCIPALE CONSEQUENCE L'APPARITION D'UNE ZONE FROIDE A FORT DEBIT AU VOISINAGE DE LA PAROI. AINSI, LORSQU'IL Y A EBULLITION AU CENTRE DE LA CONDUITE, UN FILM LIQUIDE DEMEURE LE LONG DE LA PAROI. LES EFFETS CAPILLAIRES AUGMENTENT AVEC LA DIMINUTION DU DIAMETRE DES PARTICULES ET AVEC L'AUGMENTATION DE LA PUISSANCE DE CHAUFFE. LA COMPARAISON ENTRE LES MODELES HOMOGENE ET INHOMEGENE MONTRE QUE LES RESULTATS SONT ASSEZ PROCHES LORSQUE LA PUISSANCE VOLUMIQUE EST MODEREEPARIS-EST Marne-la-Vallee-BU (774682101) / SudocSudocFranceF...|$|E
40|$|Jean-Claude Passeron {{articulated}} his defence of {{an historical}} {{approach to the}} analysis of social science concepts in Le raisonnement sociologique in direct opposition to the position announced by R. K. Merton: “C’est le role heuristique du passé théorique, présent directement ou allusivement dans les parties les plus vivantes du lexique sociologique, qui rend inopérante la distinction mertonienne entre ‘théorie sociologique <b>valable</b> actuellement’ et ‘histoire des théories’ » (Passeron, 2006, 107) Much {{has been written about the}} rediscovery of Hegelian philosophy in France in the 1930 s and 1940 s, focusing on the work of Kojève, Koyré, and, most importantly, Hyppolite. This has led to interest in Althusser’s argument against the academicisation of Hegelianism (in “Le retour à Hegel. Dernier mot du révisionnisme universitaire”, 1950, Althusser 1994, 251 - 268) and in his attempt to interpret the relationship between the thought of Marx and Hegel in such a way as to ground Marxism as science rather than philosophy and to deploy this science as the foundation for the political agenda of the Parti Communiste Français. His position as caïman at the Ecole Normale Supérieure from 1949 enabled him to keep these questions on the agenda for the new generation of entrants to the Ecole at the beginning of the 1950 s, including Foucault, Derrida, and Bourdieu. Relatively less has been written about the reception in the same period in France of the work of Edmund Husserl, and this has led to some misunderstanding of the subsequent development of relations between philosophy and sociology. The purpose of this article is to follow Passeron’s cue by seeking to situate historically, rather than abstractly, the development of Bourdieu’s thought and practice in relation to the legacy of Husserlian phenomenology. In doing so, it will suggest that Bourdieu’s outlook on politics, which Wacquant has characterised as ‘sociologically political’ (Wacquant, 2005, 1) and which advocated ‘socio-analytic encounter’ and engagement with new social movements, should be understood as one which is grounded in ‘inter-subjectivity’ as advanced in the phenomenological approach to philosophical practice rather more than in reflexively empirical ‘sociology’...|$|E
40|$|LA CAPACITE DE BIOACCUMULATION ET LES FORMES PHYSICO-CHIMIQUES DE STOCKAGE DES METAUX ONT UNE GRANDE IMPORTANCE ECOTOXICOLOGIQUE PUISQU'ELLES CONTROLENT TANT LA TOLERANCE D'UNE ESPECE DONNEE A LA CONTAMINATION DE SON MILIEU PAR LES METAUX QUE LE TRANSFERT DE CES DERNIERS VERS LES ECHELONS TROPHIQUES SUPERIEURS. L'ARGENT, LE CADMIUM, LE CUIVRE, LE MERCURE, LE NICKEL ET LE ZINC ONT ETE DOSES DANS DES COPEPODES HARPACTICOIDES TEMOINS ET EXPOSES A DIFFERENTES CONCENTRATIONS DE CES METAUX ET PENDANT DES TEMPS VARIABLES. LES COPEPODES, TIGRIOPUS BREVICORNIS, INFEODES AUX MARES INTERTIDALES DE LA ZONE SUPRALITTORALE, ONT ETE RECOLTES SUR LES COTES DE LOIRE ATLANTIQUE (LE CROISIC). LE COPEPODE TIGRIOPUS BREVICORNIS S'EST REVELE SENSIBLE AUX METAUX, PARTICULIEREMENT LES MALES DE L'ESPECE. CEPENDANT, A L'INSTAR DES CRUSTACES INFERIEURS, LES METAUX ONT ETE ACCUMULES PROPORTIONNELLEMENT AUX CONCENTRATIONS D'EXPOSITION; MODEREMENT ET SUR TOUTE LA DUREE DE L'EXPERIENCE, POUR LES METAUX ESSENTIELS (CU, NI, ZN) ET RELATIVEMENT FORTEMENT MAIS JUSQU'A UNE CERTAINE LIMITE, POUR LES METAUX NON-ESSENTIELS (AG, CD, HG). LES PROCESSUS DE DETOXICATION DES ELEMENTS METALLIQUES METTENT EN EVIDENCE DEUX VOIES PRINCIPALES DE DETOXICATION IMPLIQUANT DES PROTEINES TYPE METALLOTHIONEINES (PTMS), D'UNE PART, ET LE SYSTEME LYSOSOMAL, D'AUTRE PART. LES PTMS CONTRIBUENT A LA PRESENCE DE CADMIUM, DE CUIVRE, DE MERCURE ET DE ZINC DANS LA FRACTION CYTOSOLIQUE, PUISQUE CES QUATRE METAUX INDUISENT FORTEMENT LEUR SYNTHESE. EN REVANCHE, CE CAS DE FIGURE N'EST <b>VALABLE</b> NI POUR L'ARGENT NI POUR LE NICKEL, CES DEUX METAUX N'INDUISANT QUE FAIBLEMENT LA SYNTHESE DES PTMS. LES CELLULES DE L'EPITHELIUM DIGESTIF AINSI QUE LE TEGUMENT DU COPEPODE CONSTITUENT LES PRINCIPAUX TISSUS DE STOCKAGE DES METAUX. LE SYSTEME LYSOSOMAL EST PARTICULIEREMENT SOLLICITE DANS LE CAS DE CONTAMINATION A L'ARGENT, AU MERCURE ET AU CUIVRE. POUR LES AUTRES METAUX, A SAVOIR LE CADMIUM, LE NICKEL ET LE ZINC, C'EST PRESQUE EXCLUSIVEMENT LA VOIE SOLUBLE QUI CONSTITUE LE RESERVOIR PRINCIPAL DE STOCKAGE DE CES METAUX. EN TERMES DE TRANSFERT TROPHIQUE, CE SONT LE CADMIUM, LE NICKEL ET LE ZINC, MAJORITAIREMENT PRESENTS SOUS FORME SOLUBLE, QUI SERONT PLUS FACILEMENT ASSIMILES PAR LES PREDATEURS DES COPEPODES QUE LE CUIVRE, L'ARGENT OU LE MERCURE, PARTIELLEMENT STOCKES SOUS FORME DE CONCRETIONS INSOLUBLES. AIX-MARSEILLE 2 -Stat. Mar. Endoume (130552206) / SudocPARIS-BIUSJ-Thèses (751052125) / SudocCentre Technique Livre Ens. Sup. (774682301) / SudocPARIS-BIUSJ-Physique {{recherche}} (751052113) / SudocSudocFranceF...|$|E
40|$|Résumé en français] LE METTEUR EN SCENE CREE L'OBSCURITE A L'AIDE DE LA LUMIERE, LE SILENCE A L'AIDE DU SON. LE MEME PARADOXE EST EGALEMENT <b>VALABLE</b> POUR L'ACTION. CHAQUE SCENE EN TANT QU'UNITE MINIMALE DU CONFLIT POSSEDE UNE ACTION PROPOSEE. POURTANT, LE METTEUR EN SCENE NE SE SERT PAS DIRECTEMENT DE CETTE DERNIERE MAIS RECOURT A DES ACTIONS QUI NE PRESENTENT MEME PAS DE SIMILITUDE AVEC ELLE ET QUE L'ON APPELLE ACTIONS SCENIQUES. DE CETTE MANIERE, IL EVITE LES STEREOTYPES, TOUT COMME L'INTERPRETATION QUE LES ACTEURS FONT DES PERSONNAGES EN S'APPUYANT SUR LES EMOTIONS. CE NE SONT NI LE CONTENU DES MOTS, NI LE SENS D'UN GESTE QUI DONNENT SA SIGNIFICATION A UNE SCENE, MAIS BEL ET BIEN LES ACTIONS SCENIQUES. GRACE A L'ACTION SCENIQUE PARADOXALE, LE METTEUR EN SCENE N'INTERPRETE NI UN AUTEUR NI UN THEME, MAIS UNIQUEMENT L'ASPECT DRAMATIQUE REALISE A PARTIR DE L'ACTION DRAMATIQUE DE LA PIECE. L'ACTION SCENIQUE EST EGALEMENT PARADOXALE DE PAR LE FAIT QU'ELLE IMPREGNE L'EVENEMENT SCENIQUE DANS SON ENSEMBLE ET NON SEULEMENT LES PERSONNAGES JOUES PAR DES ACTEURS. LE METTEUR EN SCENE EST AINSI OBLIGE DE FAIRE APPEL A LA PAN-PERSONNIFICATION. IL CONCOIT POUR CHAQUE EVENEMENT SCENIQUE DES PERSONNAGES : SCENOGRAPHIQUES, COSTUMOGRAPHIQUES, SONORES, MUSICAUX, DES PERSONNAGES-ECLAIRAGES [...] EN CELA, LE PRINCIPE DE LA SUMATRAISATION LUI VIENT EN AIDE. IL S'AGIT D'UNE TECHNIQUE DE MISE EN RAPPORT DE TOUS LES PHENOMENES N'AYANT AUCUN LIEN APPARENT, A L'INTERIEUR DU CHAMP SCENIQUE, EN RECOURANT AUX ACTIONS SCENIQUES. C'EST AINSI QUE LE SUMATRAISME GARANTIT LES METAPHORES, CE EN QUOI L'EVENEMENT SCENIQUE TRANSCENDE, PAR SA SIGNIFICATION, LES FRONTIERES DU JEU LUI-MEME. AFIN D'APPRENDRE A TRADUIRE L'ASPECT DRAMATIQUE DE LA PIECE, PAR L'APPLICATION DES ACTIONS SCENIQUES PARADOXALES SUR L'ACTION PROPOSEE DE LA SCENE INCARNANT L'EVENEMENT SCENIQUE, IL EST NECESSAIRE DE MAITRISER AU PREALABLE TOUTE UNE SERIE D'ELEMENTS DE LA MISE EN SCENE EXPRIMES A TRAVERS SON LANGAGE. COMME TOUT AUTRE LANGAGE, SA NATURE EST COMPOSEE DE PROPRIETES GENERATIVES. C'EST POUR CETTE RAISON QUE L'ON N'APPREND PAS LA MISE EN SCENE EN PRENANT EXEMPLE SUR CE QUI EST CONNU ET EXISTE DEJA. ON APPREND A RECONNAITRE LES GENERATEURS DU LANGAGE A PARTIR DESQUELS SURGIT QUELQUE CHOSE DE JUSQU'ALORS INCONNU ET INEXISTANT. DANS LES PAGES QUI PRECEDENT, EN PROCEDANT A UNE REDEFINITION DE TOUS LES ELEMENTS DU LANGAGE DE LA MISE EN SCENE, NONANTERRE-BU PARIS 10 (920502102) / SudocSudocFranceF...|$|E
40|$|Standard Arabic is {{actually}} the language of writing. The speeches made {{in the media and}} in some TV series are, in most cases, a literal restatement of visual coding of the language (text written in standard Arabic) in auditory coding (reading aloud the written text). Similarly, everyday Arabic does not have the same coding as Arabic that exists in the media, in books and in Arabic language courses. This gives the impression that the current teaching content is not suitable for a usage outside the language classroom. This thesis deals with the problem of the composition of the lexical content of textbooks of teaching Arabic L 2 of Higher Language Institute of Damascus (Syria). A content that does not withdraw from standard norms (focus on the adaptation of a classic or moderne standard Arabic), but seeks to be {{as close as possible to}} the daily practice of language that is very rich in dialect. The current content represents the traditional approach of the lexicon, which focuses on the semantics of words and phrases while the communicative features of these language elements are little treated. The proposed analysisshows the weak points in the structure of textbooks now in use. It is based on the criteria of the Common European Framework of Reference for Languages (CEFR) and the skill references of Niveaux pour le français that offer an approach batter adapted to the preparation of the lexicon in recent textbooks of teaching moderne languages. This analysis focuses on finding the crossing points in standard and spoken Arabic in Syria to build a route map that allows the learner an easy passage from what he learns in the Arabic language classroom to Arabic that is really practiced in everyday communications. It provides some solutions to reduce the gap between these two usages of Arabic. L’enseignement du lexique arabe à l’Institut supérieur des langues de Damas n’est pas encore à la hauteur des attentes de l’apprenant pour lui fournir une bonne connaissance lexicale. Les outils pour développer ce travail n’ont pas évolué dans les méthodes utilisées. Dans ces méthodes, on applique toujours l’approche classique du lexique. Cette approche n’est plus <b>valable</b> au moment où le critère de fonctionnalité lié à la notion de fréquence a commencé à avoir sa place dans la nouvelle conception du lexique. Ce projet de thèse vise donc à contribuer à l’enseignement de l’arabe langue étrangère à l'Institut supérieur des langues en profitant des recherches faites pour l'enseignement d’autres langues vivantes, et spécialement celles qui s’inscrivent dans le Cadre européen commun de référence pour les langues (CECRL) ...|$|E
40|$|NOUS ETUDIONS LES FLUCTUATIONS MAGNETIQUES ET LES PROPRIETES A UNE PARTICULE (1 P) DU MODELE DE HUBBARD A 2 D, EN DECRIVANT LES FLUCTUATIONS DE SPIN PAR UN MODELE SIGMA NON LINEAIRE (MSNL) EFFECTIF. NOTRE THEORIE SUPPOSE L'EXISTENCE D'UN ORDRE ANTIFERROMAGNETIQUE (AF) A COURTE PORTEE. ELLE EST <b>VALABLE</b> POUR TOUTE VALEUR DE L'INTERACTION COULOMBIENNE U, EN DESSOUS D'UNE TEMPERATURE DE CROSS-OVER, OU S'ETABLIT L'ORDRE AF LOCAL. AU DEMI-REMPLISSAGE, NOUS TRAÇONS LE DIAGRAMME DE PHASES MAGNETIQUE NOUS MONTRONS QU'A TEMPERATURE NULLE (T= 0) L'ORDRE AF EXISTE QUELLE QUE SOIT LA VALEUR DE U. LE FONDAMENTAL EVOLUE CONTINUMENT ENTRE UN REGIME CARACTERISTIQUE DE L'AF DE SLATER A FAIBLE U ET UN COMPORTEMENT DE TYPE MOTT-HEISENBERG A GRAND U. A T> 0, L'ORDRE AF DISPARAIT, EN ACCORD AVEC LE THEOREME DE MERMIN-WAGNER. CEPENDANT, LA LONGUEUR DE CORRELATION AF RESTE TRES GRANDE PAR RAPPORT A LA MAILLE DU RESEAU, NOUS DEVELOPPONS UNE NOUVELLE METHODE DE CALCUL DES PROPROETES A 1 P, QUI TIENT COMPTE DE LA NATURE NON GAUSSIENNE DES FLUCTUATIONS DE SPIN. NOUS RENDONS COMPTE D'UNE TRANSITION ENTRE UN REGIME DE FAIBLE U OU UN PSEUDOGAP APPARAIT DANS LE SPECTRE DES FERMIONS ET UN REGIME DE GRAND U OU LES EXCITATIONS A 1 P SONT GAPPEES. NOUS ETUDIONS L'EVOLUTION DES QUASI PARTICULES (QP) DE BOGOLIUBOV A T=O EN PRECURSEURS INCOHERENTS A T> 0. DANS LE CAS DOPE, NOUS PRESENTONS UNE NOUVELLE TECHNIQUE DE DERIVATION DE L'ACTION EFFECTIVE DE BASSE ENERGIE, CELLE-CI FAIT INTERVENIR DES QP DE BOGOLIUBOV AU VOISINAGE DE LA SURFACE DE FERMI COUPLEES A UN MSNL DECRIVANT LES FLUCTUATIONS DE SPIN. L'ACTION DE BASSE ENERGIE EST COMPAREE AUX MODELES PHENOMENOLOGIQUES CONNUS DE FERMIONS COUPLES A UN MSNL. WE STUDY MAGNETIC AND ONE-PARTICLE PROPERTIES OF THE 2 D HUBBARD MODEL WITHIN THE FRAMEWORK OF A NON-LINEAR SIGMA MODEL (NLSM) DESCRIPTION OF SPIN FLUCTUATIONS THE THEORY RESTS UPON THE ASSUMPTION OF LOCAL ANTIFERROMAGNETIC (AF) ORDERING. IT IS VALID AT ALL COULOM INTERACTION STRENGTHS, BELOW A CROSS-OVER TEMPERATURE MARKING THE ONSET OF AF SHORT-RANGE ORDER. AT HALF-FILLING, WE DERIVE THE MAGNETIC PHASE DIAGRAM AND COMPUTE THE FERMION SPECTRAL FUNCTION. AT ZERO TEMPERATURE, LONG-RANGE AF ORDER IS SHOWN TO BE PRESENT FOR ALL VALUES OF THE COULOMB REPULSION. THE GROUND-STATE EXHIBITS A SMOOTH TRANSITION FROM A SLATER-LIKE BEHAVIOR AT WEAK COUPLING, TO A MOTT-HEISENBERG-LIKE BEHAVIOR AT STRONG COUPLING. AT FINITE TEMPERATURES THE AF ORDER IS SUPPRESSED, IN AGREEMENT WITH THE MERMIN-WAGNER THEOREM, BUT THE AF CORRELATION LENGTH REMAINS EXPONENTIALLY LARGE WITH RESPECT TO THE LATTICE SPACING, WE DEVELOP A NEW TECHNIQUE FOR CALCULATING THE SPECTRAL FUNCTION AND THE DENSITY OF STATES, WHICH TAKES INTO ACCOUNT THE HIGHLY NON-GAUSSIAN NATURE OF MAGNETIC FLUCTUATIONS. WE ESTABLISH THE EXISTENCE OF A TRANSITION BETWEEN A WEAK-COUPLING REGIME EXHIBITING A PSEUDOGAP AT FINITE TEMPERATURES, AND A STRONG-COUPLING REGIME WHERE ONE-PARTICLE EXCITATIONS ARE GAPPED. THE PROPERTIES OF BOGOLIUBOV QUASI PARTICLES AT ZERO TEMPERATURE AND OF THEIR PRECURSORS AT FINITE TEMPERATURES ARE ANALYZED. AWAY FROM HALF FILLING, A NEW METHOD FOR DERIVING THE LOW-ENERGY EFFECTIVE ACTION IS PROPOSED. THE EFFECTIVE MODEL INVOLVES LOW-ENERGY BOGOLIUBOV QUASI PARTICLES COUPLED TO A NLSM. THE LOW-ENERGY ACTION IS CRITICALLY COMPARED TO KNOWN PHENOMENOLOGICAL NLSM-FERMION THEORIES. ORSAY-PARIS 11 -BU Sciences (914712101) / SudocSudocFranceF...|$|E
40|$|Optical fiber, Raman fiber laser, fiber bragg mirror, optical power spectrum, waveturbulence theory, Non-Linear Schrödinger equation, {{non-linear}} optics. The work {{presented in}} this thesis deals {{with the formation of}} the optical power spectrum in Raman fiber lasers. We carried out an experimental study on a Raman fiber laser oscillating in a Pérot-Fabry cavity closed by fiber Bragg grating mirrors. We report that the shape of the optical spectrum is power dependent. Developing several models, we show that fiber Bragg gratings are responsible for this property of the optical power spectrum. In particular, at low power, the asymetric shape of the spectrum is due to dispersive effects occurring in fiber Bragg grating mirrors. At high laser power, those dispersive effects are dominated by the filtering action of fiber Bragg grating mirrors, which results in a symetrisation of the optical power spectrum observed in our experiment. In addition, we have also studied numerically the statistics of the intracavity Stokes field. We show that the field statistics strongly depends on whether Stokes light is incident or reflected by cavity mirrors. This result allows us to question the validity of a model recently developped in order to describe the formation of the optical power spectrum in Raman fiber lasers. This model relies on the recent tools of wave kinetic theory which is valid exclusively in the case of nearly gaussian fields statistics. However, our numerical study seems to indicate this condition is not fulfilled in Raman fiber lasers, and the shape of the optical spectrum observed in our experiment contrasts with the one predicted by this statistical approach of the formation of the optical power spectrum in Raman fiber lasers. Le travail présenté dans ce mémoire s'inscrit dans la problématique générale de la formation du spectre optique dans les lasers Raman à fibre. Nous avons mené une étude expérimentale sur un laser Raman à fibre oscillant dans une cavité Pérot-Fabry fermée par des miroirs de Bragg. Cette étude montre que la forme du spectre optique diffère selon la puissance du laser. En développant différents modèles, nous avons montré que les miroirs de Bragg sont à l'origine de ce changement de forme du spectre optique. En particulier, à faible puissance, la forme asymétrique du spectre provient d'effets dispersifs lors de la réflexion sur les miroirs de Bragg. A forte puissance, ces effets dispersifs sont dominés par les effets de filtrage des miroirs, ce qui conduit à la symétrisation du spectre du laser observée dans notre expérience. Par ailleurs, nous avons également étudié numériquement la statistique du champ Stokes intracavité. Nous avons montré que celle-ci change fortement selon que l'onde Stokes est incidente ou réfléchie par les miroirs de Bragg. Ce résultat nous a permis de questionner la validité d'un modèle récemment publié sur la formation du spectre optique du laser Raman à fibre. Ce modèle s'appuie sur les outils de la théorie cinétique des ondes, <b>valable</b> uniquement dans le cas de champs possédant une statistique gaussienne. Toutefois, notre étude numérique indique que cette condition n'est pas respectée dans le laser Raman à fibre, et la forme du spectre optique observé dans notre étude expérimentale s'oppose fortement à celle prédite par cette approche statistique de la formation du spectre optique du laser Raman à fibre...|$|E
40|$|But de l'étude] Il s'agit d'effectuer un projet pilote afin de développer la méthodologie pour une large étude et d'en {{examiner}} les possibilités de réalisation. Cette large étude devrait permettre de tester l'hypothèse qu'une thérapeutique non médicamenteuse de l'hypertension artérielle modérée est une alternative <b>valable</b> au traitement chimiothérapeutique en termes de résultats cliniques et de rapport coût/efficacité. [Auteurs, p. 4]]]> Hypertension/therapy; Life Style; Pilot Projects; Switzerland fre [URL] [URL] urn:nbn:ch:serval-BIB_ 6160 C 24 E 0 EE 67 info:eu-repo/semantics/openAccess Copying {{allowed only}} for non-profit organizations [URL] application/pdf oai:serval. unil. ch:BIB_ 6161 2017 - 11 - 29 T 16 : 04 : 55 Z [URL] Travail et accouchement des grossesses gémellaires. Wirthner, D Hohlfeld, P info:eu-repo/semantics/article article 1996 Revue Médicale de la Suisse romande 116255 - 260 oai:serval. unil. ch:BIB_ 61610502 E 097 2017 - 11 - 29 T 16 : 04 : 55 Z [URL] Generation of cytotoxic T lymphocytes in vitro. VI. Effect of cell density on response in mixed leukocyte cultures info:pmid: 127012 Fitch, F. W. Engers, H. D. MacDonald, H. R. Cerottini, J. C. Brunner, K. T. info:eu-repo/semantics/article article 1975 - 12 Journal of Immunology 11561688 - 94 <![CDATA[Reexposure of day 14 murine mixed leukocyte culture (MLC) populations {{to the original}} irradiated allogeneic stimulating spleen cells has previously been found to result in the ratpid generation of cytolytic T lymphocytes (CTL) associated with a net increase in cultured cell number. Under the experimental conditions used, day 5 MLC cells appeared unable {{to respond to the}} allogeneic stimulus. In order to characterize further the development of the potential for anamnestic reactivity during the course of MLC, C 57 BL/ 6 spleen cells were incubated with irradiated (1000 rads) DBA/ 2 spleen cells (primary MLC) for up to 3 weeks. At various time intervals after the onset of the primary MLC, the surviving cells were collected and reexposed, at varying cell concentrations, to irradiated DBA/ 2 spleen cells (secondary MLC). At daily intervals thereafter, CTL activity was assessed using a quantitative 51 Cr-release assay system. A paradoxic effect of responding cell concentration on generation of CTL activity was observed; relatively greater increase in CTL activity was observed as the concentration of responding cells was decreased over a 100 -fold range. This effect was more pronounced with responding cells reexposed to antigen after primary MLC for 20 days, but was observed even with normal cells. The apparent unresponsiveness of day 5 MLC cells to alloantigen restimulation could be overcome by simple dilution of responding cells. Cytotoxic activity at the time of restimulation with antigen seems to be a major factor determining the magnitude of the secondary response. Since intact cells bearing alloantigens are required for the generation of CTL in MLC, residual cytotoxic cells reduce the effective antigenic stimulus by destroying stimulating cells. This effect of concentration of responding cells on generation of CTL in MLC complicates interpretation of experiments investigating the role of "inhibitor" and "helper" cell in cell-mediated immune responses occurring in vitro. Under optimal conditions, the highest CTL activity and the largest increase in total cell number was observed 4 days after restimulation of day 10 MLC cells. On a per cell basis, the lytic activity was up to 4 times greater than that observed at the peak of a primary response, and the number of viable cells recovered was nearly 20 times higher than that at the onset. Such secondary MLC are thus a convenient source of lymphoid cells selected primarily on the basis of proliferation induced by alloantigens...|$|E
40|$|Le présent article rapporte les résultats d'une {{investigation}} des facteurs géométriques applicables à des réacteurs annulaires à mélange axial complet et appliqués à la désinfection des eaux au moyen de lumière UV de 254 nm. La loi de Bunsen-Roscoe est suivie en prenant en compte la dose corrigée par un facteur géométrique m; dose=mIot. Le bactériophage f 2 ne montre pas de phase de latence de mortalité et constitue dès lors un modèle <b>valable.</b> La dose létale à 99 % mesurée est de 470 ± 30 J/m 2. The f 2 -bacteriophage {{is chosen}} {{as a test}} organism to evaluate the geometrical factors which intervene in the disinfection of water by UV-light. This phage is an ARN and single strain cell which has the characteristic of being killed without a lethal lag phase being observed. It is also shown as a representative organism for the estimation of the virucidal action of UV-light. In this work a cold cathode mercury lamp emitting the 254 nm photon at low intensity, th. e. 14. 9 W/m 2 at the lamp surface, is used. The Lamp has the advantage that its photochemical yield {{does not depend on}} the temperature of the water investigated. The geometrical factor of different annular reactors is investigated by submersing the lamp in water contained in vessels of different diameters. The introduction of an artificial competitor, that is para-hydroxybenzoïc acid, which absorbs part of the 254 nm-photons also allows the impact of the reactor geometry to be evaluated. All the experiments are carried out in batch-type conditions and the water is completely mixed during the experiments. These conditions applied in laboratory investigations are representative of those existing in plug-flow reactors with complete axial mixing of discrete portions of the liquid contained in the annular space between the lamp and the reactor. In this work all data conform to the Bunsen-Roscoe Law relating the kinetics of first order decay to the irradiation dose : (I. t). No residual resisting organisms or "protected" organisms which could subsist at the end of exhaustive irradiation were observed. The practical dose, that is the dose at any point of the reactors taking into account the absorption of the light and the increasing surface irradiated at increasing reactor diameter and also the finite dimension of the lamp diameter is accounted for by a single correction factor m : Dose (D) = m. Io. t, in which, also according to the literature :        2 r o (1 - exp [- E (r- - ro) ]) m = ______________________________            E (r- 2 - r 2 o) where ro and r- are respectively the lamp radius and the reactor radius. E is the extinction coefficient (base e). The data as a whole converge to a 99 % lethal dose of 470 ± 30 J/m 2 in clear water, either absorbing or not at 254 nm. In the presence of turbidity, obtained by the introduction of 10 mgL- 1 koalin the efficiency is enhanced by 15 to 20 X, that is the apparent 99 % lethal dose is of 400 ± 30 J/m 2. By correcting the light intensity transmitted by reflection, this dose is about 420 J/m 2. Turbidity in UV-disinfection is thus not necessarily a negative factor in disinfection of liquids with UV-light. This investigation as a whole establishes an "economical space" between lamp surface and reactor wall of about 4 cm at which the energy consumption for a given level of disinfection attains a sufficiently tow value...|$|E
40|$|This {{analytical}} study {{deals with}} the spatio-temporal evolution of linear thermo-convective instabilities in a horizontal fluid layer heated from below (the Rayleigh [...] Benard system) and subject to a horizontal pressure gradient (Poiseuille flow). The novelty consists of a spatially inhomogeneous temperature, {{in the form of}} a two-dimensional bump imposed on the lower plate, while the upper plate is kept at a constant tremperature. The inhomogeneous boundary temperature and the mean flow of the Rayleigh [...] Benard [...] Poiseuille system break the symmetries of the classical Rayleigh [...] Benard system. The instabilities of interest are therefore spatially localised packets of convection rolls. If a mode of this type is synchronised, it is called a global mode. Assuming that the characteristic scale of the spatial variation of the lower plate temperature is large compared to the wavelength of the rolls, global modes are sought in the form of eigenmodes in the confined vertical direction, modulated by a two-dimensional WKBJ expansion in the slowly-varying horizontal directions. Such an expansion breaks down at points where the group velocity of the instability vanishes, i. e. at WKBJ turning points. In the neighbourhood of one such point, located at the top of the temperature bump, the boundedness of the solution imposes a selection criterion for the global modes which provides the growth rate (or equivalently the critical threshold), the frequency and the wave vector of the most amplified global mode. This study thus generalises to two-dimensional cases the methods used and the results obtained for one-dimensional inhomogeneities. The analysis is first applied to a simplified governing equation obtained by an envelope formalism and the analytical results are compared with numerical solutions of the amplitude equation. The formalism is finally applied to the Rayleigh [...] Benard [...] Poiseuille system described by the Navier [...] Stokes equations with the Boussinesq approximation. Cette etude concerne la determination analytique de l'evolution spatio-temporelle des modes lineaires d'instabilite thermo-convective dans une couche de fluide horizontale chauffee par le bas (systeme de Rayleigh [...] Benard) et soumise a un gradient de pression (ecoulement de Poiseuille). L'originalite reside dans l'inhomogeneite de la temperature de la plaque inferieure presentant une bosse bidimensionnelle. Cette inhomogeneite et le flux moyen de l'ecoulement de Rayleigh [...] Benard [...] Poiseuille ainsi obtenu rompent les symetries du probleme de convection pure et amene a considerer des modes spatialement localises d'instabilite en rouleaux. Un mode synchronise se developpant sur une telle configuration est appele mode global. L'echelle spatiale caracteristique des variations de la bosse de temperature etant supposee grande devant celle de la longueur d'onde des rouleaux, les modes globaux sont cherches sous la forme de modes propres dans la direction de confinement, modules par un developpement WKBJ bidimensionnel dans les directions horizontales lentement variables. Un tel developpement ne peut etre <b>valable</b> aux points ou la vitesse de groupe de l'instabilite s'annule, ou points tournants. Au voisinage d'un tel point situe au sommet de la bosse de temperature, le caractere borne de la solution, cherchee sous la forme d'un developpement intermediaire, impose un critere de selection donnant taux de croissance (ou de facon equivalente seuil critique), frequence et vecteur d'onde du mode global. Cette etude generalise a des cas bidimensionnels les methodes utilisees et les resultats obtenus pour des inhomogeneites unidimensionnelles. Une telle approche est d'abord appliquee a une equation dynamique simplifiee obtenue par le formalisme d'enveloppe. Les resultats analytiques sont compares a des simulations numeriques de cette equation. Puis ces modes globaux sont determines pour un ecoulement decrit par les equations de Navier [...] Stokes dans l'approximation de Boussinesq...|$|E
40|$|This PhD work {{is devoted}} to elaboraton of nitrogen-doped TiO 2 {{nanoparticles}} of controlled size for applications in nanocoatings and photocatalysis. The metastable colloids are prepared in a sol-gel reactor with rapid (turbulent) micro-mixing and in-situ particles granulometry, starting from titanium tétraisopropoxyde precursor. The effect of the fluids mixing on the particle size distribution was analysed using hydrodynamic k- modeling. The study of the nucleation-growth kinetics has evidenced that the hierarchical growth mechanism is also valid for the sub-nucleus units (clusters). Different domains of the cluster stability and growth kinetics have been discovered. The nitrogen-doped TiO 2 nanoparticles were prepared by hydroxyurea (HyU) injection into the reaction zone at the nucleation stage. The doping accelerates the reaction kinetics and induces strong yellow coloration of the nanocolloid, due to a new absorption band in the spectral range of 380 - 550 nm. This has been explained by {{the formation of a}} stable HyU-TiO 2 complex, which bounds two nanoparticles through the NCO group. FTIR, Raman, UV-visible absorption and XPS measurements confirm the complex formation. In particular, the XPS measurements suggest formation of the interstitial NO (400 eV peak). The doped nanocoatings were prepared on glass beads and thereafter were subjected to calcination in order to achieve most catalytically active anatase polymorph. The XPS, ATG-MS and EXAFS measurements indicate that the calcination temperature is critical for the dopant retention in the prepared material. The photocatalytic tests were performed on trichlorethylene degradation in gas phase under visible light illumination. The influence the hydrolysis ratio, HyU molar loading and calcination temperature on photocatalytic activity was studiedCe travail de thèse est consacré à la synthèse par méthode sol-gel de nanoparticules de TiO 2 (précurseur de tétraisopropoxyde de titane) dopées à l'azote de taille contrôlée pour des applications en nanodépôts et en photocatalyse. Les colloïdes métastables sont préparés dans un réacteur à micromélange rapide (turbulent). Des mesures de granulométrie in-situ permettent le suivi de la cinétique de formation des nanoparticules. L'effet du processus de mélange des réactifs sur la distribution de taille a été analysé en utilisant le modèle hydrodynamique k-. L'étude de la cinétique de nucléation-croissance a mis en évidence que le modèle de croissance hiérarchique est aussi <b>valable</b> pour les sub-nucleis (clusters). Différents domaines cinétiques de stabilité et de croissance ont été mis en évidence. Les nanoparticules de TiO 2 dopées à l'azote ont été préparées par injection d'hydroxyurée (HyU) dans la zone réactionnelle pendant l'étape de nucléation. Le dopage accélère la cinétique des réactions et induit une coloration jaune vif des nanocolloïdes, due à une nouvelle bande d'absorption dans le domaine spectral de 380 - 550 nm. Cela a été expliqué par la formation d'un complexe stable d' HyU- TiO 2, qui lie deux nanoparticules à travers le groupe NCO. Les mesures FTIR, Raman, absorption UV-visible et XPS confirment la formation du complexe. En particulier, les mesures XPS suggèrent la formation de NO interstitiel (pic à 400 eV). Les nanodépôts dopés ont été préparés sur des billes de verre, et traités thermiquement afin d'obtenir la phase anatase active photocatalytiquement. Les mesures XPS, ATG-MS et EXAFS montrent que la température de traitement thermique est cruciale pour la rétention de dopant dans les matériaux préparés. Les tests photocatalytiques ont été réalisés sur la dégradation du trichloréthylène en phase gaz sous rayonnement visible. L'influence du taux d'hydrolyse, de la quantité de dopant et de la température de traitement sur l'activité photocatalytique a été étudiée. This PhD work {{is devoted to}} elaboraton of nitrogen-doped TiO 2 nanoparticles of controlled size for applications in nanocoatings and photocatalysis. The metastable colloids are prepared in a sol-gel reactor with rapid (turbulent) micro-mixing and in-situ particles granulometry, starting from titanium tétraisopropoxyde precursor. The effect of the fluids mixing on the particle size distribution was analysed using hydrodynamic k- modeling. The study of the nucleation-growth kinetics has evidenced that the hierarchical growth mechanism is also valid for the sub-nucleus units (clusters). Different domains of the cluster stability and growth kinetics have been discovered. The nitrogen-doped TiO 2 nanoparticles were prepared by hydroxyurea (HyU) injection into the reaction zone at the nucleation stage. The doping accelerates the reaction kinetics and induces strong yellow coloration of the nanocolloid, due to a new absorption band in the spectral range of 380 - 550 nm. This has been explained by the formation of a stable HyU-TiO 2 complex, which bounds two nanoparticles through the NCO group. FTIR, Raman, UV-visible absorption and XPS measurements confirm the complex formation. In particular, the XPS measurements suggest formation of the interstitial NO (400 eV peak). The doped nanocoatings were prepared on glass beads and thereafter were subjected to calcination in order to achieve most catalytically active anatase polymorph. The XPS, ATG-MS and EXAFS measurements indicate that the calcination temperature is critical for the dopant retention in the prepared material. The photocatalytic tests were performed on trichlorethylene degradation in gas phase under visible light illumination. The influence the hydrolysis ratio, HyU molar loading and calcination temperature on photocatalytic activity was studie...|$|E
40|$|A {{major issue}} in {{fracture}} mechanics is to model the nucleation of a crack in a sound material. There are two difficulties: {{the first one is}} to propose a law able to predict that nucleation; the second is a purely numerical issue. It is indeed difficult to compute with a good accuracy all the mechanical quantities like the energy release rate associated with a crack of small length which appears at the tip of a notch. The classical finite element method leads to inaccurate results because of the overlap of two singularities which cannot be correctly captured by this method: one due to the tip of the notch, the other due to the tip of the crack. A specific method of approximation based on asymptotic expansions is preferable as it is developed in analog situations with localized defects. The first chapter of the thesis is devoted to the presentation of this Matched Asymptotic Method (shortly, the MAM) {{in the case of a}} defect (which includes the case of a crack) located at the tip of a notch in the simplified context of antiplane linear elasticity. The main goal of the thesis is to use these asymptotic methods to predict the nucleation or the propagation of defects (like cracks) near those singular points. The second chapter of the thesis will be devoted to this task. This requires, of course, to overcome the first issue by introducing a criterion for nucleation. This delicate issue has not received a definitive answer at the present time and it was considered for a long time as a problem which could not be solved in the framework of Griffith theory of fracture. The main invoked reason is that the release of energy due to a small crack tends to zero when the length of the crack tends to zero. Therefore, if one follows the Griffith criterion which stands that the crack can propagate only when the energy release rate reaches a critical value characteristic of the material, no nucleation is possible because the energy release rate vanishes when there is no preexisting crack. This "drawback" of Griffith's theory was one of the motivations which led Francfort and Marigo to replace the Griffith criterion by a principle of least energy. It turns out that this principle of global minimization of the energy is really able to predict the nucleation of cracks in a sound body. However, the nucleation is necessarily brutal in the sense that a crack of finite length suddenly appears at a critical loading. Moreover the system has to cross over an energy barrier which can be high when the minimum is "far". Another way to overcome the issue of the crack nucleation is to leave the pure Griffith setting by considering cohesive cracks. Indeed, since any cohesive force model contains a critical stress, it becomes possible to nucleate crack without invoking global energy minimization. Accordingly, we propose to revisit the problem of nucleation of a crack at the tip of a notch by comparing the three criteria. One of our goal is to use the MAM to obtain semi-analytical expressions for the critical loading at which a crack appears and the length of the nucleated crack. Specifically, the thesis is organized as follows. Chapter 1 is devoted to the description of the MAM on a generic anti-plane linear elastic problem where the body contains a defect near the tip of a notch. We first decompose the solution into two expansions: one, the outer expansion, valid far enough from the tip of the notch, the other, the inner expansion, valid in a neighborhood of the tip of the notch. These expansions contain a sequence of inner and outer terms which are solutions of inner and outer problems and which are interdependent by the matching conditions. Moreover each term contains a regular and a singular part. We explain how all the terms and the coefficients entering in their singular and regular parts are sequentially determined. The chapter finishes by an example where the exact solution is obtained in a closed form and hence where we can verify the relevance of the MAM. In Chapter 2, the MAM is applied to the case where the defect is a crack. Its main goal is to compute with a good accuracy the energy release rate associated with a crack of small length near the tip of the notch. Indeed, it is a real issue in the case of a genuine notch (by opposition to a crack) because the energy release rate starts from 0 when the length of the nucleated crack is 0, then is rapidly increasing with the length of the crack before reaching a maximum and finally is decreasing. Accordingly, after the setting of the problem, one first explains how one computes the energy release rate by the FEM and why the numerical results are less accurate when the crack length is small. Then, one uses the MAM to compute the energy release rate for small values of the crack length and one shows, as it was expected, that the smaller the size of the defect, the more accurate is the approximation by the MAM at a certain order. It even appears that one can obtain very accurate results by computing a small number of terms in the matched asymptotic expansions. We discuss also the influence of the angle of the notch on the accuracy of the results, this angle playing an important role in the process of nucleation (because, in particular, the length at which the maximum of the energy release rate is reached depends on the angle of the notch). It turns out that when the notch is sufficiently sharp, i. e. sufficiently close to a crack, it suffices to calculate the first two non trivial terms of the expansion of the energy release rate to capture with a very good accuracy the dependence of the energy release rate on the crack length. Then a cohesive model, the so-called Dugdale model, is considered in the last section of the chapter. Combining the MAM with the G method allows us to calculate in an almost closed form the nucleation and the evolution of the crack, namely the relations between the external load and the lengths of the non-cohesive zone and the cohesive zone. Specifically, it turns out that the inner problem can be seen as an Hilbert problem which can be solved with the help of complex potentials. Thus, the access to the solution is reduced to a few quadratures which are computed numerically. One obtains so an analytical expression of the critical load at which a "macroscopic" crack will appear in the body after an unstable stage of propagation of the nucleated crack. The order of magnitude of that critical load is directly associated with the power of the singularity of the solution before nucleation which is itself a known function of the angle of the notch. Chapter 3 proposes a generalization of all the previous results in the plane elasticity setting. Specifically, the goal is still to study the nucleation of non cohesive or cohesive cracks at the angle of a notch in the case of a linearly elastic isotropic material but now by considering plane displacements. Moreover, we will consider as well pure mode I situation as mixed modes cases. In the first part of the chapter we use the global minimization principle in the case of a non cohesive crack. In the second part we consider Dugdale cohesive force model. In both cases the MAM is used to compensate the non accuracy of the finite element method. All the derived results can be seen as simple generalizations of those developed in the antiplane case. Indeed, from a conceptual and qualitative viewpoint, we obtain essentially the same types of properties. However, from a technical point of view, the MAM is more difficult to apply in plane elasticity because the sequence of singularities can be obtained only by solving transcendental equations. Therefore, the numerical procedure becomes more expansive. Moreover, from the analytical point of view, the calculations become much more intricate and consequently a part of these calculations are given in the appendix. Un enjeu majeur de mécanique de la rupture est de modéliser l'initiation d'une fissure dans une structure saine. Il y a deux difficultés: la première est de proposer une loi capable de prédire la nucléation, la seconde est d'ordre purement numérique. En ce qui concerne ce deuxième point, il est en effet difficile de calculer avec une bonne précision toute quantité comme le taux de restitution d'énergie associée à une fissure de faible longueur qui apparaît en fond d'entaille. La méthode des éléments finis classique conduit à des résultats inexacts en raison de la superposition de deux singularités (l'une due à l'entaille, l'autre à la pointe de la fissure) qui ne peuvent être correctement capturées par cette méthode. Une méthode spécifique d'approximation basée sur des développements asymptotiques est préférable comment il a déjà été constaté dans des situations analogues présentant des défauts localisés. Le premier chapitre de la thèse est consacré à la présentation de cette méthode asymptotique dite Méthode des Développements Asymptotiques Raccordés (MAM) dans le cas d'un défaut (ce qui inclut le cas d'une fissure) situé à l'extrémité d'une entaille. Cette première étude est faite dans le cadre simplifié de l'élasticité linéaire antiplane avant d'être étendue à l'élasticité plane dans le troisième chapitre. Un objectif majeur est d'utiliser cette méthode asymptotique pour prédire la nucléation ou la propagation d'une fissure à proximité d'un point singulier. Le deuxième chapitre de la thèse sera consacré à cette tâche. Cela nécessite, bien sûr, de lever la première difficulté en proposant un critère de nucléation physiquement raisonnable. Cette délicate question n'a pas reçu de réponse définitive à l'heure actuelle et a été considérée pendant longtemps comme un problème qui ne pouvait être résolu dans le cadre de la théorie de Griffith. La principale raison invoquée est que le taux de restitution de l'énergie dû à une petite fissure tend vers zéro lorsque la longueur de la fissure tend vers zéro. Par conséquent, si l'on suit le critère de Griffith qui stipule que la fissure peut se propager que lorsque le taux de libération d'énergie atteint une valeur caractéristique du matériau, il n'y a pas de nucléation possible. Ce "défaut" de la théorie de Griffith fut l'une des motivations qui conduit Francfort et Marigo à remplacer le critère de Griffith par un principe de minimisation de l'énergie. Il s'avère que ce principe de minimum global de l'énergie est vraiment en mesure de prédire la nucléation des fissures dans un corps sain. Cependant, la nucléation est nécessairement brutale dans le sens où une fissure de longueur finie apparaît brutalement à une charge critique et de plus il faut que le système franchisse une barrière d'énergie qui peut être d'autant plus haute que le minimum est "loin". Une autre façon de rendre compte de la nucléation de fissures est de quitter le cadre de la théorie de Griffith en introduisant le concept de forces cohésives. L'intérêt d'une telle approche est qu'elle contient automatiquement la notion de contrainte critique qui permet de régir naturellement la nucléation sans passer par le principe de minimisation globale de l'énergie. En résumé, nous proposons de traiter le problème de la nucléation d'une fissure à la pointe d'une entaille de trois façons et de comparer les trois critères correspondants. L'un de nos objectifs est aussi d'utiliser la MAM pour obtenir des expressions semi-analytiques pour la charge critique à partir de laquelle une fissure apparaît ainsi que la longueur de la fissure une fois nucléée. De façon précise, la thèse est organisée comme suit. Le chapitre 1 est consacré à la description de la MAM sur un problème générique d'élasticité linéaire antiplane où la structure contient un défaut situé au voisinage de la pointe d'une entaille. Nous avons d'abord décomposé la solution en deux développements: l'un, le développement extérieur, <b>valable</b> assez loin de la pointe de l'entaille, l'autre, le développement intérieur, <b>valable</b> au voisinage de la pointe de l'entaille. Ces développements contiennent une séquence de termes "intérieurs" et "exterieurs" qui sont solutions de problèmes "intérieurs" et "extérieurs" reliés les uns aux autres par des conditions de raccord. En outre, chaque terme contient une partie régulière et une partie singulière. Nous expliquons ensuite comment tous les termes et les 4 coefficients qui entrent dans les parties singulières et régulières sont déterminés séquentiellement. Le chapitre se termine par un exemple où la solution exacte est connue et peut donc être développée directement avant d'être comparée à celle fournie par la MAM. Dans le chapitre 2, laMAMest appliquée au cas où le défaut est une fissure. Le premier objectif est de calculer avec une bonne précision le taux de restitution d'énergie associée à une fissure non cohésive de faible longueur située près de la pointe de l'entaille. En effet, il s'agit d'un véritable problème dans le cas où l'entaille n'est elle-même pas une fissure parce que le taux de restitution d'énergie est voisin de 0 lorsque la longueur de la fissure nucléée est voisine de 0, puis augmente rapidement avec la longueur de la fissure avant d'atteindre un maximum pour finalement redécroître. On explique d'abord comment le taux de restitution d'énergie est calculé par la Méthode des Elémenst Finis et pourquoi les résultats numériques sont moins précis lorsque la longueur de la fissure est faible. Ensuite, on utilise la MAM pour calculer le taux de restitution d'énergie pour les petites valeurs de la longueur de la fissure et on montre, comme il était prévu, que plus la taille de la fissure est petite, plus le résultat fourni par la MAM à un ordre donné est précis. Il s'avère même que l'on peut obtenir des résultats très précis en calculant seulement un petit nombre de termes. Nous discutons aussi de l'influence de l'angle de l'entaille sur l'exactitude des résultats. Cet angle joue un rôle important dans le processus de nucléation (parce que, en particulier, la longueur à partir de laquelle le maximum du taux de restitution d'énergie est atteinte dépend de l'angle de l'entaille). Lorsque l'angle de l'entaille est suffisamment grand, il suffit de calculer les deux premiers termes non triviaux du développement du taux de restitution d'énergie pour obtenir avec une très bonne précision la dépendance du taux de restitution d'énergie avec la longueur de fissure. Nous considérons ensuite le cas des fissures cohésives en introduisant le modèle de forces cohésives de Dugdale. En combinant la MAM avec la méthode G, nous obtenons un système de deux équations non linéaires couplées régissant l'évolution des longueurs de la zone non-cohésive et la zone cohésive en fonction du chargement. Il s'avère que le problème intérieur fourni par la MAM est un problème de Hilbert qui peut être résolu par la méthode des potentiels complexes. Ce faisant, la résolution se ramène à de simples quadratures qui sont calculées numériquement. On obtient ainsi, de façon quasiment analytique, la charge critique à partir de laquelle la petite fissure se propage de façon instable pour donner lieu à une fissure "macroscopique". En particulier, l'ordre de grandeur de cette charge critique est directement relié à l'exposant de la singularité de la solution avant fissuration qui est lui-même fonction de l'angle de l'entaille. Le chapitre 3 propose une généralisation de toutes les méthodes et résultats précédents au cas de l'élasticité plane. De façon précise, le but est toujours d'étudier la nucléation de fissures cohésives ou non cohésives à l'angle d'une entaille dans un milieu linéairement élastique et isotrope, mais maintenant en considérant des déplacements plans. De plus, il s'agit de traiter les conditions de nucléation aussi bien sous mode I pur que sous mode mixte. Dans la première partie du chapitre, nous utilisons le principe de minimisation globale pour traiter le cas des fissures non cohésives, alors que dans la deuxième partie nous utilisons le modèle de Dugdale pour traiter le cas des fissures cohésives. Dans les deux cas, la MAM est mise en oeuvre pour pallier le manque de précision de la méthode des éléments finis. Tous les résultats qui sont obtenus peuvent être considérés comme de simples généralisations de ceux développés dans le cas antiplan. En effet, d'un point de vue conceptuel et qualitatif, nous obtenons essentiellement le même type de propriétés. Toutefois, d'un point de vue technique, la MAM est plus délicate d'application en élasticité plane parce que l'obtention de la suite des fonctions singulières passe par la résolution d'équations transcendantes. Ce faisant, la mise en oeuvre numérique est sensiblement plus coûteuse. De plus, d'un point de vue analytique, les calculs et les démonstartions sont beaucoup plus lourds et une partie est donc passée en annexe...|$|E
40|$|Parts of {{this thesis}} {{has been written}} during long term visits to ORIE - Cornell University and Statistics department, Columbia University. In this thesis, we study various {{contemporary}} issues in quantitative finance. The first chapter {{is dedicated to the}} stability of the semimartingale property under filtration expansion. We study first progressive filtration expansions with random times. We show how semimartingale decompositions in the expanded filtration can be obtained using a natural link between progressive and initial expansions. The link is, on an intuitive level, that the two coincide after the random time. We make this idea precise and use it to establish known and new results in the case of expansion with a single random time. The methods are then extended to the multiple time case, without any restrictions on the ordering of the individual times. We then look to the expanded filtrations {{from the point of view}} of filtration shrinkage. We turn then to studying progressive filtration expansions with processes. Using results from the weak convergence of sigma fields theory, we first establish a semimartingale convergence theorem, which we apply in a filtration expansion with a process setting and provide sufficient conditions for a semimartingale of the base filtration to remain a semimartingale in the expanded filtration. A first set of results is based on a Jacod's type criterion for the increments of the process we want to expand with. An application to the expansion of a Brownian filtration with a time reversed diffusion is given through a detailed study and some known examples in the litterature are recovered and generalized. Finally, we focus on filtration expansion with continuous processes and derive two new results. The first one is based on a Jacod's type criterion for the successive hitting times of some levels and the second one is based on honest times assumptions for these hitting times. We provide examples and see how those can be used as first steps toward harmful dynamic insider trading models. In the expanded filtration the finite variation term of the price process can become singular and arbitrage opportunities (in the sense of FLVR) can therefore arise in these models. In the second chapter, we reconcile structural models and reduced form models in credit risk from the perspective of the information induced credit contagion effect. That is, given multiple firms, we are interested on the behaviour of the default intensity of one firm at the default times of the other firms. We first study this effect within different specifications of structural models and different levels of information. Since almost all examples are non tractable and computationally very involved, we then work with the simplifying assumption that conditional densities of the default times exist. The classical reduced-form and filtration expansion framework is therefore extended to the case of multiple, non-ordered defaults times having conditional densities. Intensities and pricing formulas are derived, revealing how information-driven default contagion arises in these models. We then analyze the impact of ordering the default times before expanding the filtration. While not important for pricing, the effect is significant in the context of risk management, and becomes even more pronounced for highly correlated and asymmetrically distributed defaults. We provide a general scheme for constructing and simulating the default times, given that a model for the conditional densities has been chosen. Finally, we study particular conditional density models and the information induced credit contagion effect within them. In the third chapter, we provide a methodology for a real time detection of bubbles. After the 2007 credit crisis, financial bubbles have once again emerged as a topic of current concern. An open problem is to determine in real time whether or not a given asset's price process exhibits a bubble. Due to recent progress in the characterization of asset price bubbles using the arbitrage-free martingale pricing technology, we are able to propose a new methodology for answering this question based on the asset's price volatility. We limit ourselves to the special case of a risky asset's price being modeled by a Brownian driven stochastic differential equation. Such models are ubiquitous both in theory and in practice. Our methods use non parametric volatility estimation techniques combined with the extrapolation method of reproducing kernel Hilbert spaces. We illustrate these techniques using several stocks from the alleged internet dot-com episode of 1998 - 2001, where price bubbles were widely thought to have existed. Our results support these beliefs. During May 2011, there was speculation in the financial press concerning the existence of a price bubble in the aftermath of the recent IPO of LinkedIn. We analyzed stock price tick data from the short lifetime of this stock through May 24, 2011, and we found that LinkedIn has a price bubble. The last chapter is about discretely sampled variance swaps, which are volatility derivatives that trade actively in OTC markets. To price these swaps, the continuously sampled approximation is often used to simplify the computations. The purpose of this chapter is to study the conditions under which this approximation is valid. Our first set of theorems characterize the conditions under which the discretely sampled variance swap values are finite, given the values of the continuous approximations exist. Surprisingly, for some otherwise reasonable price processes, the discretely sampled variance swap prices do not exist, thereby invalidating the approximation. Examples are provided. Assuming further that both variance swap values exist, we study sufficient conditions under which the discretely sampled values converge to their continuous counterparts. Because of its popularity in the literature, we apply our theorems to the 3 / 2 stochastic volatility model. Although we can show finiteness of all swap values, we can prove convergence of the approximation only for some parameter values. Dans cette thèse, nous étudions différentes problématiques d'actualité en finance quantitative. Le premier chapitre est dédié à la stabilité de la propriété de semimartingale après grossissement de la filtration de base. Nous étudions d'abord le grossissement progressif d'une filtration avec des temps aléatoires et montrons comment la décomposition de la semimartingale dans la filtration grossie est obtenue en utilisant un lien naturel entre la filtration grossie initiallement et celle grossie progressivement. Intuitivement, ce lien se résume au fait que ces deux filtrations coincident après le temps aléatoire. Nous précisons cette idée et l'utilisons pour établir des résultats connus pour certains et nouveaux pour d'autres dans le cas d'un grossissement de filtrations avec un seul temps aléatoire. Les méthodes sont alors étendues au cas de plusieurs temps aléatoires, sans aucune restriction sur l'ordre de ces temps. Nous étudions ensuite ces filtrations grossies du point de vue des rétrécissements des filtrations. Nous nous intéressons enfin au grossissement progressif de filtrations avec des processus. En utilisant des résultats de la convergence faible de tribus, nous établissons d'abord un théorème de convergence de semimartingales, que l'on appliquera dans un contexte de grossissement de filtrations avec un processus pour obtenir des conditions suffisantes pour qu'une semimartingale de la filtration de base reste une semimartingale dans la filtration grossie. Nous obtenons des premiers résultats basés sur un critère de type Jacod pour les incréments du processus utilisé pour grossir la filtration. Nous nous proposons d'appliquer ces résultats au cas d'un grossissement d'une filtration Brownienne avec une diffusion retournée en temps et nous retrouvons et généralisons quelques examples disponibles dans la littérature. Enfin, nous concentrons nos efforts sur le grossissement de filtrations avec un processus continu et obtenons deux nouveaux résultats. Le premier est fondé sur un critère de Jacod pour les temps d'atteinte successifs de certains niveaux et le second est fondé sur l'hypothèse que ces temps sont honnêtes. Nous donnons des examples et montrons comment cela peut constituer un premier pas vers des modèles dynamiques de traders initiés donnant naissance à des opportunités d'arbitrage nocives. Dans la filtration grossie, le terme à variation finie du processus de prix peut devenir singulier et des opportunités d'arbitrage (au sens de FLVR) apparaissent clairement dans ces modèles. Dans le deuxième chapitre, nous réconcilions les modèles structuraux et les modèles à forme réduite en risque de crédit, du point de vue de la contagion de crédit induite par le niveau d'information disponible à l'investisseur. Autrement dit, étant données de multiples firmes, nous nous intéressons au comportement de l'intensité de défaut (par rapport à une filtration de base) d'une firme donnée aux temps de défaut des autres firmes. Nous étudions d'abord cet effet sous des spécifications différentes de modèles structuraux et sous différents niveaux d'information, et tirons, par l'exemple, des conclusions positives sur la présence d'une contagion de crédit. Néanmoins, comme plusieurs exemples pratiques ont un coup calculatoire élevé, nous travaillons ensuite avec l'hypothèse simplificatrice que les temps de défaut admettent une densité conditionnelle par rapport à la filtration de base. Nous étendons alors des résultats classiques de la théorie de grossissement de filtrations avec des temps aléatoires aux temps aléatoires non-ordonnés admettant une densité conditionnelle et pouvons ainsi étendre l'approche classique de la modélisation à forme réduite du risque de crédit à ce cas général. Les intensités de défaut sont calculées et les formules de pricing établies, dévoilant comment la contagion de crédit apparaît naturellement dans ces modèles. Nous analysons ensuite l'impact d'ordonner les temps de défaut avant de grossir la filtration de base. Si cela n'a aucune importance pour le calcul des prix, l'effet est significatif dans le contexte du management de risque et devient encore plus prononcé pour les défauts très corrélés et asymétriquement distribués. Nous proposons aussi un schéma général pour la construction et la simulation des temps de défaut, étant donné qu'un modèle pour les densités conditionnelles a été choisi. Finalement, nous étudions des modèles de densités conditionnelles particuliers et la contagion de crédit induite par le niveau d'information disponible au sein de ces modèles. Dans le troisième chapitre, nous proposons une méthodologie pour la détection en temps réel des bulles financières. Après la crise de crédit de 2007, les bulles financières ont à nouveau émergé comme un sujet d'intéret pour différents acteurs du marché et plus particulièrement pour les régulateurs. Un problème ouvert est celui de déterminer si un actif est en période de bulle. Grâce à des progrès récents dans la caractérisation des bulles d'actifs en utilisant la théorie de pricing sous probabilité risque-neutre qui caractérise les processus de prix d'actifs en bulles comme étant des martingales locales strictes, nous apportons une première réponse fondée sur la volatilité du processus de prix de l'actif. Nous nous limitons au cas particulier où l'actif risqué est modélisé par une équation différentielle stochastique gouvernée par un mouvement Brownien. Ces modèles sont omniprésents dans la littérature académique et en pratique. Nos méthodes utilisent des techniques d'estimation non paramétrique de la fonction de volatilité, combinées aux méthodes d'extrapolation issues de la théorie des reproducing kernel Hilbert spaces. Nous illustrons ces techniques en utilisant différents actifs de la bulle internet (dot-com bubble) de la période 1998 - 2001, où les bulles sont largement acceptées comme ayant eu lieu. Nos résultats confirment cette assertion. Durant le mois de Mai 2011, la presse financière a spéculé sur l'existence d'une bulle d'actif après l'OPA sur LinkedIn. Nous analysons les prix de cet actif en nous basant sur les données tick des prix et confirmons que LinkedIn a connu une bulle pendant cette période. Le dernier chapitre traite des variances swaps échantillonnés en temps discret. Ces produits financiers sont des produits dérivés de volatilité qui tradent activement dans les marchés OTC. Pour déterminer les prix de ces swaps, une approximation en temps continu est souvent utilisée pour simplifier les calculs. L'intérêt de ce chapitre est d'étudier les conditions garantissant que cette approximation soit <b>valable.</b> Les premiers théorèmes caractérisent les conditions sous lesquelles les valeurs des variances swaps échantillonnés en temps discret sont finies, étant donné que les valeurs de l'approximation en temps continu sont finies. De manière étonnante, les valeurs des variances swaps échantillonnés en temps discret peuvent etre infinies pour des modèles de prix raisonnables, ce qui rend la pratique de marché d'utiliser l'approximation en temps continu invalide. Des examples sont fournis. En supposant ensuite que le payoff en temps discret et son approximation en temps continu ont des prix finis, nous proposons des conditions suffisantes pour qu'il y ait convergence de la version discrète vers la version continue. Comme le modèle à volatilité stochastique 3 / 2 est de plus en plus populaire, nous lui appliquons nos résultats. Bien que nous pouvons démontrer que les deux valeurs des variances swaps sont finies, nous ne pouvons démontrer la convergence de l'approximation que pour certaines valeurs des paramètres du modèle...|$|E

