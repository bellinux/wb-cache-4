1|72|Public
50|$|After the Allied Commission {{approved}} the plan, the Military Political Department established its central {{office with a}} counterintelligence unit, an intelligence unit, <b>verifying</b> <b>unit</b> (to screening and verifying the returning officers), guard unit, logistical unit and a personnel affairs unit. The department also had offices in every division, military district, at the border checkpoints and in the internment camps for the returning soldiers.|$|E
50|$|Read the {{specified}} unsorted_in.bam as input, sort it in blocks up to 5 million k (5 Gb) <b>verify</b> <b>units</b> here, {{this could be}} wrong and write output {{to a series of}} bam files named sorted_out.0000.bam, sorted_out.0001.bam, etc., where all bam 0 reads come before any bam 1 read, etc. verify this is correct.|$|R
50|$|NAPICU and the Royal College of Psychiatrists have {{teamed up}} to develop {{accreditation}} for psychiatric intensive care units. The standards {{are based on the}} existing national minimum standards and recently published evidence. Member units undertake a period of self-assessment and review, followed by peer review. Once <b>verified</b> <b>units</b> are awarded a certificate of accreditation.|$|R
5000|$|To <b>verify</b> a <b>unit</b> margin ($): Selling {{price per}} unit = Unit margin + Cost per Unit ...|$|R
40|$|Abstract — In {{this paper}} we {{describe}} a methodology and ex-perience of simulation-based verification of microprocessor units based on cycle-accurate contract specifications. Such specifica-tions describe {{behavior of a}} unit {{in the form of}} preconditions and postconditions of microoperations. We have successfully applied the methodology to several units of the industrial microprocessor. The experience shows that cycle-accurate contract specifications are very suitable for simulation-based verification, since, first, they represent functional requirements on a unit in compre-hensible declarative form, and second, they make it possible to automatically construct test oracles which <b>verify</b> <b>unit</b> correctness. I...|$|R
50|$|Integration Test Plans are {{developed}} during the Architectural Design Phase. These tests <b>verify</b> that <b>units</b> created and tested independently can coexist and communicate among themselves. Test results are shared with customer's team.|$|R
30|$|AusLCI {{contains}} <b>verified</b> Australian <b>unit</b> processes, {{but where}} data is limited, it is populated with the shadow database modified from Ecoinvent data. Whilst some energy and transport-related processes are replaced with Australian data, better analysis can be conducted when more Australian-specific data are available.|$|R
40|$|Abstract: This paper {{proposed}} {{a new type}} of converter called Single Phase Switched Inductor Z-source Matrix Converter (SLMC). It is an ac-to-ac converter with diode bridge bidirectional switch cell. The limitations of existing matrix converter like voltage regulation and quality output issues are overcome in the proposed SLMC by adding the switched inductance. The simulation is performed for different frequencies. The simulation results are presented to <b>verify</b> <b>unit</b> gain operation and compared with the existing Z-source matrix converter. A prototype was constructed with a voltage of 20 V rms/ 50 Hz. The performance of the proposed converter verified with this hardware model. The experimental output voltage amplitude can be varied with the variable frequencies. The output voltage and Total Harmonic Distortion (THD) are observed with 100 Hz and 25 Hz frequencies for step-up operation...|$|R
5000|$|By 1761 {{existing}} payroll accounts <b>verify</b> {{that the}} <b>unit</b> was indeed mustered, and by 1762 they {{had formed a}} part of the expedition against Havana, Cuba. There is also oral tradition that one of the cannons at the Old Barracks in Trenton, N. J. was a spoil of war for the Jersey Blues. Payroll accounts also <b>verify</b> that the <b>unit</b> remained activated through 1765. The Old Barracks Museum put forth a nice exhibit about the F & I War which includes rare artifacts of the Blues! ...|$|R
30|$|OBCSS {{software}} is <b>verified</b> through <b>unit</b> tests (Patton, 2005; Myers et al., 2011), acceptance test (Hsia et al., 1997; Myers et al., 2011) and beta test (Patton, 2005). Unit tests are created and run in development process. After development process has finished, acceptance test is run and beta test of OBCSS is run with eight sixth grade students {{of a state}} school in Turkey.|$|R
40|$|This paper {{describes}} {{the application of}} model-checking based verification tools to specification models of automotive control units. It firstly discusses {{the current state of}} a tool set which copes with discrete controllers described in Statemate, and then reports on proposed extensions currently under development to deal with hybrid ones which involve continuous values, too. First results based on an extension of abstraction techniques to <b>verify</b> such <b>units</b> are reported...|$|R
50|$|Using an {{automation}} framework, {{the developer}} codes criteria, or an oracle or result {{that is known}} to be good, into the test to <b>verify</b> the <b>unit's</b> correctness. During test case execution, the framework logs tests that fail any criterion. Many frameworks will also automatically flag these failed test cases and report them in a summary. Depending upon the severity of a failure, the framework may halt subsequent testing.|$|R
40|$|Many {{programs}} make implicit {{assumptions about}} data. Common as-sumptions include whether a variable has been initialized or can only contain non-null references. Domain-specific examples are also common, with many scientific programs manipulating values with implicit units of measurement. However, in languages like C, {{there is no}} language facil-ity for representing these assumptions, making violations of these implicit program policies challenging to detect. In this paper, we present a frame-work for pluggable policies for the C language. The core of the framework is a shared rewrite-logic semantics of C designed for symbolic execution of C programs, and an annotation engine allowing for annotations across multiple policies {{to be added to}} C programs. Policies are created by providing a policy specific language, usable in annotations, and policy specific values and semantics. This provides a method to quickly develop new policies, taking advantage of the existing framework components. To illustrate the use of the framework, two case studies in policy development are presented: a basic null pointer analysis, and a more comprehensive analysis to <b>verify</b> <b>unit</b> of measurement safety. ...|$|R
40|$|To {{verify the}} 15 -year {{reliability}} of the Navy half-watt radioisotope thermoelectric generator (RTG), bismuth-telluride thermoelectric converters were submitted to testing at high temperatures which accelerated the degradation and caused failure of the converters. Metallographic diagnostic examination of failed <b>units</b> <b>verified</b> failure mechanisms. Results of diagnostic examinations are presented...|$|R
40|$|Interactive {{theorem proving}} {{requires}} a lot of human guidance. Proving a property involves (1) figuring out why it holds, then (2) coaxing the theorem prover into believing it. Both steps can take a long time. We explain how to use GL, a framework for proving finite ACL 2 theorems with BDD- or SAT-based reasoning. This approach makes it unnecessary to deeply understand why a property is true, and automates the process of admitting it as a theorem. We use GL at Centaur Technology to <b>verify</b> execution <b>units</b> for x 86 integer, MMX, SSE, and floating-point arithmetic. ...|$|R
40|$|In this work, {{we present}} an {{approach}} to predicting transcription units based on Bayesian classifiers. The predictor uses publicly available data to train the classifier, such as genome sequence data from Genbank, expression values from microarray experiments, {{and a collection of}} experimentally <b>verified</b> transcription <b>units.</b> We have studied the importance of each of the data source on the performance of the predictor by developing three classifier models and evaluating their outcomes. The predictor was trained and validated on the E. coli genome, but can be extended to other organisms. Using the full Bayesian classifier, we were able to correctly identify 80 % of gene pairs belonging to operons...|$|R
40|$|Abstract. For {{the reality}} of thermal power units and the {{training}} needs of operating crew, introduce the PID regulator on the thermal power plant simulation machine. Depending on the various needs of simulation modeling, introduce the PID regulator control algorithm and some auxiliary functions. Through simulation of the actual <b>unit,</b> <b>Verify</b> that the controller has good dynamic performance and robustness...|$|R
40|$|This paper {{describes}} a rainfall-runoff simulation study, {{conducted in a}} laboratory to investigate surface runoff characteristics, <b>verify</b> <b>unit</b> hydrograph assumption and investigate {{the nature of the}} recession constant. A hydrology bench consisting of a metallic tray with an over head sprinkler system was used for this study. The metallic tray with soil bed and a river network acted as a small catchment. The over head sprinkler system consisting of spray nozzles acted as rainfall simulator. Different rainfall intensities and durations were taken as the treatments for the experiments. Surface runoff volume was collected at 10 secondly pulses of time in each experiment. Collected data were then processed and analyzed to explain the results. Unit hydrographs were developed from the surface runoff hydrographs for different rainfall durations and intensities. Recession constant K was calculated from the recession limb of each surface runoff hydrograph by optimization. Investigations show that runoff volume, runoff generation rate and peak runoff rate increase with the increasing rainfall duration. However, the peak runoff rate per sec of effective rainfall decreases with the increasing rainfall duration. There is also an evidence of the effects of rainfall intensity on runoff characteristics but no specific trend is identified. This study also reveals that the assumption of linearity between runoff volume and hydrograph ordinates is partially valid with some error which may be attributed to the non-uniform distributions of rainfall. Nature of recession constant suggests that the recession hydrograph is not only a function of catchment characteristics but also depends on rainfall intensities...|$|R
5000|$|In philosophy, any {{doctrine}} {{that emphasizes the}} priority of a whole over its parts is holism. Some suggest that such a definition owes its origins to a non-holistic view of language and places it in the reductivist camp. Alternately, a 'holistic' definition of holism denies {{the necessity of a}} division between the function of separate parts and the workings of the 'whole'. Effectively this means that the concept of a part has no absolute foundation in observation, but is rather a result of a materialist structuring of reality based on the necessity of logical and distinct units as a means to deriving information through comparative analysis. It suggests that the key recognizable characteristic of a concept of 'true' holism is a sense of the fundamental truth of any particular experience. This exists in contradistinction to what is perceived as the reductivist reliance on inductive method as the key to verification of its concept of how the parts function within the whole. Equally the potential for recognising the clarity of holistic experience within the logical terms of maths is limited by the abstract nature of numbers. In terms of real life measurements numbers have no scale or dimensional properties so have to rely on experimentally <b>verified</b> <b>units</b> (e.g. inches, volts, calories etc.), to describe reality. It is this reliance on the holistic integrity of experience which leads to the recognition that intuitive perception rather than mathematical calculation {{is the source of the}} truth of effective theories. (See references Holism, 2016.) ...|$|R
40|$|Energy {{from the}} exhaust gas of an {{internal}} combus-tion engine is used to power an absorption refriger-ation system to air-condition an ordinary passenger car. The theoretical design is <b>verified</b> by a <b>unit</b> that is tested under both laboratory and road-test condi-tions. For the latter, the unit is installed in a Nissan 1400 truck and the results indicate a successful pro-totype and encouraging prospects for future devel-opment...|$|R
40|$|Pattern {{geometry}} plays a {{major role}} in determining oil recovery during secondary and enhanced oil recovery operations. Although simulation is an important tool for design and evaluation, the first step often involves rough calculations based upon areal sweep efficiencies of displacements in homogeneous, two-dimensional, scaled, physical models. These results are available as a function of the displacement pattern and the mobility ratio, M. The mobility ratio is simply the mobility of the displacing phase over that of the displaced, or resident, phase. Because it is possible to compute sweep efficiency analytically when the displacing and displaced phase have the same mobility, scaled physical model results have been <b>verified</b> for <b>unit</b> mobility ratios...|$|R
40|$|We {{present a}} {{symbolic}} model checking approach that allows <b>verifying</b> a <b>unit</b> of code, e. g., a single procedure or {{a collection of}} procedures that interact with each other. We allow temporal specification that make assertions about both the program counters and the program variables. We decompose the verification into two parts: (1) a search {{that is based on}} the temporal behavior of the program counters, and (2) the formulation and refutation of a path condition, which. inherits conditions on the program variables from the temporal specification. This verification approach is modular, as there is no requirement that all the involved procedures are provided. Furthermore, we do not require that the code is based on a finite domain. The presented approach can also be used for automating the generation of test cases for unit testing...|$|R
40|$|We present {{algorithms}} that {{solve the}} following prob-lem: given three ranges of floating-point numbers Rx, Ry, Rz, a floating-point operation (op), and a rounding-mode (round), generate three floating-point numbers x̄, ȳ, z ̄ such that x ̄ ∈ Rx, y ̄ ∈ Ry, z ̄ ∈ Rz, and z ̄ = round(x ̄ op ȳ). This problem, although quite simple {{when dealing with}} intervals of real numbers, is much more complex when con-sidering ranges of machine numbers. We provide full solu-tions for add and subtract, and partial solutions for multiply and divide. We use range constraints on the input operands and on the result operand of floating-point instructions to target corner cases when generating test cases for use in ver-ification of floating-point hardware. The algorithms have been implemented in a floating-point test-generator and are currently being used to <b>verify</b> floating-point <b>units</b> of several processors. ...|$|R
40|$|Background. The {{effects of}} {{different}} practices on fault distributions in evolving complex software systems {{is not fully}} understood. Software reuse and unit verification are prac- tices used to improve system reliability by minimising the number of late faults. Reused software benefits from already being <b>verified</b> while <b>unit</b> verification aims to find faults early. Aims. We want to study effects of software reuse and unit verification on future modifications, fault densities of software units, and fault distributions. Method. We applied statistical analysis {{to a sample of}} 520 units that were reused and modified within four sequential projects from one product line in the telecommunication domain. Results. In reused units, the results of unit verification are correlated to a smaller degree of modifications and decreased fault densities. Conclusion. Unit verification in complex systems may improve system evolution in terms of smaller modifications and decrease of fault densities. The unit verification faults in reused components may be used as predictors of component modification and fault density...|$|R
40|$|An {{essential}} component of quality assurance in radiation therapy is verifying the accuracy of monitor unit calculations. Differences between sophisticated algorithms using 2. 5 D or 3 D calculations and simpler monitor unit check algorithms or hand calculations assuming a flat water phantom must be expected. For many anatomical sites, such differences are small and of little or no consequence {{in the context of}} expected clinical impact. However, for tangential breast fields the discrepancies are considerably larger than those that would generally be considered acceptable. A simple model to reconcile the differences between sophisticated and simple algorithms is presented, based on replacing the breast contour with a triangular or elliptical contour and using this to estimate an equivalent rectangular prism providing equivalent scatter to the prescription point. The elliptical approximation reconciles the observed differences in calculated monitor units. The analysis we present can assist the treatment planning physicist in selecting a method and tolerance window for <b>verifying</b> monitor <b>unit</b> calculations for tangential breast fields...|$|R
5000|$|Developers {{can sign}} disk images {{that can be}} <b>verified</b> as a <b>unit</b> by the system. In macOS Sierra, this allows {{developers}} to guarantee the integrity of all bundled files and prevent attackers from infecting and subsequently redistributing them. In addition, [...] "path randomization" [...] executes application bundles from a random, hidden path and prevents them from accessing external files relative to their location. This feature is turned off if the application bundle originated from a signed installer package or disk image or if the user manually moved the application without any other files to another directory.|$|R
40|$|Background: Operon {{structures}} play {{an important}} role in transcriptional regulation in prokaryotes. However, there have been fewer studies on complicated operon structures in which the transcriptional units vary with changing environmental conditions. Information about such complicated operons is helpful for predicting and analyzing operon structures, as well as understanding gene functions and transcriptional regulation. Results: We systematically analyzed the experimentally <b>verified</b> transcriptional <b>units</b> (TUs) in Bacillus subtilis and Escherichia coli obtained from ODB and RegulonDB. To understand the relationships between TUs and operons, we defined a new classification system for adjacent gene pairs, divided into three groups according to the level of gene co-regulation: operon pairs (OP) belong to the same TU, sub-operon pairs (SOP) that are at the transcriptional boundaries within an operon, and non-operon pairs (NOP) belonging to different operons. Consequently, we found that the levels of gene co-regulation was correlated to intergenic distances and gene expression levels. Additional analysis revealed that they were also correlated to the levels of conservation across about 200 prokaryotic genomes. Most interestingly, we found that functional associations i...|$|R
40|$|This paper {{proposes a}} set of well defined steps to design {{functional}} verification monitors intended to <b>verify</b> Floating Point <b>Units</b> (FPU) described in HDL. The first step consists on defining the input and output domain coverage. Next, the corner cases are defined. Finally, an already verified reference model is used {{in order to test}} the correctness of the Device Under Verification (DUV). As a case study a monitor for an IEEE 754 - 2008 compliant design is implemented. This monitor is built to be easily instantiated into verification frameworks such as OVM. Two different designs were verified reaching complete input coverage and successful compliant results...|$|R
50|$|The {{first new}} {{mechanism}} allows developers to code-sign disk images {{that can be}} <b>verified</b> as a <b>unit</b> by the system. This allows developers to guarantee the integrity of external files that are distributed alongside the application bundle on the same disk image. An attacker could infect these external files with malicious code and with them exploit a vulnerability in the application, without having to break the signature of the application bundle itself. By signing the disk image, the developer can prevent tampering and force an attacker to repackage the files onto a new disk image, requiring a valid developer certificate to pass Gatekeeper without a warning.|$|R
25|$|Later in the month, Bader {{scored a}} further two {{victories}} over Messerschmitt Bf 110s. On 30 August 1940, No. 242 Squadron {{was moved to}} Duxford again and found itself {{in the thick of}} the fighting. On this date, the squadron claimed 10 enemy aircraft, Bader scoring two victories against Bf 110s. Other squadrons were involved, and it was impossible to <b>verify</b> which RAF <b>units</b> were responsible for the damage on the enemy. On 7 September, two more Bf 110s were shot down, but in the same engagement Bader was badly hit by a Messerschmitt Bf 109. Bader almost baled out, but recovered the Hurricane. Other pilots witnessed one of Bader's victims crash.|$|R
40|$|In this paper, a {{multisensor}} fusion fault tolerant control system with fault detection and identification via set separation is presented. The fault detection and identification <b>unit</b> <b>verifies</b> that for each sensor–estimator combination, the estimation tracking errors lie inside pre-computed sets and discards faulty sensors when their associated estimation tracking errors leave the sets. An active fault tolerant controller is obtained, where the remaining healthy estimates are combined using a technique {{based on the}} optimal fusion criterion in the linear minimum-variance sense. The fused estimates are then used to implement a state feedback tracking controller. We ensure closed-loop stability and performance under the occurrence of abrupt sensor faults. Experimental validation, illustrating the {{multisensor fusion}} fault tolerant control strategy is included...|$|R
50|$|Later in the month, Bader {{scored a}} further two {{victories}} over Messerschmitt Bf 110s. On 30 August 1940, No. 242 Squadron {{was moved to}} Duxford again and found itself {{in the thick of}} the fighting. On this date, the squadron claimed 10 enemy aircraft, Bader scoring two victories against Bf 110s. Other squadrons were involved, and it was impossible to <b>verify</b> which RAF <b>units</b> were responsible for the damage on the enemy. On 7 September, two more Bf 110s were shot down, but in the same engagement Bader was badly hit by a Messerschmitt Bf 109. Bader almost baled out, but recovered the Hurricane. Other pilots witnessed one of Bader's victims crash.|$|R
40|$|Verification of {{industrial}} designs {{is becoming more}} challenging as technology advances and demand for higher performance increases. One of the most suitable debugging aids is automatic formal verification, which tests behaviors under all possible executions of a system. However, automatic formal verification {{is limited by the}} state explosion problem. This thesis presents a practical verification approach using FormalCheck, which helps reducing the state space explosion problem when verifying the high level descriptions of practical systems. This approach relies on the design's built-in hierarchy as the mechanism to conquer its complexity during verification. Then an assume guarantee paradigm is used to <b>verify</b> functional <b>units</b> built on top of instantiated and previously verified modules. We applied this approach to an industrial design (Transmit Master/Receive Slave (TMRS) Telecom System Block) as a case study. The TMRS was thoroughly verified and in consistencies in the design with respect to its specification were uncovered through model checking. The main contributions of this thesis are, (1) the application of a variety of model checking techniques to a real size design and (2) proposing a number of improvements to the design flow which can accelerate the whole verification process...|$|R
40|$|HMS Industrial {{networks}} is {{a company}} that offers communication solutions for automation systems. There exists an abundance of different industrial network technologies and HMS manufactures gateways that translate and allow communication between the different networks. The multiplicity of network technologies introduces problems when it comes to monitoring the processes in an automation system. It is desirable to be able to access the process data through a single network technology and this is what OPC UA is used for. Briefly, OPC UA can be described as an interface for exchange ofprocess data in automation systems. HMS has noticed a rising trend in the interest for OPC UA and therefore wants to investigate the possibility to use OPC UA on their platform, the Anybus X-Gateway. The goal of this thesis has been to port an OPC UA stack, provided by the OPCfoundation, to the HMS operating system running on an Anybus X-Gateway. The port has been successful and has been <b>verified</b> by <b>unit</b> tests and a test application. Thus, a first step towards a complete OPC UA product has been taken. Further, the thesis presents a theoretical summary about real-time operating systems to explain their function and usage...|$|R
40|$|This study {{attempts}} {{to find out the}} relationship between exports and participation in Clean Development Mechanism [CDM] in technology intensive industries in India. Firm level data are used from the PROWESS, CMIE and <b>Verified</b> Carbon <b>Units</b> VCU-database from 2007 to 2012. Results {{of this study indicate that}} firm size, age of the firms, profitability and R&D intensity are the major determinants of export intensity. In addition, technology imports and multinational affiliation also help firms in exporting more. The CDM participation in terms of higher VCU, and energy related technological advancements at firm level are also found to be major determinants of export intensity. India, unlike other established European carbon markets is not a platform for trading but the country is known for its creation of VCU and selling them. Government should focus more on smaller and less profitable firms and create a wider platform for them to be an active participant. Technology spillovers created by bigger and profitable firms which attract more benefits from Verified carbon offsetting should pool the entire interested ready-to-participate firms and attain a common goal, i. e. economically viable and environmentally sustainable and the leaders in the international export market...|$|R
40|$|The aim of {{this work}} is to explain and assess {{the results of the}} {{application}} of the TRAMO-SEATS seasonal adjustment method on the data of the ISAE manufacturing business and consumer surveys. In particular, the study begins by focusing on the description of some of the typical problems of the seasonal adjustment of qualitative series, in relation to the operational choices to be made when applying the procedure (the trading day effect, logarithmic transformation of the series, choice of a temporal interval etc) making the choices explicit for the series of analysis. Subsequently, the characteristics of the seasonal component of the series will be analysed; special attention is given to the identification of the non-stationary seasonality of each series by using a procedure which consists in the extension of a test of the Dickey-Fuller kind to <b>verify</b> the <b>unit</b> roots at the seasonal frequencies. Later, {{on the basis of the}} considerations which have been made and on the results which have been previously obtained, the models which have been obtained applying Tramo-Seats will then be described highlighting the flexibility of the method in grasping the stochastic characteristics of the seasonality of the series. Seasonal adjustment, ARIMA models, Survey, Tramo-Seats...|$|R
