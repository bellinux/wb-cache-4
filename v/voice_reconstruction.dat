14|10|Public
40|$|This article reviews {{methods of}} <b>voice</b> <b>reconstruction.</b> Nonsurgical methods of <b>voice</b> <b>reconstruction</b> include electrolarynx, {{pneumatic}} artificial larynx, and esophageal speech. Surgical methods of <b>voice</b> <b>reconstruction</b> include neoglottis, tracheoesophageal puncture, and prosthesis. Tracheoesophageal puncture {{can be performed}} in patients with pedicled flaps such as colon interposition, jejunum, or gastric pull-up or in free flaps such as perforator flaps, jejunum, and colon flaps. Other flaps for <b>voice</b> <b>reconstruction</b> include the ileocolon flap and jejunum. Laryngeal transplantation is also reviewed...|$|E
30|$|We {{showed that}} using an optimal transport-based loss can improve {{performance}} of NMF-based models for <b>voice</b> <b>reconstruction</b> and separation tasks. We {{believe this is}} a first step towards using optimal transport as a loss for speech processing, possibly using more complicated models such as sparse NMF or deep neural networks. The versatility of optimal transport, which can compare spectrograms on different frequency domains, lets us use dictionaries on sounds that are not recorded or processed {{in the same way as}} the training set. This property could also be beneficial to learn common representations (e.g., dictionaries) for different datasets.|$|E
40|$|Although the {{electrolarynx}} (EL) {{provides an}} important means of <b>voice</b> <b>reconstruction</b> {{for patients who}} lose their vocal cords by laryngectomies, the radiated noise and additive environment noise reduce the intelligibility of the resulting EL speech. This paper proposes an improved spectrum subtract algorithm by {{taking into account the}} non-uniform effect of colored noise on the spectrum of EL speech. Since the over-subtraction factor of each frequency band can be adjusted in the enhancement process, a better noise reduction effect was obtained and the perceptually annoying musical noise was efficiently reduced, as compared to other standard speech enhancement algorithms...|$|E
2500|$|Smith, John David, ed. We Ask Only for Even-Handed Justice: Black <b>Voices</b> from <b>Reconstruction,</b> 1865–1877 (University of Massachusetts Press, 2014). xviii, 133 pp ...|$|R
40|$|This work {{presents}} the {{theoretical background to}} provide the phase space <b>reconstruction</b> of chaotic <b>voice</b> signals. The <b>reconstruction</b> of phase space {{requires the use of}} the chaos theory and statistical methods such as mutual information and false neighbors. The reconstruction of the phase space in voice signals provides greater accuracy in the diagnosis of pathologies of the vocal system. ...|$|R
50|$|Koufman is {{the founder}} and {{director}} of the Voice Institute of New York, a comprehensive voice and reflux treatment center, and Professor of Clinical Otolaryngology at New York Medical College. As a surgeon, Koufman pioneered laryngeal framework surgery in the United States and was a founding member of the International Association of Phonosurgery. She performs <b>voice</b> (vocal cord) <b>reconstruction</b> surgery and office-based minimally invasive laryngeal laser surgery.|$|R
30|$|Optimal {{transport}} as a {{loss for}} machine learning optimization problems has recently gained a lot of attention. Building upon recent advances in computational optimal transport, we develop an optimal transport non-negative matrix factorization (NMF) algorithm for supervised speech blind source separation (BSS). Optimal transport allows us to design and leverage a cost between short-time Fourier transform (STFT) spectrogram frequencies, which takes into account how humans perceive sound. We give empirical evidence that using our proposed optimal transport, NMF leads to perceptually better results than NMF with other losses, for both isolated <b>voice</b> <b>reconstruction</b> and speech denoising using BSS. Finally, we demonstrate how to use optimal transport for cross-domain sound processing tasks, where frequencies represented in the input spectrograms may be different from one spectrogram to another.|$|E
40|$|Voice data packets have {{to arrive}} at the {{destination}} in time, with a defined cadence and with low and constant delay in order to allow the real time <b>voice</b> <b>reconstruction.</b> From this point of view, transmitting voice over IP networks is the most sensitive category of applications, especially when wireless medium is involved. The paper discusses the possibilities of transmitting the maximum number of simultaneous voice streams over 802. 11 wireless networks considering the main factors which impact with VoIP throughput, in a basic scenario. Starting from a proposed communication model, the number of simultaneous possible VoIP sessions is calculated, taking into consideration the contribution of the protocol overheads, the security overheads, the PHY level timings and the CODEC proprieties. Numerical results are generated and compared...|$|E
40|$|Abstract—Voice data packets have {{to arrive}} at the {{destination}} in time, with a defined cadence and with low and constant delay in order to allow the real time <b>voice</b> <b>reconstruction.</b> From this point of view, transmitting voice over IP networks is the most sensitive category of applications, especially when wireless medium is involved. The paper discusses the possibilities of transmitting the maximum number of simultaneous voice streams over 802. 11 wireless networks considering the main factors which impact with VoIP throughput, in a basic scenario. Starting from a proposed communication model, the number of simultaneous possible VoIP sessions is calculated, taking into consideration the contribution of the protocol overheads, the security overheads, the PHY level timings and the CODEC proprieties. Numerical results are generated and compared. Index Terms—throughput, quality of service (QoS), IEEE 802. 22 wireless LAN (WLAN), voice over IP (VoIP), voice codec I...|$|E
3000|$|... [*]>[*] 0.5, the {{adaptive}} sparsifying matrix and the DCT basis have similar {{performance for the}} first type and third type of voiced speech. However, for {{the second type of}} <b>voiced</b> speech, the <b>reconstruction</b> performance of {{the adaptive}} sparsifying matrix is slightly worse than that of the DCT basis. The reason is that with the great attenuation of the amplitude, the quasi-periodicity of the second type of voiced speech is undesirable.|$|R
30|$|Setting We now use NMF {{to first}} learn a {{universal}} speech model and noise models and then apply these models for speech denoising. The universal speech model is learned on the concatenated training {{data of the}} first male and first female voices of our dataset. For each noise type, we learn a model with NMF on its training data. We then mix test voices with test noise with a pSNR of 0 and use our BSS approach to separate the voice. All the scores reported are evaluated on the <b>voices</b> only since <b>reconstruction</b> of the noise is not our goal here.|$|R
40|$|Abstract. The {{equipment}} <b>voice</b> de-noising and <b>reconstruction</b> {{algorithm is}} {{presented in this paper}} based on intelligent robot in transformer situation (transformer and high resistance). The method is an embodiment of information and intelligence which can be applied in voice recognition of inspection robot. Firstly, equipment voice was collected and formed a sample database. Secondly, the voice features were analyzed in sample database, and the power-frequency Fourier spectrum as the voice features was extracted in the frequency domain. Finally, Fourier spectrum of power-frequency multiple was used to construct the voice by taking advantage of the inverse Fourier transform. The experimental results show that the algorithm has stable performance, strong robustness, and can accurately reconstruct the voice, so it is benefit to the follow-up voice recognition...|$|R
40|$|This paper {{considers}} regeneration {{of natural}} sounding speech from whisper-speech, produced by patients with vocal tract lesions affecting the glottis. Such reconstruction {{is important for}} both total and partial laryngectomy patients to improve on the monotonous robotized sound typical of electrolarynx devices. Reconstruction of speech from whispers has been demonstrated previously, however the resulting speech does not exhibit particularly high intelligibility, and more importantly, sounds un-natural. It is the conjecture of the authors that limited pitch variations in the reconstructed speech contributes most to that lack of naturalness. In this paper, a method for pitch contour variation in reconstructed speech is presented. This method extracts voice factors which are important to ‘naturalness’ from the whispered signal and applies these to the reconstructed speech. The method is based upon our previous published work which implemented an analysis-by-synthesis approach to <b>voice</b> <b>reconstruction</b> using a modified CELP codec...|$|E
40|$|Forward error {{correction}} (FEC) techniques {{are used to}} compensate for anticipated transmission errors in a network. When Packetized audio data is sent over a network channel, several different <b>voice</b> <b>reconstruction</b> techniques {{can be used to}} compensate for lost and delayed packets. Some of these make use of FEC principles while others do not. Most of the FEC techniques described in the literature are based on transmission of redundant information. Whenever a packet is lost or delayed, an approximate reconstruction of the data contained in that packet can be obtained by using some of the redundant data. In this paper we propose an FEC based reconstruction technique that does not transmit redundant information. Instead, we rely on the limited sensitivity of human ear to low frequency noise and very small periods of silence in an audio stream. 1 Introduction As applications like interactive conferencing over Internet become widespread, the quality of audio transmission becomes mor [...] ...|$|E
30|$|In this paper, we {{extend the}} optimal {{transport}} NMF of [22] {{to the case}} where the columns of the input matrix X are not normalized in order to propose an algorithm which is suitable for spectrogram data. We define a cost between frequencies so that the optimal transport objective between spectrograms provides a relevant metric between them. We apply our NMF framework to isolated <b>voice</b> <b>reconstruction</b> and show that an optimal transport loss yields better results than other classical losses. We show that optimal transport yields comparable results to other losses for BSS, where the sources to separate are voices. Moreover, we show that optimal transport achieves better results than other losses for learning a “universal” voice model, i.e., a model {{that can be applied}} to any voice, regardless of the speaker. We use this universal voice model to perform speech denoising, which is BSS where one of the source is a voice and the other is noise. Finally, we show how to use our framework for cross-domain BSS, where frequencies represented in the test spectrograms may be different from the ones in the dictionary. This may happen for example when train and test data are recorded with different equipment, or when the STFT is computed with different parameters.|$|E
40|$|Whispered speech can be {{effectively}} used for quiet and private communications over mobile phones {{and is also}} the communication means for ENT patients under a regime of <b>voice</b> rest. The <b>reconstruction</b> of natural sounding speech from such whispers can be useful for several types of application across different scientific fields ranging from communications to biomedical engineering. Despite the useful applications for a such technology, the reconstruction of natural speech from whispers has received relatively little research effort to date. This paper presents novel methods for spectral enhancement and formant smoothing {{with the aim of}} attaining more natural sounding speech within the reconstruction process. The proposed approach uses a probability mass-density function to identify a reliable formant trajectory through whispers and apply vocal modifications accordingly. Subjective evaluation experiments were performed, and are reported, to assess the performance of the techniques. A method for the near real-time conversion of whispers to normal phonated speech through a modified CELP codec has been discussed in our previously published work which, the proposed formant modification approach in this paper builds upon...|$|R
40|$|Abstruct-Packet {{switching}} {{has been}} proposed as an effective technology for integrating voice and data in a single network. An important aspect of packet-switched <b>voice</b> is the <b>reconstruction</b> of a continuous stream of speech from the set of packets that arrive at the destination terminal, each of which may encounter a different amount of buffering delay in the packet network. The magnitude {{of the variation in}} delay may range from a few milliseconds in a local area network to hundreds of milliseconds in a long-haul packet voice and data network. This paper discusses several aspects of the packet voice synchronization problem, and techniques {{that can be used to}} address it. These techniques estimate in some way the delay encountered by each packet and use the delay estimate to determine how speech is reconstructed. The delay estimates produced by these techniques can be used in managing the flow of information in the packet network to improve overall performance. Interactions of packet voice synchronization techniques with other network design issues are also discussed. A I...|$|R
40|$|When {{individuals}} {{lose the}} ability to produce their own speech, due to degenerative diseases such as motor neurone disease (MND) or Parkinson’s, they lose not only a functional means of communication but also a display of their individual and group identity. In order to build personalized synthetic voices, {{attempts have been made}} to capture the voice before it is lost, using a process known as voice banking. But, for some patients, the speech deterioration frequently coincides or quickly follows diagnosis. Using HMM-based speech synthesis, it is now possible to build personalized synthetic voices with minimal data recordings and even disordered speech. The power of this approach is that it is possible to use the patient’s recordings to adapt existing voice models pre-trained on many speakers. When the speech has begun to deteriorate, the adapted voice model can be further modified in order to compensate for the disordered characteristics found in the patient’s speech. The University of Edinburgh has initiated a project for <b>voice</b> banking and <b>reconstruction</b> based on this speech synthesis technology. At the current stage of the project, more than fifteen patients with MND have already been recorded and five of them have been delivered a reconstructed voice. In this paper, we present an overview of the project as well as subjective assessments of the reconstructed voices and feedback from patients and their families...|$|R
40|$|Abstract—rehabilitation of {{the ability}} to speak in a natural {{sounding}} voice, for patients who suffer larynx and voice box deficiencies, has long been a dream for both patients and researchers working in this field. Removal of, or damage to, the voice box in a surgical operation such as laryngectomy, affects the pitch generation mechanism of the human voice production system. Such patients speech thus becomes hoarse, whisper like and sometimes not easily perceptible. This speech is obviously different to that from normal speakers, and will have lost many of the distinctive characteristics of the original speech. However, these patients typically retain the ability to whisper in a similar way to normal speakers. This paper aims to present an engineering approach to providing laryngectomy patients the capacity to regain their ability to speak with a more natural voice, and as a side effect, to allow them to conveniently use a mobile phone for communications. The method uses auditory information only, allied with analysis, formant insertion and novel methods for spectrum enhancement and formant smoothing within the reconstruction process. In effect, natural sounding speech is obtained from their spoken whisper-speech, without recourse to surgery. The method builds upon our previously published works using an analysis-by-synthesis approach for <b>voice</b> <b>reconstruction</b> with a modified CELP codec...|$|E
40|$|Rehabilitation of {{the ability}} to speak in a natural {{sounding}} voice, for patients who suffer larynx and voice box deficiencies, has long been a dream for both patients and researchers working in this field. Removal of, or damage to, the voice box in a surgical operation such as laryngectomy, affects the pitch generation mechanism of the human voice production system. Post-laryngectomised patients thus exhibit hoarse, whisper like and sometimes less intelligible speech – it is obviously different to fully phonated speech, and may lack many of the distinctive characteristics of the patients normal voice. However these patients often retain the ability to whisper in a similar way to normal speakers. This chapter firstly discusses how the laryngectomy affects speech before briefly reviewing the three common methods of speech rehabilitation in such patients. It then presents, as a fourth method, a engineering approach to providing laryngectomy patients the capacity to speak with a more natural sounding voice. As a side effect, this allows them to conveniently use a mobile phone for communications. The approach is non-invasive and uses only auditory information, performing analysis, formant insertion, spectral enhancements and formant smoothing within the reconstruction process. In effect, natural sounding speech is obtained from spoken whispers, without recourse to surgery. The method builds upon our previously published works of using an analysis-by-synthesis approach for <b>voice</b> <b>reconstruction...</b>|$|E
40|$|Springer International Publishing AG 2017. In this work, {{we present}} a silent speech system that is able to {{generate}} audible speech from captured movement of speech articulators. Our {{goal is to help}} laryngectomy patients, i. e. patients who have lost the ability to speak following surgical removal of the larynx most frequently due to cancer, to recover their voice. In our system, we use a magnetic sensing technique known as Permanent Magnet Articulography (PMA) to capture the movement of the lips and tongue by attaching small magnets to the articulators and monitoring the magnetic field changes with sensors close to the mouth. The captured sensor data is then transformed into a sequence of speech parameter vectors from which a time-domain speech signal is finally synthesised. The key component of our system is a parametric transformation which represents the PMA-tospeech mapping. Here, this transformation {{takes the form of a}} statistical model (a mixture of factor analysers, more specifically) whose parameters are learned from simultaneous recordings of PMA and speech signals acquired before laryngectomy. To evaluate the performance of our system on <b>voice</b> <b>reconstruction,</b> we recorded two PMA-and-speech databases with different phonetic complexity for several non-impaired subjects. Results show that our system is able to synthesise speech that sounds as the original voice of the subject and also is intelligible. However, more work still need to be done to achieve a consistent synthesis for phonetically-rich vocabularies...|$|E
40|$|Abstract. Packet loss {{is one of}} {{the most}} {{essential}} problems in speech communication. It will cause the information loss and uncomfortable for listeners in voice over IP. This investment proposed an approach based on waveform similarity measure using overlap-and-Add algorithm. The waveform similarity overlap-and-add (WSOLA) technique is an effective algorithm to deal with packet loss concealment (PLC). For real-time time communication, the WSOLA algorithm is widely used to deal with the length adaptation and packet loss concealment of speech signal. Time scale modification of audio signal {{is one of the}} most essential research topics in data communication, especially in voice of IP (VoIP). Herein, we proposed the dual-side WSOLA that is derived by standard WSOLA. Instead of only exploitation one direction speech data, the proposed method will reconstruct the lost voice data according to the preceding and cascading voice. The dual-side WSOLA can use both the past and future speech signal waveform to <b>reconstruction</b> <b>voice</b> waveform of lost packet. The evaluations show that the quality of the reconstructed speech signal of the dual-side WSOLA is higher than that of the standard WSOLA and GWSOLA on different packet loss rate and length using the metrics: PESQ and MOS. The significant improvement is obtained by dual side information in the proposed method. The proposed dual-side waveform similarity overlap-and-add (DSWSOLA) outperforms the traditional approaches...|$|R
40|$|The human larynx is a {{versatile}} organ. Main functions are phonation, protection and {{regulation of the}} air ways. Patients suffer severely from the diagnosis of a laryngeal carcinoma of the stages T 3 and T 4. In most cases this diagnosis {{will lead to a}} total laryngectomy, which is usually dissatisfying in the sense of postoperative rehabilitation. The postoperative consequences include the loss of the native voice, the loss of regular air ways via mouth and nose, sense of smell, and the inability to build up an abdominal pressure. In this paper we focus on the feasibility of a modular larynx prosthesis which enables the laryngectomee to talk with his native voice, to breathe via the regular air ways, and to build up abdominal pressure. In particular we will give insights for a postoperative solution - a modular prosthesis based on a biomimetic self-regulating double clack-valve and on a <b>voice</b> <b>reconstruction</b> module, a so called vocoder. The vocoder is a device to reproduce the natural human voice. Most important for the use is an additional device required to analyze, conserve and manage voice characteristics of the patient before surgery. The self-regulating double clack-valve is designed to build up an abdominal pressure e. g. to cough. Therefore, our valve-system is working in both directions - a two-way valve system. By bridging the gap of the regular air ways lost by laryngectomy, the sense of smell and taste are restored. In the following we will present details and characteristics of these two main components required for a modular prosthesis of the larynx in laryngectomees...|$|E
30|$|Statistical speech {{synthesis}} (SSS) is a fast-growing research area for text-to-speech (TTS) systems. While a state-of-the-art concatenative method [1, 2] for TTS {{is capable of}} synthesizing natural and smooth speech for a specific voice, an SSS-based approach [3, 4] has the strength to produce a diverse spectrum of voices without requiring significant amount of new data. This is an important feature for building next-generation applications such as a story-telling robot capable of synthesizing the speech of multiple characters with different emotions, personalized {{speech synthesis}} such as in speechto-speech translation [5, 6], and clinical applications such as <b>voice</b> <b>reconstruction</b> of patients with speech disorders [7]. In this article, we study the problem of generating new models of SSS from existing models. The model parameters of SSS can be systematically modified to express different emotions. Many instances of this problem have been investigated in the literature. In [8], the prosody is mapped from neutral to emotional using Gaussian mixture models and classification and regression trees. In [9], the spectrum and duration are converted in a voice conversion system with duration-embedded hidden Markov models (HMMs). In [10, 11], style-dependent and style-mixed modeling methods for emotional expressiveness are investigated. In [12], adaptation methods are used to transform the neutral model to the target model, requiring only small amounts of adaptation data. In [13 – 15], simultaneous adaptation of speaker and style is applied to an average voice model of multiple-regression HMMs to synthesize speaker-dependent styled speech. A few methods without the requirement of target speaker’s emotional speech have been studied. In [16], neutral speech are adapted based on analysis of emotional speech from the prosodic point of view. In [17, 18], speech with emotions or mixed styles are generated by interpolating styled speech models trained independently. In [19], prosodic parameters including pitch, duration, and strength factors are adjusted to generate emotional speech from neutral voice.|$|E

