42|1492|Public
500|$|The {{plane of}} motion is {{perpendicular}} to the angular momentum vector L, which is constant; this may be expressed mathematically by the <b>vector</b> <b>dot</b> <b>product</b> equation likewise, since A lies in that plane, [...]|$|E
2500|$|... with uθ a {{unit vector}} {{perpendicular}} to uR at time t (as can be verified by noticing that the <b>vector</b> <b>dot</b> <b>product</b> with the radial vector is zero) and pointing {{in the direction of}} travel.|$|E
2500|$|Orthogonality can be {{verified}} {{by showing that}} the <b>vector</b> <b>dot</b> <b>product</b> is zero. The unit magnitude of these vectors {{is a consequence of}} Eq. 1. Using the tangent vector, the angle θ of the tangent to the curve is given by: ...|$|E
5000|$|From the theorem, {{the actual}} {{form of the}} Poynting vector S can be found. The time {{derivative}} of the energy density (using the <b>product</b> rule for <b>vector</b> <b>dot</b> <b>products)</b> is ...|$|R
40|$|We {{report on}} early {{results of a}} {{numerical}} and statistical study of binary black hole inspirals. The two black holes are evolved using post-Newtonian approximations starting with initially randomly distributed spin vectors. We characterize {{certain aspects of the}} distribution shortly before merger. In particular we note the uniform distribution of black hole spin <b>vector</b> <b>dot</b> <b>products</b> shortly before merger and a high correlation between the initial and final black hole spin <b>vector</b> <b>dot</b> <b>products</b> in the equal-mass, maximally spinning case. These simulations were performed on Graphics Processing Units, and we demonstrate a speed-up of a factor 50 over a more conventional CPU implementation. Comment: Added one referenc...|$|R
5000|$|For a {{point in}} a {{two-dimensional}} grid, this will require the computation of 4 distance <b>vectors</b> and <b>dot</b> <b>products,</b> while in three dimensions 8 distance <b>vectors</b> and 8 <b>dot</b> <b>products</b> are needed. This leads to the [...] complexity scaling.|$|R
2500|$|... where Ecs is the {{conservative}} electrostatic field {{created by the}} charge separation associated with the emf, dℓ {{is an element of}} the path from terminal A to terminal B, and ‘·’ denotes the <b>vector</b> <b>dot</b> <b>product.</b> This equation applies only to locations A and B that are terminals, and does not apply to paths between points A and B with portions outside the source of emf. This equation involves the electrostatic electric field due to charge separation Ecs and does not involve (for example) any non-conservative component of electric field due to Faraday's law of induction.|$|E
2500|$|A line L in 3-dimensional Euclidean {{space is}} {{determined}} by two distinct points that it contains, or by two distinct planes that contain it. Consider the first case, with points x= (x1,x2,x3) and y= (y1,y2,y3). The vector displacement from x to y is nonzero because the points are distinct, and represents {{the direction of the}} line. That is, every displacement between points on L is a scalar multiple of d= y−x. If a physical particle of unit mass were to move from x to y, it would have a moment about the origin. The geometric equivalent is a vector whose direction is perpendicular to the plane containing L and the origin, and whose length equals twice the area of the triangle formed by the displacement and the origin. Treating the points as displacements from the origin, the moment is m= x×y, where [...] "×" [...] denotes the vector cross product. For a fixed line, L, the area of the triangle is proportional to the length of the segment between x and y, considered as the base of the triangle; it is not changed by sliding the base along the line, parallel to itself. By definition the moment vector is perpendicular to every displacement along the line, so d•m= 0, where [...] "•" [...] denotes the <b>vector</b> <b>dot</b> <b>product.</b>|$|E
5000|$|... (where [...] {{denotes the}} <b>vector</b> <b>dot</b> <b>product</b> {{and which is}} taken over [...] ).|$|E
40|$|Attempts {{to answer}} {{problems}} in areas {{as diverse as}} science, technology and economics involve solving simultaneous linear equations. In this unit we {{look at some of}} the equations that represent points, lines and planes in mathematics. We explore concepts such as Euclidean space, <b>vectors,</b> <b>dot</b> <b>products</b> and conics. ...|$|R
2500|$|... where [...] and [...] are -dimensional vectors, and [...] is the <b>dot</b> <b>product</b> of the <b>vectors.</b> The <b>dot</b> <b>product</b> is {{sometimes}} written as [...]|$|R
5000|$|By {{the usual}} {{procedure}} for finding the angle &theta; between two <b>vectors</b> (see <b>dot</b> <b>product),</b> the uncentered correlation coefficient is: ...|$|R
50|$|The more {{generalized}} form is used {{to describe}} a plane wave traveling in an arbitrary direction. It uses vectors {{in combination with the}} <b>vector</b> <b>dot</b> <b>product.</b>|$|E
5000|$|Orthogonality can be {{verified}} {{by showing that}} the <b>vector</b> <b>dot</b> <b>product</b> is zero. The unit magnitude of these vectors {{is a consequence of}} Eq. 1. Using the tangent vector, the angle θ of the tangent to the curve is given by: ...|$|E
50|$|The {{plane of}} motion is {{perpendicular}} to the angular momentum vector L, which is constant; this may be expressed mathematically by the <b>vector</b> <b>dot</b> <b>product</b> equation r ⋅ L = 0; likewise, since A lies in that plane, A ⋅ L = 0.|$|E
2500|$|Without {{reference}} to {{the components of the}} <b>vectors,</b> the <b>dot</b> <b>product</b> of two non-zero Euclidean vectors [...] and [...] is given by ...|$|R
5000|$|Without {{reference}} to {{the components of the}} <b>vectors,</b> the <b>dot</b> <b>product</b> of two non-zero Euclidean vectors [...] and [...] is given bywhere [...] is the angle between [...] and [...]|$|R
2500|$|... {{the rows}} and columns are {{orthogonal}} unit <b>vectors,</b> therefore their <b>dot</b> <b>products</b> are zero.|$|R
50|$|This {{displacement}} {{is necessarily}} tangent to the curve at s, {{showing that the}} unit vector tangent to the curve is:while the outward unit vector normal to the curve is Orthogonality can be verified by showing the <b>vector</b> <b>dot</b> <b>product</b> is zero. The unit magnitude of these vectors {{is a consequence of}} Eq. 1.|$|E
5000|$|If ƒ{0,1}n→{0,1}n is {{a one-way}} permutation, then so is ƒ'{0,1}2n→{0,1}2n, where ƒ'(x,y)=ƒ(x).y by definition. Then B(x,y)=x⋅y is a hard-core {{predicate}} for ƒ', where ⋅ is a <b>vector</b> <b>dot</b> <b>product.</b> To {{prove that it}} is indeed hard-core let's assume otherwise, and show a contradiction with the hypothesis of ƒ being one-way. If B is not a hard-core predicate, then there exists a circuit C that predicts it, so ...|$|E
5000|$|... where [...] is {{an element}} of surface area of the moving surface , [...] is the {{magnetic}} field (also called [...] "magnetic flux density"), and [...] is a <b>vector</b> <b>dot</b> <b>product</b> (the infinitesimal amount of magnetic flux through the infinitesimal area element [...] ). In more visual terms, the magnetic flux through the wire loop is proportional to the number of magnetic flux lines that pass through the loop.|$|E
25|$|Note {{that the}} order is {{important}} because between a bivector and a <b>vector</b> the <b>dot</b> <b>product</b> is anti-symmetric. Upon a space time split like one can obtain the velocity, and fields as above yielding the usual expression.|$|R
40|$|We present paired {{learning}} and inference algorithms for significantly reducing computation and increasing {{speed of the}} <b>vector</b> <b>dot</b> <b>products</b> in the classifiers {{that are at the}} heart of many NLP components. This is accomplished by partition-ing the features into a sequence of templates which are ordered such that high confidence can often be reached using only a small fraction of all features. Pa-rameter estimation is arranged to maximize accuracy and early confidence in this sequence. We present experiments in left-to-right part-of-speech tagging on WSJ, demonstrating that we can preserve accuracy above 97 % with over a five-fold re-duction in run-time. ...|$|R
50|$|With {{row major}} matrix order, {{it is easy}} to {{transform}} <b>vectors</b> using <b>dot</b> <b>product</b> operations, since the coefficients of each component are sequential in memory. Consequently, this layout may be desirable if a processor supports <b>dot</b> <b>product</b> operations natively. It is also possible to efficiently use a '3x4' affine transformation matrix without padding or awkward permutes.|$|R
5000|$|... {{where the}} leading term is the {{customary}} <b>vector</b> <b>dot</b> <b>product</b> {{and the second}} term is called the wedge product. Using the postulates of the algebra, all combinations of dot and wedge products can be evaluated. A terminology to describe the various combinations is provided. For example, a multivector is a summation of k-fold wedge products of various k-values. A k-fold wedge product also {{is referred to as}} a k-blade.|$|E
5000|$|... and so forth. (The {{number of}} {{dimensions}} may {{be larger than}} three.) An important aspect of such coordinate systems is the element of arc length that allows distances to be determined. If the curvilinear coordinates form an orthogonal coordinate system, the element of arc length ds is expressed as:where the quantities hk are called scale factors. A change dqk in qk causes a displacement hk dqk along the coordinate line for qk. At a point P, we place unit vectors ek each tangent to a coordinate line of a variable qk. Then any vector can be {{expressed in terms of}} these basis vectors, for example, from an inertial frame of reference, the position vector of a moving particle r located at time t at position P becomes:where qk is the <b>vector</b> <b>dot</b> <b>product</b> of r and ek.The velocity v of a particle at P, can be expressed at P as:where vk is the <b>vector</b> <b>dot</b> <b>product</b> of v and ek, and over dots indicate time differentiation.The time derivatives of the basis vectors can be expressed in terms of the scale factors introduced above. for example: ...|$|E
5000|$|... where Ecs is the {{conservative}} electrostatic field {{created by the}} charge separation associated with the emf, dℓ {{is an element of}} the path from terminal A to terminal B, and ‘·’ denotes the <b>vector</b> <b>dot</b> <b>product.</b> This equation applies only to locations A and B that are terminals, and does not apply to paths between points A and B with portions outside the source of emf. This equation involves the electrostatic electric field due to charge separation Ecs and does not involve (for example) any non-conservative component of electric field due to Faraday's law of induction.|$|E
5000|$|In {{an inner}} product space, {{the concept of}} {{perpendicularity}} is replaced by the concept of orthogonality: two vectors v and w are orthogonal if their inner product [...] is zero. The inner product is a generalization of the <b>dot</b> <b>product</b> of <b>vectors.</b> The <b>dot</b> <b>product</b> is called the standard inner product or the Euclidean inner product. However, other inner products are possible.|$|R
5000|$|Vector {{calculus}} identities can {{be derived}} {{in a similar way}} to those of <b>vector</b> <b>dot</b> and cross <b>products</b> and combinations. For example, in three dimensions, the curl of a cross product of two vector fields A and B: ...|$|R
3000|$|... flop {{operations}} [14]. The flop {{count for}} SVD {{of a real}} valued M × N matrix is given by 4 M 2 N + 8 MN 2 + 9 N 3 in Golub-Reinsch algorithm [15]. The multiplication and the addition between two complex scalar values require six flops and two flops, respectively. Further, most operations in SVD are matrix multiplications, which in turn consist of several <b>vector</b> <b>dot</b> <b>products.</b> Each <b>dot</b> <b>product</b> of two real vectors with length N has the flop count of 2 N, whereas the flop count for two complex vectors is 8 N. That is, the SVD complexity of a complex matrix is four times {{higher than that of}} a real matrix approximately due to some additional scalar multiplications and additions. This is more accurate than [14] where the flop count of a complex SVD is approximated by six times that of a real SVD by treating every operation as complex multiplication. Thus, the flop count for SVD of a complex valued M × N matrix is [...]...|$|R
5000|$|However, a line {{integral}} involves {{the application of}} the <b>vector</b> <b>dot</b> <b>product,</b> and when this is extended to 4-dimensional spacetime, a change of sign is introduced to either the spatial co-ordinates or the time co-ordinate depending on the convention used. This is due to the non-Euclidean nature of spacetime. In this article, we place a negative sign on the spatial coordinates (the time-positive metric convention [...] ). The factor of (1/c) is to keep the correct unit dimensionality {1/length} for all components of the 4-vector and the (−1) is to keep the 4-gradient Lorentz covariant. Adding these two corrections to the above expression gives the correct definition of 4-gradient: ...|$|E
50|$|Components of {{mechanical}} systems will store elastic potential energy {{if they are}} deformed when forces are applied to the system. Energy is transferred to an object (i.e. work is done on it) any time a force external to it displaces or deforms the object. The quantity of energy transferred by work to the object is computed as the <b>vector</b> <b>dot</b> <b>product</b> of the force and the displacement of the object. As forces are applied to the system they are distributed internally to its component parts. While some of the energy transferred can end up stored as kinetic energy of acquired velocity, the deformation of the shape of component objects results in stored elastic energy.|$|E
5000|$|An {{important}} part of determining bending moments in practical problems is the computation of moments of force.Let [...] be a force vector acting at a point A in a body. The moment of this force about a reference point (O) is defined as where [...] is the moment vector and [...] is the position vector from the reference point (O) {{to the point of}} application of the force (A). The [...] symbol indicates the vector cross product. For many problems, it is more convenient to compute the moment of force about an axis that passes through the reference point O. If the unit vector along the axis is , the moment of force about the axis is defined aswhere [...] indicates the <b>vector</b> <b>dot</b> <b>product.</b>|$|E
40|$|We present paired {{learning}} and inference algorithms for significantly reducing com-putation and increasing {{speed of the}} <b>vector</b> <b>dot</b> <b>products</b> in the classifiers {{that are at the}} heart of many NLP components. This is accomplished by partitioning the features into a sequence of templates which are or-dered such that high confidence can of-ten be reached using only a small fraction of all features. Parameter estimation is arranged to maximize accuracy and early confidence in this sequence. Our approach is simpler and better suited to NLP than other related cascade methods. We present experiments in left-to-right part-of-speech tagging, named entity recognition, and transition-based dependency parsing. On the typical benchmarking datasets we can preserve POS tagging accuracy above 97 % and parsing LAS above 88. 5 % both with over a five-fold reduction in run-time, and NER F 1 above 88 with more than 2 x in-crease in speed. ...|$|R
40|$|Precomputed {{radiance}} transfer (PRT) [10] is {{an exciting}} new approach to low-frequency lighting conditions introducing area light sources, soft shadows and reflections on diffuse and glossy objects. The approach models the transfer of radiance by the rendered objects represented in low-order spherical harmonic functions to enable the calculation of the rendering equation integrals using simple coefficient <b>vector</b> <b>dot</b> <b>products</b> or matrix multiplications. The transfer functions are precomputed densely over the object with raytracing. Self-shadowing and interreflections are implemented {{with no additional cost}} at run-time. The approach handles static and dynamic lighting. A tabulated arbitrary BRDF method [3] extends the approach. Matrix Transfer [4] combines all the previous properties with full matrix representation of the transfer, a final basis change to accelerate exit radiance calculations and compression to limit the size of the transfer functions. The variations of PRT produce images not possible with previou...|$|R
40|$|This paper revisits {{the main}} {{problems}} faced by linear regression models. The exogenous condition for linear regression is verified by using the triangular law of <b>vectors</b> and <b>dot</b> <b>product</b> of <b>vectors.</b> Errors in variables and missing variables are analyzed analytically. This paper shows that these two problems will cause large sample bias of LS estimator for the parameters. Practical suggestions are made on how these problems can be minimized on a case to case basis...|$|R
