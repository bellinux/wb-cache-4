61|229|Public
25|$|IBAN {{imposes a}} {{flexible}} but regular format sufficient for account identification and contains <b>validation</b> <b>information</b> to avoid errors of transcription. It carries all the routing {{information needed to}} get a payment from one bank to another wherever it may be; it contains key bank account details such as country code, branch codes (known as sort codes in the UK and Ireland) and account numbers, and it contains check digits which can be validated at source according to a single standard procedure. Where used, IBANs have reduced trans-national money transfer errors to under 0.1% of total payments.|$|E
50|$|In the 2011 {{version of}} TTD, target <b>{{validation}}</b> <b>information</b> has been integrated. Target validation normally requires the determination that {{the target is}} expressed in the disease-relevant cells/tissues, it can be directly modulated by a drug or drug-like molecule with adequate potency in biochemical assay, and that target modulation in cell and/or animal models ameliorates the relevant disease phenotype. Therefore, TTD collects three types of target validation data: experimentally determined potency of drugs against their primary target or targets, observed potency or effects of drugs against disease models (cell-lines, ex-vivo, in-vivo models) linked to their primary target or targets, and the observed effects of target knockout, knockdown, RNA interference, transgenetic, antibody or antisense treated in-vivo models. Currently, TTD provides complete or partial <b>validation</b> <b>information</b> for 932 targets (351 successful, 252 clinical trial, 34 discontinued and 295 research targets). All <b>validation</b> <b>information</b> can be retrieved from Target Validation Page.|$|E
50|$|On January 28, 2013, Google's DNS servers silently started {{providing}} DNSSEC <b>validation</b> <b>information,</b> {{but only}} if the client explicitly set the DNSSEC OK (DO) flag on its query.|$|E
3000|$|Develop {{tools for}} {{ortholog}} prediction between rice, Arabidopsis and crops to accelerate candidate <b>validation</b> and <b>information</b> transfer [...]...|$|R
5000|$|... #4 Common Criteria Evaluation and <b>Validation</b> Scheme for <b>Information</b> Technology Security — Guidance to Common Criteria Testing Laboratories ...|$|R
50|$|The HDI has a {{clinician}} {{rating form}} that allows <b>validation</b> of self-report <b>information.</b> This improves the database for research purposes.|$|R
50|$|An ECRS {{can provide}} the ability to {{schedule}} tasks on both the accounting system server and the LAN. Individual tasks may be run at timed intervals separately, or grouped into task lists and run together. Scheduled tasks may include processes on the accounting server to extract <b>validation</b> <b>information,</b> transferring <b>validation</b> <b>information</b> to the LAN, updating a vendor’s validation tables on the cost recovery system (such as employee IDs, accounting codes and cost-types), transferring cost transactions from the LAN to the accounting server and processing cost transactions into the billing system. Transaction processes can then be automated to minimize administrative overhead and reduce delays updating transactions into the billing system.|$|E
50|$|The space mapping {{methodology}} for modeling and design optimization of engineering systems was first discovered by John Bandler in 1993. It uses relevant existing knowledge {{to speed up}} model generation and design optimization of a system. The knowledge is updated with new <b>validation</b> <b>information</b> from the system when available.|$|E
5000|$|... #Caption: A 2D {{diagram of}} an N-glycan {{linked to an}} {{antibody}} fragment in the structure with PDB accession code '4BYH'. This diagram, which has been generated with Privateer, follows the standard symbol nomenclature and includes, in its original svg format, annotations containing <b>validation</b> <b>information,</b> including ring conformation and detected monosaccharide types.|$|E
50|$|This {{effort is}} a part of a larger {{interoperability}} testbed. The interop testbed serves as an online presence for learning about EDXL, how to implement systems using EDXL, online <b>validation</b> and <b>information</b> sharing tools, and a place to perform integration with other systems that use EDXL.|$|R
5000|$|... #1 Common Criteria Evaluation and <b>Validation</b> Scheme for <b>Information</b> Technology Security — Organization, Management, and Concept of Operations and Scheme Publication ...|$|R
50|$|From July 21 to 23, {{unauthorized}} {{troop movements}} apparently bound for Manila had been monitored upon <b>validation</b> of the <b>information</b> {{that there was}} restiveness among junior AFP officers.|$|R
5000|$|Drug SubstanceType II DMFs {{for drug}} {{substances}} may be submitted in the format for [...] "Drug substance" [...] in the [...] "Guidance for Industry M4Q: The CTD - Quality".(Category 3) Drug Substance:See the current Guideline for Submitting Supporting Documentation in Drug Applications for the Manufacture of Drug Substances.It {{is not necessary}} to include a Methods Validation Package (3.2.R.3). Methods <b>Validation</b> <b>information</b> should be submitted in Section 3.2.S.4.3.See also the DRAFT ICH Guidance “Q11 Development and Manufacture of Drug SubstancesDrug Product:Type II DMFs for drug products may be submitted in the format for [...] "Drug product" [...] in the [...] "Guidance for Industry M4Q: The CTD - Quality".(Category 3) Drug Product.See the Guideline For Submitting Supporting Documentation In Drug Applications For The Manufacture Of Drug Products.It {{is not necessary to}} include a Methods Validation Package (3.2.R.3). Methods <b>Validation</b> <b>information</b> should be submitted in Section 3.2.P.5.3.|$|E
50|$|Privateer also generates {{scalable}} two-dimensional SVG diagrams {{according to}} the Essentials of Glycobiology standard symbol nomenclature containing all the <b>validation</b> <b>information</b> as tooltip annotations (see figure). This functionality is currently integrated into other CCP4 programs, such as the molecular graphics program CCP4mg (through the Glycoblocks 3D representation, which conforms to the standard symbol nomenclature) and the suite's graphical interface, CCP4i2.|$|E
50|$|IBAN {{imposes a}} {{flexible}} but regular format sufficient for account identification and contains <b>validation</b> <b>information</b> to avoid errors of transcription. It carries all the routing {{information needed to}} get a payment from one bank to another wherever it may be; it contains key bank account details such as country code, branch codes (known as sort codes in the UK and Ireland) and account numbers, and it contains check digits which can be validated at source according to a single standard procedure. Where used, IBANs have reduced trans-national money transfer errors to under 0.1% of total payments.|$|E
40|$|The {{authors are}} {{involved}} in monitoring actions on passive solar systems, in particular on glasshouses and Trombe-Michel walls, applied in retrofitting of residential buildings. Those monitoring actions are producing significant data concerning: the operation/efficiency of the checked systems, their performances according to solar radiation absorption, the mode/efficiency of heat transfer, {{the effect of the}} users’ behaviour, the <b>validation</b> of <b>information</b> in the literature...|$|R
50|$|<b>Validation</b> of <b>information</b> in an Open Interdisciplinary Peer Review is {{an ongoing}} or second Interdisciplinary Peer Review. Interdisciplinary Peer Review is a continual process of review. When {{publication}} is instant and prior to a review, the accuracy falls under scrutiny in the Open review nature of social media. The level of accuracy potentially becomes more variable as the non peer group dissemination increases.|$|R
25|$|Most {{people do}} not keep record of minute details of their {{healthcare}} experiences and therefore {{find it difficult to}} make use of web-based PHRs. Overall, the sites selected for evaluation offered limited functionality to the general public. Low adoption of web-based PHRs can be a direct result of limitations in these applications’ data entry, <b>validation</b> and <b>information</b> display methods. PHR development should be guided by ample patient-oriented research in future.|$|R
50|$|At {{the launch}} of Google Public DNS, it did not {{directly}} support DNSSEC. Although RRSIG records could be queried, the AD (Authenticated Data) flag was not set in the launch version, meaning the server was unable to validate signatures {{for all of the}} data. This was upgraded on 28 January 2013, when Google's DNS servers silently started providing DNSSEC <b>validation</b> <b>information,</b> but only if the client explicitly set the DNSSEC OK (DO) flag on its query. This service requiring a client-side flag was replaced on 6 May 2013 with full DNSSEC validation by default, meaning all queries will be validated unless clients explicitly opt out.|$|E
40|$|Abstract: A {{system is}} {{proposed}} that {{is capable of}} identifying the true originator of an email message. This information can be combined with existing whitelist and blacklist technology to provide an effective anti-spam system. The approach is to store <b>validation</b> <b>information</b> that {{can be traced to the}} sender and to utilize a “Reachback URL ” in the message to access the <b>validation</b> <b>information.</b> The approach proposed here has a number of advantages over existing systems. It does not require use of DNS, it can use the existing email distribution system, it is robust against in-transit header modifications and mail forwarding, and it can identify sources down to the granularity of individual email addresses. It can be incrementally deployed by individual users and can provide incremental value through automated whitelisting. 1...|$|E
40|$|Abstract. Courseware {{validation}} should locate Learning Objects {{inconsistent with}} the courseware instructional design being used. In order for validation to take place {{it is necessary to}} identify the implicit and explicit information needed for validation. In this paper, we identify this information and formally define an information architecture to model courseware <b>validation</b> <b>information</b> explicitly. This promotes tool-support for courseware validation and its interoperability with the courseware specifications. ...|$|E
50|$|Advanced {{software}} development; cyber security; database engineering; enterprise architecture; independent <b>validation</b> and verification; <b>information</b> assurance; intelligence, surveillance, and reconnaissance; interoperability certification; missile {{research and}} development; modeling and simulation; requirements analysis; test and evaluation; threat assessment; training; weapon system design.|$|R
40|$|Climate {{change is}} a multi-faceted issue. It relies on deep {{scientific}} bases, but merges with politics, economics, ethics and culture in a complex and strongly nonlinear social debate. This interview focuses on the relationships between public communication on climate change (with emphasis on the so-called ‘new media’) and the decision making processes. It argues that more productive and sustainable forms of communication on climate change are needed due to problems related with <b>validation</b> of <b>information</b> in the Web...|$|R
40|$|AbstractMicroblogs like Twitter 1 are {{sources for}} a lot of useful {{information}}. But these information are unstructured. To automatically process it, these information have to be extracted with the help of natural language processing techniques. Corresponding systems for information extraction have to be trained and validated with manual annotated data. This paper presents an approach for the cooperative creation of annotated corpora for training and <b>validation</b> of <b>information</b> extraction systems supported by statistical analyses. 1 [URL]...|$|R
40|$|The CDC Picornavirus Laboratory from mid-September to mid-October {{developed}} and evaluated the EV-D 68 -specific rRT-PCR assay. The assay and protocol are primarily focused on evaluating respiratory disease due to EV-D 68. Some developmental and <b>validation</b> <b>information</b> {{can be found}} in Appendix B. The protocol that follows has worked reliably in our hands with little difficulty in any phase of the testing process, including interpretation of results...|$|E
40|$|Finding an {{antibody}} {{that works}} for a specific application can be a difficult task. Hundreds of vendors offer millions of antibodies, but the quality of these products and available <b>validation</b> <b>information</b> varies greatly. In addition, several studies have called into question the reliability of published data as the primary metric for assessing antibody quality. We briefly discuss the antibody quality problem and provide best practice guidelines for selecting and validating an antibody, {{as well as for}} publishing data generated using antibodies...|$|E
40|$|Researchers rarely provide solid {{performance}} and <b>validation</b> <b>information</b> about their acceleometer-based approaches to human gait analysis. We present here a novel signal {{processing and analysis}} algorithm that automatically extracts four consecutive fundamental events of walking: heel strike (HS), toe strike (TS), heel off (HO), and toe off (TO). In addition, we validate this accelerometer-based technique by comparing these extracted gait events with those obtained by a kinematic 3 D analysis system and a force plate, used as gold standards. Peer reviewe...|$|E
40|$|This paper compares six model {{checkers}} (Alloy, cadp, fdr 2, NuSMV, ProB, Spin) for the <b>validation</b> of <b>information</b> system specifications. The same {{case study}} (a library system) is specified using each model checker. Fifteen properties {{of various types}} are checked using temporal logics (CTL and LTL), first-order logic and failure-divergence (fdr 2). Three characteristics are evaluated: ease of specifying information system i) behavior, ii) properties, and iii) the number of IS entity instances that can be checked. The pape...|$|R
40|$|The {{scope of}} the EMMA D 1. 6. 1 _TSOD (Test Sites Operations Document for Prague-Ruzyne, Toulouse-Blagnac and Milan-Malpensa) is to provide readers with a global view of each Test-Site first and then both to {{describe}} the current way of operating at these three Airports and the new implementing Equipments and Operational Procedures that will be tested through the <b>Validation</b> Activities. <b>Information</b> contained in this document will {{be consistent with the}} EMMA Operational Requirements Document and to plan the V and V activities with SP 6...|$|R
50|$|The Spring Framework has {{received}} some criticism for what some developers {{perceive to be}} an over-reliance on XML by Spring's container. Since version 3.0.0, however, developers {{have been able to}} specify all or part of an application context through annotations or Java code. Spring Boot makes heavy use of this to minimize the amount of configuration that must be written. Furthermore, the Spring Tool Suite (STS), built on top of Eclipse, provides code-completion, <b>validation,</b> contextual <b>information,</b> and graphical visualizations when editing Spring XML configuration files.|$|R
40|$|Motivated by {{the recent}} diphoton excess {{reported}} by both the ATLAS and CMS collaborations, we provide a model-independent combination of diphoton results obtained at √(s) = 8 and 13 TeV at the LHC. We consider resonant s-channel production of a spin- 0 and spin- 2 particle with a mass of 750 GeV that subsequently decays to two photons. The size of the excess reported by ATLAS {{appears to be in}} slight tension with other measurements under the spin- 2 particle hypothesis. Comment: 14 pages, 6 figures, improved text, <b>validation</b> <b>information</b> added; to appear in EPJ...|$|E
40|$|The {{document}} provides <b>validation</b> <b>information</b> {{for software}} {{used to support}} TRU operational activities. Calculations were performed using a spreadsheet application. This document provides information about the usage of the software application, Microsoft{reg_sign} Excel. Microsoft{reg_sign} Excel spreadsheets were used to perform specific calculations to {{determine the amount of}} containers to visually examine and to perform analyses on container head-gas data. Contained in this document are definitions of formulas and variables with relation to the Excel codes used. Also, a demonstration is provided using predetermined values to obtain predetermined results...|$|E
40|$|Abstract –This paper {{introduces}} the experimental results of ship detection by both RADARSAT SAR imagery and landbased RADAR data, {{operated by the}} local Authority of South Korea, so called vessel traffic system (VTS) radar. Two fine imagery of Ulsan Port were acquired on June 19 and August 6, 2004 and are processed to detect ships automatically. The candidate target positions are compared with in-situ ship <b>validation</b> <b>information</b> collected field experiments. Our analysis for anchoring ships, above 62 m in length, with AIS indicates a 100 % ship detection rate for the RADARSAT single beam modes. Keywords: RADARSAT, SAR, Ship, VTS, Radar. 1...|$|E
40|$|The {{prevalence}} of respiratory symptoms and illnesses among 2225 schoolchildren in Hong Kong was studied by questionnaires administered independently {{to them and}} their parents. The agreement was generally poor for respiratory symptoms. The disparity shows the need for cross <b>validation</b> of clinical <b>information</b> in history taking. ...|$|R
40|$|Abstract. This paper compares six model {{checkers}} (Alloy, cadp, fdr 2, NuSMV, ProB, Spin) for the <b>validation</b> of <b>information</b> system specifications. The same {{case study}} (a library system) is specified using each model checker. Fifteen properties {{of various types}} are checked using temporal logics (CTL and LTL), first-order logic and failure-divergence (fdr 2). Three characteristics are evaluated: ease of specifying information system i) behavior, ii) properties, and iii) the number of IS entity instances that can be checked. The paper then identifies the most suitable features required to validate information systems using a model checker. ...|$|R
40|$|This {{study used}} the Department of Energy (DOE) Occurrence Reporting and Processing System (ORPS) data to {{investigate}} occurrences reported during one year at Los Alamos National Laboratory (LANL). ORPS provides a centralized database and computerized {{support for the}} collection, distribution, updating, analysis, and <b>validation</b> of <b>information</b> in occurrence reports about abnormal events related to facility operation. Human factors causes for occurrences are not always defined in ORPS. Content analysis of narrative data revealed that 33 % of all LANL 1994 adverse operational events have human factors causes related to procedures. Procedure-caused occurrences tha...|$|R
