141|116|Public
25|$|Drake's {{father was}} a World War II veteran and his mother a {{secretary}} for Pearl S. Buck. He entered the U.S. Air Force in 1979, becoming an Airborne <b>Voice</b> <b>Processing</b> Specialist, with a fluency in German, and went on ELINT (electronic intelligence) missions. It was in that capacity that he encountered the surveillance state of East Germany and the Stasi, which informed his worldview and to which he compares developments in the United States since the September 11 attacks. Drake left the Air Force in 1989. He {{was also in the}} U.S. Navy, where he analyzed intelligence for the National Military Joint Intelligence Center. According to the Washington Post, he also at one time worked with the CIA. In 1989 Drake began work as an NSA contractor, evaluating software. As a contractor, he worked on projects like JACKPOT and LIBRARIAN, becoming an expert in the quality-testing of software and working on a system for measuring the quality of computer code at the NSA. Drake also continued his academic studies.|$|E
5000|$|Berta González Frankenberger, Mexico {{speech and}} <b>voice</b> <b>processing</b> in {{neonates}} and premature babies ...|$|E
50|$|VPIM {{defines a}} subset of the Internet {{multimedia}} messaging protocols (MIME) for use between <b>voice</b> <b>processing</b> server platforms.|$|E
5000|$|Haiku, 1991 (ca 12’30’’) for <b>voice,</b> {{clarinet}} (EWI), <b>processing</b> {{and computer}} ...|$|R
5000|$|The Silverman (Phil Knight) - keyboards, filters, sound <b>processing,</b> <b>voices</b> {{from beyond}} ...|$|R
40|$|In this work, a new {{instantaneous}} {{fundamental frequency}} extraction method is presented, with the attention especially focused on its robustness for pathological <b>voices</b> <b>processing.</b> It {{is based on}} the Ensemble Empirical Mode Decomposition (EEMD) algorithm, which is a completely datadriven method for signal decomposition into a sum of AM- FM components, called Intrinsic Mode Functions (IMFs) or modes. Our results show that the speech fundamental frequency can be captured in a single IMF. We also propose an algorithm for selecting the mode where the fundamental frequency can be found, based on the logarithm {{of the power of the}} IMFs. The instantaneous frequency is then extracted by means of well-known techniques. The behaviour of the proposed method is compared with other two ones (Robust Algorithm for Pitch Tracking-RAPT- and auto-correlation based algorithms), both in normal and pathological sustained vowels. 1...|$|R
50|$|In November 2016 XMOS {{partnered with}} Sensory, Inc. to deliver TrulyHandsfree voice control {{technology}} on XMOS <b>voice</b> <b>processing</b> platforms.|$|E
5000|$|... xCORE {{devices have}} been used in a range of {{different}} markets, including <b>voice</b> <b>processing,</b> USB Audio, AVB and Time-Sensitive Networking, industrial communications, and robotics.|$|E
5000|$|... 2005 - The company {{acquired}} FERMA SA, {{a company}} founded in 1983 and {{a pioneer of}} <b>voice</b> <b>processing.</b> The acquisition was valued at €38 million.|$|E
40|$|Abstract. This paper {{describes}} {{the advantages of}} DSP TMS 320 VC 5402 in the voice coding communication and focuses on interface design of real-time <b>voice</b> signal <b>processing</b> {{as well as the}} hardware and software design of the system from the aspect of voice signal acquisition and processing. Besides, it also introduces the corresponding design principle of hardware and software...|$|R
50|$|Garcia {{delivered}} the 1.5 million GSIS members into the Digital Age by embarking on the ambitious eCard Plus System, the GSIS Wireless Automated Processing System (G-W@PS) and the GSIS <b>Voice</b> Activated <b>Processing</b> System (G-V@PS). These programs enabled GSIS members {{to enjoy their}} GSIS benefits and loan privileges anytime and anywhere—using automated, paperless, secure, and wireless systems.|$|R
50|$|Prior to his {{employment}} by the NSA, Pelton {{served in the}} United States Air Force. He was taught the Russian language by the Air Force and served {{for a time in}} the early 1960s in Peshawar, Pakistan as a <b>voice</b> intercept <b>processing</b> specialist. After that 15-month tour, he was transferred to National Security Agency, where he continued as a civilian employee upon discharge.|$|R
50|$|His {{career began}} {{developing}} companies for voice mail and <b>voice</b> <b>processing,</b> private pay phones, operator services, telecom reseller and VOIP, and {{prepaid telephone cards}} in the United States.|$|E
50|$|Host Media Processing or HMP is {{a design}} model in {{telecommunications}} systems {{that involves the}} use of software solutions to perform <b>voice</b> <b>processing</b> functions where dedicated Digital Signal Processors (DSP) were previously required.|$|E
50|$|The {{transcription}} machine {{is a special}} purpose machine which is used for word or <b>voice</b> <b>processing.</b> This special device manages audio video recording to transcribe them into written or hard copy form. So {{transcription machine}}s are combination of transcribers and dictation machines.|$|E
40|$|Combining {{wireless}} sensor {{networks and}} voice communication for multidata hybrid wireless network suggests possible applications in numerous fields. However, voice communication and sensor data transmissions have significant differences, Meanwhile, high-speed massive real-time <b>voice</b> data <b>processing</b> poses challenges for hardware design, protocol design, and especially power management. In this paper, we present a wireless audio sensor network platform A-LNT and study and discuss key elements for systematic design and implementation: node hardware design, low-power <b>voice</b> codec and <b>processing,</b> wireless network topology, hybrid MAC protocol design based on superframe, radio channel allocation, and clock synchronization. Furthermore, we discuss energy management methods such as address filtering and efficient power management in detail. The experimental and simulation results show that A-LNT is a lightweight, low-power, low-speed, and high-performance wireless sensor network platform for multichannel real-time voice communications...|$|R
30|$|Moreover, {{microphone}} arrays {{have become}} essential in many applications related to music or <b>voice</b> recording, <b>processing,</b> and transmission [6]. More specifically, microphones arrays are particularly useful {{in order to}} remove from the desired signal interference due for example to noise, reverberation or acoustic echoes. In fact, spatial filtering, in addition to temporal filtering, is very efficient because the sources of interferences are usually spatially located away from speaker in many environments.|$|R
40|$|International audienceThe {{experimental}} {{investigation of}} response inhibition and the neuropsychological assessment of impulsivity are classically conducted with Go/Nogo tasks, where the participant presses a key for standard (Go) stimuli and withholds the response for deviant (Nogo) ones. However, auditory Go/Nogo tasks frequently fail to elicit the typical ERP correlates of response inhibition (N 2, P 3). We elaborated an auditory Go/Nogo experiment with speech stimuli (VCV) and sufficient difficulty level (Go and Nogo stimuli differed by one phonetic feature only) to strongly involve response inhibition. An N 2 wave – the earlier correlate of inhibition – {{was recorded in}} 15 healthy adults. This result encourages the use of auditory Go/Nogo tasks to assess impulsivity, which results in decreased N 2 amplitude. Additionally, a substantial P 3 was observed as a secondary correlate of inhibition. Its amplitude was clearly modulated by the perceptual salience of the phonetic difference: P 3 was highest for manner of articulation, then voicing, and it was smallest for place differences. ERP indices of the right-hemisphere involvement in <b>voicing</b> <b>processing</b> are also reported. This auditory Go/Nogo task therefore appears useful as a clinical tool for impulsivity assessment and an experimental way to address phonetic issues...|$|R
50|$|The term became popularized after 2000 {{with the}} {{proliferation}} of voice over internet protocol technology in software DSP systems. Voice engines handle the <b>voice</b> <b>processing</b> for an IP Phone system on a standard processor, compared to prior generations of systems which required dedicated, math-optimized digital signal processor chips.|$|E
50|$|Microsemi {{has been}} {{producing}} various electronic products, including high-performance and radiation-hardened analog mixed-signal integrated circuits, FPGAs, SoCs and ASICs; power management products; timing and synchronization devices and precise time solutions, <b>voice</b> <b>processing</b> devices; RF solutions; discrete components; enterprise storage and communication solutions, security technologies and scalable anti-tamper products; Ethernet solutions; Power-over-Ethernet ICs.|$|E
50|$|AudioSmart {{software}} - Conexant develops AudioSmart software, {{audio and}} <b>voice</b> <b>processing</b> technologies for far-field voice communication and far-field speech control. Applications include speech recognition for smart home, smart phone, IoT, robotic and wearable devices, voice calls using social media apps, or Skype calling. Conexant's AudioSmart software {{is available on}} Windows, Android and Linux operating systems.|$|E
50|$|GIPS {{software}} was generally delivered as “engines” that packaged together <b>voice</b> and video <b>processing</b> components into optimized frameworks for smoother integration and better performance. GIPS’ customers are primarily service providers, application developers, and manufacturers of IP phones, gateways or voice and video conferencing systems.|$|R
50|$|As of 2006, {{the program}} has {{graduated}} about 60 PhD students in nearly all areas of speech and hearing research: auditory mechanics, peripheral and central auditory neuroscience, auditory psychophysics, hearing aids/cochlear implants, speech perception and production, machine processing of speech, language <b>processing,</b> <b>voice</b> disorders/laryngeal physiology, and vestibular physiology.|$|R
5000|$|LYRtech inc. (...) is {{a digital}} signal {{processing}} development company based in Quebec City, Quebec, Canada. Lyrtech designs and produces electronics systems for audio processing, video <b>processing,</b> networking, <b>voice</b> over IP <b>processing,</b> and wireless communications. Lyrtech also develops aerospace and military electronics for applications including geolocation, missile warning systems, and laser warning receivers.|$|R
5000|$|Philips Business Communications, Cambridge: offered {{voice and}} data {{communications}} products, specialising in Customer Relationship Management (CRM) applications, IP Telephony, data networking, <b>voice</b> <b>processing,</b> {{command and control}} systems and cordless and mobile telephony. In 2006 the business was placed into a 60/40 joint venture with NEC. NEC later acquired 100% ownership and the business was renamed NEC Unified Solutions.|$|E
50|$|The Company {{offers a}} broad range of {{products}} including Session Border Controllers (SBCs), Media Gateways, Multi-Service Business Routers (MSBRs), IP Phones, Residential Gateways, Media Servers, Value Added Applications and Professional Services. AudioCodes’ technology, VoIPerfectHD™, relies on the company’s experience in DSP, voice coding and <b>voice</b> <b>processing</b> technologies. AudioCodes’ High Definition (HD) VoIP technologies and products provide an improved voice communications experience.|$|E
50|$|In short, server {{provisioning}} configures servers {{based on}} resource requirements. The {{use of a}} hardware or software component (e.g. single/dual processor, RAM, HDD, RAID controller, a number of LAN cards, applications, OS, etc.) depends on the functionality of the server, such as ISP, virtualization, NOS, or <b>voice</b> <b>processing.</b> Server redundancy depends {{on the availability of}} servers in the organization. Critical applications have less downtime when using cluster servers, RAID, or a mirroring system.|$|E
30|$|Microphone arrays and {{beamforming}} techniques jointly play {{a relevant}} role in many applications related to music or <b>voice</b> recording, <b>processing,</b> and transmission [6]. Due to the spatial filtering capability, they allow removing annoying disturbances, like noise, reverberation, and acoustic echoes from the desired signal. Indeed, {{focusing on the}} echo cancelation problem, several beamforming based algorithmic architectures have been proposed in the literature so far [9, 10], also in the multichannel case study [11]. This study proposes a fixed beamforming algorithm to be included within the SAEC system, typically composed of the decorrelation block, the adaptive filters, and the double-talk detection module.|$|R
50|$|Conexant Systems, Inc. is an American-based {{software}} developer and fabless semiconductor company that provides products for <b>voice</b> and audio <b>processing,</b> imaging and modems. The company {{began as a}} division of Rockwell International, before being spun off as a public company. Conexant itself then spun off several business units, creating independent public companies which included Skyworks Solutions and Mindspeed Technologies.|$|R
5000|$|Among the {{key players}} in this area, Lucent played a big role and IBM {{acquired}} ROLM Inc, a US pioneer in ACDs, {{in an attempt to}} normalize all major PBX vendor interfaces with its CallPath middleware. This attempt failed when it sold this company to Siemens AG and gradually divested in the area. A pioneer startup that combined the technologies of voice digitization, Token Ring networking, and time-division multiplexing was ZTEL of Wilmington, Massachusetts. ZTEL's computer-based voice and data network combined user-programmable <b>voice</b> call <b>processing</b> features, protocol conversion for automated [...] "data call processing," [...] database-driven directory and telset definitions, and custom LSI chipset technology. ZTEL ceased operation in 1986.|$|R
5000|$|The {{challenge}} in <b>voice</b> <b>processing</b> {{is to remove}} background noise, remove the far-end signal, and enhance the near-end signal to just contain the voice. The far-end signal is typically msuic or speech reproduced through a speaker. The near-end signal is what is {{picked up by the}} microphones which is a mix of the voice signal, the far-end signal, and echoes of both. xCORE Voice products contain algorithms to perform, amongst others the following tasks: ...|$|E
50|$|SME is a {{term used}} in many {{cellular}} circles to describe a network entity (mobile/cell phone) that can send/receive messages. ESME (pronounced EZ-mee) is essentially one of these but without all the wireless aspects; i.e. it is connected via TCP/IP, X.25 or similar. On SMPP 3.4 protocol specifications ESME refers only to external sources and sinks of short messages as <b>Voice</b> <b>Processing</b> Systems, WAP Proxy Servers or Message Handling computers, and it specifically excludes SMEs which are located within the Mobile Network, i.e., a mobile station (MS).|$|E
50|$|In the {{following}} years, Parrot’s automotive business unit transitioned from aftermarket products {{for consumers to}} infotainment platforms and connectivity modules sold directly to car makers or to Tier-1 suppliers. Parrot’s technology revolve around connectivity, analog and digital radio, <b>voice</b> <b>processing</b> and recognition. Parrot’s head units provide entertainment features for the front and {{the rear of the}} vehicle, are mostly Android-based, and support Android Auto and Apple CarPlay. The Simple Box, introduced at CES 2016, enables the vehicle occupants to use their own tablets or smartphones as the main interface with their vehicles.|$|E
50|$|Working in more or {{less the}} same way, every digital {{synthesizer}} appears similar to a computer. At a steady sample rate, digital synthesis produces a stream of numbers. Sound from speakers is then produced by a conversion to analog form. Through signal generation, <b>voice</b> and instrument-level <b>processing,</b> a signal flow is created and controlled either by MIDI capabilities or voice and instrument-level controls.|$|R
50|$|Between {{the years}} of 1979-1981,Titze {{developed}} a new course entitled Principles of Voice Production, which was taught jointly in the School of Music. During the 1980s he developed various university courses that included acoustics, biomechanics of speech, experimental phonetics, digital signal <b>processing,</b> <b>voice</b> therapy and vocal pedagogy, all of which culminated in him coining the phrase 'vocology', which he then proposed as a discipline parallel to audiology.|$|R
40|$|Abstract. For {{the driver}} {{in the process of}} moving {{inconvenient}} to manually operated vehicle electronics, as well as the monopoly of foreign technology and other issues related, a framework based on DSP + MCU car speech recognition and control systems is designed. According to the embedded application environment, the corresponding recognition algorithm and the hardware architecture of DSP + MCU are chosen, in which DSP is mainly responsible for <b>voice</b> signal <b>processing</b> work, MCU is responsible for communicating with DSP and MCU to obtain recognition results after speech signal processing, as the final control instructions. The experimental results show that the hardware platform can run normally, and control the car body light on experimental bench...|$|R
