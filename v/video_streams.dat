2935|9273|Public
5|$|The rally was {{broadcast}} live on Comedy Central and C-SPAN. The Comedy Central live broadcast reportedly drew 2,000,000 total viewers, {{with an additional}} 570,000 live <b>video</b> <b>streams</b> on the Internet.|$|E
5|$|The {{technology}} company Akamai reported that 5,401,250web users logged on news sites {{in less than}} one minute, the fifth highest peak among news websites since the company started tracking data in 2005. During at-peak usage, news websites served seven million simultaneous <b>video</b> <b>streams,</b> which was {{the highest number of}} simultaneous <b>video</b> <b>streams</b> in Akamai's history. The Obama inaugural ceremony not only achieved the highest Internet viewership for a U.S.presidential inauguration, the inaugural event was the first to feature a live audio description of a swearing-in ceremony and the first to include closed captioning in the live webcast of the event.|$|E
5|$|In late 2011, Shadows Fall {{entered the}} studio to begin {{recording}} their seventh studio album. While in the studio, they held live <b>video</b> <b>streams</b> to discuss {{the progress of the}} album and answer questions from fans. This album is the first to be produced by Adam Dutkiewicz since the band's original studio release, Somber Eyes to the Sky. Fire From the Sky was released on May 15, 2012 through Razor & Tie.|$|E
40|$|In recent years, {{the demand}} for live <b>video</b> <b>streaming</b> has {{steadily}} increased. Unfortunately, current <b>video</b> <b>streaming</b> architectures embody a number of drawbacks, which impact the quality of live <b>video</b> <b>streaming</b> and place a heavy demand on the <b>video</b> <b>streaming</b> server. Client-server architectures engender issues of network congestion, server bottlenecks and load-balancing, often leading to poor quality video playback at the client and thus making them inappropriate for live <b>video</b> <b>streaming.</b> Moreover, most live <b>video</b> <b>streaming</b> systems offer only a single, fixed bit rate <b>video</b> <b>stream,</b> which is typically not appropriate for all clients. If this bit rate is too high, then some clients may not possess sufficient bandwidth to view the <b>video</b> <b>stream.</b> Conversely, if it is set too low, then all clients will receive a low quality <b>video</b> <b>stream,</b> even those whose bandwidth can support a higher standard. The aforementioned issues can be addressed using multiple bit rate <b>video</b> <b>streaming,</b> thereby allowing clients to download content at a rate appropriate for their bandwidth. This paper focuses on the utilization of a BitTorrent-based, Peer-to-Peer (P 2 P) architecture, which mitigates the load on the <b>video</b> <b>streaming</b> server whilst supporting multiple bit rate live <b>video</b> <b>streaming.</b> Using this architecture, each client is able to share {{the responsibility of the}} streaming server by providing part of the steamed video content to other clients. Simulations conducted indicate that the proposed architecture offers better performance than both: the client-server approach and current P 2 P-based live <b>video</b> <b>streaming</b> systems...|$|R
40|$|<b>Video</b> <b>streaming</b> {{technology}} enables <b>video</b> content, {{held on the}} web sites, to be streamed via the web. We {{report the}} implementation and evaluation of <b>video</b> <b>streaming</b> in an undergraduate nursing program in a metropolitan university in Australia. Students (n = 703) were emailed a survey with a 15 % response rate. We found that 91 % (n = 74) of respondents stated that <b>video</b> <b>streaming</b> assisted their learning. Forty-six percent(n = 50) of students had difficulty accessing <b>video</b> <b>streaming</b> (particularly {{at the beginning of}} the study period). Over a 97 -day period there were 8440 “hits” to the site from 1039 different internet protocol (IP) addresses. There were 4475 <b>video</b> <b>streaming</b> sessions undertaken by users. <b>Video</b> <b>streaming</b> was used for reviewing previously attended lectures (52 %, n = 56), examination preparation (34 %, n = 37), viewing missed lectures (27 %, n = 29) and class preparation (9 %, n = 10). Our experience with the introduction of <b>video</b> <b>streaming</b> has met with general enthusiasm from both students and teaching staff. <b>Video</b> <b>streaming</b> has particular relevance for rural students. <br /...|$|R
30|$|In short, FTP traffic {{consists}} of a stream of back-to-back packets similar to <b>video</b> <b>streaming</b> traffic with a difference {{that it has no}} ON-OFF cycle mechanism for transmission rate control {{as in the case of}} <b>video</b> <b>streaming,</b> but FTP traffic is asymmetric like <b>video</b> <b>streaming</b> traffic [3].|$|R
5|$|The single did {{not begin}} to sell {{significantly}} until February 2013, when a YouTube video set to its music developed into an Internet meme of the same name. The media response to the meme helped increase the single's sales, as it charted at number one for five consecutive weeks on the US Billboard Hot 100. It also reached number three in the United Kingdom and number one in both Australia and New Zealand. During the song's chart run, Billboard enacted a policy that included <b>video</b> <b>streams</b> {{as a component of}} their charts.|$|E
5|$|HDMI 2.0 {{increases}} the maximum TMDS clock to 600MHz (18.0Gbit/s). HDMI 2.0 uses 8b/10b encoding for video transmission like previous versions, {{giving it a}} maximum video bandwidth of 14.4Gbit/s. This enables HDMI 2.0 to carry 4K video at 60Hz with 24bit/px color depth. Other features of HDMI 2.0 include support for the Rec. 2020 color space, up to 32 audio channels, up to 1536kHz audio sample frequency, dual <b>video</b> <b>streams</b> to multiple users on the same screen, up to four audio streams, 4:2:0 chroma subsampling, 25 fps 3D formats, support for the 21:9 aspect ratio, dynamic synchronization of video and audio streams, the HE-AAC and DRA audio standards, improved 3D capability, and additional CEC functions.|$|E
5|$|The HDMI {{standard}} {{was not designed}} to pass closed caption data (for example, subtitles) to the television for decoding. As such, any closed caption stream must be decoded and included as an image in the <b>video</b> <b>stream(s)</b> prior to transmission over an HDMI cable to be viewed on the DTV. This limits the caption style (even for digital captions) to only that decoded at the source prior to HDMI transmission. This also prevents closed captions when transmission over HDMI is required for upconversion. For example, a DVD player that sends an upscaled 720p/1080i format via HDMI to an HDTV has no way to pass Closed Captioning data so that the HDTV can decode it, {{as there is no}} line 21 VBI in that format.|$|E
40|$|Abstract — The {{consistent}} superiority {{in terms}} of reduced packet loss to enhance video quality it is what this paper proposing. Prior investigation of <b>video</b> <b>streaming</b> over wireless networks has assumed a single access point and a homogeneous wireless technology. With different channel effects and conditions a long side the Hard Handover (HHO) consequences on mobile broadband <b>video</b> <b>streaming,</b> IEEE 802. 21, it is now becoming possible to offer seamless <b>video</b> <b>streaming</b> and harmonizing that influence. The paper presents a <b>video</b> <b>streaming</b> transport scheme that is more capable of exploiting the expected reduced latencies of real time <b>video</b> <b>streaming</b> content distribution networks. Broadband <b>Video</b> <b>Streaming</b> (BVS) with adaptive packet retransmission promises better video quality during an (HHO) than both raw UDP transport and traditional congestion-controlled streaming, making it attractive to mobile broadband <b>video</b> <b>streaming</b> services. It achieves this by distinguishing between high congestion and poor channel conditions, the latter of which an HHO induces, and by prioritized retransmission according to picture type...|$|R
40|$|<b>Video</b> <b>streaming</b> in MANETs is most Challenging {{issue and}} it mainly {{affected}} by these factors like node mobility, dynamic change in topology, multi path shadowing and fading, collusion, interference and many more. The dynamic change in topology causes periodic connectivity {{which results in}} large packet loss. <b>Video</b> <b>streaming</b> in real time requires special techniques that can overcome the losses of packets in the unreliable networks. Developments in mobile devices and wireless networking provide the technical platform for <b>video</b> <b>streaming</b> over mobile ad hoc networks (MANETs). And efforts to realize <b>video</b> <b>streaming</b> over MANETs have met many challenges, which are addressed by several different techniques. Here {{in this paper we}} have studied and reviewed many issues and different techniques present for <b>video</b> <b>streaming</b> over MANETs. This paper contain work done in the field of <b>video</b> <b>streaming</b> in MANETs and guide newcomers who are willing to work in <b>video</b> <b>streaming</b> in MANETs field. Keywords-Video streaming,MANETs, cross layer design, MDC, Multipath routing. I...|$|R
40|$|<b>Video</b> <b>streaming</b> is {{becoming}} increasingly popular among the wireless users. However, supporting <b>video</b> <b>streaming</b> over the wireless networks {{is not an easy}} task due to the dynamic radio propagation environment, limited radio resources as well as Quality of Service (QoS) requirements of the <b>video</b> <b>streaming</b> that need to be satisfied at acceptable levels. Most studies proposed to support <b>video</b> <b>streaming</b> are computationally expensive to be used in Orthogonal Frequency Division Multiple Access (OFDMA) based wireless IP networks. This paper evaluates <b>video</b> <b>streaming</b> performance under three well-known algorithms that are more practical {{to be used in the}} OFDMA based wireless IP networks due to their reduced complexity. It is demonstrated via computer simulation that Proportional Fair (PF) algorithm outperforms other well-known algorithms by providing <b>video</b> <b>streaming</b> QoS at acceptable levels whilst maximizing cell throughput...|$|R
5|$|Through Steamworks, Steam {{provides}} a means of server browsing for multiplayer games that use the Steam Community features, allowing users to create lobbies with friends or members of common groups. Steamworks also provides Valve Anti-Cheat (VAC), Valve's proprietary anti-cheat system; game servers automatically detect and report users who are using cheats in online, multiplayer games. In August 2012, Valve added new featuresincluding dedicated hub pages for games that highlight the best user-created content, top forum posts, and screenshotsto the Community area. In December 2012, a feature called Game Guides, where users can upload text and images detailing games and game strategies {{in the same manner}} as GameFAQs was added. Starting in beta in December 2014 and publicly released in January 2015, the Steam client allows players to broadcast <b>video</b> <b>streams</b> to the public or Steam friends while playing video games.|$|E
5|$|Prior to the {{initiation}} of the C-SPAN Video Library, websites such as Metavid and voterwatch.org hosted House and Senate video records, however C-SPAN contested Metavid's usage of C-SPAN copyrighted footage. The result was Metavid's removal of portions of the archive produced with C-SPAN's cameras, while preserving its archive of government-produced content. C-SPAN also engaged in actions to stop parties from making unauthorized uses of its content online, including its video of House and Senate proceedings. Most notably, in May 2006, C-SPAN requested the removal of Stephen Colbert's performance at the White House Correspondents' Association Dinner from YouTube. After concerns by some webloggers, C-SPAN gave permission for Google Video to host the full event. On March 7, 2007 C-SPAN liberalized its copyright policy for current, future, and past coverage of any official events sponsored by Congress and any federal agency and now allows for attributed non-commercial copying, sharing, and posting of C-SPAN video on the Internet, excluding re-syndication of live <b>video</b> <b>streams.</b> The new policy {{did not affect the}} public's right to use the public domain video coverage of the floor proceedings of the U.S. House and Senate.|$|E
5|$|In 2010, the Kinect was {{released}} by Microsoft as a 3D scanner/webcam hybrid peripheral device which provides full-body detection of Xbox 360 players and hands-free control of the user interfaces of video games and other software on the console. This was later modified by Oliver Kreylos of University of California, Davis {{in a series of}} YouTube videos which showed him combining the Kinect with a PC-based virtual camera. Because the Kinect is capable of detecting a full range of depth (through computer stereo vision and Structured light) within a captured scene, Kreylos demonstrated the capacity of the Kinect and the virtual camera to allow free-viewpoint navigation of the range of depth, although the camera could only allow a video capture of the scene as shown {{to the front of the}} Kinect, resulting in fields of black, empty space where the camera was unable to capture video within the field of depth. Later, Kreylos demonstrated a further elaboration on the modification by combining the <b>video</b> <b>streams</b> of two Kinects in order to further enhance the video capture within the view of the virtual camera. Kreylos' developments using the Kinect were covered among the works of others in the Kinect hacking and homebrew community in a New York Times article.|$|E
40|$|Compared {{with the}} {{traditional}} <b>video</b> <b>streaming</b> media system based on C/S mode, the <b>video</b> <b>streaming</b> media system based on P 2 P can efficiently solved the problems like single point of failure, high construction cost. Therefore, this study implemented a <b>video</b> <b>streaming</b> media system to provide the <b>video</b> <b>streaming</b> media service of high quality and large capacity. A mobile P 2 P <b>video</b> <b>streaming</b> media system architecture is firstly presented. Next, the design and implementation on the three modules, including server control program, client service program and client playing program, is introduced in detail. At last, the run results of each module as well are presented...|$|R
40|$|The {{future success}} of {{application}} layer video multicast {{depends on the}} availability of <b>video</b> <b>stream</b> distribution methods that can scale in the number of stream senders and receivers. Previous work on the problem of application layer <b>video</b> <b>streaming</b> has not effectively addressed scalability in the number of receivers and senders. Therefore, new solutions that are amenable to analysis and can achieve scalable P 2 P <b>video</b> <b>streaming</b> are needed. In this work we propose the use of automated negotiation algorithms to construct <b>video</b> <b>streaming</b> trees at the application layer. We show that automated negotiation can effectively solve the problem of distributing a <b>video</b> <b>stream</b> to a large number of receivers...|$|R
5000|$|Switching slices, called SP and SI slices, {{allowing}} an encoder {{to direct}} a decoder to jump into an ongoing <b>video</b> <b>stream</b> for such purposes as <b>video</b> <b>streaming</b> bit rate switching and [...] "trick mode" [...] operation. When a decoder jumps {{into the middle of}} a <b>video</b> <b>stream</b> using the SP/SI feature, it can get an exact match to the decoded pictures at that location in the <b>video</b> <b>stream</b> despite using different pictures, or no pictures at all, as references prior to the switch.|$|R
25|$|There is an {{expanded}} specification called SDTI (Serial Data Transport Interface), which allows compressed (i.e. DV, MPEG and others) <b>video</b> <b>streams</b> {{to be transported}} over an SDI line. This allows for multiple <b>video</b> <b>streams</b> in one cable or faster-than-realtime (2x, 4x,...) video transmission. A related standard, known as HD-SDTI, provides similar capability over an SMPTE 292M interface.|$|E
25|$|Linux {{currently}} has two modern kernel-userspace APIs for handing video input devices: V4L2 API for <b>video</b> <b>streams</b> and radio, and DVB API for digital TV reception.|$|E
25|$|As with {{previous}} optical disc formats, HD DVD supports several file systems, such as ISO 9660 and Universal Disk Format (UDF). All HD DVD titles use UDF version 2.5 as the file system. In this file system, multiplexed audio and <b>video</b> <b>streams</b> {{are stored in}} EVO container format.|$|E
40|$|International audienceVideo {{streaming}} is {{a growing}} application on the Internet, and its growing pace is not slowing down. There have been {{a tremendous amount of}} work on <b>video</b> <b>streaming</b> over the Internet but nobody has ever studied in detail <b>video</b> <b>streaming</b> over a nano-wireless network. We think that <b>video</b> <b>streaming</b> could be a potential application for nano-wireless networks and we know that <b>video</b> <b>streaming</b> is a challenging application for networks. First, <b>video</b> <b>streaming</b> is a real-time transmission meaning that it is sensitive to delay and jitter. Second, it is often better not to retransmit losses to avoid video freezing. That is why nano-wireless layers will probably have to be tuned for <b>video</b> <b>streaming.</b> This article studies, through simulation, different scenarios of video transmission over a nanowireless network. We conclude that research needs better tools and models for such studies...|$|R
2500|$|Controversy also exists whether utility {{user tax}} “modernization” {{measures}} permit {{local governments to}} impose taxes on online <b>video</b> <b>streaming</b> services. [...] With regard to previously approved “modernization” measures, voters may have unknowingly authorized the imposition of taxes on online <b>video</b> <b>streaming</b> services. [...] This places greater emphasis {{on the need for}} voters to carefully review the text of any tax “modernization” measure to determine whether taxes on online <b>video</b> <b>streaming</b> services would be authorized. [...] To the extent that previously approved tax “modernization” measures are interpreted to include taxes on online <b>video</b> <b>streaming</b> services, voters/taxpayers have an available legislative remedy using the local initiative power under Proposition 218 to reduce or repeal any tax on online <b>video</b> <b>streaming</b> services.|$|R
30|$|The use of {{different}} streaming strategies change the traffic characteristics of <b>video</b> <b>streaming</b> traffic {{to some extent}} but <b>video</b> <b>streaming</b> traffic consists of back-to-back packets sent over {{a considerable amount of}} time no matter which streaming strategy is used. <b>Video</b> <b>streaming</b> traffic is asymmetric meaning its traffic volume is much larger at the downlink than at the uplink [3].|$|R
25|$|The {{massacre}} also sparked many {{conversations in}} Japanese blogs {{when it was}} discovered that two Ustream users had broadcast live <b>video</b> <b>streams</b> of the tragedy, attracting a viewership estimated at between 1000 and 3000 people. No known recording has been saved of the videos, although the event has been written about in many Japanese blogs and online IT magazines.|$|E
25|$|To bypass DRM {{technologies}} {{embedded in}} video-streaming services, hackers employ {{a variety of}} methods. Besides rerecording and redistributing <b>video</b> <b>streams,</b> they place links to video-streaming services in web pages owned by the hackers, sell legitimate users' data {{on the black market}} for other people's use, and legitimate users sharing their account with family or friends who intend not to pay for the service.|$|E
25|$|Early in 2010, Hulu chief {{executive}} Jason Kilar said the service {{had made a}} profit in two quarters and that the company could top $100 million in revenue by summer 2010, more than its income for all of 2009. ComScore says monthly <b>video</b> <b>streams</b> reached 903 million in January 2010, over three times the figure for a year earlier, and second only to YouTube.|$|E
40|$|For {{several years}} we've {{witnessed}} an incredible growth in use of <b>video</b> <b>streaming</b> services. Recent network traffic studies and surveys show {{no signs of}} this process slowing down. There is growing need for <b>video</b> <b>streaming</b> systems in companies for video calling, security, home and public surveillance and much more. Therefore {{it is important to}} make a model of <b>video</b> <b>streaming</b> system and find out what transfer protocols, codecs suits better and what such system is capable of. Purpose of this work is to develop and research <b>video</b> <b>streaming</b> system model. Analyze, try and test specific characteristics in a pursuit of perfect transmission conditions. Work includes various transmission channels, protocols and algorithms, which might be used in the <b>video</b> <b>streaming</b> system. Trying find out which technology and with what parameters enables face recognition or only movement spotting, using which transmission technology <b>video</b> <b>stream</b> viewing is available while moving and only stationary...|$|R
40|$|The {{invention}} {{relates to}} {{a method of}} detecting manipulations of digital <b>video</b> <b>stream</b> data, wherein the <b>video</b> <b>stream</b> data represents a sequence (17) of video images comprising at least one moving object that moves relatively to other objects and/or relatively to a background scenery and wherein the method comprises: a) detecting {{the at least one}} moving object from the <b>video</b> <b>stream</b> data, b) identifying (19) a kinematic model (21) which describes the movement of the moving object, c) determining (23) deviations of the movement which is performed by the moving object according to the <b>video</b> <b>stream</b> data and of a modelled movement which should have been performed by the moving object according to the kinematic model (21), d) deciding (25) if the deviations indicate a manipulation of the <b>video</b> <b>stream</b> data. In particular, the sequence (17) of video images may be obtained by decompressing (15) compressed <b>video</b> <b>stream</b> data...|$|R
30|$|In this article, {{we propose}} an {{architecture}} and implementation approach for cross-layer adaptive <b>video</b> <b>streaming</b> required for ubiquitous <b>video</b> <b>stream</b> delivery. Our solution {{relies on the}} SVC technology for implementing wireless bandwidth-adaptive <b>video</b> <b>streaming</b> services without adding any extra redundancy to the streaming. We present an end-to-end architecture for scalable video transmission enhanced with different cross-layer signaling and adaptation capabilities. Our solution {{is based on the}} OPTIMIX system architecture [10], which supports novel controlling modules for cross-layer optimization as well as a signaling framework for transmitting timely cross-layer context information within the <b>video</b> <b>streaming</b> system.|$|R
25|$|An RTP {{session is}} {{established}} for each multimedia stream. A session {{consists of an}} IP address {{with a pair of}} ports for RTP and RTCP. For example, audio and <b>video</b> <b>streams</b> use separate RTP sessions, enabling a receiver to deselect a particular stream. The ports which form a session are negotiated using other protocols such as RTSP (using SDP in the setup method) and SIP.|$|E
25|$|Windows Vista {{includes}} a specialized QoS API called qWave (Quality Windows Audio/Video Experience), {{which is a}} pre-configured Quality of Service module for time dependent multimedia data, such as audio or <b>video</b> <b>streams.</b> qWave uses different packet priority schemes for real-time flows (such as multimedia packets) and best-effort flows (such as file downloads or e-mails) to ensure that real time data gets as little delays as possible, while providing a high quality channel for other data packets.|$|E
25|$|DirectShow 6.0, {{released}} {{as part of}} DirectX Media introduced the Overlay Mixer renderer designed for DVD playback and broadcast <b>video</b> <b>streams</b> with closed captioning and subtitles. The Overlay Mixer uses DirectDraw 5 for rendering. Downstream connection with the Video Renderer is required for window management. Overlay Mixer also supports Video Port Extensions (VPE), enabling it to work with analog TV tuners with overlay capability (sending video directly to a video card via an analog link rather than via the PCI bus). Overlay Mixer also supports DXVA connections. Because it always renders in overlay, full-screen video to TV-out is always activated.|$|E
40|$|<b>Video</b> <b>streaming</b> {{has become}} a popular form of {{transferring}} video over the Internet. With the emergence of mobile computing needs, a successful <b>video</b> <b>streaming</b> solution demands 1) uninterrupted services even {{with the presence of}} mobility and 2) adaptive video delivery according to current link properties. In this paper we study the need and evaluate the performance of adaptive <b>video</b> <b>streaming</b> in vertical handoff scenarios. We use Universal Seamless Handoff Architecture (USHA) to create a seamless handoff environment, and use the Video Transfer Protocol (VTP) to adapt <b>video</b> <b>streaming</b> rates according to "Eligible Rate Estimates". Using testbed measurements experiments, we verify the importance of service adaptation, as well as show the improvement of user-perceived video quality, via adapting <b>video</b> <b>streaming</b> in the vertical handoffs...|$|R
40|$|<b>Video</b> <b>streaming</b> over lossy IP {{networks}} is {{very important}} issues, due to the heterogeneous structure of networks. Infrastructure of the Internet exhibits variable bandwidths, delays, congestions and time-varying packet losses. Because of variable attributes of the Internet, <b>video</b> <b>streaming</b> applications should not only have a good end-to-end transport performance but also have a robust rate control, furthermore multipath rate allocation mechanism. So for providing the <b>video</b> <b>streaming</b> service quality, some other components such as Bandwidth Estimation and Adaptive Rate Controller {{should be taken into}} consideration. This paper gives an overview of <b>video</b> <b>streaming</b> concept and bandwidth estimation tools and then introduces special architectures for bandwidth adaptive <b>video</b> <b>streaming.</b> A bandwidth estimation algorithm – pathChirp, Optimized Rate Controllers and Multipath Rate Allocation Algorithm are considered as all-in-one solution for <b>video</b> <b>streaming</b> problem. This solution is directed and optimized by a decision center which is designed for obtaining the maximum quality at the receiving side...|$|R
50|$|<b>Video</b> <b>Streaming</b> Service/Site {{aggregators}} are {{services that}} scan across multiple <b>video</b> <b>streaming</b> sites {{to make it}} easier to find Movies and/or TV shows and where they are available to stream.|$|R
