265|323|Public
5|$|A <b>vector</b> <b>processor</b> is a CPU or {{computer}} {{system that can}} execute the same instruction on large sets of data. Vector processors have high-level operations that work on linear arrays of numbers or vectors. An example vector operation is A = B × C, where A, B, and C are each 64-element vectors of 64-bit floating-point numbers. They {{are closely related to}} Flynn's SIMD classification.|$|E
25|$|The SIMD <b>vector</b> <b>processor</b> (VMX128) was {{modified}} for the Xbox {{to include a}} dot-product instruction. The dot-product instruction took far less latency than discrete instructions. The VMX128 was also modified {{by the addition of}} direct 3D (D3D) compressed data format. This led to an approximate 50 percent savings in required band-width and memory footprint making the CPU having a theoretical peak performance of 115.2GFLOPS, being capable of 9.6 billion dot products per second. Each core of the CPU was capable of simultaneous multithreading and was clocked at 3.2GHz. However, to reduce CPU die size, complexity, cost, and power demands, the processor used in-order execution in contrast to the Intel Coppermine 128-based Pentium III used in the original Xbox, which used more complex out of order execution. The original chip used a 90nm process, although a newer 65nm process SOI revision was implemented on later models, which was in-turn superseded by a 45nm combined CPU and GPU chip. A 21.6GB/s front side bus, aggregated 10.8GB/s upstream and downstream, connected Xenon with the graphics processor/northbridge. Xenon was equipped with an 8th way set associative 1MB Level 2 cache on-die running at half CPU clock speed. This cache was shared amongst the three CPU cores. Each core had separate L1 caches, each containing a two-way set associative 32-Kbyte L1 instruction cache and a four-way set associative 32-Kbyte L1 data cache. The write-through data cache did not allocate cache lines on writes. The CPU also contained ROM storing Microsoft private encrypted keys, used to decrypt game data. The heat sink implemented to cool the Xenon CPU was composed of aluminum fins with a copper base, and a heat pipe. Newer revisions, which had a smaller core, do not feature the heat pipe or copper base. The heat sink was cooled by two 70mm fans {{at the rear of the}} console on original-style consoles, while a single fan mounted on the side of the consoles was used in Xbox 360 S consoles. There were several types of fan used in Xbox 360s, which were produced by Nidec, Sunon and Delta Electronics.|$|E
2500|$|Programs {{that create}} {{vectorized}} functions for programs in higher-level languages such as C. [...] In the higher-level language this is sometimes aided by compiler intrinsic functions which map directly to SIMD mnemonics, but nevertheless {{result in a}} one-to-one assembly conversion specific for the given <b>vector</b> <b>processor.</b>|$|E
25|$|In the 1960s {{pipelining}} {{was viewed}} as an innovation, and by the 1970s the use of <b>vector</b> <b>processors</b> had been well established. By the 1980s, many supercomputers used parallel <b>vector</b> <b>processors.</b>|$|R
40|$|Despite their {{superior}} {{performance for}} multimedia applications, <b>vector</b> <b>processors</b> have three limitations that hinder their widespread acceptance. First, {{the complexity and}} size of the centralized vector register file limits the number of functional units. Second, precise exceptions for vector instructions are difficult to implement. Third, <b>vector</b> <b>processors</b> require an expensive on-chip memory system that supports high bandwidth at low access latency...|$|R
40|$|<b>Vector</b> <b>processors</b> {{are a very}} {{promising}} solution for mobile devices and servers due to their inherently energy-efficient way of exploiting data-level parallelism. Previous research on vector architectures predominantly focused on performance, so <b>vector</b> <b>processors</b> require a new design space exploration to achieve low power. In this paper, we present a design space exploration of adder unit for <b>vector</b> <b>processors</b> (VA), as {{it is one of}} the crucial components in the core design with a non-negligible impact in overall performance and power. For this interrelated circuit-architecture exploration, we developed a novel framework with both architectural- and circuit-level tools. Our framework includes both design- (e. g. adder's family type) and vector architecture-related parameters (e. g. vector length). Finally, we present guidelines on the selection of the most appropriate VA for different types of <b>vector</b> <b>processors</b> according to different sets of metrics of interest. For example, we found that 2 -lane configurations are more EDP (Energy×Delay) -efficient than single lane configurations for low-end mobile processors. Peer ReviewedPostprint (published version...|$|R
2500|$|In {{the early}} days, DSPs (such as the AT DSP32C) {{have been used}} as neural network accelerators e.g. to {{accelerate}} OCR software, and there have been attempts to create parallel high throughput systems for workstations (e.g. TetraSpert in the 1990s, which was a parallel fixed-point <b>vector</b> <b>processor),</b> aimed at various applications including neural network simulations. FPGA-based accelerators were also first explored in the 1990s for both inference and training. [...] ANNA was a neural net CMOS accelerator developed by Yann LeCun.|$|E
2500|$|The {{technology}} {{behind the}} game relied heavily upon {{the use of}} a <b>vector</b> <b>processor</b> in the PlayStation 2 called Vector-unit Zero (VU0). According to Gratton, [...] "a large chunk of this game is written in hand coded assembly language on the vector units. It's a miracle of technology!" [...] He also explained that because the CPUs of both the Xbox and GameCube are so adept, although the game was developed on PlayStation 2 technology, it transferred straight across to the other consoles. Gratton was also keen to point out that no middleware was used at any point during the production of the game, and that the technological innovations were all based upon gameplay decisions; not simply to be innovative for innovation's sake.|$|E
2500|$|In 2008, IBM {{announced}} a revised {{variant of the}} Cell called the PowerXCell 8i, which is available in QS22 Blade Servers from IBM. The PowerXCell is manufactured on a 65nm process, and adds support for up to 32GB of slotted DDR2 memory, as well as dramatically improving double-precision floating-point performance on the SPEs {{from a peak of}} about 12.8GFLOPS to 102.4GFLOPS total for eight SPEs, which, coincidentally, is the same peak performance as the NEC SX-9 <b>vector</b> <b>processor</b> released around the same time. The IBM Roadrunner supercomputer, the world's fastest during 2008-2009, consists of 12,240 PowerXCell 8i processors, along with 6,562 AMD Opteron processors. The PowerXCell 8i powered super computers also dominated all of the top 6 [...] "greenest" [...] systems in the Green500 list, with highest MFLOPS/Watt ratio supercomputers in the world. Beside the QS22 and supercomputers, the PowerXCell processor is also available as an accelerator on a PCI Express card and is used as the core processor in the QPACE project.|$|E
5000|$|Choose the {{weighting}} factor for each processor: 0.9 for <b>vector</b> <b>processors</b> and 0.3 for non-vector processors. This is W(i).|$|R
50|$|The company {{applied for}} patents, {{encompassing}} parallel execution queries on multi-core processors and speeding up parallel execution on <b>vector</b> <b>processors.</b>|$|R
5000|$|... 48 vector units floating-point <b>vector</b> <b>processors</b> for shader execution, {{divided in}} three {{dynamically}} scheduled SIMD groups of 16 processors each.|$|R
50|$|The VAX 9000's CPU was {{coupled with}} a <b>vector</b> <b>processor</b> with a maximum {{theoretical}} performance of 125 MFLOPS. The <b>vector</b> <b>processor</b> circuitry was present in all units shipped and disabled via a software switch on units sold 'without' the <b>vector</b> <b>processor.</b> The <b>vector</b> <b>processor</b> {{was referred to as}} the V-box, and it was Digital's first ECL implementation of the VAX Vector Architecture. The design of the <b>vector</b> <b>processor</b> began in 1986, two years after development of the VAX 9000 CPU had begun.|$|E
5000|$|But to a <b>vector</b> <b>processor,</b> {{this task}} looks {{considerably}} different: ...|$|E
50|$|SIMD engines: <b>vector</b> <b>processor,</b> array processor, {{digital signal}} processor, stream processor.|$|E
50|$|Manycore {{processors}} {{may have}} more in common (conceptually) with technologies originating in high performance computing such as clusters and <b>vector</b> <b>processors.</b>|$|R
50|$|The {{earliest}} {{example of}} a load/store architecture was the CDC 6600. Almost all <b>vector</b> <b>processors</b> (including many GPUs) use the load/store approach.|$|R
50|$|Recent {{experimental}} <b>vector</b> <b>processors</b> with variable-width data paths {{also show}} profitable increases in operations per: second (speed), area (lower cost), and watt (longer battery life).|$|R
5000|$|... 10 FP ops per <b>vector</b> <b>processor</b> per cycle (5 fused multiply-add) ...|$|E
50|$|NEC's SX-9 {{supercomputer}} was the world's first <b>vector</b> <b>processor</b> {{to exceed}} 100 gigaFLOPS per single core.|$|E
50|$|The Fujitsu FR-V (Fujitsu RISC-VLIW) {{is one of}} {{the very}} few {{processors}} ever able to process both a very long instruction word (VLIW) and <b>vector</b> <b>processor</b> instructions at the same time, increasing throughput with high parallel computing while increasing performance per watt and hardware efficiency. The family was presented in 1999. Its design was influenced by the VPP500/5000 models of the Fujitsu VP/2000 <b>vector</b> <b>processor</b> supercomputer line.|$|E
40|$|We {{consider}} {{pseudo-random number}} generators suitable for <b>vector</b> <b>processors.</b> In particular, we describe vectorised implementations of the Box-Muller and Polar methods, {{and show that}} they give good performance on the Fujitsu VP 2200. We also consider some other popular methods, e. g. the Ratio method of Kinderman and Monahan (1977) (as improved by Leva (1992)), and the method of Von Neumann and Forsythe, and show why {{they are unlikely to}} be competitive with the Polar method on <b>vector</b> <b>processors.</b> Comment: An old Technical Report, not published elsewhere. 6 pages. For details see [URL]...|$|R
50|$|Modern GPUs {{include an}} array of shader {{pipelines}} which may be driven by compute kernels, which can be considered <b>vector</b> <b>processors</b> (using a similar strategy for hiding memory latencies).|$|R
40|$|This note {{describes}} a performance {{evaluation of a}} workstation based on the Silicon Graphics R 8000 microprocessor running at 75 MHz. The evaluation {{is based on a}} variety of Fortran 77 benchmark codes that have a range of computational characteristics and that represent Los Alamos National Laboratory applications. Benchmark data from the R 8000 system are compared with those from an IBM RISC System/ 6000 - 590 and with two older Cray Research <b>vector</b> <b>processors.</b> Only single-processor results are considered. The results of the study echo that of previous microprocessor/vector processor comparisons: for non-vectorizable problems microprocessors can run at favorable speeds relative to the <b>vector</b> <b>processors</b> (although on these codes the RS/ 6000 is generally faster than the R 8000). However, because of relatively poor data cache reuse, on vectorizable codes the <b>vector</b> <b>processors</b> still maintain a significant advantage over the microprocessors. The R 8000 's large secondary data cache does provide an imp [...] ...|$|R
5000|$|The VAX 9000 Model 4x0 was a {{multiprocessor}} capable model, {{the value}} of [...] "x" [...] (1, 2, 3 or 4) denoting the number of CPUs present. These models supported the <b>vector</b> <b>processor,</b> with one <b>vector</b> <b>processor</b> supported per CPU. A maximal configuration had 512 MB of memory. The number of I/O buses supported varied, with the Model 410 and 420 supporting two XMI, ten CI and eight VAXBI; while the Model 430 and 440 supported four XMI, ten CI and 14 VAXBI.|$|E
50|$|Several POWER5 {{processors}} in high-end {{systems can}} be coupled together {{to act as a}} single <b>vector</b> <b>processor</b> by a technology called ViVA (Virtual Vector Architecture).|$|E
50|$|Under SGI ownership, one new Cray model line, the SV1, was {{launched}} in 1998. This was a clustered SMP <b>vector</b> <b>processor</b> architecture, developed from J90 technology.|$|E
50|$|In 2004, the Earth Simulator {{supercomputer}} {{built by}} NEC at the Japan Agency for Marine-Earth Science and Technology (JAMSTEC) reached 35.9 teraflops, using 640 nodes, each with eight proprietary <b>vector</b> <b>processors.</b>|$|R
5000|$|Maximum vertex count: 1.21 Billion {{vertices}} {{per second}} (48 shader <b>vector</b> <b>processors</b> × 2 ops per cycle × 500 MHz) / 8 vector ops per vertex) for simple transformed and lit polygons ...|$|R
50|$|The late 1980s {{and early}} 1990s saw the {{introduction}} of vector architectures, such as the Cray Y-MP/4 and Nippon Electric Corporation SX-3 that supported 4-10 <b>vector</b> <b>processors</b> with a shared memory (see NEC SX architecture).|$|R
50|$|<b>Vector</b> <b>processor</b> (single instruction, {{multiple}} data (SIMD)) cores can {{be combined}} with the VLIW architecture {{such as in the}} Fujitsu FR-V microprocessor, further increasing throughput and speed.|$|E
50|$|In addition, two further devices {{implemented}} the VAX <b>vector</b> <b>processor</b> option; these comprised the DC555 Vector Register set chip (VERSE) and the DC556 Vector Data Path chip (FAVOR).|$|E
50|$|Perhaps {{the most}} {{influential}} implementations of computational RAM came from The Berkeley IRAM Project. Vector IRAM (V-IRAM) combines DRAM with a <b>vector</b> <b>processor</b> integrated on the same chip.|$|E
50|$|The peak {{performance}} of the SX-6 series <b>vector</b> <b>processors</b> is 8 GFLOPS. Thus a single-node system provides a {{peak performance}} of 64 GFLOPS, while a multi-node system provides up to 8 TFLOPS of peak floating-point performance.|$|R
40|$|This paper {{presents}} a vectorized algorithm for entering data into a hash table. A program that enters multiple data {{could not be}} executed on <b>vector</b> <b>processors</b> by conventional vectorization techniques because of data dependences. Our method enables execution of multiple data entry by conventional <b>vector</b> <b>processors</b> and improves the performance {{by a factor of}} 12. 7 when entering 4099 pieces of data on the Hitachi S- 810, compared to the normal sequential method. This method is applied to the address calculation sorting and the distribution counting sort, whose main part was unvectorizable by previous techniques. It improves performance by a factor of 12. 8 when n = 2 14 on the S- 810. 1...|$|R
50|$|The VP2000 was {{the second}} series of vector {{supercomputers}} from Fujitsu. Announced in December 1988, they replaced Fujitsu's earlier FACOM VP Model E Series. The VP2000 was succeeded in 1995 by the VPP300, a massively parallel supercomputer with up to 256 <b>vector</b> <b>processors.</b>|$|R
