919|891|Public
5|$|Drache {{was also}} used for {{shipboard}} trials with the Flettner Fl 282 Kolibri (Hummingbird) helicopter. She embarked the V6 and V10 prototypes for a period in 1942 and in January–February 1943. They used the small platform abaft the funnel to take-off and land. The Kriegsmarine (German navy) wished to evaluate their potential for anti-submarine warfare and mine reconnaissance, but <b>visual</b> <b>detection</b> proved to be possible only in clear weather.|$|E
5|$|The {{gameplay}} of Snake Eater {{is similar}} to that of previous games in the Metal Gear Solid series. Snake, controlled by the player, must move undetected through a hostile, enemy-filled environment. Although Snake acquires various weapons (ranging from handguns to rocket propelled grenades), the emphasis is on using stealth to avoid confrontations. A number of objects and gadgets can be found along the way to aid in this, including motion detectors to track hostile soldiers, and the Metal Gear series' trademark cardboard box, which Snake can hide under to avoid <b>visual</b> <b>detection.</b>|$|E
25|$|Adult {{individuals}} {{often have}} hairy antenna-like tails complete {{with black and}} white annulated (ringed) appearance. Many species also have a spot {{at the base of}} the tail and some turn around upon landing to confuse potential predators from recognizing the true head orientation. This causes predators to approach from the true head end resulting in early <b>visual</b> <b>detection.</b>|$|E
40|$|Dugong {{calls were}} {{collected}} using a towed stereo hydrophone system around Talibong Island and Muk Island in Thailand in January 2008. Standard visual observation was conducted simultaneously {{to record the}} dugong distribution. A total of 223 dugong calls and 80 dugongs were detected. Spatial distributions of both of the acoustical and <b>visual</b> <b>detections</b> were analyzed using Iδ-index. The spatial distribution of the <b>visual</b> <b>detections</b> showed almost uniform distribution {{and that of the}} acoustical observations showed concentrated distribution (Iδ= 0. 85 and 3. 18, respectively). The number of snapping noises per minute was less in the areas where dugong calls were observed (P < 0. 001). It was suggested that dugongs vocalized selectively in less noisy areas...|$|R
40|$|Several {{studies have}} {{assessed}} <b>visual</b> contrast <b>detection</b> {{in patients with}} schizophrenia, but the findings among these studies have not been consistent with each other. Some studies have reported higher <b>visual</b> contrast <b>detection</b> thresholds in patients than in nonpsychiatric comparison subjects (1 – 4), and another study found that schizophrenic patients {{did not differ in}} <b>visual</b> contrast <b>detection</b> from comparison subjects (5). In a preliminary report, Kéri and colleagues (6) noted that <b>visual</b> contrast <b>detection</b> thresholds were significantly lower in schizophrenic patients than in nonpsychiatric comparison subjects. The explanation for these disparate results may reside in the type of antipsychotic drugs the patients were receiving. Most of the patients included in the studies that reported poor performance were receiving depot antipsychoti...|$|R
5000|$|Hoov, a {{team member}} specializing in {{communications}} and audio <b>visual</b> forgery <b>detection.</b>|$|R
25|$|Visual {{extinction}} {{has also}} been researched {{with regard to the}} effect of repetition on <b>visual</b> <b>detection</b> rate. Patients were shown a colored (red or green) letter (O or E), one to each visual field, and then asked variably to report the color or shape of one letter or the other. Extinction was found to be increased in the contralesional field when the patient was asked to report on a repeated characteristic – if both stimuli had been the same shape, or same color – regardless of whether the other characteristic had also been changed. This is another example of repetition blindness.|$|E
25|$|Pure {{methanol}} {{has been}} used in open wheel auto racing since the mid-1960s. Unlike petroleum fires, methanol fires can be extinguished with plain water. A methanol-based fire burns invisibly, unlike gasoline, which burns with a visible flame. If a fire occurs on the track, there is no flame or smoke to obstruct the view of fast approaching drivers, but this can also delay <b>visual</b> <b>detection</b> of the fire and the initiation of fire suppression. The decision to permanently switch to methanol in American IndyCar racing was a result of the devastating crash and explosion at the 1964 Indianapolis 500, which killed drivers Eddie Sachs and Dave MacDonald. In 2007 IndyCars switched from methanol to ethanol.|$|E
25|$|On August 4, 1968, a Convair CV-580, flying as North Central Airlines flight 261, {{collided}} {{in mid-air}} with a privately owned Cessna 150. The Cessna cabin remained {{attached to the}} Convair's forward baggage compartment. The Convair made a safe emergency landing at Milwaukee. The three Cessna occupants were killed. The Cessna was on a VFR flight from Lombard, Illinois to Sheboygan County Memorial Airport in Sheboygan Falls. It was determined that {{the inability of the}} Convair 580 flight crew to detect the Cessna 150 visually in sufficient time to take evasive action, despite having been provided with three radar traffic advisories, caused the crash. <b>Visual</b> <b>detection</b> capabilities were reduced by the heavy accumulation of insect smears on the windows of the Convair. Visibility was further reduced by haze, smoke and sunglare, and by the inconspicuous colour and lack of relative motion of the Cessna.|$|E
40|$|International audienceThis paper {{presents}} a visual-based media event detection {{system based on}} the automatic discovery of the most circulated images across the main news media (news websites, press agencies, TV news and newspapers). Its main originality is {{to rely on the}} transmedia contextual information to denoise the raw <b>visual</b> <b>detections</b> and consequently focus on the most salient transmedia events...|$|R
40|$|Our group {{within the}} University of Amsterdam {{participated in the}} {{large-scale}} <b>visual</b> concept <b>detection</b> task of ImageCLEF 2010. The submissions from our <b>visual</b> concept <b>detection</b> system {{have resulted in the}} best visual-only run in the per-concept evaluation. In the per-image evaluation, it achieves the highest score in terms of example-based F-measure across all types of runs...|$|R
40|$|This paper {{presents}} a visual-based media event detection {{system based on}} the automatic discovery of the most cir-culated images across the main news media (news websites, press agencies, TV news and newspapers). Its main origi-nality is {{to rely on the}} transmedia contextual information to denoise the raw <b>visual</b> <b>detections</b> and consequently focus on the most salient transmedia events...|$|R
2500|$|Psychotic-like symptoms, such as {{hallucinations}} {{and unusual}} perceptual experience, involve gross alterations {{in the experience}} of reality. Normal perception is substantially constructive and what we perceive [...] is strongly influenced by our prior experiences and expectancies. [...] Healthy individuals prone to hallucinations, or scoring highly on psychometric measures of positive schizotypy, [...] tend to show a bias toward reporting stimuli that did not occur under perceptually ambiguous experimental conditions. [...] During <b>visual</b> <b>detection</b> of fast-moving words, undergraduate students scoring highly on positive schizotypy had significantly high rates of false perceptions of words (i.e. reported seeing words that {{were not included in the}} experimental trials). [...] Positive schizotypal symptoms in healthy adults seem to predict false perceptions in laboratory tasks and certain environmental parameters such as perceptual load and frequency of visual targets [...] are critical in the [...] generation of false perceptions. When detection of events becomes either effortless or cognitively demanding, generation of such biases can be prevented.|$|E
2500|$|Within the Harry Potter universe, an invisibility cloak {{is used to}} {{make the}} wearer invisible. All are very rare and expensive, and may be spun from pelts of the Demiguise, magical herbivores that are found in the Far East. They can also be {{ordinary}} cloaks with a Disillusionment Charm or a Bedazzlement Hex placed on them. Over time, these cloaks will lose their invisibility ability, eventually becoming opaque and vulnerable to penetration by various spells. Harry's cloak, being one of the three Deathly Hallows, is a true cloak of invisibility, and will retain its invisibility forever. It is also resistant to most simple spells and charms (e.g. the summoning charm). Invisibility cloaks protect the wearer from <b>visual</b> <b>detection</b> only, meaning that even though the wearer cannot be seen they are still solid, and can therefore be felt by physical contact. Alastor Moody's magically charmed eye is able to penetrate them. The cloak is less effective against some animals, such as cats (e.g. Mrs. Norris) and snakes (e.g. Nagini). The Dementors in the books have no sense of sight and instead sense human despair, a sense unhindered by the use of an invisibility cloak. In addition to Harry's cloak, Moody is known to possess two. One of these was borrowed by Sturgis Podmore in the course of work for the Order of the Phoenix. Barty Crouch, Sr. possessed one as well, which he used to hide his son Barty Crouch, Jr. to prevent him from going to Azkaban, the wizarding prison. Several times in the series, characters have been shown to either suspect or in some other fashion [...] "sense" [...] that Harry is wearing his cloak: Snape is seen to be suspicious when being followed by Harry, even reaching out to grab at (what appears to be) thin air; in Half-Blood Prince, Draco Malfoy realises Harry is in his train carriage and successfully immobilizes him with a Petrificus Totalus (Body-Bind) curse, as despite wearing his cloak Harry inadvertently moved objects near him; and in Chamber of Secrets, Albus Dumbledore senses Harry and Ron beneath it in Hagrid's cabin while talking to Lucius Malfoy during the event when Cornelius Fudge comes to take Hagrid to Azkaban and Lucius Malfoy hands over to Dumbledore his suspension letter.|$|E
5000|$|CRL - {{a system}} to {{suppress}} contrails to reduce <b>visual</b> <b>detection</b> ...|$|E
25|$|Pashler, H. (1988). Familiarity and <b>visual</b> change <b>detection.</b> Perception & Psychophysics, 44(4), 369–378.|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedInformation on <b>visual</b> target <b>detection</b> is widely scattered in the literature. This thesis presents a review and a categorization of current literature {{and provides a}} general discussion of representative models {{in the field of}} <b>visual</b> target <b>detection.</b> A literature research matrix is presented to aid the researcher in locating existing models which meet his requirements. [URL] United States Arm...|$|R
40|$|International audienceIn this paper, {{we present}} a {{cooperative}} multi-person tracking system between external fixed-view wall mounted cameras and a mobile robot. The proposed system fuses <b>visual</b> <b>detections</b> from the external cameras and laser based detections from a mobile robot, in a centralized manner, employing a "tracking-by-detection" approach within a Particle Filtering scheme. The enhanced multi-person tracker's ability to track targets in the surveilled area distinctively is demonstrated through quantitative experiments...|$|R
50|$|Using {{volumetric}} titration with <b>visual</b> <b>detection</b> of a titration endpoint is {{also possible}} with coloured samples by UV/VIS spectrophotometric detection.|$|E
50|$|Although {{he started}} searching for asteroids {{in the era}} of <b>visual</b> <b>detection,</b> by 1891 Max Wolf had pioneered the use of {{astrophotography}} to drastically speed up the rate of detection of asteroids, and both Wolf and Charlois separately discovered far more asteroids than would have been feasible by <b>visual</b> <b>detection.</b> In 1899, Charlois received the Prix Jules Janssen, the highest award of the Société astronomique de France, the French astronomical society, and was also awarded the Valz Prize by the French Academy of Sciences in 1889 for his work on calculating asteroid orbits.|$|E
5000|$|Reiczigel J, Mejía Salazar MF, Bollinger TK, Rozsa L 2015. Comparing radio-tracking and <b>visual</b> <b>detection</b> {{methods to}} {{quantify}} group size measures. European Journal of Ecology, 1(2), 1 - 4.|$|E
40|$|Over {{the last}} few years, <b>visual</b> people <b>detection</b> has made {{impressive}} progress. The paper gives an overview {{of some of the}} most successful techniques for people detection and also summarizes a recent quantitative comparison of several state-of-the-art methods. As a proof-of-concept we show that the combination of visual and laser-based people detection can result in a significant increase in performance. We also briefly discuss future research directions for <b>visual</b> people <b>detection.</b> 1...|$|R
40|$|<b>Visual</b> concept <b>detection</b> {{is one of}} {{the most}} {{important}} tasks in image and video indexing. This paper describes our system in the ImageCLEF <b>Visual</b> Concept <b>Detection</b> Task 2010 which ranked first for large-scale <b>visual</b> concept <b>detection</b> tasks in terms of Equal Error Rate (EER) and Area under Curve (AUC) and ranked third in terms of ontology measure. The presented approach involves state-of-the-art local descriptor computation, vector quantisation via clustering, structured scene or object representation via localised histograms of vector codes, similarity measure for kernel construction and classifier learning. The main novelty is the classifierlevel and kernel-level fusion using Kernel Discriminant Analysis with RBF/Power Chi-Squared kernels obtained from various image descriptors. For 32 out of 53 individual concepts, we obtain the best performance of all 12 submissions to this task. 1...|$|R
40|$|International audienceIn this paper, {{we propose}} a novel {{stereoscopic}} image retargeting algorithm based on 3 D <b>visual</b> saliency <b>detection.</b> A new 3 D visual attention model is designed based on 2 D <b>visual</b> feature <b>detection,</b> depth feature detection and the modeling of various viewing bias in stereo vision. A geometrically consistent seam carving technique is adopted for retargeting stereo image pair. Experimental results demonstrated {{that both the}} proposed visual attention model and the proposed retargeting method outperform the state-of-the-art studies...|$|R
50|$|In {{scientific}} imaging where spatial correlation is {{more important}} than intensity of signal (such as separating DNA fragments of quantized length), the small signal to noise ratio usually hampers <b>visual</b> <b>detection.</b>|$|E
50|$|Active {{camouflage}} or adaptive camouflage is camouflage that adapts, often rapidly, to {{the surroundings}} {{of an object}} such as an animal or military vehicle. In theory, active camouflage could provide perfect concealment from <b>visual</b> <b>detection.</b>|$|E
50|$|Closed-circuit {{television}} or a web camera {{can be used}} for <b>visual</b> <b>detection</b> of (wavelengths between 0.4 and 0.7 µm). Smoke or fog can limit the effective range of these, since they operate solely in the visible spectrum.|$|E
40|$|Abstract—In this paper, {{we present}} marine mammal {{observation}} statistics, high-frequency seismic source characteristics, and example denoising of marine mammal acoustical recordings using data {{collected during the}} mitigation and monitoring program for a 3 -D seismic survey by EnCana Corporation, Calgary, AB, Canada, in the Northwest Atlantic during 2003. Marine mammals were observed both visually and acoustically. No marine mammal incidents or adverse reactions were observed during the survey. Acoustical observations {{were made by the}} Seamap Passive Acoustic Cetacean Monitoring System (SPACMS), consisting of two hydrophones placed 50 m apart, towed ahead of and {{to one side of the}} seismic source. <b>Visual</b> and acoustical <b>detections</b> were uncorrelated, indicating the complementary nature of the two observational techniques. <b>Visual</b> <b>detections</b> were more common per hour of effort than acoustical detections. Acoustical detection rate...|$|R
40|$|AbstractComputationally, {{audio-visual}} temporal synchrony detection {{is analogous}} to <b>visual</b> motion <b>detection</b> {{in the sense that}} both solve the correspondence problem. We examined whether audio-visual synchrony detection is mediated by a mechanism similar to low-level motion sensors, by one similar to a higher-level feature matching process, or by both types of mechanisms {{as in the case of}} <b>visual</b> motion <b>detection.</b> We found that audio-visual synchrony–asynchrony discrimination for temporally dense random pulse trains was difficult, whereas motion detection is known to be easy for spatially dense random dot patterns (random dot kinematograms) due to the operation of low-level motion sensors. Subsequent experiments further indicated that the temporal limiting factor of audio-visual synchrony discrimination is the temporal density of salient features not the temporal frequency of the stimulus, nor the physical density of the stimulus. These results suggest that audio-visual synchrony perception is based solely on a salient feature matching mechanism similar to that proposed for high-level <b>visual</b> motion <b>detection...</b>|$|R
50|$|In {{the domain}} of {{computer}} vision, efforts {{have been made in}} modeling the mechanism of human attention, especially the bottom-up attentional mechanism. Such a process is also called <b>visual</b> saliency <b>detection.</b>|$|R
5000|$|Multi-Spectral Camouflage Net - camouflages against night-vision, infra-red, {{radar and}} {{millimeter}} wave sensors {{as well as}} <b>visual</b> <b>detection.</b> Stated to reduce an object's radar cross-section (RCS) by 86% on average and reduce average detection range by 43.8%.|$|E
50|$|Co-training {{was used}} on FlipDog.com, a job search site, {{and by the}} U.S. Department of Labor, for a {{directory}} of continuing and distance education. It {{has been used in}} many other applications, including statistical parsing and <b>visual</b> <b>detection.</b>|$|E
50|$|However, <b>visual</b> <b>detection</b> in {{any form}} listed above, is not {{sufficient}} for establishing pathological classification, cell type or {{the stage of the}} present tumor. A so-called cold cup biopsy during an ordinary cystoscopy (rigid or flexible) will not be sufficient for pathological staging either. Hence, a <b>visual</b> <b>detection</b> needs to be followed by transurethral surgery. The procedure is called transurethral resection of bladder tumor (TURBT). Further, bimanual examination should be carried out before and after the TURBT to assess whether there is a palpable mass or if the tumour is fixed ("tethered") to the pelvic wall. The pathological classification obtained by the TURBT-procedure, is of fundamental importance for making the appropriate choice of ensuing treatment and/or follow-up routines.|$|E
5000|$|... #Caption: A {{submarine}} at periscope depth risks <b>visual</b> or radar <b>detection</b> ...|$|R
40|$|Recent {{evidence}} suggests that schizophrenia is associated with impaired processing of global visual motion, but intact processing of global visual form. This project assessed whether preserved <b>visual</b> form <b>detection</b> in schizophrenia extended beyond low-level pattern discrimination to a naturalistic form-detection task. We assessed both naturalistic form detection and global motion detection in individuals with schizophrenia spectrum disorder, bipolar affective disorder, and healthy controls. Individuals with schizophrenia spectrum disorder and bipolar affective disorder were impaired relative to healthy controls on the global motion task, but not the naturalistic form-detection task. Results indicate that preservation of <b>visual</b> form <b>detection</b> in these disorders extends beyond configural forms to naturalistic object processing...|$|R
40|$|In this paper, a novel {{approach}} to <b>visual</b> salience <b>detection</b> via Neural Response Divergence (NeRD) is proposed, where synaptic portions of deep neural networks, previously trained for complex object recognition, are leveraged to compute low level cues {{that can be used}} to compute image region distinctiveness. Based on this concept, an efficient <b>visual</b> salience <b>detection</b> framework is proposed using deep convolutional StochasticNets. Experimental results using CSSD and MSRA 10 k natural image datasets show that the proposed NeRD approach can achieve improved performance when compared to state-of-the-art image saliency approaches, while the attaining low computational complexity necessary for near-real-time computer vision applications. Comment: 5 page...|$|R
