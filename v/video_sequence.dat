3814|6639|Public
5|$|Ciao Italia: Live from Italy (credited as Madonna: Ciao, Italia! Live from Italy in the <b>video</b> <b>sequence)</b> is a video album by American singer-songwriter Madonna and was {{released}} by Warner Reprise Video and Sire Records on May 24, 1988. It contained footage from a previous TV special of the Who's That Girl World Tour, Madonna in Concerto, broadcast in Europe in 1987, filmed at the Stadio Comunale in Turin, Italy. The video release also contained footage from shows recorded in Florence, Italy and Tokyo, Japan, the latter having previously been released as a Japanese TV special and home video release, Who's That Girl: Live in Japan. The decision to release Ciao Italia was spurred {{by the fact that}} this previous release became a commercial success in Japan. A re-release of the video took place in 1999, when it {{was released}} in DVD format, with a stereo soundtrack containing the songs only.|$|E
5|$|Final Fantasy III Original Soundtrack is a soundtrack {{released}} for the {{remake of}} Final Fantasy III for the Nintendo DS. The album contains the original tracks {{from the game}} rearranged by Tsuyoshi Sekito and Keiji Kawamori for the DS system, {{as well as two}} remixes, one from The Black Mages and the other by Yasuhiro Yamanaka, the synth operator for the soundtrack. The album also included a DVD containing the opening full motion <b>video</b> <b>sequence</b> of the game, a promotional video, and an interview with the game's staff. It was released on September 20, 2006 by Square Enix and bears the catalog numbers SQEX-10076~7. The soundtrack disc contains 61 tracks and covers a duration of 70:56., while the DVD's three tracks have a length of 28:24.|$|E
5|$|HAL Laboratory {{developed}} Super Smash Bros. Melee, with Masahiro Sakurai as {{the head}} of production. The game {{was one of the first}} games released on the GameCube and highlighted the advancement in graphics from the Nintendo 64. The developers wanted to pay homage to the debut of the GameCube by making an opening full motion <b>video</b> <b>sequence</b> that would attract people's attention to the graphics. HAL worked with three separate graphic houses in Tokyo to make the opening sequence. On their official website, the developers posted screenshots and information highlighting and explaining the attention to physics and detail in the game, with references to changes from its predecessor.|$|E
3000|$|The {{performance}} of the proposed method is verified in this section. We used <b>video</b> <b>sequences</b> shown in Table 1. According to Equation (1), motion-blurred LR <b>video</b> <b>sequences</b> shown in Table 2 were generated from the motion blur kernels (PSF) shown in Figure 1. Then we applied the proposed method to the LR <b>video</b> <b>sequences</b> and generated resolution-enhanced <b>video</b> <b>sequences</b> at the original resolution. When applying the proposed method to the test sequences, we simply set α= 1, μ= 0, [...]...|$|R
40|$|In {{this paper}} {{we present a}} system for the {{exploration}} of <b>video</b> <b>sequences.</b> The system, GAMBAL-EVS, segments <b>video</b> <b>sequences</b> extracting an image for each shot and then clusters such images and presents them in a visualization system. The system permits to find similarities between images and to traverse along the <b>video</b> <b>sequences</b> to find the rellevant ones...|$|R
3000|$|The “Breakdancers” and “Ballet” test <b>video</b> <b>sequences</b> can be {{retrieved}} from the “[URL] The “Interview” and “Orbit” test <b>video</b> <b>sequences</b> can be {{retrieved from}} the “[URL] [...]...|$|R
5|$|The Vs. Battle is the {{multiplayer}} mode {{where two}} to four players can compete simultaneously. Time Attack lets the player choose any track and complete it in the shortest time possible. An Internet ranking system was established where players enter a password on the official F-Zero website and get ranked based on {{their position in the}} database. Players receive a password after completing a Time Attack race, which records their time and machine used. Ghost data, transparent re-enactments of the player's Time Attack performances, can be saved on memory cards to later race against. Up to five ghosts can be raced against simultaneously. The Replay mode allows saved Grand Prix and Time Attack gameplay to be replayed with different camera angles and in-game music. The Pilot Profile mode has each character's biography, theme music, information on their machine, and a short full motion <b>video</b> <b>sequence.</b>|$|E
500|$|During {{the dance}} sequence, puppets are {{suspended}} in the audience aisles while Jackson emerges from a robotic spider originally seen in the vignette. Jackson and Ortega rehearsing the cherry-picker is seen next, along with Jackson rehearsing [...] "Beat It". Footage of Jackson and the band rehearsing [...] "Black or White" [...] is shown next, in which he instructs his band to skip the second verse and later allows guitarist Orianthi Panagaris to take center stage to finish with a high guitar riff. The <b>video</b> <b>sequence</b> for [...] "Earth Song" [...] is shown next, featuring {{a little girl who}} wanders through a forest, falls asleep, and wakes up to find the forest destroyed by man. Jackson then performs the song, with his voice being heard at the end telling of the dangers of global warming and the lack of reversible time left. He then performs a quick version of his song [...] "Billie Jean". Michael is then seen talking to all crew members and wishing everyone the best for the London performances. At a sound check, Michael performs [...] "Man in the Mirror" [...] with strong backing vocals. The credits are shown next, with a montage of rehearsal clips and [...] "This Is It" [...] being played in the background. After the show, a live recording of [...] "Heal The World" [...] was played. Then, the audio of [...] "Human Nature" [...] was played, with a clip of Michael rehearsing it in early June (the 3D screen was not set up yet). Then, a clip of {{what could have been a}} Dome Project video of [...] "Heal the World" [...] was shown, in which the girl that appeared in the [...] "Earth Song" [...] video was shown holding the world and a signed message, by Michael, saying [...] "I Love You." ...|$|E
2500|$|A robust {{background}} subtraction algorithm {{should be}} able to handle lighting changes, repetitive motions from clutter and long-term scene changes. [...] The following analyses make use of the function of V(x,y,t) as a <b>video</b> <b>sequence</b> where t is the time dimension, x and y are the pixel location variables. e.g. V(1,2,3) is the pixel intensity at (1,2) pixel location of the image at t=3 in the <b>video</b> <b>sequence.</b>|$|E
30|$|Before {{implementing}} our algorithm, {{we conducted}} a set of experiments on standard benchmark <b>video</b> <b>sequences</b> {{to determine the best}} inter mode selection in homogeneous and non-homogeneous regions of the <b>video</b> <b>sequences.</b>|$|R
40|$|This paper {{outlines}} a {{study of}} MPEG compressed <b>video</b> <b>sequences</b> and simulation of multiplexed video traffic in the ATM environment. A number of statistical characteristics including autocorrelation and variance of MPEG- 1 compressed <b>video</b> <b>sequences</b> are used to characterize the 16 sample traces used in this study. From these measurements, a preliminary model is developed which utilizes basic measurements of the individual component <b>video</b> <b>sequences</b> to predict bandwidt...|$|R
40|$|Automatic {{extraction}} of events from <b>video</b> <b>sequences</b> has important applications {{in a variety}} of Intelligent Transportation Systems (ITS) problems including scene monitoring, traffic data collection, intersection monitoring, etc. When deploying a system that recognizes events automatically from <b>video</b> <b>sequences,</b> two important things to consider are the real-time analysis of the <b>video</b> <b>sequences</b> and fast learning times required for learning the different classes of events in a scene. A related requirement which is often ignored is the limited reliance of the learning system on the user provided knowledge. In this work, we present an innovative technique for detecting the different events in <b>video</b> <b>sequences</b> through a semi-supervised learning method...|$|R
2500|$|A <b>video</b> <b>sequence</b> used in {{connection}} {{with the opening of the}} Olympic Games in London in 2012 shows two crop circle areas shaped as the Olympic Rings. [...] Another Olympic crop circle area was visible for those landing at Heathrow Airport, London, UK before and during the Olympic Games.|$|E
2500|$|The {{method used}} for {{creating}} these effects involved a technically expanded {{version of an}} old art photography technique known as time-slice photography, in which an array of cameras are placed around an object and triggered simultaneously. Each camera is a still-picture camera not a motion picture camera, and it contributes just one frame to the <b>video</b> <b>sequence.</b> When those pictures are shown in sequence, they create the effect of [...] "virtual camera movement"; {{the illusion of a}} viewpoint moving around an object that appears frozen in time.|$|E
2500|$|... "Wanna Be Startin' Somethin'" [...] was {{confirmed}} {{to be the}} opener, followed by [...] "Jam", a dance sequence referred to as [...] "The Drill" [...] leading into [...] "They Don't Care About Us", [...] "Human Nature", and [...] "Smooth Criminal". The show would open with a <b>video</b> <b>sequence</b> referred to as [...] "Glimpses and Flashes", followed by a large space suit with video imagery wrapping around it appearing before the audience, referred to as [...] "Light Man". Then, various parts of Light Man would open up to reveal Jackson, who would jump out and stand still {{for a few moments}} before starting the show. The performances of [...] "Smooth Criminal", [...] "Thriller", and [...] "Earth Song" [...] would feature 3D vignettes featuring Jackson, most of which would involve Michael coming out of the videos and onto the stage. Michael would occasionally replace [...] "Human Nature" [...] and [...] "The Way You Make Me Feel" [...] with [...] "Stranger in Moscow" [...] and [...] "You Rock My World", respectively.|$|E
40|$|This paper {{proposed}} and developed hybrid approach for extraction of key-frames from <b>video</b> <b>sequences</b> from stationary camera. This method first uses histogram difference {{to extract the}} candidate key frames from the <b>video</b> <b>sequences,</b> later using Background subtraction algorithm (Mixture of Gaussian) was used to fine tune the final key frames from the <b>video</b> <b>sequences.</b> This developed approach show considerable improvement over the state-of-the art techniques and same is reported in this paper...|$|R
3000|$|... [...]) of the <b>video</b> <b>sequences,</b> except Akiyo, were similar. Therefore, {{the optimal}} {{parameters}} computed for the Bus video {{would be almost}} optimal for the other four <b>video</b> <b>sequences</b> generated by the same encoding parameters. We therefore use the [...]...|$|R
40|$|Multiple view 3 D video {{reconstruction}} of actor performance captures a level-of-detail for body and clothing movement which is time-consuming to produce using existing animation tools. In this paper {{we present a}} framework for concatenative synthesis from multiple 3 D <b>video</b> <b>sequences</b> according to user constraints on movement, position and timing. Multiple 3 D <b>video</b> <b>sequences</b> of an actor performing different movements are automatically constructed into a surface motion graph which represents the possible transitions with similar shape and motion between sequences without unnatural movement artefacts. Shape similarity over an adaptive temporal window is used to identify transitions between 3 D <b>video</b> <b>sequences.</b> Novel 3 D <b>video</b> <b>sequences</b> are synthesized by finding the optimal path in the surface motion graph between user specified key-frames for control of movement, location and timing. The optimal path which satisfies the user constraints whilst minimizing the total transition cost between 3 D <b>video</b> <b>sequences</b> is found using integer linear programming. Results demonstrate that this framework allows flexible production of novel 3 D <b>video</b> <b>sequences</b> which preserve the detailed dynamics of the captured movement for actress with loose clothing and long hair without visible artefacts. 1...|$|R
5000|$|A coded <b>video</b> <b>sequence</b> {{consists}} {{of a series of}} access units that are sequential in the NAL unit stream and use only one sequence parameter set. Each coded <b>video</b> <b>sequence</b> can be decoded independently of any other coded <b>video</b> <b>sequence,</b> given the necessary parameter set information, which may be conveyed [...] "in-band" [...] or [...] "out-of-band". At the beginning of a coded <b>video</b> <b>sequence</b> is an instantaneous decoding refresh (IDR) access unit. An IDR access unit contains an intra picture which is a coded picture that can be decoded without decoding any previous pictures in the NAL unit stream, and the presence of an IDR access unit indicates that no subsequent picture in the stream will require reference to pictures prior to the intra picture it contains in order to be decoded.A NAL unit stream may contain one or more coded <b>video</b> <b>sequence.</b>|$|E
5000|$|Temporal {{and spatial}} {{alignment}} between reference and processed <b>video</b> <b>sequence</b> ...|$|E
5000|$|... #Caption: Vivi, Zidane, Garnet, and Steiner in a {{full motion}} <b>video</b> <b>sequence.</b>|$|E
40|$|While it is {{generally}} possible to do recognition from <b>video</b> <b>sequences,</b> the training process is usually done over static images. This {{is due to the}} fact that, in many applications (e. g., homeland security), one does not have large <b>video</b> <b>sequences</b> which can be used for training. For example, law enforcement agencies generally have a frontal and a profile view of wanted individuals, but do not usually keep <b>video</b> <b>sequences</b> in file. Nonetheless, in these applications, it is still possible to analyze the information of <b>video</b> <b>sequences</b> for subsequent recognition tasks. This paper presents a probabilistic algorithm that learns from small sets of static images and then recognizes faces from <b>video</b> <b>sequences.</b> The proposed algorithm is robust to partial occlusions, different orientations and expression changes and does not require of precise face localizations. Our preliminary results with a small database show that the proposed method is more robust to such changes than static-to-static recognition of faces...|$|R
3000|$|From the {{obtained}} results, {{we can see}} {{the proposed}} method enables the successful reconstruction of the HR <b>video</b> <b>sequences</b> from the motion blurred LR <b>video</b> <b>sequences.</b> As shown in the previous section, the proposed method newly adopts the following two novel approaches: [...]...|$|R
40|$|Video {{processing}} and understanding lab. Trabajo parcialmente financiado pro el Gobierno de España bajo el proyecto TEC 2011 - 25995 (EventVídeo). In this work, a {{comprehensive study of}} an existing anomaly detection framework has been carried out. After identifying current challenges {{in the field of}} anomaly detection in <b>video</b> <b>sequences,</b> an existing framework has been selected for its implementation and evaluation. A set of <b>video</b> <b>sequences</b> containing anomalies from common surveillance scenarios have been selected from publicly available datasets. The system has been evaluated on these <b>video</b> <b>sequences</b> in order to identify existing shortcomings. Improvements to the original algorithm have been proposed in order to address the observed limitations. Finally, the performance of the proposed changes has been evaluated on the same <b>video</b> <b>sequences</b> for comparison...|$|R
5000|$|... #Caption: The {{optical flow}} vector of a moving object in a <b>video</b> <b>sequence.</b>|$|E
50|$|The {{condensation}} algorithm {{has also}} been used for face recognition in a <b>video</b> <b>sequence.</b>|$|E
5000|$|... #Caption: This <b>video</b> <b>sequence</b> {{is based}} on an artist’s {{impression}} of exocomets orbiting the star Beta Pictoris.|$|E
40|$|This paper {{presents}} a novel match-and-tiling approach to retrieve <b>video</b> <b>sequences.</b> The approach considers video similarity matching at two levels [...] the shot and sequence levels. At the shot level, we transform the matching of similar shots {{into a problem}} of matching video feature trajectories using a longest sub-sequence matching technique. This is to achieve both computational simplicity and retrieval effectiveness. At the sequence level, we view sequence matching as a clustering problem and employ an effective sliding window algorithm to locate multi-occurrences of similar <b>video</b> <b>sequences</b> in the database. The resulting technique is able to retrieve both exact and similar <b>video</b> <b>sequences</b> with different durations and shot ordering. Our results demonstrate that our technique is robust and effective in retrieving similar <b>video</b> <b>sequences...</b>|$|R
40|$|In this paper, {{we explore}} a {{technique}} for automatic classification of <b>video</b> <b>sequences,</b> (such as a TV broadcast, movies). This technique analyses the incoming <b>video</b> <b>sequences</b> and classifies them into categories. It {{can be viewed}} as an on-line parser for video signals. We present two techniques for automatic classification...|$|R
40|$|This paper {{describes}} and evaluates an algorithm for real-time people detection in <b>video</b> <b>sequences</b> {{based on}} the fusion of evidence provided by three simple independent people detectors. Experiments with real <b>video</b> <b>sequences</b> show that the proposed integrationbased approach is effective, robust and fast by combining simple algorithms. 1...|$|R
5000|$|... #Caption: This <b>video</b> <b>sequence</b> {{shows the}} rapid {{brightening}} and slower fading of a supernova {{explosion in the}} galaxy.|$|E
5000|$|A robust {{background}} subtraction algorithm {{should be}} able to handle lighting changes, repetitive motions from clutter and long-term scene changes. [...] The following analyses make use of the function of V(x,y,t) as a <b>video</b> <b>sequence</b> where t is the time dimension, x and y are the pixel location variables. e.g. V(1,2,3) is the pixel intensity at (1,2) pixel location of the image at t = 3 in the <b>video</b> <b>sequence.</b>|$|E
50|$|The Teknomo-Fernandez {{algorithm}} (TF algorithm), is {{an efficient}} algorithm for generating the background {{image of a}} given <b>video</b> <b>sequence.</b>|$|E
40|$|The {{temporal}} {{complexity of}} <b>video</b> <b>sequences</b> {{can be characterized}} by motion vector map which consists of motion vectors of each macroblock (MB). In order to obtain the optimal initial QP (quantization parameter) for the various <b>video</b> <b>sequences</b> which have different spatial and temporal complexities, this paper proposes a simple and high performance initial QP determining method based on motion vector map and temporal complexity to decide an initial QP in given target bit rate. The proposed algorithm produces the reconstructed <b>video</b> <b>sequences</b> with outstanding and stable quality. For any <b>video</b> <b>sequences,</b> the initial QP can be easily determined from matrices by target bit rate and mapped spatial complexity using proposed mapping method. Experimental {{results show that the}} proposed algorithm can show more outstanding objective and subjective performance than other conventional determining methods...|$|R
40|$|This paper {{presents}} a new video quality metric for automatically estimating the perceptual quality of compressed <b>video</b> <b>sequences.</b> Distortion {{measures such as}} the mean squared error (MSE) and the peak {{signal to noise ratio}} (PSNR) have been found to poorly correlate with visual quality at lower bit-rates. The proposed quality metric (MOSp) predicts perceptual quality of compressed <b>video</b> using <b>sequence</b> characteristics and the mean squared error (MSE) between the original and compressed <b>video</b> <b>sequences.</b> The metric has been tested on various <b>video</b> <b>sequences</b> compressed using the H. 264 video compression standard at different bit-rates. Results show that the proposed metric has better correlation with subjective quality compared to popular metrics such as PSNR, SSIM and PSNRplus. The new metric is simple to compute and hence suitable for incorporation into real-time applications such as the standard video compression codecs inorder to improve the visual quality of compressed <b>video</b> <b>sequences.</b> Index Terms — quality metrics, video quality, mean squared error, perceptual quality, compressed video 1...|$|R
40|$|Recommendations such as P. 910 {{suggests}} parameters TI (temporal information) and SI (spatial information) for characterizing <b>video</b> <b>sequences</b> {{for quality}} assessment. In this paper, we suggest two additional parameter based on disparity called SPI (spatial parallax information) and TPI (temporal parallax information) to characterize 3 DTV <b>video</b> <b>sequences</b> for this purpose...|$|R
