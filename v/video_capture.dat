795|2431|Public
5|$|In 2010, the Kinect was {{released}} by Microsoft as a 3D scanner/webcam hybrid peripheral device which provides full-body detection of Xbox 360 players and hands-free control of the user interfaces of video games and other software on the console. This was later modified by Oliver Kreylos of University of California, Davis {{in a series of}} YouTube videos which showed him combining the Kinect with a PC-based virtual camera. Because the Kinect is capable of detecting a full range of depth (through computer stereo vision and Structured light) within a captured scene, Kreylos demonstrated the capacity of the Kinect and the virtual camera to allow free-viewpoint navigation of the range of depth, although the camera could only allow a <b>video</b> <b>capture</b> of the scene as shown {{to the front of the}} Kinect, resulting in fields of black, empty space where the camera was unable to capture video within the field of depth. Later, Kreylos demonstrated a further elaboration on the modification by combining the video streams of two Kinects in order to further enhance the <b>video</b> <b>capture</b> within the view of the virtual camera. Kreylos' developments using the Kinect were covered among the works of others in the Kinect hacking and homebrew community in a New York Times article.|$|E
5|$|When {{it comes}} to video walkthroughs of games, {{gameplay}} may be recorded in multiple ways, such as {{through the use of}} screencast software, built-in recording features in some emulators or via a <b>video</b> <b>capture</b> device connected to a console or another computer. Some video games also include built-in recording features, such as Grand Theft Auto V(2013), which included in-game recording and editing features in its PlayStation 4 and Xbox One re-releases, allowing players to record and edit gameplay to share with others. Video content is typically shared over the internet via streaming, using video sharing and media streaming websites such as YouTube and Twitch, where the content has a potential audience consisting of millions of people.|$|E
5|$|To {{create the}} {{character}} animations for the game, actors {{were placed in}} front of a gray background and performed the motions, which were recorded on videotape (using a broadcast-quality, $20,000 Sony camera instead of the standard Hi8 camera used for the original Mortal Kombat). The <b>video</b> <b>capture</b> footage was then processed into a computer, and the background was removed from selected frames to create sprites. Towards the end of the game's development, they opted to instead use a blue screen technique and processed the footage directly into the computer for a similar, simpler process. The actors were lightly sprayed with water to give them a sweaty, glistening appearance, while post-editing was done on the sprites afterward to highlight flesh tones and improve the visibility of muscles, which Tobias felt set the series apart from similar games using digitized graphics. Animations of Shang Tsung morphing into other characters were created by Midway's John Vogel using a computer, while hand-drawn animations were used for other parts of the game, such as the Fatalities. For animating Goro and Kintaro, clay sculptures were created by Tobias' friend Curt Chiarelli and then turned into 12-inch latex miniatures that were used for stop motion filming. Because of technical restrictions, the actors' costumes had to be simple and no acrobatic moves such as backflips could have been recorded; the hardest moves to perform were some of the jumping kicks.|$|E
500|$|... Extended <b>Video</b> <b>captured</b> of a Bobcat Swimming Across Lake Lanier Georgia ...|$|R
5000|$|... #Caption: This {{time-lapse}} <b>video</b> <b>captures</b> the Milky Way {{circling over}} ALMA.|$|R
5000|$|... #Caption: High-speed, slow-motion {{lightning}} <b>video</b> <b>captured</b> at 6,200 frames per second.|$|R
25|$|Besides the {{hardware}} implementations, it's {{also possible to}} decode teletext using a PC and <b>video</b> <b>capture</b> or DVB board.|$|E
25|$|Stage Sets were premium {{personal}} spaces where {{users who}} had a <b>video</b> <b>capture</b> system could make their own machinimas. Loot released four different Stage Sets for users to create and film their own machinimas with, and provided various tools within the Stage Sets (e.g. lighting and props) to help the users create their own machinimas. Loot also had an array of items available at their Loot store in the shopping complex.|$|E
25|$|From 2011-2016, Chiao served Epiphan Video as VP Aerospace. He {{currently}} {{serves as}} an advisor to the company. Based on NASA's space technologies, Epiphan Video produces high-resolution <b>video</b> <b>capture,</b> streaming, and recording products for the medical, educational, IT and industrial markets. Chiao's role at Epiphan Video {{is to work with}} the aerospace industry to define the company's vision and achieve strategic goals in areas such as air traffic control.|$|E
50|$|Initial {{acquisition}} {{is possible}} in either progressive or interlaced form. <b>Video</b> <b>captured</b> as progressive can be transported with either progressive transport or progressive segmented frame (PsF)transport. <b>Video</b> <b>captured</b> as interlaced can be transported with interlace transport. In cases where a progressive captured image is transported as a segmented frame, segment/field frequency must be twice the frame rate.|$|R
5000|$|... #Caption: Border Surveillance <b>video</b> <b>captured</b> by a UAS (likely {{along the}} Mexican border).|$|R
5000|$|... #Caption: <b>Video</b> <b>captured</b> by NASA's Solar Dynamics Observatory of {{the initial}} {{ejection}} taken August 1, 2010.|$|R
25|$|A TV tuner card is a {{computer}} component that allows television signals to be received by {{a computer}}. Most TV tuners also function as <b>video</b> <b>capture</b> cards, allowing them to record television programs onto a hard disk. Several manufacturers build combined TV tuner plus capture cards for PCs. Many such cards offer hardware MPEG encoding to reduce the computing requirements. Some cards are designed for analog TV signals such as standard definition cable or off the air television, while others are designed for high definition digital TV.|$|E
25|$|OSS Watch {{provides}} both reactive and proactive {{support to}} a wide range of projects. Their mission is to ensure that software developed using public funding is, wherever possible, made available under free and open source licenses. Recent success stories have seen them participate in the creation of Opencast Matterhorn, a worldwide community project building audio and <b>video</b> <b>capture</b> and delivery software, as well as the migration of a W3C Widget standards compliant widget engine from an EU funded project into the Apache Software Foundations Incubator.|$|E
25|$|Windows Vista {{introduces}} DirectX Video Acceleration (DXVA) 2.0 which {{enhances the}} implementation of the video pipeline and adds a host of other DDIs, including a Capture DDI for <b>video</b> <b>capture.</b> The DDIs it shares with DXVA 1.0 are also enhanced with support for hardware acceleration of more operations. Also, the DDI functions are directly available to callers and need not be mediated by the video renderer. As such, pipelines for simply decoding the media (without rendering) or post-processing and rendering (without decoding) can also be created. These features require the Windows Display Driver Model drivers.|$|E
40|$|This paper {{introduces}} a novel automated camera control method for capturing desktop presentations. For this purpose, we first discuss typical features of shots and their cameraworks that frequently appear in TV programs. To realize those features in our automated <b>video</b> <b>capturing</b> system, we classify {{the purpose of}} a camerawork from two points of view: target and aspect-of-target. Then, we consider the correspondence between the classification and typical shots and cameraworks. We propose the virtual-frame control algorithm based on this idea, and the implementation in our video production system. We then show experimental results that verified our method through two kinds of experiments: virtual <b>video</b> <b>capturing</b> using CG animations and real <b>video</b> <b>capturing</b> of real presentations. 1...|$|R
50|$|In 1981 a twister {{dubbed the}} Har-Mar tornado touched down in Minneapolis, {{proceeding}} {{to affect the}} northern suburbs of the metro area, including killing a man near Lake Harriet. On July 18, 1986 a tornado touched down in Fridley, and <b>video</b> <b>captured</b> from KARE 11 news helicopter was broadcast live on their 5:00 pm newscast. The aerial <b>video</b> <b>captured</b> on that day was unprecedented at the time, and was heavily researched.|$|R
5000|$|The First Poetry Space Shuttle Landing on Second Life, digital <b>video</b> <b>captured</b> on Second Life, 2010; {{with music}} by Mirko Lalit Egger ...|$|R
500|$|Star Trek: Secret of Vulcan Fury is a {{cancelled}} action-adventure game, {{in development}} by Interplay Entertainment from 1997 until its cancellation in 1999. Based on the [...] license, the game would have followed Captain James T. Kirk {{and the crew}} of the USS Enterprise through a series of adventures regarding the Vulcan and Romulan races. Secret of Vulcan Fury was to have been {{the latest in a series}} of games produced by Interplay based on the license. It would have featured a control method similar to those seen in LucasArts games of that period, and nearly seven hours of full motion <b>video</b> <b>capture</b> using clay models.|$|E
500|$|The {{accompanying}} {{music video}} for [...] "Slow" [...] {{was directed by}} Baillie Walsh and choreographed by Michael Rooney. The video was shot in Barcelona, Spain, and begins with a scene of a man diving into the Piscina Municipal de Montju√Øc swimming pool and coming out of its edge, where {{a number of very}} lightly beachwear-clad people are sunbathing. Minogue stands out in a series of different zoom central shots lying on a sky-blue towel wearing a dark blue bodyhugging Balenciaga dress. The next scenes of the <b>video</b> <b>capture</b> her singing the song through different camera angles, particularly during the chorus when the camera angle shifts to a [...] "bird's eye" [...] view and show Minogue amid beach models performing synchronised choreography to the dance beats. A reviewer from District MTV commented that the video showed that [...] "synchronised sun bathing is more fun than it sounds". Ben Taylor from Swide Magazine included the video in his list of Minogue‚Äôs [...] "Best Music Video Moments". Used for promoting the song, the video premiered earlier than the song's release date, on 21 October 2003. Minogue talked about the video, saying: ...|$|E
500|$|The {{music video}} for [...] "Bedtime Story" [...] was {{directed}} by Mark Romanek over a course of six days at Universal Studios, Universal City, California. Madonna had first approached Romanek to direct the music video of her Erotica single, [...] "Bad Girl" [...] (1993). Romanek recalled in the DVD, The Work of Director Mark Romanek, that [...] "Bad Girl" [...] was ultimately directed by David Fincher, but he got later approached by the singer's team for [...] "Bedtime Story". Romanek contacted storyboard artist Grant Shaffer to create the storyboards for the video. He met with Romanek the next day, who played [...] "Bedtime Story" [...] for Shaffer and also showed him some photographs of Madonna, which {{were supposed to be}} used as the album cover. The surrealism inspired images portrayed a mystical looking Madonna, with white hair billowing behind her. Romanek wanted to have the music <b>video</b> <b>capture</b> the same look. Madonna called from Florida and together with Romanek they described to Shaffer every aspect of the video, including budget and their concepts. For the next few days, Shaffer sketched the storyboards and faxed them to Romanek for review. About 20 days later, Shaffer dropped the final sketches at Propaganda Films, who were producing the video.|$|E
30|$|The rest of {{the paper}} is {{organized}} as follows: Section <b>Video</b> <b>capturing</b> and encoding settings describes the <b>video</b> <b>capturing</b> and encoding settings used in this paper, Section Video content classification presents the video content classification methodology, Section VSN Power consumption modelling and formulation describes the energy consumption model for the VSN used in the paper, experiments and results are provided in Section Experiments and results, and conclusions are and future works are discussed in Section Conclusions.|$|R
50|$|After {{the first}} <b>video</b> (<b>captured</b> in Austin, TX) was released, Planned Parenthood denied {{supporting}} sex-selective abortion and fired the employee {{featured in the}} tape.|$|R
5000|$|... "Violet" [...] is a live {{performance}} <b>video</b> <b>captured</b> during the Violet EP release party on July 31, 2004, at the 360 Club in Toronto.|$|R
2500|$|Weezer {{released}} its much-delayed first DVD on March 23, 2004. The <b>Video</b> <b>Capture</b> Device DVD chronicles the band from its beginnings through Maladroits Enlightenment Tour. Compiled by Karl Koch, the DVD features home video footage, music videos, commercials, rehearsals, concert performances, television performances, and band commentary. The DVD was certified [...] "gold" [...] on November 8, 2004.|$|E
2500|$|In mid-2009, Apple {{released}} Final Cut Pro version 7 {{and began}} support for inserting closed caption data into SD and HD tape masters via firewire and compatible <b>video</b> <b>capture</b> cards. [...] Up until this time, {{it was not}} possible for video editors to insert caption data with both CEA-608 and CEA-708 to their tape masters. The typical workflow included first printing the SD or HD video to a tape and sending it to a professional closed caption service company that had a stand-alone closed caption hardware encoder.|$|E
2500|$|Late in the 2000s {{smartphones}} {{increased in}} usage, with radar viewing applications frequently used. Particularly, [...] on the iOS platform and [...] on Android are favored. Other apps {{may be used}} as are browsers for viewing meteorological data and accessing social networking services. Some handsets can be used as WiFi hotspots and wireless cards may also be used to avoid committing a handset to tethering or operating as a hotspot. Some hotspots operate as mobile broadband MNVO devices using any radio spectrum that is both available and is in contract with a service provider. Such devices may expand mobile data range beyond a single carrier's service area and typically can work on month-to-month contracts. Adoption of tablet computers is expanding as of the early 2010s. 4G LTE has been adopted when available and can be especially useful for uploading HD video. A gradual uptick of those selecting mirrorless interchangeable-lens cameras (MILCs) began in the mid-2010s although DSLR remains heavily favored. Usage of DSLR for <b>video</b> <b>capture,</b> called HDSLR, is common, although HD camcorders remain popular due to their greater functionality (many chasers still shoot both).|$|E
25|$|An amateur <b>video</b> <b>capturing</b> {{the scene}} at the {{restaurant}} in Kuta showed one bomber with a backpack walking inside just seconds before a huge explosion.|$|R
25|$|NASA {{on flight}} day 7 {{released}} the <b>video</b> <b>captured</b> by cameras mounted {{on each of}} Atlantis's solid rocket boosters showing {{the launch of the}} shuttle.|$|R
50|$|After {{the first}} <b>video</b> (<b>captured</b> in Austin, TX) was released, Planned Parenthood denied {{supporting}} sex-selective elective abortion and fired the employee {{featured in the}} tape.|$|R
2500|$|From {{the onset}} of {{computer}} video entertainment, video game players with access to screenshot capture software, <b>video</b> <b>capture</b> devices, and screen recording software have recorded themselves playing through games, often as part of walkthroughs, longplays, speedruns or other entertainment form. For example, the Japanese television program GameCenter CX had the host challenged to complete retro games within a single day, and others like Skip Rodgers had provided VHS tapes describing to players how to complete difficult games. One such form these took was the addition of running commentary, typically humorous in nature, along with the screenshots or videos; video-based playthroughs would typically be presented without significant editing to maintain the raw response the players had to the game. The presenter would also often poll the readers or viewers to certain in-game decisions as to provide an element of interactivity for longer games. [...] Though others had used the same approach at the time, the forums at the website Something Awful are credited with {{coming up with the}} term [...] "Let's Play" [...] in 2007 to describe such playthroughs. The exact origins of the term are unclear, but believed to be in reference to a screenshot playthrough of The Oregon Trail via the Something Awful forums sometime in 2005; the playthrough can no longer be found on the site though has been referenced by other forum threads.|$|E
5000|$|... 5.0 MP with dual LED flash, 4√ó digital zoom and autofocus, 720p <b>video</b> <b>capture</b> at 30 frame/s(Full 1080p <b>video</b> <b>capture</b> will be officially {{supported}} via software upgrade sometime post-launch, unofficially available since 15 May 2011 via customized package) ...|$|E
50|$|<b>Video</b> <b>Capture</b> Device (2004), as himself.|$|E
50|$|Haring also himself {{appears in}} the <b>video,</b> <b>captured</b> when {{painting}} black patterns on a white 60-feet skirt that Jones wears while standing on a platform.|$|R
50|$|NASA {{on flight}} day 7 {{released}} the <b>video</b> <b>captured</b> by cameras mounted {{on each of}} Atlantis's solid rocket boosters showing {{the launch of the}} shuttle.|$|R
50|$|One notable {{feature that}} remains missing in VirtualDubMod {{is the ability}} to program timed <b>video</b> <b>captures,</b> which was present in one VirtualDub fork called VirtualDubVCR.|$|R
