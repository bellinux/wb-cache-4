56|54|Public
5|$|Since Voyager 2s fly-by, the {{brightest}} rings (Adams and Le Verrier) have been imaged with the Hubble Space Telescope and Earth-based telescopes, owing to advances in resolution and light-gathering power. They are visible, slightly above background noise levels, at methane-absorbed wavelengths {{in which the}} glare from Neptune is significantly reduced. The fainter rings are still far below the <b>visibility</b> <b>threshold.</b>|$|E
50|$|During {{the first}} two weeks of April 2015, {{scientists}} fired lasers through a microwave cavity and noticed highly significant variations in the path time. The readings indicated that some of the laser pulses traveled longer, possibly pointing to a slight warp bubble inside the resonance chamber of the device. However, a small rise in ambient air temperature inside the chamber was also recorded, which could possibly have caused the recorded fluctuation in speeds of the laser pulses. According to Paul March, a NASA JSC researcher, the experiment was to be verified inside a vacuum chamber to remove all interference of air. This was done at the end of April 2015. White does not think, however, that the measured change in path length is due to transient air heating, because the <b>visibility</b> <b>threshold</b> is 40 times larger than the predicted effect from air.|$|E
3000|$|In [18], Safranek {{showed that}} the <b>visibility</b> <b>threshold</b> {{needs to be changed}} based on the {{background}} luminance. In other words, the <b>visibility</b> <b>threshold</b> may differ depending on the background luminance level. For example, if the background luminance level is low, the <b>visibility</b> <b>threshold</b> generally has a relatively large value. For medium luminance levels, the <b>visibility</b> <b>threshold</b> is generally small. This property was used when computing the proposed blocking metric. The proposed blocking metric was computed using the following two steps: [...]...|$|E
40|$|A {{method for}} {{determining}} the <b>visibility</b> <b>thresholds</b> for a given subband system is introduced. The approach identifies the important worse case combination of the quantisation error in each basis function and determines the corresponding <b>visibility</b> <b>thresholds</b> using results previously measured in the DCT domain. Using the proposed method, it is relatively simple to determine the <b>visibility</b> <b>thresholds</b> for any subband system in any colour space. Simulation results on the lapped orthogonal transform (LOT) show that the <b>visibility</b> <b>thresholds</b> are useful in visually lossless coding and perceptual weighted quantisation. link_to_subscribed_fulltex...|$|R
40|$|IEEE International Symposium on Circuits and Systems, Hong Kong, China, 9 - 12 June 1997 In this paper, {{a method}} to {{determine}} the <b>visibility</b> <b>thresholds</b> for a given subband system is introduced. Our approach identifies the important worse case combination of the quantization error in each basis function and determine the corresponding <b>visibility</b> <b>thresholds</b> using results previously measured in the DCT domain. Using the proposed method, it is relatively simple to determine the <b>visibility</b> <b>thresholds</b> for any subband system in the YCrCb domain. Simulation results on the Lapped Orthogonal Transform (LOT) show that the <b>visibility</b> <b>thresholds</b> are useful in visually lossless coding and perceptual weighted quantization. published_or_final_versio...|$|R
40|$|ITC/USA 2009 Conference Proceedings / The Forty-Fifth Annual International Telemetering Conference and Technical Exhibition / October 26 - 29, 2009 / Riviera Hotel & Convention Center, Las Vegas, NevadaThis paper {{describes}} a psychophysical experiment to measure <b>visibility</b> <b>thresholds</b> (VT) for quantization distortion in JPEG 2000 and an associated quantization algorithm for visually lossless coding of color aerial images. The <b>visibility</b> <b>thresholds</b> are {{obtained from a}} quantization distortion model based on the statistical characteristics of wavelet coefficients and the deadzone quantizer of JPEG 2000, and the resulting <b>visibility</b> <b>thresholds</b> are presented for the luminance component (Y) and two chrominance components (Cb and Cr). Using the thresholds, we have achieved visually lossless coding for 24 -bit color aerial images at an average bitrate of 4. 17 bits/pixels, which is approximately 30 % of the bitrate required for numerically lossless coding...|$|R
30|$|Texture is an {{important}} factor in image content [15]. In this paper, we focus on revealing the effect of texture on perceptual <b>visibility</b> <b>threshold</b> in stereoscopic image. Given the left view be considered as the dominant view, a hypothesis is preconditioned that texture factor affects the asymmetrical <b>visibility</b> <b>threshold,</b> which means that human vision system cannot be aware of small textural quality change in stereoscopic image unless the degradation exceeds a threshold. Based on a subjective perceptual experiment, a TAVT model of quantization parameters (QP) is established to reveal the relationship between the asymmetrical <b>visibility</b> <b>threshold</b> and texture complexity. Finally, an asymmetric coding scheme with adaptive quantization parameter based on TAVT model is proposed, in which the left view is encoded with normal quality, while the right view is encoded depending on the <b>visibility</b> <b>threshold.</b>|$|E
40|$|The aim of {{this study}} was to compare the <b>visibility</b> <b>threshold</b> of eight plates with {{different}} chromatic contrast. The staircasepsychophysics method based on the resolution of gaps in Landolt C was used to determine the average <b>visibility</b> <b>threshold.</b> Thirty young adults with best-corrected visual acuity of 6 / 6, normal colour perception and no history of ocular diseases were recruited. The results showed a combination of white on blue background plate gave a highest visibility level (mean= 44. 48 ± 6. 37 m), while red on a blue background was the least visible combination (mean= 33. 30 ± 4. 68 m). In conclusion, the chromatic contrast of an object can affect the <b>visibility</b> <b>threshold...</b>|$|E
30|$|Step 1. We {{computed}} {{a horizontal}} blocking feature (BLKH) and a vertical blocking feature (BLKV) using a <b>visibility</b> <b>threshold</b> of block boundaries.|$|E
40|$|A {{model is}} {{developed}} to approximate <b>visibility</b> <b>thresholds</b> for discrete cosine transform (DCT) coefficient quantization error {{based on the}} peak-to-peak luminance of the error image. Experimentally measured <b>visibility</b> <b>thresholds</b> for R, G, and B DCT basis functions can be predicted by a simple luminance-based detection model. This model allows DCT coefficient quantization matrices to be designed for display conditions other {{than those of the}} experimental measurements: other display luminances, other veiling luminances, and other spatial frequencies (different pixel spacings, viewing distances, and aspect ratios) ...|$|R
40|$|ITC/USA 2012 Conference Proceedings / The Forty-Eighth Annual International Telemetering Conference and Technical Exhibition / October 22 - 25, 2012 / Town and Country Resort & Convention Center, San Diego, CaliforniaThis paper {{proposes a}} method of {{measuring}} <b>visibility</b> <b>thresholds</b> for quantization distortion in JPEG 2000 for compression of stereoscopic 3 D images. The crosstalk effect is carefully considered to ensure that quantization errors in each channel of stereoscopic images are imperceptible to both eyes. A model for <b>visibility</b> <b>thresholds</b> is developed to reduce the daunting number of measurements required for subjective experiments...|$|R
5000|$|In Alberta, special {{community}} messaging is {{used when}} {{the level of}} specific pollutants is higher than specified odour or <b>visibility</b> <b>thresholds</b> but the AQHI is rated as “Low” or “Moderate” risk. This messaging {{is used for the}} following pollutants (when they exceed the noted concentrations): ...|$|R
30|$|How {{to set up}} a {{reasonable}} threshold model of stereo perception is the key to improve the efficiency of asymmetric coding. However, the <b>visibility</b> <b>threshold</b> proposed in [8] mainly focused on the whole image distortion, rather than the effect of the image content and local features on the <b>visibility</b> <b>threshold.</b> Obviously, if only a single unified perception threshold is used for natural stereoscopic images, visual perceptual redundancy cannot be maximally removed, because the texture, brightness, and contrast characteristics in different blocks of the image are usually typically diverse.|$|E
30|$|Stereoscopic video coding {{is one of}} {{the most}} {{important}} technologies in three-dimensional video applications. In this paper, the influence of texture features on stereoscopic perceptual threshold is revealed and an asymmetric stereoscopic video coding scheme with texture-based asymmetrical <b>visibility</b> <b>threshold</b> model is proposed. In the proposed coding scheme, a hypothesis is first proposed and a subjective perception experiment is executed to verify the hypothesis. Based on the subjective perceptual experiment, we reveal the relationship between the asymmetrical <b>visibility</b> <b>threshold</b> and texture complexity and build our asymmetric stereoscopic video coding scheme. The proposed scheme has the following characteristics. The method takes the perceptual capabilities of human vision system into account, which achieves significant bitrate saving while maintaining perception quality very well, especially in the applications of small QP and high bitrate. Future work related to the stereoscopic perceptual video coding should focus on two aspects. One is the research on the stereoscopic TAVT model that can assess more stereoscopic perceptual features. The other is exploring the application of the proposed model in the field of rate control and super-high resolution video coding.|$|E
40|$|Perceptual <b>visibility</b> <b>threshold</b> estimation, {{based upon}} {{characteristics}} of the human visual system (HVS), has wide applications in digital image/video processing. An improved scheme for estimating just-noticeable distortion (JND) is proposed in this paper. It is proved to outperform the DCTune model, with the major contributions of a new formula for luminance adaptation adjustment and the incorporation of block classification for contrast masking. The HVS <b>visibility</b> <b>threshold</b> for digital images exhibits an approximately parabolic curve versus gray levels {{and this has been}} formulated to yield a more accurate base threshold. Moreover, edge regions have been differentiated via block classification to effectively avoid over-estimation of JND in the said regions. Experiments with different images and the associated subjective tests show improved performance of the proposed scheme over the DCTune model for luminance adaptation (especially in dark regions) and masking effect in edge regions. Our model has further demonstrated to achieve favorable results in perceptual visual distortion gauge and image compression. The improvement in JND estimation facilitates better visual distortion measurement and visual signal compression. r 2004 Elsevier B. V. All rights reserved...|$|E
30|$|The {{pioneering}} {{experiments in}} [24] found <b>visibility</b> <b>thresholds</b> {{for each of}} the various levels and orientations of the wavelet basis functions. These thresholds translate to step-sizes for uniform quantizers—following these step sizes would keep DWT quantization noise for each individual DWT basis function below the visible threshold.|$|R
40|$|When {{driving in}} foggy conditions, the {{impairment}} of vision may induce {{delay in the}} detection of obstacles and have negative impacts on traffic safety. In order to investigate the <b>visibility</b> <b>thresholds</b> of targets in these conditions, experiments were conducted in a fog chamber. As a first step, traditional photometers were used in order to monitor the luminance of the target and background in changing fog density. A new method using a calibrated camera was investigated {{in order to measure}} the complete visual field using a luminance matrix. The luminance map can subsequently be analysed in order to determine significant parameters for the visibility of the analysed objects. In addition to metrological aspects, the experiment data were analysed and compared to a theoretical approach using a Vision Model developed by Adrian. The <b>visibility</b> <b>thresholds</b> are discussed in relation to the experiment conditions...|$|R
40|$|Existing {{models of}} the optical {{characteristics}} of the eye are combined with a recent model of optical characteristics of the atmosphere given by its modulation transfer function. This combination results in the combined eye-atmosphere performance given by the product of their modulation transfer functions. An application for the calculation of <b>visibility</b> <b>thresholds</b> {{in the case of}} a two-halves field is given...|$|R
30|$|To {{study the}} texture-based {{asymmetrical}} <b>visibility</b> <b>threshold</b> and verify our hypothesis, an appropriate subjective perceptual experiment is needed. We first generate the test stereoscopic image sets and implement the subjective experiment. Then, a TAVT model {{is given by}} non-linear fitting of perceptual thresholds. In addition, some details regarding the implementations are also presented. Finally, to verify the validity and performance, the TAVT model is tested with natural stereoscopic images {{at the end of}} this section.|$|E
30|$|Asymmetric {{stereoscopic}} video coding {{is becoming}} increasingly popular, as it can reduce the bandwidth required for stereoscopic 3 D delivery without degrading the visual quality. Based on the perceptual theory of binocular suppression, {{the left and right}} views of stereoscopic video are coded with different levels of quality. However, existing asymmetric perceptual coding approaches on stereoscopic video mainly focus on the threshold of whole image distortion. It is not so reasonable to use a single unified rather than adaptable perception threshold for a random natural stereoscopic image as the texture complexity typically varies in different blocks of image. In this paper, we generated an asymmetrically distorted stereoscopic image set with different texture densities and conducted a large number of subjective perceptual experiments. A strong correlation between the asymmetrical <b>visibility</b> <b>threshold</b> and texture complexity is revealed from the subjective experiments, and a texture-based asymmetrical <b>visibility</b> <b>threshold</b> model (TAVT) is established. Then, the model is extended to the hierarchical B picture (HBP) coding architecture and an asymmetric stereoscopic video coding method is proposed based on the TAVT model. Experimental results show that the proposed method can effectively reduce the unnecessary perceptual redundancy without visual quality degradation. Especially, it is more efficient for high bitrate configuration.|$|E
30|$|The most {{commonly}} used objective image quality metric is the peak {{signal to noise ratio}} (PSNR). However, PSNR does not correlate well with human perception in some cases. Recently, a number of other objective quality metrics have been developed, which consider the human visual system (HVS). In [1] the Sarnoff model computed errors when distortions exceeded a <b>visibility</b> <b>threshold.</b> The structural similarity index (SSIM) compares local patterns of pixel intensities normalized for luminance and contrast [2]. One drawback of these metrics is that they require the original image as a reference.|$|E
40|$|We {{determined}} the luminance {{level at which}} a defective pixel in a relatively dark environment becomes visible {{as a function of}} its visual angle, its color and the average display background luminance. A new model has been implemented that can predict these <b>visibility</b> <b>thresholds.</b> The results can be used to update the ISO standard for the acceptability of defective pixels in high-resolution displays. © 2005 SID...|$|R
40|$|Visual {{information}} is reduced in foggy conditions, {{and in particular}} the contrast of objects when driving at night-time with car headlights. This impairment of vision may induce delay in the detection of obstacles and thus {{have a negative impact on}} traffic safety. In order to investigate the <b>visibility</b> <b>thresholds</b> of roadway and roadside objects in these conditions, experiments were conducted in a fog chamber using car headlights and a comparison made to a theoretical approach using a Vision Model developed by Adrian...|$|R
40|$|Stereoscopic 3 -D has {{received}} considerable attention {{over the last}} few decades. Since a stereoscopic 3 -D pair includes two 2 -D images together, the amount of data for an uncompressed stereo image is double compared to that for an uncompressed 2 -D image. Thus efficient compression techniques are of paramount importance. However, crosstalk effect is an inherent perceivable problem in current 3 -D display technologies. It can lead not only to degradation in the perceived quality of 3 -D images, but also to discomfort in some individuals. Correspondingly, when crosstalk occurs, the compression artifacts in a compressed stereo pair can be perceived, despite the fact that such artifacts are imperceptible in individual left and right images. This dissertation proposes a methodology for visually lossless compression of monochrome stereoscopic 3 -D images in which crosstalk effect is carefully considered. In the proposed methodology for visually lossless compression of monochrome stereoscopic 3 -D images, <b>visibility</b> <b>thresholds</b> are measured for quantization distortion in JPEG 2000 to conceal perceivable compression artifacts. These thresholds are found to be functions of not only spatial frequency, but also of wavelet coefficient variance, as well as the gray level in both the left and right images. In order to avoid a daunting number of measurements of <b>visibility</b> <b>thresholds</b> during subjective experiments, a model for <b>visibility</b> <b>thresholds</b> is developed. The left image and right image of a stereo pair are then compressed jointly using the <b>visibility</b> <b>thresholds</b> obtained from the proposed model to ensure that quantization errors in each image are imperceptible to both eyes. This methodology is then demonstrated via a 3 -D stereoscopic liquid crystal display (LCD) system with an associated viewing condition. The resulting images are visually lossless when displayed individually as 2 -D images, and also when displayed in stereoscopic 3 -D mode. In order to have better perceptual quality of stereoscopic 3 -D images, hardware based techniques have been used to reduce crosstalk in 3 -D stereoscopic display systems. However, crosstalk is still readily apparent in some 3 -D viewing systems. To reduce crosstalk remains after hardware crosstalk compensation, a methodology for crosstalk compensation accomplished via image processing is provided in this dissertation. This methodology focuses on crosstalk compensation of 3 -D stereoscopic LCD systems in which active shutter glasses are employed. Subjective experiments indicate that crosstalk is a function of not only the pixel intensity in both the left and right channels, but also of spatial location. Accordingly, look-up tables (LUTs) are developed for spatially-adaptive crosstalk compensation. For a given combination of gray levels in the left and right channels at a specific spatial location, the original pixel values are replaced by values contained in the LUTs. The crosstalk in the resulting stereo pair is significantly reduced, resulting in a significant increase in perceptual image quality...|$|R
40|$|International audienceMore than ever, {{the growing}} amount of {{exchanged}} digital contents calls for efficient and practical techniques to protect intellectual property rights. During {{the past two}} decades, watermarking techniques have been proposed to embed and detect information within these contents, with four key requirements at hand: robustness, security, capacity and invisibility. So far, researchers mostly focused on the first three, but seldom addressed the invisibility from a perceptual perspective and instead mostly relied on objective quality metrics. In this paper, a novel DFT watermarking scheme featuring perceptually-optimal visibility versus robustness is proposed. The watermark, a noise-like square patch of coefficients, is embedded by substitution within the Fourier domain; the amplitude component adjusts the watermark strength, and the phase component holds the information. A perceptual model of the Human Visual System (HVS) based on the Contrast Sensitivity Function (CSF) and a local contrast pooling is {{used to determine the}} optimal strength at which the mark reaches the <b>visibility</b> <b>threshold.</b> A novel blind detection method is proposed to assess the presence of the watermark. The proposed approach exhibits high robustness to various kind of attacks, including geometrical distortions. Experimental results show that the robustness of the proposed method is globally slightly better than state-of-the-art. A comparative study was conducted at the <b>visibility</b> <b>threshold</b> (from subjective data) and showed that the obtained performances are more stable across various kinds of contents...|$|E
40|$|The {{influence}} of regional {{background on the}} visibility of sharpness differences has been investigated by blurring various still images to different extents. The assessment of sharpness has been performed both in China by Chinese people and in the Netherlands by European people. The results showed that both Chinese characters and Roman text were clearly more critical image material for judging sharpness than natural images. Independent on whether the image contained Chinese characters or Roman text, the <b>visibility</b> <b>threshold</b> for a difference in sharpness was the same for both the Chinese and European people. When related to a diagonal step response, the threshold on average equaled an angular resolution of 5 arcsec...|$|E
40|$|In this paper, a {{supra-threshold}} spatio-velocity CSF {{experiment is}} described. It consists in a contrast matching task with a methods of limits procedure. Results enable {{the determination of}} contrast perception functions which give, for given spatial and temporal frequencies, the perceived contrast of a moving stimulus. These contrast perception functions are then used to construct supra-threshold spatio-velocity CSF. As for supra-threshold CSF in spatial domain, it can be observed that CSF shape changes from band-pass behaviour at threshold to low-pass behaviour at supra-threshold, along spatial frequencies. However, supra-threshold CSFs have a band-pass behaviour along temporal frequency has threshold one. This means that if spatial variations can be neglected above the <b>visibility</b> <b>threshold,</b> temporal ones are still of primary importance...|$|E
40|$|Abstract—Visually {{lossless}} coding allows image codecs to achieve high compression ratios while producing images without visually noticeable distortion. In general, visually {{lossless coding}} is approached {{from the point}} of view of the encoder, so most methods are not applicable to already compressed codestreams. This paper presents two algorithms focused on the visually lossless decoding and transmission of JPEG 2000 codestreams. The proposed strategies can be employed by a decoder, or a JPIP server, to reduce the decoding or transmission rate without penalizing the visual quality of the resulting images. Index Terms—Visually lossless coding, <b>visibility</b> <b>thresholds,</b> human visual system, JPEG 2000. I...|$|R
40|$|Driving in poor {{meteorological}} conditions is particularly dangerous {{in terms of}} road safety. In order to investigate the <b>visibility</b> <b>thresholds</b> of targets in these conditions, experiments were conducted in a fog chamber. A new method using a Calibrated camera, in comparison to traditional photometers, was investigated {{in order to measure}} the complete visual field using a luminance matrix. The luminance map can subsequently be analysed in order to determine significant parameters for the visibility of the analysed objects. In addition to metrological aspects, the experiment data were analysed and compared to a theoretical approach using a Vision Model developed by Adrian...|$|R
40|$|In {{this paper}} we propose a digital image quality metric based on human visual system. This metric {{considers}} the coefficients of discrete cosine transform related to each 8 x 8 block of an image. To perform image evaluation PQMET detects a distortion applied to the image and then selects the corresponding matrix of minimum <b>visibility</b> <b>thresholds</b> capable to produce a visible signal. Therefore it uses the information about the distortion applied, with a consequent improvement in the image quality evaluation. The experimental results show that the proposed metric achieves competitive performance with other well known metrics and outperforms them in some cases...|$|R
40|$|The paper {{presented}} testing of surface defects by pulse video thermography techniques. Such techniques rely on transient infrared {{radiation from the}} sample heated by the short duration flux initiated by flesh. Experimental measurements are realized by infrared sensor (FLIR camera). Testing results are considered for the samples with controlled designed defects beyond observed surfaces. The effects of response through the transparent wall are measured as infrared visible radiance. Researches with controlled samples are performed to verify <b>visibility</b> <b>threshold</b> of defect dimensions and forms, for possible use as modulation transfer function of defects hidden beyond the surfaces of thin metal walls. Dimensionless coefficients are derived for method estimations as the results from experimental research...|$|E
30|$|Based on {{the above}} considerations, {{it is found}} that the success of {{asymmetric}} coding depends on the type of encoding distortion. However, up to now much research works focus on the qualitative analysis of binocular suppression in stereoscopic perception. Only a few scholars have studied the problem of improving the efficiency of asymmetric coding from the aspect of the asymmetric quantization coding. Based on subjective perception experiment, researchers in [8] proposed the quantitative <b>visibility</b> <b>threshold</b> (VT) model and found that 2  dB will be a safe bound for asymmetric stereoscopic coding and where most of people cannot perceive the degradation of quality. The VT model in [8] can be further applied to asymmetric coding and save the total bitrate 9 to 34 % [9].|$|E
30|$|Different {{approaches}} are proposed by Kanumuri et al. in [22]: the RR metric {{is based on}} a two-step approach. The information gathered from the original, received, and decoded video are used in a classifier whose output will be used in the evaluation of artifact visibility performed on a decision tree trained by subjective tests. Similarly, in [23], a general linear model (GLM) is adopted for estimating the <b>visibility</b> <b>threshold</b> of packet loss in H. 264 video streaming. In [24], GLM is modified by computing a saliency map, for weighting the pixel-wise errors, and by taking into account the influence of the temporal variation of saliency map and packet loss. The results show that if the HVS features are considered, the prediction of subjective scores is improved.|$|E
40|$|The {{one-dimensional}} incremental parsing rule, {{which is}} used in the Lempel-Ziv universal compression, is extended to that of two dimension in this paper. And its three essential component schemes, a hierarchical structure for two-dimensional source coding, dictionary augmentation, and maximum decimation matching, are addressed. To design an approximate pattern matching algorithm, two types of distortion functions, local average distortion and local minimax distortion, with noise <b>visibility</b> <b>thresholds</b> are given. We have compared our algorithm to existing lossy data compression algorithms based on pattern matching schemes, and demonstrated its superiority both in minimizing signal distortion and in maximizing perceptual quality...|$|R
3000|$|... where dCb(λ, θ, i, j) and dCr(λ, θ, i, j) denote <b>visibility</b> <b>thresholds</b> of the {{coefficients}} at location (i, j) of the (λ, θ) subband in Cb and Cr components, respectively, and η and κ the parameters that {{are allowed to}} vary with frequency and perceptual color channel [17]. The larger the values of η and κ are set, the greater the crossed masking effect can be given. When η and κ are set by the values of 0, no crossed masking occurs and the crossed masking adjustment is constant at 1. Through experiments, η = 1.0 and κ = 1.0 for all bands are determined in this article.|$|R
40|$|Fog {{is one of}} {{the most}} {{dangerous}} meteorological phenomena in terms of road visibility perturbation. The decrease and the levelling of luminance levels reduce the contrasts and delay the detection of obstacles. Experimentations with observers were carried out in a fog chamber in order to quantify the visual degradations generated by the fog in nocturnal conditions. The luminance of the scene has been recorded with videophotometers based on calibrated CCD cameras. These photometric measurements led to the calculation of <b>visibility</b> <b>thresholds</b> that are compared to theoretical values provided by Adrian's model. The visibility levels are then determined. Further investigations with other observers are needed in order to reduce the statistic variance of the results, and then enable to propose an adaptation of the model in fog...|$|R
