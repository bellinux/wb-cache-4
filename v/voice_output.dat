147|59|Public
5|$|SGDs {{that use}} {{synthesized}} speech apply the phonetic {{rules of the}} language to translate the user’s message into <b>voice</b> <b>output</b> (speech synthesis). Users {{have the freedom to}} create novel words and messages and are not limited to those that have been pre-recorded on their device by others.|$|E
5|$|There {{are several}} input and display methods for users of varying {{abilities}} {{to make use}} of SGDs. Some SGDs have multiple pages of symbols to accommodate a large number of utterances, and thus only a portion of the symbols available are visible at any one time, with the communicator navigating the various pages. Speech-generating devices can produce electronic <b>voice</b> <b>output</b> by using digitized recordings of natural speech or through speech synthesis—which may carry less emotional information but can permit the user to speak novel messages.|$|E
5|$|Blissymbols {{were first}} used in Canada in 1971 to provide {{communication}} to those {{not able to}} use traditional orthography; their use quickly spread to other countries. With improved technology, keyboard communication devices developed in Denmark, the Netherlands and the US increased in portability; the typed messages were displayed on a screen or strip of paper. By {{the end of the}} 1970s, communication devices were being commercially produced, and a few, such as the HandiVoice, had <b>voice</b> <b>output.</b> Countries such as Sweden, Canada and the United Kingdom initiated government-funded services for those with severe communication impairments, including developing centres of clinical and research expertise.|$|E
5000|$|Output check (this {{checks the}} {{individual}} <b>voice</b> <b>outputs</b> use <- or -> {{to change the}} currently selected output and {{check to see if}} a test tone is emitted from that output).|$|R
40|$|Heart beat {{monitoring}} {{is vital}} to ensuring healthiness of the human cardiovascular system, but availability of a simple and low-cost heart beat monitoring device that does not require expert medical personnel to handle still remains a challenge especially in rural and semi-urban areas of developing countries like Nigeria. This paper describes the design and implementation of a simple, reliable, accurate and cost effective microcontroller based heart beat monitoring device with Liquid Crystal Display (LCD) and <b>voice</b> <b>outputs.</b> The heart rate of the subject is measured from the fingertip using optical sensors and the rate is then displayed on a text based LCD and <b>voice</b> <b>outputs</b> i...|$|R
5000|$|Gender stereotyping: When <b>voice</b> <b>outputs</b> {{are used}} on computers, this {{triggers}} mindless gender stereotyped scripts, expectations, and attributions from individuals. For example, a 1997 {{study revealed that}} female-voiced tutor computers were rated as more informative about love and relationships than male-voiced tutors and male-voiced computers were more proficient in technical subjects than female-voiced computer ...|$|R
500|$|High-tech AAC aids {{permit the}} storage and {{retrieval}} of electronic messages, with most allowing {{the user to}} communicate using speech output. Such devices are known as speech generating devices (SGD) or <b>voice</b> <b>output</b> communication aids (VOCA). [...] A device's speech output may be digitized and/or synthesized: digitized systems play recorded words or phrases and are generally more intelligible while synthesized speech uses text-to-speech software that can be harder to understand but that permits the user to spell words and speak novel messages.|$|E
500|$|Speech-generating devices (SGDs), {{also known}} as <b>voice</b> <b>output</b> {{communication}} aids, are electronic augmentative and alternative communication (AAC) systems used to supplement or replace speech or writing for individuals with severe speech impairments, enabling them to verbally communicate. SGDs are important {{for people who have}} limited means of interacting verbally, as they allow individuals to become active participants in communication interactions. They are particularly helpful for patients suffering from amyotrophic lateral sclerosis (ALS) [...] but recently have been used for children with predicted speech deficiencies.|$|E
500|$|High-tech devices vary in {{the amount}} of {{information}} that they can store, as well as their size, weight and thus their portability. Access methods depend on the abilities of the user, and may include the use of direct selection of symbols on the screen or keyboard with a body part, pointer, adapted mice or joysticks, or indirect selection using switches and scanning. [...] Devices with <b>voice</b> <b>output</b> offer its user the advantage of more communicative power, including the ability to initiate conversation with communication partners who are at a distance. However, they typically require programming, and tend to be unreliable.|$|E
3000|$|... {{represent}} {{parameters of}} the <b>voicing</b> and <b>output</b> probability distributions that are trained for the lth leaf of the output decision tree.|$|R
40|$|Virtual {{representatives are}} {{increasingly}} used in recommender systems to guide users and add conversational aspects. However, {{the impacts of}} virtual representatives on users’ evaluations of the recommender system have not been investigated. This study specifically examined the influence of virtual representatives’ anthropomorphism cues on system users’ perceptions of system credibility and liking. The results revealed that system users’ perceptions of the virtual representative’s credibility have a significant influence on users’ perceived credibility and liking of the system. Also, the human-like appearance of a virtual representative significantly influences users’ perceived attractiveness of the virtual representative, while <b>voice</b> <b>outputs</b> from the representative {{were found to have}} a significant influence on users’ liking of the recommender system...|$|R
50|$|The Mockingboard {{provided}} multiple <b>voices</b> {{of sound}} <b>output,</b> {{and was the}} closest thing to a standard sound card available for the Apple series. It utilized the AY-3-8910 sound generator chip.|$|R
500|$|AAC {{systems are}} diverse: unaided {{communication}} uses no equipment and includes signing and body language, while aided approaches use external tools. Aided communication methods {{can range from}} paper and pencil to communication books or boards to devices that produce <b>voice</b> <b>output</b> (speech generating devices or SGD's)and/or written output. The symbols used in AAC include gestures, photographs, pictures, line drawings, letters and words, {{which can be used}} alone or in combination. Body parts, pointers, adapted mice, or eye tracking can be used to select target symbols directly, and switch access scanning is often used for indirect selection. Message generation is generally much slower than spoken communication, and as a result rate enhancement techniques may be used {{to reduce the number of}} selections required. These techniques include [...] "prediction", in which the user is offered guesses of the word/phrase being composed, and [...] "encoding", in which longer messages are retrieved using a prestored code.|$|E
500|$|... {{characterized}} by deficits in memory and other cognitive domains. Communication impairments are partly attributed to memory deficits, and AAC intervention {{may be used}} to compensate for deficits and to capitalize on the person's strengths, such as the ability to recognize material they cannot recall. Low-tech devices are generally preferred, such as memory books that include autobiographical information, daily schedules, photographs, and reminders or labels. Several studies have shown positive outcomes in the amount of on-topic conversation and the length of interaction with these approaches. The gains were maintained four months after the training {{in the use of the}} memory aids had ceased. High-tech devices with <b>voice</b> <b>output</b> have been found to be less effective; in one study devices resulted in limited topic elaboration/initiation, reduced output and heightened distraction. AAC is also used to enhance the comprehension of those with dementia. The use of augmented listening strategies, such as identifying topics of conversation with pictures, improves the conversational skills of individuals with dementia.|$|E
5000|$|Sound I/O: JAMMA output/ left/right <b>voice</b> <b>output</b> {{terminal}} X 2 ...|$|E
40|$|In {{this paper}} we present the {{architecture}} and implementation issues of a dictation machine prototype for medical reports. This machine features a voice recognition input and a <b>voice</b> synthesis <b>output.</b> The physician dictates {{the results of}} a medical analysis to the system, controls the construction of the report as well as the system operation by an oral dialogue in natural language. At the end of the dictation, the system generates a written report...|$|R
40|$|Presented at the 14 th International Conference on Auditory Display (ICAD 2008) on June 24 - 27, 2008 in Paris, France. This paper {{looks at}} non-speech {{uses of the}} human voice in {{interactive}} objects. A collection of projects using non-verbal voice, as input and as output, is briefly reviewed. The Laughing Swing - an interactive object using non-verbal <b>voice</b> as <b>output,</b> created by the author and associates - is {{described in terms of}} motivations, sound design, sonic behavior implementation and user responses. The significance and potential of interactions with non verbal voice is discussed...|$|R
40|$|C. A. S. E., a managment {{model for}} {{introducing}} microcomputers into a service delivery system {{over a period}} of four years, provides a systematic method for approaching its four components&mdash;conceptualization, acquisition, staff development, and evaluation. Aspects of each component are described here, and practical applications are provided. introducing microcomputers into a pre-school program is a complicated task. Agen-cy planning must ensure that they are used effectively. Frequently, because of computer illiteracy or intimidation {{on the part of the}} agency administrator, appropriate software, hardware, or uses of the available tech-nology may not be explored. This may be es-pecially true in planning for the special,needs of the preschool population. These children require specific computer applica-tions (e. g., <b>voice</b> <b>outputs,</b> special input de-vices, stimulus-response activities) which dif-fer from the standard applications with school-age students (e. g., computer-assisted instruction, word processing). A lack of knowledge and awareness among key deci-sion-makers within the agency results in in-appropriate purchases. Computers are not put to use and are often found in closets or basements. Once the correct purchases are made, there is still a need for appropriate knowledge, motivation, and training among staff. To meet with success, providers need to follow a management model for introduc-ing this technology into their service delivery system. BACKGROUND Currently in the third year of a four-year phase-in, the C. A. S. E. model (Conceptu...|$|R
50|$|Aided {{systems of}} {{communication}} {{do not require}} both individuals to be physically present in the same location, though they might be. Aided systems are often electronic devices, and {{they may or may}} not provide some form of <b>voice</b> <b>output.</b> If a device does create a <b>voice</b> <b>output,</b> it is referred to as a speech generating device. While the message may take the form of speech output, it may also be printed as a visual display of speech. Many of these devices can be connected to a computer, and in some cases, they may even be adapted to produce a variety of different languages.|$|E
5000|$|SILVIA Voice: A modular {{component}} designed for accepting voice input and rendering <b>voice</b> <b>output.</b> It {{can be used}} within an application, web page, {{or as part of}} SILVIA server for better optimization of media streaming.|$|E
50|$|<b>Voice</b> <b>output</b> or speech {{synthesis}} can read any string at virtually any time. Pitch, volume, and other characteristics can be customized using CSS and Speech Synthesis Markup Language (SSML) however the Opera web browser doesn't currently support all these features.|$|E
40|$|Privacy and Security are two {{universal}} rights and, {{to ensure}} that in our daily life we are secure, {{a lot of research}} {{is going on in the}} field of home security, and IoT is the turning point for the industry, where we connect everyday objects to share data for our betterment. Facial recognition is a well-established process in which the face is detected and identified out of the image. We aim to create a smart door, which secures the gateway on the basis of who we are. In our proof of concept of a smart door we have used a live HD camera on the front side of setup attached to a display monitor connected to the camera to show who is standing in front of the door, also the whole system will be able to give <b>voice</b> <b>outputs</b> by processing text them on the Raspberry Pi ARM processor used and show the answers as output on the screen. We are using a set of electromagnets controlled by the microcontroller, which will act as a lock. So a person can open the smart door with the help of facial recognition and at the same time also be able to interact with it. The facial recognition is done by Microsoft face API but our state of the art desktop application operating over Microsoft Visual Studio IDE reduces the computational time by detecting the face out of the photo and giving that as the output to Microsoft Face API, which is hosted over Microsoft Azure cloud support. Comment: 4 pages, 5 figures, published with International Journal of Engineering Trends and Application...|$|R
40|$|IBM has {{recently}} launched Project Intu, which extends the existing web-based cognitive service Watson with the Internet of Things {{to provide an}} intelligent personal assistant service. We propose a voice customization service that allows a user to directly customize the voice of Intu. The method for voice customization is based on IBM Watson’s text-to-speech service and voice conversion model. A user can train the voice conversion model by providing a minimum of approximately 100 speech samples in the preferred voice (target <b>voice).</b> The <b>output</b> <b>voice</b> of Intu (source voice) is then converted into the target voice. Furthermore, the user {{does not need to}} offer parallel data for the target voice since the transcriptions of the source speech and target speech are the same. We also suggest methods to maximize the efficiency of voice conversion and determine the proper amount of target speech based on several experiments. When we measured the elapsed time for each process, we observed that feature extraction accounts for 59. 7 % of voice conversion time, which implies that fixing inefficiencies in feature extraction should be prioritized. We used the mel-cepstral distortion between the target speech and reconstructed speech as an index for conversion accuracy and found that, when the number of target speech samples for training is less than 100, the general performance of the model degrades...|$|R
40|$|Includes bibliographical {{references}} (pages 107 - 108) VIOLET is {{a computer}} terminal which enables the handicapped user to communicate via <b>voice</b> input and <b>output</b> with a host computer. VIOLET is comprised of a Votrax voice synthesizer, an Interstate Electronics Voice Recognition Module, and an Apple II Plus computer. The software for VIOLET is written in 6502 assembly language and the Apple implementation of UCSD Pascal. VIOLET can interface with a large variety of host computers through a standard RS 232 interface. The voice recognition hardware is user specific and has a one hundred word vocabulary limit. These hardware shortcomings are overcome by allowing each user to tailor their vocabulary to match a specific application. The user's vocabulary is maintained on their own floppy disk for future use. Each disk contains tables recording the user's personal vocabulary and a bootable operating system with turnkey execution of VIOLET. VIOLET allows the handicapped to interact, using only <b>voice</b> input and <b>output,</b> with a multitude of host computers {{in a variety of}} programming languages and software packages...|$|R
50|$|SGDs {{that use}} {{synthesized}} speech apply the phonetic {{rules of the}} language to translate the user’s message into <b>voice</b> <b>output</b> (speech synthesis). Users {{have the freedom to}} create novel words and messages and are not limited to those that have been pre-recorded on their device by others.|$|E
5000|$|The {{game was}} notable {{at the time}} for its use of sound samples on limited 8-bit hardware. The game counts [...] "Three...two...one...go!" [...] to start the race, announces the player's status after winning, losing, or crashing, and says [...] "Game over!" [...] to end the game. Other games of the era that produce sampled <b>voice</b> <b>output</b> include Super Robin Hood, Ghost Hunters and RoboCop.|$|E
5000|$|The {{electronic}} banknote reader distributed for Canadians requiring assistive technologies {{was also}} updated {{to be able}} to scan and identify these banknotes, and was half the size and weight than that used for the Birds of Canada series. It was also improved by adding tone and vibration output modes in addition to the speech synthesis <b>voice</b> <b>output</b> of the earlier model. Its development cost about [...]|$|E
5|$|The 808 was {{the first}} drum machine {{with the ability to}} program an entire {{percussion}} track from beginning to end, complete with breaks and rolls. It includes volume knobs for each <b>voice,</b> numerous audio <b>outputs,</b> and a DIN sync port (a precursor to MIDI) to synchronize with other devices through the Digital Control Bus interface, which was considered groundbreaking. The machine has three trigger outputs, which can be used to synchronize with synthesizers and other equipment.|$|R
30|$|The {{goals of}} this study {{can be divided into}} in {{following}} three points: (1) convert the voice uttered by a person with an articulation disorder so that everyone can understand what he/she said, (2) preserve the individuality of the speaker’s <b>voice,</b> and (3) <b>output</b> a natural-sounding <b>voice.</b> Our proposed exemplar-based VC can create a natural-sounding voice because there is no statistical model in our approach, and the source speaker’s individuality can be preserved using our individuality-preserving dictionary.|$|R
50|$|The 808 was {{the first}} drum machine {{with the ability to}} program an entire {{percussion}} track from beginning to end, complete with breaks and rolls. It includes volume knobs for each <b>voice,</b> multiple audio <b>outputs,</b> and a DIN sync port (a precursor to MIDI) to synchronize with other devices via the Digital Control Bus interface, which was considered groundbreaking at the time. The machine has three trigger outputs, which can be used to synchronize with synthesizers and other equipment.|$|R
50|$|People with ALS {{who have}} {{difficulty}} speaking {{may benefit from}} working with a speech-language pathologist. These health professionals can teach people adaptive strategies such as techniques to help them speak louder and more clearly. As ALS progresses, speech-language pathologists can recommend the use of augmentative and alternative communication such as voice amplifiers, speech-generating devices (or <b>voice</b> <b>output</b> communication devices) or low-tech communication techniques such as head mounted laser pointers, alphabet boards or yes/no signals.|$|E
50|$|The {{official}} headset {{allows for}} high quality voice-chat, and provides volume level, battery level, charging status and connection status indicators on the PS3's on-screen display. The headset {{can be used}} as a microphone when docked in the charging cradle - <b>voice</b> <b>output</b> from PS3 is automatically transferred to the TV in this case. The official PS3 headset is also compatible with the PSP Go, as well as Bluetooth capable PCs and mobile phones.|$|E
50|$|Speech-generating devices (SGDs), {{also known}} as <b>voice</b> <b>output</b> {{communication}} aids, are electronic augmentative and alternative communication (AAC) systems used to supplement or replace speech or writing for individuals with severe speech impairments, enabling them to verbally communicate. SGDs are important {{for people who have}} limited means of interacting verbally, as they allow individuals to become active participants in communication interactions. They are particularly helpful for patients suffering from amyotrophic lateral sclerosis (ALS) but recently have been used for children with predicted speech deficiencies.|$|E
40|$|A {{new voice}} {{conversion}} method that improves {{the quality of}} the <b>voice</b> conversion <b>output</b> at higher sampling rates is proposed. Speaker Transformation Algorithm Using Segmental Codebooks (STASC) is modified to process source and target speech spectra in different subbands. The new method ensures better conversion at sampling rates above 16 KHz. Discrete Wavelet Transform (DWT) is employed for subband decomposition to estimate the speech spectrum better with higher resolution. Faster voice conversion is achieved since the computational complexity decreases at a lower sampling rate. A Voice Conversion System (VCS) is implemented using the proposed algorithm with necessary tools. The performance of the proposed method is demonstrated by both subjective listening tests and applications to film dubbing and looping. In ABX listening tests, the listeners preferred the subband based output by 92. 1 % as compared to the full-band based output. 1...|$|R
30|$|For the {{baseline}} system, a five-state multi-stream left-to-right without skip path MSD-HSMM was trained. A conventional maximum likelihood-based decision tree construction algorithm {{was used to}} tie HMM states. In the conventional HMM-based speech synthesis framework, a unique tying structure (decision tree) is normally incorporated for both voicing probabilities and F 0 output probabilities. As opposed to the conventional HMM-based synthesis system, the proposed method uses a soft decision tree structure for the output probability distribution and a hard decision tree for voicing probabilities; therefore, we cannot apply the same tying structure for both <b>voicing</b> and <b>output</b> probabilities in the proposed system. With a view to having a fair comparison, {{the baseline}} system was implemented with two different decision trees for F 0 trajectories, one for the voicing labels {{and the other for}} the output probability distributions.|$|R
5000|$|<b>Voice</b> or tonal <b>output</b> {{from the}} IA can be {{effective}} as a reminder, warning, or indication of action performed, but tends to be irritating to the user {{if it is the}} principal method of interaction. Verbal output is slower than viewing the information and it is difficult for a person to pay attention to and understand information. Systems such as JAWS screen reader for the visually impaired do exist, but are not practical for construction site users and application. See Shneiderman section 9.4 (...) [...]|$|R
