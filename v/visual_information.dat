9732|2229|Public
5|$|The {{optic nerve}} (II) transmits <b>visual</b> <b>information.</b>|$|E
5|$|The game {{features}} an open world environment with a day-night cycle and dynamic weather system {{which can be}} seamlessly explored. The map is composed of forest, jungle, desert, and snowy mountain regions. Mountainous terrain is traversed with the employment of parkour, which is aided {{by the use of}} zip-lines installed throughout the world. Corruption Zones constitute areas that heighten difficulty and are populated by corrupted machines that behave with more aggression. To uncover more of the map, one must scale large giraffe-like machines known as Tallnecks. Twenty-five robotic creature designs are present in the game. Save points and fast travel can be accessed by interacting with campfires, once discovered. The quest structure unfolds to accommodate the exploration of tribes, while the main story covers the entire world. Side quests involve Aloy completing tasks, like gathering materials, coming to the aid of individuals in danger of being killed, solving mysteries, assuming control of bandit camps, eliminating criminals and more difficult machines, accomplishing various challenges at any of the five Hunting Grounds, and obtaining an ancient armour that makes Aloy almost impervious to damage. A dialogue wheel is used to communicate with non-playable characters. Collectibles include vantages that offer <b>visual</b> <b>information</b> of the Old World; metal flowers, which when acquired contain poetry; and old relics, such as ancient mugs and tribal artefacts.|$|E
25|$|Palmer, J. (1990). Attentional {{limits on}} the {{perception}} and memory of <b>visual</b> <b>information.</b> Journal of Experimental Psychology: Human Perception and Performance, 16(2), 332–350.|$|E
5000|$|... #Caption: Transmissometer {{providing}} runway <b>visual</b> range <b>information</b> ...|$|R
5000|$|... #Caption: Transmissometer {{providing}} Runway <b>Visual</b> Range <b>information</b> ...|$|R
50|$|Dive {{computers}} {{provide a}} variety of <b>visual</b> dive <b>information</b> to the diver.|$|R
25|$|The latest canine {{tactical}} vests are {{outfitted with}} cameras and durable microphones that allow dogs to relay audio and <b>visual</b> <b>information</b> to their handlers.|$|E
25|$|The McGurk {{effect is}} a perceptual {{phenomenon}} that demonstrates an interaction between hearing and vision in speech perception. The illusion occurs when the auditory component of one sound is paired with the visual component of another sound, leading to the perception of a third sound. The <b>visual</b> <b>information</b> a person gets from seeing a person speak changes the way they hear the sound. If a person is getting poor quality auditory information but good quality <b>visual</b> <b>information,</b> {{they may be more}} likely to experience the McGurk effect. Integration abilities for audio and <b>visual</b> <b>information</b> may also influence whether a person will experience the effect. People who are better at sensory integration have been shown to be more susceptible to the effect. Many people are affected differently by the McGurk effect based on many factors, including brain damage and other disorders.|$|E
25|$|The ventral stream pathway {{begins with}} purely <b>visual</b> <b>{{information}}</b> {{in the primary}} visual cortex (occipital lobe), and then this information is transferred to the temporal lobe.|$|E
5000|$|Industrial Technology, <b>Visual</b> Arts, <b>Information</b> Software Technology, Food Technology and Textile Technology {{classrooms}} ...|$|R
40|$|Based on {{cognitive}} load {{theory and the}} transient information effect, this paper investigated the modality effect while interpreting a contour map. The length and complexity of auditory and visual text instructions were manipulated. Experiment 1 indicated that longer audio text information within a presentation was inferior to the equivalent longer <b>visual</b> text <b>information</b> demonstrating {{a reversal of the}} modality effect due to transient information imposing a heavy working memory load. However, the expected modality effect was not obtained from the equivalent shorter auditory text presentation compared to shorter <b>visual</b> text <b>information.</b> It was hypothesised that the shorter text still contained too much auditory information for working memory to readily process. Experiment 2 further decreased the shorter auditory text information which then resulted in a traditional modality effect including a modality by text length interaction in which shorter, audio-visual information was better than <b>visual</b> only <b>information</b> but longer, audio-visual information was worse than <b>visual</b> only <b>information.</b> 17 page(s...|$|R
40|$|Dental {{materials}} are specific materials that were {{developed as a}} general materials for specific aplication in oral environment. To determinate the functional properties of this materials, we are obligated to use nonstandard approach and specific methods. In this study, two methodologies of material testing-artificial agging and quantification of <b>visual</b> <b>informations</b> for life circle assessment of hydroxyapatite (Hap) based materials, were used. Hap was chemically synthetized which produced the material with high purity and crystallinity. Artificially produced Hap is used in stomatology for repair of bone tissue, as a filling for periodontal defects, and as a preservative augmentation for alveolar ridges. In the mean time those {{materials are}} used for definitive root canal obturation in endodontic therapy procedure as an apical plug or as complete filling material. This research {{was focused on the}} analysis of the bonding properties of the Hap based materials to the root canal walls. The methodology of artificial agging was used together with the quantification of <b>visual</b> <b>informations</b> in purpose to quantify the Hap bonding properties and bonding quality. Experiments were done in-vitro, with the artificia saliva as the agressive agent. The experimental tooths were analyzed by the high resolution optical microscope for the morphological characterisation of the bonding layer. The model for the bond life circle assessment was developed. Hap based materials proved that has favorable properties for the dental use. The presented results proved that the combination of two methodologies (artificial agging and quantification of <b>visual</b> <b>informations</b> could be used as the tool for analyzing the material-dentine interaction...|$|R
25|$|It is {{the duty}} of every photojournalist to work to {{preserve}} all freedom-of-the-press rights recognized by law and to work to protect and expand freedom-of-access to all sources of news and <b>visual</b> <b>information.</b>|$|E
25|$|Children with {{specific}} language impairment show a significantly lower McGurk effect {{than the average}} child. They use less <b>visual</b> <b>information</b> in speech perception, or have a reduced attention to articulatory gestures, but have no trouble perceiving auditory-only cues.|$|E
25|$|Unfortunately, this {{variant of}} the tail-flip escape has not been {{extensively}} studied. Further studies should focus on this escape variant, paying special attention to exactly how <b>visual</b> <b>information</b> is processed and then converted into neuronal signals that produce a tail flip response.|$|E
50|$|Sanctuary Asia is Indias {{first and}} one of its leading {{environmental}} news magazines. It was founded in 1981 to raise awareness among Indian people of their disappearing natural heritage. The magazine is attractively packaged with colored photographs. The Sanctuary Photo Library is a melting pot of natural history <b>visuals,</b> <b>information</b> and resources used to produce some of the finest wildlife and nature calendars, posters, slide shows, exhibitions and other products available in India.|$|R
40|$|International audienceThe {{current study}} {{investigated}} the role of congruent <b>visual</b> context <b>information</b> in the recognition of facial emotional expression in 190 participants from 5 to 15 years of age. Children performed a matching task that presented pictures with different facial emotional expressions (anger, disgust, happiness, fear, and sadness) in two conditions: with and without a visual context. The results showed that emotions presented with <b>visual</b> context <b>information</b> were recognized more accurately than those presented {{in the absence of}} visual context. The context effect remained steady with age but varied according to the emotion presented and the gender of participants. The findings demonstrated {{for the first time that}} children from the age of 5 years are able to integrate facial expression and <b>visual</b> context <b>information,</b> and this integration improves facial emotion recognition...|$|R
40|$|We {{present a}} novel method for 3 D shape {{recovery}} {{based on a}} combination of <b>visual</b> hull <b>information</b> and multi image stereo. We start from a coarse triangle mesh extracted from <b>visual</b> hull <b>information.</b> The mesh is then hierarchically refined and its vertex positions are optimized based on multi image stereo information. This optimization procedure utilizes 3 D graphics hardware to evaluate the quality of vertex positions, and takes both color consistency, and occlusion e#ects as well as silhouette information into account...|$|R
25|$|Research in 2003 by Professor Margaret Livingstone of Harvard University {{said that}} Mona Lisa's smile disappears when looked with direct vision, known as foveal. Because {{of the way}} the human eye {{processes}} <b>visual</b> <b>information,</b> it is less suited to pick up shadows directly; however, peripheral vision can pick up shadows well.|$|E
25|$|Enterprise Infrastructure Services (CEEIS)— designs {{information}} technology {{standards for the}} Corps, including automation, communications, management, <b>visual</b> <b>information,</b> printing, records management, and information assurance. CEEIS outsources the maintenance of its IT services, forming the Army Corps of Engineers Information Technology (ACE-IT). ACE-IT {{is made up of}} both civilian government employees and contractors.|$|E
25|$|The McGurk {{effect is}} {{stronger}} when {{the right side}} of the speaker's mouth (on the viewer's left) is visible. People tend to get more <b>visual</b> <b>information</b> from {{the right side of}} a speaker's mouth than the left or even the whole mouth. This relates to the hemispheric attention factors discussed in the brain hemispheres section above.|$|E
40|$|Abstract: Cortico-cortical {{projections}} for visual processing that originate from the striate cortex are organized into two streams. The dorsal stream projects to the parietal {{region and the}} ventral stream to the inferior temporal region. One hypothesis is that the dorsal stream processes <b>visual</b> spatial <b>information,</b> and the ventral stream processes <b>visual</b> object <b>information.</b> Although recognition of human faces or common objects has been shown preferentially to activate the ventral stream, the issue of when such processing starts to engage the ventral or the dorsal stream is not clear. The question explored {{in this study is}} whether processing of visual form per se without evoking the brain mechanisms that are associated with recognition of human faces or common objects is sufficient to activate the ventral stream more significantly relative to the condition when only visual spatial processing is involved. Functional magnetic resonance images were acquired while subjects performed a delayed comparison task in which either visual spatial or <b>visual</b> form <b>information</b> was processed. Cortical areas that were preferentially activated in visual spatial or visual form processing showed not only ventral-dorsal segregation, but also hemispheric laterality. The results extended previous findings by showing that preferential activation in the ventral pathway is not contingent upon such powerful stimuli as faces and common objects. Processing of simple <b>visual</b> form <b>information</b> is cause enough for such activation to be observed. A strong left hemisphere dominance in visual form recognition was also revealed. The observed laterality may be a reflection that the left hemisphere is more important in symbolic and/or semantic coding of <b>visual</b> form <b>information.</b> Hum. Brai...|$|R
40|$|The size-weight {{illusion}} (SWI) {{occurs when}} the smaller of equally weighted objects is judged to feel heavier than the larger object. Experiment 1 compared the SWI generated in a natural versus augmented-reality environment while grasping and lifting three differently sized cubes of equal weight. Both environments induced the SWI for all twenty participants. Lift kinematics covariedwith cube size in both environments. Experiment 2 investigated the influence of incongruent <b>visual</b> size <b>information</b> on the SWI in an augmented environment. Physical cubes were paired with three graphical representations: a smaller, an equal-sized, and a larger cube. The SWI was influenced by both haptic and <b>visual</b> size <b>information.</b> Kinematics covariedwith physical size throughout the experiment. Results suggest that vision significantly impacts the bimodal SWI when haptic and <b>visual</b> size <b>information</b> is not redundant. Results have implications for theories of heaviness perception, multimodal interaction, and perception and action in augmented environments...|$|R
40|$|With the {{disintegration}} of analog technologies and media, the book struggles to maintain its validity {{as a form of}} communication. The architectures that create and maintain the book as a repository of history and knowledge have developed {{to the point that the}} book must transform its methods of construction of information that make it more adept at communicating ideas in an age of ephemeral digital information. This thesis seeks to find, understand and manipulate architectures of redundant <b>visual</b> <b>informations</b> in a manner that integrates space (architecture), media (communication), and culture...|$|R
25|$|A {{review of}} 42 follow up studies of {{prenatal}} drug exposed children suggests that cocaine affects the areas concerned with behavior problems, attention, language and cognition for children tested between 4 and 13 years of age. Specifically, short-term memory, visual spatial short-term memory (short-term memory for <b>visual</b> <b>information</b> specifically) and working memory were negatively affected {{in a number}} of studies.|$|E
25|$|<b>Visual</b> <b>information</b> is {{then sent}} to the brain from retinal {{ganglion}} cells via the optic nerve to the optic chiasma: {{a point where the}} two optic nerves meet and information from the temporal (contralateral) visual field crosses {{to the other side of}} the brain. After the optic chiasma the visual tracts are referred to as the optic tracts, which enter the thalamus to synapse at the lateral geniculate nucleus (LGN).|$|E
25|$|Visual {{short term}} memory is the {{capacity}} for holding {{a small amount of}} <b>visual</b> <b>information</b> in mind in an active, readily available state {{for a short period of}} time (usually no more than 30 seconds). Although visual {{short term memory}} is essential for the execution of a wide array of perceptual and cognitive functions, and is supported by an extensive network of brain regions, its storage capacity is severely limited.|$|E
50|$|The Sanctuary Photo Library, a stock photo agency, has a fully {{computerised}} database of {{images that are}} available on request. their focus is on Indian/Asian natural history. It is used by academicians, picture researchers for publications, non-profits, websites, advertising agencies and corporate communicators. Sanctuary Photo Library is a melting pot of natural history <b>visuals,</b> <b>information</b> and resources used to produce {{some of the finest}} wildlife and nature calendars, posters, slide shows, exhibitions and other products available in India. These high quality products are available at reasonable rates for republication anywhere.|$|R
5000|$|Applies human visual {{perception}} to <b>visual</b> presentation of <b>information</b> ...|$|R
40|$|Abstract. Electronic presentations {{are used}} in {{numerous}} scenarios, such as lectures and meetings. In recent years, {{the widespread use of}} electronic presentations means that presentation slide data is increasing as one of industry’s most important information resources. Therefore, it is neces-sary to develop a practical usage method for the reutilisation of the data on slides. An approach to achieve this is to focus on <b>visual</b> structure <b>information</b> within a slide, because <b>visual</b> structure <b>information</b> {{is one of the most}} valuable, easy to understand methods for humans. However, since <b>visual</b> structure <b>information</b> is not explicitly defined in the slide data itself, computers have difficulty comprehending structure informa-tion directly. In this paper, we propose a method of extracting structure information from slide information. The proposed method is composed of two steps: organising objects within the slide as units, such as title, body text, figure and table, and structuring the units as a hierarchy tree based on a top-down approach...|$|R
25|$|Multiple seismic {{surveys were}} {{conducted}} near Sakhalin in 2010, carried out separately by Rosneft, Sakhalin Energy and Gazprom. The surveys conducted by Sakhalin Energy and Rosneft apparently had corresponding monitoring and mitigation plans. The monitoring data, including acoustic and <b>visual</b> <b>information</b> on whale distribution and behavior, {{is yet to}} be analyzed. Two of those seismic surveys occurred later in the year when more gray whales were present and temporally overlapped.|$|E
25|$|The Production Services Flight {{includes}} a <b>Visual</b> <b>Information</b> Branch, providing digital and wet imagery processing, reproduction and graphic design: a Dissemination Branch that distributes and tracks outgoing products, maintains a chart library with worldwide coverage {{and the basic}} target and training graphic repository; a Security Branch maintaining security clearances and facility security devices; a Facility Branch managing the facility and grounds; and a Logistics Branch managing the group's supply and equipment accounts.|$|E
25|$|The eyes do {{not need}} to fixate in order to {{integrate}} audio and <b>visual</b> <b>information</b> in speech perception. There was no difference in the McGurk effect when the listener was focusing anywhere on the speaker's face. The effect does not appear if the listener focuses beyond the speaker's face. In order for the McGurk effect to become insignificant, the listener's gaze must deviate from the speaker's mouth by at least 60 degrees.|$|E
40|$|Abstract: Many neurophysiological {{studies in}} monkeys have {{indicated}} that <b>visual</b> motion <b>information</b> for the guidance of perception and smooth pursuit eye movements is-at an early stage-processed in the same visual pathway in the brain, crucially involving the middle temporal area (MT). However, these studies left some questions unanswered: Are perception and pursuit driven by the same or independent neuronal signals within this pathway? Are the perceptual interpretation of <b>visual</b> motion <b>information</b> and the motor response to visual signals limited by the same source of neuronal noise? Here, we review psychophysical studies that were motivated by these questions and compared perception and pursuit behaviorally in healthy human observers. We further review studies {{that focused on the}} interaction between perception and pursuit. The majority of results point to similarities between perception and pursuit, but dissociations were also reported. We discuss recent developments in this research area and conclude with suggestions for common and separate principles for the guidance of perceptual and motor responses to <b>visual</b> motion <b>information.</b> Cover Lette...|$|R
5000|$|Integration of <b>Visual</b> and Linguistic <b>Information</b> in Spoken Language Comprehension ...|$|R
5000|$|... 2 <b>Visual</b> Passenger <b>Information</b> System or VPIS {{installed}} in each train car. These displays show {{the name of}} the next station, current station, door closing messages and occasionally the date and time.|$|R
