22|10000|Public
3000|$|With {{the best}} <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> of {{similarity}} in hand, we proceeded to analyze a larger dataset C [...]...|$|E
30|$|Large {{values for}} α {{decrease}} the model complexity providing larger modeling error and details are not preserved. In our experiments, we set α[*]=[*]⌈ 0.01 [*]×[*]N⌉ for computing {{the values of}} T 1 and T 2. To make our implementation more efficient, instead of taking all points into consideration, we computed a random permutation of the indices of points and used only the first 10 % of them. Thus, in high density datasets, like in the ETHZ database [28], the <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> could be estimated quickly.|$|E
3000|$|... are set as 9 and 6, empirically. The {{selection}} of thresholds {{is based on}} similar experiments as is shown in Figure 3. The application of these thresholds is {{to determine whether the}} mean chromaticity value and standard deviation of each candidate region {{are similar to those of}} the neighboring pixels. As for smaller thresholds, more candidate regions can be identified as nonshadow regions, but some true shadow regions may be identified as nonshadow regions. However, if the <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> are too great, some true shadow regions will not be detected from candidate nonshadows regions.|$|E
30|$|<b>The</b> <b>threshold</b> {{value is}} an {{important}} parameter that depends {{on a number of}} factors, such as image brightness, contrast, level of noise, and even edge direction. <b>The</b> selection <b>of</b> <b>the</b> <b>threshold</b> in Sobel filtering is associated to <b>the</b> sensitivity <b>of</b> <b>the</b> filter to edges. In particular, <b>the</b> lower <b>the</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold,</b> <b>the</b> higher the sensitivity to edges. Too high <b>values</b> <b>of</b> <b>the</b> <b>threshold</b> do not detect edges which are important for quality assessment. On the other side, if <b>the</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> is too small, large parts <b>of</b> <b>the</b> image are considered as edges, whereas these are irrelevant for quality assessment. <b>The</b> <b>threshold</b> can be selected following an analysis <b>of</b> <b>the</b> gradient image histogram. Based on this consideration and on <b>the</b> analysis <b>of</b> Sobel filtering performance for <b>the</b> images <b>of</b> <b>the</b> considered databases, <b>the</b> selected <b>threshold</b> value is t = 0.001.|$|R
3000|$|FP are <b>the</b> <b>values</b> <b>of</b> <b>the</b> <b>threshold</b> in <b>the</b> case <b>of</b> NSCM and FP estimates, respectively. <b>The</b> <b>values</b> <b>of</b> λ [...]...|$|R
3000|$|... fa(η) for varying <b>values</b> <b>of</b> <b>the</b> <b>threshold.</b> To express <b>the</b> curve by {{a single}} value, the area under the ROC curve (AUC) is calculated. Based on this <b>value,</b> <b>the</b> {{performance}} <b>of</b> different VAD algorithms can be compared (optimal value AUC = 1). The ROC curve directly depends on the data and does not require further assumptions. Furthermore, AUC does not rely on a certain <b>value</b> <b>of</b> <b>the</b> <b>threshold.</b> To find an optimal <b>threshold</b> for <b>the</b> specific dataset, an optimization criterion has to be applied, e.g., P [...]...|$|R
40|$|In this paper, {{we propose}} an individual-difference model {{based on the}} models by Samejima(1969) and Andrich (1978 a), that can be {{effectively}} used {{in the analysis of}} ordered categorical responese. In this model each individual has his own <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> of categories with proportional intervals. The method of maximum likelihood estimation for the parameters in the model, using Fisher 2 ̆ 7 s scoring method, is presented. The advantage of the model is {{that it is possible to}} estimate the thresholds 2 ̆ 7 parameters even when an individual has no responses for some categories. Finally, an example is presented, in which the model provides productive findings...|$|E
40|$|A general {{method is}} {{proposed}} for predicting the asymptotic percolation threshold of networks with bottlenecks, in the limit that the sub-net mesh size goes to zero. The {{validity of this}} method is tested for bond percolation on filled checkerboard and "stack-of-triangle" lattices. Thresholds for the checkerboard lattices of different mesh sizes are estimated using the gradient percolation method, while for the triangular system they are found exactly using the triangle-triangle transformation. The <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> approach the asymptotic values of 0. 64222 and 0. 53993 respectively as the mesh is made finer, consistent with a direct determination based upon the predicted critical corner-connection probability. Comment: to appear, Physical Review E. Small changes from first versio...|$|E
40|$|Thresholding is {{a popular}} image {{segmentation}} method that converts gray-level image into binary image. The selection of optimum thresholds has remained a challenge over decades. In order to determine thresholds, most methods analyze the histogram of the image. The optimal thresholds are often found by either minimizing or maximizing an objective function {{with respect to the}} <b>values</b> <b>of</b> <b>the</b> <b>thresholds.</b> In this paper, a new intelligence algorithm, particle swarm opti-mization (PSO), is presented for multilevel thresholding in image segmentation. This algorithm is used to maximize the Kapur’s and Otsu’s objective functions. The performance of the PSO has been tested on ten sample images and it is found to be superior as compared with genetic algorithm (GA) ...|$|E
30|$|We {{assert that}} for <b>the</b> desired {{accuracy}} <b>of</b> <b>the</b> approximation (6) an offered load has to exceed a certain <b>threshold.</b> <b>The</b> concrete <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> {{is given by}} the following theorem.|$|R
40|$|We {{explored}} experimentally how threshold uncertainty affects coordination {{success in}} a threshold public goods game. Whereas all groups succeeded in providing the public good when <b>the</b> exact <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> was known, uncertainty was generally detrimental for the public good provision. <b>The</b> negative effect <b>of</b> <b>threshold</b> uncertainty was particularly severe when it took <b>the</b> form <b>of</b> ambiguity, i. e. when players were not only unaware <b>of</b> <b>the</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> but also <b>of</b> its probability distribution. Early signaling of willingness to contribute and share the burden equitably helped groups in coping with threshold uncertainty. [...] Public good,threshold uncertainty,ambiguity,experiment...|$|R
3000|$|... [...]. Thus, we obtain <b>the</b> best <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> and <b>the</b> {{corresponding}} feature {{component in}} the feature vector for one node at a time, and then move down to the next node.|$|R
30|$|In this paper, a novel {{algorithm}} is proposed {{to deal with the}} problem of blind recognition of linear STBCs in the MISO system. Utilizing the space-time redundancy, the original MISO model is transformed into a MIMO model by reconstructing the received samples. It is shown that the second- and higher-order statistics of the reconstructed receiver possess distinguishable features for different STBCs. Based on the high-dimensional feature space mapped by these features, an SVM-based classifier is trained to recognize the candidate STBCs without prior knowledge of CSI and modulation. Simulations show that the proposed method is capable of recognizing STBCs with high performance and robust to modulations. Future research will focus on the theoretical <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> for different features.|$|E
40|$|The aim of {{this paper}} is to derive an {{adaptive}} approach for track fusion in a multisensor environment. The measurements of two sensors tracking the same target are processed by linear Kalman Filters. The outputs of the local trackers are sent to the central node. In this node, a decision logic, which is based on the comparison between distance metrics and thresholds, selects the method to obtain the global estimate. Numerical simulations assess the influence of the thresholds and of the sensor noise ratio on the adaptive algorithm performance. The <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> govern the trade-o# between accuracy and computational burden. The main advantage of the adaptive fusion is its ability to react to changes in the system characteristics. Keywords: Track-to-Track Fusion, Multisensor, Adaptive Fusio...|$|E
40|$|Image {{thresholding}} is a {{very common}} image processing operation, since almost all image processing schemes need some sort of separation of the pixels into different classes. In {{order to determine the}} thresholds, most methods analyze the histogram of the image. The optimal thresholds are often found by either minimizing or maximizing an objective function with respect to the <b>values</b> <b>of</b> <b>the</b> <b>thresholds.</b> By defining two classes of objective functions for which the optimal thresholds can be found by efficient algorithms, this paper provides a framework for determining the solution approach for current and future multilevel thresholding algorithms. We show, for example, that the method proposed by Otsu and other well-known methods have objective functions belonging to these classes. By implementing the algorithms in ANSI C and comparing their execution times, we can also make quantitative statements about their performance...|$|E
30|$|To reduce {{possible}} server underutilization, PCS delays <b>the</b> service <b>of</b> streams only if <b>the</b> number <b>of</b> available server channels (freeChannels) {{is smaller}} than a certain threshold (freeChannelThresh). Algorithm 1 shows a proposed algorithm to dynamically find <b>the</b> best <b>value</b> <b>of</b> freeChannelThresh. <b>The</b> algorithm changes <b>the</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> and observes its impact on customer defection probability over a certain time interval. <b>The</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> is then updated based on the trend in defection probability (increase or decrease) and the last action (increase or decrease) performed on <b>the</b> <b>threshold.</b> <b>The</b> algorithm is to be executed periodically but not frequently to ensure stable system behavior.|$|R
30|$|Finally, we {{determine}} <b>the</b> sensitivity <b>of</b> {{our results}} to reductions <b>of</b> <b>the</b> sample {{due to the}} ‘minimum friends threshold’ by recalculating all Happiness Paradox magnitudes for <b>values</b> <b>of</b> <b>the</b> <b>threshold</b> ranging from 1 to 200.|$|R
30|$|There {{are nine}} EHV {{transmission}} {{lines in the}} power network, and each is modeled as a distributed parameter block with the following positive and negative sequence parameters: R[*]=[*] 0.0234  Ω/km, L[*]=[*] 95.1  mH/km, C[*]=[*] 1.24 uF/km. The zero sequence components <b>of</b> <b>the</b> line are: R 0 [*]=[*] 0.3885  Ω/km, L 0 [*]=[*] 3.25  mH/km, C 0 [*]=[*] 8.45  nF/km respectively. <b>The</b> <b>threshold</b> values were determined experimentally. <b>The</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> (τB) is 2.17 kA, whereas <b>the</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> (τi) is 0.43 kA. Furthermore, for a 1000 MVA, 400  kV system base, 0.3 p.u of current corresponds to 0.43 kA, and 1.5 p.u of current corresponds to 2.17 kA.|$|R
40|$|We {{study the}} {{threshold}} control protocol for a collective flashing ratchet. In particular, we analyze {{the dependence of}} the current on the <b>values</b> <b>of</b> <b>the</b> <b>thresholds.</b> We have found analytical expressions for the small threshold dependence both for the few and for the many particle case. For few particles the current is a decreasing function of the thresholds, thus, the maximum current is reached for zero thresholds. In contrast, for many particles the optimal thresholds have a nonzero finite value. We have numerically checked the relation that allows to obtain the optimal thresholds for {{an infinite number of}} particles from the optimal period of the periodic protocol. These optimal thresholds for an infinite number of particles give good results for many particles. In addition, they also give good results for few particles due to the smooth dependence of the current up to these threshold values. Comment: LaTeX, 10 pages, 7 figures, improved version to appear in Phys. Rev. ...|$|E
40|$|We {{introduce}} a multiple classifier system that incorporates a global optimization technique {{based on a}} Genetic Algorithm for dynamically selecting the set of experts {{to use in the}} majority vote approach. The proposed technique is applicable when the experts in the pool provide both the class assigned to the input sample and a measure of the reliability of the this classification. For each sample, the experts selected for participating in the majority vote are those whose reliability is larger than a given threshold. There are as many thresholds as the number of experts by the number of classes. The <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> aimed at selecting the best set of experts for each input sample are determined by a canonical Genetic Algorithm. The reliability measures provided by the experts of the pool are also used to implement the tie-break mechanism needed within the majority vote scheme. The system has been tested on a handwritten digit recognition problem, and its performance compared with those exhibited by other multiexpert systems exploiting different combining rules...|$|E
40|$|Abstract: Problem statement: Route {{maintenance}} and re-discovery are expensive in signaling and computation for routing in Vehicular Ad hoc Networks (VANETs). Hence it was desirable {{to choose the}} optimal route during the route selection phase. Approach: In this study, the threshold-based routing protocol β-wt uses the notion of threshold from variable precision rough sets. This protocol {{was used to evaluate}} routing performance on freeway scenarios in VANETs. A Traffic Generator tool IMPORTANT was used to obtain vehicular movement traces, that are then given as input to the Network Simulator NS 2. Results: Results of four performance metrics were got for different <b>values</b> <b>of</b> <b>the</b> <b>thresholds.</b> The performance of the new protocol was compared with that of the original Dynamic Source Routing (DSR). Conclusion: The new protocol performs better than DSR in Packet Delivery Ratio (PDR) and Normalized Routing Load (NRL). The study showed that variations in thresholds do not affect PDR and NRL, while for End to End Delay (EED) and Average Hop Count (AHC), certain values of these thresholds perform much better than other values in this particular VANET application...|$|E
3000|$|... {{was chosen}} to be 100 packets. During the time {{interval}} (125 [*]s– 175 [*]s) <b>the</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> (th) is decreased to 75 % of buffer occupancy in order to overcome any queue size oscillation.|$|R
3000|$|In {{order to}} {{investigate}} on <b>the</b> impact <b>of</b> <b>the</b> two factors T and V {{involved in the}} split criterion SpC, we present below the NS-SE relation for different <b>values</b> <b>of</b> α and β (0, 1, and 2), with different <b>values</b> <b>of</b> <b>the</b> <b>threshold</b> T [...]...|$|R
40|$|This paper {{outlines}} {{a theoretical}} framework to define <b>the</b> optimal notification <b>thresholds</b> so as to minimize <b>the</b> sum <b>of</b> Type I and Type II error costs. Results suggest that, when the notification rule takes into account in a cumulative way both <b>the</b> aggregate turnover <b>of</b> <b>the</b> merging parties and their individual turnover, <b>the</b> optimal <b>values</b> <b>of</b> these turnovers are interdependent. The model is then applied to the Italian case. <b>The</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> for <b>the</b> aggregate turnover has been obtained by benchmarking the rules set in the EU Member States through a simple econometric exercise. <b>The</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> for <b>the</b> individual turnover is then calculated applying the theoretical framework and <b>the</b> estimated costs <b>of</b> Type I and Type II errors...|$|R
40|$|We {{study the}} dynamic {{assignment}} of flexible servers to {{stations in the}} presence of setup costs that are incurred when servers move between stations. We focus on tandem lines with two stations and two servers with the goal of maximizing the long-run average profit. We investigate how the optimal server assignment policy for such systems depends on the magnitude of the setup costs, {{as well as on the}} homogeneity of servers and tasks. More specifically, for systems with either homogeneous servers or homogeneous tasks, small buffer sizes, and constant setup cost, we prove the optimality of “multiple threshold ” policies (where servers ’ movement between stations depends on both the number of jobs in the system and the locations of the servers) and determine the <b>values</b> <b>of</b> <b>the</b> <b>thresholds.</b> For systems with heterogeneous servers and tasks, small buffers, and constant setup cost, we provide results that partially characterize the optimal server assignment policy. Finally, for systems with larger buffer sizes and different service rate and setup cost configurations, we present structural results for the optimal policy and provide numerical results that strongly support the optimality of multiple threshold policies...|$|E
40|$|ABSTRACT The {{threshold}} laser fluence for {{the onset}} of surface melting is calculated for Ni films of different thicknesses and for a bulk Ni target using a combined atomistic-continuum computational model. The model combines the classical molecular dynamics (MD) method for simulation of non-equilibrium processes of lattice superheating and fast phase transformations with a continuum description of the laser excitation and subsequent relaxation of the conduction band electrons based on the two-temperature model (TTM). In the hybrid TTM-MD method, MD substitutes the TTM equation for the lattice temperature, and the diffusion equation for the electron temperature is solved simultaneously with MD integration of the equations of motion of atoms. The dependence of the threshold fluence on the film thickness predicted in TTM-MD simulations qualitatively agrees with TTM calculations, while the <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> for thick films and bulk targets are ∼ 10 % higher in TTM-MD. The quantitative differences between the predictions of TTM and TTM-MD demonstrate that the kinetics of laser melting {{as well as the}} energy partitioning between the thermal energy of atomic vibrations and energy of the collective atomic motion driven by the relaxation of the laser-induced pressure should be taken into account in interpretation of experimental results on surface melting. PACS 61. 80. Az; 64. 70. Dv; 02. 70. Ns...|$|E
40|$|Recently, it {{was shown}} {{that there is a}} phase {{transition}} in the community detection problem. This transition was first computed using the cavity method, and has been proved rigorously in the case of q= 2 groups. However, analytic calculations using the cavity method are challenging since they require us to understand probability distributions of messages. We study analogous transitions in so-called "zero-temperature inference" model, where this distribution is supported only on the most-likely messages. Furthermore, whenever several messages are equally likely, we break the tie by choosing among them with equal probability. While the resulting analysis does not give the correct <b>values</b> <b>of</b> <b>the</b> <b>thresholds,</b> it does reproduce some of the qualitative features of the system. It predicts a first-order detectability transition whenever q > 2, while the finite-temperature cavity method shows that this is the case only when q > 4. It also has a regime analogous to the "hard but detectable" phase, where the community structure can be partially recovered, but only when the initial messages are sufficiently accurate. Finally, we study a semisupervised setting where we are given the correct labels for a fraction ρ of the nodes. For q > 2, we find a regime where the accuracy jumps discontinuously at a critical value of ρ. Comment: 6 pages, 6 figure...|$|E
40|$|International audienceThe {{feasibility}} of bulk semiconductors subjected to strong periodic electric fields for terahertz radiation generation {{due to the}} high-order harmonic extraction is analyzed by using Monte Carlo simulations. The high-order harmonic intensity and <b>the</b> spectral density <b>of</b> velocity fluctuations are calculated for GaAs, InP, and InN. By comparing the harmonic intensity with the noise level <b>the</b> <b>threshold</b> bandwidth for high-order harmonic extraction determined by their ratio is introduced and evaluated for the above materials. The results show that semiconductor materials with a high <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> field for <b>the</b> Gunn-effect are characterized by a high <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> bandwidth under high-order harmonic generation and, hence, they are promising materials for microwave generation in the THz frequency range by high-order harmonic extraction...|$|R
30|$|We discuss {{below the}} notions {{involved}} and <b>the</b> explicit <b>values</b> <b>of</b> <b>the</b> <b>threshold</b> parameters λ _*, λ _**, and λ _***. Key is <b>the</b> following notion <b>of</b> Hardy interior mass associated to the operator -Δ -γ/|x|^ 2 -λ on a bounded domain Ω containing 0.|$|R
3000|$|Note {{that the}} {{previous}} description applies to strategies E 3, E 4, and E 5 under the following considerations: (i) When no new data sessions are allowed to be queued in the buffer, as in strategy E 4, <b>the</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> Q [...]...|$|R
40|$|From {{anomalies}} {{of daily}} data of maximum and minimum temperatures, {{that have been}} obtained as difference between the real data of every day and the average data of the corresponding {{day of the year}} in each of the 14 observatories of the Spanish Central Plateau (8 in North subplateau and 6 in the South subplateau) between 1961 - 2010, the extremely cold and warm days are determined, throughout all the year, in all the study area and the two different sub areas. We consider a day as an extremely cold day (ECD) if achieves simultaneously the following conditions: the anomaly of minimum temperature of the day is lower than the value of the P 05 percentile of the series of daily anomalies of minimum temperature, and the value of the anomaly of daily maximum temperature is lower, as well, than the P 05 percentile of the corresponding series of anomalies. The <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> determined by these percentiles are obtained considering the complete anomalies daily series of temperature for all the study regions. In order to establish the extremely warm days the methodology is the same but the conditions are: the anomaly of minimum temperature of the day is greater than the value of the P 95 percentile of the series of daily anomalies of minimu...|$|E
40|$|The {{inhibition}} that is exerted mutually among receptor units (ommatidia) of {{the compound}} eye of Limulus is less for units widely separated than for those close together. This diminution of inhibition with distance is the resultant of two factors: (1) the threshold of inhibitory action increases with increasing distance between the units involved; and (2) the coefficient of inhibitory action decreases with increasing distance. The discharge of nerve impulses from ommatidia at various distances from one another may be described quantitatively {{by a set of}} simultaneous linear equations which express the excitatory effects of the illumination on each ommatidium and the inhibitory interactions between each ommatidium and its neighbors. The <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> and coefficients of inhibitory action, which appear as parameters in these equations, must be determined empirically: their dependence on distance is somewhat irregular and cannot yet be expressed in an exact general law. Nevertheless the diminution of inhibitory influences with distance is sufficiently uniform that patterns of neural response generated by various patterns of illumination on the receptor mosaic can be predicted qualitatively. Such predictions have been verified experimentally for two simple patterns of illumination: an abrupt step in intensity, and a simple gradient between two levels of intensity (the so-called Mach pattern). In each case, transitions in the pattern of illumination are accentuated in the corresponding pattern of neural response...|$|E
30|$|The <b>values</b> <b>of</b> <b>the</b> <b>thresholds</b> δ _ 1, δ _ 2, δ _ 3 and δ _ 4 {{are highly}} {{influenced}} by {{the accuracy of the}} historical data and the precision of the location device; when they are appropriate, they reduce the interference of NLOS and improve the location accuracy overall. We conducted several experiments yielding a large amount of measured data which were used to get location results by the three algorithms (Chan, Taylor, and Kalman). δ _ 1 and δ _ 2 first determined by the residual sum of squares of the location results of Chan and Taylor separately. δ _ 3 and δ _ 4 first determined by the difference value between the mean value of the residual sum of squares of the location results of Taylor and Kalman. Then adjusted the threshold values according to the actual effect. Finally, the thresholds were set by the following principles iteratively and verified according to the accuracy of the location results. (1) δ _ 1 is set as large as possible to filter the measurements with large error and reduce the calculation amount of the Taylor algorithm. (2) δ _ 2 is set carefully to discard the measurements which suffer from excessive NLOS. Otherwise, the accuracy of the whole method would be severely affected. (3) δ _ 3 and δ _ 4 validate whether the measurements meet the necessary criteria, then measurements suffering excessive NLOS are further discarded.|$|E
40|$|Many {{natural systems}} involve {{thresholds}} that, once triggered, imply irreversible damages for the users. Although <b>the</b> existence <b>of</b> such <b>thresholds</b> is undisputed, their location is highly uncertain. We explore experimentally how threshold uncertainty affects collective {{action in a}} series of threshold public goods games. Whereas the public good is always provided when <b>the</b> exact <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> is known, threshold uncertainty is generally detrimental for the public good provision as contributions become more erratic. <b>The</b> negative effect <b>of</b> <b>threshold</b> uncertainty is particularly severe when it takes <b>the</b> form <b>of</b> ambiguity, i. e. when players are not only unaware <b>of</b> <b>the</b> <b>value</b> <b>of</b> <b>the</b> <b>threshold,</b> but also <b>of</b> its probability distribution. Early and credible commitment helps groups to cope with uncertainty...|$|R
30|$|When we {{estimate}} the model with all possible <b>values</b> <b>of</b> <b>the</b> <b>threshold</b> variable (TGap), <b>the</b> estimator for <b>the</b> <b>threshold</b> value should correspond to that yielding <b>the</b> smallest sum <b>of</b> squared errors (SSE). As for the double-threshold model, {{we should take}} the following three-stage regressions and obtain <b>the</b> two <b>threshold</b> values.|$|R
30|$|Each {{method has}} its {{advantages}} and disadvantages. The first method ensures a good quality of recommendations because queries {{that do not}} respect a defined threshold of similarity will be directly eliminated. However, this method may give an empty set <b>of</b> recommendations if <b>the</b> defined <b>value</b> <b>of</b> <b>the</b> <b>threshold</b> similarity is high.|$|R
