526|483|Public
25|$|The Alpha has a 64-bit linear <b>virtual</b> <b>address</b> {{space with}} no memory segmentation. Implementations can {{implement}} a smaller <b>virtual</b> <b>address</b> {{space with a}} minimum size of 43 bits. Although the unused bits were not implemented in hardware such as TLBs, the architecture required implementations to check whether they are zero to ensure software compatibility with implementations with a larger (or full) <b>virtual</b> <b>address</b> space.|$|E
25|$|The kernel has {{full access}} to the system's memory and must allow {{processes}} to safely access this memory as they require it. Often {{the first step in}} doing this is virtual addressing, usually achieved by paging and/or segmentation. Virtual addressing allows the kernel to make a given physical address appear to be another address, the <b>virtual</b> <b>address.</b> <b>Virtual</b> <b>address</b> spaces may be different for different processes; the memory that one process accesses at a particular (<b>virtual)</b> <b>address</b> may be different memory from what another process accesses at the same address. This allows every program to behave as if it is the only one (apart from the kernel) running and thus prevents applications from crashing each other.|$|E
25|$|New {{address mapping}} scheme called Rotate <b>Virtual</b> <b>Address</b> Descriptors (VAD). It {{is used for}} the {{advanced}} Video subsystem.|$|E
50|$|A page {{table is}} the data {{structure}} {{used by a}} virtual memory system in a computer operating system to store the mapping between <b>virtual</b> <b>addresses</b> and physical <b>addresses.</b> <b>Virtual</b> <b>addresses</b> are used by the accessing process, while physical addresses are used by the hardware, or more specifically, by the RAM subsystem.|$|R
5000|$|... : User mode <b>virtual</b> <b>addresses</b> {{are passed}} to the driver without mapping or validation.|$|R
50|$|In computing, an {{input-output}} {{memory management}} unit (IOMMU) is a {{memory management unit}} (MMU) that connects a direct-memory-access-capable (DMA-capable) I/O bus to the main memory. Like a traditional MMU, which translates CPU-visible <b>virtual</b> <b>addresses</b> to physical addresses, the IOMMU maps device-visible <b>virtual</b> <b>addresses</b> (also called device addresses or I/O addresses in this context) to physical addresses. Some units also provide memory protection from faulty or malicious devices.|$|R
25|$|For 64-bit PowerPC processors, the <b>virtual</b> <b>address</b> {{resides in}} the {{rightmost}} 64 bits of a pointer while it was 48 bits in the S/38 and CISC AS/400. The 64-bit address space references main memory and disk as a single address set which is the single-level storage concept.|$|E
25|$|In some cases, a {{page fault}} may {{indicate}} a software bug, {{which can be}} prevented by using memory protection as one of key benefits of an MMU: an operating system {{can use it to}} protect against errant programs by disallowing access to memory that a particular program should not have access to. Typically, an operating system assigns each program its own <b>virtual</b> <b>address</b> space.|$|E
25|$|Randomization of {{the virtual}} memory {{addresses}} at which functions and variables can be found can make exploitation of a buffer overflow more difficult, but not impossible. It also forces the attacker to tailor the exploitation attempt to the individual system, which foils the attempts of internet worms. A similar but less effective method is to rebase processes and libraries in the <b>virtual</b> <b>address</b> space.|$|E
50|$|Later Xanadu {{designs are}} more indirect: a growing pool of sharable content pieces, called the istream (invariant stream) is {{organized}} into the documents, links and versions - all with <b>virtual</b> <b>addresses</b> - that the users see and work on. A collection of enfilade types manages the bi-directional mapping between <b>virtual</b> and istream <b>addresses.</b> Tracing correspondences and links between documents {{is made possible}} by mapping from virtual, to invariant, and back to <b>virtual</b> <b>addresses.</b> Storing documents using shared content pieces that remember their identities and can trace back to all their appearances, is called Transclusion.|$|R
25|$|Memory {{translation}} from 48-bit <b>virtual</b> <b>addresses</b> {{based on}} the existing Large Physical Address Extension (LPAE), {{which was designed to}} be easily extended to 64-bit.|$|R
50|$|Addresses in the ODT {{debugger}} are 16 bit <b>virtual</b> <b>addresses</b> in {{the mode}} in which ODT is operating, not the physical addresses used with console ODT.|$|R
25|$|V60-V80 had a {{built-in}} MMU that divide the 4 GB <b>virtual</b> <b>address</b> space into in four 1-GB sections, each section further divided in 1,024 1-MB areas, each area composed of 256 4-KB pages. On the V60/V70 four registers (ATBR0 to ATBR3) store section pointers on the processor, but the area tables entries (ATE) and page tables entries (PTE) {{are stored in}} RAM (off-chip). The V80 merged the ATE and ATBR registers, which are both on-chip with only the PTE entries stored in RAM, allowing for a faster execution of TLB misses by eliminating one memory read.|$|E
25|$|Since shared {{libraries}} on most {{systems do}} not change often, systems can compute a likely load address for each shared library on the system before it is needed, and store that information in the libraries and executables. If every shared library that is loaded has undergone this process, then each will load at its predetermined address, which speeds up the process of dynamic linking. This optimization is known as prebinding in macOS and prelinking in Linux. Disadvantages of this technique include {{the time required to}} precompute these addresses every time the shared libraries change, the inability to use address space layout randomization, and the requirement of sufficient <b>virtual</b> <b>address</b> space for use (a problem that will be alleviated by the adoption of 64-bit architectures, {{at least for the time}} being).|$|E
25|$|On many systems, a program's <b>virtual</b> <b>address</b> may {{refer to}} data {{which is not}} {{currently}} in memory. The layer of indirection provided by virtual addressing allows the operating system to use other data stores, like a hard drive, to store what would otherwise have to remain in main memory (RAM). As a result, operating systems can allow programs to use more memory than the system has physically available. When a program needs data which is not currently in RAM, the CPU signals to the kernel that this has happened, and the kernel responds by writing the contents of an inactive memory block to disk (if necessary) {{and replacing it with}} the data requested by the program. The program can then be resumed from the point where it was stopped. This scheme is generally known as demand paging.|$|E
5000|$|Used to {{translate}} <b>virtual</b> <b>addresses</b> to physical addresses. Contains {{the size and}} number of segments, the root location of the page table and the address space number.|$|R
5000|$|Dynamic Address Translation (DAT) {{with support}} for 24 or 32-bit <b>virtual</b> <b>addresses</b> using segment and page tables (up to 16 {{segments}} each containing up to 256 4096 byte pages) ...|$|R
50|$|A set {{of memory}} map {{registers}} {{is used to}} map <b>virtual</b> <b>addresses</b> to physical. There are eight memory map registers, each mapping 2K words, to provide an address space of 16K.|$|R
25|$|To {{maintain}} {{compatibility with}} older operating systems and applications, the 640 KB barrier remained {{part of the}} PC design even after the 8086/8088 had been replaced with the Intel 286 processor, which could address up to 16 MB of memory in Protected mode. The 1 MB barrier also remained {{as long as the}} 286 was running in Real mode, since DOS required Real mode which uses the segment and offset registers in an overlapped manner such that addresses with more than 20 bits are not possible. It is still present in IBM PC compatibles today if they are running in Real mode such as used by DOS. Even the most modern Intel PCs still have the area between 640 and 1024 KB reserved. This however is invisible to programs (or even most of the operating system) on newer operating systems (such as Windows, Linux, or Mac OS X) that use virtual memory, because they have no awareness of physical memory addresses at all. Instead they operate within a <b>virtual</b> <b>address</b> space, which is defined independently of available RAM addresses.|$|E
2500|$|MIPS32 and MIPS32r2 support 32 bits of <b>virtual</b> <b>address</b> {{space and}} up to 36 bits of {{physical}} address space. [...] MIPS64 supports up to 64 bits of <b>virtual</b> <b>address</b> space {{and up to}} 59 bits of physical address space.|$|E
2500|$|Starting in August, 1972, the IBM System/370 had {{a similar}} MMU, {{although}} it initially supported only a 24-bit <b>virtual</b> <b>address</b> space rather than the 32-bit <b>virtual</b> <b>address</b> space of the System/360 Model 67. [...] It also stored the accessed and dirty bits outside the page table. [...] In early 1983, the System/370-XA architecture expanded the <b>virtual</b> <b>address</b> space to 31 bits, and in 2000, the 64-bit z/Architecture was introduced, with the address space expanded to 64 bits; those continued to store the accessed and dirty bits outside the page table.|$|E
5000|$|Based on z/Architecture (64-bit {{real and}} <b>virtual</b> <b>addresses),</b> {{as opposed to}} earlier ESA/390 (31-bit) used in S/390 systems yet {{emphasizing}} the backwards compatibility the ESA/390 applications are fully compatible with z/Architecture ...|$|R
5000|$|TSS {{provided}} an early implementation of [...] "position-independent code", {{the ability to}} have different processes run a single copy of an executable possibly mapped to a different <b>virtual</b> <b>addresses</b> in each process.|$|R
50|$|Virtual memory systems {{abstract}} {{between physical}} RAM and <b>virtual</b> <b>addresses,</b> assigning <b>virtual</b> memory <b>addresses</b> both to physical RAM and to disk-based storage, expanding addressable memory, {{but at the}} cost of speed. NUMA and SMP architectures optimize memory allocation within multi-processor systems. While these technologies dynamically manage memory within individual computers, memory virtualization manages the aggregated memory of multiple networked computers as a single memory pool.|$|R
2500|$|The context {{register}} {{was important}} in a multitasking operating system because it allowed the CPU to switch between processes without reloading all the translation state information. [...] The 4-bit context register could switch between 16 sections of the segment map under supervisor control, which allowed 16 contexts to be mapped concurrently. [...] Each context had its own <b>virtual</b> <b>address</b> space. [...] Sharing of <b>virtual</b> <b>address</b> space and inter-context communications {{could be provided by}} writing the same values in to the segment or page maps of different contexts. [...] Additional contexts could be handled by treating the segment map as a context cache and replacing out-of-date contexts on a least-recently used basis.|$|E
2500|$|A child {{partition}} {{does not}} have access to the physical processor, nor does it handle its real interrupts. Instead, it has a virtual view of the processor and runs in Guest <b>Virtual</b> <b>Address,</b> which, depending on the configuration of the hypervisor, might not necessarily be the entire <b>virtual</b> <b>address</b> space. Depending on VM configuration, Hyper-V may expose only a subset of the processors to each partition. The hypervisor handles the interrupts to the processor, and redirects them to the respective partition using a logical Synthetic Interrupt Controller (SynIC). [...] Hyper-V can hardware accelerate the address translation of Guest Virtual Address-spaces by using second level address translation provided by the CPU, referred to as EPT on Intel and RVI (formerly NPT) on AMD.|$|E
2500|$|Modern MMUs {{typically}} {{divide the}} <b>virtual</b> <b>address</b> space (the range of addresses {{used by the}} processor) into pages, each having a size which is a power of 2, usually a few kilobytes, {{but they may be}} much larger. [...] The bottom bits of the address (the offset within a page) are left unchanged. The upper address bits are the virtual page numbers.|$|E
50|$|In the Intel 80386 and later, {{protected}} mode retains the segmentation mechanism of 80286 {{protected mode}}, but a paging unit {{has been added}} as a second layer of address translation between the segmentation unit and the physical bus. Also, importantly, address offsets are 32-bit (instead of 16-bit), and the segment base in each segment descriptor is also 32-bit (instead of 24-bit). The general operation of the segmentation unit is otherwise unchanged. The paging unit may be enabled or disabled; if disabled, operation {{is the same as}} on the 80286. If the paging unit is enabled, addresses in a segment are now <b>virtual</b> <b>addresses,</b> rather than physical addresses as they were on the 80286. That is, the segment starting address, the offset, and the final 32-bit address the segmentation unit derived by adding the two are all <b>virtual</b> (or logical) <b>addresses</b> when the paging unit is enabled. When the segmentation unit generates and validates these 32-bit <b>virtual</b> <b>addresses,</b> the enabled paging unit finally translates these <b>virtual</b> <b>addresses</b> into physical addresses. The physical addresses are 32-bit on the 386, but can be larger on newer processors which support Physical Address Extension.|$|R
5000|$|The Intel {{white paper}} [...] "5-Level Paging and 5-Level EPT" [...] {{describe}} a mechanism, under development by Intel, {{that will allow}} Intel 64 processors to support 57-bit <b>virtual</b> <b>addresses,</b> with an additional page table level.|$|R
5000|$|The data TLB has {{two copies}} which keep {{identical}} entries. The two copies allow two data accesses per cycle to translate <b>virtual</b> <b>addresses</b> to physical addresses. Like the instruction TLB, this TLB is {{split into two}} kinds of entries.|$|R
2500|$|The MIPS {{architecture}} supports one to 64 {{entries in}} the TLB. [...] The number of TLB entries is configurable at CPU configuration before synthesis. [...] TLB entries are dual. [...] Each TLB entry maps a virtual page number (VPN2) to either one of two page frame numbers (PFN0 or PFN1), depending on the least significant bit of the <b>virtual</b> <b>address</b> that {{is not part of}} the page mask. [...] This bit and the page mask bits are not stored in the VPN2. [...] Each TLB entry has its own page size, which can be any value from [...] to [...] in multiples of four. [...] Each PFN in a TLB entry has a caching attribute, a dirty and a valid status bit. [...] A VPN2 has a global status bit and an OS assigned ID which participates in the <b>virtual</b> <b>address</b> TLB entry match, if the global status bit is set to zero. [...] A PFN stores the physical address without the page mask bits.|$|E
2500|$|A TLB refill {{exception}} is generated {{when there are}} no entries in the TLB that match the mapped <b>virtual</b> <b>address.</b> [...] A TLB invalid {{exception is}} generated when there is a match but the entry is marked invalid. [...] A TLB modified exception is generated when there is a match but the dirty status is not set. [...] If a TLB exception occurs when processing a TLB exception, a double fault TLB exception, it is dispatched to its own exception handler.|$|E
2500|$|The CPU {{primarily}} divides memory into [...] pages. [...] Segment registers, {{fundamental to}} the older 8088 and 80286 MMU designs, are not used in modern OSes, with one major exception: access to thread-specific data for applications or CPU-specific data for OS kernels, which is done with explicit use of the FS and GS segment registers. All memory access involves a segment register, chosen according to the code being executed. The segment register acts as an index into a table, which provides an offset {{to be added to}} the <b>virtual</b> <b>address.</b> Except when using FS or GS, the OS ensures that the offset will be zero.|$|E
3000|$|... from m' will be {{returned}} (with a given non negligible probability). We emphasize that the definition above {{is focused on the}} searching problem (which is the tough task here): the algorithms' outputs are the <b>virtual</b> <b>addresses</b> where the retriever [...]...|$|R
50|$|In {{computer}} engineering a load-store unit is a specialized execution unit responsible for executing all load and store instructions, generating <b>virtual</b> <b>addresses</b> of load and store operations and loading data from memory or storing {{it back to}} memory from registers.|$|R
5000|$|Large {{regions of}} memory can be {{allocated}} {{without the need}} to be contiguous in physical memory the IOMMU maps contiguous <b>virtual</b> <b>addresses</b> to the underlying fragmented physical addresses. Thus, the use of vectored I/O (scatter-gather lists) can sometimes be avoided.|$|R
