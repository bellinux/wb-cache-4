886|963|Public
50|$|In {{addition}} to the Architects Registration Board, the RIBA provides accreditation to architecture schools in the UK under a course <b>validation</b> <b>procedure.</b> It also provides validation to international courses without input from the ARB.|$|E
50|$|There are no firm industry-wide {{rules for}} {{establishing}} minimum RFU threshold values. Each laboratory, in general, has established its own threshold levels as {{one aspect of}} its particular <b>validation</b> <b>procedure.</b> Many laboratories have established both lower and upper thresholds for data interpretation, as a window of minimum and maximum readings.|$|E
50|$|Grid search then trains an SVM {{with each}} pair (C, γ) in the Cartesian product {{of these two}} sets and evaluates their {{performance}} on a held-out validation set (or by internal cross-validation on the training set, in which case multiple SVMs are trained per pair). Finally, the grid search algorithm outputs the settings that {{achieved the highest score}} in the <b>validation</b> <b>procedure.</b>|$|E
40|$|The use {{of social}} <b>validation</b> <b>procedures</b> has become {{widespread}} in recent years. Although most researchers have used social <b>validation</b> <b>procedures</b> to select target behaviors and {{to evaluate whether}} the changes produced by a treatment program should be considered socially useful, {{little attention has been}} focused upon using the social validation process to determine the optimal levels for target behaviors. This paper suggests several ways in which social <b>validation</b> <b>procedures</b> can be employed in order to select when and how much to change target behaviors...|$|R
40|$|Abstract. This paper {{provides}} {{a discussion on}} <b>validation</b> <b>procedures</b> associated with heuristic solution approaches used in forest planning, initiated by Bettinger et al. (2008) (Bettinger, Sessions and Boston, 2008. A review of the status and use of <b>validation</b> <b>procedures</b> for heuristics used in forest planning. MCFNS 1 (1) : 26 – 37). Three issues are addressed...|$|R
40|$|This {{document}} {{establishes the}} guidelines for method selection and the procedures for verification of standard method performance, {{as well as the}} validation of non-standard methods. ORA laboratories verify standard method performance and validate nonstandard methods introduced into the laboratory. A. Directors: ensures implementation of method verification and <b>validation</b> <b>procedures.</b> B. Supervisors: implements method verification and <b>validation</b> <b>procedures</b> in respective division. C. Staff: adheres to written protocol for method performance verification, validation or modification...|$|R
5000|$|Product {{activation}} is {{a license}} <b>validation</b> <b>procedure</b> required by some proprietary computer software programs. Product activation prevents unlimited free use of copied or replicated software. Unactivated software refuses to fully function until it determines {{whether it is}} authorized to fully function. Activation allows the software to stop blocking its use. An activation can last [...] "forever", or it can have a time limit, requiring a renewal or re-activation for continued use.|$|E
50|$|The {{most active}} IMA {{commission}} is the Commission on New Minerals and Mineral Names (CNMMN). It {{was founded in}} 1959 to coordinate the assigning of new mineral names, revision of existing names and discreditation of invalid species. Traditionally, the <b>validation</b> <b>procedure</b> of new minerals {{is one of the}} chairman's tasks and the discreditation or revalidation procedure of invalid species are two of the vice-chairman's tasks. In July 2006 a merger between the CNMMN and the Commission on Classification of Minerals (CCM), initiated at the request of both commissions, resulted in the Commission on New Minerals, Nomenclature and Classification (CNMNC).|$|E
5000|$|Debt Validation, or [...] "debt verification", {{refers to}} a consumer's right to {{challenge}} a debt and/or receive written verification of a debt from a debt collector. The right to dispute the debt and receive validation {{are part of the}} consumer's rights under the United States Federal Fair Debt Collection Practices Act (FDCPA) and are set out in §809 of that act, which has been codified in Title 15, Section 1692-1692p of the United States Code. This debt <b>validation</b> <b>procedure</b> was expectedto reduce the incidence of debt collectors dunning the wrong person or attempting to collect previously paid debts.|$|E
40|$|AbstractResearches {{related to}} {{motivation}} and mathematics achievement indicate that academic intrinsic math motivation {{is related to}} mathematics achievement (Yıldırım, 2011; Gottfried et al., 2007). For this reason there is need for a scale to measure the motivation related to mathematics achievement. During the scale carrying out process, less-known but more effective validated procedures are used. The {{aim of this study}} is carrying out a reliability and validity study for a scale which assess the motivation related to mathematics achievement. In this research, the scale is applied to 6 th, 7 th, 8 th grade students, the data obtained is analyzed for the validity and reliability studies of the scale. However the most frequently used statistical methods are eigenvalues-greater-than-one-rule and scree plot, Velicer's Map Test (1986) and Parallel analysis are used as less-known validated <b>procedures</b> in structural <b>validation</b> studies (O’Connor, 2000). In addition to those less-known <b>validation</b> <b>procedures,</b> confirmatory factor analysis is used to compare the results of <b>validation</b> <b>procedures.</b> Results show that the reliability of this scale is satisfying. Moreover, the findings of confirmatory factor analysis are similar to the findings of less-known <b>validation</b> <b>procedures</b> determined below. As a result of this research the validity and reliability value of the scale are provided. Findings show that the less-known <b>validation</b> <b>procedures</b> give stronger statistical results than the popular analyses procedures given below. That's why those <b>validation</b> <b>procedures</b> should be used for the development of this kind of scales...|$|R
40|$|The {{problem of}} {{assessing}} {{the value of}} mathematical models in physiology and medicine is considered. The role of validation within the modeling process is clearly defined. An appropriate vocabulary and <b>validation</b> <b>procedures</b> to be adopted are outlined for simple and complex models, with these two classes defined operationally {{on the basis of}} theoretical identifiability. Some examples illustrating these <b>validation</b> <b>procedures</b> are briefly discussed. It is shown that simple and complex models each have a role both in physiology and clinical application when properly validated...|$|R
5000|$|It is {{important}} that a knowledge engineer incorporates <b>validation</b> <b>procedures</b> into their systems within the program code. After the knowledge-based system is constructed, it can be maintained by the domain expert [...]|$|R
5000|$|Where [...] {{is the sum}} of squared {{prediction}} errors. These {{errors are}} estimated based on cross validation. In the cross <b>validation</b> <b>procedure,</b> the set of support points is mapped to [...] subsets. Then the approximation model is built by removing subset [...] from the support points and approximating the subset model output [...] using the remaining point set. This means that the model quality is estimated only at those points which are not used to build the approximation model. Since the prediction error is used instead of the fit, this approach applies to regression and even interpolation models.|$|E
3000|$|... {{parameter}} of the kernel with a leave-one-out cross-validation procedure. According to {{the results}} of cross <b>validation</b> <b>procedure</b> [...]...|$|E
40|$|A {{critical}} {{discussion of}} the in-house <b>validation</b> <b>procedure</b> presents the benefits of an application of a capillary electrophoresis (CE) method in aqueous process samples consisting of various types of carbohydrates. This study emphasized the complexity of CE via <b>validation</b> <b>procedure,</b> {{in the case of}} heterogeneous processes. An in-house <b>validation</b> <b>procedure</b> of a capillary electrophoretic method aiming at analysis of aqueous process samples with heterogeneous matrices was evaluated. The validation parameters were discussed through an example case of a CE method, developed for the determination of saccharose, glucose and polydatin, applied in calibration solutions and process samples. The validation data was used in evaluation of uncertainty components. The results from the in-house <b>validation</b> <b>procedure</b> showed that the most critical parameter in the determination of uncertainty was repeatability. Selectivity and reproducibility are also critical, particularly in the case of analyzing heterogeneous samples with changing composition. Especially in process analytical applications the evaluation of uncertainty factors was concluded to be essential, as in addition to process conditions the sample composition itself caused variation...|$|E
5|$|Also in 1988, {{a chapter}} titled Modelling Human Exposure to Altered Pressure Environments, by T.R. Hennessy was {{published}} in Environmental Ergonomics, discussing the shortcomings of several decompression models and the associated experimental <b>validation</b> <b>procedures.</b>|$|R
50|$|The {{foundation}} {{should be}} laid strong and firm. primary, upper primary {{and middle school}} should provide the space for children to explore and develop rational thinking that they would imbibe in them and have sufficient knowledge of concepts, language, knowledge, investigation and <b>validation</b> <b>procedures.</b>|$|R
40|$|Some <b>validation</b> <b>procedures</b> are {{presented}} concerning the physicis and the biology, {{as well as}} the decomposition of the oxygen cycle in its different components. The role of the Sevastopol eddy of retaining POM in the Crimea peninsula causing intense bacterial oxygen consumption is evidenced. Peer reviewe...|$|R
40|$|In this paper, an {{experimental}} <b>validation</b> <b>procedure</b> {{is applied to}} an improved one-dimensional model of fuel additive assisted regeneration of a diesel particulate filter. Full-scale tests on an engine bench of the regeneration behaviour of a diesel filter fitted to a modern diesel engine run on catalyst-doped fuel are employed for this purpose. The main objectives of the <b>validation</b> <b>procedure</b> concern {{the ability of the}} model to predict the effects of exhaust mass flowrate, initial soot loading mass, volatile organic fraction of the soot and additive concentration in the fuel. The results of the <b>validation</b> <b>procedure</b> are intended to demonstrate the scope and extent of applicability of models of this type to real-world design and optimization studies with diesel filters...|$|E
40|$|RPKI Validation Reconsidered draft-huston-rpki-validation- 00. txt This {{document}} {{reviews the}} certificate <b>validation</b> <b>procedure</b> specified in RFC 6487 and highlights aspects of operational management of certificates in the RPKI {{in response to}} the movement of resources across registries, and the associated actions of Certification Authorities to maintain certification of resources during this movement. The document describes an alternative <b>validation</b> <b>procedure</b> that reduces the operational impact of certificate management during resource movement. Status of this Memo This Internet-Draft is submitted in full conformance with th...|$|E
30|$|Futures Maps are {{generated}} for actors and their decision making. The <b>validation</b> <b>procedure</b> with Futures Maps serves {{in this way}} decision making and action focus of the standard 1.4.|$|E
30|$|In the {{following}} sections, we start by introducing the experimental setup and the processing {{used to obtain}} ZTD and GNSS-derived PWV time series from the GNSS and meteorological data. The internal and external <b>validation</b> <b>procedures</b> follow, and {{the analysis of the}} PWV variations and final considerations conclude the paper.|$|R
40|$|The {{crisis in}} the {{reproducibility}} of experiments invites a re-evaluation of methods of inquiry and <b>validation</b> <b>procedures.</b> The text challenges current assumptions of knowledge acquisition and introduces G-complexity for defining decidable vs. non-decidable knowledge domains. A "second Cartesian revolution" should result in scientific methods that transcend determinism and reductionism...|$|R
40|$|The use of {{recursive}} lattice filters {{for identification}} and adaptive control of large space structures is studied. Lattice filters {{were used to}} identify the structural dynamics model of the flexible structures. This identification model is then used for adaptive control. Before the identified model and control laws are integrated, the identified model is passed {{through a series of}} <b>validation</b> <b>procedures</b> and only when the model passes these <b>validation</b> <b>procedures</b> is control engaged. This type of validation scheme prevents instability when the overall loop is closed. Another important area of research, namely that of robust controller synthesis, was investigated using frequency domain multivariable controller synthesis methods. The method uses the Linear Quadratic Guassian/Loop Transfer Recovery (LQG/LTR) approach to ensure stability against unmodeled higher frequency modes and achieves the desired performance...|$|R
40|$|Park et al. 1 In the {{application}} of microscopic simulation models, the importance of model calibration and validation cannot be overemphasized. A recent study proposed a systematic approach of conducting simulation model calibration and <b>validation</b> <b>procedure</b> {{on the basis of}} experimental design and optimization, and applied it to an isolated intersection using a VISSIM simulation model. This study further evaluates the previously developed simulation model calibration and <b>validation</b> <b>procedure</b> using an urban arterial network consisted of 12 coordinated actuated signalized intersections. Both VISSIM and CORSIM simulation models were used. Travel time was used for calibration measure, while maximum queue length was used for validation measure. The study results showed that the calibrated and validated simulation models were able to adequately represent field conditions while default parameter based models were not. As such the previously developed simulation model calibration and <b>validation</b> <b>procedure</b> was proven to be effective for an arterial network under both VISSIM and CORSIM simulation models. Park et al. ...|$|E
30|$|We also {{explored}} {{alternative approaches}} to derive an empirical classification of graduate jobs (see Green and Henseke 2014 for details). These fared only slightly {{worse in the}} <b>validation</b> <b>procedure</b> than SOC(HE)_GH.|$|E
40|$|In this paper, {{we present}} and apply a {{computer-assisted}} method to study steady states of a triangular cross-diffusion system. Our approach consist in an a posteriori <b>validation</b> <b>procedure,</b> {{that is based}} on using a fxed point argument around a numerically computed solution, {{in the spirit of the}} Newton-Kantorovich theorem. It allows us to prove the existence of various non homogeneous steady states for different parameter values. In some situations, we get as many as 13 coexisting steady states. We also apply the a posteriori <b>validation</b> <b>procedure</b> to study the linear stability of the obtained steady states, proving that many of them are in fact unstable...|$|E
40|$|The multitrait-multimethod matrix {{approach}} {{as proposed by}} Campbell and Fiske (1959) was {{an important contribution to}} our understanding of the nature of <b>validation</b> <b>procedures.</b> There are, however, problems encountered when using the Campbell and Fiske (1 959) approach. The purpose of this article is to discuss the method and selected problems, and to propose an alternate approach to address those problems. Campbell and Fiske (1959) provided important insights into the nature of <b>validation</b> <b>procedures.</b> In particular, they proposed the multitrait-mul-timethod matrix (MTMM matrix) as a way to assess convergent and discriminant validity as well as to estimate the effect of method variance on validity assessments. However, there are problems with the traditional bivariate analysis of the MTMM matrix that may severely limit the utility of the method. The purpose of this article is to discus...|$|R
5000|$|<b>Validation</b> of <b>Procedures</b> for Monitoring Crewmember Immune Function (Integrated_Immune) ...|$|R
40|$|Software {{added to}} {{compiler}} for automated test system for Space Shuttle decreases computer run errors by providing offline validation of engineering units used system command programs. <b>Validation</b> <b>procedures</b> are general, though originally written for GOAL, a free-form language that accepts "English-like" statements, {{and may be}} adapted to other programming languages...|$|R
40|$|This paper employs {{previously}} developed modeling, validation, and stimulation {{tools to}} address, {{for the first}} time, the realistic macroscopic simulation of a real large-scale motorway network. More specifically, the macroscopic simulator METANET, involving a second-order traffic flow model as well as network-relevant extensions, is utilized. A rigorous quantitative <b>validation</b> <b>procedure</b> is applied to individual network links, and subsequently a heuristic qualitative <b>validation</b> <b>procedure</b> is employed at a network level. The large-scale motorway network around Amsterdam, The Netherlands, is considered in this investigation. The main goal of the paper is to describe the application approach and procedures and to demonstrate the accuracy and usefulness of macroscopic modeling tools for large-scale motorway networks...|$|E
30|$|In {{order to}} address the {{scientific}} reliability of the developed biomass productivity models, a <b>validation</b> <b>procedure</b> was applied using an independent dataset. A remote sensing–derived productivity indicator was used to validate all three land use–specific soil productivity models independently.|$|E
40|$|A new mutual {{information}} based algorithm is introduced for term selection in spatio-temporal models. A generalised cross <b>validation</b> <b>procedure</b> is also introduced for model length determination and examples based on cellular automata, coupled map lattice and partial differential equations are described...|$|E
40|$|Spatial data usually {{encapsulate}} semantic {{characterization of}} features which carry out important meaning and relations among objects, {{such as the}} containment between the extension of a region and of its constituent parts. The GeoUML methodology allows one to bring {{the gap between the}} definition of spatial integrity constraints at conceptual level and the realization of <b>validation</b> <b>procedures.</b> In particular, it automatically generates SQL validation queries starting from a conceptual specification and using predefined SQL templates. These queries can be used to check data contained into spatial relational databases, such as PostGIS. However, the quality requirements and the amount of available data are considerably growing making unfeasible the execution of these <b>validation</b> <b>procedures.</b> The use of the map-reduce paradigm can be effectively applied in such context since the same test can be performed in parallel on different data chunks and then partial results can be combined together to obtain the final set of violating objects. Pigeon is a data-flow language defined on top of Spatial Hadoop which provides spatial data types and functions. The aim {{of this paper is to}} explore the possibility to extend the GeoUML methodology by automatically producing Pigeon <b>validation</b> <b>procedures</b> starting from a set of predefined Pigeon macros. These scripts can be used in a map-reduce environment in order to make feasible the validation of large datasets...|$|R
40|$|Innovative {{methods of}} {{artificial}} intelligence such as artificial neural networks (ANNs) have been increasingly adopted to predict consumer responses to direct marketing. However, appropriate learning algorithms, evaluation criteria, and <b>validation</b> <b>procedures</b> {{are necessary for}} effective implementation of neural networks to provide decision support to managers. This study compares the performance of Bayesian neural networks with that of logistic regression and the backpropagation method in modelling consumer responses. The results of a tenfold stratified cross-validation suggest that although the three methods perform equally well under the error rate, Bayesian neural networks generate higher statistics for the Area under the Receiver Operating Characteristic Curve (AUROC) and cumulative lifts. The findings suggest that researchers should adopt effective learning algorithms, relevant evaluation criteria and appropriate <b>validation</b> <b>procedures</b> for neural networks to model consumer responses and solve marketing problems facing today 2 ̆ 7 s businesses...|$|R
40|$|There are no {{measurement}} {{tools that}} accurately measure depression among Lao refugees. The overall {{purpose of this}} research was to complete the development and <b>validation</b> <b>procedures</b> for the Lao Depression Inventory (LDI). The study consisted of 216 Ethnic Lao refugees. A clinical interview and 164 true/false questions were administered to identify specific items which could identify depression among the Ethnic Lao people. All items were administered in both English and Lao. Overall, 78 of the 164 items differentiated groups of depressed and nondepressed Lao at the. 01 level. Results of <b>validation</b> <b>procedures</b> showed that a 30 -item scale had an accuracy rate of 89 % in identifying the presence of depression in the validation group; the hit-rate for the same items and cutoff was 92 % in the cross-validation group. Potential uses of the scale are discussed...|$|R
