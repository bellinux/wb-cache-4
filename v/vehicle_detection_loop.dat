0|1376|Public
5|$|Using closed-circuit {{television}} cameras, <b>vehicle</b> <b>detection</b> <b>loops</b> and LED changeable-message signs, COMPASS enables the MTO Traffic Operations Centre {{to obtain a}} real-time assessment of traffic conditions and alert drivers of collisions, congestion and construction.|$|R
50|$|Highway 401 widens into a collector-express systemas it {{approaches}} Hurontario Street in Mississauga, a concept {{inspired by the}} Dan Ryan Expressway in Chicago. The system divides each direction of travel into collector and express lanes,giving the highway a wide span and four carriageways. To avoid confusion between carriageways, blue signs are used for the collector lanes and green signs for the express lanes. Unlike the collector lanes, which provide access to every interchange, the express lanes only provide direct access to a select few interchanges. Access {{between the two is}} provided by transfers, which are strategically placed to prevent disruptions caused by closely spaced interchanges.The overall purpose of the collector-express system is to maximize traffic flow for both local and long-distance traffic. In addition, Highway 401 was equipped with a traffic camera system called COMPASS in early 1991.Using closed-circuit television cameras, <b>vehicle</b> <b>detection</b> <b>loops</b> and LED changeable-message signs, COMPASS enables the MTO Traffic Operations Centre to obtain a real-time assessment of traffic conditions and alert drivers of collisions, congestion and construction.The system currently stretches from the Highway 403 / 410 interchange in Mississauga to Harwood Avenue in Ajax.|$|R
50|$|<b>Vehicle</b> <b>detection</b> <b>loops,</b> called inductive-loop traffic detectors, {{can detect}} {{vehicles}} passing or {{arriving at a}} certain point, for instance approaching a traffic light or in motorway traffic. An insulated, electrically conducting loop is installed in the pavement. The electronics unit transmits energy into the wire loops at frequencies between 10 kHz to 200 kHz, depending on the model. The inductive-loop system behaves as a tuned electrical circuit in which the loop wire and lead-in cable are the inductive elements. When a vehicle passes over the loop or is stopped within the loop, the vehicle induces eddy currents in the wire loops, which decrease their inductance. The decreased inductance actuates the electronics unit output relay or solid-state optically isolated output, which sends a pulse to the traffic signal controller signifying the passage or presence of a vehicle. Parking structures for automobiles may use inductive loops to track traffic (occupancy) in and out or may be used by access gates or ticketing systems to detect vehicles while others use Parking guidance and information systems. Railways may use an induction loop to detect the passage of trains past a given point, as an electronic treadle.|$|R
30|$|In ITS, neural {{networks}} {{can be found}} on the areas like <b>vehicle</b> <b>detection,</b> road <b>detection,</b> and single <b>loop</b> <b>vehicle</b> type classification [32, 33]. Rarely some work related with traffic flow control can be found and they are also not well defined [34].|$|R
40|$|Vision based <b>vehicle</b> <b>detection</b> is a {{critical}} technology that {{plays an important role}} in not only vehicle active safety but also road video surveillance application. Traditional shallow model based <b>vehicle</b> <b>detection</b> algorithm still cannot meet the requirement of accurate <b>vehicle</b> <b>detection</b> in these applications. In this work, a novel deep learning based <b>vehicle</b> <b>detection</b> algorithm with 2 D deep belief network (2 D-DBN) is proposed. In the algorithm, the proposed 2 D-DBN architecture uses second-order planes instead of first-order vector as input and uses bilinear projection for retaining discriminative information so as to determine the size of the deep architecture which enhances the success rate of <b>vehicle</b> <b>detection.</b> On-road experimental results demonstrate that the algorithm performs better than state-of-the-art <b>vehicle</b> <b>detection</b> algorithm in testing data sets...|$|R
40|$|<b>Vehicle</b> <b>detection</b> is {{critical}} operation in automotive active safety systems. Although {{there are a}} number of <b>vehicle</b> <b>detection</b> techniques available in literature, computationally efficiency for realization on embedded platforms is not explored and addressed in most existing works. In this paper, we present a computationally efficient <b>vehicle</b> <b>detection</b> algorithm that is particularly designed for architectural translation into efficient embedded hardware. The proposed method uses camera calibration to derive the appropriate window scales that must be used for <b>vehicle</b> <b>detection,</b> resulting in a computational cost reduction of over 10 times. In addition to reduction in sampling windows, the proposed <b>vehicle</b> <b>detection</b> technique uses a novel multi-part based <b>vehicle</b> <b>detection</b> method which detects the vehicles that pose the highest risk to the ego-vehicle. The proposed method is evaluated using different datasets and computational savings are seen in orders of magnitude as compared to conventional sliding window approaches, without compromising on accuracy. Keywords- <b>vehicle</b> <b>detection,</b> computational efficiency I...|$|R
30|$|<b>Vehicle</b> <b>detection</b> {{is a very}} {{important}} component in traffic surveillance and automatic driving [1]. The traditional <b>vehicle</b> <b>detection</b> algorithms such as Gaussian mixed model (GMM) [2] has achieved promising achievements. But it is not ideal due to illumination changes, background clutter, occlusion, etc. <b>Vehicle</b> <b>detection</b> is still an important challenge in computer vision.|$|R
40|$|Passenger {{safety in}} {{vehicles}} {{is the primary}} concern and hence <b>Vehicle</b> <b>detection</b> for providing enough safety information for Driver Assistant System (DAS) become popular among researchers. Many approaches use different types of information such as shadow, edge, light, to detect the vehicles. Here vision based <b>vehicle</b> <b>detection</b> techniques were summarized. Following topics discussed below, camera placement and the various applications of monocular <b>vehicle</b> <b>detection,</b> common features and common classification methods, motion-based approaches and nighttime <b>vehicle</b> <b>detection</b> and monocular pose estimation...|$|R
40|$|Copyright © 2014 Hai Wang et al. This is an {{open access}} article {{distributed}} under theCreativeCommonsAttributionLicense,which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Vision based <b>vehicle</b> <b>detection</b> is a critical technology that {{plays an important role}} in not only vehicle active safety but also road video surveillance application. Traditional shallow model based <b>vehicle</b> <b>detection</b> algorithm still cannot meet the requirement of accurate <b>vehicle</b> <b>detection</b> in these applications. In this work, a novel deep learning based <b>vehicle</b> <b>detection</b> algorithm with 2 D deep belief network (2 D-DBN) is proposed. In the algorithm, the proposed 2 D-DBN architecture uses second-order planes instead of first-order vector as input and uses bilinear projection for retaining discriminative information so as to determine the size of the deep architecture which enhances the success rate of <b>vehicle</b> <b>detection.</b> On-road experimental results demonstrate that the algorithm performs better than state-of-the-art <b>vehicle</b> <b>detection</b> algorithm in testing data sets. 1...|$|R
40|$|Abstract — In {{this paper}} we {{describe}} the experimental work and present an algorithm for <b>vehicle</b> <b>detection</b> using sensor node data. Both acoustic and magnetic signals are processed for <b>vehicle</b> <b>detection.</b> We propose a real-time <b>vehicle</b> <b>detection</b> algorithm called the Adaptive Threshold algorithm (ATA). This adaptive algorithm first computes the time-domain energy distribution curve and then slices the energy curve using a threshold updated adaptively by some decision states. Finally, the hard decision results from threshold slicing are passed to a finite-state machine, which makes the final <b>vehicle</b> <b>detection</b> decision. Real-time tests and offline simulations both demonstrate that the proposed algorithm is effective...|$|R
40|$|Abstract—Vehicle {{detection}} is {{the critical}} step for highway monitoring. In this paper we propose background subtraction and edge <b>detection</b> technique for <b>vehicle</b> <b>detection.</b> This technique uses the advantages of both approaches. The practical applications approved {{the effectiveness of this}} method. This method consists of two procedures: First, automatic background extraction procedure, in which the background is extracted automatically from the successive frames; Second <b>vehicles</b> <b>detection</b> procedure, which depend on edge detection and background subtraction. Experimental results show the effective application of this algorithm. <b>Vehicles</b> <b>detection</b> rate was higher than 91 %. Keywords—Image processing; Automatic background extraction; Moving <b>vehicle</b> <b>detection...</b>|$|R
40|$|Abstract—On {{the basis}} of a {{necessary}} development of the road safety, vision-based <b>vehicle</b> <b>detection</b> techniques have gained an important amount of attention. This work presents a novel <b>vehicle</b> <b>detection</b> and tracking approach, and structured based on a <b>vehicle</b> <b>detection</b> process starting from, images or video data acquired from sensors installed on board of the <b>vehicle,</b> to <b>vehicle</b> <b>detection</b> and tracking. The features of the vehicle are extracted by the proposed GIST image processing algorithm, and recognized by the state-of-art Support Vectors Machine classifier. The tracking process was performed based on edge features matching approach. The Kalman filter was used to correct the measurements. Extensive experiments were carried out on real image data validate that it is promising to employ the proposed approach for on road <b>vehicle</b> <b>detection</b> and tracking...|$|R
40|$|Abstract—On-road <b>vehicle</b> <b>{{detection}}</b> and lane detection {{are integral}} parts of most advanced driver assistance systems (ADAS). In this paper, we introduce an integrated approach called Efficient Lane and <b>Vehicle</b> <b>detection</b> with Integrated Synergies (ELVIS), that exploits the inherent synergies between lane and on-road <b>vehicle</b> <b>detection</b> {{to improve the}} overall com-putational efficiency without compromising on the robustness of both the tasks. Detailed evaluations show that the <b>vehicle</b> <b>detection</b> component of ELVIS shows at least 50 % lesser false alarms with equal or better detection rates, and reducing the computational costs by over 90 % as compared to state-of-the-art <b>vehicle</b> <b>detection</b> methods. Similarly, the lane detection component shows more reliable lane feature extraction with average computation costs that are at least 35 % lesser than existing techniques. Keywords-vehicle detection, lane detection, integrated system, computational efficiency I...|$|R
30|$|In this section, we give a brief {{introduction}} of <b>vehicle</b> <b>detection</b> in traffic surveillance cameras. Vision-based <b>vehicle</b> <b>detection</b> algorithms {{can be divided}} into three categories: motion-based approaches, hand-crafted feature-based approaches, and CNN-based approaches.|$|R
40|$|<b>Vehicle</b> <b>detection</b> {{plays an}} {{important}} role in safe driving assistance technology. Due to the high accuracy and good efficiency, the deformable part model is widely used in the field of <b>vehicle</b> <b>detection.</b> At present, the problem related to reduction of false positivity rate of partially obscured vehicles is very challenging in <b>vehicle</b> <b>detection</b> technology based on machine vision. In order to address the abovementioned issues, this paper proposes a deep <b>vehicle</b> <b>detection</b> algorithm based on the dual-vehicle deformable part model. The deep learning framework can be used for <b>vehicle</b> <b>detection</b> to solve the problem related to incomplete design and other issues. In this paper, the deep model is used for <b>vehicle</b> <b>detection</b> that consists of feature extraction, deformation processing, occlusion processing, and classifier training using the back propagation (BP) algorithm to enhance the potential synergistic interaction between various parts and to get more comprehensive vehicle characteristics. The experimental results have shown that proposed algorithm is superior to the existing detection algorithms in detection of partially shielded vehicles, and it ensures high detection efficiency while satisfying the real-time requirements of safe driving assistance technology...|$|R
30|$|According to the <b>detection</b> {{principle}} of <b>vehicle</b> target by DPM and combined with vehicle color information, a <b>vehicle</b> target <b>detection</b> method based on color fusion DPM is proposed. Firstly, the traffic image is conducted with HSI color space conversion, the information of each channel is extracted, {{and then the}} color fusion DPM is obtained by using the adaptive fusion method. Finally, the fusion model is used for <b>vehicle</b> <b>detection.</b> The method retains the vehicle’s color information based on the traditional vehicle DPM. Experiments show that the proposed method is superior to the commonly used <b>vehicle</b> <b>detection</b> methods and achieves a good <b>vehicle</b> <b>detection</b> effect, which can effectively solve the practical <b>vehicle</b> target <b>detection</b> problems encountered in intelligent transportation. In the future research, time consumption in <b>vehicle</b> <b>detection</b> process and the transplant in the hardware system will be the research targets.|$|R
40|$|Abstract — Automated <b>Vehicle</b> <b>detection</b> and {{classification}} is {{an important}} component of intelligent transport system. Due to significant importance in various fields such as traffic accidents avoidance, toll collection, congestion avoidance, terrorist activities monitoring, security and surveillance systems, intelligent transport system has become important field of study. Various technologies have been used for detecting and classifying vehicles automatically. Automated <b>vehicle</b> <b>detection</b> is broadly divided into two types- Hardware based and software based detection. Various algorithms have been implemented to classify different vehicles from videos. In this paper an efficient and economical solution for automatic <b>vehicle</b> <b>detection</b> and classification is proposed. The proposed system first isolates the object through background subtraction followed by <b>vehicle</b> <b>detection</b> using ontology. <b>Vehicle</b> <b>detection</b> is based on low level features such as shape, size, and spatial location. Finally system classifies vehicles into one of the known classes of vehicle based on size...|$|R
40|$|Vehicle Tracking Generating vehicle trajectories {{from video}} data is an {{important}} application of ITS (Intelligent Transportation Systems). We introduce a new tracking approach which uses model-based 3 -D <b>vehicle</b> <b>detection</b> and description algorithm. Our <b>vehicle</b> <b>detection</b> and description algorithm {{is based on a}} probabilistic line feature grouping, and it is faster (by up to an order of magnitude) and more flexible than previous image-based algorithms. We present the system implementation and the <b>vehicle</b> <b>detection</b> and tracking results...|$|R
40|$|Abstract: Intelligent {{transport}} system (ITS) {{refers to a}} system that manages road traffic using information and communications technology. One of the most important parts of it is the <b>vehicle</b> <b>detection</b> which provides vehicular data such as volume, density, and speed for traffic management centers. This paper proposes a <b>vehicle</b> <b>detection</b> method which measures volume and speed using Vehicle-to-Infrastructure communication and Global Positioning System. It can be implemented on roadway infrastructure with or without other <b>vehicle</b> <b>detection</b> techniques such as loop detectors...|$|R
40|$|Robust and {{reliable}} <b>vehicle</b> <b>detection</b> from images acquired by a moving vehicle (i. e., on-road <b>vehicle</b> <b>detection)</b> {{is an important}} problem with applications to driver assistance systems and autonomous, self-guided vehicles. The focus of this work is {{on the issues of}} feature extraction and classification for rear-view <b>vehicle</b> <b>detection.</b> Specifically, by treating the problem of <b>vehicle</b> <b>detection</b> as a two-class classification problem, we have investigated several di#erent feature extraction methods such as Principal Component Analysis (PCA), Wavelets, and Gabor filters. To evaluate the extracted features, we have experimented with two popular classifiers, Neural Networks(NNs) and Support Vector Machines(SVMs). Based our evaluation results, we have developed an on-board real-time monocular precrash <b>vehicle</b> <b>detection</b> system that is capable of acquiring grey-scale images, using Ford's proprietary low light camera, achieving an average detection rate of 10 Hz. Our <b>vehicle</b> <b>detection</b> algorithm consists of two main steps: a multi-scale driven hypothesis generation step and an appearance-based hypothesis verification step. During the hypothesis generation step, image locations where vehicles might be present are extracted. This step uses multi-scale techniques to speed up detection but also to improve system robustness. The appearance-based hypothesis verification step verifies the hypotheses using Gabor features and SVMs. The system has been tested in Ford's concept vehicle under di#erent tra#c conditions (e. g., structured highway, complex urban streets, varying weather conditions), illustrating good performance. Keywords [...] - <b>Vehicle</b> <b>detection,</b> Principal Component Analysis, Wavelets, Gabor filters, Neural Networks, Support Vector Machines...|$|R
30|$|<b>Vehicle</b> <b>detection</b> {{process is}} {{required}} in order to find the distance between host car and other cars that {{can be seen from the}} camera. This distance will be used to build up a feature which characterize tailgating or unsafe following distance behaviour. For <b>vehicle</b> <b>detection</b> task, we used a simple and robust approach for the sake of real-time operation and we employed histogram of oriented gradients (HOG) features with a cascade classifier. We also improved the algorithmic efficiency and accuracy of <b>vehicle</b> <b>detections</b> by exploiting lane detection results since we are interested in only the vehicles which are in the same lane with host vehicle. This condition enabled us to run <b>vehicle</b> <b>detection</b> process in a specific region of interest.|$|R
40|$|Conference Name: 6 th International Conference on Computer Science and Education, ICCSE 2011. Conference Address: Singapore, Singapore. Time:August 3, 2011 - August 5, 2011. In this paper, {{we first}} {{reviewed}} {{different kinds of}} <b>vehicle</b> <b>detection</b> methods and {{pointed out that the}} video based detection technique is the most advantageous method. Then we introduced several of video based <b>vehicle</b> <b>detection</b> algorithms in detail and compared their performance. Finally, the difficulties and development trends of the video based <b>vehicle</b> <b>detection</b> algorithm research were presented. ? 2011 IEEE...|$|R
40|$|Abstract—Developing {{on-board}} automotive {{driver assistance}} systems aiming to alert drivers about driving environments, and possible collision with other vehicles {{has attracted a}} lot of attention lately. In these systems, robust and reliable <b>vehicle</b> <b>detection</b> is a critical step. This paper presents a review of recent vision-based on-road <b>vehicle</b> <b>detection</b> systems. Our focus is on systems where the camera is mounted on the vehicle rather than being fixed such as in traffic/driveway monitoring systems. First, we discuss the problem of on-road <b>vehicle</b> <b>detection</b> using optical sensors followed by a brief review of intelligent vehicle research worldwide. Then, we discuss active and passive sensors to set the stage for vision-based <b>vehicle</b> <b>detection.</b> Methods aiming to quickly hypothesize the location of vehicles in an image as well as to verify the hypothesized locations are reviewed next. Integrating detection with tracking is also reviewed to illustrate the benefits of exploiting temporal continuity for <b>vehicle</b> <b>detection.</b> Finally, we present a critical overview of the methods discussed, we assess their potential for future deployment, and we present directions for future research. Index Terms—Vehicle detection, computer vision, intelligent vehicles. ...|$|R
40|$|To realize {{road traffic}} flow {{surveillance}} under various environments which contain poor visibility conditions, {{we have already}} proposed two <b>vehicle</b> <b>detection</b> methods using thermal images taken with an infrared thermal camera. The first method uses pattern recognition for the windshields and their surroundings to detect vehicles. However, the first method decreases the <b>vehicle</b> <b>detection</b> accuracy in winter season. To maintain high <b>vehicle</b> <b>detection</b> accuracy in all seasons, we developed the second method. The second method uses tires’ thermal energy reflection areas on a road as the detection targets. The second method did not achieve high <b>detection</b> accuracy for <b>vehicles</b> on left-hand and right-hand lanes except for two center-lanes. Therefore, we have developed a new method based on the second method to increase the <b>vehicle</b> <b>detection</b> accuracy. This paper proposes the new method and shows that the <b>detection</b> accuracy for <b>vehicles</b> on all lanes is 92. 1 %. Therefore, by combining the first method and the new method, high <b>vehicle</b> <b>detection</b> accuracies are maintained under various environments, and road traffic flow surveillance can be realized...|$|R
40|$|Vision-based multivehicle {{detection}} {{plays an}} important role in Forward Collision Warning Systems (FCWS) and Blind Spot Detection Systems (BSDS). The performance of these systems depends on the real-time capability, accuracy, and robustness of <b>vehicle</b> <b>detection</b> methods. To improve the accuracy of <b>vehicle</b> <b>detection</b> algorithm, we propose a multifeature fusion <b>vehicle</b> <b>detection</b> algorithm based on Choquet integral. This algorithm divides the <b>vehicle</b> <b>detection</b> problem into two phases: feature similarity measure and multifeature fusion. In the feature similarity measure phase, we first propose a taillight-based <b>vehicle</b> <b>detection</b> method, and then vehicle taillight feature similarity measure is defined. Second, combining with the definition of Choquet integral, the vehicle symmetry similarity measure and the HOG + AdaBoost feature similarity measure are defined. Finally, these three features are fused together by Choquet integral. Being evaluated on public test collections and our own test images, the experimental results show that our method has achieved effective and robust multivehicle detection in complicated environments. Our method can not only improve the detection rate but also reduce the false alarm rate, which meets the engineering requirements of Advanced Driving Assistance Systems (ADAS) ...|$|R
5000|$|The {{animator}} may, or may not, combine other test/debugging features {{within it}} such as program trace, dump, conditional breakpoint and memory alteration, program flow alteration, code coverage analysis, [...] "hot spot" [...] <b>detection,</b> <b>loop</b> <b>detection</b> or similar.|$|R
30|$|The {{authors of}} [19] {{presented}} a <b>vehicle</b> <b>detection</b> method based on extracting a histogram of oriented gradient (HOG) features from a given region of an image. In [20], {{a combination of}} speeded up robust features (SURF) [21] and edges was used to detect vehicles in the blind spot. Recently, researchers studying <b>vehicle</b> <b>detection</b> have moved away from complex image features such as Gabor filters and HOGs to simpler, more efficiently computable feature sets. As Haar-like features are sensitive to vertical, horizontal, and symmetric structures, {{and they can be}} computed efficiently, they are well suited to real-time <b>vehicle</b> <b>detection</b> applications [22].|$|R
40|$|AbstractMoving <b>vehicles</b> <b>detection</b> is an {{important}} part of Intelligence Transport System (ITS). Traditional method of moving <b>vehicles</b> <b>detection</b> from video is image subtraction which is apt to be affected by brightness changing, in this paper a kind of moving <b>vehicles</b> <b>detection</b> algorithm based on optical flow is purposed: estimate optical flow through two consecutive frames’ image pyramids and compute every optical flow image's threshold with which images are be segment into binaryzation images, after that, through morphological transformation operator and rectangular splitting algorithm on images, moving vehicles’ images will be extracted from background. Experiment shows that the algorithm framework is practicable...|$|R
40|$|An {{approach}} for <b>vehicle</b> <b>detection</b> system from satellite images, {{which are used}} in many applications. <b>Vehicle</b> <b>detection</b> is done by pixelwise classification method instead sliding window and region based methods, which are used in existing system. The {{vital part of the}} paper is feature extraction and vehicle colour classification. Feature extraction includes edge and corner detection. For edgedetection, the Canny edge detector technique is applied. For, corner detection, the Harris corner detector process is applied. Adaboost is employed for vehicle colour extraction to separate vehicle and non-vehicle colours. Utterly, morphological operations are applied to enhance the <b>vehicle</b> <b>detection...</b>|$|R
40|$|Detecting the {{vehicles}} {{and having a}} detailed behavior analysis of {{the vehicles}} and their behavior in a traffic surveillance system is an emerging area of research. <b>Vehicle</b> <b>detection</b> {{would be the first}} step to be addressed in this process. Various classes of vehicles are to be detected from the surveillance video and then they need to be classified based on various feature points. This paper brings out the different methods used for the <b>vehicle</b> <b>detection</b> from a video. An overview of the edge detection methodology is also given here, {{which is one of the}} methodologies used in <b>vehicle</b> <b>detection...</b>|$|R
40|$|Abstract: <b>Vehicle</b> <b>detection</b> {{is a very}} {{important}} problem in the measurement of traffic parameters and it becomes more important in different climate conditions. This paper presents an approach for <b>vehicle</b> <b>detection</b> in complex environments such as sunny days, rainy days, cloudy days, sunrise time, sunset time, or night time. The <b>vehicle</b> <b>detection</b> under various environments will have many difficulties such as illumination vibrations, shadow effects, and vehicle overlapping problems that appear in traffic jams. The main contribution {{of this paper is to}} propose an adaptive <b>vehicle</b> <b>detection</b> approach in complex environments to directly detect vehicles without extracting and updating a reference background image in complex environments. In the proposed approach, histogram extension addresses the removal of the effects of weather and light impact. The gray-level differential value method (GDVM) is utilized to directly extract moving objects from the images. Finally, tracking and error compensation are applied to refine the target tracking quality. In addition, many useful traffic parameters including traffic flows, velocity, and vehicle classification are evaluated that can help to control traffic. Index Terms- Histogram Extension (HE), tracking compensation, tracking, traffic jam, <b>vehicle</b> <b>detection.</b> 1...|$|R
5000|$|Diamond Consulting Services Ltd of Aylesbury, Buckinghamshire for ‘Idris’ <b>vehicle</b> <b>detection</b> products.|$|R
30|$|With the {{information}} of the roadside {{obtained in the}} processing step described before, {{it is possible to}} restrict <b>vehicle</b> <b>detections</b> and tracking only to the well determined road areas. This increases performance and enhances the accuracy of <b>vehicle</b> <b>detection.</b> Based on this, we developed an algorithm for the <b>detection</b> of <b>vehicles</b> which is described in the following.|$|R
40|$|Abstract—This {{document}} {{provides a}} review of the past decade’s literature in on-road vision-based <b>vehicle</b> <b>detection.</b> Over the past decade, vision-based surround perception has matured significantly from its infancy. We detail advances in <b>vehicle</b> <b>detection,</b> discussing representative works from the monocular and stereo-vision domains. We provide discussion on the state-of-the-art, and provide perspective on future research directions in the field...|$|R
40|$|Abstract — <b>Vehicle</b> <b>detection</b> from aerial {{images is}} {{becoming}} an increasingly important research topic in surveillance, traffic monitoring and military applications. The system described in this paper focuses on <b>vehicle</b> <b>detection</b> in rural environments and its applications to oil and gas pipeline threat <b>detection.</b> Automatic <b>vehicle</b> <b>detection</b> by unmanned aerial vehicles (UAV) will replace current pipeline patrol services that rely on pilot visual inspection of the pipeline from low altitude high risk flights that are often restricted by weather conditions. Our research compares a set of feature extraction methods applied for this specific task and four classification techniques. The best system achieves an average 85 % <b>vehicle</b> <b>detection</b> rate and 1800 false alarms per flight hour over a large variety of areas including vegetation, rural roads and buildings, lakes and rivers collected during several day time illuminations and seasonal changes over one year. I...|$|R
40|$|<b>Vehicle</b> <b>detection</b> {{technology}} is the key technology of intelligent transportation systems, attracting the attention of many researchers. Although much literature has been published concerning daytime <b>vehicle</b> <b>detection,</b> little has been published concerning nighttime <b>vehicle</b> <b>detection.</b> In this study, a nighttime <b>vehicle</b> <b>detection</b> algorithm, consisting of headlight segmentation, headlight pairing and headlight tracking, is proposed. First, the pixels of the headlights are segmented in nighttime traffic images, {{through the use of}} the thresholding method. Then the pixels of the headlights are grouped and labeled, to analyze the characteristics of related components, such as area, location and size. Headlights are paired based on their location and size and then tracked via a tracking procedure designed to detect vehicles. Vehicles with only one headlight or those with three or four headlights are also detected. Experimental results show that the proposed algorithm is robust and effective in detecting vehicles in nighttime traffic...|$|R
