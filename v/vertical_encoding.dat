1|13|Public
40|$|Abstract Draft 802. 16 e/D 5 a {{contains}} references {{references to}} horizontal and <b>vertical</b> <b>encoding</b> architectures as means to map spatially multiplexed schemes to multiple antennas. However, the exact {{details of the}} mapping are not specified. Interleaving of spatial streams across antennas is important to achieve spatial diversity for MIMO systems. for MIMO. Starting on page 362, the vertical encoder proposed for spatially-multiplexed MIMO systems does not specify details of the blocks shown in Figure 251 c, i. e. the Encoder, Modulation, Demux and Sub-carrier mapping/PRBS blocks. It is important to design these blocks carefully to fully exploit spatial and frequency diversity with all types of receivers. In this contribution we propose space-frequency bit-interleaved coded modulation (SF-BICM) “vertical-encoded ” architecture which interleaves FEC blocks across both spatial streams and frequency tones. Spatial streams are multiple data streams transmitted over multiple antennas, both in open-loop and closed-loop modes. Space-frequency interleaving provides spatial diversity in addition to frequency diversity, especially with minimum mean squared error (MMSE) spatial filters per tone. Performance of the proposed SF-BICM is compared to simple spatial multiplexing (F-BICM) over 2 x 2 spatially i. i. d ITU channels. The proposed SF-BIC...|$|E
50|$|Several {{compression}} schemes {{have been}} introduced in the ANIM format. Most of these are strictly of historical interest as the only one currently used is the <b>vertical</b> run length <b>encoded</b> byte encoding developed by Atari software programmer Jim Kent.|$|R
40|$|Additional {{evidence}} is presented concerning the anisotropy between <b>vertical</b> and horizontal <b>encoding,</b> which emerges {{from studies of}} human perception and cognition of space in plane mirror reflections. Moreover, {{it is suggested that}} the non-metric characteristic of polarization – that Jeffery et al. discuss with respect to gravity – {{is not limited to the}} vertical dimension...|$|R
40|$|This paper {{outlines}} {{experimental work}} {{on the use of}} virtual environments in assessing and improving spatial skills in people with physical disabilities. New evidence is presented which suggests that the degree of spatial impairment experienced by physically disabled children varies dependent on early mobility, and that this impairment may persist into the teenage years. We also review an experiment demonstrating transfer of spatial knowledge from a virtual environment to the real world, and outline a proposed follow up study examining virtual experience versus physical model experience. Finally, other studies in progress are outlined that focus on <b>vertical</b> spatial <b>encoding</b> in virtual environments based on larger real world environments and include older users as the target group...|$|R
40|$|The use of {{auditory}} displays {{for selected}} cockpit instruments was examined. In auditory, visual, and combined auditory-visual compensatory displays of a vertical axis, critical tracking task were studied. The visual display <b>encoded</b> <b>vertical</b> error as {{the position of}} a dot on a 17. 78 cm, center marked CRT. The auditory display <b>encoded</b> <b>vertical</b> error as log frequency with a six octave range; the center point at 1 kHz was marked by a 20 -dB amplitude notch, one-third octave wide. Asymptotic performance on the critical tracking task was significantly better when using combined displays rather than the visual only mode. At asymptote, the combined display was slightly, but significantly, better than the visual only mode. The maximum controllable bandwidth using the auditory mode was only 60 % of the maximum controllable bandwidth using the visual mode. Redundant cueing increased the rate of improvement of tracking performance, and the asymptotic performance level. This enhancement increases with the amount of redundant cueing used. This effect appears most prominent when the bandwidth of the forcing function is substantially less than the upper limit of controllability frequency...|$|R
40|$|Analysis of {{handwritten}} word {{images is}} {{closely tied to}} the method of representing the images. Different representations have their own sets of advantages and disadvantages. In this paper, we propose a novel method of encoding handwritten images using vertical runs that significantly simplifies the implementation of several image-processing tasks pertaining to handwriting recognition. We demonstrate the advantages of both horizontal and <b>vertical</b> run-length <b>encoding</b> schemes and compare them to other widely used representations like chain-code and bitmap. We illustrate ease of use of horizontal runs for correcting the slant angle, image smoothing, and base-line detection and vertical runs for correcting the skew angle and character segmentation. We believe this paper will serve as a useful tutorial in image representation schemes used in handwriting analysis and recognition. 1 Introduction Representation of handwritten images is an important issue in handwriting recognition. I [...] ...|$|R
40|$|Some {{possibilities}} {{offered by}} microprogramming in {{the realization of}} computer systems implemented according to several architectures are investigated in this paper. The serial and the classical parallel (SISD, SIMD, multiprocessors) organizations are considered together with some approaches to the realization of modern distributed systems (local networks, Logic Machines, Configurable Computers). The microprogramming possibilities are examined by {{taking into account the}} type of microinstruction <b>encoding</b> (<b>vertical</b> vs. horizontal), the opportunity for dynamic microprogramming and the Control Part-Operation Part model, and by evaluating the influence of these factors on the optimization of some design parameters...|$|R
50|$|The card's reverse {{includes}} a QR code encoding a GUID identifying the cardholder's {{details in the}} JCE's database. Next to the QR code, a Codabar encodes the cardholder's cédula number. A <b>vertical</b> Code128 barcode <b>encodes</b> the card's serial number. The card's serial number's first letter also identifies whether the cardholder is able to vote (N for a non-voting person and V for a voting person). A Machine Readable Zone {{at the bottom of}} the card encodes the cardholder's cédula number, birthday, sex, card expiration date, nationality, and names.|$|R
40|$|This article {{outlines}} {{experimental work}} investigating {{the way that}} people <b>encode</b> <b>vertical</b> as well as horizontal spatial information from exploration of virtual environments (VEs). We present two studies using simple multi level VEs that provide novel evidence for a vertical asymmetry in spatial memory, where downward spatial judgments are more accurate than upward spatial judgements. The effect was found in able-bodied adults and children, and in physically disabled children. A third study examined transfer of spatial learning from a VE to a real-world equivalent environment using a simulation of a multi-level complex shopping centre with elderly participants. This study confirms the potential of VEs as training media for the elderly. 1...|$|R
40|$|This paper aims {{to clarify}} the major {{determinants}} of the construal involved in Japanese spatial nouns mae (FRONT) and ushiro (BACK). Basically, mae and ushiro encode the anterior-posterior axis based on the functional asymmetry of our front-back structured body. Their spatial construals can be changed depending on {{the perspective of the}} conceptualizer even in the case where the reference object has an intrinsic front-back orientation. First, when mae and ushiro are used with an intrinsic reference frame, two different spatial construals for each expression are possible by employing two different types of reference points. On the other hand, {{in the case of a}} relative reference frame, the locational relations between the conceptualizer and objects will be given priority over intrinsic features of the reference object. In addition, the target object is always located between the conceptualizer and a reference object in Japanese language. In some cases, ue (UP) and shita (DOWN) are used for representing the front-back relation. This indicates that the anterior-posterior axis encoded by mae and ushiro is conceptualized as a spatial category partially overlapping with the <b>vertical</b> axis <b>encoded</b> by ue and shita in Japanese...|$|R
40|$|In this paper, we {{summarize}} the Auditory Information Seeking Principle (AISP) (gist, navigate, filter, and details-ondemand). To improve blind access to geo-referenced statistical data, we developed several interactive sonifications, {{adhering to the}} above AISP. Two user studies are presented. In the first user study with nine sighted subjects, a preliminary map design is compared with an enhanced table design. The study shows subjects can recognize geographic data distribution patterns on a real map with 51 geographic regions, in both designs. The map-based design was strongly preferred. The study also shows evidence that AISP conforms to people information seeking strategies. Based on the observations from the first user study, a second user {{study was conducted with}} forty-eight sighted subjects comparing four map designs. The effects of using sound to <b>encode</b> <b>vertical</b> geographic positions and two map navigation methods were compared. The result is presented and future work is discussed...|$|R
40|$|Abstract—In this paper, we {{summarize}} the Auditory Information Seeking Principle (AISP) (gist, navigate, filter, and details-ondemand). To improve blind access to geo-referenced statistical data, we developed several interactive sonifications, {{adhering to the}} above AISP. Two user studies are presented. In the first user study with nine sighted subjects, a preliminary map design is compared with an enhanced table design. The study shows subjects can recognize geographic data distribution patterns on a real map with 51 geographic regions, in both designs. The map-based design was strongly preferred. The study also shows evidence that AISP conforms to people’s information seeking strategies. Based on the observations from the first user study, a second user {{study was conducted with}} forty-eight sighted subjects comparing four map designs. The effects of using sound to <b>encode</b> <b>vertical</b> geographic positions and two map navigation methods were compared. The result is presented and future work is discussed. Index Terms—Auditory (non-speech) feedback, evaluation, interaction style, sound, user interfaces...|$|R
40|$|International audienceAdaptive {{motor control}} is based {{mainly on the}} {{processing}} and integration of proprioceptive feedback information. In crayfish walking leg, many of these operations are performed directly by the motor neurons (MNs), which are connected monosynaptically by sensory afferents (CBTs) originating from a chordotonal organ that <b>encodes</b> <b>vertical</b> limb movements. An in vitro preparation of the crayfish CNS was used to investigate a new control mechanism exerted directly by motor neurons on the sensory inputs themselves. Paired intracellular recordings demonstrated that, {{in the absence of}} any presynaptic sensory firing, the spiking activity of a leg MN is able long-lastingly to enhance the efficacy of the CBT-MN synapses. Moreover, this effect is specific to the activated MN because no changes were induced at the afferent synapses of a neighboring silent MN. We report evidence that long-term potentiation (LTP) of the monosynaptic EPSP involves a retrograde system of glutamate transmission from the postsynaptic MN, which induces the activation of a metabotropic glutamate receptor located presynaptically on the CBTs. We demonstrate that LTP at crayfish sensory-motor synapses results exclusively from the long-lasting enhancement of release of acetylcholine from presynaptic sensory afferent terminals, without inducing any modifications in postsynaptic MN properties. Our data indicate that this positive feedback control represents a functional mechanism that may play a key role in the auto-organization of sensory-motor networks...|$|R
40|$|Nervous systems process {{information}} about the environment in order to generate adaptive behavior. Sensory information that is obtained through different modalities, gleaned from different interactions of the animal with its surroundings, generated by different neural algorithms, or used to infer different distal stimulus properties, is often processed by distinct pathways in the brain. The auditory system compares sounds at the two ears in order to derive {{the location of the}} source. In the barn owl, Tyto alba, this is accomplished by interaural comparisons of the time that a sound reaches each ear, and of the level (intensity) at each ear. Interaural time differences code for horizontal positions of sound sources while interaural level differences, due to a vertical asymmetry in the owl's ears, can <b>encode</b> the <b>vertical</b> position of a sound. These two cues together can assign unique locations to sound sources in space. The barn owl processes time- and level differences in separate neural channels that converge in the inferior colliculus. This structure is the first site of neurons with spatially restricted auditory receptive fields, and with a neural map of auditory space. Downstream projections from here provide the sensory input for accurate sound localization by saccadic head movements. I report that the owl's two auditory processing streams are also segregated histochemically. The pathway that computes level differences stains especially strongly for the enzyme acetylcholinesterase, which may underlay processing of scalar (intensity) information over large dynamic ranges. This staining is complementary to immunohistochemical staining for calbindin, which has been shown previously to stain the pathway that processes interaural time differences. In further hodological and physiological experiments, I describe the algorithms that generate tuned responses in the inferior colliculus that <b>encode</b> <b>vertical</b> sound source position. This study shows that a lemniscal nucleus, nucleus ventralis lemnisci lateralis pars posterior (VLVp), projects bilaterally to a subdivision of the inferior colliculus (the shell of ICc). This projection appears to preserve tonotopy, and to provide inhibition by sounds of large interaural level difference. This probably GABAergic mechanism leads to the synthesis of neuronal responses in the inferior colliculus that are narrowly tuned to interaural level difference. My methodological strategy was to increase or decrease activity in VLVp by injection of blockers or agonists of GABA-A receptors, and then to record downstream in the inferior colliculus any changes in response tuning that resulted. The study suggests that the bilateral inhibition by VLVp is sufficient to explain the peaked responses to level differences of collicular neurons. Excitatory input to the inferior colliculus is conveyed by fibers of the lateral lemniscus, and may arise from a number of stations, including lemniscal and cochlear nuclei. The circuits I describe determine the tuning of cells to interaural level differences, but are independent of and have no effect on the tuning to interaural time differences, and further support that time and level are processed separately in the owl's brainstem. ...|$|R

