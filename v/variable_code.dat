39|1216|Public
5000|$|These restarts, if {{unhandled}} by code, can {{be presented}} to users (as part of a user interface, that of a debugger for example), so that the user can select and invoke one of the available restarts. Since the condition handler is called {{in the context of}} the error (without unwinding the stack), full error recovery is possible in many cases, where other exception handling systems would have already terminated the current routine. The debugger itself can also be customized or replaced using the [...] dynamic <b>variable.</b> <b>Code</b> found within unwind-protect forms such as finalizers will also be executed as appropriate despite the exception.|$|E
40|$|JPEG 2000 {{is the new}} {{standard}} for image compression. The features of this standard makes it is suitable for imaging and multimedia applications {{in this era of}} wireless and Internet communications. Discrete Wavelet Transform and embedded bit plane coding are the two key building blocks of the JPEG 2000 encoder. The JPEG 2000 architecture for image compression makes high quality compression possible in video mode also, i. e. motion JPEG 2000. In this paper, we present a study of the compression impact using <b>variable</b> <b>code</b> block size in different levels of DWT instead of fixed code block size as specified in the original standard. We also discuss the advantages of using <b>variable</b> <b>code</b> block sizes and its VLSI implementation. Keywords: image compression, JPEG 2000, rate-distortion optimization, <b>variable</b> <b>code</b> block size, VLSI, 1...|$|E
40|$|Conditional Compilation (CC) is {{frequently}} {{used as a}} variation mechanism in software product lines (SPLs). However, as a SPL evolves the <b>variable</b> <b>code</b> realized by CC erodes {{in the sense that}} it becomes overly complex and difficult to understand and maintain. As a result, the SPL productivity goes down and puts expected advantages more and more at risk. To investigate the variability erosion and keep the productivity above a sufficiently good level, in this paper we 1) investigate several erosion symptoms in an industrial SPL; 2) present a variability improvement process that includes two major improvement strategies. While one strategy is to optimize <b>variable</b> <b>code</b> within the scope of CC, the other strategy is to transition CC to a new variation mechanism called Parameterized Inclusion. Both of these two improvement strategies can be conducted automatically, and the result of CC optimization is provided. Related issues such as applicability and cost of the improvement are also discussed...|$|E
5000|$|... #Subtitle level 4: Dependent <b>Variable</b> (<b>coded</b> as a dummy variable) ...|$|R
5000|$|... #Subtitle level 4: Independent <b>Variables</b> (<b>coded</b> as a dummy variables) ...|$|R
50|$|Tooway and ViaSat SurfBeam {{make use}} of DVB-S2 <b>Variable</b> <b>Coding</b> and Modulation technologies.|$|R
40|$|Study {{instruments}} {{supporting a}} retrospective cohort study that explored potential links between prescription of anti-diabetic glitazone (GTZ) drugs and incidence of Parkinson’s disease. Outputs include: information on patient demographics and characteristics; codes {{used to identify}} GTZ exposure; codes used to identify Parkinson’s disease; <b>variable</b> <b>code</b> listings; a checklist of items {{to be included in}} cohort study reports; an ISAC application form; and a CPRD research protocol...|$|E
40|$|We propose and {{demonstrate}} a reconfigurable tunable encoder for two-dimensional time–wavelength optical code {{division multiple access}} (OCDMA). This encoder is capable of creating 2 D codes with <b>variable</b> <b>code</b> weight, enabling differentiated service provisioning. The demonstrated novel scheme uses ultra-fast optical delay lines and all-optical sampling while operating at 115 Gchip/s. Our proposed architecture provides an all-optical method of varying the code weight on a bit-per-bit basis, while maintaining the core architecture of a tunable OCDMA encoder...|$|E
40|$|Abstract—In this paper, an OFDM-CDM (orthogonal {{frequency}} division multiplexing code division multiplexing) system with adaptive symbol mapping is presented. This combination enables a robust transmission with flexible error protection and data rate adaptation for parallel data streams by exploiting additional diversity due to CDM. Performance {{results are presented}} for fading channels where OFDM-CDM with adaptive symbol mapping and soft interference cancellation is compared to conventional OFDM systems also taking into account channel coding with <b>variable</b> <b>code</b> rates. I...|$|E
30|$|Female is {{a binary}} <b>variable,</b> <b>coded</b> 1 if the responded is female and 0 otherwise.|$|R
30|$|Emigration {{intentions}} is {{a binary}} <b>variable,</b> <b>coded</b> 1 if the respondent intends to emigrate {{in the next}} 3 years, and 0 otherwise.|$|R
30|$|Employed is {{a binary}} <b>variable,</b> <b>coded</b> 1 if the {{respondent}} regularly earns an income through labor or a pension, and 0 otherwise.|$|R
40|$|Highly-configurable {{software}} systems (also called software prod-uct lines) gain {{momentum in}} both, academia and industry. For instance, the Linux kernel comes with over 12 000 configuration options and thus, can be customized {{to run on}} nearly every kind of system. To a large degree, this configurability is achieved through <b>variable</b> <b>code</b> structures, for instance, using conditional compila-tion. Such source code variability adds a new dimension of com-plexity, thus giving rise to new possibilities for design flaws. Code smells are an established concept to describe design flaws or decay in source code. However, existing smells have no notion of variabil-ity and thus do not support flaws regarding <b>variable</b> <b>code</b> structures. In this paper, we propose an initial catalog of four variability-aware code smells. We discuss the appearance and negative effects of these smells and present code examples from real-world systems. To evaluate our catalog, we have conducted a survey amongst 15 researchers {{from the field of}} software product lines. The results confirm that our proposed smells (a) have been observed in existing product lines and (b) are considered to be problematic for common software development activities, such as program comprehension, maintenance, and evolution...|$|E
40|$|The {{advent of}} {{variability}} management and generator technology enables users to derive individual variants from a <b>variable</b> <b>code</b> base {{based on a}} selection of desired configuration options. This approach {{gives rise to the}} generation of possibly billions of variants that, however, cannot be efficiently analyzed for errors with classic analysis techniques. To address this issue, researchers and practitioners usually apply sampling heuristics. While sampling reduces the analysis effort significantly, the information obtained is necessarily incomplete and it is unknown whether sampling heuristics scale to billions of variants. Recently, researchers have begun to develop variability-aware analyses that analyze the <b>variable</b> <b>code</b> base directly exploiting the similarities among individual variants to reduce analysis effort. However, while being promising, so far, variability-aware analyses have been applied mostly only to small academic systems. To learn about the mutual strengths and weaknesses of variability-aware and sampling-based analyses of software systems, we compared the two strategies by means of two concrete analysis implementations (type checking and liveness analysis), applied them to three subject systems: Busybox, the x 86 Linux kernel, and OpenSSL. Our key finding is that variability-aware analysis outperforms most sampling heuristics with respect to analysis time while preserving completeness...|$|E
40|$|A {{prototype}} indoor wireless {{optical transceiver}} system that uses LED as transmitting light source {{has been designed}} and developed. This wireless optical transceiver system can transmit ASCII-coded data for a distance up to 50 meters, and achieve a data rate of 230. 4 kbps. Huffman source coding with <b>variable</b> <b>code</b> words length is implemented as a compression technique so that data redundancy is minimised and spectral efficiency increased, and channel error-correction coding using Hamming linear block codes is implemented to counter the effect of noise during transmission...|$|E
3000|$|... “Time” is an {{indicator}} of time and covers the 9 trimesters of study (<b>variable</b> <b>coded</b> 1 – 9). The coefficient β [...]...|$|R
5000|$|VCM (<b>Variable</b> <b>Coding</b> and Modulation) and ACM (Adaptive Coding and Modulation) modes, {{which allow}} {{optimizing}} bandwidth utilization by dynamically changing transmission parameters.|$|R
40|$|In {{this paper}} we {{describe}} a trellis representation of <b>variable</b> length <b>coded</b> data which {{is capable of}} being used for bit-level or symbol-level maximum a posteriori (MAP) decoding of <b>variable</b> length <b>codes</b> (VLC). A bit-level soft-input/soft-output module is derived and is applied in an iterative decoding structure consisting of an outer <b>variable</b> length <b>code</b> and an inner convolutional code. Due to their inherent redundancy reversible <b>variable</b> length <b>codes</b> (RVLC) yield good results with this system. We present simulation results in terms of symbol error rate performance when the data is transmitted over a fully interleaved Rayleigh fading channel using BPSK modulation. As measure for the symbol error rate the Levenshtein distance is used which regards the self-synchronizing properties of <b>variable</b> length <b>codes</b> better than a simple symbol-by-symbol comparison. 1 Introduction Recently in [2] - [7] several approached have been introduced to improve decoding of <b>variable</b> length <b>codes</b> [...] ...|$|R
40|$|This paper proposes an {{algorithm}} {{to search}} {{a family of}} multiple sets of minimum correlated one dimensional uni-polar (optical) orthogonal codes (1 -DUOC) or optical orthogonal codes (OOC) with fixed as well as <b>variable</b> <b>code</b> parameters. The cardinality of each set is equal to upper bound. The codes within a set can be searched for general values of code length, code weight, auto-correlation constraint and cross-correlation constraint. Each set forms a maximal clique of the codes within given range of correlation properties. These one-dimensional uni-polar orthogonal codes can find their application as signature sequences for spectral spreading purpose in incoherent optical {{code division multiple access}} (CDMA) systems...|$|E
40|$|To support {{simultaneous}} multicasting and unicasting service, a 2 -level superposition coded modulation (SCM) {{system with}} <b>variable</b> <b>code</b> rate allocation is studied. To obtain the most power-efficient scheme for this system, brute-force method {{can be used}} to find the best power allocation for each code rate allocation. However, it is very complicated and time-consuming. In this work, the properties of the 2 -level SCM capacity is first studied using numerical evaluation and a heuristic method is proposed to efficiently find the optimal rate assignment and power allocation. The simulation results verify the performance of the proposed power allocation method and experimental results show that equal rate allocation scheme provides a power-efficient transmission...|$|E
40|$|Abstract — In {{recent years}} advancements {{in the field}} of {{wireless}} communications have generated interest in the deployment of multiple antenna systems (MIMO) for mobile terminals. Next generation wireless local area networks (WLANs) standards such as IEEE 802. 11 n are based on MIMO and will be operating at bit rates above 200 Mbps. The physical layer (PHY) of the 802. 11 n supports multiple modulation schemes, multiple antennas configuration, <b>variable</b> <b>code</b> rate and multiple space-time coding schemes. Receiver architecture should be able to support all these features preferably in a single reconfigurable architecture. Besides all these requirements need to be designed and implemented under the strict low power and low complexity (low area) design criteria. Keywords- MIMO, IEEE 802. 11 n, reconfigurable hardwar...|$|E
40|$|National Aeronautics and Space Administration (NASA) 's Space Communication and Navigation Testbed on the International Space Station {{provides}} {{a unique opportunity}} to evaluate advanced communication techniques in an operational system. The experimental nature of the Testbed allows for rapid demonstrations while using flight hardware in a deployed system within NASA's networks. One example is <b>variable</b> <b>coding</b> and modulation, which is a method to increase data-throughput in a communication link. This paper describes recent flight testing with <b>variable</b> <b>coding</b> and modulation over S-band using a direct-to-earth link between the SCaN Testbed and the Glenn Research Center. The testing leverages the established Digital Video Broadcasting Second Generation (DVB-S 2) standard to provide various modulation and coding options. The experiment was conducted in a challenging environment due to the multipath and shadowing caused by the International Space Station structure. Performance of the <b>variable</b> <b>coding</b> and modulation system is evaluated and compared to the capacity of the link, as well as standard NASA waveforms...|$|R
30|$|As for methodological aspects, {{the gender}} {{variable}} is measured as a binary <b>variable</b> <b>coded</b> 0 if the ethnic entrepreneur is female and coded 1 if the ethnic entrepreneur is male.|$|R
50|$|These degrees give {{specific}} {{instruction on}} research methodology, <b>variable</b> <b>coding,</b> and database construction and management. Classroom topics might include database management, focus group development, statistics in marketing, and consumer behavior.|$|R
40|$|Automatic parallelization in the {{polyhedral}} {{model is}} based on affine transformations from an original computation domain (iteration space) to a target space-time domain, often with a different transformation for each <b>variable.</b> <b>Code</b> generation is an often ignored step in this process that has {{a significant impact on}} the quality of the final code. It involves making a trade-off between code size and control code simplification/optimization. Previous methods of doing code generation are based on loop splitting, however they have non-optimal behavior when working on parameterized programs. We present a general parameterized method for code generation based on dual representation of polyhedra. Our algorithm uses a simple recursion on the dimensions of the domains, and enables fine control over the tradeoff between code size and control overhead...|$|E
40|$|A low-density parity-check (LDPC) decoder {{architecture}} that supports variable block sizes and multiple code rates is presented. The proposed architecture {{is based on}} the structured quasi-cyclic (QC-LDPC) codes whose performance compares favorably with that of randomly constructed LDPC codes for short to moderate block sizes. The main contribution of this work is to address the variable block-size and multirate decoder hardware complexity that stems from the irregular LDPC codes. The overall decoder, which was synthesized, placed and routed on TSMC 0. 13 -micron CMOS technology with a core area of 4. 5 square millimeters, supports <b>variable</b> <b>code</b> lengths from 360 to 4200 bits and multiple code rates between 1 / 4 and 9 / 10. The average throughput can achieve 1 Gbps at 2. 2 dB SNR. NokiaNational Science Foundatio...|$|E
40|$|In this {{contribution}} a novel adaptive differential space-time spreading assisted turbo detected sphere packingmodulation {{scheme is}} proposed {{for improving the}} achievable throughput of {{code division multiple access}} (CDMA) systems. The scheme is capable of accommodating the channel signal-to-noise ratio (SNR) variation of wireless systems by adapting the system parameters. Explicitly, an adaptive transmission scheme constituted by a novel reconfigurable four transmit antenna aided arrangement using a variable spreading factor based differential space-time spreading scheme, as well as <b>variable</b> <b>code</b> rate recursive systematic convolutional codes is introduced. Our results demonstrate that significant effective throughput improvement can be achieved while maintaining a target bit-error-ratio of 10 ? 4. Explicitly, when assuming an ideal Nyquist filter having a zero excess bandwidth, the system’s effective throughput varies from 0. 25 bits/sec/Hz to 16 bits/sec/Hz...|$|E
5000|$|... • Questionnaires• Interviewer and Coder Manuals• Codebooks with <b>variable</b> <b>codes</b> and frequencies• Follow-up {{master file}} to link study {{subjects}} through the three waves• Fieldwork reports: duration of interviews, response rates ...|$|R
50|$|The {{other six}} {{parts of the}} book are: laying the foundation, {{creating}} high-quality <b>code,</b> <b>variables,</b> statements, <b>code</b> improvements and system considerations.|$|R
30|$|The {{channel coding}} {{procedure}} has five steps: randomization, {{forward error correction}} (FEC), bitinterleaving, repetition <b>coding,</b> and modulation. <b>Variable</b> <b>coding</b> rate and modulation are supported to enable adaptive modulation and coding (AMC) capabilities.|$|R
40|$|Abstract—This paper proposes an {{improvement}} of the random multiple access scheme for satellite communication named Multi-slot coded ALOHA (MuSCA). MuSCA is a generalization of Contention Resolution Diversity Slotted ALOHA (CRDSA). In this scheme, each user transmits several parts of a single codeword of an error correcting code instead of sending replicas. At the receiver level, the decoder collects all these parts and includes them in the decoding process {{even if they are}} interfered. In this paper, we show that a high throughput can be obtained by selecting <b>variable</b> <b>code</b> rates and user degrees according to a probability distribution. With an optimal irregular degree distribution, our system achieves a normalized throughput up to 1. 43, resulting in a significant gain compared to CRDSA and MuSCA. The spectral efficiency and the implementation issues of the scheme are also analyzed. I...|$|E
40|$|The {{selection}} of refractory {{lining of the}} ladles for steel casting has been based, until the present, in the metallurgy technologists’ practical criteria. In this article the compared application of two search operators of materials options selection by zones inspired in the Evolutionary Multiple Objectives Algorithms {{for the treatment of}} the task of materials selection according to the adopted decomposition outline, is firstly reflected in the specialized bibliography. The numerical validation of the behavior of different indicators of both operators, as well as the comparison of their gain, efficiency and obtained solutions quality in the computational executions of both algorithms is carried out. These operators were implemented under the concept of the Integration of Variables method. Particularly, the Random Search of a <b>Variable</b> <b>Code</b> operator and a Not-Dominated Sorting Genetic Operator, based on elitist genetic algorithm NSGAII applied to the studied task are used...|$|E
30|$|We can go {{one step}} further and reduce the {{complexity}} of the previous algorithm by considering that the number of codes or the power assigned to data users are fixed. In this case, similar to the approach from [12], only one <b>variable</b> (<b>code</b> or power) will be used as a load metric of the BS. There is a slight conceptual difference between these two approaches (fixed codes and fixed power) when compared to the previous approach or the general approach in (12). In the two previous cases, the association strategy did not force to assign resources to all users, i.e., some data users could be assigned to a particular BS but the average rate they are assigned could be zero. However, as in this case a given user is already assigned a portion of the total power or a certain number of codes, the associated rate will be greater than zero, i.e., the BS will spend resources as long as such user is associated to it.|$|E
5000|$|<b>Variable</b> <b>coding</b> and {{modulation}} (VCM) {{to optimize}} bandwidth utilization {{based on the}} priority of the input data; e.g., SDTV could be delivered using a more robust setting than the corresponding HDTV service.|$|R
30|$|The main {{dependent}} variable is electoral turnout intentions. It is a binary <b>variable,</b> <b>coded</b> 1 if {{respondents said they}} would vote, if the next presidential election was being held this week, and 0 otherwise.|$|R
50|$|Besides the {{distances}} between the group members, Sociomap shows additional <b>variable</b> <b>coded</b> in the height (or color) of the subject. Typical variables {{used for the}} height are: social status, performance indicators of the subjects, average communication frequency, etc.|$|R
