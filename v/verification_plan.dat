99|268|Public
50|$|The {{hardware}} design and hardware verification {{need to be}} done independently. The {{hardware design}}er works to ensure the design of the hardware will meet the defined requirements. Meanwhile, the verification engineer will generate a <b>verification</b> <b>plan</b> which will allow for testing the hardware to verify that it meets all of its derived requirements.|$|E
5000|$|Records of Material / Performance Tests A {{summary of}} every test {{performed}} on the part. This summary is usually on a form of DVP&R (Design <b>Verification</b> <b>Plan</b> and Report), which lists each individual test, when it was performed, the specification, results and the assessment pass/fail. If there is an Engineering Specification, usually it is noted on the print. The DVP&R shall be reviewed and signed off by both customer and supplier engineering groups. The quality engineer will look for a customer signature on this document.In addition, this section lists all material certifications (steel, plastics, plating, etc.), as specified on the print. The material certification shall show compliance to the specific call on the print.|$|E
50|$|The {{purpose of}} the IPMVP is to {{increase}} certainty, reliability, and level of savings; reduce transaction costs by providing an international, industry consensus approach and methodologies; reduce financing costs by providing a project with a Measurement and <b>Verification</b> <b>Plan</b> (M&V Plan) standardisation, thereby allowing project bundling and pooled project financing. It aims to {{provide a basis for}} demonstrating emission reduction and delivering enhanced environmental quality; also to provide a basis for negotiating the contractual terms to ensure that an energy efficiency project achieves or exceeds its goals of saving money and improving energy efficiency. The Efficiency Valuation Organization also provides training in Measurement and Verification, and has established the Certified Measurement and Verification Professional qualification in association with the Association of Energy Engineers. It is a requirement of an IPMVP adherent M&V Plan that the plan is developed by a named individual.|$|E
40|$|Aerospace {{systems are}} subject to many {{stringent}} performance requirements to be verified with low risk. This report investigates <b>verification</b> <b>planning</b> using conditional approaches vice the standard classical statistical methods, and usage of historical surrogate data for requirement validation and in <b>verification</b> <b>planning.</b> The example used in this report to illustrate {{the results of these}} investigations is a proposed mission assurance requirement with the concomitant maximum acceptable verification risk for the NASA Constellation Program Orion Launch Abort System (LAS). This report demonstrates the following improvements: 1) <b>verification</b> <b>planning</b> using conditional approaches vice classical statistical methods results in plans that are more achievable and feasible; 2) historical surrogate data can be used to bound validation of performance requirements; and, 3) incorporation of historical surrogate data in <b>verification</b> <b>planning</b> using conditional approaches produces even less costly and more reasonable <b>verification</b> <b>plans.</b> The procedures presented in this report may produce similar improvements and cost savings in verification for any stringent performance requirement for an aerospace system...|$|R
5000|$|Iraq {{says that}} it {{considers}} the Monitoring and <b>Verification</b> <b>Plans</b> adopted by Resolution 715 to be unlawful, and states {{that it is not}} ready to comply with the Resolution.|$|R
40|$|Efficient {{implementations}} of DPLL {{with the}} addition of clause learning are the fastest complete satisfiability solvers and can handle many significant real-world problems, such as <b>verification,</b> <b>planning,</b> and design. Despite its importance, little is known of the ultimate strengths and limitations of the technique...|$|R
50|$|Away {{from the}} {{commercial}} side of conservation, there are tagging efforts to monitor gulper populations. Tagging {{is a common}} ecological tool to study the species characteristics. A large problem with monitoring the populations of Australian and Indonesian dogfish is that discriminating between the seven local species by morphological attributesalone is unreliable. In 2012 {{a study conducted by}} Ross Daley, Sharon Appleyard, and Matthew Koopman from the CSIRO Marine and Atmospheric Research Center in Hobart, Australia aims to help monitored recovery plans by implementing a new catch data <b>verification</b> <b>plan.</b> Their study focuses on using the 16s mitochondrial gene region to differentiate these species and when sequenced, all but C. harrissoni and C. isodon were distinguishable. They concluded that 16s gene is a strong marker suitable for fishery catch verification and that using this technique is a reliable and efficient system for routine testing. However, specialized primers needed for trials are sensitive to decay. Therefore, preservation problems need to be researched to further the prospective use of a 16s mitochondrial classification. This system for routine testing is only available to scientists and would require substantial training for fishermen {{to be able to use}} this technique.|$|E
5000|$|Between May 1999 and Election Day 2000, two Florida {{secretaries}} of state, Sandra Mortham and Katherine Harris, contracted with DBT Online Inc., {{at a cost}} of $4.294 million, to have the [...] "scrub lists" [...] reworked. In a May 2000 list, over 57,000 voters were identified as felons, with all counties being ordered to remove all listed names from their voting rolls. Democrats claimed that many simply had names similar to actual felons, some listed [...] "felonies" [...] were dated years in the future, and some were random. Some counties refused to use the list, finding it error-ridden. In other counties, supervisors of elections notified those at risk of being scrubbed, giving them a chance to prove they were not felons, which a small number chose to do. In most cases, those on the scrub list were not told that they weren't allowed to vote until they were turned away at the polls. An estimated 15% of the names on the county lists were in error. Florida was the only state in the nation to contract the first stage of removal of voting rights to a private company and did so with directions not to use cross-checks or the company's sophisticated <b>verification</b> <b>plan.</b> See Florida Central Voter File.|$|E
40|$|This Master's Thesis {{describes}} {{methods of}} software certification {{and development of}} airborne systems, focusing on software testing and verification during project's life cycle. Thesis includes also designed software <b>verification</b> <b>plan</b> for concrete application according to RTCA/DO- 178 B. Another part of thesis illustrates the exemplary realization of tests according to designed <b>verification</b> <b>plan.</b> At the close we describe the options of applying the designed <b>verification</b> <b>plan</b> and evaluation of its results...|$|E
5000|$|Gregory Delawie [...] (born 1957) is a United States diplomat. Since mid 2015, he {{has been}} the US Ambassador to Kosovo. Previously served as the Deputy Assistant Secretary for <b>Verification,</b> <b>Planning,</b> and European Security in the State Department’s Bureau of Arms Control, Verification and Compliance. He also served as Deputy Chief of Mission, U.S. Embassy Embassy Zagreb, Croatia and Berlin, Germany ...|$|R
40|$|Heat {{exchangers}} {{were developed}} {{for use in}} a solar heating and cooling system installed in a single family dwelling. Each of the three exchangers consisted of a heating and cooling module and a submersed electric water heating element. Information necessary to evaluate the preliminary design of the heat exchanger is presented in terms of the development and <b>verification</b> <b>plans,</b> performance specifications, installation and maintenance, and hazard analysis...|$|R
30|$|The {{final step}} comes after {{the design and}} {{implementation}} phase and it is requirements verification. Although it comes after the development phase, {{it is an important}} part of the requirement management process. The purpose is to verify that the end product or development process meet the given requirements. For this purpose, the requirements specification can include additional <b>verification</b> <b>plans</b> and models that refine how the requirement is supposed to be verified.|$|R
40|$|This {{as-built}} <b>verification</b> <b>plan</b> {{outlines the}} methodology and responsibilities {{that will be}} implemented during the as-built field verification activity for the Canister Storage Building (CSB) MCO HANDLING MACHINE (MHM). This as-built <b>verification</b> <b>plan</b> covers THE ELECTRICAL PORTION of the CONSTRUCTION PERFORMED BY POWER CITY UNDER CONTRACT TO MOWAT. The as-built verifications will be performed in accordance Administrative Procedure AP 6 - 012 - 00, Spent Nuclear Fuel Project As-Built <b>Verification</b> <b>Plan</b> Development Process, revision I. The results of the verification walkdown will be documented in a verification walkdown completion package, approved by the Design Authority (DA), and maintained in the CSB project files...|$|E
40|$|A {{compilation}} of analyses generated {{during the development}} of the electron-proton spectrometer for the Skylab program is presented. The data documents the analyses required by the electron-proton spectrometer <b>verification</b> <b>plan.</b> The <b>verification</b> <b>plan</b> was generated to satisfy the ancillary hardware requirements of the Apollo Applications program. The certification of the spectrometer requires that various tests, inspections, and analyses be documented, approved, and accepted by reliability and quality control personnel of the spectrometer development program...|$|E
40|$|Biomass is a P-band Synthetic Aperture Radar {{satellite}} mission {{proposal to}} estimate the biomass on a global scale. In support of the studies connected to this mission a Biomass end-to-end simulator has been developed for ESA. The Modules <b>Verification</b> <b>Plan</b> for the Product Generation Module (PGM) describes the individual steps of how to verify the algorithmic implementation of the PGM. The <b>verification</b> <b>plan</b> defines procedures and required inputs and outputs, which have to be produced for the Modules Verification Report...|$|E
40|$|This paper {{demonstrates}} a formal verificationplanning process and presents associated verification strategy {{that we believe}} is an essential (yet often neglected) step in an ASIC or SoC functional formal verification flow. Our contribution is to present a way to apply the <b>verification</b> <b>planning</b> process {{and a set of}} abstraction techniques on a non-trivial open-source example (the Sun OpenSPARC ™ DDR 2 controller). The process and verification strategy can be applied to DDR 2 controllers in particular and generalized for other designs. 1...|$|R
40|$|The Boolean Satisfiability Problem (SAT) is a {{well known}} NP-Complete problem. While its {{complexity}} remains a source of many interesting questions for theoretical computer scientists, the problem has found many practical applications in recent years. The emergence of efficient SAT solvers which can handle large structured SAT instances has enabled the use of SAT solvers in diverse domains such as <b>verification,</b> <b>planning,</b> routing, etc. These applications continue to motivate the development of faster and more robust SAT solvers. In this paper, we describe the popular SAT solver zchaff {{with a focus on}} recent developments...|$|R
40|$|Purpose: This study aims to {{clinically}} {{evaluate the}} directional dependence of a 2 D seven 29 ion-chamber array with different intensity-modulated radiotherapy (IMRT) plans. Methods: Twenty-five {{patients who had}} already been treated with IMRT plans were selected for the study. <b>Verification</b> <b>plans</b> were created in an Eclipse treatment planning system (TPS) for each treatment <b>plan.</b> The <b>verification</b> <b>plans</b> were executed twice for each patient. The first IMRT plan used a true gantry angle (plan-related approach), and the second plan used a 0 ° gantry angle (field-related approach). Measurements were performed using a Varian Clinac 2100 iX linear accelerator. The fluence was measured for all the delivered plans and analyzed using Verisoft software. A comparison of the fluence was performed between IMRT with a static gantry (0 ° gantry angle) and real gantry angles. Results: The {{results indicate that the}} Gamma average was 98. 8 % for IMRT with a 0 ° gantry angle and 96. 616 % for IMRT with a true gantry angle. Average percent difference of normalized doses for IMRT delivered with zero degree gantry angle and IMRT with actual gantry angles is 0. 15 and 0. 88 respectively. Conclusion: The ion chamber of the 2 D array used in IMRT verification has angular dependence, reducing the verification accuracy when the 2 D array is used for measuring the actual beams of the treatment plan. </p...|$|R
40|$|Approved {{afforestation}} and reforestation baseline methodology AR-AM 0002 “Restoration of degraded lands through afforestation/reforestation” This methodology {{is based}} on the draft CDM-AR-PDD “Moldova Soil Conservation Project ” whose baseline study, monitoring and <b>verification</b> <b>plan</b> and project design document were prepared by th...|$|E
40|$|Approved {{afforestation}} and reforestation baseline methodology AR-AM 0004 “Reforestation or afforestation of land {{currently under}} agricultural use” This methodology {{is based on the}} draft CDM-AR-PDD “Reforestation around Pico Bonito National Park, Honduras”, whose baseline study, monitoring and <b>verification</b> <b>plan</b> and project design documen...|$|E
40|$|Functional {{verification}} consumes {{more than}} 70 % {{of the labor}} invested in today’s SoC designs. Yet, even with such a large investment in verification, there’s more risk of functional failure at tapeout than ever before. The primary {{reason is that the}} design team does not know where they are, in terms of functional correctness, relative to the tapeout goal. They lack a functional verification map for reference that employs coverage as its primary element. Coverage, in the broadest sense, is responsible for measuring verification progress across a plethora of metrics and for helping engineers assess their location relative to design completion. [1] The map to be referenced must be created by the design team upfront, so they know not only where they are starting from-specification but no implementationbut also where they are going: fully functional first silicon. The metrics of the map must be chosen for their utility: RTL written, software written, features, properties, assertion count, simulation count, failure rate, and coverage closure rate. The map is the <b>verification</b> <b>plan,</b> an executable natural language document [2],[3] that defines the scope of the verification problem and its solution. The scope of the problem is defined by implicit and explicit coverage models. [1] The solution to the verification problem is described by the methodology employed to achieve full coverage: dynamic and static verification. Simulation (dynamic) contributes to coverage closure through RTL execution. Formal analysis (static) contributes to coverage closure through proven properties. By annotating the <b>verification</b> <b>plan</b> with these (and other) progress metrics, it becomes a live, executable document that directs the design team to their goal. Most verification planning today lacks the rigor required to recognize the full scope of the verification problem faced by the design team. The {{reason for this is that}} substantial effort is required to write a thorough <b>verification</b> <b>plan.</b> If that plan is obsolete as soon as it is written, the effort is not justified. However, by transforming the <b>verification</b> <b>plan</b> into an active specification that controls the verification process, the planning effort is more than justified. This article illustrates the application of an executable <b>verification</b> <b>plan</b> to a processor-based SoC...|$|E
40|$|The {{traditional}} approach used for verification in the analog world still lacks some key aspects {{that have been}} efficiently deployed in digital verification for years. SPICE-based analog verification environments are usually hard to reuse at the system-on-chip (SoC) level, difficult to control and barely meet the required simulation performance. By leveraging the well-proven VMM and UVM methodologies, the VCS® AMS testbench technology is to provide analog designers and verification engineers with a methodology that allows them to: ` ` Introduce analog <b>verification</b> <b>planning</b> ` ` Introduce constraint-random verification for driving analog nodes ` ` Model analog stimulus as shaped transaction-based bus functional models ` ` Integrate reference models with various abstraction level ` ` Sample analog nodes to monitor incoming traffic ` ` Introduce assertions on analog nodes ` ` Introduce analog code coverage and functional coverage ` ` Introduce regression management In addition to elaborating on the above features, this white paper describes a scalable and reusable methodology for verifying analog IP. Reuse is made possible by correct modeling of verification models that can be stitched into the SoC. These models can be implemented with HDL or Verilog-AMS, depending on the required accuracy. This white paper is a case study that explains the various aspects of this methodology {{that can be applied}} to VMM/UVM, from <b>verification</b> <b>planning</b> to testbench implementation and coverage collection...|$|R
5000|$|... 1059-1993 IEEE Guide for Software <b>Verification</b> & Validation <b>Plans</b> (withdrawn) ...|$|R
40|$|Performing {{business}} or personal financial auditing, the State Tax Inspectorate's staff analyzes data, performs screening and afterwords plans auditing. Therefore, inspection plans {{are being made}} up. 	This paper analyzes the work particularity of the Auditing Screening Division of the Šiauliai County State Tax Inspectorate including challengers of the non-computerized formation of the auditing plans. Having done the comparative analysis of products existing on the market, {{it was decided to}} develop a new system. The system is designed, implemented, tested and the quality evaluation has been carried out. The information system facilitates the <b>verification</b> <b>planning</b> process: clearance of data, reporting and data searches...|$|R
40|$|In 2007 the TerraSAR-X {{the first}} German Radar {{satellite}} for scientific and commercial applications will be launched. The {{project is a}} public-private partnership between DLR and EADS Astrium GmbH. TerraSAR-X consists of a high resolution Synthetic Aperture Radar (SAR) at X-Band. The radar antenna is based on active phased array technology that operating in multiple SAR modes (Stripmap, ScanSAR and Spotlight) with various polarizations. The highly advanced instrument allows the active configuration of many different instrument parameters and settings. The pre-launch activities for the TerraSAR-X system include the preparation of a <b>verification</b> <b>plan</b> to be accomplished during the commissioning phase. The aim of this plan is to define a procedure including all sub-systems to ensure optimum end-products (SAR images). The procedure involves tasks such as calibration, characterization/verification of SAR-instrument, SAR system performance, orbit and attitude as well as product verification. Due to the complexity and re-configurability of the system {{it is not possible}} to verify all possible combinations and settings. This makes the <b>verification</b> <b>plan</b> construction and the scheduling of the individual activities a non-trivial task requiring expertise for both the complete system and detailed sub-system level. The paper starts by introducing the areas covered by the system <b>verification</b> <b>plan.</b> These are combined in a block diagram for the basic SAR product verification flow. A detailed description of the philosophy behind the system <b>verification</b> <b>plan</b> is given. This is crucial to ensure proper interaction and to avoid conflicts during the detailed planning. The overall system <b>verification</b> <b>plan</b> is used to derive the verification matrix which identifies the tasks required for SAR System and Product release during the commissioning phase. Specifically one bottom level outcome of this matrix are the commissioning phase data take and their sequence of acquisition. However, the matrix is also a driver for the development of the tools required for the evaluation/analysis of the data take measurements. The paper will present both the verification matrix as well as the overall commissioning phase schedule. First results and trends of the TerraSAR-X commissioning phase with respect to SAR system and SAR products verification will be presented. The paper gives an insight and is intended to be a valuable reference for the development of system verification strategies of state-of-the-art and future SAR systems. ...|$|E
40|$|Draft {{afforestation}} and reforestation baseline methodology AR-AM 00 xx “Reforestation or afforestation of land {{currently under}} agricultural use” This methodology {{is based on the}} draft CDM-AR-PDD “Reforestation around Pico Bonito National Park, Honduras”, whose baseline study, monitoring and <b>verification</b> <b>plan</b> and project design documen...|$|E
40|$|Draft Approved {{afforestation}} and reforestation baseline methodology AR-AM 00 ## “Restoration of degraded lands through afforestation/reforestation” This methodology {{is based}} on the draft CDM-AR-PDD “Moldova Soil Conservation Project ” whose baseline study, monitoring and <b>verification</b> <b>plan</b> and project design document were prepared by th...|$|E
40|$|This paper {{addresses}} {{the problem of}} verifying plan execution. An implemented computer program {{which is part of}} the execution monitoring process for an experimental robot system is described. The program analyzes a plan and automatically inserts appropriate perception requests into the plan and generates anticipated sensor values. Real-time confirmation of these expectations implies successful plan execution. The implemented <b>plan</b> <b>verification</b> strategy and knowledge representation are described. Several issues and extensions of the method are discussed, including a language for <b>plan</b> <b>verification,</b> heuristics for constraining <b>plan</b> <b>verification,</b> and methods for analyzing plans at multiple levels of abstraction to determine context-dependent verification strategies...|$|R
5000|$|... 1012-1986 IEEE Standard for Software <b>Verification</b> and Validation <b>Plans</b> (superseded by 1012-1998) ...|$|R
40|$|Title: Visualization and <b>Verification</b> of <b>Plans</b> Author: Radoslav Glinský Department: Department of Theoretical Computer Science and Mathematical Logic Supervisor of the {{bachelor}} thesis: Doc. RNDr. Roman Barták, Ph. D. Abstract: Plan analysis {{is an important}} part of complete planning systems. In order to make even larger plans transparent and human readable, we have developed a program which helps users with the analysis and visualization of plans. This program is called VisPlan - Interactive Visualization and <b>Verification</b> of <b>Plans.</b> VisPlan is an inevitable part of this thesis as it practically implements its <b>plan</b> <b>verification</b> and visualization solutions. VisPlan finds and displays causal relations between actions, it identifies possible flaws in plans (and thus verifies plans' correctness), it highlights the flaws found in the plan and finally, it allows users to interactively modify the plan and hence manually repair the flaws or just fine-tune the plan. Keywords: Planning, Artificial Intelligence, PDDL, Verificatio...|$|R
40|$|In 2007 TerraSAR-X, {{the first}} German Radar {{satellite}} for scientific and commercial applications, will be launched. The {{project is a}} public-private partnership between DLR and EADS Astrium GmbH. TerraSAR-X consists of a high resolution Synthetic Aperture Radar (SAR) at X-Band. The radar antenna is based on active phased array technology operating in multiple SAR modes (Stripmap, ScanSAR and Spotlight) with various polarizations. The highly advanced instrument allows the active configuration of many different instrument parameters and settings. The pre-launch activities for the TerraSAR-X system include the preparation of a <b>verification</b> <b>plan</b> to be accomplished during the commissioning phase. The aim of this plan is to define a procedure including all sub-systems to ensure optimum end-products (SAR images). The procedure involves tasks such as calibration, characterization/verification of 1) SAR-instrument, 2) SAR system performance, and 3) orbit and attitude determination, as well as 4) product verification. Due to the complexity and re-configurability of the system {{it is not possible}} to verify all possible combinations and settings. This makes the <b>verification</b> <b>plan</b> construction and the scheduling of the individual activities a non-trivial task requiring expertise for both the complete system and detailed sub-system level. The paper starts by introducing the areas covered by the system <b>verification</b> <b>plan.</b> These are combined in a block diagram for the basic SAR product verification flow. A detailed description of the philosophy behind the system <b>verification</b> <b>plan</b> is given. This is crucial to ensure proper interaction and to avoid conflicts during the detailed planning. The overall system <b>verification</b> <b>plan</b> is used to derive the verification matrix which identifies the tasks required for SAR System and Product release during the commissioning phase. Specifically, the bottom level outcome of this matrix are the commissioning phase data take and their sequence of acquisition. However, the matrix is also a driver for the development of the tools required for the evaluation/analysis of the data take measurements. The paper will present both the verification matrix as well as the overall commissioning phase schedule. First results and trends of the TerraSAR-X commissioning phase with respect to SAR system and SAR products verification will be presented. The paper gives an insight and is intended to be a valuable reference for the development of system verification strategies of state-of-the-art and future SAR systems. ...|$|E
40|$|Draft {{revision}} to the approved {{afforestation and reforestation}} {{baseline and}} monitoring methodology AR-AM 0007 “Afforestation and Reforestation of Land Currently Under Agricultural or Pastoral Use” This methodology {{is based on the}} draft CDM-AR-PDD “Chocó-Manabí Corridor Reforestation and Conservation Carbon Project ” whose baseline study, monitoring and <b>verification</b> <b>plan</b> and project desig...|$|E
40|$|Details how to {{optimize}} a <b>verification</b> <b>plan</b> and an environment, {{and how to}} get results effectively. This book on Effective Functional Verification, presents case studies with analysis of proposed improvements. It discusses various subjects on how {{to get the most out}} of a verification environment. It also contains some tool specific guidelines...|$|E
5000|$|Change management, {{supported}} by <b>verification</b> how <b>planned</b> changes {{can influence the}} quality of created solution and eventual change of test plan. One of the products can be changes in test plan, test cases and scenarios.|$|R
40|$|Many <b>verification,</b> <b>planning,</b> {{and control}} {{problems}} can be modeled as games played on state-transition graphs by one or two players whose conflicting goals are to form a path in the graph. The focus here is on simple stochastic parity games, that is, two-player games with turn-based probabilistic transitions and #-regular objectives formalized as parity (Rabin chain) winning conditions. An e#cient translation from simple stochastic parity games to nonstochastic parity games is given. As many algorithms are known for solving the latter, the translation yields e#cient algorithms for computing the states of a simple stochastic parity game from which a player can win with probability 1...|$|R
50|$|HPC {{participates in}} the Greenhouse Gas Inventory and <b>Verification</b> Trial <b>Plan</b> {{promoted}} by the Energy Bureau of the Ministry of Economic Affairs and the Greenhouse Gas Registration, Verification and Voluntary Reduction Trial Plan by the Environmental Protection Administration.|$|R
