4|14|Public
40|$|Software-engineering aspects in {{computational}} electromagnetics (CEM) {{are becoming}} more important as the complexity of GEM codes continues to increase. Object-oriented programming (OOP) methods promise to alleviate the challenges posed by more-complex software systems, but offer little help for legacy codes. Python, an object-oriented <b>very-high-level</b> <b>language</b> (VHLL), {{can be used to}} extend legacy codes. It provides the dual benefit of a very productive programming environment and of enabling legacy codes to be migrated to object-oriented designs with low risk. The application of this method is described in the context of eMA GUS, a microwave Finite-Element Method code. Articl...|$|E
40|$|Semantic {{analysis}} {{is important for}} compilers. In the APTS program transformation system, semantics is specified by rules in the language RSL. The semantic rules are interpreted by APTS to generate the semantic information of the program, which is then used by the rewriting engine for program translation. This approach {{has proved to be}} convenient and powerful in our construction of a SETL-to-C compiler. In this paper, we discuss the features, applications, implementation strategy, and performance of RSL. 1. Introduction RSL is the specification language of the APTS system, an experimental program transformation system on which Robert Paige and the author have been working for several years. Recently, a SETL-to-C translator, written in RSL, has been built in the APTS environment with some success [4]. SETL is a <b>very-high-level</b> <b>language</b> and is convenient to use, but usually much slower than C. With the SETL-to-C translator, we combine the convenience of SETL with the efficiency of [...] ...|$|E
40|$|This report {{summarizes}} {{the current status}} of CTA's investigation of methods and tools for automating the software development process in NASA Goddard Space Flight Center, Code 500. The emphasis in this effort has been on methods and tools in support of software reuse. The most recent phase of the effort has been a domain analysis of Payload Operations Control Center (POCC) software. This report {{summarizes the}} results of the domain analysis, and proposes an approach to semi-automatic development of POCC Application Processor (AP) software based on these results. The domain analysis enabled us to abstract, from specific systems, the typical components of a POCC AP. We were also able to identify patterns in the way one AP might be different from another. These two perspectives [...] aspects that tend to change from AP to AP, and aspects that tend to remain the same [...] suggest an overall approach to the reuse of POCC AP software. We found that different parts of an AP require different development technologies. We propose a hybrid approach that combines constructive and generative technologies. Constructive methods emphasize the assembly of pre-defined reusable components. Generative methods provide for automated generation of software from specifications in a <b>very-high-level</b> <b>language</b> (VHLL) ...|$|E
5000|$|The {{development}} of a <b>very-high-level</b> Megaprogramming <b>language</b> for software composition in 1992.|$|R
40|$|Many non-specialists are {{intimidated by}} the {{mathematical}} appearance of most applicative, functional, and <b>very-high-level</b> <b>languages.</b> This report presents a simple notation that has an unintimidating, natural-language appearance {{and that can be}} adapted to a variety of languages. The paper demonstrates its use as an alternate syntax for LISP, PROLOG, Backus' FP, relational programming, and relational database retrievals. The grammar's eight productions can be handled by a simple recursive-descent parser. (Author) Chief of Naval Research Arlington, Virginia[URL] Agency: Chief of Naval Research, Arlington, Virginia 22217...|$|R
40|$|Problems of application-system cost, control, and eflectiveness {{can best}} be {{addressed}} by highly consistent development and execution environments. This paper examines some relevant new approaches (systems description languages, new data models, application generators, and <b>very-high-level</b> <b>languages),</b> discusses {{the need for additional}} integration, and outlines a particular integration direction. This direction is intended to illustrate both the kind of consolidation needed and some of the problems involved. Towards an integrated development environment by P. S. Newman The history of general-purpose software can, in some sense, be seen as the provision of increasingly powerful remedies for the following persistent problems: i Development cost. It costs so much to develop and modif...|$|R
40|$|This {{dissertation}} introduces 2 ̆ 2 open predicate path expressions 2 ̆ 2 [...] a non-procedural, <b>very-high-level</b> <b>language</b> notation for the synchronization of concurrent accesses to {{shared data}} in distributed computer systems. The target environment {{is one in}} which 2 ̆ 2 resource modules 2 ̆ 2 (totally encapsulated instances of abstract data types) are the basic building blocks in a network of conventional, von Neumann computers or of functional, highly parallel machines. Each resource module will contain two independent submodules: a synchronization submodule which coordinates requests for access to the resource 2 ̆ 7 s data and an access-mechanism submodule which localizes the code for operations on that data;Open predicate path expressions are proposed as a specification language for the synchronization submodule and represent a blend of two existing path notations: open path expressions and predicate path expressions. Motivations for the adoption of this new notation are presented, and an implementation semantics for the notation is presented in the form of dataflow graphs;An algorithm is presented which will automatically synthesize an open predicate path expression into a dataflow graph, which is then implemented by a network of communicating submodules written in either a sequential or an applicative language. Finally, an extended notation for the synchronization submodule is proposed, the purpose of which is to provide greater expressive power for certain synchronization problems which are difficult to specify using path expressions alone...|$|E
40|$|This report {{describes}} {{the concept of}} programming in a relational calculus. This is a style of programming in which entire relations are manipulated rather than individual data, and in which the program itself is represented as a relation. Thus relational programming is more general than functional programming in three respects. First, it is more general because relations subsume functions. Second, it is more general because the same objects, viz. relations are used to represent both {{the program and the}} data. Finally, since complex data structures are easily represented as relations, relational programming can manipulate with facility a much wider class of structures that other <b>very-high-level</b> <b>languages.</b> (Author) Prepared for: Naval Postgraduate School, Monterey, California 93943. [...] Cover. [URL]...|$|R
40|$|An {{investigation}} is made into efficiently-implementable <b>very-high-level</b> programming <b>language</b> constructs. In a manner analogous to ALGOL 60 's abstraction away from GOTO's, an abstract replacement for pointers (the path) is proposed. The use of paths instead of pointers in unshared recursive data structures greatly simplifies {{the process of}} reasoning about programs. The existence of an efficient implementation of paths makes their use palatable as well as desirable. Also investigated is the integration of paths with existing <b>very-high-level</b> programming <b>language</b> implementation techniques, such as hash-consing. Several real-time programs in Pure LISP are presented. Building on {{the foundation of a}} real-time queue and a real-time double-ended queue, a real-time implementation of paths is given. This leads to the surprising negative result that the addition of paths does not increase the "power" of Pure LISP...|$|R
40|$|The {{motivation}} {{behind the}} work in <b>very-high-level</b> <b>languages</b> is to ease the programming task by pro-viding the programmer with a language containing primitives or abstractions suitable to his problem area. The programmer is then able to spend his effort in the right place; he concentrates on solving his problem, and the resulting program will be more reliable as a result. Clearly, this is a worthwhile goal. Unfortunately, {{it is very difficult}} for a designer to select in advance all the abstractions which the users of his language might need. If a language is to be used at all, {{it is likely to be}} used to solve problems which its designer did not envision, and for which the abstractions embedded in the language are not sufficient. This paper presents an approach which allows the set of built-in abstractions to be augmented when the need for a new data abstraction is discovered. This approach to the handling of abstraction is an outgrowth of work on designing a language for structured programming. Relevant aspects of this language are described, and examples of the use and definitions of abstractions are given...|$|R
40|$|In {{this paper}} we address two {{problems}} concerned with the maintenance of safety-critical software. Firstly, we analyse the new issues required for the re-verse engineering of real-time existing code to extract high level designs. Secondly, we present a possible de-sign, abstraction mechanism {{that can be used}} for safety-critical software. We use formal transformations both in the reuerse engineering of systems involving tem-representation. We present a design framework and the results of initial experiments. The contributions are: (I) the requirements analysis for reverse engi-neering safety-critical systems, (2) the use of <b>very-high-level</b> domain <b>languages,</b> and (3) formal transfor-mations QS the unifying technology...|$|R
50|$|The {{spirit of}} the Meta-IV {{specification}} language is well captured by the following passageWe stress here... that the meta-language is to be used, not for solving algorithmic problems (on a computer), but for specifying, in an implementation-independent way, the architecture (or models) of software. Instead of using informal English mixed with technical jargon, we offer you a <b>very-high-level</b> 'programming' <b>language.</b> We do not offer an interpreter or compiler for this meta-language. And we have absolutely no intention of ever wasting our time trying to mechanize this meta-language. We wish, as we {{have done in the}} past, and as we intend to continue doing in the future, to further develop the notation and to express notions in ways for which no mechanical interpreter system can ever be provided.VDM is a Method. The Meta-IV was the Specification language that accompanied the method, and the VDM-SL is the current standardized form of that language.|$|R
40|$|Bibliography: leaves 203 - 210. A <b>very-high-level</b> data {{manipulation}} <b>language</b> for a database system {{is one in}} which the user specifies in non-procedural terms the operations that are to be performed on the data stored in the database; the actual method by which the operations are executed does not concern the user. VIADUCT provides such an interface to a microcomputer-based database system known as MDBS. Thus VIADUCT allows a microcomputer user lacking in computer sophistication to interact with, and derive the benefits of, a powerful database management system. Additional security restrictions and integrity constraints usually found only on mainframe database management systems are provided by VIADUCT through the mechanism of a subschema generator...|$|R
40|$|BULK is a <b>very-high-level</b> {{persistent}} programming <b>language</b> {{and environment}} for prototyping and implementing database applications. BULK provides sets and sequences as primitive type constructors, provides high-level operations on them, and allows programmers to define application-oriented bulk types, e. g. syntax trees, bond portfolios, or (geographic) maps. BULK encourages separation of correctness and efficiency concerns by distinguishing logical type from representation. BULK supports a three-step development paradigm consisting of (i) prototyping, (ii) intensive analysis, optimization, and data structure selection by the compiler to achieve efficiency, and (iii) if efficiency is still inadequate, hot-spot refinement [CGK 89]. (In hot-spot refinement developers remove performance bottlenecks {{by providing the}} compiler with more information, by directing its optimization efforts, or by re-implementation.) Step (i) focuses on correctness, steps (ii) and (iii) on efficiency. Our goal is an implementation that can usually achieve acceptable efficiency by step (ii) and that provides a tractable interface for hot-spot refinement...|$|R
40|$|Constraint Handling Rules (CHR) is a <b>very-high-level</b> {{declarative}} programming <b>language</b> {{based on}} concurrent multiset rewrite rules that are conditional, multiheaded, and committed-choice. Originally {{designed in the}} early 1990 s as a specialpurpose programming language for adding user-defined constraint solvers to a host language, CHR has evolved {{over the last decade}} into a powerful and elegant general-purpose language with a wide spectrum of application domains. Computational complexity theory is the study of scalability of computer programs in terms of the computational resources they require — in particular, time (cpu usage) and space (memory usage). In this dissertation we investigate the CHR programming language {{from the point of view}} of computational complexity theory. The first part introduces complexity theory, CHR, and CHR compilation. In the second part, we improve the state of the art by proposing and implementing several compiler optimizations. We confirm experimentally that these optimizations improve both the time an...|$|R
40|$|Development of {{large-scale}} grammars for natural languages {{is a complicated}} endeavor: Grammars are developed collaboratively by teams of linguists, computational linguists, and computer scientists, in a process {{very similar to the}} development {{of large-scale}} software. Grammars are written in grammatical formalisms that resemble <b>very-high-level</b> programming <b>languages,</b> and are thus very similar to computer programs. Yet grammar engineering is still in its infancy: Few grammar development environments support sophisticated modularized grammar development, in the form of distribution of the grammar development effort, combination of sub-grammars, separate compilation and automatic linkage, information encapsulation, and so forth. This work provides preliminary foundations for modular construction of (typed) unification grammars for natural languages. Much of the information in such formalisms is encoded by the type signature, and we subsequently address the problem through the distribution of the signature among the different modules. We define signature modules and provide operators of module combination. Modules may specify only partial information about the components of the signature and may communicate through parameters, similarly to function calls in programming languages. Our definitions are inspired by methods and techniques of programming language theory and software engineering and are motivated by the actual needs of grammar developers, obtained through a careful examination of existing grammars. We show that our definitions meet these needs by conforming to a detailed set of desiderata. We demonstrate the utility of our definitions by providing a modular design of the HPSG grammar of Pollard and Sag. 1...|$|R
40|$|In {{order to}} be truly portable, a program must be {{tolerant}} {{of a wide range}} of development and execution environments, and a parallel program is just one which must be tolerant of a very wide range. First, the term "tolerant programming " is defined. Then, a formal model called F-Nets is described in which parallel algorithms are expressed as folded partial-orderings of operations, and this is argued to provide a suitable framework for building tolerant programs. Finally, Software Cabling (SC), a <b>very-high-level</b> graphical programming <b>language,</b> demonstrates how many of the features normally expected from today's computer languages (e. g. data abstraction and data parallelism) can be obtained within the F-Net paradigm. 1. Introduction The subgoals of parallel processing are very similar to the subgoals of software engineering in general [...] -i. e. the decomposition of a large problem into smaller tasks or modules, the precise expression of the scope of data and the semantics of sharing and com [...] ...|$|R
40|$|In {{order to}} be truly portable, a program must be {{tolerant}} {{of a wide range}} of development and execution environments, and a parallel program is just one which must be tolerant of a very wide range. This paper first defines the term "tolerant programming", then describes many layers of tools to accomplish it. The primary focus is on F-Nets, a formal model for expressing computation as a folded partial-ordering of operations, thereby providing an architecture-independent expression of tolerant parallel algorithms. For implementing F-Nets, Cooperative Data Sharing (CDS) is a subroutine package for implementing communication efficiently in a large number of environments (e. g. shared memory and message passing). Software Cabling (SC), a <b>very-high-level</b> graphical programming <b>language</b> for building large F-Nets, possesses many of the features normally expected from today's computer languages (e. g. data abstraction, array operations). Finally, L 2 (sup 3) is a CASE tool which facilitates the construction, compilation, execution, and debugging of SC programs...|$|R

