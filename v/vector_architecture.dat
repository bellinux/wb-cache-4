61|219|Public
50|$|Several POWER5 {{processors}} in high-end {{systems can}} be coupled together {{to act as a}} single vector processor by a technology called ViVA (Virtual <b>Vector</b> <b>Architecture).</b>|$|E
50|$|An early {{version of}} the {{software}} {{was one of the}} first applications of parallel vector computing, the predecessor to today's multi-core processors, to geological research. The current release is multithreaded, and as such retains features of the early parallel <b>vector</b> <b>architecture.</b>|$|E
50|$|The vector {{register}} unit, {{also known}} as the vector register file, implemented the 16 vector registers defined by the VAX <b>vector</b> <b>architecture.</b> The vector register file was multi-ported and contained three write ports and five read ports. Each register consisted of 64 elements, and each element was 72 bits wide, with 64 bits used to store data and 8 bits used to store parity information.|$|E
40|$|<b>Vector</b> <b>architectures</b> {{have long}} been the of choice for {{building}} supercomputers. They {{first appeared in the}} early seventies and had a long period of unquestioned dominance from the time the CRAY- 1 was introduced in 1976 until the the appearance of "killer micros", in 1991. They still have a foothold in the supercomputer marketplace, although their continued viability, in the face of micro-based parallel systems, is being seriously questioned. We present a brief history of supercomputing and discuss the merits of <b>vector</b> <b>architectures.</b> Then we relate the advantages of <b>vector</b> <b>architectures</b> with current trends in computer system and device technology. Although the viability of vector supercomputers is indeed questionable, largely because of cost issues, we argue that <b>vector</b> <b>architectures</b> have a long future ahead of them [...] with new applications and commodity implementations. Vector instruction sets have many fundamental advantages and deserve serious consideration for implementation in next generation computer systems, where graphics and other multimedia applications will abound...|$|R
5000|$|<b>Vector</b> <b>architectures</b> that stream <b>vector</b> {{elements}} into functional {{units from}} special vector registers are termed register-to-register architectures, while those that feed functional units from special memory buffers are designated as [...] memory-to-memory architectures. [...] Early examples of register-to-register architectures from the 1960s and early 1970s include the Cray-1 and Fujitsu VP-200, while the Control Data Cyber 205 and Texas Instruments Advanced Scientific Computer [...] are early examples of memory-to-memory <b>vector</b> <b>architectures.</b>|$|R
40|$|We compare {{implementations}} of two integer factorisation algorithms, the {{elliptic curve}} method (ECM) and {{a variant of}} the Pollard &quot;rho &quot; method, on three machines (the Fujitsu AP 1000, VP 2200 and VPP 500) with parallel and/or <b>vector</b> <b>architectures.</b> ECM is scalable and well suited for both <b>vector</b> and parallel <b>architectures...</b>|$|R
50|$|Featuring a 1-8 way {{very long}} {{instruction}} word (VLIW, Multiple Instruction Multiple Data (MIMD), up to 256 bit) instruction set it additionally uses a 4-way single instruction, multiple data (SIMD) vector processor core. A 32-bit RISC instruction {{set in the}} superscalar core is combined with most variants integrating a dual 16-bit media processor also in VLIW and <b>vector</b> <b>architecture.</b> Each processor core is superpipelined as well as 4-unit superscalar.|$|E
50|$|Throughout, Cray {{continued}} to be the performance leader, continually beating the competition {{with a series of}} machines that led to the Cray-2, Cray X-MP and Cray Y-MP. Since then, the supercomputer market has focused much more on massively parallel processing rather than better implementations of vector processors. However, recognising the benefits of vector processing IBM developed Virtual <b>Vector</b> <b>Architecture</b> for use in supercomputers coupling several scalar processors to act as a vector processor.|$|E
50|$|The VAX 9000's CPU was {{coupled with}} a vector {{processor}} with a maximum theoretical performance of 125 MFLOPS. The vector processor circuitry was present in all units shipped and disabled via a software switch on units sold 'without' the vector processor. The vector processor {{was referred to as}} the V-box, and it was Digital's first ECL implementation of the VAX <b>Vector</b> <b>Architecture.</b> The design of the vector processor began in 1986, two years after development of the VAX 9000 CPU had begun.|$|E
40|$|A non-coherent <b>vector</b> delay/frequency-locked loop <b>architecture</b> for GNSS {{receivers}} is proposed. Two dynamics {{models are}} considered: PV (position and velocity) and PVA (position, velocity, and acceleration). In contrast with other <b>vector</b> <b>architectures,</b> the proposed approach {{does not require}} the estimation of signals amplitudes. Only coarse estimates of the carrier-to-noise ratios are necessary...|$|R
50|$|The late 1980s {{and early}} 1990s saw the {{introduction}} of <b>vector</b> <b>architectures,</b> such as the Cray Y-MP/4 and Nippon Electric Corporation SX-3 that supported 4-10 vector processors with a shared memory (see NEC SX architecture).|$|R
40|$|Simultaneous multithreaded <b>vector</b> <b>architectures</b> {{combine the}} best of data-level and instruction-level {{parallelism}} and perform better than either approach could separately. Our design achieves performance equivalent to executing 15 to 26 scalar instructions/cycle for numerical applications. Peer ReviewedPostprint (published version...|$|R
50|$|ViVA (Virtual <b>Vector</b> <b>Architecture)</b> is a {{technology}} from IBM for coupling together multiple scalar floating point units {{to act as}} a single vector processor. Certain computing tasks are more efficiently handled through vector computations where an instruction can be applied to multiple elements simultaneously, rather than the scalar approach where one instruction is applied to one piece of data at a time. This kind of technology is highly sought after for scientific computing and is IBM's answer to the vector-based supercomputers pioneered by Cray and that was the basis for NEC's Earth Simulator which was the fastest supercomputer in the world 2002-2004.|$|E
5000|$|POWER6 {{also takes}} {{advantage}} of ViVA-2, Virtual <b>Vector</b> <b>Architecture,</b> which enables the combination of several POWER6 nodes {{to act as a}} single vector processor. Each core has two integer units, two binary floating-point units, an AltiVec unit, and a novel decimal floating-point unit. The binary floating-point unit incorporates “many microarchitectures, logic, circuit, latch and integration techniques to achieve a 6-cycle, 13-FO4 pipeline,” according to a company paper. [...] Unlike the servers from IBM's competitors, the POWER6 has hardware support for IEEE 754 decimal arithmetic and includes the first decimal floating-point unit integrated in silicon. More than 50 new floating point instructions handle the decimal math and conversions between binary and decimal. This feature was also added to the z10 microprocessor featured in the System z10.|$|E
40|$|In {{this work}} we {{have studied the}} {{influence}} of the vector register size over two different concepts of vector architectures. We have observed that, long vector registers {{play an important role in}} a conventional <b>vector</b> <b>architecture.</b> However, we observed that even using highly vectorizable codes, only a small fraction of that large vector registers is used. Nevertheless, we have observed that, reducing vector register size on a conventional <b>vector</b> <b>architecture,</b> result in a severe performance degradation, providing slowdowns in the range of 1. 8 to 3. 8. When we including an out-of-order execution on a <b>vector</b> <b>architecture,</b> the necessity of long vector registers, is reduced. We have used a trace driven approach to simulate a selection of the Perfect Club and Specfp 92 programs. The results of the simulations show that, the register size reduction on an outof -order <b>vector</b> <b>architecture</b> is less negative than in a conventional vector machine, providing slowdowns in the range of 1. 0 [...] ...|$|E
40|$|Teaching {{methodology}} Learning {{objectives of}} the subject To provide students with the general concepts and techniques used in current high-performance general purpose microprocessors and systems. Basic contents of the course are the following: Processor design, pipelined processors, superscalar processors, multiprocessor and <b>vector</b> <b>architectures.</b> 1 /...|$|R
40|$|Abstract — The {{efficient}} {{processing of}} MultiMedia Applications (MMAs) is currently {{one of the}} main bottlenecks in the media processing field. Many architectures have been proposed for processing MMAs such as VLIW, superscalar (general-purpose processor enhanced with a multimedia extension such as MMX), <b>vector</b> <b>architectures,</b> SIMD architectures, and reconfigurable computing devices. The question then arises: which architecture can exploit the characteristic features of MMAs the most? In this paper, first, we explain the characteristics of MMAs, after that we discuss the different architectures that have been proposed for processing MMAs. Subsequently, they are compared based on their ability to exploit the characteristics of MMAs. Superscalar processors with dynamic out-of-order scheduling provide higher performance than VLIW processors and than superscalar processors with in-order scheduling. Because superscalar architectures include complicated control logic for out-of-order execution, and because VLIW processors have to decode every instruction slot in parallel and need a register file with multiple read and write ports, they are more complex than single-issue <b>vector</b> <b>architectures...</b>|$|R
40|$|Conflicts often arise {{during the}} {{optimisation}} of NWP codes for MPP's and <b>vector</b> parallel <b>architectures,</b> as caches {{rely heavily on}} temporal locality whereas <b>vector</b> <b>architectures</b> rely heavily on spatial locality. Furthermore, any scheme which addresses these conflicts must involve minimal code modification and not detract from the underlying science. This paper uses a macrotasking approach within which we address load balance, cache use and vector length issues for the physics portion of the UM. We concentrate on the three most computationally demanding routines in the model, long wave radiation, short wave radiation, and convection...|$|R
40|$|This paper {{presents}} {{a study of}} the impact of reducing the vector register size in a decoupled <b>vector</b> <b>architecture.</b> In traditional in-order vector architectures, long vector registers have typically been the norm. We start presenting data that shows that, even for highly vectorizable codes, {{only a small fraction of}} all elements of a long vector register are actually used. We also show that reducing the register size in a traditional <b>vector</b> <b>architecture</b> in an attempt to reduce hardware cost and maximize register utilization results in a severe performance degradation. However, we combine the decoupling technique with the vector register reduction and show that the resulting architecture tolerates very well the register size cuts. We simulate a selection of Perfect Club and Specfp 92 programs using a trace driven approach and compare the execution time in a conventional <b>vector</b> <b>architecture</b> with a decoupled <b>vector</b> <b>architecture</b> using different registers sizes. Halving the register size and u [...] ...|$|E
40|$|The paper {{presents}} {{a study of}} the impact of reducing the vector register size in a decoupled <b>vector</b> <b>architecture.</b> In traditional in-order vector architectures long vector registers have typically been the norm. The authors present data which shows that, even for highly vectorizable codes, {{only a small fraction of}} all elements of a long vector register are actually used. They also show that reducing the register size in a traditional <b>vector</b> <b>architecture</b> in an attempt to reduce hardware cost and maximize register utilization results in a severe performance degradation. However they combine the decoupling technique with the vector register reduction and show that the resulting architecture tolerates very well the register size cuts. They simulate a selection of Perfect Club and Specfp 92 programs using a trace driven approach and compare the execution time in a conventional <b>vector</b> <b>architecture</b> with a decoupled <b>vector</b> <b>architecture</b> using different registers sizes. Halving the register size and using decoupling provides speedups between 1. 04 - 1. 49 over a traditional in-order vector machines. Even reducing the register length to 1 / 4 the original size (and in some cases, to 1 / 8) the performance of the decoupled machine is better than a conventional vector model. Moreover they observe that the resulting decoupled machine with short registers tolerates very well long memory latencies. Peer ReviewedPostprint (published version...|$|E
40|$|A major {{challenge}} facing computer architects today is designing cost-effective hardware that executes multiple operations simultaneously. The goal of such designs {{is to improve}} performance {{by taking advantage of}} fine-grain parallelism. In this dissertation, I study vector architectures, the oldest of several processor designs that support fine-grain parallelism. Because implementing a cost-effective processor that performs well requires studying not only the design of processors but also the design of algorithms for compilers, this dissertation encompasses aspects of both hardware and software design. In {{the first half of this}} dissertation, I demonstrate that a <b>vector</b> <b>architecture</b> is a cost-effective processor that supports fine-grain parallelism. I show that implementing a <b>vector</b> <b>architecture</b> is no more costly than implementing a superscalar architecture, which is currently popular among designers of VLSI microprocessors. I then show that programs that are rich in parallelism tend als [...] ...|$|E
40|$|During {{the last}} decade the {{scientific}} computing community has optimized many applications for execution on superscalar computing platforms. The recent arrival of the Japanese Earth Simulator has revived interest in <b>vector</b> <b>architectures</b> especially in the US. It is important to examine how to port our current scientific applications to the new vector platforms and how to achieve high performance. The success of porting these applications will also influence the acceptance of new <b>vector</b> <b>architectures.</b> In this paper, we first investigate the memory performance characteristics of the Cray X 1, a recently released vector platform, and determine the most influential performance factors. Then, we examine how to optimize applications tuned on superscalar platforms for the Cray X 1 using its performance characteristics as guidelines. Finally, we evaluate {{the different types of}} optimizations used, the effort for their implementations, and whether they provide any performance benefits when ported back to superscalar platforms...|$|R
40|$|A {{limitation}} of the direct simulation Monte Carlo (DSMC) method {{is that it does}} not allow efficient use of <b>vector</b> <b>architectures</b> that predominate in current supercomputers. Consequently, the problems that can be handled are limited to those of one- and two-dimensional flows. This work focuses on a reformulation of the DSMC method with the objective of designing a procedure that is optimized to the <b>vector</b> <b>architectures</b> found on machines such as the Cray- 2. In addition, it focuses on finding a better balance between algorithmic complexity and the total number of particles employed in a simulation so that the overall performance of a particle simulation scheme can be greatly improved. Simulations of the flow about a 3 D blunt body are performed with 10 to the 7 th particles and 4 x 10 to the 5 th mesh cells. Good statistics are obtained with time averaging over 800 time steps using 4. 5 h of Cray- 2 single-processor CPU time...|$|R
40|$|<b>Vector</b> <b>architectures</b> {{have been}} {{traditionally}} {{applied to the}} supercomputing domain with many successful incarnations. The energy efficiency and high performance of vector processors, {{as well as their}} applicability in other emerging domains, encourage pursuing further research on <b>vector</b> <b>architectures.</b> However, {{there is a lack of}} appropriate tools to perform this research. This paper presents two tools for measuring and analyzing an application's suitability for vector microarchitectures. The first tool is VALib, a library that enables hand-crafted vectorization of applications and its main purpose is to collect data for detailed instruction level characterization and to generate input traces for the second tool. The second tool is SimpleVector, a fast trace-driven simulator that is used to estimate the execution time of a vectorized application on a candidate vector microarchitecture. The potential of the tools is demonstrated using six applications from emerging application domains such as speech and face recognition, video encoding, bioinformatics, machine learning and graph search. The results indicate that 63. 2...|$|R
40|$|We {{examine the}} {{importance}} of problem formulation for the solution of large-scale optimization problems on high-performance architectures. We use limited memory variable metric methods to illustrate performance issues. We show that the performance of these algorithms is drastically affected by application implementation. Model applications are drawn from the MINPACK- 2 test problem collection, with numerical results from a super-scalar architecture (IBM RS 6000 / 370), a <b>vector</b> <b>architecture</b> (CRAY- 2), and a massively parallel architecture (Intel DELTA). Key words. optimization, large-scale, limited memory, variable metric, performance evaluation, <b>vector</b> <b>architecture,</b> parallel architecture. AMS subject classifications. 65 Y 05, 65 Y 20, 65 K 05, 65 K 10, 90 C 06, 90 C 30 1. Introduction. Our aim is to explore performance issues associated with the solution of large-scale optimization problems on high-performance architectures. The solution of these problems, where the number of variables ranges betwe [...] ...|$|E
40|$|This article {{discusses}} GUI {{development for}} GRASS GIS. Sophisticated native GUI for GRASS {{is one of}} the key points (besides the new 2 D/ 3 D raster library, <b>vector</b> <b>architecture</b> improvements, etc.) for the future development of GRASS. In 2006 the GRASS development team decided to start working on the new generation of GUI instead of improving the current GUI based on Tcl/Tk...|$|E
40|$|Many {{scientific}} applications involve {{operations on}} sparse matrices. However, due to irregularities {{induced by the}} sparsity patterns, many operations on sparse matrices execute inefficiently on traditional scalar and vector architectures. To tackle this problem a scheme has been proposed consisting of two parts: (a) An extension to a <b>vector</b> <b>architecture</b> to support sparse matrix-vector multiplication using (b) a novel Blocked Based sparse matrix Compression Storage (BBCS) format. Within this context, {{in this paper we}} propose and describe a hardware mechanism for the extended <b>vector</b> <b>architecture</b> that performs the transposition A of a sparse matrix A using a hierarchical variation of the aforementioned sparse matrix compression format. The proposed Sparse matrix Transposition Mechanism (STM) is used as a Functional Unit for a vector processor and requires an s s word in-processor memory where s is the vector processor's section size. In this paper we provide a full description of the STM and show an expected performance increase of one order of magnitude...|$|E
40|$|The {{purpose of}} this paper is to show that using {{decoupling}} techniques in a vector processor, the performance of vector programs can be greatly improved. We will show how, even for an ideal memory system with no latency, decoupling provides a significant advantage over standard mode of operation. We will also present data showing that for more realistic latencies, decoupled <b>vector</b> <b>architectures</b> perform substantially better than non-decoupled <b>vector</b> <b>architectures.</b> We will also introduce a bypassing technique between the queues and show how it can reduce the total memory traffic. A side effect of the decoupling technique presented is that it tolerates so well long memory latencies that could make feasible to use very slow DRAM parts in vector computers in order to reduce cost. 1 Introduction Recent years have witnessed an increasing gap between processor speed and memory speed, which is due to two main reasons. First, technological improvements in cpu speed have not been matched [...] ...|$|R
40|$|AbstractIn {{this paper}} an inverse QR {{decomposition}} based recursive least-squares algorithm for linearly constrained minimum variance filtering is proposed. The proposed algorithm is numerically stable in finite precision environments and {{is suitable for}} implementation in systolic arrays or DSP <b>vector</b> <b>architectures.</b> Its performance is illustrated by simulations of a blind receiver for a multicarrier CDMA communication system and compared with previously proposed inverse QR decomposition recursive least-squares algorithms...|$|R
40|$|Geology and Geophysics, University of Minnesota (DGG/UMN) on {{analysis}} and visualization of large-scale simulation data of mantle convection. Our analysis revealed possible {{impacts of the}} post-perovskite phase transition on the dynamics in the Earth's lower mantle. Through the collaborative works, we also demonstrated that the ACuTEMan, a simulation code developed by SESG/ESC, shows an excellent performance on scalar architectures {{as well as on}} <b>vector</b> <b>architectures</b> like the Earth Simulator...|$|R
40|$|Abstract—Many {{scientific}} applications involve {{operations on}} sparse matrices. However, due to irregularities {{induced by the}} sparsity patterns, many operations on sparse matrices execute inefficiently on traditional scalar and vector architectures. To tackle this problem a scheme has been proposed consisting of two parts: (a) An extension to a <b>vector</b> <b>architecture</b> to support sparse matrix-vector multiplication using (b) a novel Blocked Based sparse matrix Compression an×¢× Storage (BBCS) format. Within this context, {{in this paper we}} propose and describe a hardware mechanism for the extended <b>vector</b> <b>architecture</b> that performs the transposition�Ìof a sparse matrix�using a hierarchical variation of the aforementioned sparse matrix compression format. The proposed Sparse matrix Transposition Mechanism (STM) is used as a Functional Unit for a vector processor and requires word in-processor memory where×is the vector processor’s section size. In this paper we provide a full description of the STM and show an expected performance increase of one order of magnitude...|$|E
40|$|Front-end signal {{processing}} {{is a crucial}} stage for speech recognition systems. The capability of operating in adverse conditions, with high background noise and different channel characteristics, {{is one of the}} major goals when developing automatic speech recognition systems for use in real world environments. In addition, the need for real-time performance and the large amount of computation often require the use of specialized architectures. We describe the study of the mapping of a fundamental part of speech recognition systems - a robust speech front end algorithm called RASTA - to the Torret architecture. This architecture, developed at ICSI, is a high performance <b>vector</b> <b>architecture</b> optimized for {{signal processing}} task. The mapping problem is particularly relevant because at the moment there is no e- cient automatic tool for implementing algorithms on the Spert architecture. An appropriate algorithms analysis is shown, as well as the design of optimal library routines which allow to fully exploit the <b>vector</b> <b>architecture.</b> Preliminary functional and performance comparisons with more standard architectures are shown...|$|E
40|$|The {{purpose of}} this paper is to show that {{decoupling}} techniques can be applied to a vector processor, resulting in a large increase in performance of vectorizable programs. Using a trace driven approach, we simulate a selection of the Perfect Club and Specfp 92 programs and compare their execution time on a conventional single port <b>vector</b> <b>architecture</b> and on a decoupled <b>vector</b> <b>architecture.</b> Decoupling provides a performance advantage of more than a factor of 1. 4 for realistic memory latencies, and even with an ideal memory system with zero latency, there is still a speedup of as much as 1. 31. An important part of this paper is devoted to study the tradeoffs involved in choosing an suitable size for the different queues of the architecture, so that the hardware cost of the queues is reduced while still retaining most of the performance advantages of decoupling. Keywords: Vector architectures, decoupling, instruction-level parallelism, memory latency 1. Introduction Recent years have [...] ...|$|E
40|$|Spiral is {{a program}} {{generator}} for linear transforms such as the discrete Fourier transform. Spiral generates highly optimized code directly from a problem specification {{using a combination of}} techniques including optimization at a high level of abstraction using rewriting of mathematical expressions and heuristic search for platform adaptation. In this paper, we overview the generation of parallel programs using Spiral. This includes programs for <b>vector</b> <b>architectures</b> and programs for shared or distributed memory platforms...|$|R
40|$|Abstract. <b>Vector</b> <b>architectures</b> {{have proven}} to be the best choice if we want to achieve high {{performance}} when executing numerical applications and multimedia. In this paper we describe a project whose main goal is to obtain a detailed description of a traditional vector processor using VHDL Hardware Description Language. This work will be very useful for direct application on computer architecture and digital systems courses at universities. Research on power consumption and improved architectures can be benefited also...|$|R
40|$|Traditional <b>vector</b> <b>architectures</b> {{often lack}} virtual memory support {{because it is}} {{difficult}} to support fast and precise exceptions for these machines. In this paper, we propose a new exception handling model for <b>vector</b> <b>architectures</b> based on software restart markers, which divide the program into idempotent regions of code. Within a region, the processor can commit instruction results to the architectural state in any order. If an exception occurs, the machine jumps immediately to the exception handler and kills ongoing instructions. To restart execution, the operating system has just to begin execution {{at the start of the}} region. This approach avoids the area and energy overhead to buffer uncommitted vector unit state that would otherwise be required with a high-performance precise exception mechanism, but still provides a simple exception handling interface for the operating system. Our scheme also removes the requirement of preserving vector register file contents in the event of a context switch. We show that using our approach causes an average performance reduction of less than 3 % across a variety of benchmarks compared with a vector machine that does not support virtual memory...|$|R
