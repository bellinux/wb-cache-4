2693|9503|Public
5|$|Zodiac was {{the first}} {{production}} to employ the Filmstream camera in its native Filmstream mode, which records an uncompressed <b>video</b> <b>stream,</b> allowing for exceptional quality.|$|E
5|$|ARC is {{an audio}} link meant to replace other cables between the TV and the A/V {{receiver}} or speaker system. This direction is used when the TV {{is the one}} that generates or receives the <b>video</b> <b>stream</b> instead of the other equipment. A typical case is the running of an app on a smart TV such as Netflix, but reproduction of audio is handled by the other equipment. Without ARC, the audio output from the TV needs to be routed by another cable, typically TOS-Link or coax, into the speaker system.|$|E
5|$|Both HDMI and DVI use TMDS to send 10-bit {{characters}} that are encoded using 8b/10b encoding that {{differs from the}} original IBM form for the Video Data Period and 2b/10b encoding for the Control Period. HDMI adds the ability to send audio and auxiliary data using 4b/10b encoding for the Data Island Period. Each Data Island Period is 32 pixels in size and contains a 32-bit Packet Header, which includes 8 bits of BCH ECC parity data for error correction and describes {{the contents of the}} packet. Each packet contains four subpackets, and each subpacket is 64 bits in size, including 8 bits of BCH ECC parity data, allowing for each packet to carry up to 224 bits of audio data. Each Data Island Period can contain up to 18 packets. Seven of the 15 packet types described in the HDMI 1.3a specifications deal with audio data, while the other 8 types deal with auxiliary data. Among these are the General Control Packet and the Gamut Metadata Packet. The General Control Packet carries information on AVMUTE (which mutes the audio during changes that may cause audio noise) and Color Depth (which sends the bit depth of the current <b>video</b> <b>stream</b> and is required for deep color). The Gamut Metadata Packet carries information on the color space being used for the current <b>video</b> <b>stream</b> and is required for xvYCC.|$|E
40|$|This paper {{considers}} {{the problem of}} multiple <b>video</b> <b>streaming</b> over wireless local area networks. In particular, we propose <b>video</b> <b>streaming</b> techniques {{to improve the quality}} of <b>video</b> <b>streams</b> in the link between an access point and multiple wireless clients. The proposed <b>video</b> <b>streaming</b> techniques decide on clients to be served, packet (re) transmissions as well as FEC rates by considering media, channel, and network properties in rate-distortion optimized manner. Multi-client rate distortion optimized <b>video</b> <b>streaming</b> is the first technique operated by an access point to jointly optimize client, packet, and FEC selection for <b>video</b> <b>streaming.</b> Second, we proposed multi-client sub-optimal <b>video</b> <b>streaming</b> technique that optimizes packet and FEC rate, but not client. The client is selected by using the results of optimization to reduce the computational complexity. The simulation results shows that the proposed <b>video</b> <b>streaming</b> techniques achieve SNR improvement up-to 5 dB as compared with TDMA and packet adaptive TDMA...|$|R
40|$|<b>Video</b> <b>streaming</b> {{technology}} enables <b>video</b> content, {{held on the}} web sites, to be streamed via the web. We {{report the}} implementation and evaluation of <b>video</b> <b>streaming</b> in an undergraduate nursing program in a metropolitan university in Australia. Students (n = 703) were emailed a survey with a 15 % response rate. We found that 91 % (n = 74) of respondents stated that <b>video</b> <b>streaming</b> assisted their learning. Forty-six percent(n = 50) of students had difficulty accessing <b>video</b> <b>streaming</b> (particularly {{at the beginning of}} the study period). Over a 97 -day period there were 8440 “hits” to the site from 1039 different internet protocol (IP) addresses. There were 4475 <b>video</b> <b>streaming</b> sessions undertaken by users. <b>Video</b> <b>streaming</b> was used for reviewing previously attended lectures (52 %, n = 56), examination preparation (34 %, n = 37), viewing missed lectures (27 %, n = 29) and class preparation (9 %, n = 10). Our experience with the introduction of <b>video</b> <b>streaming</b> has met with general enthusiasm from both students and teaching staff. <b>Video</b> <b>streaming</b> has particular relevance for rural students. <br /...|$|R
5000|$|Afreeca: Online TV with P2P <b>video</b> <b>streaming</b> service. Users can upload {{their own}} videos {{as well as}} live <b>video</b> <b>streams.</b>|$|R
5|$|In June 2014, YouTube {{introduced}} videos {{playing at}} 60 frames per second, {{in order to}} reproduce video games with a frame rate comparable to high-end graphics cards. The videos play back at a resolution of 720p or higher. YouTube videos are available {{in a range of}} quality levels. The former names of standard quality (SQ), high quality (HQ), and high definition (HD) have been replaced by numerical values representing the vertical resolution of the video. The default <b>video</b> <b>stream</b> is encoded in the VP9 format with stereo Opus audio; if VP9/WebM is not supported in the browser/device or the browser's user agent reports Windows XP, then H.264/MPEG-4 AVC video with stereo AAC audio is used instead.|$|E
5|$|On 9June 2004, the {{day after}} the first of a 21st-century pair of Venus transits {{occurred}} as predicted by Horrocks, a commemorative street nameplate in memory of William Crabtree was unveiled at the junction of Lower Broughton Road and Priory Grove, which marks the northern boundary of Crabtree Croft. In December 2005, a commemorative plaque was unveiled a few yards away near Ivy Cottage on Lower Broughton Road, which is thought to have been the home of Crabtree and his family {{at the time he was}} collaborating with Horrocks. The second transit of the pair occurred on 5 and 6June 2012, and was marked by a celebration held in the church at Much Hoole, which was streamed live worldwide on the NASA website. A celebration was also held at Crabtree's former home in Broughton when NASA broadcast a re-creation of the observation at Ivy Cottage, inspired by the Ford Madox Brown mural, to millions of viewers, and projected a live <b>video</b> <b>stream</b> of the transit from Hawaii onto the side of the house.|$|E
5|$|HDMI 1.0 was {{released}} on December 9, 2002 and is a single-cable digital audio/video connector interface. The link architecture is based on DVI, using exactly the same video transmission format but sending audio and other auxiliary data during the blanking intervals of the <b>video</b> <b>stream.</b> HDMI 1.0 allows a maximum TMDS clock of 165MHz (4.95 Gbit/s), the same as DVI. It defined two connectors called Type A and Type B, with pinouts based on the Single-Link DVI-D and Dual-Link DVI-D connectors respectively, though the Type B connector was never used in any commercial products. HDMI 1.0 uses 8b/10b encoding for video transmission, giving it 3.96Gbit/s of video bandwidth (1920×1080 or 1920×1200 at 60Hz) and 8channel LPCM/192kHz/24-bit audio. HDMI 1.0 supported only 24bit/px color depth and required support for RGB video, with optional support for YCBCR 4:4:4 and 4:2:2 (mandatory if the device had support for YCBCR on other interfaces). Only the Rec. 601 and Rec. 709 color spaces were supported. HDMI 1.0 allowed only specific pre-defined video formats to be transmitted, including all the formats defined in EIA/CEA-861-B {{as well as some}} additional formats listed in the HDMI Specification itself. All HDMI sources are also required to be capable of sending or receiving native Single-Link DVI video and be fully compliant with the DVI Specification.|$|E
30|$|In short, FTP traffic {{consists}} of a stream of back-to-back packets similar to <b>video</b> <b>streaming</b> traffic with a difference {{that it has no}} ON-OFF cycle mechanism for transmission rate control {{as in the case of}} <b>video</b> <b>streaming,</b> but FTP traffic is asymmetric like <b>video</b> <b>streaming</b> traffic [3].|$|R
40|$|Abstract — The {{consistent}} superiority {{in terms}} of reduced packet loss to enhance video quality it is what this paper proposing. Prior investigation of <b>video</b> <b>streaming</b> over wireless networks has assumed a single access point and a homogeneous wireless technology. With different channel effects and conditions a long side the Hard Handover (HHO) consequences on mobile broadband <b>video</b> <b>streaming,</b> IEEE 802. 21, it is now becoming possible to offer seamless <b>video</b> <b>streaming</b> and harmonizing that influence. The paper presents a <b>video</b> <b>streaming</b> transport scheme that is more capable of exploiting the expected reduced latencies of real time <b>video</b> <b>streaming</b> content distribution networks. Broadband <b>Video</b> <b>Streaming</b> (BVS) with adaptive packet retransmission promises better video quality during an (HHO) than both raw UDP transport and traditional congestion-controlled streaming, making it attractive to mobile broadband <b>video</b> <b>streaming</b> services. It achieves this by distinguishing between high congestion and poor channel conditions, the latter of which an HHO induces, and by prioritized retransmission according to picture type...|$|R
40|$|<b>Video</b> <b>streaming</b> in MANETs is most Challenging {{issue and}} it mainly {{affected}} by these factors like node mobility, dynamic change in topology, multi path shadowing and fading, collusion, interference and many more. The dynamic change in topology causes periodic connectivity {{which results in}} large packet loss. <b>Video</b> <b>streaming</b> in real time requires special techniques that can overcome the losses of packets in the unreliable networks. Developments in mobile devices and wireless networking provide the technical platform for <b>video</b> <b>streaming</b> over mobile ad hoc networks (MANETs). And efforts to realize <b>video</b> <b>streaming</b> over MANETs have met many challenges, which are addressed by several different techniques. Here {{in this paper we}} have studied and reviewed many issues and different techniques present for <b>video</b> <b>streaming</b> over MANETs. This paper contain work done in the field of <b>video</b> <b>streaming</b> in MANETs and guide newcomers who are willing to work in <b>video</b> <b>streaming</b> in MANETs field. Keywords-Video streaming,MANETs, cross layer design, MDC, Multipath routing. I...|$|R
25|$|Playback {{hardware}} plays back {{an existing}} <b>video</b> <b>stream</b> from disk or tape based storage mediums, e.g. VHS tape players and DVD players.|$|E
25|$|In February and April 1990, Georges Cornuéjols {{introduced}} the first real-time HDR camera that combined two images captured by a sensor or simultaneously by two sensors of the camera. This process {{is known as}} bracketing used for a <b>video</b> <b>stream.</b>|$|E
25|$|VLC {{can handle}} some {{incomplete}} files {{and in some}} cases can be used to preview files being downloaded. Several programs make use of this, including eMule and KCeasy. The free/open-source Internet television application Miro also uses VLC code. HandBrake, an open-source video encoder, used to load libdvdcss from VLC Media Player. A program named Livestreamer may utilize VLC as its main <b>video</b> <b>stream</b> player and will not work without one.|$|E
40|$|Abstract <b>Video</b> <b>streaming</b> over {{wireless}} networks {{is becoming}} increasingly important {{for a variety of}} applications. To accommodate the dynamic change of wireless network bandwidths, Quality of Service (QoS) scalable <b>video</b> <b>streams</b> need to be provided. This paper presents a system of content-adaptive streaming of instructional (lecture) videos over wireless networks for E-learning applications. We first provide a real-time content analysis method to detect and extract content regions from instructional videos, then apply a “leaking-video-buffer ” model to adjust QoS of <b>video</b> <b>streams</b> dynamically based on video content. In content-adaptive <b>video</b> <b>streaming,</b> an adaptive feedback control scheme is also developed to transmit properly compressed <b>video</b> <b>streams</b> to <b>video</b> clients not only based on network bandwidth, but also based on video content and the preferences of users. Finally, we demonstrate the scalability and content adaptiveness of the proposed <b>video</b> <b>streaming</b> system with experimental results on several instructional videos. Keywords Instructional video analysis. Content-adaptive <b>video</b> <b>streaming.</b> E-learning 1...|$|R
40|$|<b>Video</b> <b>streaming</b> is {{becoming}} increasingly popular among the wireless users. However, supporting <b>video</b> <b>streaming</b> over the wireless networks {{is not an easy}} task due to the dynamic radio propagation environment, limited radio resources as well as Quality of Service (QoS) requirements of the <b>video</b> <b>streaming</b> that need to be satisfied at acceptable levels. Most studies proposed to support <b>video</b> <b>streaming</b> are computationally expensive to be used in Orthogonal Frequency Division Multiple Access (OFDMA) based wireless IP networks. This paper evaluates <b>video</b> <b>streaming</b> performance under three well-known algorithms that are more practical {{to be used in the}} OFDMA based wireless IP networks due to their reduced complexity. It is demonstrated via computer simulation that Proportional Fair (PF) algorithm outperforms other well-known algorithms by providing <b>video</b> <b>streaming</b> QoS at acceptable levels whilst maximizing cell throughput...|$|R
5000|$|... 2015 - Based on {{the modern}} {{technological}} basis was issued Web Call Server 4 version, which allowed {{not only to}} make SIP calls, but also to use the product in a <b>video</b> <b>streaming</b> server mode and broadcasts. There were two sets of options: calls and <b>streaming</b> <b>video.</b> Block 'call' {{was responsible for the}} integration with the SIP, and 'streaming' block - for standard <b>video</b> <b>streaming</b> functions, such as the publication of an arbitrary number of <b>video</b> <b>streams,</b> playback of <b>video</b> <b>streams</b> from the server, security, etc.|$|R
25|$|Independent Phoenix {{television}} station KTVK broadcast a live <b>video</b> <b>stream</b> from a Webcam located {{outside of the}} University of Phoenix Stadium. The camera provided millions of Internet users {{from around the world}} a chance to peer in on pre- and post-game activities, watching thousands of spectators file {{into and out of the}} stadium on Sunday, February 3. The Stadium Cam broadcast from Friday, February 1 to Monday, February 4, 2008 on the station's website.|$|E
25|$|The US ATSC digital {{television}} system originally specified two {{different kinds of}} closed captioning datastream standards: the original analog-compatible (available by Line 21) and the more modern digital-only CEA-708 formats are delivered within the <b>video</b> <b>stream.</b> The US FCC mandates that broadcasters deliver (and generate, if necessary) both datastream formats with the CEA-708 format merely a conversion of the Line 21 format. The Canadian CRTC has not mandated that broadcasters either broadcast both datastream formats or exclusively in one format. Most broadcasters and networks to avoid large conversion cost outlays just provide EIA-608 captions along with a transcoded CEA-708 version encapsulated within CEA-708 packets.|$|E
25|$|Like all thin clients, {{when using}} X across a network, {{bandwidth}} limitations can impede {{the use of}} bitmap-intensive applications that require rapidly updating large portions of the screen with low latency, such as 3D animation or photo editing. Even a relatively small uncompressed 640x480x24bit 30fps <b>video</b> <b>stream</b> can easily outstrip the bandwidth of a 100Mbit/s network for a single client. In contrast, modern versions of X generally have extensions such as MESA allowing local display of a local program's graphics to be optimized to bypass the network model and directly control the video card, for use of full-screen video, rendered 3D applications, and other such applications.|$|E
40|$|Compared {{with the}} {{traditional}} <b>video</b> <b>streaming</b> media system based on C/S mode, the <b>video</b> <b>streaming</b> media system based on P 2 P can efficiently solved the problems like single point of failure, high construction cost. Therefore, this study implemented a <b>video</b> <b>streaming</b> media system to provide the <b>video</b> <b>streaming</b> media service of high quality and large capacity. A mobile P 2 P <b>video</b> <b>streaming</b> media system architecture is firstly presented. Next, the design and implementation on the three modules, including server control program, client service program and client playing program, is introduced in detail. At last, the run results of each module as well are presented...|$|R
40|$|International audienceVideo {{streaming}} is {{a growing}} application on the Internet, and its growing pace is not slowing down. There have been {{a tremendous amount of}} work on <b>video</b> <b>streaming</b> over the Internet but nobody has ever studied in detail <b>video</b> <b>streaming</b> over a nano-wireless network. We think that <b>video</b> <b>streaming</b> could be a potential application for nano-wireless networks and we know that <b>video</b> <b>streaming</b> is a challenging application for networks. First, <b>video</b> <b>streaming</b> is a real-time transmission meaning that it is sensitive to delay and jitter. Second, it is often better not to retransmit losses to avoid video freezing. That is why nano-wireless layers will probably have to be tuned for <b>video</b> <b>streaming.</b> This article studies, through simulation, different scenarios of video transmission over a nanowireless network. We conclude that research needs better tools and models for such studies...|$|R
2500|$|Controversy also exists whether utility {{user tax}} “modernization” {{measures}} permit {{local governments to}} impose taxes on online <b>video</b> <b>streaming</b> services. [...] With regard to previously approved “modernization” measures, voters may have unknowingly authorized the imposition of taxes on online <b>video</b> <b>streaming</b> services. [...] This places greater emphasis {{on the need for}} voters to carefully review the text of any tax “modernization” measure to determine whether taxes on online <b>video</b> <b>streaming</b> services would be authorized. [...] To the extent that previously approved tax “modernization” measures are interpreted to include taxes on online <b>video</b> <b>streaming</b> services, voters/taxpayers have an available legislative remedy using the local initiative power under Proposition 218 to reduce or repeal any tax on online <b>video</b> <b>streaming</b> services.|$|R
25|$|In March 2013, Apple filed {{a patent}} for an {{augmented}} reality (AR) {{system that can}} identify objects in a live <b>video</b> <b>stream</b> and present information corresponding to these objects through a computer-generated information layer overlaid {{on top of the}} real-world image. The company also made several high-profile hiring decisions in 2013. On July 2, 2013, Apple recruited Paul Deneve, Belgian President and CEO of Yves Saint Laurent as a vice president reporting directly to Tim Cook. A mid-October 2013 announcement revealed that Burberry executive Angela Ahrendts will commence as {{a senior vice president at}} Apple in mid-2014. Ahrendts oversaw Burberry's digital strategy for almost eight years and, during her tenure, sales increased to about US$3.2 billion and shares gained more than threefold.|$|E
500|$|She {{covered the}} July 22, 2007, [...] "The Kill Point" [...] series premiere party live on her lifecast <b>video</b> <b>stream.</b> Ezarik was cited {{as among the}} website's most popular lifecasters in the October 2007 issues of both The New York Times and The Wall Street Journal.|$|E
500|$|Before each suite, the {{moderator}} would introduce the upcoming musical piece, {{as well as}} introduce the composer in attendance. Each [...] "Fantasy" [...] lasted for more than 15 minutes each. The Kingdom Hearts suite featured solo pianist Benyamin Nuss. For the Chrono suite, Rony Barrak joined the orchestra and performed on his signature darbuka. A surprise encore was performed after the final suite, which {{took the form of}} a medley of the final boss themes from each game. Rony Barrak returned on stage as a soloist for the encore. No video screens or other form of tools were used during the concert, with only minimal lighting effects at certain parts for atmosphere being employed. The event was broadcast live on the WDR4 radio station, as well as through an online <b>video</b> <b>stream,</b> enabling a worldwide audience to watch the concert. It was the first fully live-streamed video game concert.|$|E
30|$|The use of {{different}} streaming strategies change the traffic characteristics of <b>video</b> <b>streaming</b> traffic {{to some extent}} but <b>video</b> <b>streaming</b> traffic consists of back-to-back packets sent over {{a considerable amount of}} time no matter which streaming strategy is used. <b>Video</b> <b>streaming</b> traffic is asymmetric meaning its traffic volume is much larger at the downlink than at the uplink [3].|$|R
40|$|<b>Video</b> <b>streaming</b> {{has become}} a popular form of {{transferring}} video over the Internet. With the emergence of mobile computing needs, a successful <b>video</b> <b>streaming</b> solution demands 1) uninterrupted services even {{with the presence of}} mobility and 2) adaptive video delivery according to current link properties. In this paper we study the need and evaluate the performance of adaptive <b>video</b> <b>streaming</b> in vertical handoff scenarios. We use Universal Seamless Handoff Architecture (USHA) to create a seamless handoff environment, and use the Video Transfer Protocol (VTP) to adapt <b>video</b> <b>streaming</b> rates according to "Eligible Rate Estimates". Using testbed measurements experiments, we verify the importance of service adaptation, as well as show the improvement of user-perceived video quality, via adapting <b>video</b> <b>streaming</b> in the vertical handoffs...|$|R
40|$|<b>Video</b> <b>streaming</b> over lossy IP {{networks}} is {{very important}} issues, due to the heterogeneous structure of networks. Infrastructure of the Internet exhibits variable bandwidths, delays, congestions and time-varying packet losses. Because of variable attributes of the Internet, <b>video</b> <b>streaming</b> applications should not only have a good end-to-end transport performance but also have a robust rate control, furthermore multipath rate allocation mechanism. So for providing the <b>video</b> <b>streaming</b> service quality, some other components such as Bandwidth Estimation and Adaptive Rate Controller {{should be taken into}} consideration. This paper gives an overview of <b>video</b> <b>streaming</b> concept and bandwidth estimation tools and then introduces special architectures for bandwidth adaptive <b>video</b> <b>streaming.</b> A bandwidth estimation algorithm – pathChirp, Optimized Rate Controllers and Multipath Rate Allocation Algorithm are considered as all-in-one solution for <b>video</b> <b>streaming</b> problem. This solution is directed and optimized by a decision center which is designed for obtaining the maximum quality at the receiving side...|$|R
2500|$|Capture {{audio and}} <b>video</b> <b>stream</b> from device memory to bypass {{cryptography}} of Skype sessions ...|$|E
2500|$|Effects {{hardware}} {{allows the}} adding of special effects to the <b>video</b> <b>stream,</b> e.g. Colour Correction units ...|$|E
2500|$|Prerendered (also {{known as}} closed) {{subtitles}} are separate video frames that are overlaid {{on the original}} <b>video</b> <b>stream</b> while playing. Prerendered subtitles are used on DVD and Blu-ray (though they are contained in the same file as the <b>video</b> <b>stream).</b> It is possible to turn them off or have multiple language subtitles and switch among them, but the player has to support such subtitles to display them. Also, subtitles are usually encoded as images with minimal bitrate and number of colors; they usually lack anti-aliased font rasterization. Also, changing such subtitles is hard, but special OCR software, such as SubRip exists to convert such subtitles to [...] "soft" [...] ones.|$|E
50|$|<b>Video</b> <b>Streaming</b> Service/Site {{aggregators}} are {{services that}} scan across multiple <b>video</b> <b>streaming</b> sites {{to make it}} easier to find Movies and/or TV shows and where they are available to stream.|$|R
40|$|<b>Video</b> <b>streaming</b> is an {{important}} field of global communications and data processing. It is divided into server and client sides connected via network. <b>Video</b> <b>streaming</b> is concerned with delivering video data from server to client over the network as fast and with as little loss as possible. In this study the possibilities to minimize the amount of data transferred over the network in <b>video</b> <b>streaming</b> are investigated and a <b>video</b> <b>streaming</b> technique comprised of server and client sides is proposed. To expand the flexibility and adaptability of the proposed <b>video</b> <b>streaming</b> technique an operational parameter system was constructed and the parameter value ranges were defined. The proposed <b>video</b> <b>streaming</b> technique was then applied to three sample <b>videos.</b> Before <b>streaming</b> the server side of the proposed technique reduced the frame count of input videos based on operational parameter values while the client side reconstructed the skipped frames. Then {{the quality of the}} resulting videos was measured and evaluated. To evaluate the reconstructed frames and videos the PSNR measurement method was used. The study concludes that by using the proposed <b>video</b> <b>streaming</b> technique it is possible {{to reduce the amount of}} transfer data by dropping frames on the server side and reconstructing them on the client side...|$|R
40|$|Abstract: This {{tutorial}} gives {{a survey}} of actual used techniques for multicast <b>streaming</b> <b>video.</b> We first discuss important issues in <b>video</b> <b>streaming</b> namely <b>video</b> compression techniques and video compression standards. We then present the challenges in multicast <b>video</b> <b>streaming</b> and we give {{a detailed description of}} recent proposals for multicast <b>video</b> <b>streaming.</b> We classify these solutions into four approaches depending on the techniques used to adapt the reception video quality and on the source/receiver/network role...|$|R
