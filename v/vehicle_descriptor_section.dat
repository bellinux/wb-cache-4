1|31|Public
50|$|The fourth to eighth {{positions}} in the VIN are the <b>vehicle</b> <b>descriptor</b> <b>section</b> or VDS. This is used, according to local regulations, to identify the vehicle type, and may include information on the automobile platform used, the model, and the body style. Each manufacturer has a unique system for using this field. Most manufacturers since the 1980s have used the eighth digit to identify the engine type whenever {{there is more than}} one engine choice for the vehicle. Example: for the 2007 Chevrolet Corvette, U is for a 6.0-liter V8 engine, and E is for a 7.0 L V8.|$|E
3000|$|The {{two sets}} of Fourier <b>descriptors</b> (<b>Section</b> 5.1. 1) are entirely included, leading to the {{two sets of}} [...]...|$|R
30|$|This {{paper is}} {{organized}} as follows. In Section 2, we introduce a statistical signature as a color <b>descriptor.</b> <b>Section</b> 3 proposes a novel dissimilarity measure, PMHD, and partial PMHD for partial matching. Then, Section 4 presents the experimental results and {{discussions on the}} effectiveness of the proposed metric. Finally, conclusions are drawn in Section 5.|$|R
30|$|The {{outline of}} this paper is as follows. Section 2 {{describes}} the emotional speech database: structure of the corpora, methods for selecting of the recording source, and the process of emotional speech labeling. Section 3 introduces the examined speech <b>descriptors.</b> <b>Section</b> 4 presents obtained results. Finally, Sections 5 and 6 concludes and summarizes the paper.|$|R
30|$|The {{paper is}} {{organized}} as follows. In Section 2, The mathematical background is described. Section 3 shows the object regions descriptor {{and the new}} update solution for those <b>descriptors.</b> <b>Section</b> 4 describes the tracking algorithm using geometric particle filtering. Results on real image sequences for evaluating algorithm performance are discussed in Section 5.Section 6 concludes this paper.|$|R
30|$|The rest of {{the paper}} is {{organized}} as follows. Section 2 briefly discusses existing {{state of the art}} low-level feature <b>descriptors.</b> <b>Section</b> 3 describes the use of these feature descriptors in different applications. The proposed method is described in Section 4. Section 5 presents a rigorous comparative experimental evaluation on five different applications. Section 6 concludes the paper with future research scope.|$|R
30|$|We have {{evaluated}} our new Fourier descriptors on {{two different}} data sets, the MPEG- 7 database of unbroken shapes and a new real-world data set with broken shapes from scans of 19 th century chant books in the Eastern neumatic notation[20]. Both data sets are described in detail in Section 4.2. Apart from {{a performance comparison of}} the broken shape <b>descriptors</b> (<b>Section</b> 4.5), we have also investigated the effect of different normalisation schemes (Section 4.3) and the number of descriptors needed for similarity-based retrieval (Section 4.4).|$|R
30|$|This section {{discusses}} a set {{of experiments}} conducted for assessing the effectiveness of our method. We analyzed and compared the proposed method under several aspects, considering different datasets and <b>descriptors.</b> <b>Section</b> 7.1 discusses the experimental setup. Sections 7.2, 7.3, and 7.4 present the experimental results considering various shape, color, and texture <b>descriptors,</b> respectively. <b>Section</b> 7.5 in turn presents the results for multimodal image retrieval tasks. The main objective of these sections consists in assessing the improvements obtained by the proposed method along the relevance feedback sessions, evaluating the increase of effectiveness results. The goal of using various datasets and descriptors is {{to demonstrate that the}} proposed method can achieve significant gains regardless the considered description scenario. Experiments aiming at comparing the obtained results with related methods are presented in Section 7.6. Finally, Section 7.7 analyzes the impact of the number of users on the effectiveness of retrieval results.|$|R
30|$|In this section, {{we first}} {{introduce}} the test data in Section 3.1 and the DAISY <b>descriptor</b> in <b>Section</b> 3.2. Then, we explain how {{to select the}} parameters of the proposed method in Section 3.3. Next, we compare the proposed feature-vector-based weighting strategy with several other weighting strategies in Section 3.4. Finally, we compare the performance of the proposed cost aggregation method with two benchmark methods on two datasets in Section 3.5.|$|R
40|$|This paper {{presents}} a global analysis framework {{for determining the}} availability of data on a virtual processor grid. The data availability information obtained is useful for optimizing communication when generating SPMD programs for distributed address-space multiprocessors. We introduce {{a new kind of}} array <b>section</b> <b>descriptor,</b> called an Available <b>Section</b> <b>Descriptor,</b> which represents the mapping of an array section onto the processor grid. We present an array data-flow analysis procedure, based on interval analysis, for determining data availability at each statement. Several communication optimizations, including redundant communication elimination, are also described. An advantage of our approach is that it is independent of actual data partitioning and representation of explicit communication...|$|R
50|$|Section 3 {{contains}} a short header {{followed by a}} sequence of descriptors that matches the contents of Section 4's bit-stream. The sequence of <b>descriptors</b> in <b>Section</b> 3 could be understood as the template of the BUFR message. The template contains the information necessary to describe {{the structure of the}} data values embedded in the matching bit-stream. It is to be interpreted in a step-by-step, algorithm-like manner. Given a set of BUFR messages, the values contained in Section 4 may differ from one message to the next, but their ordering and structure will be kept predictable if the template provided in Section 3 remains unchanged.|$|R
30|$|The {{remainder}} {{of this paper is}} organized as follows. Section 2 gives a brief overview of related works regarding event <b>descriptors</b> in AED. <b>Section</b> 3 presents a detailed description of our proposed approach, including the principle of the context-wise gradient, construction of the HOCG descriptor, and AED using the HOCG descriptor. Experiments and results analysis are presented in Section 4, and Section 5 concludes the paper.|$|R
30|$|In Section “Feature {{extractor}} and descriptor comparison” we evaluate {{both the}} feature extractor (proposed in Section “Feature extraction”) and <b>descriptor</b> (introduced in <b>Section</b> “Feature descriptioncomparison” we evaluate our correspondence skim procedure (described in Section “Correspondence test and selection”) {{with respect to}} other solutions by comparing both precision and computational efficiency. All the comparisons presented in this section have been performed on the same platform described in Section “Pairwise alignment results”.|$|R
30|$|We {{employ the}} bag-of-words model for {{representing}} activities in videos. Since each image frame {{of a video}} activity is represented by a covariance <b>descriptor</b> (see <b>Section</b> 3.2), a most straightforward way would be to directly treat the video activity as a bag of covariance descriptors. However, temporal information as an important cue for activity recognition is neglected, which may lead to inferior results. Instead, in our case, each video activity is treated as a temporal sequence (time series) of bags of covariance descriptors. Further, comparing to representing the video activity as a time series of covariance matrices, the BoW model is more efficient and {{has been shown to}} be effective in many classification tasks. We refer to this temporal BoW model on Riemannian manifold as Riemannian BoW+T model.|$|R
30|$|All Fourier <b>descriptors</b> {{described}} in <b>Section</b> 2 start from a closed contour {{description of the}} shape and are therefore not applicable when the shape is broken, i.e. consists {{of more than one}} connected component. In this section we first present a method to describe the contour of an arbitrary (broken or unbroken) shape by a periodic three-dimensional curve and then derive different Fourier descriptors for this curve which are invariant under translation, scale, rotation, and start point shift.|$|R
40|$|Systems using Extended PRSDs. (Under the {{direction}} of Dr. Frank Mueller.) Analyzing the memory traces of multi-threaded SPMD programs is a cumbersome and expensive process due to large trace size, program complexity and long running times. Though many binary instrumentation tools generate memory traces, they either gather statistical information with loss of details or generate large trace files {{that are difficult to}} handle. approach provides near-constant size memory traces for dense algebraic kernels irrespective of the problem size or number of threads involved while preserving the memory access details along with the order in which memory references are issued. Our scheme not only compresses loops but also groups similar memory access patterns across threads and processes into a single entity called Extended Power Regular <b>Section</b> <b>Descriptor</b> (EPRSD), which is an enhancement over the Power Regular <b>Section</b> <b>Descriptor</b> (PRSD) concept. We introduce a multi-level compression scheme exploiting memory access patterns in loops, thread dependences and process dependences that are capable of extracting an application’s memory access structure. We further introduce a replay mechanism for the traces generated by our approach and discuss results of our prototype on the X 86 - 64 architecture...|$|R
50|$|The X3 premiered in September 2003 at the Frankfurt Auto Show (Internationale Automobil-Ausstellung), sharing {{its rear}} {{suspension}} with the E46 330xi and using an automatic four-wheel drive system marketed as xDrive. All X3 models feature BMW's {{all wheel drive}} system, with a default 40:60 torque split between {{the front and rear}} axles and the ability to direct all torque to either axle. The system used an electronically controlled multiple-plate clutch to enable infinitely adjustable, fully variable distribution of torque from front to rear with the capability of up to 100 percent of engine torque going to either axle. BMW markets the crossover as a Sports Activity <b>Vehicle,</b> the company's <b>descriptor</b> for its X-line of vehicles.|$|R
40|$|This paper {{presents}} a framework, based on global array dataflow analysis, to reduce communication costs {{in a program}} being compiled for a distributed memory machine. This framework applies techniques for partial redundancy elimination to available <b>section</b> <b>descriptors,</b> a novel representation of communication involving array sections. With a single framework, {{we are able to}} capture numerous optimizations like (i) vectorizing communication, (ii) eliminating communication that is redundant on any control flow path, (iii) reducing the amount of data being communicated, (iv) reducing the number of processors to which data must be communicated, and (v) moving communication earlier to hide latency, and to subsume previous communication. Further, the explicit representation of availability of data in our framework allows processors other than the owners also to send values needed by other processors, leading to additional opportunities for optimizing communication. Another contr [...] ...|$|R
40|$|Abstract — One of {{the main}} {{challenges}} for intelligent vehicles is the capability of detecting other vehicles in their environment, which constitute {{the main source of}} accidents. Specifically, many methods have been proposed in the literature for video-based vehicle detection. Most of them perform supervised classifi-cation using some appearance-related feature, in particular, symmetry has been extensively utilized. However, an in-depth analysis of the classification power of this feature is missing. As a first contribution of this paper, a thorough study of the classification performance of symmetry is presented within a Bayesian decision framework. This study reveals that the performance of symmetry-based classification is very limited. Therefore, as a second contribution, a new gradient-based descriptor is proposed for <b>vehicle</b> detection. This <b>descriptor</b> exploits the known rectangular structure of vehicle rears within a Histogram of Gradients (HOG) -based framework. Experiments show that the proposed descriptor outperforms largely symmetry as a feature for vehicle verification, achieving classification rates over 90 %. I...|$|R
30|$|After {{the change}} {{detection}} step, {{the data in}} each subsequence between the detected change points is processed for more {{detailed analysis of the}} activity in it. Activity Areas and a temporally weighted version of them called the Activity History Areas are extracted for the resulting subsequences. The shape of the Activity Areas is used for recognition of the activities taking place: the outline of each Activity Area is described by the Fourier Shape <b>Descriptors</b> (see <b>Section</b> 5), which are compared to each other using the Euclidean distance, for recognition. When different activities have a similar Activity Area (e.g., a person walking and running), the Activity History Areas (AHAs) are used to discriminate between them, as they contain information about the temporal evolution of these actions. This is achieved by estimating the Mahalanobis distance between appropriate features of the AHAs, like their slope and magnitude (see Section 5 for details). It {{is important to note that}} Activity History Areas would have the same limitations as MHIs [15] if they were applied on the entire video sequence: the repetitions of an activity would overwrite the previous activity history information, so the Activity History Area would not provide any new information. This issue is overcome in the proposed system, as the video is already divided into segments containing different activities, so that Activity History Areas are extracted for each repeating component of the motion separately, and no overwriting takes place.|$|R
3000|$|The set of 8 {{test pieces}} was {{separated}} in two subsets: the odd subset (composed by test pieces 1, 3, 5, and 7) and the even subset (composed by test pieces 2, 4, 6, and 8). Both subsets were measured separately and individual estimators were computed and compared between subsets. The measurement procedure was as follows: uniformly distributed A-scans were obtained around each test piece contour. Individual A-scan TFRs were obtained using the Spectrogram (by {{means of the}} Short-Time Fourier Transform). Final TFR for each test piece was obtained averaging individual A-scan TFRs. After thresholding the final TFR, geometrical <b>descriptors</b> presented in <b>Section</b> 4 were calculated for each subset. The parameters and graphs obtained after processing each subset were similar, for that (and for representation purposes) all parameters and graphs presented in this section were averaged for even and odd subsets, thus representing an only value for each parameter for every value of [...]...|$|R
40|$|Many {{problems}} in computer vision involving recognition and/or classification can be posed {{in the general}} framework of supervised learning. There is however one aspect of image datasets, the high-dimensionality of the data points, that makes the direct application of off-the-shelf learning techniques problematic. In this paper, we present a novel concept class and a companion tractable algorithm for learning a suitable classifier from a given labeled dataset, that is particularly suited to high-dimensional sparse datasets. Each member class in the dataset is represented by a prototype conic section in the feature space, and new data points are classified based on a distance measure to each such representative conic section that is parameterized by its focus, directrix and eccentricity. Learning is achieved by altering {{the parameters of the}} conic <b>section</b> <b>descriptor</b> for each class, so as to better represent the data. We demonstrate the efficacy of the technique by comparing it to several well known classifiers on multiple public domain datasets. 1...|$|R
5000|$|It {{was ranked}} the twenty-eighth {{best place to}} live by Money {{magazine}} in 2005, despite it being essentially a postal zip code and a general <b>descriptor</b> of a <b>section</b> of the suburban Pittsburgh metropolitan area, not a municipality of any type. The presence of North Allegheny Senior High School, a large, well funded public high school, the numerous businesses, {{and a number of}} churches along the [...] "Wexford Flats" [...] gives the area a more distinct community identity than simply an otherwise unremarkable suburb in the Greater Pittsburgh Area. Adjacent to Wexford is North Park and North Park lake. This area is a great asset to the community featuring many hiking/biking trails, 5-mile paved running path around the lake, many pavilions for outdoor events, outdoor ice rink, golf course, dog parks, many playgrounds, a C.O.P.E. course, and local restaurants and shops. The lake underwent construction, including dredging and refinishing shore lines, between 2009 and 2012.|$|R
40|$|Introduction: The EQ- 5 D, {{a generic}} health related {{quality of life}} measure {{developed}} in Europe, has been recently translated into Shona, {{the language of the}} majority of Zimbabweans. Although the reliability of the Shona version of the EQ- 5 D has been established within a community setting, {{the reliability and validity of}} the measure within a group of Shona speaking people with disabilities has not been examined. Aim: The aim of the study was to examine the reliability and concurrent validity of the Shona version of the EQ- 5 D, within the context of a house-to-house survey of disability in a high-density area of Harare, Zimbabwe. Methods: As part of a house-to-house survey of disability in a high-density area in Zimbabwe, 588 Shona speaking subjects with disability/morbidity or their proxies were asked to respond to the Shona version of the EQ- 5 D questionnaire. Those who were able to understand the concept filled in the visual analogue scale.   A testretest was done to determine the reliability of the EQ- 5 D.   Timed walking was used to investigate the validity of the domain of mobility and the International Classification of Impairment, Disability and Handicap Beta Draft  (ICIDH 2) was used as the gold standard for usual activities and self care. The concurrent validity of the anxiety/depression domain was determined against the Shona Symptom Questionnaire, which is a validated screen for depression in the Zimbabwe population. No measure of pain could be found which had been validated in Zimbabwe. Data analysis: The Intraclass-correlation  (ICC) and Pearson’s correlation co-efficient were used to determine the test re-test reliability of the <b>descriptor</b> <b>section</b> and visual analogue scale of the EQ- 5 D respectively. The t-test, ANOVA, and post-hoc Scheffe test were used to compare the EQ- 5 D with the measures of function. Results: Each domain of the Shona EQ- 5 D demonstrated reliability on the test re-test (ICC ranging from. 58 for self care to. 85 for mobility, p<. 01).   The first and second scores on the visual analogue scale were significantly correlated   (Pearson’s r=. 79, p<. 001).   Those who reported no problems with mobility walked significantly faster than those who reported some problems with mobility (t=- 6. 2, p<. 001). The mean number of activity limitations using the International Classification of Functioning was significantly different between  those who reported no, some or severe limitations in usual activities  (F= 39. 9 p<. 001).   Of those reporting no, some and severe problems with self-care. 6 %, 13. 6 % and 62. 5 % respectively were found to have functional limitation in dressing on the ICIDH 2   (the numbers were too small to apply statistical analysis). There was a significant difference between the mean number of affirmative answers in the Shona Symptom Questionnaire in respondents who reported no, moderate and severe problems with anxiety/depression  (F= 70. 7, p<. 001). Discussion and conclusion: It is concluded that the EQ- 5 D is a robust indicator of health related quality of life across different cultures. It is suggested that the Shona version of the EQ- 5 D can be used with confidence in a sample of Shona speaking subjects. Physiotherapists in the region are encouraged to translate and validate questionnaires to ensure that research with non-English speaking members of the Southern African population is performed with appropriate instrumentation</p...|$|R
40|$|Organic {{pollutants}} {{include a}} very wide variety of chemical compounds with different structures, properties, functions and origins, which may produce diverse damages to the ecosystem and the human beings. This review presents the recent progress {{on the use of}} chemometrics to evaluate the occurrence of these substances in the environment. The main topics addressed are: (a) the problems related to the interpretation of the analytical measurements used in the determination of organic pollutants (quantitative analytical determinations section), (b) the profiling of the related environmental pollution sources through their compositional, geographical and temporal distribution patterns (environmental exploratory studies section) and (c) the prediction of the toxicological activity of these substances through models based on the use of structural or physical/chemical <b>descriptors</b> (toxicity studies <b>section).</b> Each section includes selected works related to pesticides, polycyclic aromatic hydrocarbons and other organic pollutants. The authors gratefully acknowledge Agencia Española de Cooperación Internacional (AECI), Project A/ 8964 / 07, Universidad Nacional de Rosario, Agencia Nacional de Promoción Científica y Tecnológica (Project PAE 22204) and Consejo Nacional de Investigaciones Científicas y Técnicas (CONICET, Argentina, Project PIP No. 1950), for financial support of this work. Peer reviewe...|$|R
40|$|Abstract—Analyzing {{the memory}} traces of multithreaded {{programs}} is a cumbersome and expensive process due to large trace size, program complexity and long running times. Though many binary instrumentation tools gener-ate memory traces, they either gather statistical informa-tion with loss of details or generate large trace files {{that are difficult}} to handle. We propose an approach that provides near constant size memory traces irrespective of the num-ber of threads involved while preserving the memory access details along with order in which memory accesses are done. The proposed scheme also groups the memory accesses with in a loop to a single entity called Extended Power Regular <b>Section</b> <b>Descriptor</b> (EPRSD) which is an enhancement over PRSD concept. We propose bi-level compression scheme based on memory access pattern and thread identifiers that are capable of extracting application’s memory access struc-ture. We further propose a replay mechanism for the traces generated by our approach and discuss results of our im-plementation on X 86 - 64 bit architecture. We propose an extrapolation mechanism as the next step which pinpoints the scalability issues. Considering all the above features makes EPRSD mechanism a novel approach for memory trace compression and replay. I...|$|R
40|$|Abstract Background Motor vehicle {{collisions}} (MVCs) {{that result}} {{in one or more}} fatalities on the 400 -series Highways represent a serious public health problem in Ontario, and were estimated to have cost $ 11 billion in 2004. To date, no studies have examined risk factors for fatal MVCs on Ontario’s 400 series highways. The investigate how demographic and environmental risk factors are associated with fatal MVCs on Ontario’s 400 -Series Highways. Methods Data were provided from the Ontario Ministry of Transport database, and included driver demographics, <b>vehicle</b> information, environmental <b>descriptors,</b> structural descriptors, as well as collision information (date and time), and severity of the collision. Multivariate analysis was used to identify factors significantly associated with the odds of dying in a collision. Results There were 53, 526 vehicles involved in collisions from 2001 to 2006 included in our analysis. Results from the multivariate analysis suggest that collisions with older age and male drivers were associated with an increased risk of involving a fatality. Highway 405 and an undivided 2 -way design proved to be the most fatal structural configurations. Collisions in the summer, Fridays, between 12 am- 4 am, and in drifting snow conditions during the wintertime were also shown to have a significantly increased risk of fatality. Conclusion Our results suggest that interventions to reduce deaths as a result of MVCs should focus on both driver-related and road-related modifications. </p...|$|R
30|$|In {{the present}} section we assess the {{correspondence}} survival rate of our feature <b>descriptor</b> (introduced in <b>Section</b> “Feature description’’) {{with respect to}} the popular Spin Images approach, introduced by Johnson [30]. Since we apply Spin Images for partial view range data matching, we have to face the problem described in [35] (for the case of model recognition in cluttered scenes) about the determination of a good tradeoff between distinctiveness and robustness. The former is favored by global or wide field Spin Images, while robustness to view changes (in this case {{due to the nature of}} the data and of the addressed problem) can be improved by adopting localized (short range) descriptors. Therefore we first addressed this tradeoff by finding the optimal Spin Image window size for our data: we experimentally found that a window size of 15 and a bin size equal to the average point spacing gave the best alignment results on all the test datasets. Being calculated in a multi-scale framework, the actual average extent of the Spin Images window {{with respect to the}} original range images corresponds to r·p· 15 points, depending on the scale parameter r and the preemptive subsample parameter p. Moreover, since we are interested in efficient feature-based reconstruction, similarly to what we do with our descriptor we only compute Spin Images on MP obtained from the extraction phase.|$|R
30|$|Besides {{testing the}} {{performance}} {{ability of the}} six local shape <b>descriptors</b> described in <b>Section</b> 4.2, we examine the potential of MKL to fuse multiple features with different representation properties. MKL has attracted significant amount of attention in CV research domain. In this paper, the soft margin MKL algorithm introduced by Xu et al. [39] is adopted, where a kernel slack variable is first introduced {{for each of the}} base kernels when learning the kernel. This approach is advancement over the MKL framework generally regarded as the hard margin MKL [40], which imposes sparsity on a category of features and selects the features that best optimize the object function. In fact, it has been pointed out in [39] that the hard margin MKL is a method which only selects the base kernels with minimum objective. This could easily lead to overfitting problem, particularly in a situation where the base kernels contain noisy features. Following the notion of standard hard margin SVM, it is believed that data from two classes can be separated by a hard margin. However, to enable usability of SVM in real applications the slack variables were introduced to the hard margin SVM, which allows some training errors to be incorporated to the training data, thereby minimizing the overfitting problem [39]. This concept inspired the development of soft margin MKL, which instead introduces kernel slack variable for each of the base kernels [39].|$|R
40|$|This data {{dictionary}} represents 24 months of effort {{collaborating with the}} EMS industry through web-based reviews, public comment periods, focus groups, industry dialogue, topic focused projects, and consensus. The National EMS Information System Version 3 represents a revision from the existing version 2. 1. 1 released in 2005. Adopting a broad perspective, the initiative {{to move to a}} 3 rd version of the NEMSIS {{data dictionary}} was fueled by the need to improve data quality, enhance our ability to assess EMS performance, augment the flexibility of the standard for state adoption and, prepare for our initial movement of this standard into Health Level 7 (HL 7) for approval as an American National Standards Institute (ANSI) standard. At the time of this initial publication, NEMSIS Version 3 has passed several ballots within HL 7 in an effort to be recognized as a federal and international healthcare information standard. Final HL 7 adoption of NEMSIS Version 3 is expected in 2012. HL 7 will be the permanent home for the NEMSIS standard once fully adopted and future revisions will occur through the HL 7 process. NEMSIS Version 3. 2. 1 Data Dictionary Content **Note: The numbers {{to the right of the}} content listed below represent the location for each element on the Sample Page of the Data Dictionary (page vi). Data Element Number (# 1) The NEMSIS Version 3 element numbering system has been revised to improve the information that can be derived from just the data element number. An example of a data element number is dAgency. 01. The data element number begins with either a "d " representing the demographic (agency) section or an "e " representing the EMS PCR section. A one word <b>descriptor</b> for each <b>section</b> is now included in the data element number. A period separates the section (e. g. dAgency) from the data element number (e. g...|$|R
40|$|The {{intention}} {{of this report}} is to list and analyze some of the published results related to different approaches of applying fuzzy set theory to fuzzy shape analysis. These results provide a good background for further development of fuzzy shape analysis methods, which is our main goal. It {{should be noted that}} only fuzzy shape analysis techniques are considered, and not other approaches to use fuzzy set theory in (crisp) shape analysis (like, e. g., fuzzy reason-ing). Even the methods referring to grey-level images are studied only if their adjustment to fuzzy sets is straightforward, by simple normalization of grey levels to the interval [0, 1]. The focus is, thus, on the shapes obtained by segmentation techniques which assign to the image pixels application-dependent membership values to the fuzzy object (shape). The overall organization of the paper is as follows: At the beginning (Section 1) a brief introduction is given. It refers to the classification and evaluation of existing crisp shape analysis methods, {{as well as to the}} general approaches when introducing fuzziness into the binary concepts. Section 2 introduces some basic fuzzy shape definitions. In Sections 3 and 4, we report on a class of shape analysis methods which produce a numer-ical shape descriptor, such as extent, diameter, area, perimeter, shape signature, Fourier transform based motion <b>descriptor,</b> and moments. <b>Sections</b> 5 is related to shape descrip-tors which produce an image (non-numerical result) as an output; we report on convexity, symmetry, distance transform, medial axis transform, and mathematical morphology, in fuzzy settings. Section 6 contains some comments on the reported results. The reporting style balances between “easy to follow ” and “get the information ” concept; we would be very glad if both, rather than none, is achieved. ...|$|R

