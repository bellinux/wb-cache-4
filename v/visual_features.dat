4322|1890|Public
25|$|In 1982 Ungerleider and Mishkin {{distinguished}} the dorsal and ventral streams, as processing {{spatial and}} <b>visual</b> <b>features</b> respectively, from their lesion studies of monkeys â€“ proposing the original where vs what distinction. Though this framework was superseded {{by that of}} Milner & Goodale, it remains influential.|$|E
25|$|In astronomy, {{rotation}} is {{a commonly}} observed phenomenon. Stars, planets and similar bodies all spin around on their axes. The rotation rate of planets {{in the solar}} system was first measured by tracking <b>visual</b> <b>features.</b> Stellar rotation is measured through Doppler shift or by tracking active surface features.|$|E
25|$|Montsalvat {{today is}} a place where {{emerging}} and established artists can present and perform their work. Its <b>visual</b> <b>features</b> are enjoyed by tourists from around the world, and it can be found listed in many major Melbourne tourist guides. Public events (including exhibitions and performances), Film and Photography, Celebrations and Gatherings of many types are held on the property and amongst its buildings frequently.|$|E
5000|$|... #Caption: Key <b>visual</b> <b>featuring</b> {{the five}} main {{characters}} in uniform.|$|R
5000|$|... #Caption: Main <b>visual,</b> <b>featuring</b> (left to right) Animaru, Hanabi, Urara and Inaho ...|$|R
5000|$|... #Caption: Promotional <b>visual</b> <b>featuring</b> (from left to right) Elephantus, Leopard, and Voltkatze ...|$|R
25|$|The {{design was}} for a flying boat that would make use of {{boundary}} layer control to achieve slow speed flight. It was intended that this would enable the aircraft {{to land on the}} open ocean in rough seas and deploy a dipping sonar. Other <b>visual</b> <b>features</b> of the design were an extremely large swept vertical fin that, combined with the dorsal fin and rudder, would have been about half the total length of the aircraft, and a thimble nose radome.|$|E
25|$|Beechcraft {{announced}} on March 6, 2007 that the Iraqi Air Force had ordered five King Air 350ERs for delivery commencing late in 2007. Hawker Beechcraft exhibited a King Air 350ER at the 2007 Paris Air Show; {{and at the}} Royal International Air Tattoo the following month. Photos of the aircraft, actually a modified 2005-built B300, show that <b>visual</b> <b>features</b> of the King Air 350ER include a belly pod, and enlarged engine nacelles compared to the nacelles of standard B300 King Airs.|$|E
25|$|Although this stork shows many common {{courtship}} {{displays in}} storks, these behaviours seem to omit {{some of the}} vocal and <b>visual</b> <b>features</b> {{to be replaced by}} an augmented tactile element. This may be yet another reflection of this stork's adaptation to nesting on the ground; in that the subdued visual displays will less likely attract the attention of predators that detect prey by sight at close range; and although loud vocalisations would be useful for mates to attract each other's attention, this could also render them more conspicuous to potential ground predators.|$|E
30|$|We use the {{top layer}} activations of a pretrained ResNet 50 as <b>visual</b> <b>feature</b> {{representations}} V(x). We investigate different embedding models S and raw semantic descriptions y {{in the form of}} words, text documents, and knowledge graphs as semantic features S(y). Our ZSL module consists of a ridge regression from the <b>visual</b> <b>feature</b> space to the semantic feature space.|$|R
50|$|Represents an {{established}} and familiar <b>visual</b> <b>feature</b> of the neighborhood, community or City.|$|R
50|$|<b>Visual</b> <b>feature</b> {{integration}} and the temporal correlation hypothesis, Annual review of physiology, 1995.|$|R
25|$|Six {{years after}} the release of the final Republic serial, Dick Tracy headlined four feature films, {{produced}} by RKO Radio Pictures. Dick Tracy (a.k.a. Dick Tracy, Detective) (1945) was followed by Dick Tracy vs. Cueball in 1946, both with Morgan Conway as Tracy. Ralph Byrd returned for the last two features, both released in 1947: Dick Tracy's Dilemma and Dick Tracy Meets Gruesome. Gruesome is probably the best known of the four, with the villain portrayed by Boris Karloff. All four movies had many of the <b>visual</b> <b>features</b> associated with film noir: dramatic, shadowy photographic compositions, with many exterior scenes filmed at night (at the RKO Encino movie ranch). Lyle Latell co-starred in all four films as Pat Patton. Anne Jeffreys played Tess Trueheart in the first two, succeeded by Kay Christopher and finally Anne Gwynne; Ian Keith joined the cast as the actor Vitamin Flintheart for two films; Joseph Crehan played Chief Brandon. RKO stocked the films with familiar faces, creating a veritable rogues' gallery of characters: Mike Mazurki as Splitface, Dick Wessel as Cueball, Esther Howard as Filthy Flora, Jack Lambert as hook-handed villain The Claw; baldheaded, pop-eyed Milton Parsons, mild-mannered Byron Foulger, dangerous Trevor Bardette, pockmarked, gently sinister Skelton Knaggs.|$|E
25|$|Both hemispheres of {{the brain}} make a {{contribution}} to the McGurk effect. They work together to integrate speech information that is received through the auditory and visual senses. A McGurk response is more likely to occur in right-handed individuals for whom the face has privileged access to the right hemisphere and words to the left hemisphere. In people that have had callosotomies done, the McGurk effect is still present but significantly slower. In people with lesions to the left hemisphere {{of the brain}}, <b>visual</b> <b>features</b> often {{play a critical role in}} speech and language therapy. People with lesions in the left hemisphere of the brain show a greater McGurk effect than normal controls. Visual information strongly influences speech perception in these people. There is a lack of susceptibility to the McGurk illusion if left hemisphere damage resulted in a deficit to visual segmental speech perception. In people with right hemisphere damage, impairment on both visual-only and audio-visual integration tasks is exhibited, although they are still able to integrate the information to produce a McGurk effect. Integration only appears if visual stimuli is used to improve performance when the auditory signal is impoverished but audible. Therefore, there is a McGurk effect exhibited in people with damage to the right hemisphere of the brain but the effect is not as strong as a normal group.|$|E
500|$|Cables are {{attached}} to the twelve masts circling the stadium with rafters and purlins for additional rigid support. The cigar-shaped masts double as <b>visual</b> <b>features,</b> with the highest at [...] Access to the upper tiers of seats is provided by eight circular ramps with conical roofs resembling turrets above which eight of the twelve masts rise up providing the support structure for the roof.|$|E
5000|$|... #Caption: The game's <b>visuals</b> <b>feature</b> {{two-dimensional}} character cut-out designs {{contained within}} three-dimensional backgrounds.|$|R
5000|$|... #Caption: Main <b>visual,</b> <b>featuring</b> (left to right) Aoi Asahina, Makoto Naegi and Kyoko Kirigiri ...|$|R
40|$|In our paper, we {{deal with}} the {{challenge}} of extending automatically the classic image indexing by <b>visual</b> relationship <b>features.</b> The <b>visual</b> relationship <b>features</b> are discovered automatically from images. They contribute to make more efficient the content-based indexing. More particularly, we develop an advanced content-based indexing articulated around the following notions: - classic indexing, - clustering algorithm, - <b>visual</b> <b>feature</b> book and relationship qualification...|$|R
500|$|An {{accompanying}} {{music video}} {{for the song}} was produced and created in late 1999. The <b>visual</b> <b>features</b> the singer performing {{in a dark room}} with several other female dancers; for the final segment of the video, Prince stands in front of a bullseye backdrop and a waterfall. In terms of live performances, the singer sang [...] "The Greatest Romance Ever Sold" [...] for his direct to video VHS film Rave Un2 the Year 2000. The aforementioned rendition was recorded live on December 31, 1999 from Paisley Park Studios.|$|E
500|$|The song {{received}} generally favourable {{reviews from}} music critics who {{described it as}} romantic and stark. Danish filmmaker Kristian Levring filmed and produced a music video for the song after Oh Land expressed interest in collaborating with him. Leth was able to select any song by Oh Land for the clip and he chose [...] "Love You Better". The <b>visual</b> <b>features</b> Oh Land aging in reverse, achieved by the singer wearing tracking devices. Following {{the release of the}} video on 21 October 2016, it entered Billboards Denmark Digital Songs chart at number six.|$|E
500|$|Critics responded {{positively}} to [...] "Sleeping with the One I Love", praising Fantasia's vocals and her collaboration with R. Kelly. It peaked at number seven on the Adult R Songs Billboard chart {{for the week}} of July 2, 2017. It was Fantasia tenth top-ten entry, and {{the second of the}} album's two top 20 singles, with [...] "No Time for It" [...] (2016) being the first. Fantasia performed the song during a July 28, 2016 concert broadcast on BET and the [...] A music video, directed by Derek Blanks, was released on June 26, 2016. Inspired by the American comedy-drama series Orange Is the New Black, the <b>visual</b> <b>features</b> Fantasia playing various characters in their pursuit of love while incarcerated. It received positive feedback from media outlets.|$|E
3000|$|The overall <b>visual</b> <b>feature</b> {{extraction}} {{function is}} defined as normalized projected gray values of mouth region: [...]...|$|R
5000|$|... #Caption: Key <b>visual</b> <b>featuring</b> {{the protagonists}} from Digimon Adventure 6 {{years after the}} events of the {{original}} series.|$|R
40|$|In this paper, we {{defined the}} viseme (visual speech element) and {{described}} about {{the method of}} extracting <b>visual</b> <b>feature</b> vector. We defined the 10 visemes based on vowel by analyzing of Korean utterance and proposed the method of extracting the 20 -dimensional <b>visual</b> <b>feature</b> vector, combination of static features and dynamic features. Lastly, we took an experiment in recognizing words based on 3 -viseme HMM and evaluated the efficiency...|$|R
500|$|The song's {{music video}} was {{directed}} by Hype Williams and shot in black-and-white in Golden Beach, Florida at a beach front manse. The <b>visual</b> <b>features</b> scenes of the pair singing the song together. [...] "Drunk in Love" [...] was performed by BeyoncÃ© and Jay-Z at the 56th Annual Grammy Awards. It was later added to the set lists of the second European leg of BeyoncÃ©'s The Mrs. Carter Show World Tour in 2013 and the pair's joint On the Run Tour in 2014. Numerous remixes and cover versions of the song were made, most notably the official rework by rapper Kanye West. The music video won Best Collaboration and was nominated for Video of the Year at the 2014 MTV Video Music Awards.|$|E
500|$|The clip was {{uploaded}} {{onto her}} official YouTube channel on 21 June 2017, where it gathered over seven million views in one week, and later 11 million views in 11 days. The video thus became trending {{on the platform}} in Romania, Austria, Israel, Lithuania, Bulgaria, Denmark, Germany, Switzerland, Spain, Turkey, Norway, Finland, Ireland, Russia, Mexico, Italy, France, Venezuela, Canada, Peru, Ecuador and Chile. The <b>visual</b> <b>features</b> the singer and a huge crowd of background dancers and other people performing to the song at a tennis court, a night bar, a pool and around a bonfire. Inna wears a white hoodie along with an animal print waistcoat, while Erick also makes appearance sporting a yellow-blue jacket, black shorts and sunnglasses. Alex StÄƒnescu from InfoMusic called the music video [...] "summery".|$|E
500|$|The game's <b>visual</b> <b>features</b> were commended by many reviewers. The art {{design was}} lauded as [...] "outstanding" [...] by Computer and Video Games Kelly, and [...] "jaw-dropping" [...] by Eurogamers Welsh. In contrast, Mc Shea of GameSpot {{identified}} the visual {{representation of the}} post-apocalyptic world was [...] "mundane", having been portrayed various times previously. The game's graphics have been frequently named by critics as the best for a PlayStation 3 game, with Helgeson of Game Informer naming them [...] "unmatched in console gaming" [...] and Moriarty of IGN stating that they contribute to the realism. Destructoid's Sterling wrote that game was visually impressive but that technical issues, such as some [...] "muddy and basic" [...] textures found early in the game, left {{a negative impact on}} the visuals.|$|E
3000|$|As {{described}} in Section 4.2, the <b>visual</b> <b>feature</b> vector is estimated according to (7) in a recursive way. Since matrices [...]...|$|R
40|$|Abstractâ€”We {{present a}} new class of <b>visual</b> text <b>features</b> that are based on text in cameraphone images. A robust text {{detection}} algorithm locates individual text lines and feeds them to a recognition engine. From the recognized characters, we generate the <b>visual</b> text <b>features</b> in a way that resembles image features. We calculate their location, scale, orientation, and a descriptor that describes the character and word information. We apply <b>visual</b> text <b>features</b> to image matching. To disambiguate false matches, we developed a word-distance matching method. Our experiments with image that contain text show that the new <b>visual</b> text <b>feature</b> based image matching pipeline performs on par or better than a conventional image feature based pipeline while requiring less than 10 bits per feature. This is 4. 5 Ã— smaller than state-of-the-art <b>visual</b> <b>feature</b> descriptors. I...|$|R
5000|$|... #Caption: Key <b>visual</b> <b>featuring</b> {{the four}} main {{characters}} in the bottom right corner. From bottom right going clockwise: Gladiolus, Prompto, Noctis, and Ignis.|$|R
500|$|The United States Senate {{approved}} the necessary legislation on November 9, 1997, and the House of Representatives {{did the same}} on November 13. On December 1 President Bill Clinton signed the 50 States Commemorative Coin Program Act, which became Public Law 105-124. Section four of the act, which is entitled [...] "United States $1 Coin Act of 1997", provided for a new dollar coin to be struck, stating in part: [...] "The dollar coin shall be golden in color, have a distinctive edge, have tactile and <b>visual</b> <b>features</b> that make the denomination of the coin readily discernible". The act also gave authority to the Secretary of the Treasury to resume production of the Susan B. Anthony dollar until production could begin on the new dollar coin. In total, more than 41million Susan B. Anthony dollars were struck bearing the date 1999.|$|E
2500|$|Cattle can {{recognize}} familiar individuals. Visual individual recognition {{is a more}} complex mental process than visual discrimination. [...] It requires the recollection of the learned idiosyncratic identity of an individual that has been previously encountered {{and the formation of}} a mental representation. By using 2-dimensional images of the heads of one cow (face, profiles, Â¾ views), all the tested heifers showed individual recognition of familiar and unfamiliar individuals from their own breed. [...] Furthermore, almost all the heifers recognized unknown individuals from different breeds, although this was achieved with greater difficulty. [...] Individual recognition was most difficult when the <b>visual</b> <b>features</b> of the breed being tested were quite different from the breed in the image, for example, the breed being tested had no spots whereas the image was of a spotted breed.|$|E
2500|$|The attention-free {{hypothesis}} soon {{emerged to}} challenge early models. The initial {{basis for the}} attention-free hypothesis was the finding that in visual search, basic <b>visual</b> <b>features</b> of objects immediately and automatically pop out to the person doing the visual search. Further experiments seemed to support this: Potter (as cited by Evans & Treisman, 2005) showed that high-order representations can be accessed rapidly from natural scenes presented at rates of up to 10 per second. Additionally, Thorpe, Fize & Marlot (as cited by Evans & Treisman) discovered that humans and primates can categorize natural images (i.e. of animals in everyday indoor and outdoor scenes) rapidly and accurately even after brief exposures. [...] The basic idea in these studies is that exposure to each individual scene is too brief for attentional processes to occur, yet human beings are able to interpret and categorize these scenes.|$|E
30|$|Audio-visual speech {{recognition}} which uses dynamic visual lip and audio {{information has been}} studied as a technique for robust {{speech recognition}} in noisy environments. In audio-visual speech recognition, there are three priminary integration methods: early integration [7], which connects the audio feature vector with the <b>visual</b> <b>feature</b> vector; late integration [8], which weighs {{the likelihood of the}} result obtained by a separate process for audio and visual signals, and synthetic integration [9], which calculates the product of the output probability in each state. A discrete cosine transform (DCT) is widely used as a <b>visual</b> <b>feature</b> in audio-speech recognition. Previously, we have proposed audio-visual speech recognition using a <b>visual</b> <b>feature</b> extracted from an active appearance model [10, 11]. The feature contains shape information that expresses lip movement and texture information that expresses intensity changes, such as tooth.|$|R
40|$|We {{propose a}} {{multimode}} retina integrating image sensing, normalization, smoothing, differentiation and <b>visual</b> <b>feature</b> extraction by incorporating: 1) a histogram equalization function onto the sensor focal plane, which normalizes the image signal {{at the same}} dynamic range under different illumination conditions and results a constant signal amplitude facilitating the post processing; 2) a capacitive Gaussian network and a spatial differentiator, which offer a bandpass filtering on the normalized image; 3) a <b>visual</b> <b>feature</b> extraction, which extracts and localizes the areas enveloping objets of interest. This novel multimode retina, when interfaced with a digital processing unit, does a first step processing and information salient region extraction suited for many real-time vision tasks. Keywords: smart retina, histogram equalization, capacitive Gaussian filter, spatial differentiator, aVLSI. 1. INTRODUCTION This paper investigates an analog multimode <b>visual</b> <b>feature</b> extraction retina de [...] ...|$|R
5|$|Its unique {{location}} or distinctive physical appearance or presence representing an established and familiar <b>visual</b> <b>feature</b> of a neighborhood, community, or the City of Chicago.|$|R
