89|238|Public
50|$|There are {{instances}} {{when it is}} more expedient and efficient to transfer some tests or inspections from the IQ to the OQ, or from the OQ to the PQ. This is allowed for in the regulations, provided that a clear and approved justification is documented in the <b>Validation</b> <b>Plan</b> (VP).|$|E
5000|$|The {{validation}} scope, {{boundaries and}} responsibilities for each process {{or groups of}} similar processes or similar equipment's must be documented and approved in a <b>validation</b> <b>plan.</b> These documents, terms and references for the protocol authors are for use in setting the scope of their protocols. It {{must be based on}} a Validation Risk Assessment (VRA) to ensure that the scope of validation being authorised is appropriate for the complexity and importance of the equipment or process under validation. Within the references given in the VP the protocol authors must ensure that all aspects of the process or equipment under qualification; that may affect the efficacy, quality and or records of the product are properly qualified. Qualification includes the following steps: ...|$|E
30|$|Methods: In {{order to}} grade our {{production}} premises, we have compiled a <b>validation</b> <b>plan</b> which {{was accepted by}} the quality assurance person of TPC. The validation process according the accepted <b>validation</b> <b>plan</b> was performed by an outside contractor according to valid standards (methods, calibrations of the measurement equipment and documentation). The tests include measurements of HEPA filter integrity, air volume flow, room differential pressure, airflow visualization, air change rate, airborne particle levels and viable microbial particles. The microbiological testing and measurement of airborne particles were performed both at rest and in operation. For microbiological testing, active and passive air samples using settle plates and surface samples using contact plates were taken from spots specified in the <b>validation</b> <b>plan.</b>|$|E
5000|$|... 1059-1993 IEEE Guide for Software Verification & <b>Validation</b> <b>Plans</b> (withdrawn) ...|$|R
5000|$|... 1012-1986 IEEE Standard for Software Verification and <b>Validation</b> <b>Plans</b> (superseded by 1012-1998) ...|$|R
50|$|SAE AS4111: RT <b>Validation</b> Test <b>Plan.</b>|$|R
30|$|In the analyse phase, {{brainstorming}} {{sessions were}} undertaken by team members {{in order to}} identify potential factors that could result in increasing the total length of the supply chain, inefficiency ratio and working capital productivity. Further, a cause analysis and <b>validation</b> <b>plan</b> to measure and analyse the potential causes related to different metrics with reference to different entities involved in supply chain network diagram are made. Based upon cause analysis and <b>validation</b> <b>plan,</b> the role of various entities involved in the network is discussed in the following paragraphs.|$|E
40|$|This Science Data <b>Validation</b> <b>Plan</b> {{describes}} {{the plans for}} validating {{a subset of the}} Multi-angle Imaging SpectroRadiometer (MISR) Level 2 algorithms and data products and supplying top-of-atmosphere (TOA) radiances to the In-flight Radiometric Calibration and Characterization (IFRCC) subsystem for vicarious calibration...|$|E
40|$|Using the External Calibration Tool, named CALIX, is {{possible}} to measure the PAZ system against standard targets. This test report proves the correctness of the software functionality, following the test cases defined in the Verification <b>Validation</b> <b>Plan</b> of the External Calibration Tool (PZ-DLR-PL- 1110) ...|$|E
40|$|A {{critical}} {{element in the}} use of PDDL 2. 1, the modelling language developed for the International Planning Competition series, has been the common understanding of the semantics of the language. The fact that this has been implemented in <b>plan</b> <b>validation</b> software was vital to the progress of the competition. However, the <b>validation</b> of <b>plans</b> using actions with continuous effects presents new challenges (that precede the challenges presented by planning with those effects). In this paper we review the need for continuous effects, their semantics and the problems that arise in <b>validation</b> of <b>plans</b> that include them. We report our progress in implementing the semantics in an extended version of the <b>plan</b> <b>validation</b> software. ...|$|R
40|$|One kind of {{temporal}} reasoning is temporal projection [...] -the computation {{of the consequences}} of a set of events. This problem is related to a number of other temporal reasoning tasks such as <b>plan</b> <b>validation</b> and <b>planning.</b> We show that one particular, simple case {{of temporal}} projection on partially ordered events turns out to be harder than previously conjectured, while planning is easy under the same restrictions. Additionally, we show that <b>plan</b> <b>validation</b> is tractable for an even larger class of plans [...] -the unconditional plans [...] -for which temporal projection is NP-hard, thus indicating that temporal projection may not be a necessary ingredient in <b>planning</b> and <b>plan</b> <b>validation.</b> Analyzing the partial decision procedure for the temporal projection problem that has been proposed by other authors, we notice that it fails to be complete for unconditional plans, a case where we have shown <b>plan</b> <b>validation</b> tractable. This work was supported by the German Ministry for Research and Technology (B [...] ...|$|R
40|$|One kind of {{temporal}} reasoning is temporal projection -the computation {{of the consequences}} {{for a set of}} events. This problem is related to a number of other temporal reasoning tasks such as story understanding, <b>plan</b> <b>validation,</b> and <b>planning.</b> We show that one particular simple case {{of temporal}} projection on partially ordered events turns out to be harder than previously conjectured. However, given the restrictions of this problem, planning and story understanding are easy. Additionally, we show that <b>plan</b> <b>validation,</b> one of the intended applications of temporal projection, is tractable for an even larger class of plans. The incomplete decision procedure for the temporal projection problem that has been proposed by other authors, however, fails to be complete in the case where we have shown <b>plan</b> <b>validation</b> to be tractable...|$|R
40|$|These diploma {{thesis is}} {{focussed}} on process modyfying of radial outlet drilling of Common Rail System. Introductory part koncern with theoretical system analysis {{from the point}} of historical and technical view. It follow elaborate <b>validation</b> <b>plan</b> for assigned problem. Next point is Practically elaborate solution. Final part include evaluation {{from the point of}} economical view...|$|E
40|$|This report {{documents}} the strategies for verification and {{validation of the}} codes LSP and ICARUS used for simulating {{the operation of the}} neutron tubes used in all modern nuclear weapons. The codes will be used to assist in the design of next generation neutron generators and help resolve manufacturing issues for current and future production of neutron devices. Customers for the software are identified, tube phenomena are identified and ranked, software quality strategies are given, and the <b>validation</b> <b>plan</b> is set forth...|$|E
40|$|Abstract. We {{present an}} {{architecture}} that promotes home TV sets to {{a platform for}} tailored interactive contents and services allowing for more active ageing of elderly people. The employed interactivity paradigm based on conversational avatars meets particular requirements of elderly people, resulting in a learning slope near to zero. ISO/IEC 24752 Universal Remote Console standard conformance allows for personalized user interfaces. Furthermore, we outline a prototype setup showing the system’s capabilities. In addition to that we present a <b>validation</b> <b>plan</b> for testing our architecture...|$|E
40|$|This report {{describes}} the <b>validation</b> <b>plans</b> for the TENCompetence project. The validation strategy is described and {{the significance of}} the pilots programme described {{in the context of the}} project work plan. The opportunities provided by the four pilot areas are analysed. More detailed plans are provided for the Digital Cinema pilot scheduled for cycle 1 of the project. Plans are also provided for the testing and technical validation of the integrated system. European Commission TENCompetence - IST- 2005 - 02708...|$|R
40|$|Under this project, General Atomics (GA) was tasked {{to develop}} the {{experimental}} <b>validation</b> <b>plans</b> for two high priority ISAs, Boundary and Pedestal and Whole Device Modeling {{in collaboration with the}} theory, simulation and experimental communities. The following sections have been incorporated into the final FSP Program Plan (www. pppl. gov/fsp), which was delivered to the US Department of Energy (DOE). Additional deliverables by GA include guidance for validation, development of metrics to evaluate success and procedures for collaboration with experiments. These are also part of the final report...|$|R
50|$|The RT Production Test Plan is a {{simplified}} {{subset of the}} <b>validation</b> test <b>plan</b> and is intended for production testing of Remote Terminals. This test plan is maintained by the SAE AS-1A Avionic Networks Subcommittee as AS4112.|$|R
40|$|The thesis {{consists}} of an analysis of spot joint fatigue estimation models suitable for aluminium car body. The gaps were identified in the existing models and a new approach put forth for SPR fatigue estimation, with a body in white <b>validation</b> <b>plan.</b> In the process, SPR fatigue failure mechanisms were also analysed. The models were critically analysed, including the proposed one. Fatigue as a phenomenon and its perception in the automotive industry were also discussed. Avenues of future work were identified and discussed briefly...|$|E
40|$|The {{aim of this}} {{bachelor}} thesis was {{validation of}} HPLC method for determination of purity of sofosbuvir and its transfer to UPLC system. The parameters included in the <b>validation</b> <b>plan</b> were: the system suitability test, robustness, accuracy, linearity, recovery, limit of detection, and limit of quantification. Robustness was tested by the design of experiments approach. Method was transferred from the HPLC system to the UPLC system. The transfer was performed by randomization test, which was evaluated by statistical methods, namely by pairwise T-test and correlation analysis...|$|E
40|$|This paper first {{summarizes}} the operational land {{products of the}} future Ocean Land Colour Instrument (OLCI) on board Sentinel 3, in particular, the Fraction of Absorbed Photosynthetic Active Radiation (FAPAR) and the OLCI Terrestrial Chlorophyll Index (OTCI). Then the <b>validation</b> <b>plan</b> of these products is then presented: it focuses on an independent strategy for making use of ground-based measurements over a large sample of vegetation types together with radiative transfer modelling for assessing theoretical accuracies from both space and in-situ retrieval methods. JRC. H. 7 -Climate Risk Managemen...|$|E
50|$|The Ares I-X Systems Engineering & Integration (SE&I) Office, {{managed by}} the NASA Langley Research Center, was {{responsible}} for integrating the vehicle’s parts into a complete rocket and making sure they work together as a system to meet flight test objectives. SE&I was responsible for ensuring all components functioned collectively to satisfy primary and secondary mission objectives. Detailed management of system interfaces, mission level requirements, <b>validation</b> <b>plans,</b> and flight instrumentation management were key SE&I contributions. SE&I provided the structural, thermal and aerodynamic analyses for the overall system to allow the components to be designed and built. SE&I also managed {{the mass of the}} vehicle and developed the trajectory and the guidance, navigation, and control algorithms used for vehicle flight.|$|R
40|$|This {{document}} (<b>Validation</b> Exercise <b>Plan),</b> as {{output of}} Task 5. 1, {{points out the}} GAMMA validation objectives (Chapter 3) and strategy (Chapter 4). Then, the validation scenarios are identified (Chapter 5) and the exercise plans are defined (Chapter 6). Thereby, the GAMMA validation activities will mainly follow the procedure advocated in the European standard E-OCVM. However, the procedure will be slightly adapted in order to consider the experiences made by the partners in other projects. The GAMMA validation strategy is, thus, {{a combination of a}} well-accepted European standard and best practice. The <b>Validation</b> Exercise <b>Plan</b> is a document containing all relevant planning information to be considered in the execution of the validation exercises (WP 9), including the Validation Scenarios Definition and Description...|$|R
40|$|The Crew Exploration Vehicle Parachute Assembly System (CPAS) {{is engaged}} in a multi-year design and test {{campaign}} aimed at qualifying a parachute recovery system for human use on the Orion Spacecraft. Orion has parachute flight performance requirements that will ultimately be verified through the use of Monte Carlo multi-degree of freedom flight simulations. These simulations will be anchored by real world flight test data and iteratively improved to provide a closer approximation to the real physics observed in the inherently chaotic inflation and steady state flight of the CPAS parachutes. This paper will examine the processes necessary to verify the flight performance requirements of the human rated spacecraft. The focus will be on the requirements verification and model <b>validation</b> <b>planned</b> on CPAS...|$|R
40|$|The {{purpose of}} the Independent Verification and Validation (IV&V) role in the {{evaluation}} of the SAPHIRE requirements definition is to assess the activities that results in the specification, documentation, and review of the requirements that the software product must satisfy, including functionality, performance, design constraints, attributes and external interfaces. The IV&V team began this endeavor after the software engineering and software development of SAPHIRE had already been in production. IV&V reviewed the requirements specified in the NRC Form 189 s to verify these requirements were included in SAPHIRE’s Software Verification and <b>Validation</b> <b>Plan</b> (SVVP) ...|$|E
40|$|Processor {{obsolescence}} is a {{big concern}} affecting most equipments involved in safety critical applications (automotive, aerospace, nuclear plants, military applications [...] .). Indeed, such applications are active years longer than was originally anticipated. A method for validating the solution consisting in the replacement of a processor not anymore available into the market by its emulated version {{by means of an}} FPGA is presented in this paper. The Motorola 6800 processor is used as test vehicle to illustrate the key aspects of the explored <b>validation</b> <b>plan.</b> Significant experimental results and their impact on the HDL description will be discussed...|$|E
40|$|Abstract. The task {{of expert}} finding {{has been getting}} {{increasing}} at-tention in the information retrieval literature. Still, the current state-of-the-art lacks in principled approaches for combining different sources of evidence in an optimal way. In the context of my MSc thesis, I will explore the usage of learning to rank methods as a principled approach for com-bining multiple estimators of expertise. This paper surveys the current state-of-the-art in both expert finding and learning to rank. It presents the fundamental concepts {{and the most important}} related works, also detailing my thesis proposal and the envisioned <b>validation</b> <b>plan.</b> ...|$|E
40|$|The New Millennium Program's first Earth-observing mission (EO- 1) is a {{technology}} validation mission. It is {{managed by the}} NASA Goddard Space Flight Center in Greenbelt, Maryland and is scheduled for launch {{in the summer of}} 2000. The purpose of this mission is to flight-validate revolutionary technologies that will contribute to the reduction of cost and increase of capabilities for future land imaging missions. In the EO- 1 mission, there are five instrument, five spacecraft, and three supporting technologies to flight-validate during a year of operations. EO- 1 operations and the accompanying ground system were intended to be simple in order to maintain low operational costs. For purposes of formulating operations, it was initially modeled as a small science mission. However, it quickly evolved into a more complex mission due to the difficulties in effectively integrating all of the <b>validation</b> <b>plans</b> of the individual technologies. As a consequence, more operational support was required to confidently complete the on-orbit validation of the new technologies. This paper will outline the issues and lessons learned applicable to future technology validation missions. Examples of some of these include the following: (1) operational complexity encountered in integrating all of the <b>validation</b> <b>plans</b> into a coherent operational plan, (2) initial desire to run single shift operations subsequently growing to 6 "around-the-clock" operations, (3) managing changes in the technologies that ultimately affected operations, (4) necessity for better team communications within the project to offset the effects of change on the Ground System Developers, Operations Engineers, Integration and Test Engineers, S/C Subsystem Engineers, and Scientists, and (5) the need for a more experienced Flight Operations Team to achieve the necessary operational flexibility. The discussion will conclude by providing several cost comparisons for developing operations from previous missions to EO- 1 and discuss some details that might be done differently for future technology validation missions...|$|R
40|$|As {{the role}} of {{computational}} models has increased, the accuracy of computational results has been of great concern to engineering decision-makers. To address a growing concern about the predictive capability of the computational models, this dissertation proposed a generic model validation framework with four research objectives as: Objective 1 &mdash to develop a hierarchical framework for statistical model validation that is applicable to various computational models of engineered products (or systems); Objective 2 &mdash to advance a model calibration technique that can facilitate to improve predictive capability of computational models in a statistical manner; Objective 3 &mdash to build a validity check engine of a computational model with limited experimental data; and Objective 4 &mdash to demonstrate the feasibility and effectiveness of the proposed validation framework with five engineering problems requiring different experimental resources and predictive computational models: (a) cellular phone, (b) tire tread block, (c) thermal challenge problem, (d) constrained-layer damping structure and (e) energy harvesting device. The validation framework consists of three activities: <b>validation</b> <b>planning</b> (top-down), <b>validation</b> execution (bottom-up) and virtual qualification. The <b>validation</b> <b>planning</b> activity requires knowledge about physics-of-failure (PoF) mechanisms and/or system performances of interest. The knowledge facilitates to decompose an engineered system into subsystems and/or components such that PoF mechanisms or system performances of interest can be decomposed accordingly. The <b>validation</b> <b>planning</b> activity takes a top-down approach and identifies vital tests and predictive computational models of which contain both known and unknown model input variable(s). On the other hand, the validation execution activity takes a bottom-up approach, which improves the predictive capability of the computational models from the lowest level to the highest using the statistical calibration technique. This technique compares experimental results with predicted ones from the computational model {{to determine the best}} statistical distributions of unknown random variables while maximizing the likelihood function. As the predictive capability of a computational model at a lower hierarchical level is improved, this enhanced model can be fused into the model at a higher hierarchical level. The validation execution activity is then continued for the model at the higher hierarchical level. After the statistical model calibration, a validity of the calibrated model should be assessed; therefore, a hypothesis test for validity check method was developed to measure and evaluate the degree of mismatch between predicted and observed results while considering the uncertainty caused by limited experimental data. Should the model become valid, the virtual qualification can be executed in a statistical sense for new product developments. With five case studies, this dissertation demonstrates that the validation framework is applicable to diverse classes of engineering problems for improving the predictive capability of the computational models, assessing the fidelity of the computational models, and assisting rational decision making on new design alternatives in the product development process...|$|R
40|$|This paper {{summarizes}} in-space structural <b>validation</b> <b>plans</b> for {{a proposed}} Space Shuttle-based flight experiment. The test article is an innovative, lightweight solar array concept that uses pop-up, refractive stretched-lens concentrators {{to achieve a}} power/mass density of at least 175 W/kg, {{which is more than}} three times greater than current capabilities. The flight experiment will validate this new technology to retire the risk associated with its first use in space. The experiment includes structural diagnostic instrumentation to measure the deployment dynamics, static shape, and modes of vibration of the 8 -meter-long solar array and several of its lenses. These data will be obtained by photogrammetry using the Shuttle payload-bay video cameras and miniature video cameras on the array. Six accelerometers are also included in the experiment to measure base excitations and small-amplitude tip motions...|$|R
40|$|This <b>Validation</b> <b>Plan</b> {{outlines}} {{an approach}} to verify the SAGE III measurement and retrieval algorithm system and a strategy to acquire correlative measurements in order to validate the accuracy and precision of the SAGE III Standard Science Products. The plan covers the first 2 years of operation of the SAGE III/Meteor- 3 M mission commencing with expected launch of the SAGE III instrument in December 2001. A second SAGE III instrument will {{be placed on the}} International Space Station (ISS) in 2005. Validation plans for the ISS/SAGE III instrument will be included in a future revision of this document...|$|E
40|$|The C 6 project 'Encapsulation Processes' {{has been}} {{designed}} to obtain experimental measurements for discovery of phenomena critical to improving these processes, as well as data required in the verification and <b>validation</b> <b>plan</b> (Rao et al. 2001) for model validation of flow in progressively complex geometries. We have observed and recorded the flow of clear, Newtonian liquids and opaque, rheologically complex suspensions in two mold geometries. The first geometry is a simple wineglass geometry in a cylinder and is reported here in Part 1. The results in a more realistic encapsulation geometry are reported in Part 2...|$|E
40|$|A {{thorough}} and unique thermal verification and model <b>validation</b> <b>plan</b> {{has been developed}} for NASA s James Webb Space Telescope. The JWST observatory consists of a large deployed aperture optical telescope passively cooled to below 50 Kelvin along with a suite of several instruments passively and actively cooled to below 37 Kelvin and 7 Kelvin, respectively. Passive cooling to these extremely low temperatures is made feasible {{by the use of}} a large deployed high efficiency sunshield and an orbit location a! !he L 2 Lagrange p~in!. Another enabling feature is the scale or size of the observatory that allows for large radiator sizes that are compatible with the expected power dissipation of the instruments and large format Mercury Cadmium Telluride (HgCdTe) detector arrays. This passive cooling concept is simple, reliable, and mission enabling when compared to the alternatives of mechanical coolers and stored cryogens. However, these same large scale observatory features, which make passive cooling viable, also prevent the typical flight configuration fully-deployed thermal balance test that is the keystone to most space missions thermal verification plan. JWST is simply too large in its deployed configuration to be properly thermal balance tested in the facilities that currently exist. This reality, when combined with a mission thermal concept with little to no flight heritage, has necessitated the need for a unique and alternative approach to thermal system verification and model validation. This paper describes the thermal verification and model <b>validation</b> <b>plan</b> that has been developed for JWST...|$|E
40|$|Because {{space science}} was caused to depend {{heavily on the}} use of {{payloads}} attached to the shuttle, it was necessary to plan for operation of scientific instruments within its induced environment. The potential for excessive contamination was recognized early; specifications were written, goals were set and measurements to provide inflight <b>validation</b> were <b>planned...</b>|$|R
50|$|StatSoft's {{professional}} services groups provide {{a range of}} services to complement the Statistica software. StatSoft provides software integration and customization services, development of custom Web applications based on Statistica Enterprise Server technology, as well as installation of a general-purpose Web Server system. StatSoft also offers deployment of data mining solutions designed to work with specific data warehouses and solve particular ranges of problems. Additionally, statistical consulting services are available. StatSoft offers both introductory and advanced training courses in major cities in the United States and overseas. StatSoft's training classes provide hands-on experience with its line of software products {{as well as an}} introduction to real-world example applications.StatSoft, through its Technical Services group, provides software validation services as part of the deployment of Statistica applications. These services include requirement gathering and documentation, <b>validation</b> <b>planning,</b> installation qualification, operational qualification, and performance qualification.|$|R
40|$|In {{this paper}} we {{describe}} the web services, processes, communication protocols and ad-hoc service chains utilized {{in the late summer}} and early fall 2007 Ikhana UAS response to the wildfires burning in southern California. Additionally, {{we describe the}} lessons learned that will be applied to the upcoming Global Hawk UAS Aura Satellite <b>Validation</b> Experiment <b>planned</b> for early 2009...|$|R
