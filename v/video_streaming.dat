4515|7749|Public
5|$|During its {{original}} run, it was broadcast simultaneously in North America, the United Kingdom, Canada, Australia, New Zealand and South Africa through the Western branch of Niconico. In addition to this, the series broadcast on Chubu-Nippon Broadcasting from July 13, and Kumamoto Asahi Broadcasting RRK station from July 31. Blood-C would later debut on WOWOW in 2013: Episodes 1 to 10 were broadcast {{back to back}} on September 22, while the final two episodes broadcast on September 29. In 2015, Niconico's Japanese channel ran a marathon broadcast of all twelve episodes starting from June 28. Blood-C {{was one of three}} anime cited—alongside Highschool of the Dead and Terror in Resonance—in a warning given by the Chinese Ministry of Culture to <b>video</b> <b>streaming</b> sites due to the series high violence. Blood-C was later put on a blacklist by the Ministry of Culture alongside 37 other anime and manga series, prohibiting its physical and online distribution in mainland China.|$|E
5|$|Steam is {{a digital}} {{distribution}} platform developed by Valve Corporation, which offers {{digital rights management}} (DRM), multiplayer gaming, <b>video</b> <b>streaming</b> and social networking services. Steam provides the user with installation and automatic updating of games, and community features such as friends lists and groups, cloud saving, and in-game voice and chat functionality. The software provides a freely available application programming interface (API) called Steamworks, which developers can use to integrate many of Steam's functions into their products, including networking, matchmaking, in-game achievements, micro-transactions, and support for user-created content through Steam Workshop. Though initially developed for use on Microsoft Windows operating systems, versions for OS X and Linux were later released. Mobile apps with connected functionality with the main software were later released for iOS, Android, and Windows Phone devices in the 2010s.|$|E
25|$|WWE Network: a subscription-based <b>video</b> <b>streaming</b> service {{launched}} in 2014 using {{the infrastructure of}} Major League Baseball Advanced Media.|$|E
40|$|The {{invention}} {{relates to}} {{a method of}} detecting manipulations of digital <b>video</b> <b>stream</b> data, wherein the <b>video</b> <b>stream</b> data represents a sequence (17) of video images comprising at least one moving object that moves relatively to other objects and/or relatively to a background scenery and wherein the method comprises: a) detecting {{the at least one}} moving object from the <b>video</b> <b>stream</b> data, b) identifying (19) a kinematic model (21) which describes the movement of the moving object, c) determining (23) deviations of the movement which is performed by the moving object according to the <b>video</b> <b>stream</b> data and of a modelled movement which should have been performed by the moving object according to the kinematic model (21), d) deciding (25) if the deviations indicate a manipulation of the <b>video</b> <b>stream</b> data. In particular, the sequence (17) of video images may be obtained by decompressing (15) compressed <b>video</b> <b>stream</b> data...|$|R
40|$|An {{algorithm}} {{for detecting}} scene changes in compressed <b>video</b> <b>streams</b> is proposed. The proposed algorithm directly exploits the motion compensation {{information and the}} prediction error signal in the MPEG 1 coded <b>video</b> <b>stream.</b> By performing minimal decoding of the compressed <b>video</b> <b>stream,</b> the proposed algorithm results in signi cant savings in terms of execution time and memory requirement. Experimental {{results show that the}} algorithm is e ective in detecting abrupt scene changes (cuts) as well as gradual scene changes (dissolves) in an MPEG 1 -coded <b>video</b> <b>stream.</b> The algorithm is capable of processing video frames in real time and could be used for the rapid generation of key frames for real-time browsing of <b>video</b> <b>streams</b> and for indexing to support content-based access to on-line video libraries. ...|$|R
50|$|The event also {{attracted}} a record on-line audience. Live coverage attracted over 8 {{million people who}} watched over 15 million <b>video</b> <b>streams,</b> while total 55 million <b>video</b> <b>streams</b> had been watched by 23 July.|$|R
25|$|The Adelaide Bite, Brisbane Bandits and Perth Heat {{provided}} free {{audio and}} <b>video</b> <b>streaming</b> through internet website Ustream.|$|E
25|$|Silverlight {{was used}} to provide <b>video</b> <b>streaming</b> for the NBC {{coverage}} of the 2008 Summer Olympics in Beijing, the 2010 Winter Olympics in Vancouver, and the 2008 conventions for both major United States political parties. Silverlight was also used by Amazon Video and Netflix for their instant <b>video</b> <b>streaming</b> services, but Netflix said in its Tech Blog in 2013 that, since Microsoft had announced Silverlight's end-of-life, they would be moving to HTML5 video.|$|E
25|$|Starting {{in early}} 1995 the University of Ulm used {{animated}} GIF as live <b>video</b> <b>streaming</b> format {{to show a}} controllable model railroad.|$|E
30|$|The FPGA {{triggers}} the cameras at an adjustable frame rate to synchronize the two incoming <b>video</b> <b>streams.</b> However, corresponding pixels {{from the different}} cameras do not necessarily arrive {{at exactly the same}} time in general, mainly due to slight mismatches of the two camera clocks. To fully synchronize the <b>video</b> <b>streams</b> at pixel level, the incoming <b>video</b> <b>streams</b> are temporarily stored in small line FIFOs to compensate for the time offsets.|$|R
40|$|In {{practical}} multimedia systems, {{the content}} of coded <b>video</b> <b>streams</b> often needs to be re-edited at the nodes of transmitting networks. For example, logo insertion is always required for copyright protection at different local transmitting nodes. This kind of <b>video</b> <b>stream</b> editing is denoted as video content editing transcoding (VCET) in this paper. Though some techniques have been suggested for VCET, these methods cannot meet the requirement of dynamic transmitting bandwidth in practical applications. In this paper, we proposed an interface macroblock-based transcoding scheme for VCET, which can reuse the variable length codes of the original <b>video</b> <b>streams</b> {{as much as possible}} to achieve the best VCET quality. In order to ensure that the edited <b>video</b> <b>streams</b> can be transmitted by the original bandwidth, we also proposed a rate control algorithm for VCET, which can accurately control the bitrate of edited <b>video</b> <b>streams</b> according to the frame level coding bits of the original <b>video</b> <b>streams.</b> Experimental results showed that the proposed scheme achieved substantially better results in bitrate accuracy, computational complexities, and video quality than many other existing schemes...|$|R
3000|$|... [...]. That is, {{the mean}} {{rate of the}} <b>video</b> <b>stream</b> for the six lowest SNR users is 90 [*]kbps, whereas, the mean rate of the <b>video</b> <b>stream</b> for the {{remaining}} fourteen users is 360 [*]kbps.|$|R
25|$|MiLB.TV is {{the minor}} leagues' {{official}} online <b>video</b> <b>streaming</b> service, in the vein of Major League Baseball's MLB.tv. The service currently offers every Triple-A game and select games {{from the other}} classifications.|$|E
25|$|Advertisements for OLPC began {{streaming}} on the <b>video</b> <b>streaming</b> website Hulu {{and others}} in 2008. One such ad has John Lennon advertising for OLPC, with an unknown voice actor redubbing over Lennon's voice.|$|E
25|$|Since 1994, {{the show}} has been taped and {{broadcast}} on several networks, including E! (1994–2005), CBS (1998–2001), and HowardTV (2005–13), an on-demand digital cable service. An upcoming audio and <b>video</b> <b>streaming</b> app is currently in development.|$|E
50|$|Dropcam {{provides}} free live <b>streaming</b> <b>video</b> {{which is}} accessible through a web app and mobile apps for iOS and Android. Dropcam sends encrypted {{data to the}} cloud, which then securely <b>streams</b> the <b>video.</b> <b>Video</b> <b>streams</b> are private by default, but users can make their <b>video</b> <b>streams</b> public as well.|$|R
30|$|Firstly, {{calculate}} the Euclidean {{distance between the}} feature vectors of the first key frame and following frames by function (6). If the distance is over T, the subsequent m frame is the key frame, which is extracted from the <b>video</b> <b>stream.</b> Extract key frames from <b>video</b> <b>stream</b> {{as described in the}} previous steps until the last frame is calculated. Following the above steps, we can get a key frame sequence of the <b>video</b> <b>stream</b> finally.|$|R
40|$|In {{this paper}} we tackle {{the problem of}} robust <b>streaming</b> of <b>video</b> data over best effort packet networks, such as the Internet. The packet losses and delay, which are commonplace over such networks, can cause severe {{degradation}} in the video quality available to the end user. We propose to use multiple description coding (MDC) to protect the transmitted data against packet losses and delay, while also ensuring that the transmitted stream can be decoded with a standard video decoder, such as the H. 263 decoder. The video data is encoded into a high resolution, i. e., high quality, <b>video</b> <b>stream</b> (description) using an encoder that produces an H. 263 compliant stream. In addition, a low resolution <b>video</b> <b>stream</b> (description) is also generated by duplicating the "important" information from the high resolution <b>video</b> <b>stream.</b> This information includes the headers, the motion vectors {{and some of the}} discrete cosine transform (DCT) coefficients of the high resolution <b>video</b> <b>stream.</b> The remaining DCT coefficients are set to zero in the low resolution <b>video</b> <b>stream.</b> Hence both <b>video</b> <b>streams</b> are independently decodable by a standard H. 263 video decoder. However, only in case of a loss in the high resolution <b>video</b> <b>stream,</b> the corresponding information from the low resolution <b>video</b> <b>stream</b> is decoded, else the received high resolution <b>video</b> <b>stream</b> is decoded. Thus our system is an example of an unbalanced MDC system where the low resolution description is used only in case of losses in the high resolution description. The main contribution of the paper is an optimization algorithm which, given the probability of packet loss, allocates bits to the high resolution and low resolution descriptions, and selects the right number of coefficients to duplicate in the low resolution description, so as t [...] ...|$|R
25|$|Apple {{also offers}} online {{services}} with iCloud, which provides cloud storage and synchronization {{for a wide}} range of user data, including documents, photos, music, device backups, and application data, and Apple Music, its music and <b>video</b> <b>streaming</b> service.|$|E
25|$|Niconico, {{a popular}} Japanese video service, {{launched}} for Switch in Japan in July 2017, the first third-party media app in any market. Hulu {{was the first}} <b>video</b> <b>streaming</b> application for the Switch in North American markets, released on November 9, 2017.|$|E
25|$|In early 2014, Netflix <b>video</b> <b>streaming</b> service {{acquired}} rights for all 6 seasons. The broadcast rights were for one year. The seasons were remastered for digital TV. All of 6 seasons {{are available for}} purchase through the Amazon Prime video on demand service.|$|E
40|$|Traffic {{monitoring}} is {{a challenging}} task on crowded roads. Traditional traffic monitoring procedures are manual, expensive, time consuming and involve human operators. They are subjective {{due to the}} very involvement of human factor and sometimes provide inaccurate/incomplete monitoring results. Large scale storage and analysis of <b>video</b> <b>streams</b> were not possible due to limited availability of storage and compute resources in the past. Recent advances in data storage, processing and communications {{have made it possible}} to store and process huge volumes of video data and develop applications that are neither subjective nor limited in feature sets. It is now possible to implement object detection and tracking, behavioural analysis of traffic patterns, number plate recognition and automate security and surveillance on <b>video</b> <b>streams</b> produced by traffic monitoring and surveillance cameras. In this paper, we present a <b>video</b> <b>stream</b> acquisition, processing and analytics framework in the clouds to address some of the traffic monitoring challenges mentioned above. This framework provides an end-to-end solution for <b>video</b> <b>stream</b> capture, storage and analysis using a cloud based GPU cluster. The framework empowers traffic control room operators by automating the process of vehicle identification and finding events of interest from the recorded <b>video</b> <b>streams.</b> An operator only specifies the analysis criteria and the duration of <b>video</b> <b>streams</b> to analyse. The <b>video</b> <b>streams</b> are then automatically fetched from the cloud storage, decoded and analysed on a Hadoop based GPU cluster without operator intervention in our framework. It reduces the latencies in video analysis process by porting its compute intensive parts to the GPU cluster. The framework is evaluated with one month of recorded <b>video</b> <b>streams</b> data on a cloud based GPU cluster. The results show a speedup of 14 times on a GPU and 4 times on a CPU when compared with one human operator analysing the same amount of <b>video</b> <b>streams</b> data...|$|R
3000|$|In the simulations, {{we assume}} that all OBUs request VOD {{services}} after they enter the simulated highway. The requested <b>video</b> <b>streams</b> are randomly selected from the aforementioned four benchmark <b>video</b> <b>streams.</b> Except for the video data ([...] [...]...|$|R
40|$|Abstract—Transmission {{distortion}} {{analysis for}} <b>video</b> <b>streams</b> is a considerably challenging task. In this paper, a compressed-domain-based (CDB) transmission distortion model for pre-coded H. 264 /AVC <b>video</b> <b>streams</b> is developed. Unlike the earlier schemes, which {{were based on}} pixel domain and required a com-plete decoding of the compressed <b>video</b> <b>streams,</b> the CDB model only requires some information on the video features, which can be directly extracted from the compressed <b>video</b> <b>streams.</b> There-fore, {{the complexity of the}} calculations is substantially reduced, which is well suited for real-time applications. More specifically, the model is applicable to the real-time transmission for precoded <b>video</b> <b>streams,</b> such as <b>video</b> on demand and mobile video. The experimental results demonstrate high accuracy of the model. Furthermore, an application example using the CDB model in resource allocation in real-time multi-user video communication reveals the applicability and effectiveness of the model. Index Terms—Video; wireless, H. 264, distortion modeling, compressed domain I...|$|R
25|$|By November 2015, ABC was {{creating}} a digital slate called internal ABC3 for its WatchABC <b>video</b> <b>streaming</b> app. The ABC3 slate of 7 comedy and lifestyle short series debuted under the ABCd banner along with 38 older series under a revamped and renamed ABC app on July 13, 2016.|$|E
25|$|Amazon Studios is Amazon.com's {{division}} that develops television shows, movies and comics from online submissions and crowd-sourced feedback. It {{was started in}} late 2010. Content would be distributed through Amazon Video, Amazon’s digital <b>video</b> <b>streaming</b> service, and a competitor to services like Netflix and Hulu. For film, Warner Bros. is a partner.|$|E
25|$|Internet <b>video</b> <b>streaming</b> service YouTube offers {{captioning}} {{services in}} videos. The {{author of the}} video can upload a SubViewer (*.SUB), SubRip (*.SRT) or *.SBV file. As a beta feature, the site also added the ability to automatically transcribe and generate captioning on videos, {{with varying degrees of}} success based upon the content of the video.|$|E
40|$|In this paper, {{we propose}} a novel {{multi-point}} video conferencing system through error-prone channels, where the aggregation of multiple <b>video</b> <b>streams</b> and resource allocation are {{performed in a}} distributed manner. <b>Video</b> <b>stream</b> combiners, which are located in different geographical areas and serve as portals for conferees, aggregate incoming streams supplied by local users with other streams aggregated from nearby <b>video</b> <b>stream</b> combiners. A distributed multi-stream error protection scheme is performed in each <b>video</b> <b>stream</b> combiner to minimize the maximal expected video distortion among all aggregated streams. The simulation results demonstrate that our proposed scheme outperforms the traditional multicasting scheme by 1 dB ∼ 1. 4 dB in terms of average PSNR. 1...|$|R
40|$|The paper {{analyzes}} the main {{characteristics of the}} efficiency of methods for processing video, which influence the evaluation time costs in the processing and transmission of the <b>video</b> <b>stream.</b> An evaluation {{of the effectiveness of}} time spent in the processing and transmission of the <b>video</b> <b>stream</b> based on the experimental hardware and software implementations for the stationary background of dynamic images from different values of the threshold filtering. Built method for estimating the time spent on processing and transmission of the <b>video</b> <b>stream.</b> The conditions under which the time required for the processing and transmission of the <b>video</b> <b>stream</b> to the developed technology reduces the relative time costs for the technology MPEG...|$|R
40|$|Teachers usually {{illustrate}} major pedagogical concepts with graphics and/or images and/or tables and, {{in doing}} so, take {{a considerable amount}} of time in explanation. Despite the availability of many text extraction methods, they are limited such as when background is noisy, degraded, multicolored or containing graphics. This work presents an illustration extraction method for <b>video</b> <b>streams</b> to increasing learning efficiency among students. The proposed method separates the foreground from <b>video</b> <b>streams.</b> Above limitations of text extraction methods are solved by using contexture between image sequences in <b>video</b> <b>streams</b> and extracting illustrations from <b>video</b> <b>streams.</b> Two stages of the proposed method are training and extraction. Shot boundaries are detected to resample a <b>video</b> <b>stream</b> in a non-redundancy training set during the training phase. A background map together with a set of colors used frequently is then constructed based on the training set, subsequently used for illustration extraction. Next, a foreground map is generated according to the background map and frequent color set for each frame of the <b>video</b> <b>stream</b> during the extraction phase. Finally, illustrations are extracted by region labeling and geometric verification. Experimental results demonstrate the feasibility of the proposed method...|$|R
25|$|Wyoming Area {{has been}} praised {{numerous}} times for its integration of technology into curricula and activities. Furthermore, {{it provides an}} outstanding set of extracurricular activities focused around technology. The district has High speed internet connection, wireless technology, Smart and Active Boards, Mobile computer labs and <b>video</b> <b>streaming.</b> The district harnesses an online grading system to communication on demand with students and parents.|$|E
25|$|In November 2010, {{access to}} the video and social {{networking}} site MUBI was enabled for European, New Zealand, and Australian users; the service integrates elements of social networking with rental or subscription <b>video</b> <b>streaming,</b> allowing users to watch and discuss films with other users. Also in November 2010 the video rental service VUDU, NHL GameCenter Live, and subscription service Hulu Plus launched on PlayStation 3 in the United States.|$|E
25|$|Internet {{television}} (Internet TV), (online television) or IPTV (Internet Protocol Television) is {{the digital}} distribution of television content via the Internet {{as opposed to}} traditional systems like terrestrial, cable and satellite, although internet itself is received by terrestrial, cable or satellite methods. Internet television is a general term that covers the delivery of television shows and other video content over the Internet by <b>video</b> <b>streaming</b> technology, typically by major traditional television broadcasters.|$|E
40|$|This report {{describes}} {{the purpose and}} the use of a flexible <b>video</b> <b>stream</b> converter program which is capable of performing various image manipulation operations on YUV-encoded <b>video</b> <b>streams.</b> This program was developed in support of a larger project that strives to make a more versitile and efficient programming environment for video processing on embedded devices such as mobile phones. The described YUVconverter program assists this project by producing test <b>video</b> <b>streams</b> for evaluating the embedded applications. The converter is able to read and edit YUV <b>video</b> input <b>streams</b> with operations, such as mirroring, black and white conversion and scaling...|$|R
50|$|<b>Videos</b> <b>stream</b> in {{different}} formats.|$|R
40|$|Abstract. A {{technique}} for detecting scene changes in compressed <b>video</b> <b>streams</b> is proposed which combines multiple modes of information. The proposed technique directly exploits and combines the luminance, chromi-nance, motion compensation {{information and the}} prediction error signal in an MPEG 1 -coded <b>video</b> <b>stream.</b> By performing minimal decoding of the compressed <b>video</b> <b>stream,</b> the proposed technique results in signif-icant savings in terms of execution time and memory usage. The tech-nique is capable of detecting abrupt scene changes (cuts), gradual scene changes (dissolves), and dominant camera motion {{in the form of}} pans and zooms in an MPEG 1 -coded <b>video</b> <b>stream.</b> Experimental results show that combining multiple modes of information is more eective in detect-ing cuts and dissolves. The proposed technique is capable of processing video frames in real time and could be used for the rapid generation of key frames for real-time browsing of <b>video</b> <b>streams</b> and for indexing to support content-based access to video libraries. ...|$|R
