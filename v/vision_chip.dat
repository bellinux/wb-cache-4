89|59|Public
5000|$|There is no {{standard}} {{definition of}} what constitutes a <b>vision</b> <b>chip</b> and thus the type of circuitry that may be performed. Below is a sample list of processing steps reported in <b>vision</b> <b>chip</b> designs, as reported in several books.: ...|$|E
5000|$|... #Subtitle level 2: Types of {{processing}} {{performed in a}} <b>vision</b> <b>chip</b> ...|$|E
50|$|Optical mouse sensor: The {{sensor chip}} {{used in an}} optical mouse is a <b>vision</b> <b>chip.</b>|$|E
40|$|In many applications, such as {{multimedia}} and on-chip camera, {{there is}} a need for the production of low power, low weight and low cost integrated circuits. Several CMOS <b>vision</b> <b>chips</b> have been proposed in the literature. Some limitations of conventional 2 D architectures are discussed and a new 3 D generation of <b>vision</b> <b>chips</b> is presented and reviewed in this paper. As a result of this analysis, some conclusions on the advantages and limitations of 2 D <b>vision</b> <b>chips</b> and the feasibility of the 3 D approach are explored...|$|R
40|$|Organisms such as {{bees and}} flies are superb at visually-guided {{navigation}} in real-world environments. We have implemented visual motion processing algorithms {{inspired by the}} visual systems of insects in custom analog/digital VLSI <b>vision</b> <b>chips.</b> In this paper we describe the implementation and operation of these algorithms, and discuss how these <b>vision</b> <b>chips</b> may be applied to practical problems of airborne visually-guided navigation. 1...|$|R
40|$|Bibliography: leaves 195 - 210. xviii, 210 leaves : ill.; 30 cm. A {{systematic}} view of all design levels, {{from the}} pixie {{level to the}} architectural level of <b>vision</b> <b>chips.</b> Important issues {{in the design of}} analog VLSI (AVLSI) <b>vision</b> <b>chips,</b> including mismatch and digital noise are addressed. Thesis (Ph. D.) [...] University of Adelaide, Dept. of Electrical and Electronic Engineering, 199...|$|R
50|$|A <b>vision</b> <b>chip</b> is an {{integrated}} circuit having both image sensing circuitry and image processing circuitry {{on the same}} die. The image sensing circuitry may be implemented using charge-coupled devices, active pixel sensor circuits, or any other light sensing mechanism. The image processing circuitry may be implemented using analog, digital, or mixed signal (analog and digital) circuitry. One area of research {{is the use of}} neuromorphic engineering techniques to implement processing circuits inspired by biological neural systems. The output of a <b>vision</b> <b>chip</b> is generally a partially processed image or a high level information signal revealing something about the observed scene. Although there is no standard definition of a <b>vision</b> <b>chip,</b> the processing performed may comprise anything from processing individual pixel values to performing complex image processing functions and outputting a single value or yes/no signal based on the scene.|$|E
50|$|The {{overwhelming}} majority of <b>vision</b> <b>chip</b> designs were executed largely by academic institutions as part of research projects. However several designs have, {{at one point or}} another, been commercialized as a product.|$|E
50|$|An {{optical flow}} sensor is a vision sensor capable of {{measuring}} optical flow or visual motion and outputting a measurement based on optical flow. Various configurations of optical flow sensors exist. One configuration {{is an image}} sensor chip connected to a processor programmed to run an optical flow algorithm. Another configuration uses a <b>vision</b> <b>chip,</b> which is an integrated circuit having both the image sensor and the processor on the same die, allowing for a compact implementation. An {{example of this is}} a generic optical mouse sensor used in an optical mouse. In some cases the processing circuitry may be implemented using analog or mixed-signal circuits to enable fast optical flow computation using minimal current consumption. One area of contemporary research is the use of neuromorphic engineering techniques to implement circuits that respond to optical flow, and thus may be appropriate for use in an optical flow sensor. Such circuits may draw inspiration from biological neural circuitry that similarly responds to optical flow.|$|E
40|$|We present our Intelligent Reconfigurable Integrated Satellite (IRIS) Processor. At {{the heart}} of the system are our {{reconfigurable}} <b>vision</b> <b>chips</b> which are capable of massively parallel analog processing. The smart <b>vision</b> <b>chips</b> are capable of not only centroiding and pattern recognition but also tracking and controlling devices including MEMs devices and active pixel arrays. In addition to discussing the active optic and active electronic devices, several small satellite system applications are presented along with experimental and simulation results...|$|R
40|$|El pdf del libro es la versión post-print. This book {{presents}} a comprehensive, systematic {{approach to the}} development of vision system architectures that employ sensory-processing concurrency and parallel processing to meet the autonomy challenges posed by a variety of safety and surveillance applications. Coverage includes a thorough analysis of resistive diffusion networks embedded within an image sensor array. This analysis supports a systematic approach to the design of spatial image filters and their implementation as <b>vision</b> <b>chips</b> in CMOS technology. The book also addresses system-level considerations pertaining to the embedding of these <b>vision</b> <b>chips</b> into vision-enabled wireless sensor networks. Describes a system-level approach for designing of vision devices and embedding them into vision-enabled, wireless sensor networks; Surveys state-of-the-art, vision-enabled WSN nodes; Includes details of specifications and challenges of vision-enabled WSNs; Explains architectures for low-energy CMOS <b>vision</b> <b>chips</b> with embedded, programmable spatial filtering capabilities; Includes considerations pertaining to the integration of <b>vision</b> <b>chips</b> into off-the-shelf WSN platforms. The authors would like to express their acknowledgment to the Andalusian Regional Goverment, that partially funded the work through project 2006 -TIC- 2352; to the Spanish Ministry of Science and Innovation, that contributed through projects TEC 2009 - 11812 and IPT- 2011 - 1625 - 430000, both co-funded by the European Regional Development Fund; and to the Office of Naval Research (USA), that partially supported the work through grant N 000141110312. Peer reviewe...|$|R
40|$|This paper {{presents}} a novel CMOS color pixel with a 2 D metal-grating structure for real-time <b>vision</b> <b>chips.</b> It {{consists of an}} N-well/P-substrate diode without salicide and 2 D metal-grating layers on the diode. The periods of the 2 D metal structure are controlled to realize color filtering. We implemented sixteen kinds of the pixels with the different metal-grating structures in a standard 0. 18 mu m CMOS process. The measured results demonstrate that the N-well/P-substrate diode without salicide and with the 2 D metal-grating structures can serve as the high speed RGB color active pixel sensor for real-time <b>vision</b> <b>chips</b> well...|$|R
5000|$|Since September 2015, Hotz {{has been}} working on his own AI startup called comma.ai. In an {{interview}} with Bloomberg, Hotz revealed he is building vehicular automation technology based on artificial intelligence algorithms. Hotz has built a working self-driving 2016 Acura ILX, which he demonstrated on the I-280 in a video. The video prompted a cease and desist letter from the California Department of Motor Vehicles. Hotz wants to sell his technology to Tesla Motors and he has reported to have talked to CEO Elon Musk and is working on proving his technology to be superior to that of Mobileye, which, at the time, was used for Tesla Autopilot. [...] Hotz claims that Musk offered him $12 million (minus $1 million for every month it took Hotz to work on the task) to create a driving system that could replace the MobilEye solution currently used in Tesla vehicles.Tesla later released a statement on their website citing corrections to the Bloomberg article, stressing that their autopilot system was developed in-house, with a <b>vision</b> <b>chip</b> component from MobilEye, instead of one separate autopilot system manufactured by MobilEye, as suggested by Hotz in the interview with Bloomberg. Tesla CEO Elon Musk offered advice on Hotz's self-driving car project in a recent interview.|$|E
40|$|A {{real-time}} {{visual processing}} system using a general-purpose <b>vision</b> <b>chip,</b> {{an image sensor}} in which photo detectors and processing elements are integrated, is de-scribed. In order to control the <b>vision</b> <b>chip</b> and pro-cess its output at high speed, a novel architecture called SPARSIS, in which control process of the <b>vision</b> <b>chip</b> is pipelined and integrated with a RISC type integer pipeline, has been developed. This architecture can guarantee real-time operation with high temporal res-olution, and even makes possible software-controlled AID conversion. Sample algorithms demonstrating its fine-grained realtimeness, and experimental results with the implemented system, are also described...|$|E
40|$|In this paper, {{we propose}} a vision system using a field {{programmable}} gate array(FPGA) and a smart <b>vision</b> <b>chip.</b> The {{output of the}} <b>vision</b> <b>chip</b> is varied by illumination conditions. This chip is suitable as a surveillance system in a dynamic environment. However, because the output swing of a smart <b>vision</b> <b>chip</b> {{is too small to}} definitely confirm the warning signal with the FPGA, a modification was needed for a reliable signal. The proposed system is based on a transmission control protocol/internet protocol(TCP/IP) that enables monitoring from a remote place. The warning signal indicates that some objects are too near...|$|E
40|$|<b>Vision</b> <b>chips</b> are microelectronic devices which combine image sensing and {{processing}} {{on a single}} silicon die. In a way somewhat resembling the vertebrate retina these VLSI chips perform preliminary image processing directly on the sensory plane and are capable of very high processing speed at very low power consumption. This makes them particularly suitable for applications such as autonomous robots and other embedded machine vision systems. This paper discusses the principles of using massively parallel fine-grain SIMD processor arrays for low-level image processing and reviews the design and implementation of <b>vision</b> <b>chips</b> developed at the University of Manchester, including the SCAMP- 3 chip, which contains 16, 384 processors. Application examples and experimental results are presented. 1...|$|R
40|$|Abstract — So as to {{face the}} large variety of their {{possible}} applications, <b>vision</b> <b>chips</b> have to be programmable. Our approach lies on an universal switched capacitors based structure that is suitable to implement {{a whole set of}} operations. In this paper, we present this structure and his use within a retina’s architecture. ...|$|R
40|$|A partial {{review of}} neuromorphic vision sensors that are {{suitable}} for use in autonomous systems is presented. Interfaces are being developed to multiplex the high-dimensional output signals of arrays of such sensors and to communicate them in standard formats to o#-chip devices for higher-level processing, actuation, storage and display. Alternatively, on-chip processing stages may be implemented to extract sparse image parameters, thereby obviating the need for multiplexing. Autonomous robots are used to test neuromorphic <b>vision</b> <b>chips</b> in real-world environments and to explore the possibilities of data fusion from di#erent sensing modalities. Examples of autonomous mobile systems that use neuromorphic <b>vision</b> <b>chips</b> for line tracking and optical flow matching are described. Keywords: vision, motion, optical flow, focal-plane array, retina, neuromorphic, analog VLSI, tracking 1. INTRODUCTION Neuromorphic vision sensors and preprocessors are increasingly being used to implement the firs [...] ...|$|R
40|$|A {{bio-inspired}} <b>vision</b> <b>chip</b> for {{edge detection}} was fabricated using 0. 35 μm double-poly four-metal complementary metal-oxide-semiconductor technology. It mimics the edge detection mechanism of a biological retina. This type of <b>vision</b> <b>chip</b> offer several advantages including compact size, high speed, and dense system integration. Low resolution and relatively {{high power consumption}} are common limitations of these chips because of their complex circuit structure. We have tried {{to overcome these problems}} by rearranging and simplifying their circuits. A <b>vision</b> <b>chip</b> of 160 × 120 pixels has been fabricated in 5 × 5 mm 2 silicon die. It shows less than 10 mW of power consumption...|$|E
40|$|We {{developed}} a compact vision system for wearable interface applications using a <b>vision</b> <b>chip.</b> The <b>vision</b> <b>chip</b> {{is capable of}} real-time vision at higher frame rates than the video frame rate with a single chip. Using this system, vision-based wearable man-machine interfaces, such as a portable eye tracker and a six-degrees-of-freedom input device, can be realized at higher frame rates than ever before. 1...|$|E
30|$|As a {{representative}} device of this category, the SCAMP- 3 <b>Vision</b> <b>Chip</b> {{was selected to}} map the retinal vessel tree extraction algorithm described in Section 2.|$|E
40|$|International audienceThis {{paper is}} focused on our recent results on the used of local pixel interactions. We show results {{obtained}} on smart <b>vision</b> <b>chips</b> {{with the help of}} the mean value computation of small pixels block. Technical details on the implementation of this computation will be done. Then, we will focus on <b>vision</b> <b>chips</b> dedicated to the improvement of the input dynamic range (HDR sensor) using a bio-inspired law close to a light adaptive Gamma curve and a smart management of the pixel integration time. We show the use of these local mean values in order to minimize temporal redundancies in a flow of images. This technique reduces the power consumption for a constant frame rate (due to the reduced number of read and converted pixels) or improves the average frame rate of the imager. Finally, we will expose a very interesting alternative dedicated to a very efficiency compression coder dedicated to image wireless sensor network...|$|R
40|$|Abstract—This paper {{presents}} {{the design and}} the VLSI imple-mentation of an asynchronous cellular logic array for fast binary image processing. The proposed processor array employs trigger-wave propagation and collision detection mechanisms for binary image skeletonization, and Voronoi tessellation. Low power, low area, and high processing speed are achieved using full custom dy-namic logic design. The prototype array consisting of 64 96 cells is fabricated in a standard 90 nm CMOS technology. The experi-mental results confirm the fast operation of the array, capable of extracting up to skeletons per second, consuming less than 1 nJ/skeleton. The asynchronous operation enables circular wave contours, which improves {{the quality of the}} extracted skele-tons. The proposed asynchronous processing module consists of 24 MOS transistors and occupies area. Such array {{can be used as a}} co-processing unit aiding global binary image processing in standard pixel-parallel SIMD architectures in <b>vision</b> <b>chips.</b> Index Terms—Cellular processor array, CMOS, CNN, image processing, skeletonization, trigger-wave propagation, <b>vision</b> <b>chips.</b> I...|$|R
40|$|Abstract. The {{field of}} neuromorphic {{engineering}} {{is a relatively}} new one. In this paper we introduce the basic concepts underlying neuromorphic engineering and point out how this type of research could be exploited for industrial applications. We describe some of the circuits commonly used in neuromorphic analog VLSI chips and present examples of neuromorphic systems, containing <b>vision</b> <b>chips</b> for extracting relevant features of the scene, such as edges or velocity vectors. ...|$|R
40|$|A {{demonstration}} {{is made of}} a programmable <b>vision</b> <b>chip,</b> containing {{an array}} of photosensors collocated with a processing circuitry and memory, implementing a Dynamic Neural Field (DNF) over a simple saliency map. The system detects and tracks moving objects with strong contrasts. The computation of the DNF's dynamics is performed entirely on the <b>vision</b> <b>chip.</b> The system solely outputs relevant information that has been processed on the array: {{the activity of the}} DNF and/or address-events corresponding to the coordinates of its bumps of activity...|$|E
40|$|Abstract—We studied neuromorphic {{models of}} {{binocular}} dis-parity processing and mapped them onto a <b>vision</b> <b>chip</b> containing a massively parallel analog processor array. Our {{goal was to}} make efficient use of the available hardware while preserving the fundamental computations performed by the models. We also developed an optical fixture that used mirrors to simultaneously focus two images onto the <b>vision</b> <b>chip.</b> This fixture simulates two horizontally-separated virtual cameras, thereby allowing us to run our binocular disparity estimation algorithms using a single image sensor in real time. I...|$|E
40|$|A {{networked}} high-speed {{vision system}} that employs as a vision sensor node a digital <b>vision</b> <b>chip,</b> a CMOS imager that integrates a digital processing element {{with a photo}} detector in each pixel is reported. High-speed visual feature information at the frame rate of 1, 000 fps is transferred over the standard TCP/IP on 100 BASE-TX Ethernet switching network. We evaluated {{the effectiveness of the}} system through experiments, and found that the system can convey visual information with sufficiently small latency. Index Terms — <b>vision</b> <b>chip,</b> real-time network, smart camera, high-speed vision 1...|$|E
40|$|In {{this paper}} {{we present a}} concept to train physics {{students}} {{in the field of}} integrated sensor design realized at the faculty of physics and astronomy at Heidelberg University (Germany). A laboratory for design and test of integrated sensor chips has been set up and a course program for physics students has been introduced. The work of the laboratory is illustrated by the presentation ofa project to design and build a tactile vision substitution system based on so-called <b>vision</b> <b>chips...</b>|$|R
40|$|Abstract—This paper {{introduces}} a new algorithm for implementing cellular active contour technique based on pixellevel snakes (PLS). The main motivation is the optimization of the computational performance, especially when PLS are implemented on pixel-parallel single instruction multiple data (SIMD) processor arrays. The algorithm {{is based on}} the evolution of an active region. This allows the implementation of the entire algorithm using very simple local rules. Additionally, nested contours and propagation into narrow cavities are supported. The algorithm and experimental results from realtime implementation on <b>vision</b> <b>chips</b> are presented. I...|$|R
40|$|Abstract. This paper proposes and {{demonstrates}} novel types of <b>vision</b> <b>chips</b> that utilize pulse trains for image processing. Two types of chips were designed using 1. 2 µm double-metal double-poly CMOS process; one {{is based on}} a pulse width modulation (PWM) and the other {{is based on a}} pulse frequency modulation (PFM). In both chips the interaction between the pixels were introduced to realize the image pre-processing. The basic experimental and simulation results are shown for the PWM and PFM chips, respectively. Also the comparison between two types is discussed. ...|$|R
40|$|AbstractWith {{the help}} of the bionic devices blind people might regain some of their sight. The main {{objective}} of this paper is the presentation of the vision restoration techniques and bionic vision devices. Also, the vertically integrated <b>vision</b> <b>chip</b> technology is bringing a revolution in the design of artificial vision systems. Prospective vision restoration techniques are presented and discussed in detail focusing on retina implants, bionic glasses and on <b>vision</b> <b>chip</b> technologies. Our paper summarizes and details the essence of our successful program, and the knowledge how to build and establish a groundbreaking innovation center...|$|E
40|$|Abstract — This live {{demonstration}} {{presents a}} vision {{system based on}} a digital SIMD <b>vision</b> <b>chip</b> with in-pixel processing capabilities. The system is comprised of asynchronous/synchronous processor array (ASPA 2), embedded custom microcontroller with interface circuits and software development environment. Execution {{of a number of}} low and medium level image processing algorithms in real time is demonstrated. INTRODUCTION: The presented system features a general purpose <b>vision</b> <b>chip</b> with real-time focal plane greyscale processing capabilities. Despite relatively low resolution such a device delivers high performance, due to massively parallel image processing, coupled with low power consumption. The mai...|$|E
40|$|Real-time image {{processing}} at high frame rates could {{play an important}} role in various visual measurement. Such {{image processing}} can be realized by using a high-speed vision system imaging at high frame rates and having appropriate algorithms processed at high speed. We introduce a <b>vision</b> <b>chip</b> for high-speed vision and propose a multi-target tracking algorithm for the <b>vision</b> <b>chip</b> utilizing the unique features. We describe two visual measurement applications, target counting and rotation measurement. Both measurements enable excellent measurement precision and high flexibility because of high-frame-rate visual observation achievable. Experimental results show the advantages of vision chips compared with conventional visual systems...|$|E
40|$|Abstract – We {{present a}} {{software}} {{environment for the}} efficient simulation of cellular processor arrays (CPAs). This software is used to explore algorithms that are designed for CPAs, neuromorphic arrays, multi-layer neural networks and <b>vision</b> <b>chips.</b> The software (APRON) uses a highly optimised core combined with a flexible compiler to provide the user with tools for the prototyping of new array hardware and the emulation of existing devices. We show that software processor arrays can operate at impressive speeds, with high numerical accuracy. APRON can be configured to use additional processing hardware if necessary, and can even {{be used as the}} graphical user interface for new or existing CPA systems...|$|R
40|$|This paper {{presents}} a new processing cell circuit, {{suitable for use}} in massively parallel fine-grain processor arrays, oriented towards image processing applications. The design, based on dynamic logic, is efficient for both local and global operations. In this paper we discuss design trade-offs and provide {{detailed description of the}} architecture. A cellular processor array based on the presented design can operate in both discrete- and continuous-time domains. Asynchronous execution of global operations significantly increases overall performance. Simulation results indicate the performance in the range from 1. 1 (unsigned products) to 2900 (asynchronous binary processing) MOPS/cell. KEY WORDS <b>Vision</b> <b>chips,</b> cellular processor arrays, asynchronous processing, SIMD arrays, wave propagations. I...|$|R
40|$|This paper {{presents}} novel {{high speed}} <b>vision</b> <b>chips</b> based on multiple levels of parallel processors. The chip integrates CMOS image sensor, multiple-levels of SIMD parallel processors and an embedded microprocessor unit. The multiple-levels of SIMD parallel processors consist of an array processor of SIMD processing elements(PEs) and {{a column of}} SIMD row processors(RPs). The PE array and RPs have an O(NxN) parallelism and an O(N) parallelism, respectively. The PE array, RPs and MPU can execute low-, mid- and high-level image processing algorithms, respectively. Prototype chips are fabricated using the 0. 18 μm CMOS process. Applications including target tracking, pattern extraction and image recognition are demonstrated. ? 2011 IEEE...|$|R
