5614|2700|Public
5|$|Transition-minimized {{differential}} signaling (TMDS) on HDMI interleaves video, {{audio and}} auxiliary data using three different packet types, called the <b>Video</b> <b>Data</b> Period, the Data Island Period and the Control Period. During the <b>Video</b> <b>Data</b> Period, the pixels {{of an active}} video line are transmitted. During the Data Island period (which occurs during the horizontal and vertical blanking intervals), audio and auxiliary data are transmitted within a series of packets. The Control Period occurs between Video and Data Island periods.|$|E
5|$|HDMI (High-Definition Multimedia Interface) is a {{proprietary}} audio/video interface for transmitting uncompressed <b>video</b> <b>data</b> and compressed or uncompressed digital audio data from an HDMI-compliant source device, {{such as a}} display controller, to a compatible computer monitor, video projector, digital television, or digital audio device. HDMI is a digital replacement for analog video standards.|$|E
5|$|Spacecraft {{communications}} {{included a}} command subsystem operating at 154.2 and 2106.4MHz and a PCM narrow-band telemetry subsystem, operating at 2287.5 and 137.86MHz, for spacecraft housekeeping, attitude, and sensor performance data. <b>Video</b> <b>data</b> from the three-camera RBV system was transmitted in both real-time and tape recorder modes at 2265.5MHz, while {{information from the}} MSS was constrained to a 20MHz radio-frequency bandwidth at 2229.5MHz.|$|E
40|$|Abstract. With {{the rise}} of the network,everyday the video {{websites}} update plenty of <b>video</b> <b>datas.</b> Faced with a lot of video datas,if you only rely on the human to analyze the <b>video</b> <b>datas</b> in order to dig out the information hidden in the video room,it will {{take a lot of time}} and is difficult to achieve the desired result. This paper develops a data mining and visualization system,which visualized shows the relationship between the <b>video</b> <b>datas</b> through a network graph of nodes. Based on visualized showing the relationship between the video datas,the system provides the tool to analyze the <b>video</b> <b>datas</b> and dig out the information hidden in the video room...|$|R
40|$|A {{compressive}} {{sensing system}} for dynamic video acquisition. The system includes a video signal interface including a compressive imager configured to acquire compressive sensed <b>video</b> frame <b>data</b> from an object, a {{video processing unit}} including a processor and memory. The video processing unit is configured to receive the compressive sensed <b>video</b> frame <b>data</b> from the <b>video</b> signal interface. The memory comprises computer readable instructions that when executed by the processor cause the processor to generate a motion estimate from the compressive sensed <b>video</b> frame <b>data</b> and generate dynamical <b>video</b> frame <b>data</b> from the motion estimate and the compressive sensed <b>video</b> frame <b>data.</b> The dynamical <b>video</b> frame <b>data</b> may be output...|$|R
40|$|The {{invention}} {{relates to}} {{a method of}} detecting manipulations of digital <b>video</b> stream <b>data,</b> wherein the <b>video</b> stream <b>data</b> represents a sequence (17) of video images comprising at least one moving object that moves relatively to other objects and/or relatively to a background scenery and wherein the method comprises: a) detecting {{the at least one}} moving object from the <b>video</b> stream <b>data,</b> b) identifying (19) a kinematic model (21) which describes the movement of the moving object, c) determining (23) deviations of the movement which is performed by the moving object according to the <b>video</b> stream <b>data</b> and of a modelled movement which should have been performed by the moving object according to the kinematic model (21), d) deciding (25) if the deviations indicate a manipulation of the <b>video</b> stream <b>data.</b> In particular, the sequence (17) of video images may be obtained by decompressing (15) compressed <b>video</b> stream <b>data...</b>|$|R
5|$|Both HDMI and DVI use TMDS to send 10-bit {{characters}} that are encoded using 8b/10b encoding that {{differs from the}} original IBM form for the <b>Video</b> <b>Data</b> Period and 2b/10b encoding for the Control Period. HDMI adds the ability to send audio and auxiliary data using 4b/10b encoding for the Data Island Period. Each Data Island Period is 32 pixels in size and contains a 32-bit Packet Header, which includes 8 bits of BCH ECC parity data for error correction and describes {{the contents of the}} packet. Each packet contains four subpackets, and each subpacket is 64 bits in size, including 8 bits of BCH ECC parity data, allowing for each packet to carry up to 224 bits of audio data. Each Data Island Period can contain up to 18 packets. Seven of the 15 packet types described in the HDMI 1.3a specifications deal with audio data, while the other 8 types deal with auxiliary data. Among these are the General Control Packet and the Gamut Metadata Packet. The General Control Packet carries information on AVMUTE (which mutes the audio during changes that may cause audio noise) and Color Depth (which sends the bit depth of the current video stream and is required for deep color). The Gamut Metadata Packet carries information on the color space being used for the current video stream and is required for xvYCC.|$|E
25|$|The {{file size}} {{distribution}} of publicly available audio and <b>video</b> <b>data</b> files (MIME types) follows a log-normal distribution over five orders of magnitude.|$|E
25|$|AT Corp., {{originally}} the American Telephone and Telegraph Company, is the subsidiary of AT that provides voice, <b>video,</b> <b>data,</b> and Internet telecommunications and professional services to businesses, consumers, and government agencies.|$|E
50|$|GBS {{provides}} high-speed, one way flow of multimegabit <b>video</b> and <b>data</b> products including National Television Standards Committee (NTSC) <b>video,</b> large <b>data</b> files, map {{files and}} web products. GBS {{operates as a}} system of broadcast sites with multiple receive suite types.|$|R
50|$|It was at Proteon, {{that the}} idea of using the same cable for {{transmitting}} <b>video</b> and <b>data</b> came to him. Though, people told him <b>video</b> and <b>data</b> couldn't mix. From 1988 to 1990 he oversaw Applitek, a data networking company, as president and CEO where he was persuaded that mixing <b>video</b> and <b>data</b> is possible, although the vision remained on hold until 1990 when he bought Applitek's assets and formed LANcity where the cable modem was born and the DNA of broadband was built.|$|R
50|$|The company {{supplies}} {{cable television}} headend or hub devices that receive digital <b>video</b> or <b>data</b> from the operator network, re-packetizes the <b>video</b> or <b>data</b> into an MPEG transport stream, then digitally modulates the MPEG transport stream onto a downstream RF channel using quadrature amplitude modulation (QAM).|$|R
25|$|The ET has {{external}} cameras {{mounted in}} the brackets attached to the shuttle along with transmitters that can continue to send <b>video</b> <b>data</b> long after the shuttle and the ET have separated.|$|E
25|$|Digital watermarks exist since 1992. They are steganographically {{embedded}} within audio or <b>video</b> <b>data</b> during production or distribution. They {{can be used}} for recording the copyright owner, the distributor, the distribution chain or identifying the purchaser of the music.|$|E
25|$|The HDMI {{interface}} is {{a compact}} audio/video interface for transferring uncompressed <b>video</b> <b>data</b> and compressed/uncompressed digital audio data from an HDMI-compliant device to a compatible computer monitor, video projector, digital television, or digital audio device. It is mainly {{used in the}} consumer area, but increasingly used in professional devices including uncompressed video, often called clean HDMI.|$|E
5000|$|Communications and Networks: {{to provide}} {{information}} through voice, <b>video</b> and <b>data</b> ...|$|R
5000|$|Store music, photos, <b>videos</b> and <b>data</b> files {{online and}} access them anywhere.|$|R
50|$|TIA-568-C (telecommunications cabling standards, used {{by nearly}} all voice, <b>video</b> and <b>data</b> networks).|$|R
25|$|The depth sensor {{consists}} of an infrared laser projector combined with a monochrome CMOS sensor, which captures <b>video</b> <b>data</b> in 3D under any ambient light conditions. The sensing range of the depth sensor is adjustable, and Kinect software is capable of automatically calibrating the sensor based on gameplay and the player's physical environment, accommodating {{for the presence of}} furniture or other obstacles.|$|E
25|$|The VLC {{media player}} {{software}} {{is able to}} read audio and <b>video</b> <b>data</b> from DVDs that incorporate Content Scramble System (CSS) encryption, even though the VLC media player software lacks a CSS decryption license. The unauthorized decryption of CSS-encrypted DVD content or unauthorized distribution of CSS decryption tools may violate the US Digital Millennium Copyright Act. Decryption of CSS-encrypted DVD content has been temporarily authorized for certain purposes (such as documentary filmmaking that uses short portions of DVD content for criticism or commentary) under the Digital Millennium Copyright Act anticircumvention exemptions that were issued by the US Copyright Office in 2010. However these exemptions do not change the DMCA's ban {{on the distribution of}} CSS decryption tools like VLC.|$|E
2500|$|Several color {{encodings}} {{are possible}} in the serial digital interface. The default (and most common case) is 10-bit linearly sampled <b>video</b> <b>data</b> encoded as 4:2:2 YCbCr. (YCbCr is a digital representation of the YPbPr colorspace). Samples of video are stored as described above. Data words correspond to signal levels of the respective video components, as follows: ...|$|E
50|$|VIA3 Meeting Manager - Securely connects {{users with}} audio, <b>video,</b> and <b>data</b> {{collaboration}} tools.|$|R
5000|$|... {{intelligent}} Multiservice Gateways (iMG) deliver voice, <b>video</b> and <b>data</b> {{over the}} [...] "last mile" ...|$|R
5000|$|Add mobile {{services}} to existing voice, <b>video</b> and <b>data</b> offers, without network and operating investments ...|$|R
2500|$|One of {{the first}} demonstrations of the ability for {{telecommunications}} to help sign language users {{communicate with each other}} occurred when AT's videophone (trademarked as the [...] "Picturephone") was introduced to the public at the 1964 New York World's Fair– two deaf users were able to freely communicate with each other between the fair and another city. However, video communication did not become widely available until sufficient bandwidth for the high volume of <b>video</b> <b>data</b> became available in the early 2000s.|$|E
2500|$|At the 2003 European Grand Prix, David Coulthard and McLaren {{managing}} director Martin Whitmarsh accused Alonso of giving Coulthard a brake test. This was {{in relation to}} a passage of racing {{towards the end of the}} race when Coulthard was trying to overtake Alonso, who was holding him up. Coulthard swerved off the track and into retirement during an attempted overtake. After talking to the drivers and viewing telemetry and <b>video</b> <b>data,</b> the FIA stewards decided that the incident did not warrant any [...] "further judicial action".|$|E
2500|$|On March 16, the {{physical}} {{edition of the}} single was released, featuring the B-sides [...] "Slow Motion" [...] and [...] "Montage". A limited edition of the single was produced, which featured CD Extra <b>video</b> <b>data</b> of [...] "Montage"'s music video. The first press issue version of the single featured a code {{to apply for the}} band's June tour of Zepp concert venues in Japan, Sakanaquarium 2011: Zepp Alive. On March 18, an official cellphone application was released for the song on the iTunes App Store. In the April edition of Rockin' On Japan, an interview with Yamaguchi about the single was featured.|$|E
5000|$|... 2011 {{focused on}} the theme The Right to Know, in which Impakt dove into all {{dilemmas}} inherent in our modern data society, with conspiracy theories and cover-ups, digital dissidents and banned <b>videos,</b> <b>data</b> journalism and fear management, fine print messages and big secrets. The theme transpired to be extremely apt, as 2011 saw {{the onset of the}} Arab Spring and the prominence of Wikileaks rise.|$|R
40|$|Millions {{of sensors}} {{around the globe}} {{currently}} collect avalanches of data about our world. The rapid development and deployment of sensor technology is intensifying the existing problem of too much data and not enough knowledge. With a view to alleviating this glut, we propose that sensor <b>data,</b> especially <b>video</b> sensor <b>data,</b> can be annotated with semantic metadata to provide contextual information about videos on the Web. In particular, we present an approach to annotating <b>video</b> sensor <b>data</b> with spatial, temporal, and thematic semantic metadata. This technique builds on current standardization efforts within the W 3 C and Open Geospatial Consortium (OGC) and extends them with Semantic Web technologies to provide enhanced descriptions and access to <b>video</b> sensor <b>data...</b>|$|R
50|$|Ultra Density Optical (UDO) is {{an optical}} disc format {{designed}} for high-density storage of high-definition <b>video</b> and <b>data.</b>|$|R
2500|$|The game's {{cinematics}} {{and voice}} direction were considered exceptional by many publications, particularly {{relative to other}} titles of the day. 1UP.com's writers referred to the cast as [...] "actual talent" [...] comparative to other actors in the medium. Some reviewers, though, described the PlayStation iteration's loading times as particularly exorbitant and dissatisfactory. Next Generation decried these as [...] "noticeable and at times intrusive", while IGN rebuked them as [...] "agonizing", but noted that they were common to disc-based games, and reasonably unobtrusive in Blood Omen. Dyack rationalized the slowdown {{as a consequence of}} the PlayStation's random-access memory constraints on <b>video</b> <b>data.</b> Baldric noted in his review that the Windows port alleviated, but did not fully amend, the issue.|$|E
2500|$|A {{standard}} PAL signal contains 625 {{lines of}} <b>video</b> <b>data</b> per screen, broken into two [...] "fields" [...] containing half {{the lines of}} the whole image, divided as every odd line, then every even line number. Lines {{near the top of the}} screen are used to synchronize the display to the signal, and are not seen on-screen. CEPT1 hides the data in these lines, where they are not visible, using lines 6–22 on the first field and 318–335 on the second field. The system does not have to use all of these lines; a unique pattern of bits allows the decoder to identify which lines contain data. Some teletext services use a great number of lines, others, for reasons of bandwidth and technical issues, use fewer.|$|E
2500|$|In September 2016, a Falcon 9 {{exploded}} {{during a}} propellant fill operation for a standard pre-launch static fire test. The payload, the Spacecom Amos-6 communications satellite valued at $200 million, was destroyed. Musk described the event as the [...] "most difficult and complex failure" [...] ever in SpaceX's history; SpaceX reviewed nearly 3,000 channels of telemetry and <b>video</b> <b>data</b> covering {{a period of}} 35–55 milliseconds for the postmortem. Musk reported the explosion {{was caused by the}} liquid oxygen that is used as propellant turning so cold that it solidified and it ignited with carbon composite helium vessels. The rocket explosion sent the company into a four-month launch hiatus while it worked out what went wrong, and SpaceX finally returned to flight in January 2017.|$|E
5000|$|<b>Video</b> and <b>data</b> files (such as digital pictures, or MP3 files) may {{be mixed}} {{on a single}} disc.|$|R
40|$|In this paper, a novel {{real-time}} <b>video</b> and <b>data</b> {{capture of}} vehicle accident is proposed in Intelligent Transportation System (ITS). The proposed scheme solves {{the problem of}} huge storage needed for recording vehicle accident in the smart vehicle and in the remote ITS server. It works efficiently with small amount of storage size and guarantee saving accident video in secondary storage. It enables user to capture real-time <b>video</b> and <b>data</b> of running vehicle. It enables user to get vehicle accident <b>video</b> and <b>data</b> anytime anywhere. The scheme is implemented using testbed and its performance is evaluated. The {{results show that the}} proposed scheme guarantees record the vehicle accident in the ITS server. The proposed scheme has better results in comparison with full time video recording scheme...|$|R
50|$|Horse Races Now {{was created}} to provide {{comprehensive}} horse racing <b>video</b> and <b>data</b> for new fans and veteran horseplayers.|$|R
