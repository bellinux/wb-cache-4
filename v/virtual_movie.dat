10|42|Public
2500|$|The {{film was}} {{released}} in Blu-ray, HD DVD, DVD 5.1, VCD Version From Anand Video Studio. It is the first Kannada film {{to be released in}} Blu-ray. The director, an advocate of alternative distribution strategies for indie filmmakers, was recently quoted as saying, [...] "It’s time to set up your own <b>virtual</b> <b>movie</b> theaters on the World Wide Web which will be open 24×7 across the globe." ...|$|E
5000|$|In {{an episode}} of Ghost in the Shell: Stand Alone Complex, a <b>virtual</b> <b>movie</b> theater lobby, filled with other Salinger esoterica, {{displays}} a poster for a feature titled [...] "May I have a Mayonnaise?".|$|E
5000|$|Finite-state {{machines}} These are reactive architectures used {{mostly for}} computer game agents, in particular for first-person shooters bots, or for <b>virtual</b> <b>movie</b> actors. Typically, the state-machines are hierarchical. For concrete game examples, see Halo 2 bots paper by Damian Isla (2005) or the Master's Thesis about Quake III bots by Jan Paul van Waveren (2001). For a movie example, see Softimage.|$|E
50|$|For {{the first}} time during the Transatlantyk Festival, the <b>virtual</b> reality <b>movies</b> was presented.|$|R
5000|$|<b>Virtual</b> 3D <b>Movie</b> Maker (V3DMM): (2004) An {{expansion}} {{management program}} allowing users to include their own customized expansions in their movies {{and allow them}} to be freely distributed.|$|R
50|$|Virtual {{goods are}} non-physical objects and money {{purchased}} {{for use in}} online communities or online games. Digital goods, on the other hand, may be a broader category including digital books, music, and <b>movies.</b> <b>Virtual</b> goods are intangible by definition.|$|R
5000|$|The {{film was}} {{released}} in Blu-ray, HD DVD, DVD 5.1, VCD Version From Anand Video Studio. It is the first Kannada film {{to be released in}} Blu-ray. The director, an advocate of alternative distribution strategies for indie filmmakers, was recently quoted as saying, [...] "It’s time to set up your own <b>virtual</b> <b>movie</b> theaters on the World Wide Web which will be open 24×7 across the globe." ...|$|E
50|$|The third {{episode of}} the Bold As Love Sequence opens on a cold beach in Mexico, where Ax and Sage are hesitantly renegotiating their relationship, while Fiorinda struggles {{on the brink of}} {{schizophrenic}} fugue. The rockstars, scarred by outrageous fortune, have dropped out, joined the masses, abandoned the centre stage: hoping to find peace. Their Avalon is invaded by Harry Lopez, the boy-wonder producer who wants to make a <b>virtual</b> <b>movie</b> about Ax Preston; who brings a summons from the US President. The secret behind the assassination of Rufus O’Niall is out. The Pentagon is openly embarked on developing the new human superweapon: but President Fred Eiffrich, who wants to stop the Neurobomb, believes the hawks are speeding the process by shocking, and extremely dangerous, means. He needs advice. With indecent haste the three decide that what they really need is the hair of the dog that bit them. Soon they are heading north to tackle the demons of the Republic of California, in an adventure where the West Coast music scene will be ignored, while Hollywood — the virtual movies, the stars, the agents, the players — takes the role that rock and roll played in England.|$|E
40|$|Machinima is the {{technique}} of using real-time 3 D technologies such as computer games or virtual worlds {{in the creation of}} animated video productions. The Second Life virtual world provides an open landscape where inexpensive <b>virtual</b> <b>movie</b> sets, props, costumes, and characters may be created to meet specialized educational purposes. Interactive video techniques used to create online video simulations, virtual tours, adventure games, or interactive tutorials can be coupled with machinima to create interactive educational machinima products. YouTube supports this technique by providing both video hosting and the Annotations tool, which enables linking from video to video. Usage and demographic data may be collected on YouTube automatically to identify patterns of use. This paper illustrates the process of interactive educational machinima design and prototype development using a combination of Second Life and YouTube technologies. Usage data from YouTube is presented and its potential value for evaluation of interactive educational video design is discussed. Initial conclusions suggest directions for future research in interactive educational machinima...|$|E
30|$|The {{three-dimensional}} {{movies are}} popular among today’s generation. Following {{the success of}} the blockbuster movie Avatar, interest in 3 D movies has increased significantly, leading to the production of more 3 D movies. 3 D televisions, 3 D broadcasting and 3 D Blu-ray movies also hit the market. More recently, virtual reality becomes a popular trend for consumers who want even more immersive 3 D experiences. A few months ago Paramount Pictures launches the first <b>virtual</b> reality <b>movie</b> theater.|$|R
40|$|Substantial {{evidence}} from social and cognitive psychology suggests that lot of behaviours {{are driven by}} processes operating outside of awareness. Many implicit or indirect measures to capture such processes have been proposed. Thus, the literature of risk perception shows {{the role of the}} heuristic thinking in the individual evaluation of the risky situations. The aim of the ALBO Project is verify, both theoretically and experimentally, if the traditional instruments for assessing work-related stress (questionnaires, check-lists and interviews) are inappropriate to detect the individual perception of psycho-social risk factors in work environments. It is also claimed that virtual reality simulations permits a better assessment of the potential factors of stress in workplaces. Game simulations based on the techniques of virtual reality are potent tools to provide a substantial improvement in {{the quality and quantity of}} information and awareness on the safety and psycho-social risks existing inside organizations. Also, the virtual reality exposure (<b>virtual</b> <b>movies)</b> can facilitate the objectivity in judgment of audience. The final product called Adventure Game, was submitted in three pilot firms to test it. The result of the first step of the project is the demo version including scenarios of virtual work environments. The final product will be used for assessing job stress and for designing training experiences in workplaces on online platforms...|$|R
30|$|We {{present a}} 360 ∘ (i.e., 4 π steradian) general-relativistic {{ray-tracing}} and radiative transfer calculations of accreting supermassive black holes. We perform state-of-the-art three-dimensional general-relativistic magnetohydrodynamical simulations using the BHAC code, subsequently post-processing this data with the radiative transfer code RAPTOR. All relativistic and general-relativistic effects, such as Doppler boosting and gravitational redshift, {{as well as}} geometrical effects due to the local gravitational field and the observer’s changing position and state of motion, are therefore calculated self-consistently. Synthetic images at four astronomically-relevant observing frequencies are generated {{from the perspective of}} an observer with a full 360 ∘ view inside the accretion flow, who is advected with the flow as it evolves. As an example we calculated images based on recent best-fit models of observations of Sagittarius A*. These images are combined to generate a complete 360 ∘ <b>Virtual</b> Reality <b>movie</b> of the surrounding environment of the black hole and its event horizon. Our approach also enables the calculation of the local luminosity received at a given fluid element in the accretion flow, providing important applications in, e.g., radiation feedback calculations onto black hole accretion flows. In addition to scientific applications, the 360 ∘ <b>Virtual</b> Reality <b>movies</b> we present also represent a new medium through which to interactively communicate black hole physics to a wider audience, serving as a powerful educational tool.|$|R
40|$|High-resolution video {{playback}} (> 1 megapixel) {{has become}} a commodity in homes (Blu-Ray players, internet streaming) and movie theaters (digital HD technology). Immersive virtual reality systems can display {{tens of millions of}} pixels today, for instance CAVE-like environments driven by 4 k projectors. However, when video is displayed in virtual environments (VEs), where the video screen is part of the virtual world, the resolution of the video is fairly low, and so is its frame rate, typically much lower than stan-dard TV. Allowing high-resolution video playback in VEs can add more realism to the virtual world (e. g., a <b>virtual</b> <b>movie</b> theater), and it can enable a new class of applications which were not possible before (e. g., virtual video surveillance centers). In this paper, we propose an algorithm based on mipmapped video frames, where each image of the video stream is stored at multiple levels of resolutions, to interactively play high-resolution video in VEs. In addition, we propose an approach to maintain a constant video playback rate, as well as optimizations for the algo-rithm, such as a memory management mechanism and predictive prefetching of data. Finally, we analyze the playback of three dif-ferent types of high-resolution video clips in an immersive VE...|$|E
40|$|The {{computer-aided}} design (CAD) of various products, machines and details, <b>virtual</b> <b>movie</b> heroes and video game characters {{is a computer}} science area with significant practical implications and challenging open scientific problems. One of these open problems is the automatic generation of 3 D geometric designs of existing physical objects, a process widely known as reverse engineering. The manual reverse engineering of a geometric design typically incurs costs comparable to engineering a completely new design from scratch. Therefore, the CAD industry is very interested in algorithmic solutions which generate such designs automatically or with a minimal user guidance. In this thesis we describe a set of techniques which combined deliver a solution for reverse engineering physical objects, which surface geometry is represented by dense triangle meshes. We contribute several novel algorithms and new research results in the following geometry processing areas: polygonal mesh simplification, anisotropic and quad-dominant remeshing, scattered data approximation, multiresolution mesh editing. The output of our system is a piecewise smooth Catmull-Clark subdivision surface representing the original object. Its control mesh provides the available degrees of freedom to manipulate and edit {{the shape of the}} represented object. Since our algorithms are designed to produce high quality control meshes, aligned to the structure and the features of the input shape, the output surface representation can be used in various mainstream computer graphics applications such as CAD systems, computer-simulated physical processes and animations (movies and games) ...|$|E
40|$|International audienceA large {{range of}} {{computer}} graphics {{applications such as}} data visualization or <b>virtual</b> <b>movie</b> production require users to position and move viewpoints in 3 D scenes to effectively convey visual information or tell stories. The desired viewpoints and camera paths are required to satisfy a number of visual properties (e. g. size, vantage angle, visibility, and on-screen position of targets). Yet, existing camera manipulation tools only provide limited interaction methods and automated techniques remain computationally expensive. In this work, we introduce the Toric space, a novel and compact representation for intuitive and efficient virtual camera control. We first show how visual properties are expressed in this Toric space and propose an efficient interval-based search technique for automated viewpoint computation. We then derive a novel screen-space manipulation technique that provides intuitive and real-time control of visual properties. Finally, we propose an effective viewpoint interpolation technique which ensures the continuity of visual properties along the generated paths. The proposed approach (i) performs better than existing automated viewpoint computation techniques in terms of speed and precision, (ii) provides a screen-space manipulation tool that is more efficient than classical manipulators {{and easier to use}} for beginners, and (iii) enables the creation of complex camera motions such as long takes {{in a very short time}} and in a controllable way. As a result, the approach should quickly find its place in a number of applications that require interactive or automated camera control such as 3 D modelers, navigation tools or 3 D games...|$|E
40|$|This {{web site}} {{contains}} {{a gallery of}} 3 D geologic maps which were created by draping color geologic maps over digital topography. The site features QuickTime <b>Virtual</b> Reality <b>movies</b> that allow the user to spin the 3 D geologic map to view it from different perspectives. 3 D JPEG images of the maps are available for those users with slower Internet connections. Most 3 D maps also have an accompanying topographic contour map so that instructors can develop exercises where students map contacts and faults onto the contour map, using the 3 D geologic maps as a guide. Educational levels: Graduate or professional, High school, Undergraduate lower division, Undergraduate upper division...|$|R
5000|$|Digital {{photography}} of {{the late}} twentieth century greatly simplified this assembly process, which is now known as image stitching. Such stitched images may even be fashioned into forms of <b>virtual</b> reality <b>movies,</b> using technologies such as Apple Inc.'s QuickTime VR, Flash, Java, or even JavaScript. A rotating line camera such as the Panoscan allows the capture of high resolution panoramic images and eliminates the need for image stitching, but immersive [...] "spherical" [...] panorama movies (that incorporate a full 180° vertical viewing angle as well as 360° around) must be made by stitching multiple images. Stitching images together can be used to create extremely high resolution gigapixel panoramic images.|$|R
2500|$|In the film, actors provide voiceovers for {{the main}} creatures. Director Barry Cook said the {{original}} plan was for the film to be without dialogue or narration. He said, [...] "I think originally, {{we were looking at}} a film that could stand alone as a <b>virtual</b> silent <b>movie...</b> You can turn the soundtrack off and still get involved with the story and feel the emotions of the characters. In its final version, the movie has a narration and goes inside the heads of the animals, so you can hear what they're thinking." [...] Executives at 20th Century Fox, one of the film's main distributors, viewed a rough cut and felt the film needed voiceovers so children in the audience could connect to the characters.|$|R
50|$|Other {{recurring}} themes {{relate to}} conspiracies, involving the Vatican and allegedly freemasonic societies such as P2. He discusses the controversial death of Roberto Calvi; {{who was known}} in some quarters of the press as ‘God’s Banker,’ because of his ties to the Vatican Bank. Elsewhere, a plethora of other topics are touched upon, including Aleister Crowleyean magick ritual, Wilson’s love of <b>movies,</b> <b>virtual</b> reality, Jungian Synchronicity, and the exponential growth of global information.|$|R
40|$|The KMODDL (Kinematic Models for Design Digital Library) is {{a digital}} library {{based on a}} {{historical}} collection of kinematic models made of steel and bronze. The digital library contains four types of learning modules including textual materials, QuickTime <b>Virtual</b> Reality <b>movies,</b> Java simulations, and stereolithographic files of the physical models. This paper reports an evaluation study on the uses of the KMODDL in two undergraduate classes. This research reveals that the users in different classes encountered different usability problems, and reported quantitatively different subjective experiences. Further, {{the results indicate that}} depending on the subject area, the two user groups preferred different types of learning modules, resulting in different uses of the available materials and different learning outcomes. These findings are discussed in terms of their implications for future digital library design. Pan...|$|R
40|$|While {{the timing}} of {{neuronal}} activity in the olfactory bulb (OB) relative to sniffing has been the object of many studies, the behavioral relevance of timing information generated by patterned activation within the bulbar response has not been explored. Here we show, using sniff-triggered, dynamic, 2 -D, optogenetic stimulation of mitral/tufted cells, that virtual odors that differ by as little as 13 ms are distinguishable by mice. Further, mice are capable of discriminating a <b>virtual</b> odor <b>movie</b> based on an optically imaged OB odor response versus the same virtual odor devoid of temporal dynamics-independently of the sniff-phase. Together with studies showing the behavioral relevance of graded glomerular responses and the response timing relative to odor sampling, these results imply that the mammalian olfactory system is capable of very high transient information transmission rates...|$|R
50|$|His latest {{business}} {{interest is}} another publicly-listed company in Hong Kong, Digital Domain, which {{is behind the}} stunning visual effects of some 250 motion pictures, including blockbusters such as Titanic, the Transformer series, the Curious Case of Benjamin Button, Iron Man 3 and Furious 7. It specializes in producing <b>virtual</b> reality (VR) <b>movie</b> sets. Its innovative products are also adopted in computer games, city planning and interior design which employed a few hundreds of employees in Vancouver.|$|R
40|$|Large-scale crowd {{simulation}} {{is important}} in computer games, <b>movies,</b> <b>virtual</b> training, and education applications. One popular approach, agent-based crowd simulation, considers the properties of each individual (agent) separately at every time step, enabling a highly realistic simulation of path navigation, cognitive reaction, collision avoidance, and animation control. Crowd simulation models Agent-based crowd simulation typically focus on navigational systems work according to a pathfinding and local collision three-layer hierarchy. The high-avoidance; little research est layer provides the navigatio...|$|R
40|$|Artificial {{intelligence}} is frequently {{used to control}} <b>virtual</b> characters in <b>movies</b> and games. When these characters appear in crowds, controlling them is called crowd simulation. In this paper, I suggest that crowd simulation could be accomplished by multi-agent reinforcement learning, a method by which groups of agents can learn to act autonomously in their environment. I present a case study that explores the challenges and benefits {{of this type of}} approach and encourages the development of learning techniques for AI in entertainment media...|$|R
50|$|James {{has been}} {{involved}} in 26 movies in writer and/or producing roles. His 1993 novel Host was adapted into the 1998 television <b>movie</b> <b>Virtual</b> Obsession. Other films on which he is credited include: Children Shouldn't Play with Dead Things, The Neptune Factor, Blue Blood, Malachi's Cove, The Blockhouse starring Peter Sellers, Spanish Fly starring Terry-Thomas and Leslie Phillips, A Different Loyalty starring Sharon Stone, The Bridge of San Luis Rey starring Robert De Niro, and The Statement starring Michael Caine.|$|R
40|$|Endocytosis, {{like many}} dynamic {{cellular}} processes, requires precise {{temporal and spatial}} orchestration of complex protein machinery to mediate membrane budding. To understand how this machinery works, we directly correlated fluorescence microscopy of key protein pairs with electron tomography. We systematically located 211 endocytic intermediates, assigned each to a specific time window in endocy-tosis, and reconstructed their ultrastructure in 3 D. The resulting <b>virtual</b> ultrastructural <b>movie</b> defines the protein-mediated membrane shape changes during endocytosis in budding yeast. It reveals that clathrin is recruited to flat membranes and does not initiate curvature. Instead, membrane invagination begins upon actin network assembly followed by amphiphy-sin binding to parallel membrane segments, which promotes elongation of the invagination into a tubule. Scission occurs on average 9 s after initial bending when invaginations are 100 nm deep, releasing nonspherical vesicles with 6, 400 nm 2 mean surface area. Direct correlationof proteindynamicswithultra-structure provides a quantitative 4 D resource...|$|R
50|$|AGX Multiphysics (now renamed to AGX Dynamics) is a {{proprietary}} real-time physics engine developed by Algoryx Simulation AB that simulates rigid body dynamics, collision detection, dry frictional contacts, jointed systems, motors, fluids, deformable materials, hydraulics, hydrodynamics, cable systems and wires. AGX targets several domains, such as virtual reality real-time simulator applications {{for training and}} marketing; computer aided engineering and <b>virtual</b> prototyping; <b>movie</b> visual effects; and education. For education, components of AGX {{are used in the}} end-user software product Algodoo also developed and sold by Algoryx. Users of AGX simulate e.g. granular systems, construction equipment, forestry machines, mining processes and machines, biomechanics, industrial robots, ship and anchor handling processes and cranes. AGX is often integrated with 3D visualization frameworks such as OpenSceneGraph and OGRE and often also with actual hardware and control systems of the real-world version of the simulator. AGX is integrated in many 3D modeling and CAD systems, including Dynamics for SpaceClaim.|$|R
40|$|Animated <b>movies</b> are {{excellent}} <b>virtual</b> environments for creating models in high quality. Animated movies can include 3 D models, sounds and lights effects, and detailed maps. In this paper, a <b>virtual</b> reality <b>movie</b> {{is applied to}} Al-Haram Expansion stages including the future stage of expansion. 3 DMAX program is used to rich the maximum benefits of using 3 D modeling. Maps with details are built by using ARCGIS program {{in order to understand}} the real difference between the three different expansions stages clearly and effectively. A novel technique is presented in order to insert 2 D maps and other details in the 3 D model built by 3 DMAX. The animated movie includes introduction, three basic expansion stages, maps, and conclusion. It is in Arabic with translation to English and sign language is also included. Accurate and documented information is applied in AL-Haram expansion movie that helps people to know about one of the most radical expansions that is occurred in the world. ...|$|R
40|$|SummaryEndocytosis, {{like many}} dynamic {{cellular}} processes, requires precise {{temporal and spatial}} orchestration of complex protein machinery to mediate membrane budding. To understand how this machinery works, we directly correlated fluorescence microscopy of key protein pairs with electron tomography. We systematically located 211 endocytic intermediates, assigned each to a specific time window in endocytosis, and reconstructed their ultrastructure in 3 D. The resulting <b>virtual</b> ultrastructural <b>movie</b> defines the protein-mediated membrane shape changes during endocytosis in budding yeast. It reveals that clathrin is recruited to flat membranes and does not initiate curvature. Instead, membrane invagination begins upon actin network assembly followed by amphiphysin binding to parallel membrane segments, which promotes elongation of the invagination into a tubule. Scission occurs on average 9  s after initial bending when invaginations are ∼ 100  nm deep, releasing nonspherical vesicles with 6, 400  nm 2 mean surface area. Direct correlation of protein dynamics with ultrastructure provides a quantitative 4 D resource...|$|R
40|$|Realistic {{humanoid}} 3 D character {{movement is}} very important to apply in the computer games, <b>movies,</b> <b>virtual</b> reality and mixed reality environment. This paper presents a technique to deform motion style using Motion Capture (MoCap) data based on computer animation system. By using MoCap data, natural human action style could be deforming. However, the structure hierarchy of humanoid in MoCap Data is very complex. This method allows humanoid character to respond naturally based on user motion input. Unlike existing 3 D humanoid character motion editor, our method produces realistic final result and simulates new dynamic humanoid motion style based on simple user interface control...|$|R
5000|$|... "Fly Life" [...] later {{made its}} {{appearances}} on various DJ mixes, including: the free mix cassette Beat Up the NME (1997), from music magazine NME, which was compiled by British DJ Fatboy Slim; Junior Vasquez's live album Live, Vol. 2 (1998); later on Victor Calderone's mix album called E=VC² (1999); {{and on the}} mix album Soul of Man Presents: Y4K: Breakin' in tha House (2004). In 2009, [...] "Fly Life Xtra" [...] appeared on Paul Ritch's DJ set for BBC Radio 1 radio show Essential Mix. The [...] "Brix" [...] mix also made its appearances on the 1999 coming-of-age <b>movie</b> <b>Virtual</b> Sexuality and its soundtrack.|$|R
40|$|Motions of <b>virtual</b> {{characters}} in <b>movies</b> or video games are typically generated by recording actors using motion capturing methods. Animations generated this way often need postprocessing, such as improving the periodicity of cyclic animations or generating entirely new motions by interpolation of existing ones. Furthermore, search and classification of recorded motions {{becomes more and}} more important as the amount of recorded motion data grows. In this paper, we will apply methods from shape analysis to the processing of animations. More precisely, we will use the by now classical elastic metric model used in shape matching, and extend it by incorporating additional inexact feature point information, which leads to an improved temporal alignment of different animations...|$|R
40|$|Three-dimensional (3 D) {{ultrasound}} volume acquisition, {{analysis and}} display of fetal structures have enhanced their visualization and greatly improved the general {{understanding of their}} anatomy and pathology. The dynamic display of volume data generally depends on proprietary software, usually supplied with the ultrasound system, and on the operator's ability to maneuver the dataset digitally. We have used relatively simple tools and an established storage, display and manipulation format to generate non-linear <b>virtual</b> reality object <b>movies</b> of prenatal images (including moving sequences and 3 D-rendered views) that can be navigated easily and interactively on any current computer. This approach permits a viewing or learning experience that is superior to watching a linear movie passively...|$|R
50|$|In rare {{occasional}} cases, a few troubled major studios {{would also}} shed their distribution and/or marketing staffs, mainly due to reduced resources, and resort to co-investing and/or co-distributing film projects with larger studios, operating as <b>virtual,</b> production-only <b>movie</b> studios. Notable examples include legendary studio Metro-Goldwyn-Mayer, which, {{after many years}} of box office flops (mostly with low budgets), bad management and distribution, and bankruptcy, was restructured at the end of 2010 under new management and currently struck deals with some of the Big Six studios (most notably the Sony Pictures Motion Picture Group and Warner Bros.); Miramax, which was downsized by former owner Disney into a smaller division after the Weinstein brothers' 2005 divestment and, after 17 years under Disney ownership, was sold to a group of investors at the end of 2010 who eventually struck deals to co-finance the studio's projects with other independent companies; and DreamWorks Pictures, the independently-run live action studio, which currently releases many projects through Universal Pictures and formerly released their projects through Disney after spinning off from Paramount Pictures (which purchased the studio in 2006 and stripped it of its independent distributor status) in 2008.|$|R
40|$|The use of {{technology}} in legal education is a rapidly evolving area but incorporating digital content into existing teaching resources can often appear daunting and resource-intensive. Those willing to experiment with new technologies have achieved significant success in embedding such technologies into existing subjects (Butler; DA, 2009 and Butler; DA, 2011). In many cases, the focus of such projects has been on providing a virtual legal environment for students {{through the use of}} Second Life or similar virtual reality platforms. This paper will focus on the use of different software, which provides an environment in which those who would not usually engage with virtual worlds can build a movie set, characters and on-screen action with a view to creating a <b>virtual</b> reality <b>movie</b> designed to address the specific needs of the particular subject. This technology has been employed to create a series of movies set in a virtual law firm, which were embedded into the content of a compulsory first year legal skills subject with the aim of enhancing student engagement and assisting with the development of students' legal writing and statutory interpretation skills. An initial pilot study of student response to the use of this new media will also be discussed...|$|R
40|$|This paper {{describes}} a TV program generation system using digest video scenes that are retrieved from video streams {{with the program}} indexes. The key features of the system are: (1) TV programs can be dynamically generated from digest video scenes selected by user preference. (2) Directions can be added using a happiness or sadness level based on the user preferences. (3) Personalized TV programs for an individual viewer can be made. The procedures taken by the system are as follows: (1) Conjunctive expressions between scenes are automatically generated, (2) Emotional expressions are automatically generated by user preference, (3) TV program metaphors are defined, (4) Direction templates corresponding to the metaphors are defined (5) These expressions and definitions are coded using a markup language, and (6) Contents such as <b>virtual</b> characters and <b>movies</b> are synchronized. The resultant program can be shown on a TV set...|$|R
