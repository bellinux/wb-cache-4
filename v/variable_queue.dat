4|50|Public
40|$|Capacity drop {{indicates}} that the queue discharge rate {{is lower than the}} road capacity. Due to the capacity drop, traffic delays increase once queues form. Researchers find that queue discharge rates vary in different traffic conditions. Empirical data shows that the queue discharge rate increases as the speed in congestion increases. Understanding what and how driver behaviors result in such <b>variable</b> <b>queue</b> discharge rates can help minimize traffic delays and eliminate congestion. However, as far as authors know, few efforts have been devoted to testing impacts of traffic behaviors on the <b>variable</b> <b>queue</b> discharge rate. This paper tries to fill in the gap. The authors investigate to what extent acceleration variety and reaction time can influence the queue discharge rate. It is found that the acceleration variety cannot reduce the queue discharge rate considerably. Modelling reaction time might be more important than modeling acceleration when giving capacity drop in car-following models. A multi-phase reaction time mechanism for giving <b>variable</b> <b>queue</b> discharge rates is proposed. That is, decreasing reaction time as the speed in congestion increases can give the same <b>variable</b> <b>queue</b> discharge rate as empirical observations. The research might indicate that motivating drivers to speed up earlier could benefit increasing queue discharge rates and minimizing delays. Transport and Plannin...|$|E
40|$|The {{capacity}} drop {{indicates that}} the queue discharge rate {{is lower than the}} free-flow capacity. Studies show that queue discharge rates vary under different traffic conditions. Empirical data show that the queue discharge rate increases as the speed in congestion increases. Insights into the underlying behavioral mechanisms that result in such <b>variable</b> <b>queue</b> discharge rates can help minimize traffic delays and eliminate congestion. However, to the best of the authors’ knowledge, few efforts have been devoted to testing impacts of traffic behaviors on the queue discharge rate. This paper tries to fill this gap. We investigate to what extent the acceleration spread and reaction time can influence the queue discharge rate. It is found that the (inter-driver) acceleration spread does not reduce the queue discharge rates as much as found empirically. Modelling reaction time might be more important than modeling acceleration for capacity drop in car-following models. A speed-dependent reaction time mechanism for giving <b>variable</b> <b>queue</b> discharge rates is proposed. That is, decreasing reaction time as the speed in congestion increases can give the same queue discharge rate as found empirically. This research suggests that motivating drivers to speed up earlier could increase the queue discharge rate and thereby minimize delays. Transport and Plannin...|$|E
40|$|Model of {{priority}} service of aerodrome operations is analyzed. The {{assumption of the}} legality of replacing the ran- dom <b>variable</b> <b>queue</b> length at its most probable value is used. The model is characterized in that the take-off and landing are described not by means of only safety priorities, but by technical and flight characteristics as well. Evaluations of the ser- vice waiting time of service and the probability of failure (or re-service) were obtained. ICAO experts have put forward the concept of "System Wide Information Management" and "Collaborative Air Traffic Management", which require for their introduction of new instruments operational management decision making for air traffic services. It should provide participants with the joint organization of new software for rapid analysis of computer results. One of the possible directions of such support is discussed in this article. Analysis of the two priority model shows that the efficiency {{of priority}} service is reduced {{in the case of}} a large spread of values of average request processing time. As a result of the loss probability for both types of requests become comparable or even approximately equal. Experiment with the five priority flows confirms the order of request losses in accordance with an increase of flow index, identified by formulas for an arbitrary number of input streams. The tendency of the values for the partial converging efficiency criterion of service can only be observed in non-real case where the values of the average service time varies several hundred times. Moreover, this effect can easily be compensated by a slight increase in volume of storage buffer. It becomes obvious that the best conditions for the maintenance of the flow of requests are provided {{in the case of a}}pproxi- mate equality of the average processing times; that is, when all the coefficients of the sequence tend to a single value. The obtained formulas have a sufficient degree of generality and can be used to analyze the priority system in a wide range of data acquisition and processing tasks...|$|E
50|$|Only one {{process can}} execute {{within a given}} monitor {{instance}} at a time. A built in data type, the queue, together with operations delay and continue, are used for scheduling within monitors. Each <b>variable</b> of type <b>queue</b> can hold a single process; if many processes are to be delayed in a monitor, multiple <b>queue</b> <b>variables,</b> usually organized as an array, must be provided. The single process <b>queue</b> <b>variable</b> gives a monitor complete control over medium-term scheduling, but the programmer is responsible for unblocking the correct process.|$|R
40|$|Abstract. The paper {{addresses}} the state estimation in the factorized form. The target application {{area is the}} urban traffic control, where the main controlled <b>variables</b> (<b>queues)</b> are not directly observable {{and have to be}} estimated. Additional problem is that some state variables are of a discrete-valued nature. Thus, estimation of mixed-type data (continuous and discrete valued) models is highly desirable. Factorized state estimation is a potential solution of this problem. The underlying methodology is Bayesian filtering. Factorized version of the filter is obtained by applying the chain rule to the state-space model. The general solution represents the recursive entry-wise performance of data updating and time updating steps. Application of the solution to linear Gaussian state-space models gives the factorized Kalman filter. ...|$|R
40|$|Recent {{years have}} {{witnessed}} an {{increased interest in}} Precision Time Protocol (PTP) in telecommunication networks, either {{as an alternative to}} Global Positioning System (GPS) or as synchronization back-up. To achieve node synchronization at the μs-level, very accurate measurements of time offsets are needed. However, unless PTP is fully supported throughout the network, timing packets may be subjected to propagation delays whose variability can significantly impair measurement. In the PTP telecommunication profile Sync packets can be broadcast at high rate, providing a slave node with statistical information that can be employed to detect and estimate such network effects. The accuracy of these estimates is analyzed in the paper, which considers the assumed underlying probability models and discusses statistical aspects for PTP packets affected by <b>variable</b> <b>queuing</b> delays. Characteristics of packet selection algorithms in ITU-T Recommendations are analyzed, providing indications on performance...|$|R
40|$|High {{performance}} grid computing {{is a key}} enabler {{of large}} scale collaborative computational science. With the promise of exascale computing, high performance grid systems are expected to incur electricity bills that grow super-linearly over time. In order to achieve cost effectiveness in these systems, {{it is essential for}} the scheduling algorithms to exploit electricity price variations, both in space and time, that are prevalent in the dynamic electricity price markets. Typically, a job submission in the batch queues used in these systems incurs a <b>variable</b> <b>queue</b> waiting time before the resources necessary for its execution become available. In variably-priced electricity markets, the electricity prices ﬂuctuate over discrete intervals of time. Hence, the electricity prices incurred during a job execution will depend on the start and end time of the job. Our thesis consists of two parts. In the first part, we develop a method to predict the start and end time of a job at each system in the grid. In batch queue systems, similar jobs which arrive during similar system queue and processor states, experience similar queue waiting times. We have developed an adaptive algorithm for the prediction of queue waiting times on a parallel system based on spatial clustering of the history of job submissions at the system. We represent each job as a point in a feature space using the job characteristics, queue state and the state of the compute nodes at the time of job submission. For each incoming job, we use an adaptive distance function, which assigns a real valued distance to each history job submission based on its similarity to the incoming job. Using a spatial clustering algorithm and a simple empirical characterization of the system states, we identify an appropriate prediction model for the job from among standard deviation minimization method, ridge regression and k-weighted average. We have evaluated our adaptive prediction framework using historical production workload traces of many supercomputer systems with varying system and job characteristics, including two Top 500 systems. Across workloads, our predictions result in up to 22 % reduction in the average absolute error and up to 56 % reduction in the percentage prediction errors over existing techniques. To predict the execution time of a job, we use a simple model based on the estimate of job runtime provided by the user at the time of job submission. In {{the second part of the}} thesis, we have developed a metascheduling algorithm that schedules jobs to the individual batch systems of a grid, to reduce both the electricity prices for the systems and response times for the users. We formulate the metascheduling problem as a Minimum Cost Maximum Flow problem and leverage execution period and electricity price predictions to accurately estimate the cost of job execution at a system. The network simplex algorithm is used to minimize the response time and electricity cost of job execution using an appropriate ﬂow network. Using trace based simulation with real and synthetic workload traces, and real electricity price data sets, we demonstrate our approach on two currently operational grids, XSEDE and NorduGrid. Our experimental setup collectively constitute more than 433 K processors spread across 58 compute systems in 17 geographically distributed locations. Experiments show that our approach simultaneously optimizes the total electricity cost and the average response time of the grid, without being unfair to users of the local batch systems. Considering that currently operational HPC systems budget millions of dollars for annual operational costs, our approach which can save $ 167 K in annual electricity bills, compared to a baseline strategy, for one of the grids in our test suite with over 76000 cores, is very relevant for reducing grid operational costs in the coming years...|$|E
40|$|This short {{communication}} {{considers the}} workload process of a queue operating in slotted time, {{focusing on the}} (multivariate) distribution of the workloads {{at different points in}} time. In a many-sources framework exact asymptotics are determined, relying on large-deviations results for the sample means of multivariate random <b>variables.</b> Keywords: <b>Queueing</b> theory; Tail asymptotics; Large deviation...|$|R
40|$|This article {{attempts}} to disentangle {{the effects of}} race and gender by examining what happens to Black, White, and Hispanic men and women as they reenter the job market after displacement from their previous jobs. The authors use data from the 1996 Displaced Worker Survey (a supple-ment to the February 1996 Current Population Survey) and focus on postdisplacement employ-ment and earnings as the main dependent <b>variables.</b> <b>Queuing</b> theory is used to help understand the powerful ranking and sorting processes in a race- and gender-conscious job market. The authors find the distribution of displacement costs unequal. White men appear to head the post-displacement queue. White women experience a gender disadvantage. Black men lose {{as a result of}} their race and do not benefit from gender in most cases. Black women generally experience the double burden of race and gender. Hispanic men do appear to generally benefit from gender, but Hispanic women lose...|$|R
5000|$|Storage is not {{necessarily}} a problem as all threads spin on one <b>variable,</b> unlike array-based <b>queueing</b> locks (ABQL) who have threads spin on individual elements of an array.|$|R
40|$|We {{consider}} the standard Lindley recursion for integer-valued random variables. A new method {{for determining the}} corresponding distributions is presented which in the case when the involved random variables are bounded from below, say by -K, K [epsilon] K, reduces to the solution of a (K x K) -system of linear equations. The stationary distribution is also obtained by this approach. Lindley recursion Integer-valued random <b>variables</b> Discrete-time <b>queue...</b>|$|R
40|$|In this paper, {{we study}} a {{geometric}} process model for M/M/ 1 queueing {{system with a}} repairable service station. By introducing a supplementary <b>variable,</b> some <b>queueing</b> characteristics {{of the system and}} reliability indices of the service station are derived. Then a replacement policy N for the service station by which the service station will be replaced following the Nth failure is applied. An optimal replacement policy N∗ for minimizing the long-run average cost per unit time for the service station is then determined...|$|R
40|$|A {{concurrent}} system {{consists of}} processes communicating via shared objects, such as shared <b>variables,</b> <b>queues,</b> etc. The concept of wait. freedom {{was introduced to}} cope with proce 3 J failures: each process that accesses a wait-free object is guaranteed to get a response even if all the other processes crash. But what if these wait-free objects themselves fail? For example, if a wait-free object &quot;crashes&quot;, all the processes that access that object are prevented from making progress. In this paper, we introduce the concept of fault. tolerant wait-flee objects, and study the problem of implementing them. We give a universal method to construct fault-tolerant waR-free objects, {{for all types of}} &quot;responsive &quot; failures (including one in which faulty objects may &quot;lie&quot;). In sharp con-trast, we prove that many common and interesting object types (such as queues, sets, and test&set) have no fault-tolerant wait-free implementations even under the most benign of the &quot;non-responsive &quot; types of failure. We also introduce several concepts and techniques that are central to the design of fault-tolerant concurrent systems: the con-cepts of self-implementation and graceful degradation, and techniques to automatically increase the fault-tolerance of implementations. We prove matching lower bounds on the resource complexity of most of our algorithms...|$|R
40|$|Queue {{computers}} are {{a viable option}} for embedded systems design. Queue computers feature a dense instruction set, high parallelism, low hardware complexity. In this paper we propose an optimization technique to reduce the overhead of long reaching definitions of <b>variables</b> in <b>queue</b> processors. Long reaching definitions have direct relationship with the queue register file utilization of the processor, and also to the bits in the instruction set reserved to reference operands. Using integer and embedded benchmarks, we demonstrate that our technique effectively reduces the length of reaching definitions up to 90 %. 1...|$|R
40|$|Abstract—We {{present a}} novel optical packet {{switching}} fabric ar-chitecture incorporating both input single-stage and output mul-tistage all-optical variable delay buffers as combined {{input and output}} queues. For a given optical buffer size (1000 B), the pro-posed architecture, which has combined input and output optical <b>variable</b> buffer <b>queues</b> with optimum partition, achieves packet loss rates (3. 4 E- 5) that are three orders of magnitude lower than the case without the variable buffers and two orders of magnitude lower than the cases with input or output optical queues alone. Index Terms—All-optical packet switching (OPS), all-optical variable buffer, optical router, slow light, switching fabric archi-tecture. I...|$|R
40|$|The {{determination}} of traffic factors impact on incident duration {{is critical for}} the creation of effective incident and traffic management systems. The present thesis focuses on the estimation of factors that influence the accident duration. The influence of traffic factors is examined with two applications of Cox’s proportional hazards model. Each application varies with the stratified <b>variable,</b> maximum <b>queue</b> length and queue duration. Among the results revealed, {{it has been shown that}} the interaction among accident duration and traffic factors is significant to the estimation of accident duration. Moreover, queues seem to have a great impact on accident duration. Μυρτώ Δ. Μαδούρου 89 σ...|$|R
40|$|International audienceThe {{emergence}} of hardware virtualization, notably exploited by cloud infrastructures, {{led to a}} paradigm shift in distributed computing by enabling complete software customization and elastic scaling of resources. However, new software architectures and deployment algorithms are still required to fully exploit virtualization in web platforms used for scientific computing, commonly called science gateways. We propose a software architecture and an algorithm to enable and optimize the deployment of virtual machines on clusters and clouds in science gateways. Our architecture is based on 3 design principles: (i) separation between resource provisioning and task scheduling (ii) encapsulation of VMs in regular computing tasks (iii) association of a virtual computing site to each disk image. Our algorithm submits and removes VMs on clusters and clouds based on the current system workload, the number of available job slots in active VMs, the cost and current performance of clouds clusters, and a parameter quantifying the performance-cost trade-off. To cope with <b>variable</b> <b>queuing</b> and booting times, it replicates VMs on independent computing sites selected from a minimization of a make span-cost linear combination in the Pareto set of non-dominated solutions. Make span and cost are estimated from the last measured queuing, booting, and task execution times, using an exponential model of the gain yielded by VM replication. We implement this algorithm in CBRAIN, a science gateway widely used for neuroimaging, and we evaluate it on an infrastructure of 2 clusters and 1 cloud. Results show that {{it is able to}} reach some points of the performance-cost trade-off associated to VM deployment...|$|R
40|$|Abstract — This paper {{considers}} {{the issue of}} optimal sub-carrier allocation in OFDMA. We show, via a counter example, that water-filling based subcarrier allocation policies, contrary to conventional wisdom, fail to provide rate-stability for an otherwise stabilizable OFDMA system. Water-filling is too myopic when considering long-time average performance, e. g. delay, queue lengths, and even long-run throughput. This is because such policies ignore <b>variable</b> state (<b>queue</b> length) information, while, in fact, such an information is necessary to guarantee rate stability and/or to minimize average delay. In this paper, we identify an optimal non-idling policy which balances the queue lengths, when the channel follows an ON/OFF model. In such case, we show that such a policy achieves the minimum average holding cost (mean response time) at any time. I...|$|R
40|$|Abstract—In this note, {{we develop}} and prove a rule for an {{upper bound on}} the optimal number of {{carriers}} (with respect to throughput) in a threeworkstation closed serial production system with finite buffers, operating under production blocking (blocking-after-service). This system is, in fact, a three server (single server) closed tandem queueing system with finite buffers. Our assumptions regarding service time distributions are nonrestrictive and include the case of iid random <b>variables.</b> Index Terms—Closed <b>queueing</b> networks, discrete-event systems, manufacturing systems, performance comparison, queueing systems. I...|$|R
40|$|A {{dynamic model}} is {{formulated}} for determining optimum operating policies in a <b>variable</b> channel <b>queuing</b> situation. Such policies are required when workers must be allocated {{to one of}} several jobs which have associated with them different waiting costs. In this model, two such jobs are considered: (a) a "queue job" i. e., serving customers in a queue, and (b) performing another task which does not involve waiting customers (called "fixed work"). The criterion of the model is a minimization of the sum of these costs: the cost of customer waiting, the cost of fixed work, {{and the cost of}} changing tasks. Decision rules involving the assignment of workers depended upon the number of waiting customers, the anticipated arrival pattern, and the amount of uncompleted fixed work remaining. The model was run using arrival and service data obtained from a medium sized suburban bank together with implicitly derived cost data. ...|$|R
40|$|The use of {{simulation}} to re-engineer a {{call center}} of a large international corporation is described. Order management and processing at call centers {{are an integral part}} of many manufacturing systems. Those centers influence repeat business, total volume, and the patterns of orders that manufacturing must fill. Call centers themselves are complex production systems which are being automated as the format of orders evolves from mail, telephone and facsimile to Email and electronic data interchange. Demand on a call center is highly <b>variable</b> yet <b>queuing</b> is not acceptable because delays can lead to lost customers. BACKGROUND In wake of advancements in computer technology businesses are constantly reevaluating and redesigning their production systems. Furthermore, activities once thought to be of marginal importance are receiving attention. Call centers for serving commercial customers are increasingly being seen as a way to improve service and increase market share in an ever more co [...] ...|$|R
40|$|Abstract―The ReconOS {{operating}} system for reconfigurable computing offers a unified multi-threaded programming model and {{operating system}} services for threads executing in software and threads mapped to reconfigurable hardware. The operating system interface allows hardware threads {{to interact with}} software threads using well-known mechanisms such as semaphores, mutexes, condition <b>variables,</b> and message <b>queues.</b> By semantically integrating hardware accelerators into a standard operating system environment, ReconOS allows for rapid design space exploration, supports a structured application development process and improves the portability of applications between different reconfigurable computing systems. Keywords―operating system, reconfigurable computing, multi-threading...|$|R
40|$|A dynamic data {{structure}} called queue is analyzed {{in this paper}} {{from the viewpoint of}} its maximum sizc. By dynamic queue we understand any {{data structure}} that is built during a sequence of insertions and deletions. The maximum size of such a structure is a fundamental quantity and is directly related to many problems of resource allocations. We assume that each element of the structure (we call it further a customer) stays for a random time in the system and then leaves it Furthermore, the interanival time of customers is a generally distributed random <b>variable.</b> Adopt-ing <b>queueing</b> theory language, we say the data structure is GIlGle queueing systems, where c (may be infinite) is the maximum number of items that can simultaneously leave the system (number of servers). We shall show that for stable staJionary queue the maximum queue length observed by the n-th arriving customer grows asymptotically in probability as loga; n, where a is a system constant...|$|R
40|$|Exploiting Regularity {{has been}} {{the key to the}} success of many tech-niques for digital systems design. This paper {{presents}} a novel ap-proach for exploiting the regularity in memory access that exists in many DSP and matrix computations, {{in order to reduce the}} access delay of memory and to cut down hardware cost. In this approach, data (variables) that have regular access patterns are not stored in a random access memory element; instead they are kept floating in special storage structures called sequencers, thus avoiding the bot-tleneck of accessing random access memories and register files and saving the overhead of memory address generation and decoding. A theoretical foundation for modeling the allocation of two types of sequencers, namely queues and stacks, is established. In addition, algorithms are developed to map <b>variables</b> to <b>queues</b> and stacks and to integrate them into conventional high-level synthesis proce-dures. Experimental results show an encouraging improvement in the performance of designs as well as a significant reduction in hardware cost. ...|$|R
40|$|Introduction We {{consider}} discrete-time queueing processes fX n # n = 0 # 1 #:::g and fY n # n = 0 # 1 #:::g: X n+ 1 =(X n; 1) + +A n+ 1 # Y n+ 1 = min; (Y n; 1) + +A n+ 1 # N Δ # where (x) + = max(x# 0), N is {{a finite}} positive integer representing the buffer size, and fA n # n = 1 # 2 #:::g denotes {{a sequence of}} non-negative integer random 2 Ishizaki and Takine / Loss probability in a finite discrete-time <b>queue</b> <b>variables</b> representing th...|$|R
5000|$|The {{solution}} is to use condition variables. Conceptually a condition <b>variable</b> is a <b>queue</b> of threads, associated with a monitor, on which a thread may wait for some condition to become true. Thus each condition variable [...] is associated with an assertion [...] While a thread is waiting on a condition variable, that thread is not considered to occupy the monitor, and so other threads may enter the monitor to change the monitor's state. In most types of monitors, these other threads may signal the condition variable [...] to indicate that assertion [...] is true in the current state.|$|R
40|$|An MX/GI/ 1 /N finite {{capacity}} queue with close-down time, {{vacation time}} and exhaustive service discipline is considered under the partial batch acceptance strategy {{as well as}} under the whole batch acceptance strategy. Applying the supplementary <b>variable</b> technique the <b>queue</b> length distribution at an arbitrary instant and at a departure epoch is obtained under both strategies, where no assumption on the batch size distribution is made. The loss probabilities and the Laplace-Stieltjes transforms of the waiting time distribution of the first customer and of an arbitrary customer of a batch are also given. Numerical examples give {{some insight into the}} behavior of the system...|$|R
5000|$|The multiqueue (mq) {{policy has}} {{three sets of}} 16 queues, using the first set for entries waiting for the cache and the {{remaining}} two sets for entries already in the cache, with the latter separated so the clean and dirty entries belong {{to each of the}} two sets. The age of cache entries in the queues is based on their associated logical time. The selection of entries going into the cache (i.e., becoming promoted) is based on <b>variable</b> thresholds, and <b>queue</b> selection is based on the hit count of an entry. This policy aims to take different cache miss costs into account, and to make automatic adjustments to different load patterns.|$|R
40|$|We {{propose a}} novel {{dynamical}} {{model of a}} simple traffic intersection, where the state <b>variables</b> represent the <b>queue</b> lengths and the mean waiting times in the queues. Including the mean waiting times in the model allows for a more fair traffic control, where the waiting times of the individual vehicles in the various streets of the intersection {{are taken into account}} to some degree. The model is linearized and its parameters are estimated using real traffic data measured during one day in Prague. For the balancing of the waiting times, two different controllers are considered: a linear quadratic regulator and a nonlinear model predictive controller. The controllers are evaluated in simulations where real traffic data is used for the incoming flows...|$|R
40|$|International audienceThe {{intrinsic}} {{complexity of}} most protocol specifications in particular, and of asynchronous systems in general, {{lead us to}} study combinations of static analysis with classical model-checking techniques {{as a way to}} enhance the performances of automated validation tools. The goal {{of this paper is to}} point out that an equivalence on our model derived from the information on live variables is stronger than the strong bisimulation. This equivalence, further called live bisimulation, exploits the unused dead values stored either in <b>variables</b> or in <b>queue</b> contents and allow to simplify the state space with a rather important factor. Furthermore, this reduction comes almost for free and is always possible to directly generate the quotient model without generating the initial one...|$|R
40|$|Abstract: We {{propose a}} novel {{dynamical}} {{model of a}} simple traffic intersection, where the state <b>variables</b> represent the <b>queue</b> lengths and the mean waiting times in the queues. Including the mean waiting times in the model allows for a more fair traffic control, where the waiting times of the individual vehicles in the various streets of the intersection {{are taken into account}} to some degree. The model is linearized and its parameters are estimated using real traffic data measured during one day in Prague. For the balancing of the waiting times, two different controllers are considered: a linear quadratic regulator and a nonlinear model predictive controller. The controllers are evaluated in simulations where real traffic data is used for the incoming flows. Copyright c ○ 2006 IFA...|$|R
40|$|The {{main goal}} {{of this paper was}} to develop an {{integrated}} simulation-design of experiments (DOE) model to optimize a petrol station queuing system and sales rate. Initially, the petrol station operating system was simulated using Witness 2014 simulation software©. Then, the responses of simulation were deployed as the input of DOE. Two-level full factorial experiments with center points were performed where the simulated model parameter studied were number of pump, number of cashier and inter arrival times (IATs). The response <b>variables</b> analyzed were <b>queue</b> length and sales rate. The obtained model from experimental design revealed that number of cashier and inter arrival time were significant in determining the queue length while all the factors and their interaction were significantly affecting the sales rate...|$|R
50|$|More recent methods {{use either}} {{discrete}} event simulation or continuous-time simulation. Discrete event simulation models are both stochastic (with random components) and dynamic (time is a <b>variable).</b> Single server <b>queues</b> for instance can be modeled very well using discrete event simulation, as servers are usually {{at a single}} location and so are discrete (e.g. traffic lights). Continuous time simulation, on the other hand, can solve the shortcoming of discrete event simulation where the model is required to have input, state and output trajectories within a time interval. The method {{requires the use of}} differential equations, specifically numerical integration methods. These equations can range from simple methods, such as Euler's method, to higher order Taylor's series methods, such as Heun's method and Runge-Kutta.|$|R
40|$|AbstractSimulation {{response}} optimization is {{an important}} problem often encountered in behaviorinvestigation of systems that are so complicated that the performance can only be evaluated by using simulation. This paper modifies the alternating variable method used in deterministic optimization to suit the stochastic environment in simulation response optimization. The main idea underlying the proposed method is to conduct several replications at each trial point to obtain reli able estimate of the theoretical response. In particular, the number of replications is not fixed but is set to a variable automatically adjusted {{on the basis of}} the distance between the two successive trial points. To avoid misjudging the real different between two points due to the stochastic nature, a t-test instead of a simple comparison of the mean responses is performed. Empirical results from a stochastic Watson function with nine <b>variables,</b> a <b>queueing</b> problem, and an inventory problem indicate that this method is able to find the optimal solutions in a statistical sense, and the varying replications has demonstrated to be able to alleviate the computational burden in the whole optimization procedure. Moreover, this method is robust with respect to the parameter used in determining the varying replications conducted at each trial point...|$|R
40|$|Abstract. The {{relevant}} {{dynamics of}} a queueing {{process can be}} anticipated by taking future arrivals into account. If the transport from one queue to another is associated with transportation delays, as it is typical for traffic or productions networks, future arrivals to a queue are known over some time horizon and, thus, {{can be used for}} an anticipative control of the corresponding flows. A queue is controlled by switching its outflow between “on ” and “off ” similar to green and red traffic lights, where switching to “on ” requires a non-zero setup time. Due to the presence of both continuous and discrete state <b>variables,</b> the <b>queueing</b> process is described as a hybrid dynamical system. From this formulation, we derive one observable of fundamental importance: the green time required to clear the queue. This quantity allows to detect switching time points for serving platoons without delay, i. e., in a “green wave ” manner. Moreover, we quantify the cost of delaying the start of a service period or its termination in terms of additional waiting time. Our findings may serve as a basis for strategic control decisions. PACS. 02. 30. Yy Control theory – 02. 30. Ks Delay and functional equations – 89. 75. -k Complex systems – 89. 40. -a Transportation...|$|R
40|$|Low {{run-time}} overhead, self-adapting storage {{policies for}} priority queues called Smart Priority Queue (SPQ) techniques are developed and evaluated. The proposed SPQ policies employ a low-complexity linear queue for near-head activities and a rapid-indexing <b>variable</b> bin-width calendar <b>queue</b> for distant events. The SPQ configuration {{is determined by}} monitoring queue access behavior using cost-scoring factors and then applying heuristics to adjust {{the organization of the}} underlying data structures. We show that optimizing storage to the spatial distribution of queue access can decrease HOLD operation cost between 25 % and 250 % over existing algorithms such as calendar queues. An SPQ-based scheduler for discrete event simulation has been implemented and was used to evaluate the resulting efficiency, components of access time, and queue usage distributions of the existing and proposed algorithms...|$|R
