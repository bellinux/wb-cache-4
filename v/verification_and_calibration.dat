84|10000|Public
5000|$|EN ISO 6506-2:2005: Metallic {{materials}} - Brinell {{hardness test}} - Part 2: <b>verification</b> <b>and</b> <b>calibration</b> of testing machine ...|$|E
5000|$|DIN 50156-2 [...] "Metallic {{materials}} - Leeb {{hardness test}} - Part 2: <b>Verification</b> <b>and</b> <b>calibration</b> {{of the testing}} devices" ...|$|E
50|$|The {{squadron}} {{is responsible}} for VIP transport of high level government officials, medical evacuation, urgent transport of human organs for transplant, and <b>verification</b> <b>and</b> <b>calibration</b> of navigational aids.|$|E
40|$|Modeling and {{simulation}} in electromagnetic engineering are discussed. Fundamental {{terms and}} concepts, and challenges in model validation <b>and</b> <b>verification</b> <b>and</b> code <b>calibration</b> are reviewed. Time- and frequency-domain models are developed <b>and</b> calibrated. Typical <b>calibration</b> scenarios are presented where tests and comparisons against analytical {{as well as}} numerical models are done. IEEE Electromagnetic Compatibility Societ...|$|R
40|$|The Microwave Limb Sounder {{instrument}} was launched aboard NASA's EOS AURA satellite in July, 2004. The overall scientific objectives for MLS are to measure temperature, pressure, and several important chemical {{species in the}} upper troposphere and stratosphere relevant to ozone processes and climate change. MLS consists of a suite of radiometers designed to operate from 11 8 GHz to 2. 5 THz, with two antennas (one for 2. 5 THz, the other for the lower frequencies) that scan vertically through the atmospheric limb, and spectrometers with spectral resolution of 6 MHz at spectral line centers. This paper describes the on-orbit commissioning the MLS instrument which includes activation <b>and</b> engineering functional <b>verifications</b> <b>and</b> <b>calibrations.</b> 1...|$|R
40|$|Traffic {{simulation}} models {{have the potential}} to provide a cost-effective, objective, and flexible approach to assessing design and management alternatives, particularly when these alternatives involve the emerging technologies of Intelligent Transportation Systems (ITS). However, in order for this potential to be realized, models must be valid for the application and must provide results that are credible and reliable. The process of ensuring validity, credibility, and reliability typically consists of three elements- <b>verification,</b> validation <b>and</b> <b>calibration.</b> In current traffic engineering practice, there appears to be little uniformity in the definition of each of these three process elements. It also appears that there exists a lack of consensus among both model developers and model users regarding the actions required to carry out each process element and the division of responsibilities between the two groups. This paper attempts to provide traffic model developers and users with a framework for the <b>verification,</b> validation <b>and</b> <b>calibration</b> of traffic models. Examples are provided to illustrate the model <b>verification</b> <b>and</b> validation processes. Furthermore, each process element is clearly defined as is the role of model developers and model users...|$|R
50|$|The {{thermodynamic}} {{method is}} used to test water, wastewater, and other pumps, but because {{of its ability to}} accurately test flow, it is also used for applications such as system curve testing, flow meter <b>verification</b> <b>and</b> <b>calibration,</b> and perpetual efficiency monitoring. This method is useful particularly in situations which do not have the piping requirements of conventional testing methods. It can, like conventional pump testing, be used to gauge the performance of pumps for preventative maintenance and to inform replacement and refurbishment decisions. Additionally, the method can be extended to blower and turbine performance testing.|$|E
50|$|The first {{signal from}} the {{satellite}} was received at 1835 BST on 20 October 2006, and {{it was confirmed that}} the satellite was in its nominally correct orbit with the solar panel deployed. Control of the satellite was with the European Space Operations Centre (ESOC — part of ESA) which had the responsibility of achieving the final positioning of the satellite, deployment of all the antennas and final reconfiguration of the satellite following necessary orbit control maneuvers. The satellite was handed over to EUMETSAT operations on 22 October 2006. The first image was received at 0800 UTC on 25 October—a visible light image of Scandinavia and Eastern Europe — but there was a six-month period of <b>verification</b> <b>and</b> <b>calibration</b> of the satellite and its instrument payload before it was declared operational. Before that point, the Met Office received data and started to test and then use it as input to the operational numerical weather prediction runs.|$|E
5000|$|The {{ship was}} {{operated}} by Military Sealift command {{and had a}} crew of 200 and supporting contractors and military personnel of approx 50. During the late 1970s and early 1980s RCA Service Corp had the contract for supporting the electronics with a contingent of approx 50 personnel. The RCA personnel operated and maintained the radar equipment. At that time the main computer was a NASA modified 642B mainframe. Supplemental computers were a Univac 1911. The aft dish was a 30 ft Telemetry dish, the 40' midship dish was an X and L band radar capable of tracking a 15 inch sphere to 1500 miles. The L band radar was 8M watts. The 30' forward dish was a C Band radar. There was an optical 'flexure monitoring system' running from beneath the Ship's Inertial Navigation System" [...] (SINS) gyros to beneath the telemetry mount. This system allowed for computer-aided steering of the three antennas to maintain 'target convergence' in compensation for the forces inflicted upon the ship in the roll, pitch and yaw axes by the sea motion. In addition, just behind the bridge and above the ship's navigational gyro was a 'star tracker' system that provided celestial navigation backup, <b>verification</b> <b>and</b> <b>calibration</b> for the SINS. A single-side-band (SSB) radio communication system, visibly represented by two large, vertically oriented antennae located on the forward deck, permitted radio communication to operational centers in the U.S. from virtually anywhere around the globe.|$|E
40|$|Abstract. We {{describe}} {{and evaluate the}} performance of a phase diversity wavefront sensor used to measure the static aberrations of the VLT instrument NAOS–CONICA. The main limitations of this phase diversity technique are compiled. We investigate the systematic errors due to the experimental implementation and the design restrictions. Further error sources stem from the imperfect knowledge of the system, and from limitations of the algorithm. The influence of these errors on the wavefront estimation is evaluated on numerical and experimental data. This study highlights the essential <b>verifications</b> <b>and</b> <b>calibrations</b> needed to obtain accurate results and gives a practical guideline for the application of a phase diversity wavefront sensor. The comprehensive <b>calibration</b> results <b>and</b> the final gain in optical performance are presented and discussed in a complementary paper (Hartung et al. 2003). Key words. instrumentation: adaptive optics 1...|$|R
50|$|Even before HEAO-2 (the Einstein Observatory) was {{launched}} in 1978, MSFC began preliminary studies for a larger X-ray telescope. To support this effort, in 1976 an X-Ray Test Facility, {{the only one of}} its size, was constructed at Marshall for <b>verification</b> testing <b>and</b> <b>calibration</b> of X-ray mirrors, telescope systems, and instruments. With the success of HEAO-2, MSFC was given responsibility for the design, development, and construction of what was then known as the Advanced X-ray Astrophysics Facility (AXAF). The Smithsonian Astrophysical Observatory (SAO) partners with MSFC, providing the science and operational management.|$|R
40|$|Sevgi, Levent (Dogus Author) [...] #nofulltext#Model validation, data <b>verification,</b> <b>and</b> code <b>calibration</b> (VV&C) {{in applied}} {{computational}} electromagnetics is discussed. The {{step by step}} VV&C procedure is given systematically through canonical scenarios and examples. Propagation over flat-Earth with linearly decreasing vertical refractivity profile, having an analytical exact solution, is taken into account as the real-life problem. The parabolic wave equation (PWE) is considered as the mathematical model. MatLab-based numerical simulators for both the split step Fourier and finite element implementations of the PWE are developed. The simulators are calibrated against analytical exact and high frequency asymptotic solutions. Problems related to the generation of reference data during accurate numerical computations are presented...|$|R
40|$|As the {{manufacturing}} community embraces {{the use of}} a variety of metrology solutions, the availability and quantity of measurement data is increasing. The tendency towards connectedness between manufacturing resources may also provide a mechanism for communication and exploitation of metrology data like never before. This research aims to provide an insight into the opportunities that are associated with accessible, abundant and communicable manufacturing metrology data. Issues are raised and critically discussed in relation to one particular aspect of manufacturing metrology, namely, machine tool accuracy <b>verification</b> <b>and</b> <b>calibration.</b> Specifically, a methodology for relating CMM part measurements to individual machine tool geometric error sources is described. A novel Monte Carlo simulation-based method is used to estimate previously unmeasured error values without the use of further testing. Using this method, the advantage of using previously captured <b>verification</b> <b>and</b> <b>calibration</b> data to identify likely causes of part defects is shown. It is envisaged that the proposed method can be used to instruct targeted machine tool <b>verification</b> <b>and</b> <b>calibration</b> routines {{to reduce the number of}} tests required to monitor a machine tool's health. By using targeted tests, the need to measure all machine error sources is reduced, which in turn can improve productivity by reducing machine tool downtime...|$|E
40|$|Sevgi, Levent (Dogus Author) Modeling and {{numerical}} simulation in electromagnetics {{is discussed in}} this paper with emphasize placed on validation, <b>verification</b> <b>and</b> <b>calibration.</b> Canonical examples from antennas, propagation to microstrip circuits are presented. Tests against measurements, when available, are also presented. IEEE,IEEE Electromagnetic Compatibility Society,International Union of Radio Science, URSI,Research-and-production Enterprise "Proryv...|$|E
30|$|Seismic {{sedimentology}} {{research on}} continental basins should highlight the <b>verification</b> <b>and</b> <b>calibration</b> of geological data. In this paper, we present {{the concepts of}} time-equivalent seismic attributes and seismic sedimentary bodies as well as seismic data-lithology conversion processing and time-equivalent seismic attribute extraction methods and techniques. On this basis, we introduce a “four-step” approach applicable to seismic sedimentology research on continental basins.|$|E
40|$|This article treats as {{the need}} of check of the {{condition}} of calibration through statistical technologies and the methodology or procedure used by the laboratories of calibration. It mentions {{the meaning of the}} concept of measuring pattern traceable <b>verification,</b> <b>and</b> any subsequent <b>calibration</b> statistical techniques based on. Finally, an experimental part is realized in order to verify the technologies of calibration for comparison in the laboratories of a zone of reference...|$|R
40|$|Abstract. In {{this paper}} we {{elaborate}} on the usage of multi-agent-based simula-tion (MABS) for quantitative impact assessment of transport policy and infras-tructure measures. We provide a general discussion {{on how to use}} MABS for freight transport analysis, focusing on issues related to input data management, validation <b>and</b> <b>verification,</b> <b>calibration,</b> output data analysis, and generalization of results. The discussion is built around an agent-based transport chain simulation tool called TAPAS (Transportation And Production Agent-based Simulator) and a simulation study concerning a transport chain around the Southern Baltic Sea...|$|R
40|$|MIRI {{is one of}} four {{instruments}} to be built for the James Webb Space Telescope. It provides imaging, coronography and integral field spectroscopy over the 5 - 28. 5 um wavelength range. MIRI is the only instrument which is cooled to 7 K by a dedicated cooler, much lower than the passively cooled 40 K of the rest of JWST, and consists of both an Optical System and a Cooler System. This paper will describe the key features of the overall instrument design and then concentrate on the status of the MIRI Optical System development. The flight model design and manufacture is complete, and final assembly and test of the integrated instrument is now underway. Prior to integration, all of the major subassemblies have undergone individual environmental qualification and performance tests and end-end testing of a flight representative model has been carried out. The paper will provide an overview of results from this testing and describe the current status of the flight model build and the plan for performance <b>verification</b> <b>and</b> ground <b>calibration.</b> status: publishe...|$|R
40|$|During {{the past}} few decades, {{significant}} numerical developments have been undertaken {{in the fields of}} basic and applied aerodynamics, including unsteady three-dimensional turbulent computations such as direct numerical, large-eddy or detached-eddy simulations. Critically the validation of a numerical model relies upon independent data sets that were not used during the <b>verification</b> <b>and</b> <b>calibration</b> of the model. Several researchers discussed the intricacy of the validation process: for example...|$|E
40|$|The {{problem of}} testing, <b>verification</b> <b>and</b> <b>{{calibration}}</b> of length-scales (electronic rangefinders) and angle-scales (geodetic instruments). The calibration of coded levelling rods and the systemic calibration of digital levelling instruments. The calibration on linear comparative baseline in a terrain – {{the elaboration of}} measured data. The testing of universal measuring instruments in laboratory conditions - specific problems in testing of instruments with the passive reflection. Some knowledge about the calibration of horizontal circles of angle-measuring geodetic instruments...|$|E
40|$|A novel two-way finite-element {{parabolic}} equation (PE) (2 W-FEMPE) {{propagation model}} which handles both {{forward and backward}} scattering effects of the groundwave propagation above the Earth's surface over irregular terrain paths through inhomogeneous atmosphere is introduced. A Matlab-based propagation tool for 2 W-FEMPE is developed and tested against mathematical exact and asymptotic solutions {{as well as the}} recently introduced two-way split-step PE model through a canonical validation, <b>verification,</b> <b>and</b> <b>calibration</b> process {{for the first time in}} literature. IEEE Geoscience and Remote Sensing Societ...|$|E
40|$|TanDEM-X (TerraSAR-X add-on for Digital Elevation Measurements) is an {{innovative}} spaceborne radar interferometer {{that is based}} on two TerraSAR-X radar satellites flying in close formation. The primary objective of the TanDEM-X mission is the generation of a consistent global digital elevation model (DEM) with an unprecedented accuracy, equaling or surpassing the HRTI- 3 specification. Beyond that, TanDEM-X provides a highly reconfigurable platform for the demonstration of new radar imaging techniques and applications. This paper gives a detailed overview of the TanDEM-X mission concept which is based on the systematic combination of several innovative technologies. Key elements are the bistatic data acquisition employing {{an innovative}} phase synchronization link, a new satellite formation flying concept allowing for the collection of bistatic data with short along-track baselines, as well as the use of new interferometric modes for system <b>verification</b> <b>and</b> DEM <b>calibration.</b> The performance is analyzed in detail taking into account the peculiarities of the bistatic operation. Based on this analysis, an optimized DEM data acquisition plan is developed which employs the combination of multiple data takes with different baselines. Finally, a collection of instructive examples illustrates the capabilities of TanDEM-X for the development and demonstration of new remote sensing applications...|$|R
40|$|The recent {{emphasis}} on utilising advanced technologies {{to make more}} efficient use of existing transportation infrastructure, coupled with the continuing advances in desktop computing technologies, has created {{an environment in which}} traffic simulation models have the potential to provide a cost-effective, objective, and flexible approach for assessing design and management alternatives. However, the models must be demonstrated to be valid, and they must be adequately calibrated for local conditions. While the processes of <b>verification,</b> validation <b>and</b> <b>calibration</b> are certainly not new, based on the lack of literature on this topic, it appears that the application of these processes to traffic simulation models is not well defined. This paper examines the issues related to primarily the calibration of traffic simulation models. It attempts to answer, or at least clarify, several key questions, including the following: What is model calibration? What measures of performance should be used in <b>calibration?</b> <b>and</b> When is a model adequately calibrated? The discussion of these questions stems from the goal of obtaining model results that are seen as credible, reliable, and useful, particularly by people who are not modellers. The distinct roles and responsibilities of model developers and model users are discussed. Examples are provided to illustrate the model calibration process...|$|R
40|$|The Advanced Synthetic Aperture Radar (ASAR) on- board Envisat {{operated}} {{successfully for}} just over 10 years until {{the failure of}} Envisat in April 2012. ASAR was ESA‚Äôs very first deployment of a C-band phased- array antenna, allowing extended imaging capacity in comparison to its ERS SAR predecessors. As such it operated in various acquisition modes ‚Äì Image (IM), Alternating Polarisation (AP), Wide Swath (WS), Global Monitoring (GM), and Wave (WV). For IM and AP modes there was a selection of 7 swaths with swath width from 100 km to 56 km: IM was single-polarisation, while AP was dual-pol, offering a choice from HH&VV, HH&HV, or VV&VH. WS and GM modes had a total swath width of 405 km based on the combination of 5 sub-swaths. WV acquired imagettes of 10 km by 10 km every 100 km along the satellite track. This paper is a look back to the 10 years of ASAR operations, covering topics such as the ASAR Instrument (characteristics, acquisition modes, product tree and observation scenario), Instrument <b>Calibration</b> <b>and</b> Performance <b>Verification</b> (including instrument stability, internal calibration, external calibration, absolute radiometric calibration, localisation accuracy, absolute geolocation accuracy, performance <b>verification</b> <b>and</b> product <b>calibration),</b> ASAR specific missions (wave and polarimetric), particular ASAR events such as antenna resets, burst synchronisation, AP swath modifications and the Envisat orbit change in October 2010...|$|R
40|$|Abstract: As {{a sequel}} to the first large {{database}} created at Northwestern University in 1978, the paper presents a further enlargement of the database, comprising 621 creep tests and 490 shrinkage tests. This database significantly extends the 1993 RILEM database which contained 518 creep tests and 426 shrinkage tests. The new database will make possible more realistic <b>verification</b> <b>and</b> <b>calibration</b> of creep prediction models for design, provided that a proper unbiased statistical technique, compensating for inevitable strong statistical bias {{in the distribution of}} data, is employed. The database can be downloaded freely from the websit...|$|E
40|$|This paper {{reviews the}} design, {{engineering}} principles and applications of machine tools specially developed for large parts. Large workshop machines {{are commonly used}} for manufacturing, where {{the impact of the}} general engineering principles differs substantially from those applied to conventional size machines. Portable machines are used during assembly and operation due to mobility, agility and energy constraints. Such large dimensions produce an amplification factor of any error source, so <b>verification</b> <b>and</b> <b>calibration</b> of such large or portable machines becomes evenmore critical than in conventional machines. The paper also includes future trends and unsolved challenges...|$|E
40|$|The {{results of}} water meter test {{facility}} calibration are presented. More than 30 test facilities {{are used in}} Lithuania nowadays. All of them are certificated for water meter of class 2 verification. The results of inter-laboratory comparison of multi-jet water meter calibration at flow rate Q = 5 m 3 /h are presented. Lithuanian Energy Institute was appointed as reference laboratory for the comparison. Twelve water meter <b>verification</b> <b>and</b> <b>calibration</b> laboratories from Lithuania participated in the ILC. The deviations from reference values were described by the normalized deviation En. Article in Lithuanian</p...|$|E
5000|$|TC 4 Measurement {{standards}} <b>and</b> <b>calibration</b> <b>and</b> <b>verification</b> devices ...|$|R
40|$|With the evolvement {{of modern}} Weigh-In-Motion {{equipment}} {{both in the}} field of sensor and logger technology the way in which <b>calibration</b> <b>and</b> <b>verification</b> is undertaken has also changed. This paper discusses some traditional <b>calibration</b> <b>and</b> <b>verification</b> methods <b>and</b> suggests how to implement more reliable in-field <b>and</b> statistical <b>calibration</b> <b>and</b> <b>verification</b> methods. In addition the paper discusses and presents a technique of correcting bias resulting from “binning ” recorded axle weights...|$|R
40|$|The NIST Analytical Chemistry Division has {{supplied}} transmittance <b>verification</b> <b>and</b> wavelength <b>calibration</b> standard {{reference materials}} (SRMs) specialized {{to the needs}} of chemical and pharmaceutical spectrophotometric analysis since 1970. Growing demand for UV/visible standards stems from the increasingly routine use of spectrophotometers for pharmaceutical quality control and from the escalation in the documented use of standards for regulatory and voluntary quality control purposes. To meet the demand, NIST is studying ways to accelerate standards production. Projects include studies of the origin of transmittance drift (which necessitates aging during production), investigations of solid UV filters and of sealed liquid standards, {{and the development of a}} NIST-Traceable Reference Material (NTRM TM) optical filters program to involve the private sector. Recently, we have revised the optical specifications of our solid filter standards to meet the requirements of reversed-geometry (post-dispersion) instruments. In the near infrared, spectrochemical process control applications mandate the need for wavelength standards to support the stability and instrument-to-instrument transfer capability of multivariate analytical calibration models. We are presently producing one such standard and are investigating others. Finally, we are studying algorithms for locating peaks in wavelength 1 standards to find a consistent means for making wavelength assignments from the UV through the mid-infrared...|$|R
40|$|As {{a sequel}} to the first large {{database}} created at Northwestern University in 1978, this paper presents a further enlargement of the database, comprising 621 creep tests and 490 shrinkage tests. This database significantly extends the 1993 RILEM database, which contains 518 creep tests and 426 shrinkage tests. This new, conveniently computerized database will make possible more realistic <b>verification</b> <b>and</b> <b>calibration</b> of creep prediction models for design, provided that a proper unbiased statistical technique, compensating for inevitable strong statistical bias {{in the distribution of}} data, is employed. The database can be downloaded freely from the Web sit...|$|E
40|$|In 2006 - 2010, several Radio Frequency (RF) {{detectors}} and calibration equipment were deployed {{as part of}} the IceCube array at depths between 5 to 1400 meters in preparation for a future large scale GZK neutrino detector. IceCube's deep holes and well-established data handling system provide a unique opportunity for deep-ice RF detection studies at the South-Pole. We will present <b>verification</b> <b>and</b> <b>calibration</b> results as well as a status-review of ongoing analyses such as ice-properties, RF noise and reconstruction algorithms. Comment: 4 pages, 6 figures, to appear in the proceedings of the Acoustic and Radio EeV Neutrino detection Activities (ARENA) 2010 conferenc...|$|E
40|$|This paper {{describes}} an approach of combining Medium Voltage laboratory and simulation resources to investigate fast transient phenomena that occur due to switching operations of feeders and turbines in a wind park. The paper {{focuses on the}} <b>verification</b> <b>and</b> <b>calibration</b> of simulation models using experimental results obtained in the Cable System Laboratory at ABB when studying the interaction of different equipments in the wind park such as cables, transformers, and switching apparatus tested with full voltage and realistic cable lengths. After such verification, the model can be confidently used to investigate transient phenomena occurring in larger and more sophisticated systems...|$|E
40|$|The {{objective}} {{of these studies}} is to analyze the possibility of determining CO 2 concentration in the atmosphere by using spectral indexes - Normalized Difference Vegetation Index (NDVI) and Enhanced Vegetation Index (EVI) and GPP, PsnNet. In the studies, spatially explicit NDVI and EVI values at a resolution of 1 km were calculated for two years, 2009 and 2010, and used {{for the analysis of}} dependencies between plant biomass growth and environmental conditions. CO 2 concentration in the atmosphere, temperature, precipitation, and time of the year. For every spatial point, the value of photosynthesis activity was calculated and the relationships among the CO 2 exchanges, the remotely sensed Normalized Difference Vegetation Index (NDVI), and other environmental factors were examined using the Pearson correlation coefficient. These studies explore the relationship between MODIS products, i. e., Normalized Difference Vegetation Index, Enhanced Vegetation Index, gross primary productivity, net Photosynthesis, and CO 2 concentration derived from GOSAT satellite. These measurements could maximize the utility of expensive flux towers for evaluating various carbon management strategies, carbon certification, quotas <b>verification,</b> validation <b>and</b> <b>calibration</b> of carbon flux models and can supplement data base. Also understanding how increasing concentration to improve plant growth can help to calculate biomass potential in CO 2 accumulation...|$|R
40|$|Measurements) is an {{innovative}} spaceborne radar interferometer {{that is based}} on two TerraSAR-X radar satellites flying in close formation. The primary objective of the TanDEM-X mission is the generation of a consistent global digital elevation model (DEM) with an unprecedented accuracy, which is equaling or surpassing the HRTI- 3 specification. Beyond that, TanDEM-X provides a highly reconfigurable platform for the demonstration of new radar imaging techniques and applications. This paper gives a detailed overview of the TanDEM-X mission concept which is based on the systematic combination of several innovative technologies. The key elements are the bistatic data acquisition employing {{an innovative}} phase synchronization link, a novel satellite formation flying concept allowing for the collection of bistatic data with short along-track baselines, as well as the use of new interferometric modes for system <b>verification</b> <b>and</b> DEM <b>calibration.</b> The interferometric performance is analyzed in detail, taking into account the peculiarities of the bistatic operation. Based on this analysis, an optimized DEM data acquisition plan is derived which employs the combination of multiple data takes with different baselines. Finally, a collection of instructive examples illustrates the capabilities of TanDEM-X for the development and demonstration of new remote sensing applications. Index Terms—Bistatic SAR, digital elevation model (DEM), formation flying, interferometry, microwave remote sensing, multistatic SAR, synchonization, synthetic aperture radar (SAR). I...|$|R
50|$|Use {{of proper}} test methods, <b>calibration,</b> <b>and</b> <b>Verification</b> <b>and</b> {{validation}} protocols {{are important for}} all phases of evaluation.|$|R
