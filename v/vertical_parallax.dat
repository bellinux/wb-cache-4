41|13|Public
25|$|The valley {{stage in}} MUSHA {{utilizes}} the Genesis' <b>vertical</b> <b>parallax</b> scrolling capabilities, which was later highlighted by critics {{as one of}} the game's most impressive technical features. The stage was programmed by Yuuichi Sotoyama, who also programmed the enemies that move {{in and out of the}} depths of the valley, and tiles that fall into the screen in other stages. Sotoyama worked with the sound effects programmer Masanobu Tsukamoto to modulate the frequency of the sound effects when objects moved in and out of the screen to simulate the Doppler effect.|$|E
50|$|One of {{the initial}} {{adjustment}} overlooked by many new users is the lenses <b>vertical</b> <b>parallax,</b> that must {{not be confused with}} the horizontal parallax (set manually by the left rocker button). Although the lenses should be perfectly aligned, by design, there is a small vertical axis error inherent for each camera body. This error implies that all pictures (and videos as well) taken with a wrong <b>vertical</b> <b>parallax</b> are harder to look at, because one eye is looking up while the other is looking down. To effectively correct this optical discrepancy, the camera offers a <b>vertical</b> <b>parallax</b> correction in its menu system: MENU/SET/OPT AXIS CONTROL. The best way to use this adjustment is to zoom at maximum, take a picture, then analyse it with a software stereoscopic player(using row or column interlaced view) to obtain the subject at the same vertical level.|$|E
50|$|So far, {{the ability}} to {{reconstruct}} scenes with occlusion and other position-dependent effects {{have been at the}} expense of <b>vertical</b> <b>parallax,</b> in that the 3D scene appears distorted if viewed from locations other than those the scene was generated for.|$|E
40|$|Maxillary canines are {{important}} aesthetically and functionally, but impacted canines {{are more difficult}} and time consuming to treat. Permanent maxillary canine impaction {{has been reported in}} about 1 % to 5 % of the population. The objective {{of this study was to}} determine the prevalence of impacted maxillary canine in patients visiting to Khyber college of dentistry, Peshawar. A total of 500 patients of 15 years and above were examined clinically. Those having maxillary canine impaction were advised Anterior Occlusal View and panoramic radiograph to determine the patterns of impaction by <b>vertical</b> <b>parallaxing</b> technique. Data were processed in SPSS version 16. 0. The chi-squared test was used to reveal any differences in the distribution of impacted maxillary canines when stratified by gender and location (left or right) [...] A p-value of < 0. 05 was accepted as statistically significant. Out of 500 patients examined 20 (4 %) had maxillary canine impaction. The mean age was 19. 05 Â± 3. 15 years. Age was ranged from 15 to 25 years. Female to male ratio was 1. 85 : 1. Females had more impaction of maxillary canine than males(p= 0. 000). Palatal were the most common in males while buccal were in females. Left side was commonly involved in impaction in both genders. Key Words: Impacted maxillary canine, patterns of impaction, <b>vertical</b> <b>parallaxing</b> technique. Original articl...|$|R
30|$|Several {{studies have}} been {{conducted}} to establish the epipolar geometry of the pushbroom camera to achieve effective epipolar image resampling. For example, Oh et al. [3] proposed a piecewise approach to this problem with rational polynomial coefficient (RPC); this is an image space-based approach and was shown to achieve almost zero y-parallax, as well as a linear relationship between the x-parallax and the ground height. Alternatively, Wang et al. [4] suggest a method that implements a new epipolarity model based on the projection reference plane (PRP); this is an object space-based approach, and experimental results showed that the <b>vertical</b> <b>parallaxes</b> all attained sub-pixel levels in along-track and cross-track stereo images from actual equipment, including Earth observation satellites SPOT- 5, IKONOS, IRS-P 5, and QuickBird.|$|R
40|$|This paper {{presents}} a practical method of epipolar resampling of high-resolution satellite imagery. Satellite imagery imaged with a linear array CCD sensor has quite different geometric characteristics from aerial photographs, therefore the conventional method of epipolar resampling is not applicable to it. On the other hand, epipolar resampling method based on rigorous orientation model with high geometric fidelity becomes too complicated {{and then is}} not suitable practical use. In order to overcome this problem, the author proposes to apply the well-established 2 D affine orientation model to the epipolar resampling of satellite imagery. Firstly, this paper roughly mentions the characteristics of this model. Then it is shown how the model is suitably applicable to epipolar resampling. Secondly, the paper proposes the improved method that does not require any DTM or rigorous geometric parameters for reduction of <b>vertical</b> <b>parallaxes.</b> Finally an experiment validates the proposed method wi [...] ...|$|R
5000|$|Stereo cameras can {{introduce}} various mismatches in stereo image (such as <b>vertical</b> <b>parallax,</b> tilt, color shift, reflections and glares in different positions) {{that should be}} fixed in post-production anyway because they ruin the 3D effect. This correction sometimes may have complexity comparable to stereo conversion.|$|E
50|$|The lens {{system used}} was Optimax III (Bill Bukowski of Optimax III served as 3D Technical Advisor), notorious for {{introducing}} <b>vertical</b> <b>parallax</b> error owing to its flawed design (i.e., the optical axes of its twin lenses {{are not at}} the same horizontal level). The film's posters by turns heralded the 3-D process as SuperVision and WonderVision.|$|E
5000|$|The four cams in the Mk. 1/1A {{computer}} provided mechanical {{time fuse}} setting, {{time of flight}} (this time is from firing to bursting {{at or near the}} target), time of flight divided by predicted range, and superelevation combined with <b>vertical</b> <b>parallax</b> correction. (Superelevation is essentially the amount the gun barrel needs to be raised to compensate for gravity drop.) ...|$|E
40|$|Linear pushbroom {{satellite}} imagery acquired in either along-track or cross-track mode, {{based on the}} projection reference plane in object space. A new method for epipolar resampling of satellite stereo imagery based on this model is then developed. In this method, the pixel-to-pixel relationship between the original image and the generated epipolar image is established directly by the geometric sensor model. The approximate epipolar images are generated in amanner similar to digital image rectification. In addition, by arranging the approximate epipolar lines on the defined projection reference plane, a stereoscopic model with consistent ground sampling distance and parallel to the object space is thus available, which is more convenient for three-dimensional measurement and interpretation. The results obtained from SPOT 5, IKONOS, IRS-P 5, and QuickBird stereo images indicate that the generated epipolar images all achieve high accuracy. Moreover, the <b>vertical</b> <b>parallaxes</b> at check points are at sub-pixel level, thus proving the feasibility, correctness, and applicability of the method...|$|R
50|$|Japanese {{designer}} Masayuki Ito, following Julesz, {{created a}} single image stereogram in 1970 and Swiss painter Alfons Schilling created a handmade single-image stereogram in 1974, after creating {{more than one}} viewer and meeting with Julesz. Having experience with stereo imaging in holography, lenticular photography, and vectography, he developed a random-dot method based on closely spaced <b>vertical</b> lines in <b>parallax.</b>|$|R
50|$|Where {{full color}} to each eye is enabled via {{alternating}} color channels and color alternating viewing filters, (ACB) prevents shimmer from pure colored objects within the modulating image. <b>Vertical</b> and diagonal <b>parallax</b> is enabled with concurrent {{use of a}} horizontally oriented lenticular or parallax barrier screen. This enables a Quadrascopic full color holographic effect from a monitor.|$|R
50|$|Horizontal Parallax Only (HPO) and <b>Vertical</b> <b>parallax</b> Only (VPO) {{displays}} only deliver optical {{information in}} two dimensions. This method of display partially compromises {{the image in}} certain viewing angles, but it requires much less computational power and data transfer. Because humans' eyes are positioned side by side, HPO displays are generally preferred over VPO displays, and sometimes preferred over full parallax displays due to their lesser demand on processing power.|$|E
50|$|Thomas Riederer is a Professional Engineer and {{inventor}} {{who developed}} the camera system used in the filming of Up Denali 3D, which needed to be reliable for the extreme cold weather anticipated by the climb, as well as light, self-contained and portable to allow a month's worth of shooting with no resupply. Advancements from the camera system used for Aconcagua were designed and tested prior to production. A digital video camera with a modification of the NuView 3D lens, which Riederer invented, was selected. Modifications included a heating system to keep the camera operational at filming temperatures down to 35 below zero Fahrenheit, Left eye/Right eye polarization balancing for taming the white glare of the snow, vertical alignment mechanisms to avoid Left eye/Right eye <b>vertical</b> <b>parallax</b> and other optical, electronic and mechanical modifications.|$|E
5000|$|The AF had an {{automatic}} mode for flash photography ("Easy Flash"). Therefore {{it had a}} guide number selector. A hot shoe for the flash gave further ease of flash usage. For manual exposure selection it offered shutter priority mode with preselection of five exposure times from 1/30 sec to 1/500 sec. The frame viewfinder was coupled to a superimposed rangefinder and had a mechanical horizontal parallax correction. For <b>vertical</b> <b>parallax</b> only a parallax arrow. The CdS exposure meter's aperture value proposal for the automatic aperture was visible through the finder, at {{the right side of}} the viewfinder image. The lens, a Rokkor 1:2,7/38mm, had only 4 elements in three groups, and a Seiko shutter. The meter's [...] "eye" [...] was placed within the filter ring of the lens.|$|E
40|$|Treballs Finals de Grau de FÃ­sica, Facultat de FÃ­sica, Universitat de Barcelona, Curs: 2017, Tutor: Artur Carnicer GonzÃ¡lezIn this work, {{we study}} a {{technique}} called Integral imaging. This technique consists in a three-dimensional scene reconstruction from two-dimensional images called elementary images. The method we use shows that under natural light conditions and through a computer program, {{we can get the}} different planes' depth of the three-dimensional scene. In addition, it will be demonstrated the different objects occlusions that may occur and its effects or problems can be reduced or solved by <b>vertical</b> and horizontal <b>parallax...</b>|$|R
40|$|AbstractâThe {{display is}} the last {{component}} in a chain of activity from image acquisition, compression, coding transmission and reproduction of 3 -D images through to the display itself. There are various schemes for 3 -D display taxonomy; the basic categories adopted for this paper are: holography where the image is produced by wavefront reconstruction, volumetric where the image is produced within a volume of space and multiple image displays where two or more images are seen across the viewing field. In an ideal world a stereoscopic display would produce images in real time that exhibit all {{the characteristics of the}} original scene. This would require the wavefront to be reproduced accurately, but currently this can only be achieved using holographic techniques. Volumetric displays provide both <b>vertical</b> and horizontal <b>parallax</b> so that several viewers can see 3 -D images that exhibit no accommodation/convergence rivalry. Multiple imag...|$|R
40|$|This report {{summarizes}} {{the work done}} to develop a 3 D teleconferencing system, which enables remote participants {{anywhere in the world}} to be scanned in 3 D, transmitted and displayed on a constructed 3 D display with correct <b>vertical</b> and horizontal <b>parallax,</b> correct eye contact and eye gaze. The main focus of this report is the development of this system and especially how to in an efï¬cient and general manner render to the novel 3 D display. The 3 D display is built out of modiï¬ed commodity hardware and show a 3 D scene for observers in up to 360 degrees around it and all heights. The result is a fully working 3 D Teleconferencing system, resembling communication envisioned in movies such as holograms from Star Wars. The system transmits over the internet, at similar bandwidth requirements as concurrent 2 D videoconferencing systems. Project done at USC Institute for Creative Technologies, LA, USA. Presented at SIGGRAPH 09...|$|R
50|$|The rainbow or Benton {{hologram}} {{is a type}} of hologram {{invented in}} 1968 by Dr. Stephen A. Benton at Polaroid Corporation (later MIT). Rainbow holograms are designed to be viewed under white light illumination, rather than laser light which was required before this. The rainbow holography recording process uses a horizontal slit to eliminate <b>vertical</b> <b>parallax</b> in the output image, greatly reducing spectral blur while preserving three-dimensionality for most observers. A viewer moving up or down in front of a rainbow hologram sees changing spectral colors rather than different vertical perspectives. Because perspective effects are reproduced along one axis only, the subject will appear variously stretched or squashed when the hologram is not viewed at an optimum distance; this distortion may go unnoticed when there is not much depth, but can be severe when the distance of the subject from the plane of the hologram is very substantial. Stereopsis and horizontal motion parallax, two relatively powerful cues to depth, are preserved.|$|E
50|$|In this method, {{parallax}} in {{the vertical}} plane is sacrificed {{to allow a}} bright, well-defined, gradiently colored reconstructed image to be obtained using white light. The rainbow holography recording process usually begins with a standard transmission hologram and copies it using a horizontal slit to eliminate <b>vertical</b> <b>parallax</b> in the output image. The viewer is therefore effectively viewing the holographic image through a narrow horizontal slit, but the slit has been expanded into a window by the same dispersion that would otherwise smear the entire image. Horizontal parallax information is preserved but movement in the vertical direction results in a color shift rather than altered vertical perspective. Because perspective effects are reproduced along one axis only, the subject will appear variously stretched or squashed when the hologram is not viewed at an optimum distance; this distortion may go unnoticed when {{there is not much}} depth, but can be severe when the distance of the subject from the plane of the hologram is very substantial. Stereopsis and horizontal motion parallax, two relatively powerful cues to depth, are preserved.|$|E
40|$|With the {{evolution}} of digital image acquisition devices, satellite positioning systems (GPS) and space orientation by the inertial navigation systems (INS), new applications of fast cartography, became feasible, as disaster management and environment monitoring. Such applications require periodic georeferenced information with characteristics of speed and reliability that {{can be obtained by}} digital photogrammetry, using additional data from sensors of direct orientation. However, the exterior orientation parameters (EO) provided by these sensors are under the required accuracy to remove the <b>vertical</b> <b>parallax</b> in the model. This paper presents an experimental evaluation of an approach for removing the <b>vertical</b> <b>parallax</b> of the model. This appoach is based on the reprocessing of the EO parameters provided by the sensors, using a modified coplanarity model. Some experiments with simulated and real data are presented. The experiments with simulated data were performed in order to assess the acceptable errors in the exterior orientation parameters. The experiments with real data were carried out to evaluate the <b>vertical</b> <b>parallax</b> effect, before and after the reprocessing of the EO parameters, and to access the accuracy of check points calculated by photogrammetric intersection...|$|E
40|$|The Internet of Things {{is built}} based on various sensors and networks. Sensors for stereo capture are {{essential}} for acquiring information and have been applied in different fields. In this paper, we focus on the camera modeling and analysis, which is very important for stereo display and helps with viewing. We model two kinds of cameras, a parallel and a converged one, and analyze the difference between them in <b>vertical</b> and horizontal <b>parallax.</b> Even though different kinds of camera arrays are used in various applications and analyzed in the research work, there are few discussions on the comparison of them. Therefore, we make a detailed analysis about their performance over different shooting distances. From our analysis, we find that the threshold of shooting distance for converged cameras is 7 m. In addition, we design a camera array in our work that {{can be used as a}} parallel camera array, as well as a converged camera array and take some images and videos with it to identify the threshold...|$|R
40|$|The {{display is}} the last {{component}} in a chain of activity from image acquisition, compression, coding transmission and reproduction of 3 -D images through to the display itself. There are various schemes for 3 -D display taxonomy; the basic categories adopted for this paper are: holography where the image is produced by wavefront reconstruction, volumetric where the image is produced within a volume of space and multiple image displays where two or more images are seen across the viewing field. In an ideal world a stereoscopic display would produce images in real time that exhibit all {{the characteristics of the}} original scene. This would require the wavefront to be reproduced accurately, but currently this can only be achieved using holographic techniques. Volumetric displays provide both <b>vertical</b> and horizontal <b>parallax</b> so that several viewers can see 3 -D images that exhibit no accommodation/convergence rivalry. Multiple image displays fall within three fundamental types: holoform in which a large number of views give smooth motion parallax and hence a hologram-like appearance, multiview where a series of discrete views are presented across viewing field and binocular where only two views are presented in regions that may occupy fixed positions or follow viewers' eye positions by employing head tracking. Holography enables 3 -D scenes to be encoded into an interference pattern, however, this places constraints on the display resolution necessary to reconstruct a scene. Although holography may ultimately offer the solution for 3 DTV, the problem of capturing naturally lit scenes will first have to be solved and holography is unlikely to provide a short-term solution due to limitations in current enabling technologies. Liquid crystal, digital micromirror, optically addressed liquid crystal and acoustooptic spatial light modulators (SLMs) have been employed as suitable spatial light modulation devices in holography. Liquid crystal SLMs are generally favored owing to the c- - ommercial availability of high fill factor, high resolution addressable devices. Volumetric displays provide both <b>vertical</b> and horizontal <b>parallax</b> and several viewers are able to see a 3 -D image that exhibits no accommodation/convergence rivalry. However, the principal disadvantages of these displays are: the images are generally transparent, the hardware tends to be complex and non-Lambertian intensity distribution cannot be displayed. Multiple image displays take many forms and it is likely that {{one or more of these}} will provide the solution(s) for the first generation of 3 DTV displays...|$|R
40|$|Two new {{complementary}} {{methods of}} stereo pair images formation are proposed. The first method {{is based on}} finding the maximum correlation between the gradient images of {{the left and right}} frames. The second one implies the finding of the shift between two corresponding key points of images for a stereo pair found by a detector of point features. These methods give the possibility to set desired values of <b>vertical</b> and horizontal <b>parallaxes</b> for the selected object in the image. Application of these methods makes it possible to measure the parallax values for the objects on the final stereo pair in pixels and / or the percentage of the total image size. It gives the possibility to predict the possible excesses in parallax values while stereo pair printing or projection. The proposed methods are easily automated after object selection, for which a predetermined value of the horizontal parallax will be exposed. Stereo pair images superposition using the key points takes less than one second. The method with correlation application requires a little bit more computing time, but makes it possible to control and superpose undivided anaglyph image. The proposed methods of stereo pair formation can find their application in programs for editing and processing images of a stereo pair, in the monitoring devices for shooting cameras and in the devices for video sequence quality assessmen...|$|R
40|$|A simple {{device is}} {{described}} that {{is capable of}} providing real-time 3 -D viewing of extended X-ray and gamma-ray objects. The visible-light images produced by the device are not merely stereoscopic, i. e., one perspective, but possess both horizontal and <b>vertical</b> <b>parallax</b> with a reasonably large field of view...|$|E
40|$|A multi-pinhole {{aperture}} lead screen {{forms an}} equal plurality of invisible mini-images having dissimilar perspectives of an X-ray and gamma-ray emitting object (ABC) onto a near-earth phosphor layer. This layer provides visible light mini-images {{directly into a}} visible light image intensifier. A viewing screen having {{an equal number of}} dissimilar perspective apertures distributed across its face in a geometric pattern identical to the lead screen, provides a viewer with a real, pseudoscopic image (A'B'C') of the object with full horizontal and <b>vertical</b> <b>parallax.</b> Alternatively, a third screen identical to viewing screen and spaced apart from a second visible light image intensifier, may be positioned between the first image intensifier and the viewing screen, thereby providing the viewer with a virtual, orthoscopic image (A"B"C") of the object (ABC) with full horizontal and <b>vertical</b> <b>parallax...</b>|$|E
40|$|This paper {{discusses}} the origins, characteristics {{and effects of}} image distortions in stereoscopic video systems. The geometry of stereoscopic camera and display systems is presented first. This {{is followed by the}} analysis and diagrammatic presentation of various image distortions such as depth plane curvature, depth non-linearity, depth and size magnification, shearing distortion and keystone distortion. The variation of system parameters is also analysed with the help of plots of image geometry to show their effects on image distortions. The converged (toed-in) and parallel camera configurations are compared and the amount of <b>vertical</b> <b>parallax</b> induced by lens distortion and keystone distortion are discussed. The range of acceptable <b>vertical</b> <b>parallax</b> and the convergence/accommodation limitations on depth range are also discussed. It is shown that a number of these distortions can be eliminated by the appropriate choice of camera and display system parameters. There are some image distortions, however, which cannot be avoided {{due to the nature of}} human vision and limitations of current stereoscopic video display techniques. 1...|$|E
40|$|Figure 1 : 3 D display with content-adaptive {{parallax}} barriers. We {{show that}} light field display using dual-stacked LCDs can be {{cast as a}} matrix approximation problem, leading to {{a new set of}} content-adaptive parallax barriers. (Left, Top) A 4 D light field, represented as a 2 D array of oblique projections. (Left, Bottom) A dual-stacked LCD displays the light field using content-adaptive parallax barriers, confirming both <b>vertical</b> and horizontal <b>parallax.</b> (Middle and Right) A pair of content-adaptive parallax barriers, drawn from a rank- 9 decomposition of the reshaped 4 D light field matrix. Compared to conventional parallax barriers, with heuristically-determined arrays of slits or pinholes, content adaptation allows increased display brightness and refresh rate while preserving the fidelity of projected images. We optimize automultiscopic displays built by stacking a pair of modified LCD panels. To date, such dual-stacked LCDs have used heuristic parallax barriers for view-dependent imagery: the front LCD shows a fixed array of slits or pinholes, independent of the multi-view content. While prior works adapt the spacing between slits or pinholes, depending on viewer position, we show both layers can also be adapted to the multi-view content, increasing brightness and refresh rate. Unlike conventional barriers, both masks are allowed to exhibit non-binary opacities. It is shown that any 4 D light field emitted by a dual-stacked LCD is the tensor product of two 2 D masks. Thus, any pair of 1 D masks only achieves a rank- 1 approximation of a 2 D light field. Temporal multiplexing of masks is shown to achieve higher-rank approximations. Non-negative matrix factorization (NMF) minimizes the weighted Euclidean distance between a target light field and that emitted by the display. Simulations and experiments characterize the resulting content-adaptive parallax barriers for low-rank light field approximation...|$|R
30|$|In 3 D {{broadcasting}} besides having visually good {{images for}} each stereo channel, {{it is also}} important that the channels match with each other. Research in stereo quality control has identified a number of factors affecting viewing experience, such as parallax (disparity) irregularities, focus mismatch, color mismatch, geometry mismatch, <b>vertical</b> <b>parallax,</b> object edge tearing, cardboard effect, pincushion distortion, etc. Such distortion factors affecting 3 D video quality are well documented [1].|$|E
40|$|International audienceThis paper {{presents}} {{a method to}} perform geometric transformations on stereoscopic images. Our paper mainly focuses on epipolar image rectiï¬cation {{for more than two}} views. Indeed, this rectiï¬cation is well suited to remove the <b>vertical</b> <b>parallax</b> that is a signiï¬cant cause of headache related to stereoscopic perception. We show that this rectiï¬cation should satisfy some constraints to provide a 3 D restitution in the correct geometric proportions...|$|E
40|$|The {{evolution}} of non-metric digital cameras and its integration with direct orientation sensors (GPS/INS), make feasible some applications that require fast mapping, like thematic and cadastral mapping, disasters management and environment monitoring. However, the accuracies of the GPS/INS sensors {{are usually not}} enough to generate a stereo-model without <b>vertical</b> <b>parallax,</b> hindering the stereoscopic visualization of the scene and affecting the 3 D reconstruction. This paper presents an automatic methodology for removing the <b>vertical</b> <b>parallax</b> in the model, based on a modified coplanarity model. Some tie points are automatically measured in the model using area-based correspondence methods, integrating methods to reduce the search space and an a priori analysis of the matching areas to increase the robustness of the process. After the EO parameters adjustment, the images are normalized through an epipolar resampling, {{in order to provide}} a suitable stereoscopic visualization and to facilitate the process of automatic Digital Terrain Model (DTM) generation. A methodology for DTM generation, based on the adjusted EO parameters and epipolar images is presented as well. Some experiments in a test area were performed, and the results obtained are discussed, showing the effectiveness of the proposed approach. 1...|$|E
30|$|Wang et al. {{described}} {{experimental results}} demonstrating feasibility of this method, with residuals from the fitted straight lines {{of less than}} 1 mm, and a root mean square of the <b>vertical</b> <b>parallax</b> of {{less than half of}} a pixel. Unlike the image space-based method, the PRP method uses the distance on the PRP as the pixel distance between the neighboring control points in epipolar image space; as a result, the horizontal parallax may not be proportional to the ground height.|$|E
40|$|Human {{stereo vision}} works by fusing {{a pair of}} {{perspective}} images with a purely horizontal parallax. Recent developments suggest that very few varieties of multiperspective stereo pairs exist. In this paper, we introduce a new stereo model, which we call epsilon stereo pairs, for fusing a broader class of multiperspective images. An epsilon stereo pair consists of two images with a slight <b>vertical</b> <b>parallax.</b> We show many multiperspective camera pairs that do not satisfy the stereo constraint can still form epsilon stereo pairs. We then introduce a new ray-space warping algorithm to minimize stereo inconsistencies in an epsilon pair using multiperspective collineations. This makes epsilon stereo model a promising tool for synthesizing close-to-stereo fusions from many non-stereo pairs. ...|$|E
40|$|This {{report has}} be written {{within the scope}} of the course TEL- 7403 summer 1995 under the {{direction}} of Prof. Janusz Konrad, my director of research. The main aim of this work is to lay out useful geometric models for further study in stereoscopic video processing. The fundamental concepts in stereoscopic processing are reviewed in company with geometric models. We try describe the concerned problems not only by giving simply a definition but also by giving a mathematical analysis. Another aim is to develop a technique to eliminate <b>vertical</b> <b>parallax</b> {{due to the fact that}} the sensor planes are not parallel in a toed-in camera setup. Finally some stereoscopic properties of human visual system are mentioned. i Content...|$|E
40|$|The stereo panoramas {{are limited}} to {{reproducing}} only horizontal parallax. The lack of <b>vertical</b> <b>parallax</b> prevents the viewer from gaining stereo sensation if, for example, the virtual camera is twisted around the optical axis or is oriented to the polar regions. Furthermore, {{in the case of}} spherical panoramas [NK 00], the output image quality tends to degrade significantly towards the poles. With current omnidirectional imaging apparatus such as parabolic mirrors, it is difficult to obtain a 360 -degree image slice with uniform resolution. Previous IBR systems based on the plenoptic function have some problems as follows. In Light Field Rendering and The Lumigraph, the allowable viewing space is affected by the geometric constraints of the acquisition system configured to work with the chose...|$|E
40|$|This paper {{proposes a}} {{holographic}} printer, which produces 3 -D hard copies of computer processed objects. For {{the purpose of}} automatic making of 3 -D hard copies of distortion free, a new method to synthesize holographic stereogram is proposed. It is is flat format and lippmann type holographic stereogram which can be printed by one optical step. The proposed hologram has not only horizontal parallax but <b>vertical</b> <b>parallax,</b> so that the reconstructed image is completely free from distor-tions. Though a basic experiment, a holographic stereogram of 8. 0 x 6. 4 cm 2 was synthesized and a 3 -D image is correctly reconstructed. In this paper the principle and the method of the new technique are described, and the system constitution and {{the problems with the}} holographic 3 -D printer are also discussed. 1...|$|E
