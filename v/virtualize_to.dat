1|504|Public
40|$|The {{research}} on useful novelty {{control is a}} {{research on}} artificiality, self-organizing ratio-nality, useful novelty, creativity, innovation and artifacts. The research is an analyti-cal investigation of how artificiality is in con-trol. Three system transitions are suggested to understand the control: higher-level cog-nition is an aggregation of a lower-level cog-nition and can itself be an aggregation to a phenomenal cognition. Each cognitive level the autonomy and capacity of the virtuality increases: lower-level will <b>virtualize</b> <b>to</b> con-cepts, the higher-level will adapt the con-cepts, the phenomenal-level experiences the concepts. The virtuality has a clear evolu-tionary advantage {{but there is a}} catch, it can be destroyed in a blink. Sustainability is reached when virtuality links to physical properties, and externalized to the physical world. The virtuality becomes even more fit when it is embedded in artifacts. Artifacts seem to have their own evolution and become a second example for the HL-architecture. Two possible natural implementations of the HL-architecture are recognized and will be used in the defense of this research. ...|$|E
50|$|With {{the advent}} of {{virtualization}} for server consolidation, {{a lot of effort}} has gone into making the x86 architecture easier <b>to</b> <b>virtualize</b> and <b>to</b> ensure better performance of virtual machines on x86 hardware.|$|R
25|$|<b>Virtualized</b> {{interrupt}} <b>to</b> {{speed up}} virtual 8086 mode.|$|R
5000|$|Different {{types of}} testing suggest {{different}} types of test environments, {{some or all of}} which may be <b>virtualized</b> <b>to</b> allow rapid, parallel testing to take place. For example, automated user interface tests may occur across several virtual operating systems and displays (real or virtual). Performance tests may require a normalized physical baseline hardware configuration, so that performance test results can be compared over time. Availability or durability testing may depend on failure simulators in virtual hardware and virtual networks.|$|R
40|$|This paper {{presents}} a DHT-based grid resource indexing and discovery (DGRID) approach. With DGRID, resource-information data is stored {{on its own}} administrative domain and each domain, represented by an index server, is <b>virtualized</b> <b>to</b> several nodes (virtual servers) subjected {{to the number of}} resource types it has. Then, all nodes are arranged as a structured overlay network or distributed hash table (DHT). Comparing to existing grid resource indexing and discovery schemes, the benefits of DGRID include improving the security of domains, increasing the availability of data, and eliminating stale data. Singapore-MIT Alliance (SMA...|$|R
50|$|The April 2012 {{releases}} by IBM of PowerLinux {{were designed}} specifically to run the Linux OS on the company’s POWER7-based systems. Unlike servers built on the Intel Xeon processor, an x86 descendant with two threads per core, the POWER7 processor provides four threads per core. POWER-based servers are <b>virtualized</b> <b>to</b> provide 60 to 80 percent utilization, compared to a typical 40-percent rate for x86 processors. The PowerVM virtualization program has a Common Criteria Evaluation Assurance (CC) level of 4+, with zero security vulnerabilities reported, as well as unlimited memory use.|$|R
5000|$|... 1) The {{application}} <b>to</b> be <b>virtualized</b> needs <b>to</b> {{be installed}} after opening Cameyo. If it is previously installed, {{it will have}} to be uninstalled and reinstalled once Cameyo is in capture mode.|$|R
40|$|Abstract — This paper {{presents}} a DHT-based grid resource indexing and discovery (DGRID) approach. With DGRID, resource-information data is stored {{on its own}} administrative domain and each domain, represented by an index server, is <b>virtualized</b> <b>to</b> several nodes (virtual servers) subjected {{to the number of}} resource types it has. Then, all nodes are arranged as a structured overlay network or distributed hash table (DHT). Comparing to existing grid resource indexing and discovery schemes, the benefits of DGRID include improve security of domains, increase availability of data, and elimination of stale data. Index Terms — Grid, resource indexing and discovery, DHT, availabilit...|$|R
5000|$|Providing an {{interface}} <b>to</b> <b>virtualized</b> support hardware, {{for example}} a GPU ...|$|R
5000|$|Parallels Workstation is able <b>to</b> <b>virtualize</b> a {{full set}} of {{standard}} PC hardware, including: ...|$|R
5000|$|IBM Storwize V7000 - Capacity up to 1.92PB and the {{capability}} <b>to</b> <b>virtualize</b> external storage ...|$|R
2500|$|Parallels Desktop for Mac is able <b>to</b> <b>virtualize</b> a {{full set}} of {{standard}} PC hardware, including ...|$|R
5000|$|IBM Storwise V7000 Gen2 - Capacity up to 4PB and the {{capability}} <b>to</b> <b>virtualize</b> external storage ...|$|R
5000|$|Parallels Desktop for Mac is able <b>to</b> <b>virtualize</b> a {{full set}} of {{standard}} PC hardware, including ...|$|R
5000|$|... 4) Cameyo {{makes it}} {{possible}} <b>to</b> <b>virtualize</b> multiple applications {{at the same time}} into one executable file ...|$|R
5000|$|<b>Virtualize</b> {{data sources}} <b>to</b> support {{migration}} from legacy data stores without modifying the applications {{that rely on}} them.|$|R
40|$|In this paper, {{we present}} a network {{function}} virtualization (NFV) architecture <b>to</b> deploy different <b>virtualized</b> network functions (VNF) on an optical transport network. NFV concepts do not only apply to data plane functions (i. e., packet processing or forwarding), but also to control plane functions, such as path computation. First, {{we focus on the}} IT and network resources that are <b>virtualized</b> <b>to</b> provide the required VNFs. Second, we provide an example of VNF on top of the virtualized infrastructure, by proposing a path computation element (PCE) architecture to deploy a PCE by means of NFV. The instances of the virtualized PCE are deployed on demand, but they are perceived as a single-network element. We present the benefits of such approach by providing experimental validation...|$|R
5000|$|Where {{mobile app}} {{virtualization}} is mainly designed <b>to</b> <b>virtualize</b> individual application sessions, VMI {{is designed to}} deliver full mobile environments ...|$|R
50|$|The App-V client {{presents}} the user with a neat, locally installed application experience for <b>virtualized</b> applications. Access <b>to</b> start the <b>virtualized</b> application appears <b>to</b> be {{identical to the}} locally install application, as extensions for the application are integrated into the user's desktop shell by the App-V client. When two or more virtual applications have a dependency on each other, the individual virtualized applications may also be configured to run together in a single isolated bubble.|$|R
30|$|Interestingly, in {{the late}} 1970 s, a {{technology}} was proposed for this aim: computer virtualization [30 – 32]. It was a heated topic thereat, after IBM set up the virtual machine monitor (VMM) in the 1960 s. The goal {{was to make a}} mainframe that could perform more than one operating system (OS). Then arose the virtual machine (VM), which is software made machine. A single mainframe could run multiple VMs, each with its own OS. In this context, <b>to</b> <b>virtualize</b> means <b>to</b> create an abstraction layer between the hardware and the OS. This abstraction layer “hides” and “homogenizes” hardware resources, allowing any OS to run concurrently in the same physical machine. In a broader sense, <b>to</b> <b>virtualize</b> can be defined as the act of creating the necessary conditions to support virtual versions of entities that perform as the original ones. According to this definition, the VMM creates a virtual machine abstraction, which performs like the real one from the operating system point of view.|$|R
50|$|In the IBM SAN Volume Controller PPRC is used <b>to</b> mirror a <b>virtualized</b> {{storage volume}} <b>to</b> remote (or the same) cluster.|$|R
40|$|Abstract. In this paper, we {{describe}} an ontology-based collaboration model for supporting semantic interoperability in open networked sys-tems. We characterize discovery and matchmaking semantic interoper-ability services for retrieving information resources semantically {{related to a}} target request, to enable a coordinated and <b>virtualized</b> access <b>to</b> distributed heterogeneous information resources...|$|R
40|$|This paper {{discusses}} {{and brings}} together {{a detailed analysis}} of virtualization implemented at various levels of computing infrastructure, keeping in mind and providing detailed transition process adopted for transition from a classical <b>to</b> <b>virtualized</b> data center. It focuses on emerging trends or areas related with storage virtualization. Further, its various network level virtualization based implementations has been presented and analyzed. And finally it sums up with step by step process of transition from a classical <b>to</b> <b>virtualized</b> data center...|$|R
50|$|<b>To</b> <b>virtualize</b> Windows 8 or Windows Server 2012 {{as a guest}} {{operating}} system, the ESXi version must be 5.0 update 1 or later.|$|R
40|$|We {{propose a}} {{virtualization}} architecture for NoC-based reconfigurable systems. The motivation {{of this work}} {{is to develop a}} service-oriented architecture that includes Partial Reconfigurable Region as a Service (PRRaaS) and Processing Element as a Service (PEaaS) for software applications. According to the requirements of software applications, new PEs can be created on-demand by (re) configuring the logic resource of the PRRs in the FPGA, while the configured PEs can also be <b>virtualized</b> <b>to</b> support multiple application tasks at the same time. As a result, such a two-level virtualization mechanism, including the gate-level virtualization and the PE-level virtualization, enables an SoC to be dynamically adapted to changing application requirements. Therefore, more software applications can be performed, and system performance can be further enhanced. Comment: Presented at Second International Workshop on FPGAs for Software Programmers (FSP 2015) (arXiv: 1508. 06320...|$|R
40|$|ISBN : 978 - 3 - 642 - 02080 - 3 / ISSN : 1867 - 8211 International audienceAutomatic Service {{framework}} named Scheduling, Reconfiguration and Virtualization (SRV) {{is developed}} in CARRIOCAS project to enhance existing Telecom network infrastructures for supporting grid applications sharing IT resources interconnected with ultra-high performance optical networks. From {{the requirements of}} Grid applications a classification is pro po sed to specify the network services and their attributes. In large-scale collaborative environments, SRV solution is described to enable automatic network service operations according to high-performance computing service access. The resources hosted at datacenters are <b>virtualized</b> <b>to</b> be attached to transport network infrastructure offering uniform interfaces towards external cus tomers. New level of service bindings is defined with network services du ring executions of Grid applications' workflows. On-demand intensive com puting and visualization services scenario is described in Telecom environment...|$|R
40|$|A Cookbook full of {{practical}} and applicable recipes {{that will enable}} you to use the full capabilities of OpenStack like never before. This book is aimed at system administrators and technical architects moving from a <b>virtualized</b> environment <b>to</b> cloud environments with familiarity of cloud computing platforms. Knowledge of virtualization and managing linux environments is expected...|$|R
30|$|The {{diagnosis}} {{is more complex}} when the guest is isolated from its external environment and an additional virtualization layer is introduced. It is therefore necessary to have powerful and efficient tools to diagnose {{the root cause of}} unexpected delays at low granularity when they occur in a <b>virtualized</b> environment. <b>To</b> our knowledge, no such tool was available.|$|R
50|$|Although the company’s {{software}} reportedly uses fewer system resources {{because it}} does not require each <b>virtualized</b> server <b>to</b> have an independent operating system, its overall flexibility is limited. For example, each virtualized Virtuozzo server must have the same version of the same operating system, and when running Linux, the operating systems' kernel must be modified from the standard version.|$|R
50|$|Laura M. Haas is an American {{computer}} scientist noted for her research in database systems and information integration. She {{is best known}} for creating systems and tools for the integration of heterogeneous data from diverse sources, including federated technology that <b>virtualizes</b> access <b>to</b> data, and mapping technology that enables non-programmers to specify how data should be integrated.|$|R
50|$|Server I/O is a {{critical}} component to successful and effective server deployments, particularly with <b>virtualized</b> servers. <b>To</b> accommodate multiple applications, virtualized servers demand more network bandwidth and connections to more networks and storage. According to a survey, 75% of virtualized servers require 7 or more I/O connections per device, {{and are likely to}} require more frequent I/O reconfigurations.|$|R
30|$|The goal of NFV is <b>to</b> <b>virtualize</b> network {{functions}} into {{software applications}} {{that can be}} run on standard servers or as virtual machines running on those servers.|$|R
50|$|In 2015, IBM re-badged the {{virtualization}} functionality as Spectrum <b>Virtualize,</b> {{in order}} <b>to</b> align {{it with the}} IBM software-defined storage naming conventions and to highlight the interoperability aspect.|$|R
40|$|Today’s IT {{infrastructure}} {{is more and}} more being virtualized. Almost every kind of component like servers, storage and network devices can be <b>virtualized</b> <b>to</b> provide a high available, scalable and sustainable environment. Server consolidation- replacing many small servers by one large physical machine- leads to an increased utilization of hardware resources, decreased power consumption for operation and cooling. Virtualization also changed the way of day-to-day operations of IT administrators. The deployment of virtual machines is an easier and simpler process than installing new physical hardware and the possibilities of moving virtual machines between host systems reduces maintenance windows and downtimes. The virtualization of hardware also introduced new ways of monitoring and measuring performance of virtualized IT services. The integration of these features in network management and monitoring systems is needed for a secure and proactive operation of virtualized infrastructures. This paper presents the idea and development process of integrating VMware vSphere virtual infrastructures in an open source enterprise-grade network management system called OpenNMS...|$|R
40|$|Cloud {{computing}} is {{an emerging}} technology where IT resources are <b>virtualized</b> <b>to</b> users {{as a set}} of a unified computing resources on a pay per use basis. The resources are dynamically chosen to satisfy a user Service Level Agreement and a required level of performance. Divisible load applications occur in many scientific and engineering applications and can easily be mapped to a Cloud using a master-worker pattern. However, those applications pose challenges to obtain the required performance. We model divisible load applications tasks processing on a set of cloud resources. We derive a novel model and formulas for computing the blocking probability in the system. The formulas are useful to analyze and predict the behavior of a divisible load application on a chosen set of resources to satisfy a Service Level Agreement before the implementation phase, thus saving time and platform energy. They are also useful as a dynamic feedback to a cloud scheduler for optimal scheduling. We evaluate the model in a set of illustrative scenarios...|$|R
40|$|This paper {{presents}} a middleware for building context-aware applications. One {{of the main}} components, Device Information Access (DIA), is discussed in detail. Since many kinds of devices (e. g., RFID, GPS, Bluetooth, etc.) {{can be used to}} collect the context information, the middleware defines the Device Information Access component to communicate with different devices. A set of interfaces are devised in DIA, and the common functions such as getting and setting a data element are defined in the interfaces. For each device, we shall provide an implementation of the interfaces to communicate with the corresponding servers or software agents. DIA can communicate with the software agents or servers using various protocols such as RMI, Web Services, and REST. In this way the access to the hardware are encapsulated by the middleware and <b>virtualized</b> <b>to</b> the end-point applications. The architecture of the middleware and the functions of DIA are discussed, and an empirical application is also developed to validate our design...|$|R
