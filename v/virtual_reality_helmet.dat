21|10000|Public
5|$|Mulder uses a {{government}} source {{to find a}} secret T3 line in Fairfax County, Virginia, one that the AI uses to access the Internet. He also finds the trailer that {{is connected to the}} T3 line. Meanwhile, Esther forces Scully to drive to David's house. However, they find that the house has been destroyed. Esther admits that she and David had been planning to transfer their consciousness into cyberspace to enter the AI. Gelman, however, thought the idea was too dangerous. Esther also admits that she and David were in love, and were having an affair behind Gelman's back. Meanwhile, Mulder finds much computer hardware inside the trailer. He also finds David’s dead body, with a <b>virtual</b> <b>reality</b> <b>helmet</b> on his head. Suddenly, Mulder is constrained by moving cables and wires, and experiences a strange vision in which he is in a hospital where nurses threaten to amputate his limbs unless he reveals Kill Switch's location. Meanwhile, the AI locates Scully and Esther driving near a swing bridge. They become trapped on the bridge after the AI manipulates its drawing mechanism, causing Scully to persuade Esther to throw the laptop into the water. Just as it hits the water it is destroyed by the defense satellite's laser strike.|$|E
5000|$|A NASA Ames Research Center {{scientist}} {{presents a}} prototype <b>Virtual</b> <b>Reality</b> <b>helmet</b> called Cyberiad.|$|E
50|$|The virtual cocoon is a proposed, in {{development}} <b>virtual</b> <b>reality</b> <b>helmet</b> that will allegedly stimulate {{all five of}} the human senses when it is finished.|$|E
50|$|Each team elects one pilot {{which takes}} seat in an {{individual}} spaceship cockpit. Using <b>virtual</b> <b>reality</b> <b>helmets</b> and an advanced set of controls, they must race each other from Saturn to Titan, avoiding asteroids, fighting space pirates and ultimately landing on the moon in a 3D simulation game. All the action is shown in huge screens for the audience present at the show as well as aired to the television.|$|R
5000|$|According to Wayne Carlson, {{professor}} of design at Ohio State University: [...] "The Large Expanse, Extra Perspective (LEEP) optical system {{was designed by}} Eric Howlett in 1979 and provides the basis {{for most of the}} current <b>virtual</b> <b>reality</b> <b>helmets</b> available today. The combined system gave a very wide field of view stereoscopic image. The users of the system have been impressed by the sensation of depth of view in the scene and the corresponding realism. The original LEEP system was redesigned used for the NASA Ames Research Center in 1985 for their first <b>virtual</b> <b>reality</b> installation, the VIEW (Virtual Interactive Environment Workstation) by Scott Fisher." ...|$|R
5000|$|A <b>virtual</b> <b>reality</b> {{simulator}} (<b>virtual</b> amusement ride/virtual gaming simulator/virtual motion simulator) is {{the equipment}} that is used for human immersion in <b>virtual</b> <b>reality</b> {{with the purpose of}} entertainment of the public. A virtual amusement in the strict sense can not be considered a computer with a <b>virtual</b> <b>reality</b> glasses (<b>helmet)</b> and game content.Attractions of <b>virtual</b> <b>reality</b> besides hardware and software use the additional means to enhance the immersion effect, for example, water spray, the effect of wind, vibration, physical motion etc. The same technique was used in the X-d cinema, but there are two significant differences between them and simulators of virtual reality: ...|$|R
50|$|Within the {{following}} weeks, only Boulanger had issued a clear statement on its {{application of the}} agreement. The brand has created a dedicated online marketplace and agrees to sell a number of products in stores, such as a <b>virtual</b> <b>reality</b> <b>helmet,</b> an 'intelligent' keyring or a connected lamp.|$|E
5000|$|In 1991, the Sega VR was {{announced}} and demonstrated, a <b>virtual</b> <b>reality</b> <b>helmet</b> {{that was never}} distributed. In 1993 Pioneer released the LaserActive system which had a bay for various [...] "PAC's" [...] including the Sega PAC and the NEC PAC. The unit was 3D capable {{with the addition of}} the LaserActive 3D goggles (GOL-1) and an adapter (ADP-1). The Virtual Boy was brought out in 1995, a console equipped with a <b>virtual</b> <b>reality</b> <b>helmet</b> that provided a stereoscopic rendering of 384x224 pixels per eye in monochrome (black and red) and for which 12 games were available in late 1995. Marketing was a dismal failure and production was halted in late 1996. SimulEyes PC VR goggles (a consumer version of CrystalEyes), bundled with the game Descent: Destination Saturn, was released in 1995.|$|E
50|$|The GF1 was co-developed by Advanced Gravis and Forte Technologies (creator of the VFX1 Headgear <b>virtual</b> <b>reality</b> <b>helmet)</b> and {{produced}} by Integrated Circuit Systems under the ICS11614 moniker. The chip was actually {{derived from the}} Ensoniq OTTO (ES5506) chip, a next-generation version of the music-synthesizer chip found in the Ensoniq VFX and its successors.|$|E
5000|$|The {{music video}} was {{directed}} by Marc Ball {{and serves as a}} solution to the previous five music videos, all of which featured a Quantum Leap theme. After leaving the [...] "Texas Tornado" [...] video, Lawrence flies through a vortex showing scenes from the previous videos. It then features him and a friend using <b>Virtual</b> <b>Reality</b> <b>helmets.</b> By wearing the helmets, the rest of the video shows Lawrence singing [...] "If the World Had a Front Porch," [...] literally on a front porch, as it flies over various American landscapes. The second verse shows views of drugs being dealt, prostitutes walking the streets, footage of the 1992 Los Angeles riots, the O.J. Simpson police chase and violent footage from the Gulf War before the <b>virtual</b> <b>reality</b> goggles are [...] "overloaded" [...] and the word [...] "ABORT" [...] flashes across the computer and video screen and the scenes are replaced with more pleasant clips of school graduations, young children playing with small animals, weddings, couples having their first child and family dinners. At the end of the video, Lawrence flies back through the vortex on the porch in a bubble.|$|R
40|$|In {{this article}} we present {{the results of our}} {{research}} related to the study of correlations between specific visual stimulation and the elicited brain's electro-physiological response collected by EEG sensors from a group of participants. We will look at how the various characteristics of visual stimulation affect the measured electro-physiological response of the brain and describe the optimal parameters found that elicit a steady-state visually evoked potential (SSVEP) in certain parts of the cerebral cortex where it can be reliably perceived by the electrode of the EEG device. After that, we continue with a description of the advanced machine learning pipeline model that can perform confident classification of the collected EEG data in order to (a) reliably distinguish signal from noise (about 85 % validation score) and (b) reliably distinguish between EEG records collected from different human participants (about 80 % validation score). Finally, we demonstrate that the proposed method works reliably even with an inexpensive (less than $ 100) consumer-grade EEG sensing device and with participants who do not have previous experience with EEG technology (EEG illiterate). All this in combination opens up broad prospects for the development of new types of consumer devices, [e. g. ] based on <b>virtual</b> <b>reality</b> <b>helmets</b> or augmented <b>reality</b> glasses where EEG sensor can be easily integrated. The proposed method can be used to improve an online user experience by providing [e. g. ] password-less user identification for VR / AR applications. It can also find a more advanced application in intensive care units where collected EEG data can be used to classify the level of conscious awareness of patients during anesthesia or to automatically detect hardware failures by classifying the input signal as noise...|$|R
50|$|Cargo {{is loaded}} {{through a large}} aft ramp that {{accommodates}} rolling stock. The Y-20 incorporates a shoulder wing, T-tail, rear cargo-loading assembly and heavy-duty retractable landing gear, consists of three rows, {{with a pair of}} wheels for each row, totaling six wheels for each side. The structural test was completed in 194 days as opposed to the 300 days originally planned, thanks to the successful development and application of an automated structural strength analysis system. In comparison, similar work for Xian JH-7 took a year. According to the deputy general designer, the shortest take-off distance of Y-20 is 600 to 700 meters. Y-20 incorporates a total of four LCD EFIS, and the development of EFIS for Y-20 utilizes <b>virtual</b> <b>reality</b> via <b>helmet</b> mounted display. Eight types of different relays used on Y-20 are developed by Guilin Aerospace Co., Ltd. a wholly own subsidiary of China Tri-River Aerospace Group Co., Ltd.(中国三江航天集团), which is also known as the 9th Academy of China Aerospace Science and Industry Corporation (CASIC).|$|R
50|$|An {{updated version}} called Missile Command 3D was {{released}} for the Atari Jaguar in 1995. It contains three {{versions of the}} game: Classic (a straight port of the arcade game), 3D (graphically upgraded and with a rotating viewpoint), and Virtual. It is the only game that works with the <b>virtual</b> <b>reality</b> <b>helmet</b> from Virtuality.|$|E
50|$|In {{addition}} to the Jackie Chan Adventures, Chan was a guest star in Drake & Josh. Stacie Chan plays Marta, asking Josh if he can see Jupiter with her <b>Virtual</b> <b>Reality</b> <b>Helmet.</b> Additional live action work includes guest roles in Mr. Show with Bob and David and Charmed; additional voice-over guest roles include What's New, Scooby-Doo? and Fillmore!.|$|E
50|$|F-Letter is {{the third}} studio album by post-hardcore band Frodus, {{originally}} released in 1996 through Double Duece NYC. To fund the recording for the album, Shelby Cinca sold a <b>virtual</b> <b>reality</b> <b>helmet</b> at a Doom tournament held by a now-defunt computer store. The album has been reissued many times on both CD and vinyl formats {{through a variety of}} record labels.|$|E
40|$|The {{objective}} of a Visual Telepresence System {{is to provide}} the operator with a high fidelity image from a remote stereo camera pair linked to a pan/tilt device such that the operator may reorient the camera position by use of head movement. Systems such as these which utilise <b>virtual</b> <b>reality</b> style <b>helmet</b> mounted displays {{have a number of}} limitations. The geometry of the camera positions and of the displays is generally fixed and is most suitable only for viewing elements of a scene at a particular distance. To address such limitations, a prototype system has been developed where the geometry of the displays and cameras is dynamically controlled by the eye movement of the operator. This paper explores why it is necessary to actively adjust the display system as well as the cameras and justifies the use of mechanical adjustment of the displays as an alternative to adjustment by electronic or image processing methods. The electronic and mechanical design is described including optical arrangements and control algorithms. The performance and accuracy of the system is assessed with respect to eye movement...|$|R
40|$|Visual Telepresence {{system which}} utilize <b>virtual</b> <b>reality</b> style <b>helmet</b> mounted {{displays}} {{have a number}} of limitations. The geometry of the camera positions and of the display is fixed and is most suitable only for viewing elements of a scene at a particular distance. In such a system, the operator's ability to gaze around without use of head movement is severely limited. A trade off must be made between a poor viewing resolution or a narrow width of viewing field. To address these limitations a prototype system where the geometry of the displays and cameras is dynamically controlled by the eye movement of the operator has been developed. This paper explores the reasons why is necessary to actively adjust both the display system and the cameras and furthermore justifies the use of mechanical adjustment of the displays as an alternative to adjustment by electronic or image processing methods. The electronic and mechanical design is described including optical arrangements and control algorithms, An assessment of the performance of the system against a fixed camera/display system when operators are assigned basic tasks involving depth and distance/size perception. The sensitivity to variations in transient performance of the display and camera vergence is also assessed...|$|R
40|$|Eye {{tracking}} {{technology is}} advancing swiftly and {{many areas of}} research have begun taking advantage of this. Existing eye trackers project gaze onto a 2 D plane, {{whether it be the}} display of a head mounted <b>virtual</b> <b>reality</b> (VR) <b>helmet</b> or an image of a real life scene the user is in. This allows us to easily analyze what a viewer is looking at, but limits classification of gaze behaviors from this type of signal. Instead, a system that takes into account head movements within the same space as gaze velocity allows researchers to classify more advanced gaze behaviors such as smooth pursuits and fixations resulting from vestibulo-ocular reflex. For this work data is collected in real world environments where head and gaze movements are recorded over a variety of tasks. The resulting data is then used to construct a distribution of naturally occurring gaze behaviors. This distribution is then used to drive a VR data collection experiment that elicits specific gaze behaviors such as fixations and saccades with specific velocities and directions. A dataset of 12 subjects was collected while subjects play a shooting game in the virtual world. Data was analyzed to see if the intended eye movements were produced, and also to compare the eye movements that occur in fast versus slow presentation of targets...|$|R
50|$|Lewis takes {{advantage}} of work in San Francisco to contact Joseph who is working in the hi-tech industry there. Joseph persuades him to try out a new <b>virtual</b> <b>reality</b> <b>helmet,</b> {{which turns out to}} have a fault that disables cyborgs' implanted monitors for 24 hours. Joseph and Lewis can now talk freely, without Company eavesdropping. Initially reluctant, Joseph drives Lewis to Bodega Bay to talk to Juan Bautista who was the last cyborg to see Mendoza. They give him a dose of VR and then pump him for information.|$|E
50|$|Motor imagery {{has been}} studied using the {{classical}} methods of introspection and mental chronometry. These methods have revealed that motor images retain many of the properties, in terms of temporal regularities, programming rules and biomechanical constraints, which are observed in the corresponding real action {{when it comes to}} execution. For instance, in an experiment participants were instructed to walk mentally through gates of a given apparent width positioned at different apparent distances. The gates were presented to the participants with a 3-D visual display (a <b>virtual</b> <b>reality</b> <b>helmet)</b> which involved no calibration with external cues and no possibility for the subject to refer to a known environment. Participants were asked to indicate the time they started walking and the time they passed through the gate. Mental walking time was found to increase with increasing gate distance and decreasing gate width. Thus, it took the participant longer to walk mentally through a narrow gate than to walk through a larger gate placed at the same distance. This finding led neurophysiologists Marc Jeannerod and Jean Decety to propose that there is a similarity in mental states between action simulation and execution.The functional equivalence between action and imagination goes beyond motor movements. For instance similar cortical networks mediate music performance and music imagery in pianists.|$|E
50|$|Mulder uses a {{government}} source {{to find a}} secret T3 line in Fairfax County, Virginia, one that the AI uses to access the Internet. He also finds the trailer that {{is connected to the}} T3 line. Meanwhile, Esther forces Scully to drive to David's house. However, they find that the house has been destroyed. Esther admits that she and David had been planning to transfer their consciousness into cyberspace to enter the AI. Gelman, however, thought the idea was too dangerous. Esther also admits that she and David were in love, and were having an affair behind Gelman's back. Meanwhile, Mulder finds much computer hardware inside the trailer. He also finds David’s dead body, with a <b>virtual</b> <b>reality</b> <b>helmet</b> on his head. Suddenly, Mulder is constrained by moving cables and wires, and experiences a strange vision in which he is in a hospital where nurses threaten to amputate his limbs unless he reveals Kill Switch's location. Meanwhile, the AI locates Scully and Esther driving near a swing bridge. They become trapped on the bridge after the AI manipulates its drawing mechanism, causing Scully to persuade Esther to throw the laptop into the water. Just as it hits the water it is destroyed by the defense satellite's laser strike.|$|E
3000|$|... of {{existing}} data types, analytical methods, visualization techniques and tools, {{with a particular}} emphasis placed on surveying the evolution of visualization methodology over the past years. Based on the results, we reveal disadvantages {{of existing}} visualization methods. Despite the technological development of the modern world, human involvement (interaction), judgment and logical thinking are necessary while working with Big Data. Therefore, the role of human perceptional limitations involving large amounts of information is evaluated. Based on the results, a non-traditional approach is proposed: we discuss how the capabilities of Augmented <b>Reality</b> and <b>Virtual</b> <b>Reality</b> {{could be applied to}} the field of Big Data Visualization. We discuss the promising utility of Mixed Reality technology integration with applications in Big Data Visualization. Placing the most essential data in the central area of the human visual field in Mixed Reality would allow one to obtain the presented information {{in a short period of}} time without significant data losses due to human perceptual issues. Furthermore, we discuss the impacts of new technologies, such as <b>Virtual</b> <b>Reality</b> displays and Augmented <b>Reality</b> <b>helmets</b> on the Big Data visualization as well as to the classification of the main challenges of integrating the technology.|$|R
40|$|This paper {{presents}} our novel concept Outdoor <b>Virtual</b> <b>Reality.</b> By using outdoor {{augmented reality}} techniques we propose to build very wide area <b>virtual</b> <b>reality</b> systems, outdoor <b>virtual</b> <b>reality.</b> The concept of outdoor <b>virtual</b> <b>reality</b> is compared and contrasted to traditional definitions of augmented <b>reality</b> and <b>virtual</b> <b>reality.</b> We present our flexible Tinmith-evo 5 software architecture {{as a platform}} to build outdoor <b>virtual</b> <b>reality</b> applications. We have constructed two outdoor <b>virtual</b> <b>reality</b> applications, a 3 D visualisation tool and an outdoor game. ...|$|R
50|$|<b>Virtual</b> <b>reality</b> {{addiction}} is {{an addiction to}} the use of <b>virtual</b> <b>reality</b> or <b>virtual,</b> immersive environments. Currently, interactive virtual media (such as social networks) are referred to as <b>virtual</b> <b>reality,</b> whereas future <b>virtual</b> <b>reality</b> refers to computer-simulated, immersive environments or worlds. Experts warn about the dangers of <b>virtual</b> <b>reality,</b> and compare the use of <b>virtual</b> <b>reality</b> (both in its current and future form) {{to the use of}} drugs, bringing with these comparisons the concern that, like drugs, users could possibly become addicted to <b>virtual</b> <b>reality.</b>|$|R
40|$|Colloque avec actes et comité de lecture. The aim of {{this paper}} is to assess the {{possibility}} of inducing linear vection, using virtual reality device. A comparative study was therefore made between vection produced by moving a part of the visual scene and vection by induced via a <b>virtual</b> <b>reality</b> <b>helmet</b> displaying a specific animation...|$|E
40|$|We are {{interested}} in saccade contingent scene updates where the vi-sual information presented in a display is altered while a saccadic eye movement of an unconstrained, freely moving observer is in progress. Since saccades typically last only several tans of mil-liseconds depending on their size, this poses dif cult constraints on the latency of detection. We have integrated two complemen-tary eye trackers in a <b>virtual</b> <b>reality</b> <b>helmet</b> to simultaneously 1) detect saccade onsets with very low latency and 2) track the gaze with high precision albeit higher latency. In a series of experiments we demonstrate the system s capability of detecting saccade onsets with suf ciantly low latency to make scene changes while a saccade is still progressing. While the method was developed to facilitate studies of human visual perception and attention, it may nd in-teresting applications in human-computer interaction and computer graphics...|$|E
40|$|Abstract: The human stress {{response}} evolved to maximize an individual’s {{probability of survival}} when threatened. The present study addressed whether physical danger modulates perception of an unrelated ambiguous threat and, if so, to what extent this response is sex-specific. The authors utilized a first-time tandem skydive as a stressor, which had been previously validated as producing a highly-controlled, genuinely stressful environment. In a counter-balanced within-subjects design, participants wore a <b>virtual</b> <b>reality</b> <b>helmet</b> to complete an emotion-identification task during the plane’s ascent (stress condition) and in the laboratory (control condition). Participants were presented static male faces morphed between 20 - 80 % aggression, which gradually emerged from degraded images. Using a binary forced-choice design, participants identified each ambiguous face as aggressive or neutral. Results showed that participants characterized emotion more rapidly under stress versus control conditions. Unexpectedly, the results also show that while women were more sensitive to affect ambiguity than men under control conditions, they exhibited a marked decrease in sensitivity equivalent to men while under stress...|$|E
50|$|<b>Virtual</b> <b>Reality</b> Scenarios: <b>virtual</b> <b>reality</b> based {{training}} {{exercises to}} teach procedural skills {{in situations of}} varying complexities. (e.g. <b>virtual</b> <b>reality</b> surgical simulation).|$|R
40|$|The <b>Reality</b> <b>Helmet</b> is an {{interactive}} experience, {{in which the}} user’s vision and hearing is shielded off from the world. Video and sound is nevertheless recorded by the <b>Reality</b> <b>Helmet,</b> but through computer processing it presents sound to the user as vision, and likewise, vision is turned into a soundscape. The result {{is a form of}} artificial synesthesia. Other than as an appreciated art installation, which seems to make people calm and reflective, the <b>Reality</b> <b>Helmet</b> is used to explore relationships between the wearer's sense of presence and the kind of realism provided by the interactive environment. ...|$|R
40|$|The study {{describes}} a therapeutic approach using psycho-dynamic psychotherapy integrating virtual environment (VE) for resolving impotence or better erectile dysfunction (ED) of presumably psychological or mixed origin and premature ejaculation (PE). The plan for therapy consists of 12 sessions (15 if a sexual partner was involved) over a 25 -week period on the ontogenetic development of male sexual identity, {{and the methods}} involved {{the use of a}} laptop PC, joystick, <b>Virtual</b> <b>Reality</b> (VR) <b>helmet</b> with miniature television screen showing a new specially-designed CD-ROM programs using Virtools with Windows 2000 and an audio CD. This study was composed of 30 patients, 15 (10 suffering from ED and 5 PE) plus 15 control patients (10 ED and 5 PE), that underwent the same therapeutic protocol but used an old VR helmet to interact with the old VE using a PC Pentium 133 16 Mb RAM. We also compared this study with another study we carried out on 160 men affected by sexual disorders, underwent the same therapeutic protocol, but treated using a VE created (in Superscape VRT 5. 6) using always Windows 2000 with portable tools. Comparing the groups of patients affected by ED and PE, there emerged a significant positive results value without any important differences among the different VE used. However, we had a % increase of undesirable physical reactions during the more realistic 15 -minute VR experience using Virtools development kit. Psychotherapy alone normally requires long periods of treatment in order to resolve sexual dysfunctions. Considering the particular way in which full- immersion VR involves the subject who experiences it (he is totally unobserved and in complete privacy), we hypothesise that this methodological approach might speed up the therapeutic psycho-dynamic process, which eludes cognitive defences and directly stimulates the subconscious, and that better results could be obtained in the treatment of these sexual disorders. This method can be used by any psychotherapist and it can be used alone or associated with pharmacotherapy prescribed by the urologist/andrologist as part of a therapeutic alliance...|$|R
40|$|Since scalp EEG {{recordings}} {{are measured}} in microvolts, electrical signals may easily interfere during an experiment. As Spehlmann discusses, such interference may be introduced through {{the lights in}} the recording room, a nearby television, or even a computer monitor [Spehlmann, 1991]. Thus, when we consider performing EEG/EP/ERP experiments within a <b>virtual</b> <b>reality</b> <b>helmet</b> containing an eye tracker, electrical interference becomes a real possibility. We tested the effects of wearing a VR 4 virtual reality (VR) helmet containing an ISCAN eye tracker while asking subjects to do a continuous performance task. The results of this task were then analyzed in the frequency domain and compared to results from the same experiment while looking at a computer screen in two different environments. Results indicate that in an environment with other computers, the vertical refresh from the back of a nearby row of computer monitors added more noise to the signal than wearing the VR helmet and eye track [...] ...|$|E
40|$|Immersion and Immersionskunst (immersive art or art of immersion) are {{relatively}} new terms. They originate from the discourses of contemporary computer art, where immersion into synthetic perceptual worlds {{has been a}} lively topic since the late 1980 s and early 1990 s. We are dealing, therefore, with an arts practice {{that has come to}} be called immersion. Immersion, in this context, means to engage with one’s immersion in artificial environments, assisted by technical equipment, for instance a <b>virtual</b> <b>reality</b> <b>helmet</b> or an electronic visor. Through these technologies, humans are finally taken seriously as beings for whom it is natural to immerse themselves – and not only in water, the ‘wet element’, but in elements and environments generally. The method has been common for some time, for instance in the context of pilots’ training in flight simulators; however, the modern problem of hallucination management and immersive change was already anticipated in nineteenth century panoramas. A core aspect of artificial immersion, as a phenomenon, is the potential replacement of whole environments – not only of the images, usually framed, one looks at in galleries. Immersion as a method unframes images and vistas, dissolving the boundaries with their environment...|$|E
40|$|The {{aim of the}} study: The aim of {{this work}} {{is to find out}} the {{possibilities}} to influence the clinical state of the patients suffering with incomplete spinal cord lesion syndrome {{with the help of a}} therapeutic video played through a <b>virtual</b> <b>reality</b> <b>helmet.</b> Methods: The research was conducted with 22 probands (15 males and 7 females) aged between 27 and 76 years (the average age of 55 ± 14 years) from the client of Rehabilitation Centre Kladruby. The probands were divided into two homogenised groups with the same number of members. The control group received a standard rehabilitation programme set by the Rehabilitation Centre. The research group followed the same plan but in addition to this, they were given helmets, and a video with virtual reality was played daily on the total of 30 occasions. The clinical state before conducting the research and after was evaluated using the standard test ASIA impairment scale where the observed transformation was the total of motoric points for the lower limbs. Initial and final examination was conducted by professional and highly trained staff at Kladruby, always doctors. The variance between the initial and the final examination results and the length of stay at the centre were used to set the relative transformation of the clinical state in comparison with the [...] ...|$|E
40|$|Many {{studies have}} been {{conducted}} on the use of <b>virtual</b> <b>reality</b> in education and training. Thisarticle lists examples of such research. Reasons to use <b>virtual</b> <b>reality</b> are discussed. Advantages and disadvantages of using <b>virtual</b> <b>reality</b> are presented, as well as suggestions onwhen to use and when not to use <b>virtual</b> <b>reality.</b> A model {{that can be used to}} determine whento use <b>virtual</b> <b>reality</b> in an education or training course is presented...|$|R
40|$|It is {{estimated}} that by 2020, revenue from <b>virtual</b> <b>reality</b> systems could reach {{one hundred and fifty}} billion dollars (Merel, 2015). The leading investors in <b>virtual</b> <b>reality</b> systems include some of the largest technology companies: Facebook; Google and Microsoft. Asian markets have also indicated a surge in spending on personal virtual equipment. This increased revenue spending has influenced improvements in <b>virtual</b> <b>reality</b> systems and these improvements have led to the proliferation of emerging theories on the effective use of <b>virtual</b> <b>reality</b> systems. As these new theories emerge, it is imperative that policy makers, educators and instructional designers consider the fusion of pedagogy and technology when using <b>virtual</b> <b>reality</b> systems. This presentation will focus on leveraging the affordances of <b>virtual</b> <b>reality</b> systems within K- 12. In this session, the presenters will: (1) focus on the latest technological advances in <b>virtual</b> <b>reality</b> systems; (2) connect <b>virtual</b> <b>reality</b> advances to innovate and scalable best practices within a K- 12 setting; (3) allow participants to engage in <b>virtual</b> <b>reality</b> encounters to establish the key affordances of <b>virtual</b> <b>reality</b> encounters within K- 12 (equipment and software will be demonstrated by the presenters); (4) share current literature on the implementation of <b>virtual</b> <b>reality</b> systems, (5) planning for educational experiences that include a <b>virtual</b> <b>reality</b> component and (6) highlight aspects of the researchers 2 ̆ 7 current research on embedded virtual encounters in K- 12...|$|R
40|$|<b>Virtual</b> <b>reality</b> offers new {{possibilities}} and new challenges {{for teaching and}} learning. For students in elementary mathematics, {{it has been suggested}} that <b>virtual</b> <b>reality</b> offers new ways of representing numeracy concepts in the form of <b>virtual</b> <b>reality</b> manipulatives. The main goal of this thesis is to investigate the effectiveness of using desktop <b>virtual</b> <b>reality</b> as a cognitive tool to enhance the conceptual understanding of numeracy concepts by elementary school children, specifically addition and subtraction. This research investigated the technical and educational aspects of <b>virtual</b> <b>reality</b> manipulatives for children beginning to learn numeracy by implementing a prototype mathematical virtual learning environment (MAVLE) application and exploring its educational effectiveness. This research provides three main contributions. First, the proposed design framework for the <b>virtual</b> <b>reality</b> model for cognitive learning. This framework provides an initial structure that can be further refined or revised to generate a robust design model for <b>virtual</b> <b>reality</b> learning environments. Second, the prototyping and implementation of a practical <b>virtual</b> <b>reality</b> manipulatives application ‘MAVLE’ for facilitating the teaching and learning processes of numeracy concepts (integer addition and subtraction) was proposed. Third, the evaluation of conceptual understanding of students’ achievements and the relationships among the navigational behaviours for the desktop <b>virtual</b> <b>reality</b> were examined, and their impacts on students’ learning experiences were noted. The successful development of the <b>virtual</b> <b>reality</b> manipulatives provides further confirmation for the high potential of <b>virtual</b> <b>reality</b> technology for instructional use. In short, the outcomes of this work express the feasibility and appropriateness of how <b>virtual</b> <b>reality</b> manipulatives are used in classrooms to support students’ conceptual understanding of numeracy concepts. <b>Virtual</b> <b>reality</b> manipulatives may be the most appropriate mathematics tools for the next generation. In conclusion, this research proposes a feasible <b>virtual</b> <b>reality</b> model for cognitive learning that can be used to guide the design of other <b>virtual</b> <b>reality</b> learning environments...|$|R
