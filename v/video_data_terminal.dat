1|8897|Public
40|$|INTRODUCTION The DP 8350 is an 2 L#LS {{technology}} integrated circuit# {{designed to}} provide all control signals for a cathode ray tube (CRT) display system# This application note explains a system using the DP 8350 and the 8080 microprocessor# The design philosophy shows how the DP 8350 interfaces to the 8080 # completing the function of a <b>video</b> <b>data</b> <b>terminal</b> with a minimum component count# After reading and understanding this application note the reader will realize the ease and flexibility of designing video terminals with the DP 8350 ##To thoroughly understand this application note the reader must {{be familiar with the}} DP 8350 and the 8080 microprocessor# The <b>video</b> <b>data</b> <b>terminal</b> described is divided into the following sections# (Figure 1) # The DP 8350 CRT controller (CRTC) # The 8080 mP system which includes ROM# RAM# interrupt instruction port# oscillator# and control support chips# The character generator# The communicat...|$|E
25|$|Force Traffic have a {{range of}} marked and unmarked patrol vehicles, all {{modified}} with the same equipment as response vehicles but with the addition of ANPR/HD <b>video</b> cameras, <b>data</b> <b>terminals</b> and accurately calibrated speedometers. Vehicles used include the BMW 3 series, BMW 5 Series and Volvo S60. Motorbikes used include the BMW R1200RT and Yamaha FJR. Motorway patrols are conducted by the CMPG in marked Jaguar XF vehicles.|$|R
50|$|By {{the early}} 1970s, many {{users in the}} {{computer}} industry realized that an affordable <b>video</b> <b>data</b> entry <b>terminal</b> could supplant the ubiquitous punched cards and permit new uses for computers that would be more interactive. The problem was that the amount of memory needed to store the information on a page of text was comparable to the memory in low end minicomputers then in use. Displaying the information at video speeds was also a challenge and the necessary control logic took up a rack worth of pre-integrated circuit electronics. One company announced plans to build a video terminal for $15,000 and attracted a large backlog of orders, but folded when their engineering plans, which included fabricating their own ICs, proved too ambitious. Another approach involved the use of the storage tube, a specialized CRT developed by Tektronix that retained information written on it without the need to refresh.|$|R
50|$|Provision of the {{associated}} User <b>Data</b> <b>Terminal</b> (UDT) for vehicular and static use was contracted to DRS Tactical Systems Inc, which also produces the Bowman Management <b>Data</b> <b>Terminal</b> (BMDT) for network management, the Vehicle User <b>Data</b> <b>Terminal</b> (VUDT) with keyboard and touchscreen for use on the move, the Staff User <b>Data</b> <b>Terminal</b> (SUDT) for command centres, and the PBISA Processing Unit (PBPU) for Challenger 2 tanks.|$|R
40|$|An {{automated}} {{accounting system}} useful for applying data {{to a computer}} from {{any or all of}} a multiplicity of <b>data</b> <b>terminals</b> is disclosed. The system essentially includes a preselected number of <b>data</b> <b>terminals</b> which are each adapted to convert data words of decimal form to another form, i. e., binary, usable with the computer. Each <b>data</b> <b>terminal</b> may {{take the form of a}} keyboard unit having a number of depressable buttons or switches corresponding to selected data digits and/or function digits. A bank of data buffers, one of which is associated with each <b>data</b> <b>terminal,</b> is provided as a temporary storage. <b>Data</b> from the <b>terminals</b> is applied to the data buffers on a digit by digit basis for transfer via a multiplexer to the computer...|$|R
5000|$|PSC Inc. was a {{manufacturer}} of portable <b>data</b> <b>terminals,</b> mobile <b>data</b> <b>terminals,</b> wireless terminals, bar code scanners, linear bar code verifiers, and RFID readers. It was founded in 1969 by John E. Blackert (Xerox) and Lawrence P. Albertson (Eastman Kodak) as Photographic Sciences Corporation in Webster, New York (a suburb of Rochester).|$|R
40|$|Abstract- Data mining {{technique}} can {{be applied}} in various documents. In this paper concentration on the application of <b>video</b> <b>data,</b> called <b>video</b> <b>data</b> mining, because acquisition and storage of <b>video</b> <b>data</b> is an easy task but retrieval of information from <b>video</b> <b>data</b> is challenging task. So <b>video</b> <b>data</b> mining {{plays an important role}} in efficient <b>video</b> <b>data</b> management for information retrieval. This paper describes a proposed framework for <b>video</b> <b>data</b> mining to extract the information from <b>video</b> <b>data.</b> This includes developing the technique for shot detection then key frame analysis is considered to compare the frames of each shot to each others to define the relationship between shots. After all hierarchical clustering technique is adopted to make a group of similar shots to detect the particular event on some requirement as per user demand. Index Terms – <b>Video</b> <b>data</b> mining, key frame analysis, clustering technique...|$|R
40|$|We {{present an}} {{efficient}} <b>video</b> <b>data</b> model that extends the DISIMA image data model {{by adding the}} video components and setting up links between image and <b>video</b> <b>data.</b> Many <b>video</b> <b>data</b> models have been proposed, most of which describe <b>video</b> <b>data</b> independently of image data and therefore fail to consider the relationship between videos and images. Our proposed model expresses the semantics of <b>video</b> <b>data</b> content by means of salient objects and relationships among them. Connections between <b>video</b> <b>data</b> and DISIMA images are made through key frames, which are extracted from each shot. Based on these connections, techniques used to query image data {{may be used to}} query <b>video</b> <b>data.</b> In addition, a set of new predicates has been defined to describe the spatio-temporal characteristics of salient objects in the <b>video</b> <b>data.</b> MOQL is used as a query language, with which we present example queries that can be posed on the proposed <b>video</b> <b>data</b> model [...] ...|$|R
50|$|<b>Data</b> <b>Terminal</b> Ready (DTR) is {{a control}} signal in RS-232 serial communications, {{transmitted}} from <b>data</b> <b>terminal</b> equipment (DTE), {{such as a}} computer, to data communications equipment (DCE), for example a modem, {{to indicate that the}} terminal is ready for communications and the modem may initiate a communications channel.|$|R
40|$|The present {{invention}} {{relates to}} a video encoding device (10) for encoding <b>video</b> <b>data</b> and a corresponding video decoding device, wherein during decoding PPG relevant information shall be preserved. For this purpose the video coding device (10) comprises a first encoder (20) for encoding input <b>video</b> <b>data</b> (100) {{according to a}} first encoding scheme and outputting first coded <b>video</b> <b>data</b> (120) having a lower quality than the input <b>video</b> <b>data,</b> and a second encoder (30) for encoding input <b>video</b> <b>data</b> (100) according to a second encoding scheme preserving PPG-relevant information and outputting second coded <b>video</b> <b>data</b> (130) ...|$|R
5000|$|MDT: Mobile <b>Data</b> <b>Terminal,</b> {{referring}} to in-car computer systems.|$|R
5000|$|It's {{unclear what}} caused data delays and {{incomplete}} screens on the mobile <b>data</b> <b>terminals.</b> Evidenced by the dispatcher reading {{the list of}} units assigned to Division 3, the CAD system was working properly at dispatch positions. At least some field units experienced problems. Possible causes of problems with <b>data</b> <b>terminals</b> in vehicles may have included: ...|$|R
5000|$|DTR (<b>Data</b> <b>Terminal</b> Ready) and DSR (Data Set Ready), DTR {{flow control}} ...|$|R
5000|$|EIA RS-232 (May 1960) [...] "Interface Between <b>Data</b> <b>Terminal</b> Equipment & Data" ...|$|R
30|$|With the {{explosive}} growth of <b>video</b> <b>data</b> and the fast development of network technologies, users become accustomed to access <b>video</b> <b>data</b> through network. However, too much <b>video</b> <b>data</b> {{at the same time}} might not be suitable for the current situation and the requirement of the users. Users have to spend much time to find <b>video</b> <b>data</b> that they are really interested in. Adapting video content to users' preferences is a key direction for enabling personalized video services. On the other hand, due to the huge size of <b>video</b> <b>data,</b> we're going to need much faster access to the network. However, most of us have limited bandwidth resources. Moreover, users may access and interact with <b>video</b> <b>data</b> on different types of terminals and networks. Personalized video services need to face the problem of delivering the big size of <b>video</b> <b>data</b> over the network with limited bandwidth in various media environments.|$|R
5000|$|... 1972: Datatel {{released}} {{their first}} product, the Silent 700, a programmable <b>data</b> <b>terminal</b> ...|$|R
5000|$|... mobile <b>data</b> <b>terminals,</b> or MDTs, {{which are}} {{computers}} that {{communicate with the}} dispatcher's computer.|$|R
50|$|Mobile data {{is the use}} of {{wireless}} data communications using radio waves to send and receive real time computer data to, from and between devices used by field based personnel. These devices can be fitted solely for use while in the vehicle (Fixed <b>Data</b> <b>Terminal)</b> or for use {{in and out of the}} vehicle (Mobile <b>Data</b> <b>Terminal).</b> See mobile Internet.|$|R
30|$|Efficient {{compression}} of <b>video</b> <b>data</b> {{is essential for}} storage and communication, since the amount of <b>video</b> <b>data</b> is very large. Video coding standards, such as MPEG or H. 264, {{have been widely used}} to compress <b>video</b> <b>data.</b> The temporal and spatial correlations of <b>video</b> <b>data</b> are used by adopting the motion compensated prediction and discrete cosine transform (DCT) in the encoder of conventional video coding systems. The conventional video encoder is more complex than the decoder is, since motion compensated prediction requires many operations. This conventional video coding system is appropriate for systems, in which <b>video</b> <b>data</b> is encoded by one complex encoder and decoded by many simple decoders.|$|R
40|$|<b>Video</b> <b>data</b> {{are rich}} of {{implicit}} information that cannot be efficiently managed {{by a computer}} when they are stored as unstructured linear streams. To allow a computer to efficiently deal {{with this kind of}} information is necessary to add some further information that offers a high level representation of what is contained in <b>video</b> <b>data.</b> This paper addresses the issues of defining a <b>video</b> <b>data</b> model. First a brief survey of the current approaches is presented then there is a proposal of a video model. The proposed model distinguishes between <b>video</b> <b>data</b> and <b>video</b> presentations. It allows to retrieve and browse <b>video</b> <b>data</b> and <b>video</b> presentations. and to build presentations...|$|R
50|$|Mobile <b>data</b> <b>terminals</b> - will be {{installed}} in cabs so firefighters have constantly updated information.|$|R
40|$|Abstract–For {{developing}} advanced {{query formulation}} methods for general multimedia data, {{we describe the}} issues related to <b>video</b> <b>data.</b> We distinguish between the requirements for image retrieval and video retrieval by identifying queryable attributes unique to <b>video</b> <b>data,</b> namely audio, temporal structure, motion, and events. Our approach is based on visual query methods to describe predicates interactively while providing feedback that is as similar {{as possible to the}} <b>video</b> <b>data.</b> An initial prototype of our visual query system for <b>video</b> <b>data</b> is presented...|$|R
40|$|Video {{applications}} {{are characterized by}} their increased requirements for hug storag spaces andtiming synchronization. <b>Video</b> <b>data</b> storag is a critical issue due to the so-called I/O bottleneck problem {{in relation to the}} quality of service while accessing video applications. The main contribution of the paper is that it considers <b>video</b> <b>data</b> dependencies, access frequencies andtiming constraints in order to introduce a <b>video</b> <b>data</b> representation model whichg ides the storag policies. Two <b>video</b> <b>data</b> representation levels are considered to capture the frequencies of accesses at external (video objects) and internal (video clips) levels. A simulation model has been developed in order to evaluate the placement strateg 2 C [...] <b>Video</b> <b>data</b> placement is performed on a tertiary storag subsystem by both constructive and iterative improvement policies. Iterative improvement placement has been proven to outperform the other <b>video</b> <b>data</b> placement approaches...|$|R
50|$|One of {{the most}} {{successful}} products of the company was the Alfaskop range of <b>data</b> <b>terminals.</b>|$|R
50|$|<b>Data</b> <b>terminals</b> {{are partly}} {{purchased}} and installed to reduce load on dispatch staff {{and to reduce}} traffic on voice channels. When they work properly, they have a significant operational benefit. A data outage during an occurrence of high call traffic can quickly overrun dispatch and voice channel capacity in cases where a routine level of calls for service requires both <b>data</b> <b>terminals</b> and voice channels.|$|R
40|$|As {{amounts of}} {{publicly}} available <b>video</b> <b>data</b> grow {{the need to}} query this data efficiently becomes significant. Consequently content-based retrieval of <b>video</b> <b>data</b> {{turns out to be}} a challenging and important problem. We address the specific aspect of inferring semantics automatically from raw <b>video</b> <b>data.</b> In particular, we introduce a new <b>video</b> <b>data</b> model that supports the integrated use of two different approaches for mapping low-level features to high-level concepts. Firstly, the model is extended with a rule-based approach that supports spatio-temporal formalization of high-level concepts, and then with a stochastic approach. Furthermore, results on real tennis <b>video</b> <b>data</b> are presented, demonstrating the validity of both approaches, as well us advantages of their integrated us...|$|R
5000|$|Interface {{to third}} party {{applications}} for; Paging to radio, GPS Location, Taxi <b>Data</b> <b>Terminals,</b> In Building tracking ...|$|R
50|$|The SAGRN {{data network}} {{is also used}} by the South Australian Police for their {{in-vehicle}} mobile <b>data</b> <b>terminals.</b>|$|R
50|$|Tasmania Police general patrol {{vehicles}} {{are equipped with}} mobile <b>data</b> <b>terminals,</b> used to interrogate criminal and traffic databases.|$|R
5000|$|TIA TIA/EIA-232-E (1991) [...] "Interface Between <b>Data</b> <b>Terminal</b> Equipment and <b>Data</b> Communications Equipment Employing Serial Binary Data Interchange" ...|$|R
40|$|This paper {{presents}} an interactive video visualization system. In this visualization <b>video</b> <b>data</b> {{is considered to}} be a block of three dimensional data where frames of <b>video</b> <b>data</b> comprise the third dimension. The user can manipulate and see a cut plane through the <b>video</b> <b>data.</b> The visualization leads to images that are aesthetically interesting as well as being useful for image analysis...|$|R
40|$|Recent {{advances}} in computing, communication, and data storage {{have led to}} {{an increasing number of}} large digital libraries publicly available on the Internet. Main problem of content-based video retrieval is inferring semantics from raw <b>video</b> <b>data.</b> <b>Video</b> <b>data</b> {{play an important role in}} these libraries. Instead of words, a video retrieval system deals with collections of video records. Therefore, the system is confronted with the problem of video understanding. Because machine understanding of the <b>video</b> <b>data</b> is still an unsolved research problem, text annotations are usually used to describe the content of <b>video</b> <b>data</b> according to the annotator's understanding and the purpose of that <b>video</b> <b>data.</b> Most of proposed systems for video annotation are domain dependent. In addition, in many of these systems, an important feature of <b>video</b> <b>data,</b> temporality, is disregarded. In this paper, we proposed a framework for video temporal annotation. The proposed system uses domain knowledge and a time ontology to perform temporal annotation of input video. Comment: Published in a Local Confrence, 200...|$|R
5000|$|EIA RS-232-C (August 1969) [...] "Interface Between <b>Data</b> <b>Terminal</b> Equipment and <b>Data</b> Communication Equipment Employing Serial Binary Data Interchange" ...|$|R
5000|$|EIA/TIA-561 8 Position Non-Synchronous Interface Between <b>Data</b> <b>Terminal</b> Equipment and <b>Data</b> Circuit Terminating Equipment Employing Serial Binary Data Interchange ...|$|R
5000|$|... between <b>data</b> <b>terminal</b> {{equipment}} (DTE) and a switching center, via data circuit-terminating equipment (DCE), {{the opposite}} types interconnected straightforwardly, ...|$|R
40|$|To allow {{better quality}} {{rendering}} of video on any display, a method is proposed of encoding, {{in addition to}} <b>video</b> <b>data</b> (VID), additional data (DD) comprising at least one change time instant (TMA- 1) indicating a change in time of a characteristic luminance (CHRLUM) of the <b>video</b> <b>data,</b> which characteristic luminance summarizes the set of luminances of pixels in {{an image of the}} <b>video</b> <b>data,</b> the method comprising: -generating {{on the basis of the}} <b>video</b> <b>data</b> (VID) descriptive data (DED) regarding the characteristic luminance variation of the <b>video,</b> the descriptive <b>data</b> comprising at least one change time instant (TMA- 1), and-encoding and outputting the descriptive data (DED) as additional data (DD) ...|$|R
