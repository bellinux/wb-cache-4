3|89|Public
5000|$|... {{insurance}} brokers (data collection, clients claims <b>verification,</b> <b>scale</b> of {{rates and}} insurance premium amounts calculation); ...|$|E
40|$|In the {{verification}} community it is {{now widely}} accepted that, in particular for large programs, verification is often incomplete and hence bugs still arise in deployed code on the machines of end users. Yet, in most cases, verification code is taken out prior to deployment due to large performance penalties induced by current runtime verification approaches. Consequently, if errors do arise in a production environment, bugs are hard to find, since the available debugging information is often very limited. In previous work on tracematches [1], we have shown {{that in many cases}} runtime monitoring can be made much more efficient using static analysis of the specification [2] and program under test [3]. Most often, the imposed runtime overhead can be reduced to under 10 %. However, the evaluation we performed also showed that some classes of specifications and programs exist for which those optimizations do not perform as well and hence large overheads remain. According to researchers in industry [5], larger industrial companies would likely be willing to accept runtime verification in deployed code if the overhead is below 5 %. Hence, additional work is required in order to make runtime <b>verification</b> <b>scale</b> even better...|$|E
40|$|The {{advent of}} {{system-on-a-chip}} (SoC) {{technology is a}} result of ever increasing transistor density. Unfortunately, this means that verification will pose the greatest problem to design because difficulties in <b>verification</b> <b>scale</b> faster than transistor technology. This paper provides evidence of this effect by citing industry trends, as well as discusses the potential pitfalls in SoC verification. Various SoC verification methods are offered by a number of industry groups such as Cadence, Synopsis, Mentor Graphics, and Motorola. These solutions generally offer theories based on divide-and-conquer and abstraction techniques. Specifically, Cadence offers the Unified Verification Methodology, which uses abstraction to check systems as design progresses instead of after the entire design is complete. Synopsis strongly encourages intellectual property (IP) reuse to allow for quick verification and gives guidelines to follow in order to create effective macros. Mentor Graphics joins Synopsis in support of reusable IP. However, Mentor Graphics is unique because they also believe that divide-and-conquer methods and specialized hardware will be important to overcome SoC verification. Motorola provides a practical viewpoint by demonstrating successful SoC designs by their own abstraction and divide-and-conquer techniques. In addition, notable insights from the University o...|$|E
40|$|This paper {{demonstrates}} the modeling and deductive verification of out-of-order microprocessors of varying complexities using a logic of Counter Arithmetic with Lambda Expressions and Uninterpreted Functions (CLU). The microprocessors support combinations of out-of-order instruction execution, superscalar operation, branch prediction, execute and memory exceptions, and load-store buffering. We illustrate that the logic is expressive enough to model components found in modern processors. The paper describes {{the challenges in}} modeling and verification {{with the addition of}} different design features. The paper {{demonstrates the}} effective use of automatic decision procedure {{to reduce the amount of}} manual guidance required in discharging most proof obligations in the verification. Unlike previous methods, the <b>verification</b> <b>scales</b> well for superscalar processors with wide dispatch and retirement widths...|$|R
40|$|Several {{similarity}} {{laws for}} the collisionless interaction of ultra-intense electromagnetic fields with a plasma of an arbitrary initial shape is presented. Both ultra-relativistic and non-relativistic cases are covered. The ion motion is included. A brief discussion of possible ways of experimental <b>verification</b> of <b>scaling</b> laws is presented. The {{results can be}} of interest for experiments and numerical simulations {{in the areas of}} particle acceleration, harmonic generation, and Coulomb explosion of clusters...|$|R
40|$|ABSTRACT: This paper {{outlines}} the latest status on seismic design for ITER in Japan, considering uniqueness in structure and safety features, and describes the associated on-going research for evaluation on tokamak dynamic response and <b>verification</b> tests using <b>scaled</b> tokamak model. Key Words: ITER, fusion experimental device, tokama...|$|R
40|$|Component-based Software Engineering (CBSE) is {{currently}} a key paradigm used for developing safety-critical systems. It provides a fundamental means to master systems complexity, by allowing to design systems parts (i. e., components) for reuse and by allowing to develop those parts independently. One of the main challenges of introducing CBSE {{in this area is}} to ensure the integrity of the overall system after building it from individual components, since safety-critical systems require a rigorous development and qualification process to be released for the operation. Although the topic of compositional modelling and verification in the context of component-based systems has been studied intensively in the last decade, there {{is currently}} still a lack of tools and methods that can be applied practically and that consider major related systems quality attributes such as usability and scalability. In this paper, we present a novel approach for design-time modelling and verification of safety-critical systems, based on data semantics of components. We describe the composition, i. e., the systems design, and the underlying properties of components as a Constraint Satisfaction Problem (CSP) and perform the verification by solving that problem. We show that CSP can be successfully applied for the verification of compositions for many types of properties. In our experimental setup we also show how the proposed <b>verification</b> <b>scales</b> with regard to the complexity of different system configurations...|$|R
40|$|Test-program {{generators}} play a {{key role}} in hardware functional <b>verification</b> of large <b>scale</b> processors. However, in the DSP domain, the usage of full-blown test-program generators is much less popular, mainly due to the limited resources (time and money) available when developing such systems. This paper describes a work-model for the fast, low cost construction of a test-program generator for DSPs. The core technology uses Genesys, a known test program generator that, until now, has been used for the <b>verification</b> of large <b>scale</b> processor families, such as PowerPC and x 86. We developed the model while using Genesys for verification of the IBM C 54 XDSP, a recently-announced fixedpoint DSP. The case study shows that it is possible to build a full test-program generator in a very short time and thus achieve better verification coverage in spite of the shorter development time...|$|R
40|$|If program {{verification}} {{tools are}} {{ever to be}} used widely, {{it is essential that}} they work in a modular fashion. Otherwise, <b>verification</b> will not <b>scale.</b> This paper discusses the scientific challenges that this poses for research in program logic, and suggests some test problems that would be useful in measuring advances on modular reasoning...|$|R
40|$|The Dagstuhl Seminar on Distributed Verification and Grid Computing {{took place}} from 10. 08. 2008 to 14. 08. 2008 and brought {{together}} {{two groups of}} researchers to discuss their recent work and recent trends related to parallel <b>verification</b> of large <b>scale</b> computer systems on large scale grids. In total, 29 experts from 12 countries attended the seminar...|$|R
40|$|The Istituto Nazionale di Ricerca Metrologica (INRIM) and Galileo {{section of}} LTF S. p. a. have cooperated {{for many years}} in the field of {{hardness}} for developing and improving Primary Hardness Standards and measuring systems for their laboratories. With this experience, Galileo-LTF has realized many installations for several NMIs in the world. All these Hardness Standards and measuring systems have been metrologically characterised by INRIM. In the paper, experiences made during the metrological characterization will be shown. They include the methods and results of direct verification of influence parameters (force, displacement, time, velocity, angle, etc.) and of indirect <b>verification</b> (hardness <b>scales</b> or indenters comparison) of the systems...|$|R
40|$|We derive {{and solve}} flow {{equations}} {{for a general}} O(N) -symmetric effective potential including wavefunction renormalization corrections combined with a heat-kernel regularization. We investigate the model at finite temperature and study {{the nature of the}} phase transition in detail. Beta functions, fixed points and critical exponents β, ν, δ and η for various N are independently calculated which allow for a <b>verification</b> of universal <b>scaling</b> relations. ...|$|R
40|$|The {{research}} method {{used in this}} study is descriptive qualitative. Study subjects {{used in this study}} is sampling census, the number of respondents 9 and 28 leaders of the staff. Techniques of data collection is by way of interviews and questionnaires, and data analysis techniques, namely data reduction, presentation of data, drawing conclusions and <b>verification</b> Likert <b>scale.</b> Based on the results obtained conclusions regarding the application of indicator variables leadership style of leadership through decision-making at the time tolernsi narrow or loose, the demands of the tasks assigned to subordinate leaders, leaders create an organizational climate, hope and leadership skills, leadership relationships with peers or colleagues and subordinate has a good walk ability...|$|R
40|$|Abstract: This paper {{reports on}} recent work in verifying railway systems through CSP||B {{modelling}} and analysis. Our motivation {{is to develop}} a modelling and ver-ification approach accessible to railway engineers: it is vital that they can validate the models and verification conditions, and — in the case of design errors — obtain comprehendable feedback. In this paper we run through a full production cycle on a real double junction case study, supplied by our industrial partner, who contributed at every stage. As our formalization is, by design, near to their way of thinking, they are comfortable with it and trust it. Without putting much effort on optimization for <b>verification,</b> the <b>scale</b> of the models analyzed is comparable with the work of other groups...|$|R
40|$|Abstract. Choreographies offer {{means to}} capture global {{interactions}} between business processes of different partners. BPEL 4 Chor {{has been introduced}} to describe these interactions using BPEL. Currently, there are no formal methods available to verify BPEL 4 Chor choreographies. In this paper, we present how BPEL 4 Chor choreographies can be verified using Petri nets. A case study undermines that our <b>verification</b> techniques <b>scale.</b> Additionally, we show how the verification techniques {{can be used to}} generate a stub process for a partner taking part in a choreography. This is especially useful when the behavior of one participant is intended to follow the corresponding requirements of the other participants. Thus, the missing participant behavior can be generated and the error-prone design of that participant can be skipped...|$|R
40|$|Well {{designed}} tunneling green transistor may enable future VLSIs {{operating at}} 0. 1 V. Sub- 60 mV/decade characteristics have been clearly demonstrated on 8 ” wafers with statistical data. Large ION at low VDD are possible according to TCAD simulations but awaits <b>verification.</b> VDD <b>scaling</b> will greatly benefit from low (effective) band gap energy materials, {{which may be}} provided by type II heterojunctions of Si/Ge or compound semiconductors. A Looming Barrier to IC Scaling Reducing the voltage VDD is a powerful way to reduce IC energy consumption, which is proportional to VDD 2. Power was kept under control because Vdd has been reduced in proportion to half-pitch up to 130 nm as shown in Fig 1 [1]. The 14 nm node is projected to operate at 0. 7 V, making the power consumption 25 x larger than i...|$|R
40|$|Abstract. In this paper, {{we explore}} a parallelization of BMC based on state space partitioning. The parallelization is {{accomplished}} by executing multiple instances of BMC independently from different seed states. These seed states are deep states, selected from the reachable states in different partitions. In this scheme, all processors work independently of each other, thus it is suitable for <b>scaling</b> <b>verification</b> to a grid-like network. Our experimental results demonstrate improvement over existing approaches, and show that the method can scale to a large network. ...|$|R
40|$|We {{present a}} {{verification}} methodology for analysing the decision-making component in agent-based hybrid systems. Traditionally hybrid automata {{have been used}} to both implement and verify such systems, but hybrid automata based modelling, programming and <b>verification</b> techniques <b>scale</b> poorly as the complexity of discrete decision-making increases making them unattractive in situations where complex log- ical reasoning is required. In the programming of complex systems it has, therefore, become common to separate out logical decision-making into a separate, discrete, component. However, verification techniques have failed to keep pace with this devel- opment. We are exploring agent-based logical components and have developed a model checking technique for such components which can then be composed with a sepa- rate analysis of the continuous part of the hybrid system. Among other things this allows program model checkers to be used to verify the actual implementation of the decision-making in hybrid autonomous systems...|$|R
40|$|This paper {{presents}} experimental <b>verification</b> {{of frequency}} <b>scaling</b> in an internal dielectric transduced resonator. A silicon bar resonator is excited in its 3 rd and 9 th longitudinal harmonic modes at 1. 53 and 4. 51 GHz, respectively. The resonator demonstrates a 2 dB improvement in transduction efficiency in its 9 th harmonic relative to its 3 rd harmonic, normalized {{to the quality}} Q of the resonance. This result is {{in close agreement with}} theory, promising lowimpedance transduction of silicon bulk acoustic resonators at frequencies exceeding 10 GHz...|$|R
40|$|Abstract — Continuing {{to scale}} CMP {{performance}} at reasonable power budgets has forced chip designers to consider emerging silicon-photonic technologies {{as the primary}} means of on- and off-chip communication. Different designs for chipscale photonic interconnects have been proposed, and systemlevel simulations have shown them to be far superior to purely electronic network solutions. However, specifying the exact geometries for all the photonic devices used in these networks is currently a time-consuming and difficult manual process. We present VANDAL, a layout tool which provides a user with semi-automatic assistance for placing silicon photonic devices, modifying their geometries, and routing waveguides for hierarchically building photonic networks. VANDAL also includes SCILL, a scripting language {{that can be used}} to automate photonic device place and route for repeatability, automation, <b>verification,</b> and <b>scaling.</b> We demonstrate some of the features and flexibility of the CAD environment with a case study, designing modulator and detector banks for integrated photonic links. I...|$|R
40|$|Critical Real-Time Embedded Systems (RTES) {{have strong}} {{requirement}} {{with respect to}} system's reliability. In Model-Driven Engineering (MDE), verification at early phases of the system lifecycle is an important issue, especially for time constraints in UML-MARTE RTES model. In order to assess that the time requirements are met by the behavior models, the key challenging problem is to transform these time constraints from the UML-MARTE model to computable formal semantics that provide time properties verification. Moreover, to allow the application of this formal semantic to real industrial use cases, the performance of <b>verification</b> should <b>scale</b> well. In this paper, we present a set of time constraint dedicated semantics under the framework for UML-MARTE RTES model's time requirement assessment. We focus on how to specify a set of synchronization-related constraints between system's tasks relying on a formal semantics and to accomplish verification by an efficient observer-based model checking method using Time Petri Nets. We analyse the method's computational complexity and demonstrate the method's scalability by illustrating some performance results...|$|R
40|$|Abstract — We present {{techniques}} for analyzing the source code of distributed Java applications, and building finite models of their behaviour. The models are labelled transition systems, representing the communication events between the distributed objects. When combined with {{techniques for}} abstracting the data values {{used by the}} programs, and especially values used {{in the creation of}} distributed objects, to bounded domains, our construction terminates. We provide models suitable for automatic verification, and typically for model checking. Moreover our models are structured in a compositionnal way, so that we can use <b>verification</b> techniques that <b>scale</b> up to applications of realistic size. I...|$|R
40|$|The {{emergence}} of the Industrial Internet results in {{an increasing number of}} complicated temporal interdependencies between automation systems and the processes to be controlled. There is a need for <b>verification</b> methods that <b>scale</b> better than formal verification methods and which are more exact than testing. Simulation-based runtime verification is proposed as such a method, and an application of Metric temporal logic is presented as a contribution. The practical scalability of the proposed approach is validated against a production process designed by an industrial partner, resulting in the discovery of requirement violations. Comment: 4 pages, 2 figures. Added IEEE copyright notic...|$|R
40|$|This paper {{introduces}} a new behavioral system model with distinct {{external and internal}} signals possibly evolving on different time scales. This allows to capture abstraction processes or signal aggregation {{in the context of}} control and <b>verification</b> of large <b>scale</b> systems. For this new system model different notions of simulation and bisimulation are derived, ensuring that they are, respectively, preorders and equivalence relations for the system class under consideration. These relations can capture a wide selection of similarity notions available in the literature. This paper therefore provides a suitable framework for their comparisonComment: Submitted to 22 nd Mediterranean Conference on Control and Automatio...|$|R
40|$|International audienceTo {{choose the}} most {{suitable}} RF coil available for an MRI study, we propose a procedure which uses a calibrated phantom, a 3 D gradient-echo sequence, and an automatic post-processing tool available on the web. This tool generates a report which contains the measurement of a SNR with uniform volumes located in the depth. The post-processing could be done on MR images acquired on most main MRI vendors (Siemens, GE, Philips and Bruker) with prior <b>verification</b> of applied <b>scaling</b> or filtering. RF coil characterization results performed on at 4. 7 T and 7 T were compared. The tool {{can be used for}} quality control...|$|R
40|$|Verifying that access-control systems {{maintain}} desired security properties {{is recognized}} as an important problem in security. Enterprise access-control systems have grown to protect {{tens of thousands of}} re-sources, and {{there is a need for}} <b>verification</b> to <b>scale</b> commensurately. We present techniques for abstraction-refinement and bound-estimation for bounded model checkers to automatically find errors in Administrative Role-Based Access Control (ARBAC) security policies. ARBAC is the first and most comprehensive admin-istrative scheme for Role-Based Access Control (RBAC) systems. In the abstraction-refinement portion of our approach, we identify and discard roles that are unlikely to be relevant to the verification question (the abstraction step). We then restore such abstracted roles incrementally (the refinement steps). In the bound-estimation portion of our approach, we lower the estimate of the diameter of the reachability graph from the worst-case by recognizing relationships between roles and state-change rules. Our techniques complement one another, and are used with conventional bounded model checking. Our approach is sound and complete: an error is found if and only if it exists. We have implemented our technique in an access-control policy anal-ysis tool called MOHAWK. We show empirically that MOHAWK scales well to realistic policies, and provide a comparison with prior tools...|$|R
40|$|This study {{examines}} {{the impact of}} the Jobseeker Diary (JSD), a program designed to increase the job search effort of unemployed persons in Australia. The JSD program is distinguished by combining a focus on work search <b>verification</b> with large <b>scale</b> implementation. Applying a quasi-experimental matching method to data on unemployment spells occurring in 1997 - 98, the authors find that JSD participation was associated with an increased rate of exit from unemployment payment recipiency and a shorter total time spent on payments. Payment receipt duration is estimated to have fallen for about one-half of JSD participants. The largest effects of the JSD occurred for payment recipients for whom labor demand conditions were the most favorable. Cost-benefit analysis suggests a fairly large net societal gain per program participant...|$|R
40|$|ACL 2 is a re-implemented {{extended}} version of Boyer and Moore's Nqthm and Kaufmann's Pc-Nqthm, intended for large <b>scale</b> <b>verification</b> projects. This paper deals primarily with how we scaled up Nqthm's logic to an "industrial strength" programming language [...] - namely, a large applicative subset of Common Lisp [...] - while preserving {{the use of}} total functions within the logic. This {{makes it possible to}} run formal models efficiently while keeping the logic simple. We enumerate many other important features of ACL 2 and we briefly summarize two industrial applications: a model of the Motorola CAP digital signal processing chip and the proof of the correctness of the kernel of the floating point division algorithm on the AMD 5 K 86 microprocessor by Advanced Micro Devices, Inc...|$|R
40|$|This paper {{describes}} {{our work}} on demonstrating verification technologies on a flight-critical system of realistic functionality, size, and complexity. Our work targeted a commercial aircraft control system named Transport Class Model (TCM), and involved several stages: formalizing and disambiguating requirements {{in collaboration with}} do- main experts; processing models for their use by formal verification tools; applying compositional techniques at the architectural and component level to <b>scale</b> <b>verification.</b> Performed {{in the context of}} a major NASA milestone, this study of formal verification in practice is one of the most challenging that our group has performed, and it took several person months to complete it. This paper describes the methodology that we followed and the lessons that we learned. Comment: 17 pages, 5 figure...|$|R
40|$|Verifying that access-control systems {{maintain}} desired security properties {{is recognized}} as an important problem in security. Enterprise access-control systems have grown to protect {{tens of thousands of}} resources, and {{there is a need for}} <b>verification</b> to <b>scale</b> commensurately. We present a new abstraction-refinement technique for automatically finding errors in Administrative Role-Based Access Control (ARBAC) security policies. ARBAC is the first and most comprehensive administrative scheme for Role-Based Access Control (RBAC) systems. Underlying our approach is a change in mindset: we propose that error finding complements verification, can be more scalable, and allows for the use of a wider variety of techniques. In our approach, we use an abstraction-refinement technique to first identify and discard roles that are unlikely to be relevant to the verification question (the abstraction step), and then restore such abstracted roles incrementally (the refinement steps). Errors are one-sided: if there is an error in the abstracted policy, then there is an error in the original policy. If there is an error in a policy whose role-dependency graph diameter is smaller than a certain bound, then we find the error. Our abstraction-refinement technique complements conventional state-space exploration techniques such as model checking. We have implemented our technique in an access-control policy analysis tool. We show empirically that our tool scales well to realistic policies, and is orders of magnitude faster than prior tools...|$|R
40|$|Failure of the {{spherical bearing}} shaft of the Space Shuttle Main Engine (SSME) gimbal bearing {{assembly}} was encountered during Design Verification Specification {{testing of the}} full scale engine. Investigation revealed that the failure {{was caused by a}} deficiency in the lubrication system. Based upon the materials and gimbal operating conditions, a lubricant of MoS 2 and graphite with a ceramic binder was the best lubricant candidate for this particular application; however, the decision to implement the change was not made without <b>verification</b> testing. <b>Scaled</b> down simulation testing was performed. Four different substrate materials and eight different dry film lubricants were subjected to tests under simulated SSME environmental and stress load conditions. The test specimens were evaluated for friction and operating life. Each test specimen was subjected to cyclic operation under load until failure. The force required to move the bearing surfaces relative to each other was monitored throughout the test, thus providing analytical data for derivation of the coefficient of friction. Results indicate that the MoS 2 /graphite lubricant with ceramic binder proved to be superior from the standpoint of endurance and also from the standpoint of friction reducing capabilities when applied to the titanium substrate material used on SSME. Endurance of this lubricant was approximately 16 times that of the lubricant which was being used when the SSME gimbal failed...|$|R
40|$|We {{report on}} a formal {{requirements}} analysis experiment involving an avionics control system. We describe a method for specifying and verifying real-time systems with PVS. The experiment involves the formalization of the functional and safety requirements of the avionics system {{as well as its}} multilevel verification. First level verification demonstrates the consistency of the specifications whilst the second level shows that certain system safety properties are satisfied by the specification. We critically analyze methodological issues of large <b>scale</b> <b>verification</b> and propose some practical ways of structuring verification activities for optimising the benefits. Keywords [...] -Formal specification, formal verification, safety critical systems, requirements analysis, avionics systems. I. Introduction T HIS paper reports on an experiment in the use of formal methods for producing and analyzing software requirements for a safety-related system. This work was conducted as part of the SafeFM [...] ...|$|R
40|$|International audienceWe {{investigate}} decoupling abstractions, {{by which}} we seek to simulate (i. e. abstract) a given system of ordinary differential equations (ODEs) by another system that features completely independent (i. e. uncoupled) subsystems, which {{can be considered as}} separate systems in their own right. Beyond a purely mathematical interest as a tool for the qualitative analysis of ODEs, decoupling can be applied to verification problems arising in the fields of control and hybrid systems. Existing <b>verification</b> technology often <b>scales</b> poorly with dimension. Thus, reducing a verification problem to a number of independent verification problems for systems of smaller dimension may enable one to prove properties that are otherwise seen as too difficult. We show an interesting correspondence between Darboux polynomials and decoupling simulating abstractions of systems of polynomial ODEs and give a constructive procedure for automatically computing the latter...|$|R
40|$|In {{the late}} 1960 s, efforts {{to advance the}} {{state-of-the-art}} in rotor systems technology indicated a significant gap existed between our ability to accurately predict {{the characteristics of a}} complex rotor system and the results obtained through flight <b>verification.</b> Even full <b>scale</b> wind tunnel efforts proved inaccurate because of the complex nature of a rotating, maneuvering rotor system. The key element missing, which prevented significant advances, was our inability to precisely measure the exact rotor state as a function of time and flight condition. Two Rotor Research Aircraft (RSRA) were designed as pure research aircraft and dedicated rotor test vehicles whose function is to fill the gap between theory, wind tunnel testing, and flight verification. The two aircraft, the development of the piloting techniques required to safely fly the compound helicopter, the government flight testing accomplished to date, and proposed future research programs...|$|R
40|$|We {{investigate}} decoupling abstractions, {{by which}} we seek to simulate (i. e. abstract) a given system of ordinary differential equations (ODEs) by another system that features completely independent (i. e. uncoupled) subsystems, which {{can be considered as}} separate systems in their own right. Beyond a purely mathematical interest as a tool for the qualitative analysis of ODEs, decoupling can be applied to verification problems arising in the fields of control and hybrid systems. Existing <b>verification</b> technology often <b>scales</b> poorly with dimension. Thus, reducing a verification problem to a number of independent verification problems for systems of smaller dimension may enable one to prove properties that are otherwise seen as too difficult. We show an interesting correspondence between Darboux polynomials and decoupling simulating abstractions of systems of polynomial ODEs and give a constructive procedure for automatically computing the latter...|$|R
40|$|Abstract: Several works {{emphasize}} {{the difficulties of}} software verification applied to embedded systems. In past years, formal verification techniques and tools were widely developed and used by the research community. However, the use of formal <b>verification</b> at industrial <b>scale</b> remains difficult, expensive and requires lot of time. This {{is due to the}} size and the complexity of manipulated models, but also, to the important gap between requirement models manipulated by different stackholders and formal models required by existing verification tools. In this paper, we fill this gap by providing the UCM framework to automatically generate formal models used by formal verification tools. At this stage of our work, we generate behavior models of environment actors interacting with the system directly from an extended form of use cases. These behavioral models can be composed directly with the system automata to be verified using existing model checking tools. ...|$|R
