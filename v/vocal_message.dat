7|29|Public
60|$|In other words, of the {{composite}} <b>vocal</b> <b>message</b> of massed humanity.|$|E
5000|$|Vocal CUIs {{interfaces}} with <b>vocal</b> <b>message</b> rendering {{and speech}} recognition.|$|E
50|$|The White Guardian is a {{character}} in the long-running British science fiction television series Doctor Who. He was played by Cyril Luckham, {{with the exception of}} a <b>vocal</b> <b>message</b> in The Stones of Blood which was performed by Gerald Cross.|$|E
50|$|Newer VCDs are speaker-independent, so {{they can}} respond to {{multiple}} voices, regardless of accent or dialectal influences. They are also capable of responding to several commands at once, separating <b>vocal</b> <b>messages,</b> and providing appropriate feedback, accurately imitating a natural conversation. They can understand around 50 different commands and retain up to 2 minutes of <b>vocal</b> <b>messages.</b> VCDs {{can be found in}} computer operating systems, commercial software for computers, mobile phones, cars, call centers, and internet search engines such as Google.|$|R
25|$|A Patronus is {{primarily}} used to repel Dementors. They {{can also be}} used for communication by accomplished witches and wizards. Albus Dumbledore devised a method of using Patronuses to deliver <b>vocal</b> <b>messages,</b> putting this to the exclusive use of the Order of the Phoenix. Dumbledore, Minerva McGonagall, Kingsley Shacklebolt, and Arthur Weasley all deliver messages via Patronus {{in the course of the}} series. McGonagall is also the only character in the series to have shown the ability to project multiple Patronuses for sending messages.|$|R
40|$|To help {{children}} with autism develop social skills, we are investigating the use of mobile robotic toys that can move autonomously in the environment and interact in various manners (<b>vocal</b> <b>messages,</b> music, visual cues, movement, etc.), in a more predictable and less intimidating way. These interactions are designed to build up their self-esteem by reinforcing what they do well. We report tests done with autistic children using different robots, each robot having particular characteristics that allow to create interesting interactions with each child. 1...|$|R
5000|$|The second [...] "Modulus" [...] configuration, the Service Robot, is {{obtained}} by fitting the Techno-cake home-security and service unit {{on to the}} Base. One of the components allow the robot to signal the presence of smoke, gas, water, and intruders; {{at the first sign}} of danger it informs the computer or triggers a siren or preset <b>vocal</b> <b>message.</b> An arm with ample freedom of movement and considerable gripping power can be added to the Service Robot. Using its meteo-system, the robot will fetch its owners umbrella if it is going to rain; a simple whistle will bring it toddling over to you.|$|E
50|$|This game is set 15 {{years after}} the events of Alien and 42 years before the events of Aliens, {{features}} Ripley's daughter Amanda. Amanda was originally introduced in the extended version of Aliens, when Ripley learns that during her 57-years long stasis, Amanda grew up, married, and died. In the game, Amanda investigates potential clues regarding her mother's disappearance, {{and goes to the}} space station Sevastopol in hope to find answers. Near the end of the game, Amanda ultimately finds a <b>vocal</b> <b>message</b> from her mother (voiced by Weaver), who added a personal message to the Nostromo's final log entry at the end of Alien addressed to Amanda. In the message Ellen Ripley explains {{the true nature of the}} disappearance of the Nostromo, tells her she loves her, and hopes that she will get to hear this someday.|$|E
30|$|The ASV (Advanced Safety Vehicle) project, co-funded by the Japanese government, {{focuses on}} {{several aspects of}} road safety (e.g. {{autonomous}} driving technologies, accident avoidance technologies, damage mitigating technologies, and post-collision injury mitigation). The project was articulated in several subsequent phases, each focusing on specific systems. ASV- 3, the third phase of the project, proposed an ARAS System based on inter-vehicle communication able to connect and share considerable information between vehicles (relative position, relative speed and so forth). The associated HMI system is comprised of an Head Up Display, a display for rear view camera, speakers and a microphone integrated in the helmet. The ARAS functions included intersection accident avoidance and blind spot assistance, and warnings to the rider were transmitted through visual and acoustic signals. The head up display showed a representation of PTW surrounding area split in several sectors: the enlightened sector indicated {{the direction of the}} oncoming vehicle. Each information/warning on the head up display was also replicated using an audio signal or a short <b>vocal</b> <b>message</b> [11].|$|E
5000|$|Tami Kanning - <b>vocals</b> & lyrics (<b>Messages</b> From Above, Auricle, Drifting).|$|R
2500|$|The use of SoundLink in Inishie no Sekiban {{demonstrated}} {{a degree of}} maturity over the previous BS Zelda games, insofar as they allowed a more natural and flowing playthrough without the pauses and delays that characterized <b>vocal</b> <b>messages</b> in BS Zelda. Rather than displaying a [...] "Listen Closely" [...] sign and pausing gameplay, the player could continue to move about during voice messages in Inishie no Sekiban. The plot that was developed through vocal files was also considerably more intricate, with important plot details revealed in dialogue only spoken during playthrough. The voice cast also grew in number from three people in BS Zelda to a cast of five, and fully voiced side-quest events and cut-scenes were also added {{at the beginning and}} end ...|$|R
50|$|Each {{platform}} meta-model is a {{refinement of}} the AUI, which specifies how a given abstract interactor {{can be represented}} in the current platform. For instance, if we consider the abstract Single Choice interactor, it can be implemented (on a graphical desktop platform) with a radio button, a drop down list or a list box, while on the vocal platform it can be rendered {{with a list of}} <b>vocal</b> <b>messages</b> for each option associated to a given keyword. The same applies for the interactor compositions: in a desktop platform a grouping can be implemented using background colours, borders etc., while in a vocal platform it is possible to use sounds before the first group element. The model definition can be exploited for creating (or deriving with a code generator) final implementations in different target languages.|$|R
40|$|The growing {{complexity}} and inherent {{risks associated with}} the operation of power transmission and distribution systems have caused personnel training to become a priority for {{a growing number of}} electrical utilities. Training simulators offer an interesting means for helping the personnel of those enterprises to learn their work. Simulation-based training has the advantage of being safe for both personnel and equipment, while ensuring service continuity. It also offers the trainee, the opportunity to be exposed to various scenarios and to exceptional conditions, which either happen rarely or are hazardous to reproduce. This thesis presents a review of virtual reality (VR) technologies and applications and describes the design and implementation of a VR based operator training simulator prototype developed for a local power utility. The architecture of this client-server system is explained in addition to the interaction metaphors the prototype offers. The training simulator is built as a distributed network system comprised of heterogeneous computer platforms and integrates various virtual reality technologies. A visual simulation host renders the three-dimensional world and manages interactions between the user and the VR application. The system also supports generation and super-imposition of sounds typically found in the substation environment such as ambient background noise, sound events related to user actions and also <b>vocal</b> <b>message</b> output used for didactic purposes. The system is augmented with speech-recognition capabilities that free the user from cumbersome manipulations and make its use more natural. ESOPE-VR automatically generates a representation of a typical power utility substation from the single-line diagram representing it. The virtual environment in which the user navigates and can simulate his daily work, is comprised of a yard with equipment such as transformers, disconnect switches and circuit breakers. A control room with a mock-up of a real control panel activating the equipment is also implemented...|$|E
40|$|Abstract: This paper {{presents}} {{the design of}} a new onboard system that contributes to the reduction of fuel consumption and CO 2 production by optimising vehicle energy. We designed an appropriate instrument that enables the driver to adopt the best driving behaviour, smooth speed and good gear management. A global optimisation algorithm was developed to provide the driver with an economic driving pattern. This algorithm enables the reduction of fuel consumption by 10 - 15 %, {{depending on the type of}} vehicle and on driving behaviour. An interaction control system was developed to provide the driver with visual information (optimal speed and gear instructions) and <b>vocal</b> <b>messages</b> with respect to road context in order to reduce risk and human errors. Keywords: Energy management; User-centred design; Instrument design; Multimodal interaction...|$|R
40|$|The diffuse {{availability}} of mobile devices, such as smartphones and tablets, {{has the potential}} to bring substantial benefits to the people with sensory impairments. The solution proposed in this paper is part of an ongoing effort to create an accurate obstacle and hazard detector for the visually impaired, which is embedded in a hand-held device. In particular, it presents a proof of concept for a multimodal interface to control the orientation of a smartphone's camera, while being held by a person, using a combination of <b>vocal</b> <b>messages,</b> 3 D sounds and vibrations. The solution, which is to be evaluated experimentally by users, will enable further {{research in the area of}} active vision with human-in-the-loop, with potential application to mobile assistive devices for indoor navigation of visually impaired people...|$|R
40|$|ABSTRACT: In {{this paper}} we propose a new, simple {{approach}} to small vocabulary word recognition. The methodology adopted is based on hybrid fuzzy learning. In particular, the application is based on the management of an extractor hood for a cooker by means of simple <b>vocal</b> <b>messages.</b> It therefore involves the recognition of isolated words from a limited vocabulary. Tests showed that the fuzzy system outputs follow a logic in line with the words uttered. The output of the matching block is a set of four values from four special fuzzy systems. Each fuzzy system is designed {{in such a way as}} to recognise a certain word (so there are four systems because there are four words to recognise). The degree of excitation of a system will measure the degree of recognition of the word. Experimental tests showed the validity of the new approach...|$|R
40|$|Abstract: The RAMPE project aims to design, realize and {{experiment}} {{a system for}} the assistance and information of blind people {{so that they can}} increase their mobility and autonomy in public transport. It is intended to equip bus or tramway stops or to be installed in poles of transport interactions. It is based on smart hand-held Personal Digital Assistant (PDA) with embedded speech synthesis and able to communicate by a wireless WiFi connection with fixed equipment in the bus or tram stations. The main characteristics of the smart hand-held devices are: they can present and filter <b>vocal</b> <b>messages,</b> they can adapt themselves to the type of information system available at the stations, they can react to real-time information sent by the stations. A special care has been given to the design of the man machine interface and to the management of priorities in the real-time vocal information application...|$|R
40|$|According to many {{psychological}} and social studies, <b>vocal</b> <b>messages</b> contain two distinct channels—an explicit, linguistic channel, and an implicit, paralinguistic channel. In particular, the latter contains information about the emotional state of the speaker, providing clues about the implicit meaning of the message. Such information can improve applications requiring human-machine interactions (for example, Automatic Speech Recognition systems or Conversational Agents), as well as support the analysis of human-human interactions (for example, clinic or forensic applications). PrEmA, the tool we present in this work, is able to recognize and classify both emotions and communication style of the speaker, relying on prosodic features. In particular, recognition of communication-styles is, to our knowledge, new, and {{could be used to}} infer interesting clues {{about the state of the}} interaction. PrEmA uses two LDA-based classifiers, which rely on two sets of prosodic features. Experimenting PrEmA with Italian speakers we obtained Ac = 71 % for emotions and Ac = 86 % for communication styles...|$|R
40|$|A {{literature}} review and a questionnaire study with 62 participants {{were carried out}} to provide recommendations {{on the design of}} a set of evacuation systems for road tunnels: 1) Traffic Information Sign (TIS) - message and size of the sign (large or small), colour scheme, and use of pictograms and/or flashing lights, 2) Emergency exit portal layout - colour scheme, 3) Acoustic systems - voice message and/or warning signals. The TIS is recommended to include the use of two panels which present text (in amber) and flashing lights in one panel and the emergency exit pictorial symbol in green in the other panel. An increased size of the panels has a positive effect on capturing participants’ attention. The recommended colour scheme for the emergency exit portal is safety green for the portal and a “green darker than the safety green” for the door. <b>Vocal</b> <b>messages</b> are not recommended since they may be quite difficult to perceive in tunnels. The use of a warning signal (F_SAW signal) based on British Standards is recommended...|$|R
40|$|In this paper, {{a system}} for gait {{training}} and rehabilitation for Parkinson’s disease (PD) patients in a daily life setting is presented. It {{is based on a}} wearable architecture aimed at the provision of real-time auditory feedback. Recent studies have, in fact, shown that PD patients can receive benefit from a motor therapy based on auditory cueing and feedback, as happens in traditional rehabilitation contexts with verbal instructions given by clinical operators. To this extent, a system based on a wireless body sensor network and a smartphone has been developed. The system enables real-time extraction of gait spatio-temporal features and their comparison with a patient’s reference walking parameters captured in the lab under clinical operator supervision. Feedback is returned to the user in form of <b>vocal</b> <b>messages,</b> encouraging the user to keep her/his walking behavior or to correct it. This paper describes the overall concept, the proposed usage scenario and the parameters estimated for the gait analysis. It also presents, in detail, the hardware-software architecture of the system and the evaluation of system reliability by testing it on a few subjects. status: publishe...|$|R
40|$|This work {{presents}} a literature review and a questionnaire study with 62 participants aimed at providing recommendations {{on the design}} of a set of evacuation systems for road tunnels: 1) Traffic Information Sign (TIS) - message and size of the sign (large or small), colour scheme, and use of pictograms and/or flashing lights, 2) Emergency exit portal layout - colour scheme, 3) Acoustic systems - voice message and/or warning signals. The TIS is recommended to include the use of two panels which present text (in amber) and flashing lights in one panel and the emergency exit pictorial symbol in green in the other panel. An increased size of the panels has a positive effect on capturing participants’ attention. The recommended colour scheme for the emergency exit portal is safety green for the portal and a “green darker than the safety green” for the door. <b>Vocal</b> <b>messages</b> are not recommended since they may be quite difficult to perceive in tunnels. The use of a warning signal (F_SAW signal) based on British Standards is recommended...|$|R
40|$|Abstract – Pervasive {{developmental}} disorders (PDD) {{refers to}} a group of disorders characterized by delays in the development of multiple basic functions including socialization and communication. Symptoms may include communication problems such as using and understanding language; difficulty relating to people, objects, and events; unusual play with toys and other objects; difficulty with changes in routine or familiar surroundings, and repetitive body movements or behavior patterns [1]. Autism is the most characteristic and best studied PDD. We are investigating the use of mobile robotic toys that can move in the environment and interact in various manners (<b>vocal</b> <b>messages,</b> music, visual cues, movement, etc.) with children with autism. The hypothesis is that mobile robots can serve as an appropriate pedagogical tool to help children with PDD develop social skills because they are more predictable and less intimidating. The objective is to see how such devices can be used to capture the child’s attention and contribute to helping him or her develop social skills. This paper outlines the design considerations for such robots, and presents experimental protocols that are being developed to study the impacts of using these robots {{on the development of the}} child...|$|R
5000|$|Anna Marie of A Kid's Point of You sayed [...] "A folk-meets-pop jam, “The Middle of Starting Over” {{is certain}} {{to be added to}} countless sleepover playlists everywhere. It has an {{inspirational}} message and a unique, unforgettable sound only made stronger by Sabrina’s powerful <b>vocals.</b> The <b>message</b> of the song has that girl power theme, which I personally love and can relate to. One thing’s for sure; this song has already been added to my Summer playlist". The song received several comparisons with Taylor Swift's early works.|$|R
40|$|Abstract—We {{demonstrate}} {{a suite of}} proximity-based appli-cations, called Crowdcast, that is build on top of our powerful Proximity framework. Proximity, efficiently connects you to your closest neighbors at all times, regardless of {{where you are and}} how far your closest neighbors are. Such a service, realizes our special operator that solves the Continuous All k-Nearest Neighbor (CAkNN) problem efficiently. Proximity does not re-quire any additional infrastructure or specialized hardware and its efficiency is mainly achieved due to the smart search space sharing technique we devise. The Crowdcast application suite demonstrates how the Prox-imity data management algorithmics can give rise to novel proximity-based services. During the conference, we will allow attendees to use the Crowdcast applications throughout the venue site. They will be able to: (i) post text or <b>vocal</b> <b>messages</b> on a neighborhood pinup wall, which will be visible to their k nearest neighbors. For instance, an attendee might initiate a discussion with other attendees of the same session to clarify issues about the presentation without disturbing; (ii) extend their view or their hearing on the conference activities using the cameras and/or microphones of their neighbors; (iii) post local tasks in their neighborhood as part of organizing an activity, etc. I...|$|R
40|$|Gift of Dr. Mary Jane Esplen. Piano <b>vocal</b> [instrumentation]There's a <b>message</b> {{from the}} land of fleur de Lis [first line]Day by day in ev'ry way I'm getting better ev'ry day [first line of chorus]A flat major [key]Moderato [tempo]Popular song [form/genre]Sun, flowers [illustration]Respectfully {{dedicated}} to Dr. Emile Coué [dedication]Starmer [engraver]Publisher's advertisement on back cover [note...|$|R
40|$|Flexible voice {{alert system}} was build {{combining}} existing softwares {{in a very}} short time. When an alert condition occurs in the system, EPICS alarm handler program send UDP packet including alert message to a server program running on a Macintosh computer. The server program uses TextSpeech program to read it out as a human voice. Both client and server programs were written in Python programing language. 1 SYSTEM OVERVIEW The voice alert system described in this paper is the system notifies alert conditions to the operator with the <b>vocal</b> alert <b>messages.</b> Main component of the system is a software on PC (Macintosh computer running MacOS 8) receives an aler...|$|R
5000|$|Both Sakuma and Yajima praised [...] "Hikari", with Sakuma {{feeling it}} was one of the most memorable songs on the album due to its shoegazing sound, Yui's [...] "floating" [...] <b>vocals,</b> and its <b>message</b> of facing up against absurdity in the world. Yamamoto singled out the song [...] "Start Line" [...] as having one of the most special {{compositions}} of the album. Yajima also singled out the song [...] "Seki o Tatsu" [...] for the [...] "uneasy atmosphere" [...] created by the song's [...] "inorganic keyboard phrases".|$|R
50|$|The demo was {{recorded}} using entirely programmed instrumentation. Busbee, {{who serves as}} the record's producer, sought to blend the synthesized instruments with authentic ones to create a soundscape that is radio-friendly but {{in tune with the}} song's <b>message.</b> <b>Vocals</b> were recorded in the summer of 2014. Alaina underwent vocal surgery on August 12, 2014 and re-recorded the lead vocals on the song after her recovery. Her vocal range expanded after her surgery with Alaina hitting a big note during the song's bridge that she struggled to reach prior.|$|R
5000|$|The 5th Rising Stars of Manga {{competition}} {{added the}} People’s Choice award, where the top-20 finalists had their entire entries {{judged by the}} fans on the Tokyopop website. “We are really pleased {{to open up the}} Rising Stars judging to the fans," [...] commented Tokyopop editor Rob Valois. [...] "Since so many people have been <b>vocal</b> on the <b>message</b> boards and at industry conventions, we’re offering them all a chance to shape the future of manga. I’m personally excited to see how the fans’ favorite will compare to our own." ...|$|R
50|$|Yet it was {{primarily}} this experiment alone, and anecdotal references {{to his own}} clinical work, upon which Moses based his belief that 'vocal dynamics truthfully reflect psychodynamics' and that 'each emotion has its vocal expression'. He further asserted that when an incongruence between the <b>vocal</b> and verbal <b>message</b> occurs 'the voice {{is more likely to}} reveal the truth about the personality' than the speech and that therefore, 'before attempting to analyse the voice, one must divorce it from the message it seeks to convey'. However, few other experiments of the hundreds conducted since Moses assessed the recorded voice of a boy have evidenced that listeners are able to accurately deduce information about the speaker from the voice alone.|$|R
40|$|AbstractThe first field {{experiment}} with intelligent speed adaptation (ISA) in Malaysia {{was held in}} December 2010 in the State of Penang. Eleven private cars were instrumented with an advisory system. The system {{used in the present}} study included a <b>vocal</b> warning <b>message</b> and a visual text message that is activated when the driver attempts to exceed the speed limit. When the driver decreases the speed, the warning stops; otherwise it is continuously repeated. The test drivers drove the vehicles for three months with the installed system, and the speed was continuously logged in all vehicles. The warning was however only activated in the second month of the three month period. The present study aimed to evaluate the effects of an advisory ISA on driving speed, traffic safety, and drivers' attitude, behavior, and acceptance of the system. To examine these effects, both the survey and the logged speed data were analyzed and explored. The results show a significant reduction in the mean, maximum and 85 th percentile speed due to the use of the system. However, there was no long-lasting effect on the speed when the system was deactivated. In the post-trial survey, drivers declared that the system helped them well in following the speed limits and that it assisted them in driving more comfortably. Furthermore, the warning method was more accepted compared to a supportive system, such as active accelerator pedal (AAP). After the trial, most drivers were willing to keep an ISA system...|$|R
40|$|Cats’ (Felis catus) {{communicative}} behaviour towards humans was explored using {{a social}} referencing paradigm {{in the presence}} of a potentially frightening object. One group of cats observed their owner delivering a positive emotional message, whereas another group received a negative emotional message. The aim was to evaluate whether cats use the emotional information provided by their owners about a novel/unfamiliar object to guide their own behaviour towards it. We assessed the presence of social referencing, in terms of referential looking towards the owner (defined as looking to the owner immediately before or after looking at the object), the behavioural regulation based on the owner’s emotional (positive vs negative) <b>message</b> (<b>vocal</b> and facial), and the observational conditioning following the owner’s actions towards the object. Most cats (79 %) exhibited referential looking between the owner and the object, and also to some extent changed their behaviour in line with the emotional message given by the owner. Results are discussed in relation to social referencing in other species (dogs in particular) and cats’ social organization and domestication history...|$|R
40|$|This article {{examines}} {{data obtained from}} the coding of 10 -minute videotapes of married couples dicussing their relationships. Each speaker turn was coded as positive, neutral or negative separately {{for each of the}} communication channels - verbal, visual, vocal or total. Three different types of negative messages were then isolated: (a) direct negative messages or those that are negative on all channels (verbal, visual and <b>vocal),</b> (b) negative <b>messages</b> with neutral or ambiguous words but negative visual and vocal cues, and (c) negative messages accompanied by smiles. The findings indicated that the preferred mode for sending negative messages was with a smile, irrespective of sex or marital adjustment level. The negative communication of unhappy couples proved to be more direct or intense (i. e. negative on more channels) than those of happy couples, and perhaps more negative than required for conveying the desired <b>message.</b> The <b>vocal</b> channel was found {{to be the most important}} channel in negative messages between spouses, since negative messages were coded negative in the vocal channel more frequently than in any other...|$|R

