10000|10000|Public
25|$|This {{implies that}} in a {{weighted}} sum of variables, the variable with the largest weight will have a disproportionally large weight in the <b>variance</b> <b>of</b> the total. For example, if X and Y are uncorrelated {{and the weight of}} X is two times the weight of Y, then the weight of the <b>variance</b> <b>of</b> X will be four times the weight of the <b>variance</b> <b>of</b> Y.|$|E
25|$|In {{this form}} R2 is {{expressed}} as {{the ratio of}} the explained variance (<b>variance</b> <b>of</b> the model's predictions, which is SSreg / n) to the total variance (sample <b>variance</b> <b>of</b> the dependent variable, which is SStot / n).|$|E
25|$|That is, the <b>variance</b> <b>of</b> {{the mean}} {{decreases}} when n increases. This formula for the <b>variance</b> <b>of</b> the mean {{is used in}} the definition of the standard error of the sample mean, which {{is used in the}} central limit theorem.|$|E
2500|$|The <b>variances</b> <b>of</b> the log inverse {{variables}} are {{identical to the}} <b>variances</b> <b>of</b> the log variables: ...|$|R
3000|$|From {{equations}} (21) and (23) it {{is apparent}} that the <b>variances</b> <b>of</b> the two-stage estimators Y_ 2 [...] and Ỹ_ 2 [...] depend on the <b>variances</b> <b>of</b> the y [...]...|$|R
30|$|Other {{more complex}} cases {{can be viewed}} as the {{combination}} of these two cases. Here, notice that the <b>variances</b> <b>of</b> channel gains are constant, but the <b>variances</b> <b>of</b> the estimation errors depend on the position of the code block.|$|R
25|$|The {{expected}} value and <b>variance</b> <b>of</b> a Poisson-distributed random variable are both equal to λ.|$|E
25|$|That the <b>variance</b> <b>of</b> {{the random}} {{variable}} describing the next event grows smaller and smaller.|$|E
25|$|Fréchet {{distribution}}: The <b>variance</b> <b>of</b> this {{distribution is}} defined only for α > 2.|$|E
3000|$|... [...]. The <b>variances</b> <b>of</b> each {{block in}} the frame is then summed up to get the motion <b>variance</b> measure <b>of</b> each frame.|$|R
2500|$|... where [...] and [...] are {{the sample}} <b>variances</b> <b>of</b> the {{estimated}} residuals and {{the dependent variable}} respectively, which {{can be seen as}} biased estimates <b>of</b> the population <b>variances</b> <b>of</b> the errors and of the dependent variable. These estimates are replaced by statistically unbiased versions: [...] and [...]|$|R
30|$|Calculate {{the initial}} <b>variances</b> <b>of</b> the {{measurement}} noise {σ _vk^ 2 (0)}_k= 1 ^K which represent the <b>variances</b> <b>of</b> the estimation error of the covariance-fitting-based algorithm at t= 0. These variances {{can also be}} obtained from the diagonal entries of (54) for a large number of samples.|$|R
25|$|For non-normal samples, the <b>{{variance}}</b> <b>of</b> {{the sample}} variance {{depends on the}} kurtosis; for details, please see variance.|$|E
25|$|The {{population}} variance matches the <b>variance</b> <b>of</b> the generating probability distribution. In this sense, {{the concept of}} population can be extended to continuous random variables with infinite populations.|$|E
25|$|Gamma distribution, for a non-negative scaling parameter; {{conjugate}} to {{the rate}} parameter of a Poisson distribution or exponential distribution, the precision (inverse <b>variance)</b> <b>of</b> a normal distribution, etc.|$|E
5000|$|... where [...] and [...] are {{the sample}} <b>variances</b> <b>of</b> the {{estimated}} residuals and {{the dependent variable}} respectively, which {{can be seen as}} biased estimates <b>of</b> the population <b>variances</b> <b>of</b> the errors and of the dependent variable. These estimates are replaced by statistically unbiased versions: [...] and [...]|$|R
5000|$|... #Subtitle level 2: Regional <b>Variances</b> <b>of</b> {{the term}} 'Horticultural Netting' ...|$|R
40|$| {{significance}} level when the <b>variances</b> <b>of</b> treatment groups are unequal, and,|$|R
25|$|When {{the mean}} is not known, the minimum {{mean squared error}} {{estimate}} of the <b>variance</b> <b>of</b> a sample from Gaussian distribution is achieved by dividing by nnbsp&+nbsp&1, rather than nnbsp&−nbsp&1 or nnbsp&+nbsp&2.|$|E
25|$|Coal {{homogenization}} {{refers to}} the process of mixing coal to reduce the <b>variance</b> <b>of</b> the product supplied. This homogenization process is performed during the coal stockpiling operation. Although the terms blending and homogenization are often used interchangeably, there are differences as the definitions show. The most notable difference is that blending refers to stacking coal from different sources together on one stockpile. The reclaimed heap would then typically have a weighted average output quality of the input sources. In contrast, homogenization focuses on reducing the <b>variance</b> <b>of</b> only one source. A blending operation will cause some homogenization.|$|E
25|$|In other words, the {{standard}} deviation σ (sigma) is the square root of the <b>variance</b> <b>of</b> X; i.e., it is the square root of the average value of (X−μ)2.|$|E
3000|$|Compared {{with the}} <b>variances</b> <b>of</b> channel {{estimation}} over one OFDMA symbol as in (22)–(24), the estimation <b>variances</b> (29)–(31) <b>of</b> the weighted average estimator (15)–(18) are significantly reduced {{owing to the}} fact that [...]...|$|R
2500|$|It also {{follows that}} the <b>variances</b> <b>of</b> the logit {{transformed}} variables are: ...|$|R
30|$|In {{order to}} assess the quality of sample balance between treated and matched controls, we follow {{recommendations}} by Stuart ([2010]) and test for differences in mean and <b>variances</b> <b>of</b> propensity scores across treated and control groups. We find no significant mean-differences and the ratio <b>of</b> <b>variances</b> <b>of</b> propensity scores (with a value of 1.3) further indicates good sample balance.|$|R
25|$|These values can be {{used for}} a {{statistical}} criterion as to the goodness of fit. When unit weights are used, the numbers should be divided by the <b>variance</b> <b>of</b> an observation.|$|E
25|$|However, if one changes coordinates, the {{way that}} {{coefficients}} change depends on the <b>variance</b> <b>of</b> the object, and one cannot ignore the distinction; see covariance and contravariance of vectors.|$|E
25|$|This simple {{combination}} is possible because the sample mean and sample <b>variance</b> <b>of</b> the normal distribution are independent statistics; {{this is only}} true for the normal distribution, and in fact characterizes the normal distribution.|$|E
50|$|The {{key reason}} for studentizing is that, in {{regression}} {{analysis of a}} multivariate distribution, the <b>variances</b> <b>of</b> the residuals at different input variable values may differ, even if the <b>variances</b> <b>of</b> the errors at these different input variable values are equal. The issue {{is the difference between}} errors and residuals in statistics, particularly the behavior of residuals in regressions.|$|R
5000|$|Variance-time plot: {{based on}} the {{analysis}} <b>of</b> the <b>variances</b> <b>of</b> the aggregate processes ...|$|R
30|$|The data {{gathered}} were analyzed through one-way analysis <b>of</b> <b>variances</b> (ANOVA) which has two main assumptions; normality {{of the data}} and homogeneity <b>of</b> the <b>variances</b> <b>of</b> the groups.|$|R
25|$|When unit weights {{are used}} (W = I, the {{identity}} matrix), it is {{implied that the}} experimental errors are uncorrelated and all equal: M = σ2I, where σ2 is the a priori <b>variance</b> <b>of</b> an observation.|$|E
25|$|The weights should, ideally, {{be equal}} to the {{reciprocal}} of the <b>variance</b> <b>of</b> the measurement. applies. In this case the weight matrix should ideally {{be equal to}} the inverse of the variance-covariance matrix of the observations.|$|E
25|$|These same {{formulae}} {{can be used}} {{to obtain}} confidence intervals on the <b>variance</b> <b>of</b> residuals from a least squares fit under standard normal theory, where k is now the number of degrees of freedom for error.|$|E
3000|$|... (n) 2 are {{estimated}} from the <b>variances</b> <b>of</b> satellite MF model coefficients in 2005, averaged over all orders. Given Equation (1), the relevant time-scales are by definition τ _c(n)=√(3)σ _g(n) / σ _ġ(n), with σ _ġ(n) the secular variation variances, estimated from the <b>variances</b> <b>of</b> satellite SV model coefficients in 2005, averaged over all orders (see Gillet et al. 2013).|$|R
3000|$|... {{from the}} <b>variances</b> <b>of</b> the {{coefficient}} series h_n^m(t) and v_n^m(t) in dipole coordinates, first obtained {{over the period}} 1960 to 2010 for which the model is weakly sensitive to the a priori matrices (we would underestimate the <b>variances</b> <b>of</b> the model parameters by considering the era before 1960, where fewer, less accurate data are available). Coefficients are then rotated back into geographic coordinates.|$|R
30|$|For this study, the {{expected}} durations and <b>variances</b> <b>of</b> activities {{will be allowed}} to differ but {{the expected}} durations and <b>variances</b> for repetitions <b>of</b> a given activity will be fixed.|$|R
