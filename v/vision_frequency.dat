0|51|Public
2500|$|... "Welcome to Channel 0/28 Multicultural Television, Sydney and Melbourne. A {{section of}} the Special Broadcasting Service, {{transmitting}} on VHF Channel 0 with a <b>vision</b> carrier <b>frequency</b> of 46.25MHz and on UHF Channel 28 with a <b>vision</b> carrier <b>frequency</b> of 527.25MHz. As {{well as from the}} Hyatt Kingsgate Tower in Kings Cross, Sydney, on UHF Channel 54 with a <b>vision</b> carrier <b>frequency</b> of 737.25MHz".|$|R
25|$|Bennett, P.J., & Cortese, F. (1996). Masking {{of spatial}} {{frequency}} in visual memory depends on distal, not retinal, <b>frequency.</b> <b>Vision</b> Research, 36(2), 233–238.|$|R
30|$|Positioning systems {{generate}} {{a lot of}} interest and effort both in academic and industrial research and nowadays, a lot of technologies can be used and mixed (e.g., ultrasound, laser scanner, infrared, camera <b>vision,</b> radio <b>frequencies,</b> and custom sensors). Each system has addressed the aggregation of sensor data into location estimations via most suitable methods.|$|R
40|$|On {{the basis}} ot MacAdam's data, we have {{computed}} a psychophysical function which characterizes the transference of the colour information processed {{by the human}} visual system in the chromatic frequency domain. This function, obtained using chromatic-discrimination criteria, shows a cut-off frequency between 0. 01375 and 0. 02 c/nm, depending upon the colour-tolerance units adopted. Colour <b>vision</b> Chromatic <b>frequency</b> Chromatic-contrast sensitivity function Colour signa...|$|R
40|$|All the {{secondary}} school students of the Albanian and Croatian communities of Molise were tested for colour <b>vision.</b> Percent <b>frequencies</b> of red-green colour blindness were 5. 91 +/- 1. 73 and 7. 02 +/- 3. 38. These figures are in agreement with those found for Central Italy thus confirming the similarity of these communities {{with the rest of}} Italy as described for several other autosomal polymorphisms. The distribution of red-green CB genes in Europe shows that they are slightly more frequent in Northern Europe than in Southern Europe and Northern Africa...|$|R
40|$|The {{purpose of}} this paper is to {{evaluate}} to what extent cracked and pirated software instruments for electronic music production represent an important contributor in the industrial dynamics of the electronic music industry. Current literature on technology transfer and technology assimilation is silent on this mode of technology transfer. This paper seeks to raise the use of cracked software in electronic music composition as a valid contributor to industrial dynamics. Additionally the paper seeks to comment on what impact the availability of these tools has on creativity within the field. A survey of 122 artists was conducted in December 2004. Results pertaining to the importance of technologies for achieving creative <b>visions</b> and <b>frequency</b> of use will be presented...|$|R
5000|$|El Cerdotado has powers {{similar to}} Superman. He can fly, has x-ray <b>vision,</b> high <b>frequency</b> hearing, {{armoured}} skin and can move at 'superspeed'. He also has [...] "a coward cloak", a time machine, a suit {{that makes him}} travel thru the internet (à la Tron) and other abilities. He has [...] "mental powers", such as mind-reading {{and the ability to}} sense when his girlfriend, Jersey, (an anthrophomorfic cow) cheats him. He can listen radio waves. He displays a healing ability: When he runs, his legs and lower body are destroyed due to friction or his skin ripples to the point of coming off due to the speed, but he eventually regenerates after scaring friends and foes to death.|$|R
5000|$|The authors {{introduce}} the story via science fiction tropes {{such as the}} uncanny - coincidences, ESP, unearthly lighting effects, distorted <b>visions,</b> supernatural aural <b>frequencies</b> and scenes dissolving into another - pointing to the underlying threat of instability that drives the novel. The story is told {{through the eyes of}} Arthur, a writer turned journalist who feels he is compromising his art. Although Arthur at first holds to high ideals (he values [...] "literature" [...] over journalism, sacrificial literary types over opportunists), he gradually moves away from them because {{he wants to be a}} somebody.|$|R
40|$|The thesis {{presents}} a successful project of vision screening in preschool children carried out mostly in kindergartens in Pardubice. The quantitative, non- experimental research of <b>vision</b> defects <b>frequency</b> in preschool children in Pardubice was realized {{by means of}} deduktive method and brought surprising, as well as alarming results. It proves, that 7. 8 % of preschool children had hidden vision defects, as until the time of vision screening these defects had not been discovered by pediatric practitioners at regular preventive examinations and also remained unnoticed by parents. The minimum of 10 % rate of vision defects in preschool children then indicates the necessity to introduce vision reeducation in common kindergarten classes in Pardubice. As special pedagogical support, the thesis provides comprehensive methodology of vision reeducation. The method tank of 50 games and playful activities with thoroughly worked up methodology will help the teachers in common kindergarten classes to work with visually handicapped children...|$|R
40|$|This study {{examined}} density of networks, frequency of interaction and shared vision {{business to business}} social capital constructs in 507 businesses in two states. Half of the communities were highly indigenous and half non indigenous. Shared vision was significantly higher for business owners from indigenous communities than those from non indigenous communities. When examined by retail or service based businesses shared vision was significantly higher among service based businesses. No other construct of social capital was significantly different for community type or business type. The findings can help improve {{understanding the importance of}} building capacity and strategic partnerships within communities. EXECUTIVE SUMMARY Small firms operating in rural communities have social capital resources available to them. Little research has been done on cross cultural social capital with no studies found that examined the social capital present in culturally distinct communities in the United States. The research reported here, {{as a part of a}} larger study on rural entrepreneurship, focused on network density, shared <b>vision</b> and <b>frequency</b> of interaction among business owners in both heavily indigenou...|$|R
40|$|Purpose: To compare {{electroretinogram}} (ERG) {{characteristics in}} patients with retinitis pigmentosa (RP) and normal subjects using frequency domain analysis. Methods: Five basic ERG recordings were performed in normal subjects and patients with a clinical diagnosis of RP according to the ISCEV (International Society of Clinical Electrophysiology of <b>Vision)</b> protocol. <b>Frequency</b> domain analysis was performed by MATLAB software. Different frequency domain parameters were compared between the study groups. Results: Peak frequency (Fmod) of flicker and oscillatory responses in RP patients showed significant (P< 0. 0001) high pass response as compared to normal controls. Peak frequency (Fmod) of the other responses was not significantly different between the two groups. Conclusion: In addition to conventional ERG using time domain methods, frequency domain analysis may be useful for diagnosis of RP. Oscillatory and flicker responses may be analyzed in frequency domain. Fast Fourier transform may reveal two distinct high pass responses (shift to higher frequencies) in Fmod. Time and frequency domain analyses may be performed simultaneously with many modern ERG machines and may therefore be recommended in RP patients...|$|R
40|$|A {{total of}} 1018 signs in one deaf child’s naturalistic {{interaction}} with her deaf mother, {{between the ages}} 19 - 24 months were analysed. This study summarises regular modification processes in the phonology of the child sign’s handshape, location, movement and prosody. Firstly changes to signs were explained by the notion of phonological markedness. Secondly, the child managed her production of first signs through two universal processes: structural change and substitution. Constraints unique to the visual modality also caused sign language specific acquisition patterns, namely: more errors for handshape articulation in locations in peripheral <b>vision,</b> a high <b>frequency</b> of whole sign repetitions and feature group rather than one-to-one phoneme substitutions as in spoken language development...|$|R
40|$|The {{measurement}} {{and control of the}} end-effector position of a large two-link flexible manipulator are investigated. The system implementation is described and an initial algorithm for static end-point positioning is discussed. Most existing robots are controlled through independent joint controllers, while the end-effector position is estimated from the joint positions using a kinematic relation. End-point position feedback can be used to compensate for uncertainty and structural deflections. Such feedback is especially important for flexible robots. Computer vision is utilized to obtain end-point position measurements. A look-and-move control structure alleviates the disadvantages of the slow and variable computer <b>vision</b> sampling <b>frequency.</b> This control structure consists of an inner joint-based loop and an outer vision-based loop. A static positioning algorithm was implemented and experimentally verified. This algorithm utilizes the manipulator Jacobian to transform a tip position error to a joint error. The joint error is then used to give a new reference input to the joint controller. The convergence of the algorithm is demonstrated experimentally under payload variation. A Landmark Tracking System (Dickerson, et al 1990) is used for vision-based end-point measurements. This system was modified and tested. A real-time control system was implemented on a PC and interfaced with the vision system and the robot...|$|R
40|$|Explore {{the brain}} code: {{synchronization}} and sequence of spikes for signal processing & recognition; • Integrate speech processing with auditory perception: – The auditory features are multiple, simultaneous, and time structured; – There is no disjunction between analysis and recognition; – The auditory objects have a structure. • Develop new signal processing and pattern recognition technics: – Polysensoriality and sensory substitution: visual and auditory interac-tions; – Source separation and cocktail party processing. J. ROUAT, 30 April 09, McGill •First •Prev •Next •Last •Go Back •Full Screen •Close •Quit Rate and synchronization coding {{in the brain}} Rate coding Many neurons should respond to conjunctions of properties (orientation, motion and color in <b>vision)</b> (tonotopic <b>frequency,</b> amplitude modulation, transient in audition). With a rate code the number of neurons should be quite large to encode all targets potentially shown to the sensory systems. Their is an explosion of the feature combinations and the spatial organization of the characteristics are lost. Synchronization Synchronization by coincidence Synchronization of pulses without oscilla-tory behavior: coincidence detector in the auditory system for fast computation. Synchronization with oscillatory neuronal assemblies Oscillatory rhythms for memory, perception, etc. One hypothesis: A non stimulated brain (brain at rest) exhibits oscillations in large networks of oscillatory neurons. A stimulation is then a perturbation of this oscillatory mode [1] a. aBuzsáki, 200...|$|R
40|$|The {{research}} {{and use of}} positioning and navigation technologies outdoors has seen a steady and exponential growth. Based on this success, there have been attempts to implement these technologies indoors, leading to numerous studies. Most of the algorithms, techniques and technologies used have been implemented outdoors. However, how they fare indoors is different altogether. Thus, several technologies have been proposed and implemented to improve positioning and navigation indoors. Among them are Infrared (IR), Ultrasound, Audible Sound, Magnetic, Optical and <b>Vision,</b> Radio <b>Frequency</b> (RF), Visible Light, Pedestrian Dead Reckoning (PDR) /Inertial Navigation System (INS) and Hybrid. The RF technologies include Bluetooth, Ultra-wideband (UWB), Wireless Sensor Network (WSN), Wireless Local Area Network (WLAN), Radio-Frequency Identification (RFID) and Near Field Communication (NFC). In addition, positioning techniques applied in indoor positioning systems include the signal properties and positioning algorithms. The prevalent signal properties are Angle of Arrival (AOA), Time of Arrival (TOA), Time Difference of Arrival (TDOA) and Received Signal Strength Indication (RSSI), while the positioning algorithms are Triangulation, Trilateration, Proximity and Scene Analysis/ Fingerprinting. This paper presents a state-of-the-art survey of indoor positioning and navigation systems and technologies, and their use in various scenarios. It analyses distinct positioning technology metrics such as accuracy, complexity, cost, privacy, scalability and usability. This paper has profound implications for future studies of positioning and navigation...|$|R
40|$|Abstract — There is a {{persistent}} {{need in the}} oceanographic community for accurate three dimensional reconstructions of seafloor structures. To meet this need underwater mapping techniques have expanded to {{include the use of}} stereo <b>vision</b> and high <b>frequency</b> multibeam sonar for mapping scenes 10 ’s to 100 ’s of square meters in size. Both techniques have relative advantages and disadvantages that depend on the task at hand and the desired accuracy. In this paper, we develop a method to constrain the often problematic stereo correspondence search to small sections of the image that correspond to estimated ranges along the epipolar lines calculated from coregistered multibeam sonar micro-bathymetry. This approach can be applied to both sparse feature based and dense area-based stereo correspondence techniques. Data were collected on an underwater vehicle survey using a calibrated stereo rig and a multibeam sonar gatherin...|$|R
40|$|We propose an {{algorithm}} of {{stereo matching}} {{based upon a}} multiscale decomposition of the input images. Contrary to "coarse-to-fine"-type algorithms, the proposed method processes information from different frequency bands simultaneously. This task is achieved by a localized correlation function defined for every pixel of the image, obtained by integration {{with respect to a}} scale variable. This is equivalent to defining a correlation kernel, which is extremely well localized with respect to position and disparity variables. Keywords [...] - stereo <b>vision,</b> matching, correlation, <b>frequency,</b> scale, wavelet transform. I. Introduction T HE matching of stereoscopic images is one of the classical problems of computer vision. Several approaches have been developed (matching of characteristics or primitives [9], [11], global matching [12], object-oriented matching, [...] .). Correlationbased approaches are among the most popular [5], [11], but generally suffer from the lack of locality of correlation f [...] ...|$|R
5000|$|Different {{points in}} the visual system have very {{different}} critical flicker fusion rate (CFF) sensitivities; the overall threshold frequency for perception cannot exceed the slowest of these for a given modulation amplitude. Each cell type integrates signals differently. For example, rod photoreceptor cells, which are exquisitely sensitive and capable of single-photon detection, are very sluggish, with time constants in mammals of about 200 ms. Cones, in contrast, while having much lower intensity sensitivity, have much better time resolution than rods do. For both rod- and cone-mediated <b>vision,</b> the fusion <b>frequency</b> increases {{as a function of}} illumination intensity, until it reaches a plateau corresponding to the maximal time resolution for each type of vision. The maximal fusion <b>frequency</b> for rod-mediated <b>vision</b> reaches a plateau at about 15 Hz, whereas cones reach a plateau, observable only at very high illumination intensities, of about 60 Hz ...|$|R
40|$|Research on dialog {{systems is}} a very active area in social robotics. During the last two decades, these systems have evolved from those based only on speech {{recognition}} and synthesis to the current and modern systems, which include new components and multimodality. By multimodal dialogue we mean the interchange of information among several interlocutors, not just using their voice as the mean of transmission but also all the available channels such as gestures, facial expressions, touch, sounds, etc. These channels add information to the message to be transmitted in every dialogue turn. The dialogue manager (IDiM) {{is one of the}} components of the robotic dialog system (RDS) and is in charge of managing the dialogue flow during the conversational turns. In order to do that, it is necessary to coherently treat the inputs and outputs of information that flow by different communication channels: audio, <b>vision,</b> radio <b>frequency,</b> touch, etc. In our approach, this multichannel input of information is temporarily fused into communicative acts (CAs). Each CA groups the information that flows through the different input channels into the same pack, transmitting a unique message or global idea. Therefore, this temporary fusion of information allows the IDiM to abstract from the channels used during the interaction, focusing only on the message, not on the way it is transmitted. This article presents the whole RDS and the description of how the multimodal fusion of information is made as CAs. Finally, several scenarios where the multimodal dialogue is used are presented. Comunidad de Madri...|$|R
40|$|Due to globalisation, {{companies}} have to {{become more and more}} agile in order to face demand fluctuations and growing customisation needs. Indeed, the mass production market moves to a mass customization one, which could be defined as the production {{of a wide variety of}} end products at a low unit cost. During last years, many efforts have been done in order to improve operating system reactivity (with the Flexible Manufacturing initiative for example), but the manufacturing decision process did not really change, and then doesn't enable to fully make the most of these new operating system skills. Facing these new trends, a lot of new research works are focusing on identification technologies, like Auto-ID, biometry or <b>vision</b> ones. Radio <b>Frequency</b> Identification technology (RFID) represents a quick and safe way to track products, opening the way of linking informational and physical flows, and providing an accurate, real time vision of the shop floor. These new technologies appear like a catalyst to change the fifty years old way of controlling production through traditional MRP² systems...|$|R
40|$|This letter {{introduces}} {{a study to}} precisely measure what an increase in spike timing precision can add to spike-driven pattern recognition algorithms. The concept of generating spikes from images by converting gray levels into spike timings is currently at the basis of almost every spike-based modeling of biological visual systems. The use of images naturally leads to generating incorrect artificial and redundant spike timings and, more important, also contradicts biological findings indicating that visual processing is massively parallel, asynchronous with high temporal resolution. A new concept for acquiring visual information through pixel-individual asynchronous level-crossing sampling has been proposed in a recent generation of asynchronous neuromorphic visual sensors. Unlike conventional cameras, these sensors acquire data not at fixed points {{in time for the}} entire array but at fixed amplitude changes of their input, resulting optimally sparse in space and time—pixel individually and precisely timed only if new, (previously unknown) information is available (event based). This letter uses the high temporal resolution spiking output of neuromorphic event-based visual sensors to show that lowering time precision degrades performance on several recognition tasks specifically when reaching the conventional range of machine <b>vision</b> acquisition <b>frequencies</b> (30 – 60  Hz). The use of information theory to characterize separability between classes for each temporal resolution shows that high temporal acquisition provides up to 70 % more information that conventional spikes generated from frame-based acquisition as used in standard artificial vision, thus drastically increasing the separability between classes of objects. Experiments on real data show that the amount of information loss is correlated with temporal precision. Our information-theoretic study highlights the potentials of neuromorphic asynchronous visual sensors for both practical applications and theoretical investigations. Moreover, it suggests that representing visual information as a precise sequence of spike times as reported in the retina offers considerable advantages for neuro-inspired visual computations...|$|R
40|$|Masking, adaptation, and {{summation}} paradigms {{have been}} used to investigate the characteristics of early spatiotemporal vision. Each has been taken to provide evidence for (i) oriented and (ii) nonoriented spatial filtering mechanisms. However, subsequent findings suggest that the evidence for nonoriented mechanisms has been misinterpreted: possibly, those experiments revealed the characteristics of suppression (e. g., gain control) not excitation, or merely the isotropic subunits of the oriented detecting-mechanisms. To shed light on this, we used all three paradigms to focus on the “high-speed” corner of spatiotemporal <b>vision</b> (low spatial <b>frequency,</b> high temporal frequency) where cross-oriented achromatic effects are greatest. We used flickering Gabor patches as targets and a 2 IFC procedure for monocular, binocular and dichoptic stimulus presentations. To account for our results we devised a simple model involving an isotropic monocular filter-stage feeding orientation-tuned binocular filters. Both filter stages are adaptable and their outputs are available to the decision-stage following nonlinear contrast transduction. However, the monocular isotropic filters adapt only to high-speed stimuli—consistent with a magnocellular sub-cortical substrate—and benefit decision making only for high-speed stimuli. According to this model, the visual processes revealed by masking, adaptation and summation are related but not identical...|$|R
40|$|Abstract—The {{computation}} {{of local}} visual motion can be ac-complished very efficiently in the focal plane with custom very large-scale integration (VLSI) hardware. Algorithms based on {{measurement of the}} spatial and temporal frequency content of the visual motion signal, since they incorporate no thresh-olding operation, allow highly sensitive responses to low contrast and low-speed visual motion stimuli. We describe analog VLSI implementations of the three most prominent spatio-temporal frequency-based visual motion algorithms, present characteriza-tions of their performance, and compare the advantages of each on an equal basis. This comparison highlights important issues {{in the design of}} analog VLSI sensors, including the effects of circuit design on power consumption, the tradeoffs of subthreshold versus above-threshold MOSFET biasing, and methods of layout for focal plane vision processing arrays. The presented sensors are capable of distinguishing the direction of motion of visual stimuli to less than 5 % contrast, while consuming as little as 1 W of electrical power. These visual motion sensors are useful in embedded applications where minimum power consumption, size, and weight are crucial. Index Terms—Analog very large-scale integration (VLSI), biomimetic, spatio-temporal <b>frequency,</b> <b>vision</b> chip. I...|$|R
40|$|AbstractWhen an undulating surface {{bearing a}} painted texture is {{illuminated}} the resulting shading pattern produces in-phase modulations {{of the mean}} luminance (LM) and luminance amplitude (AM) of the texture. Experimentally, in-phase combinations of LM and AM (LM+AM) are seen as undulating surfaces whereas anti-phase combinations (LM−AM) are more ambiguous; being seen as undulating when presented alone but as flat when presented in a plaid with LM+AM. AM is a second-order cue and its influence on shape-from-shading can be explained with a bottom-up layer decomposition model containing second-order mechanisms. However, the role of second-order vision in layer decomposition has not been established. If second-order vision is involved in layer decomposition then the perceptual differences between LM+AM and LM−AM should depend on {{the properties of the}} carrier texture {{in a way that is}} consistent with the known properties of second-order vision. Here we find a preference for carrier frequencies 3 octaves above the modulation frequency and take this as an indication that second-order (filter-rectify-filter) mechanisms are involved in processing our LM/AM mixes. We introduce a modified model which takes into account the selectivity of second-order <b>vision</b> for carrier <b>frequency...</b>|$|R
40|$|It {{has been}} {{suggested}} that the Bouba/Kiki effect, in which meaningless speech sounds are systematically mapped onto rounded or angular shapes, reflects a universal crossmodal correspondence between audition and <b>vision.</b> Here, radial <b>frequency</b> (RF) patterns were adapted in order to compare the Bouba/Kiki effect in Eastern and Western participants demonstrating different perceptual styles. Three attributes of the RF patterns were manipulated: The frequency, amplitude, and spikiness of the sinusoidal modulations along the circumference of a circle. By testing participants in the US and Taiwan, both cultural commonalities and differences in sound-shape correspondence were revealed. RF patterns {{were more likely to be}} matched with “Kiki” than with “Bouba” when the frequency, amplitude, and spikiness increased. The responses from both groups of participants had a similar weighting on frequency; nevertheless, the North Americans had a higher weighting on amplitude, but a lower weighting on spikiness, than their Taiwanese counterparts. These novel results regarding cultural differences suggest that the Bouba/Kiki effect is partly tuned by differing perceptual experience. In addition, using the RF patterns in the Bouba/Kiki effect, provides a “mid-level” linkage between visual and auditory processing, and a future understanding of sound-shape correspondences based on the mechanism of visual pattern processing...|$|R
40|$|There is a {{persistent}} {{need in the}} oceanographic community for accurate three dimensional reconstructions of seafloor structures. To meet this need underwater mapping techniques have expanded to {{include the use of}} stereo <b>vision</b> and high <b>frequency</b> multibeam sonar for mapping scenes 102 ̆ 7 s to 1002 ̆ 7 s of square meters in size. Both techniques have relative advantages and disadvantages that depend on the task at hand and the desired accuracy. In this paper, we develop a method to constrain the often problematic stereo correspondence search to small sections of the image that correspond to estimated ranges along the epipolar lines calculated from coregistered multibeam sonar micro-bathymetry. This approach can be applied to both sparse feature based and dense area-based stereo correspondence techniques. Data were collected on an underwater vehicle survey using a calibrated stereo rig and a multibeam sonar gathering coincident datasets. Overall, the constrained correspondence method shows improvements in the number and reliability of correct matches and allows for reduction in complexity of feature descriptors but it is heavily reliant {{on the quality of the}} intrinsic and extrinsic calibration of the camera and sonar systems...|$|R
40|$|PURPOSE: To {{analyze the}} {{indications}} for intraocular lens (IOL) exchange, interval {{between the first}} IOL implantation and the exchange, type and mix of IOLs used, effect on <b>vision,</b> and <b>frequency</b> of complications. SETTING: Cincinnati Eye Institute-Cincinnati-Ohio-USA. METHODS: This retrospective study comprised 49 eyes of 49 adult patients who had IOL exchange between 1986 and 2002 performed by the same surgeon. the mean age was 70 years old, and 55 % were women. the mean interval between surgeries was 53. 8 months and the mean follow-up, 35. 6 months. the patients were divided into 2 groups according {{to the type of}} IOL originally implanted: anterior chamber (AC) or posterior chamber (PC). RESULTS: There were 15 eyes with an AC IOL and 34 eyes with a PC IOL. the difference in mean age and follow-up were not statistically significant between groups. the mean interval between the primary surgery and IOL explantation was 82. 3 months in the AC IOL group and 37. 9 months in the PC IOL group. the main reason for IOL exchange was inflammation (53. 34 %) and dislocation/decentration (85. 30 %), respectively. the preoperative best corrected visual acuity was similar in both groups, and visual acuity was maintained or improved in 80 %. Vitreous prolapse was the main intraoperative complication. CONCLUSIONS: the primary indication for IOL exchange was intraocular inflammation in patients with an AC IOL and IOL malposition in patients with a PC IOL. the results confirm the safety and positive visual outcome in this complex group of patients. Universidade Federal de São Paulo, Escola Paulista Med, Complexo Hosp Padre Bento Guarulhos, Cataract Sectors, São Paulo, BrazilUniversidade Federal de São Paulo, Escola Paulista Med, Ctr Estudo Hosp Monumento, São Paulo, BrazilUniv Cincinnati, Cincinnati, OH 45221 USAUniversidade Federal de São Paulo, Escola Paulista Med, Complexo Hosp Padre Bento Guarulhos, Cataract Sectors, São Paulo, BrazilUniversidade Federal de São Paulo, Escola Paulista Med, Ctr Estudo Hosp Monumento, São Paulo, BrazilWeb of Scienc...|$|R
50|$|As {{the story}} progresses, Lord succeeds in {{stealing}} the Heart of Darkness (aka the Eclipso Diamond) and {{uses it to}} control the League, and through them, gains control of the world. Batman rallies Lobo and the remaining Squad members to make a final stand against Lord; escalating to conflict with the compromised Justice League. Meanwhile, Amanda observes that Lord himself is falling {{under the influence of}} the Eclipso Diamond, and warns him of this when Lord has her brought to the White House. Lord realizes too late that Waller's warning held truth. In the following chaos, Batman deems them the new Justice League. Although Lord is able to bring most of the Squad/League under his control, he is defeated when Killer Frost, acting on Batman's instructions, is able to create a prism of ice that reflects Superman's heat <b>vision</b> in a <b>frequency</b> that will disrupt Eclipso's control of the heroes, Eclipso himself being vanquished by Killer Frost as she draws on the life energy of the rest of the heroes and Squad members present, thus limiting the drain on any one of them. In the aftermath of the crisis, Killer Frost is officially released while Lord is kept in Waller's custody, Waller musing that she will use him for 'Task Force XI'.|$|R
40|$|AbstractVelocity {{matching}} {{using the}} method of Constant Stimuli shows that perceived velocity varies with contrast [Thompson, P. (1982). Perceived rate of movement depends upon contrast. Vision Research, 22, 377 – 380]. Random contrast jitter would therefore be expected to increase the slopes of psychometric functions, and thus the velocity discrimination threshold. However, McKee, S., Silverman, G., and Nakayama, K. [(1986) Precise velocity discrimination despite random variation in temporal <b>frequency.</b> <b>Vision</b> Research, 26, 609 – 620] found no effect of contrast jitter on thresholds, {{using the method}} of single stimuli. To determine whether this apparent discrepancy {{is due to the}} difference in methodology, or to the different ranges of temporal frequencies used in the two studies, we used the method of single stimuli to measure psychometric functions at three different velocities (0. 5, 2. 0 and 4. 0 °/s). We found that contrast jitter increased thresholds at low but not at high velocities. Separate analysis of the psychometric functions at each contrast level showed that increases in contrast increased perceived velocity at low standard speeds (0. 5 °/s) but not at high. We conclude that the effect of contrast on perceived speed is real, and not a methodological artefact, but that it is found only at low temporal frequencies...|$|R
40|$|This thesis {{deals with}} {{estimating}} position and orientation in real-time, using measurements from vision and inertial sensors. A {{system has been}} developed {{to solve this problem}} in unprepared environments, assuming that a map or scene model is available. Compared to ‘camera-only’ systems, the combination of the complementary sensors yields an accurate and robust system which can handle periods with uninformative or no vision data and reduces the need for high <b>frequency</b> <b>vision</b> updates. The system achieves real-time pose estimation by fusing vision and inertial sensors using the framework of nonlinear state estimation for which state space models have been developed. The performance of the system has been evaluated using an augmented reality application where the output from the system is used to superimpose virtual graphics on the live video stream. Furthermore, experiments have been performed where an industrial robot providing ground truth data is used to move the sensor unit. In both cases the system performed well. Calibration of the relative position and orientation of the camera and the inertial sensor turn out to be essential for proper operation of the system. A new and easy-to-use algorithm for estimating these has been developed using a gray-box system identification approach. Experimental results show that the algorithm works well in practice...|$|R
5000|$|The flicker fusion {{threshold}} {{is proportional}} to the amount of modulation; if brightness is constant, a brief flicker will manifest a much lower threshold frequency than a long flicker. The threshold also varies with brightness (it is higher for a brighter light source) and with location on the retina where the perceived image falls: the rod cells of the human eye have a faster response time than the cone cells, so flicker can be sensed in peripheral <b>vision</b> at higher <b>frequencies</b> than in foveal vision. This is essentially the concept known as the Ferry-Porter law, where it may take some increase in brightness, by powers of ten, to require as many as 60 flashes to achieve fusion, while for rods, it may take as little as four flashes, since in the former case each flash is easily cut off, and in the latter it lasts long enough, even after 1/4 second, to merely prolong it and not intensify it. [...] From a practical point of view, if a stimulus is flickering, such as computer monitor, decreasing the intensity level will eliminate the flicker.The flicker fusion threshold also is lower for a fatigued observer. Decrease in the critical fusion frequency has often been used as an index of central fatigue.|$|R
40|$|Abstract — This work {{presents}} a stable vision based haptic feedback for micromanipulation using both an asynchronous Address Event Representation (AER) silicon retina and a conventional frame-based camera. At this scale, {{most of the}} grippers used to manipulate objects lack of force sensing. High <b>frequency</b> <b>vision</b> detection thus provides a sound solution to get information about {{the position of the}} object and the tool to provide virtual haptic guides. Artificial retinas present high update rates, which enables to address one of the major challenge of haptic feedback teleoperation systems, namely stability. However static objects are not detected. The haptic feedback is thus based on an asynchronous silicon retina to provide a high update rate of moving objects and a framebased camera to retrieve the position of the target object. This approach is validated by pick-and-place of microspheres (diameter: around 50 micrometers) using a piezoelectric microgripper. The displacement of the tool, as well as the opening and closing of the gripper are controlled by the haptic device. Haptic virtual guides are transmitted to users to assist them in the different steps of the pick-and-place task: a virtual stiffness ensures the correct alignment of the tool with respect to the object, a repulsive haptic force enables users to monitor the gripping step, and operators are assisted while picking and placing the object. I...|$|R
40|$|We {{explored}} how {{changes in}} <b>vision</b> and perturbation <b>frequency</b> impacted upright postural control in healthy adults exposed to continuous multiaxial support-surface perturbation. Ten {{subjects were asked}} to maintain equilibrium in standing stance with eyes open (EO) and eyes closed (EC) during sinusoidal 3 D rotations at 0. 25 (L) and 0. 50 Hz (H). We measured upper-body kinematics – head, trunk, and pelvis – and analyzed differences in horizontal displacements and roll, pitch, and yaw sways. The presence of vision significantly decreased upper-body displacements in the horizontal plane, especially at the head level, while in EC the head was the most unstable segment. H trials produced a greater segment stabilization compared to L ones in EO and EC. Analysis of sways showed that in EO participants stabilized their posture by reducing the variability of trunk angles; in H trials a sway decrease for the examined segments was observed in the yaw plane and, for the pelvis only, in the pitch plane. Our results suggest that, during continuous multiaxial perturbations, visual information induced: (i) in L condition, a continuous reconfiguration of multi-body-segments orientation to follow the perturbation; (ii) in H condition, a compensation for the ongoing perturbation. These findings were not confirmed in EC where the same strategy – that is, the use of the pelvis as a reference frame for the body balance was adopted both in L and H...|$|R
40|$|Peripheral vision {{plays an}} {{important}} role in normal reading, but its role becomes larger for visually impaired people with centralfield loss. This experiment studied whether lexical processing differs in central and peripheral vision through the analysis of wordfrequency effects in lexical decisions. We asked two main questions: (1) Do central and peripheral vision differ in the time course of lexical processing? and (2) do central and peripheral vision differ in the quality of lexical processing? To address the first question, we examined the time course of frequency effects in central and peripheral vision over a range from 25 to 500 ms. We found that significant frequency effects occurred for the shortest exposures, 25 – 50 ms, in central <b>vision,</b> whereas significant <b>frequency</b> effects did not occur in peripheral vision until 100 ms. To address the second question, we used word-frequency effects as a marker for the nature of lexical processing. We compared frequency effects in central and peripheral vision for data within matched ranges of percent accuracy (0 – 20 %, 20 – 40 %, 40 – 60 %, 60 – 80 %, and 80 – 100 %). We found that there was no difference in the pattern of frequency effects in central and peripheral vision at equivalent performance levels. We conclude that lexical processing is slower in peripheral vision, but the quality of lexical processing is similar in central and peripheral vision...|$|R
40|$|Background: Intrauterine growth {{retardation}} (IUGR) resulting in infants born small for gestational {{age is a}} known risk factor for neurologic deficits and may predispose to poor cognitive development later in life. We recently found an association between IUGR and a reduced neuroretinal rim area at 18 years of age. We evaluated the possible association between IUGR and visual function. Subjects and Methods: We studied 26 subjects who had been born small for gestational age and 20 subjects whose birth weights were appropriate for gestational age (controls) using letter acuity thresholds, color <b>vision</b> testing, full-threshold <b>frequency</b> doubling technology perimetry, and rarebit perimetry at 18 years of age. Results: Eight of the subjects who were small for gestational age had a rarebit hit rate below the normal range as compared {{with none of the}} controls (P =. 006). These 8 subjects had a significantly smaller rim-disc ratio compared with the subjects who were small for gestational age who had a normal rarebit hit rate (P =. 047). The frequency doubling technology indices did not differ significantly between the control group and the group that was small for gestational age, nor did the visual acuity, refraction, and color vision test results. Conclusion: These data indicate that IUGR is associated with an increased rate of impaired visual function, which can be detected by using rarebit perimetry but not frequency doubling technology perimetry, visual acuity, or color vision tests...|$|R
40|$|AbstractPeripheral vision {{plays an}} {{important}} role in normal reading, but its role becomes larger for visually impaired people with central-field loss. This experiment studied whether lexical processing differs in central and peripheral vision through the analysis of word-frequency effects in lexical decisions. We asked two main questions: (1) Do central and peripheral vision differ in the time course of lexical processing? and (2) do central and peripheral vision differ in the quality of lexical processing? To address the first question, we examined the time course of frequency effects in central and peripheral vision over a range from 25 to 500 ms. We found that significant frequency effects occurred for the shortest exposures, 25 – 50 ms, in central <b>vision,</b> whereas significant <b>frequency</b> effects did not occur in peripheral vision until 100 ms. To address the second question, we used word-frequency effects as a marker for the nature of lexical processing. We compared frequency effects in central and peripheral vision for data within matched ranges of percent accuracy (0 – 20 %, 20 – 40 %, 40 – 60 %, 60 – 80 %, and 80 – 100 %). We found that there was no difference in the pattern of frequency effects in central and peripheral vision at equivalent performance levels. We conclude that lexical processing is slower in peripheral vision, but the quality of lexical processing is similar in central and peripheral vision...|$|R
