26|5|Public
50|$|<b>Versatile</b> <b>Place</b> and Route (VPR) is {{the final}} {{component}} of VTR. Its input is a BLIF circuit, which it packs, places and routes on an input FPGA architecture.|$|E
40|$|Fast FPGA CAD {{tools that}} produce high quality re-sults {{has been one}} o] the most {{important}} research issues in the FPGA domain. Simulated annealing has been the method of choice for placement. However, simulated annealing is a very compute-intensive method. In our present work we investigate a range of parallelization strategies to speedup simulated annealing with applica-tion to placement]or FPGA. We present experimental results obtained by applying the different parallelization strategies to the <b>Versatile</b> <b>Place</b> and Route (VPR) Tool, implemented on an SGI Origin shared memory multi-processor and an IBM-SP 2 distributed memory multi-processor. The results show the tradeoff between execu-tion time and quality of result for the different paral-lelization strategies. ...|$|E
40|$|Increasing the {{performance}} of uniprocessor systems is becoming increasingly difficult. As a result, processor systems are moving towards chip multiprocessor designs. Because of this trend, parallel programming design is becoming increasingly important. This presents new issues for complex software optimized for uniprocessor performance. CAD tools for placing and routing of FPGA designs are an example of complex uniprocessor-targeted software. In order to study possible performance improvements of these tools in a multiprocessor environment, I implemented parallel Markov Chains and manual parallel programming techniques to the <b>Versatile</b> <b>Place</b> and Route (VPR) benchmark. The results show a definite possibility in increasing speedup of the placement algorithm, with some trade-off {{in the quality of}} result for the parallelized execution. ...|$|E
40|$|We {{present the}} work on a {{simulator}} of construction machinery developed to train workers in their safe use. The simulation setup consists of a real <b>versatile</b> cabin <b>placed</b> on a motion platform {{in order to provide}} a realistic interaction with the system and a stereoscopic augmented reality system for visualization. We present some insights into the mixed reality setup we used for complex construction machines and discuss the interaction and usability problems that have arisen during its development and testing. Visualization has been implemented as a chroma-key-based mixed reality system, which combines the 3 D virtual environment, the real cabin interior, and some superimposed messages to the user. As a result of our experience, we describe the main problems encountered from a usability and ergonomics point of view...|$|R
2500|$|Named as a [...] "monogram man" [...] in {{his final}} season, Hogan won {{first place in the}} pole vault in a May 19, 1923, meet with Michigan Agricultural College, and tied for fifth in the broad jump at the Western Intercollegiate Meet, on June 2–3. According to the 1923 Notre Dame yearbook, The Dome: [...] "Eddie Hogan, who {{consistently}} cleared the bar in the pole vault at twelve feet, accounted for many points during the season". Hogan was joined on the track team by his roommate Elmer Layden, another <b>versatile</b> athlete who <b>placed</b> first in the 100-yard dash during the May meet with Michigan [...] "Aggie". He is said to have trained for the 1924 Paris Olympics but was injured during practice and did not participate.|$|R
40|$|Given an unlabeled road map, we consider, from an {{algorithmic}} perspective, the cartographic {{problem to}} place non-overlapping road labels embedded in their roads. We first decompose the road network into logically coherent road sections, e. g., parts of roads between two junctions. Based on this decomposition, we present {{and implement a}} new and <b>versatile</b> framework for <b>placing</b> labels in road maps such {{that the number of}} labeled road sections is maximized. In an experimental evaluation with road maps of 11 major cities we show that our proposed labeling algorithm is both fast in practice and that it reaches near-optimal solution quality, where optimal solutions are obtained by mixed-integer linear programming. In comparison to the standard OpenStreetMap renderer Mapnik, our algorithm labels 31 % more road sections in average. Comment: extended version of a paper to appear at GIScience 201...|$|R
40|$|Placement (and routing) of {{circuits}} is very computationally intensive. This intensity has motivated {{several attempts}} at acceleration {{of this process}} for application-specific integrated circuits (ASIC) and Field-programmable gate arrays (FPGA). In this paper an overview {{of some of these}} attempts is given. Specifically, parallelization of the standard simulated annealing (SA) algorithm is examined as well as a particular improvement to VPR, the academic <b>Versatile</b> <b>Place</b> and Route tool. Overall, it is clear that SA is difficult to parallelize and that very minor improvements on a well-known tool is cause for publication. A discussion is provided outlining a more innovative and potentially fruitful direction for acceleration of placement and routing. 1 Introduction an...|$|E
40|$|Abstract—This paper {{presents}} {{a novel approach}} to reduce dynamic power in field-programmable gate arrays (FPGAs) by reducing glitches during routing. It finds alternative routes for early-arriving signals so that signal arrival times at look-up tables are aligned. We developed an efficient algorithm to find routes with target delays and then built a glitch-aware router aiming at reducing dynamic power. To {{the best of our}} knowledge, this is the first glitch-aware routing algorithm for FPGAs. Experiments show that an average of 27 % reduction in glitch power is achieved, which translates into an 11 % reduction in dynamic power, compared to the glitch-unaware <b>versatile</b> <b>place</b> and route’s router. Index Terms—FPGA, glitch reduction, low power, path balancing, routing. I...|$|E
40|$|ABSTRACT- <b>Versatile</b> <b>Place</b> and Route Tool (VPR) is {{the state}} of art in FPGA (Field Programmable Gate Array) {{placement}} and route academic tool. Concerning the placement stage, its great success in terms of quality is based on the use of Simulated Annealing and simple routines that generate random positions for swapping logical and I/O blocks. For complex circuits, however, the search of the best result can consume too much computing time. This work is focused on the development of three main points: a constructive heuristic for the initial placement, in order to accelerate the iterative phase of the VPR Tool; an alternative implementation of the VPR logical blocks swapping routines, reducing the random factor; a new way to calculate the initial temperature for the annealing phase. In comparison to the original VPR, this new implementation produces considerable reduction of the total computational cost, verified by the execution time at least 2 X speed-up, without significant loses in the placement quality...|$|E
40|$|The shuttle {{has been}} {{primarily}} {{designed to be}} a <b>versatile</b> vehicle for <b>placing</b> a variety of scientific and technological equipment in space including very large payloads; however, since many large payloads do not fill the shuttle bay, the space and weight margins remaining after the major payloads are accommodated often can be made available to small payloads. The Goddard Space Flight Center (GSFC) has designed standardized mounting structures and other support systems, collectively called attached shuttle payload (ASP) carriers, to make this additional space available to researchers at a relatively modest cost. Other carrier systems for ASP's are operated by other NASA centers. A major feature of the ASP carriers is their ease of use {{in the world of the}} Space Shuttle. ASP carriers attempt to minimized the payload interaction with Space Transportation System (STS) operations whenever possible. Where this is not possible, the STS services used are not extensive. As a result, the interfaces between the carriers and the STS are simplified. With this near autonomy, the requirements for supporting documentation are considerably lessened and payload costs correspondingly reduced. The ASP carrier systems and their capabilities are discussed in detail. The range of available capabilities assures that an experimenter can select the simplest, most cost-effective carrier that is compatible with his or her experimental objectives. Examples of payloads which use ASP basic hardware in nonstandard ways are also described...|$|R
40|$|We {{describe}} {{the capabilities of}} and algorithms used in a new FPGA CAD tool, <b>Versatile</b> <b>Place</b> and Route (VPR). In terms of minimizing routing area, VPR outperforms all published FPGA place and route tools to which we can compare. Although the algorithms used are based on previously known approaches, we present several enhancements that improve run-time and quality. We present placement and routing results on {{a new set of}} large circuits to allow future benchmark comparisons of FPGA place and route tools on circuit sizes more typical of today's industrial designs. VPR is capable of targeting a broad range of FPGA architectures, and the source code is publicly available. It and the associated netlist translation / clustering tool VPACK have already been used in a number of research projects worldwide, and should be useful in many areas of FPGA architecture research. 1 Introduction In FPGA research, one must typically evaluate the utility of new architectural features experimentally. That [...] ...|$|E
40|$|Abstract — As {{the feature}} size shrinks to the {{nanometer}} scale, SRAM-based FPGAs {{will become increasingly}} vulnerable to soft errors. Existing reliability-oriented placement and routing approaches primarily focus on reducing the fault occurrence probability (node error rate) of soft errors. However, our analysis shows that, besides the fault occurrence probability, the propagation probability (error propagation probability) {{plays an important role}} and should be taken into consideration. In this paper, we first propose a cube-based analysis algorithm to efficiently and accurately estimate the error propagation probability. Based on such a model, we propose a novel reliability-oriented placement and routing algorithm that combines both the fault occurrence probability and the error propagation probability together to enhance system-level robustness against soft errors. Experimental results show that, compared with the baseline <b>versatile</b> <b>place</b> and route technique, the proposed scheme can reduce the failure rate by 20. 73 %, and increase the mean time between failures by 39. 44 %. Index Terms — Cube-based analysis, failure rate, field-programmable gate arrays (FPGAs), mean time between failures (MTBFs), placement and routing, soft error mitigation. I...|$|E
40|$|Power {{has become}} a {{critical}} issue for FPGA vendors. Understanding the power dissipation within FPGAs {{is the first step}} to develop power-efficient architectures and CAD tools for FPGAs. This paper describes a detailed and flexible power model which has been integrated in the widely-used <b>Versatile</b> <b>Place</b> and Route (VPR) CAD tool. This power model estimates the dynamic, short-circuit, and leakage power consumed by FPGAs. It is the first flexible power model developed to evaluate architectural tradeoffs and the efficiency of power-aware CAD tools for a variety of FPGA architectures, and is freely available for non-commercial use. The model is flexible, in that it can estimate the power {{for a wide variety of}} FPGA architectures, and it is fast, in that it does not require extensive simulation, meaning it can be used to explore a large architectural space. We show how the model can be used to investigate the impact of various architectural parameters on the energy consumed by the FPGA, focusing on the segment length, switch block topology, lookup-table size, and cluster size...|$|E
40|$|Battery-powered {{applications}} and the scaling of process technologies and clock frequencies have made power dissipation a first class concern among FPGA vendors. One approach to reduce power dissipation in FPGAs is to embed coarse-grained fixed-function blocks that implement {{certain types of}} functions very efficiently. Commercial FPGAs contain embedded multipliers and “Digital Signal Processing (DSP) blocks ” to improve the performance and area efficiency of arithmetic-intensive applications. In order to evaluate the power saved by using these blocks, a power model and tool flow are required. This thesis describes our development and evaluation of methods to estimate the activity and the power dissipation of FPGA circuits containing embedded multiplier and DSP blocks. Our goal {{was to find a}} suitable balance between estimation time, modeling effort, and accuracy. We incorporated our findings to create a power model and CAD tool flow for these circuits. Our tool flow builds upon the Poon power model, and the <b>Versatile</b> <b>Place</b> and Route (VPR) CAD tool, which are both standard academic experimental infrastructure. ii...|$|E
40|$|International audienceThis paper {{presents}} an improved interconnect network for Mesh of Clusters (MoC) Field-Programmable Gate Array (FPGA) architecture. Proposed architecture has a depopulated intra-cluster interconnect with flexible Rent's parameter. It presents new multi-levels Switch Box (SB) interconnect which unifies a downward and an upward unidirectional networks {{based on the}} Butterfly-Fat-Tree (BFT) topology. To improve the routability of proposed MoC-based FPGA, long routing segments are introduced {{as a function of}} channel width with adjustable span. Compared to basic <b>Versatile</b> <b>Place</b> and Route (VPR) Mesh architecture, a saving of 32 % of area and 30 % of power was achieved with proposed MoC-based architecture. Based on analytical and experimental methods, we identified and explored architecture parameters that control the interconnect flexibility of the proposed MoC-based FPGA such as Rent's parameter, cluster size, Look-Up-Table (LUT) size, long wires span and percentage. Experimental results show that architecture with LUT size 4 and Cluster arity 8 is the best trade-off between power consumption and density. It can also be noted that in general long wires span equal to 4 and percentage between 20 % and 30 % produce most efficient results in terms of density and power...|$|E
40|$|In this work, the {{benefits}} of using 3 -D integration in the fabrication of Field Pro-grammable Gate Arrays (FPGAs) are analyzed. A CAD tool has been developed to specify 3 -dimensional FPGA architectures and map RTL descriptions of circuits to these 3 -D FPGAs. The CAD tool was created from the widely used <b>Versatile</b> <b>Place</b> and Route (VPR) CAD tool for 2 -D FPGAs. The tool performs timing-driven placement of logic blocks in the 3 -dimensional grid of the FPGA using a two-stage Simulated Annealing (SA) process. The SA algorithm in the original VPR tool has been modified to focus more directly on minimizing the critical path delay of the circuit and hence maximizing {{the performance of the}} mapped circuit. After placing the logic blocks, the tool generates a Routing-Resource graph from the 3 -D FPGA ar-chitecture for the VPR router. This allows the efficient Pathfinder-based VPR router to be used without any modification for the 3 -D architecture. The CAD tool that was developed for mapping circuits to the fabricated 3 -D FPGA is also used for exploring the design space for the 3 -D FPGA architecture. ...|$|E
40|$|This paper {{presents}} an efficient algorithm {{to detect the}} global topological similarity between two circuits. By applying the proposed circuit similarity algorithm in an incremental design flow, IDUCS (incremental design using circuit similarity), the design and optimization effort in the previous design iterations is automatically captured {{and can be used}} to guide the next design iteration. IDUCS is able to identify the similarity between the original netlist and the modified one with aggressive resynthesis, which might destroy the naming and local structures of the original netlist. This is superior to the existing design preservation approaches such as naming and local topological matching. Furthermore, IDUCS simply inserts a plugin for circuit similarity detection, and therefore preserves the “push-button” feature, significantly simplifying the engineering complexity of incremental tasks. As a case study, we perform the proposed IDUCS process to generate the placement for a logically resynthesized netlist based on the placement of the original netlist and the circuit similarity between the original and the modified logic-level netlists. The experimental results show our IDUCS-based placement is 28 X faster than <b>versatile</b> <b>place</b> and route (VPR) with comparable wire length and estimated critical delay...|$|E
40|$|Placement {{is one of}} {{the most}} {{important}} steps in physical design for VLSI circuits. For field programmable gate arrays (FPGAs), the placement step determines the location of each logic block. I present novel timing and congestion driven placement algorithms for FPGAs with minimal runtime overhead. By predicting the post-routing timing-critical edges and estimating congestion accurately, this algorithm is able to simultaneously reduce the critical path delay and the minimum number of routing tracks. The core of the algorithm consists of a criticality-history record of connection edges and a congestion map. This approach is applied to the 20 largest Microelectronics Center of North Carolina (MCNC) benchmark circuits. Experimental results show that compared with the state-of-the-art FPGA place and route package, the <b>Versatile</b> <b>Place</b> and Route (VPR) suite, this algorithm yields an average of 8. 1 % reduction (maximum 30. 5 %) in the critical path delay and 5 % reduction in channel width. Meanwhile, the average runtime of the algorithm is only 2. 3 X as of VPR. ACKNOWLEDGMENTS I have been fortunate to have my parents over the past 28 years. They always support me whenever I was ambitious or in depression. Without them, I can never be strong enough to stand success and failure. I dedicate this thesis to them...|$|E
40|$|Just-in-time (JIT) {{compilation}} {{has been}} used in many applications to enable standard software binaries to execute on different underlying processor architectures. We previously introduced the concept of a standard hardware binary, using a just-in-time compiler to compile the hardware binary to a field-programmable gate array (FPGA). Our JIT compiler includes lean versions of technology mapping, placement, and routing algorithms, of which routing is the most computationally and memory expensive step. As FPGAs continue to increase in size, a JIT FPGA compiler must be capable of efficiently mapping increasingly larger hardware circuits. In this paper, we analyze the scalability of our lean on-chip router, the Riverside On-Chip Router (ROCR), for routing increasingly large hardware circuits. We demonstrate that ROCR scales well in terms of execution time, memory usage and circuit quality, and we compare the scalability of ROCR to the well known <b>Versatile</b> <b>Place</b> and Route (VPR) timing-driven routing algorithm, comparing to both their standard routing algorithm and their fast routing algorithm. Our results show that on average ROCR executes 3 times faster using 18 times less memory than VPR. ROCR requires only 1 % more routing resources, while creating a critical path 30 % longer VPR's standard timing-driven router. Furthermore, for the largest hardware circuit, ROCR executes 3 times faster using 14 times less memory, and results in a critical path 2. 6 % shorter than VPR's fast timing-driven router...|$|E
40|$|Abstract — In {{traditional}} FPGA placement methods, {{there is}} virtually no coupling between placement and routing. Performing simultaneous placement and detailed routing has been shown to generate much better placement qualities, but at the expense of significant runtime penalties [19]. We propose a routing-aware partitioning-based placement algorithm for FPGAs in which a looser but effective coupling between the placement and routing stages is used. The placement engine incorporates a more accurate FPGA delay model and employs effective heuristics that minimize circuit delay. Delay estimations are obtained from routing profiles of selected circuits that are placed and routed using the timing-driven <b>versatile</b> <b>place</b> and route (TVPR) [6][7]. As a result, the delay predictions during placement more accurately resemble those observed after detailed routing, which in turn leads to better delay optimization. An efficient terminal alignment heuristic for delay minimization is applied during placement to further optimize the delay of the circuit. These two techniques help maintain harmony between placement and routing delay optimization stages. Simulation results show that the proposed partitioning-based placement combined with more accurate delay models and the alignment heuristic can achieve post-routing circuit delays comparable to those obtained from TVPR while achieving a 4 -fold speedup in total placement runtime. In another experiment, we augmented the original TVPR algorithm with the terminal alignment heuristic, and achieved on average 5 % improvement in circuit delay with negligible runtime penalty. Index Terms — Field programmable gate arrays (FPGA), FPGA placement, timing-driven placement, partitioning-based placement, delay estimation...|$|E
40|$|Just-in-time (JIT) {{compilation}} {{has previously}} been used in many applications to enable standard software binaries to execute on different underlying processor architectures. However, embedded systems increasingly incorporate Field Programmable Gate Arrays (FPGAs), for which {{the concept of a}} standard hardware binary did not previously exist, requiring designers to implement a hardware circuit for a single specific FPGA. We introduce the concept of a standard hardware binary, using a just-in-time compiler to compile the hardware binary to an FPGA. A JIT compiler for FPGAs requires the development of lean versions of technology mapping, placement, and routing algorithms, of which routing is the most computationally and memory expensive step. We present the Riverside On-Chip Router (ROCR) designed to efficiently route a hardware circuit for a simple configurable logic fabric that we have developed. Through experiments with MCNC benchmark hardware circuits, we show that ROCR works well for JIT FPGA compilation, producing good hardware circuits using an order of magnitude less memory resources and execution time compared with the well known <b>Versatile</b> <b>Place</b> and Route (VPR) tool suite. ROCR produces good hardware circuits using 13 X less memory and executing 10 X faster than VPR's fastest routing algorithm. Furthermore, our results show ROCR requires only 10 % additional routing resources, and results in circuit speeds only 32 % slower than VPR's timing-driven router, and speeds that are actually 10 % faster than VPR's routabilitydriven router...|$|E
40|$|Abstract—To {{capitalize}} on the growing abundance of multicore hardware, FPGA vendors have begun to parallelize the most compute intensive algorithms in their CAD software. However, parallelization is a painstaking and hence expensive process that limits the number of algorithms that can be cost-effectively parallelized. Transactional Memory (TM) promises an easier-touse alternative to locks for critical sections in threaded code— allowing programmers to avoid deadlocks and data races, and also allowing critical sections to execute in parallel {{as long as they}} dynamically access independent data. In this paper, we present our work on using TM to parallelize simulated annealingbased placement for FPGAs. In particular, we use a software TM (TinySTM) to parallelize the placement phase of <b>Versatile</b> <b>Place</b> and Route (VPR) 5. 0. 2 [1]. With TM we very quickly produced a parallel and correct version of the software, allowing us to focus on incrementally tuning performance. We describe our experiences in tuning the TM system and CAD software, and the interesting algorithmic trade-offs that exist. In the end, we found that optimized transactional placement has the potential for scalable performance: our non-deterministic implementation achieves self-relative speedups over a single thread of 1. 82 x, 3. 62 x and 7. 27 x at 2, 4, and 8 threads respectively with little quality degradation. However, hardware support for TM is likely required to overcome the overheads of STM, as our implementation’s single thread performance is 8 x slower than sequential VPR. I...|$|E
40|$|VPR (<b>Versatile</b> <b>Place</b> and Route) is an FPGA {{placement}} and routing tool. VPR has four required and many optional parameters; it is invoked by typing:> vpr netlist. net architecture. xml placement. p routing. r [-options] Netlist. net is the netlist describing the circuit {{to be placed}} and/or routed, while architecture. xml describes {{the architecture of the}} FPGA in which the circuit is to be realized. If VPR is placing a circuit, the final placement will be written to placement. p; if VPR is routing a previously placed circuit, the placement is read from placement. p. The final routing of a circuit is written to file routing. r. The format of each of these files is described in Section 0. VPR can be run in one of two basic modes. In its default mode, VPR places a circuit on an FPGA and then repeatedly attempts to route it in order to find the minimum number of tracks required by the specified FPGA architecture to route this circuit. If a routing is unsuccessful, VPR increases the number of tracks in each routing channel and tries again; if a routing is successful, VPR decreases the number of tracks before trying to route it again. Once the minimum number of tracks required to route the circuit is found, VPR exits. The other mode of VPR is invoked when a user specifies a specific channel width for routing. In this case, VPR places a circuit and attempts to route it only once, with the specified channel width. If the circui...|$|E
40|$|Abstract—This paper {{proposes a}} {{systematic}} strategy to efficiently explore the design space of {{field-programmable gate array}} (FPGA) routing architectures. The key idea is to use stochastic methods to quickly locate near-optimal solutions in designing FPGA routing architectures without exhaustively enumerating all design points. The main objective {{of this paper is}} not as much about the specific numerical results obtained, as it is to show the applicability and effectiveness of the proposed optimization approach. To demonstrate the utility of the proposed stochastic approach, we developed the tool for optimizing routing architecture (TORCH) software based on the <b>versatile</b> <b>place</b> and route tool [1]. Given FPGA architecture parameters and a set of benchmark designs, TORCH simultaneously optimizes the routing channel segmentation and switch box patterns using the performance metric of average interconnect power-delay product estimated from placed and routed benchmark designs. Special techniques—such as incremental routing, infrequent placement, multi-modal move selection, and parallelized metric evaluation— are developed to reduce the overall run time and improve the quality of results. Our experimental results have shown that the stochastic design strategy is quite effective in co-optimizing both routing channel segmentation and switch patterns. With the optimized routing architecture, relative to the performance of our chosen architecture baseline, TORCH can achieve average improvements of 24 % and 15 % in delay and power consumption for the 20 largest Microelectronics Center of North Carolina benchmark designs, and 27 % and 21 % for the eight benchmark designs synthesized with the Altera Quartus II University Interface Program tool. Additionally, we found that the average segment length in an FPGA routing channel should decrease with technology scaling. Finally, we demonstrate the versatility of TORCH by illustrating how TORCH can be used to optimize other aspects of the routing architecture in an FPGA. Index Terms—Design exploration, FPGA, routing architecture, stochastic...|$|E
40|$|University of Minnesota M. S. E. E. thesis. August 2015. Major: Electrical Engineering. Advisor: Kiarash Bazargan. 1 {{computer}} file (PDF); viii, 50 pages. With increasing complexity of modern circuit, FPGA demands {{to be dealt}} with good CAD algorithm and suitable architecture to meet the lower non-recurring engineering cost and faster time-to-market. Placement is one of the crucial steps among them, as it decides time for implementing FPGA, routing resources and power consumption by digital circuits. Our research is centered on the placement algorithm for FPGA design. Simulated Annealing (SA) being the most popular among all the placement methods for quality results, takes huge compile time to implement larger circuits with the current new architectures. Researchers {{try to find a way}} for getting similar or better results with less run time. Based on the requirement, placement can be wirelength driven, timing driven and path driven. There are alternate ways of placement which are based on min-cut algorithm and analytic placement, and take less time. We targeted to optimize wirelength while doing placement using Gordian method in multiple iteration to get similar results as that of well-known academic research tool for FPGA - <b>Versatile</b> <b>Place</b> and route (VPR). Each iteration divides a subspace in four partitions and applies linear and bounding constraint to solve for quadratic optimization. We bypassed the placement methodology of VPR with our placement algorithm of analytical placement, implemented in MATLAB, and then fed back the output of our placer to the VPR flow for detailed placement and routing. We compare our results of placement and routing using 20 MCNC benchmarks and homogeneous VTR benchmarks with the VPR flow. Our MATLAB placer is faster by 38 % with the expense of wirelength quality. It gets 1 % better wirelength with 11 % increase in runtime compared to the whole VPR placer after low temperature simulated annealing based final detailed placement...|$|E
40|$|The {{field of}} {{placement}} methods for components of integrated circuits, {{especially in the}} domain of reconfigurable chip architectures, is mainly dominated by a handful of concepts. While some of these are easy to apply but difficult to adapt to new situations, others are more flexible but rather complex to realize. This work presents the FieldPlacer framework, a flexible, fast and unconstrained force-directed placement method for heterogeneous reconfigurable logic architectures, in particular for the ever important heterogeneous FPGAs. In contrast to many other force-directed placers, this approach is called ‘unconstrained’ as it does not require a priori fixed logic elements in order to calculate a force equilibrium as the solution to a system of equations. Instead, it is based on a free spring embedder simulation of a graph representation which includes all logic block types of a design simultaneously. The FieldPlacer framework offers a huge amount of flexibility in applying different distance norms (e. g., the Manhattan distance) for the force-directed layout and aims at creating adapted layouts for various objective functions, e. g., highest performance or improved routability. Depending on the individual situation, a runtime-quality trade-off can be considered to either produce a decent placement {{in a very short time}} or to generate an exceptionally good placement, which takes longer. An extensive comparison with the latest simulated annealing placement method from the well-known <b>Versatile</b> <b>Place</b> and Route (VPR) framework shows that the FieldPlacer approach can create placements of comparable quality much faster than VPR or, alternatively, generate better placements in the same time. The flexibility in defining arbitrary objective functions and the intuitive adaptability of the method, which, among others, includes different concepts from the field of graph drawing, should facilitate further developments with this framework, e. g., for new upcoming optimization targets like the energy consumption of an implemented design. ...|$|E
40|$|Since the {{invention}} of FPGAs in 1984, their capabilities have increased dramatically making them more speed, area, and power efficient than older reconfigurable devices. These advances were made possible by better computer aided design tools and the continuous development of algorithms used to both design the chips, and to map circuits onto them. However, current methodologies for FPGA chip design suffer from their dependence on empirical approaches which sample the design space based on intuition and heuristic techniques. As a result these empirical tools might result in good architectures but their optimality cannot be measured. This thesis argues {{the case for the}} use of analytical models in heterogeneous FPGA architecture exploration. It shows that the problem, when simplified, is amenable to formal optimisation techniques such as Integer Linear Programming (ILP). However, the simplification process may lead to inaccurate models causing uncertainty {{about the quality of the}} results. Consequently, existing accurate models such as that used in the <b>versatile</b> <b>place</b> and route (VPR) tool are used to quantify the performance of the analytical framework in comparison with traditional design methodologies. The results obtained in this thesis show that the architectures found by the ILP model are better than those found using traditional parameter sweep techniques with an average improvement of up to 15 % in speed. In addition, these architectures are further improved by combining the accuracy of VPR with the efficiency of analytical techniques. This was achieved using a closed loop framework which iteratively refines the analytical model using place and route information from VPR. The results show a further average improvement of 10 % and a total improvement of 25 % in comparison with a parameter sweep methodology. In summary, the work carried out in this thesis shows that the ILP architecture exploration framework may not model heterogeneous architectures as accurately as current place and route tools, however, it improves on parameter sweep techniques by exploring a wider range of designs. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E
40|$|In this work, the {{benefits}} of using 3 -D integration in the fabrication of Field Programmable Gate Arrays (FPGAs) are analyzed. A CAD tool has been developed to specify 3 -dimensional FPGA architectures and map RTL descriptions of circuits to these 3 -D FPGAs. The CAD tool was created from the widely used <b>Versatile</b> <b>Place</b> and Route (VPR) CAD tool for 2 -D FPGAs. The tool performs timing-driven placement of logic blocks in the 3 -dimensional grid of the FPGA using a two-stage Simulated Annealing (SA) process. The SA algorithm in the original VPR tool has been modified to focus more directly on minimizing the critical path delay of the circuit and hence maximizing {{the performance of the}} mapped circuit. After placing the logic blocks, the tool generates a Routing-Resource graph from the 3 -D FPGA architecture for the VPR router. This allows the efficient Pathfinder-based VPR router to be used without any modification for the 3 -D architecture. The CAD tool that was developed for mapping circuits to the fabricated 3 -D FPGA is also used for exploring the design space for the 3 -D FPGA architecture. A significant contribution of this work is a dual-interconnect architecture for the 3 -D FPGA which has parasitic capacitance comparable to 2 -D FPGAs. The nets routed in a 3 -D FPGA are divided into intra-layer nets and inter-layer nets, which are routed on separate interconnect systems. This work also proposes a technique called I/O pipelining which pipelines the primary inputs and outputs of the FPGA through unused registers. This 3 -D architecture and I/O pipelining technique have not been found in any of the works proposed so far, in the area of 3 -D FPGA design. It is shown that the Dual-Interconnect I/O pipelined 3 -D FPGA on an average achieves 43 % delay improvement and in the best case, up to 54 % for the MCNC' 91 benchmark circuits. bu Vikram Chandrasekhar. Thesis (S. M.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2007. Includes bibliographical references (p. 73 - 77) ...|$|E
40|$|Routing is {{the most}} time {{consuming}} step {{of the process of}} synthesizing an electronic design on a Field Programmable Gate Array (FPGA). It involves the creation of a Routing Resource Graph (RRG); a large data structure representing the physical architecture of the FPGA. In this work, we first introduce two scalable routing heuristics for FPGAs with sparse intra-cluster routing crossbars: SElective RRG Expansion (SERRGE), which compresses the RRG, and dynamically decompresses it during routing, and Partial Pre-Routing (PPR), which locally routes all nets in each cluster, and routes global nets afterwards. Our experiments show that: (1) PPR and SERRGE converge faster than a traditional router using a fully-expanded RRG; (2) they both achieve better routability than the traditional router, given a limited runtime budget; and (3) PPR uses far less memory and runs much faster than SERRGE, making it ideal for high capacity FPGAs. We then introduce a new dynamic-multiplexing based hybrid logic blocks that can be configured to operate as regular configurable logic blocks, or to implement shifting operations required for mantissa alignment and normalization in floating point operations. We show that: (1) the number of CLBs required for shifting operations is reduced by 67 %, and if shifting is not required, these hybrid logic blocks can be configured for normal operation, so no functionality is sacrificed; (2) the area overhead incurred by these modifications is small, and (3) there is no negative impact in terms of clock frequency or routability for benchmarks that do not use floating point shifting. Finally, we investigate the parallelization of FPGA routing on both GPUs and Multicore, shared memory CPUs, using a speculation-based approach. The router is a parallel implementation of PathFinder, which is the basis for most commercial FPGA routers. Our results demonstrate scalability for large benchmarks and that the amount of available parallelism depends primarily on the circuit size, not the inter-dependence of signals. The Multicore-based parallel implementation achieved an average speedup of approximately 6 x while the GPU achieved (10 - 15 x) in comparison to the single threaded router implemented in the publicly available <b>Versatile</b> <b>Place</b> and Route (VPR) framework...|$|E
40|$|Particle Swarm Optimization (PSO) {{is one of}} {{the most}} effFective {{optimization}} tools, which emerged in the last decade. Although, the original aim was to simulate the behavior of a group of birds or a school of fish looking for food, it was quickly realized that it could be applied in optimization problems. Different directions have been taken to analyze the PSO behavior as well as improving its performance. One approach is the introduction of the concept of cooperation. This thesis focuses on studying this concept in PSO by investigating the different design decisions that influence the cooperative PSO models' performance and introducing new approaches for information exchange. Firstly, a comprehensive survey of all the cooperative PSO models proposed in the literature is compiled and a definition of what is meant by a cooperative PSO model is introduced. A taxonomy for classifying the different surveyed cooperative PSO models is given. This taxonomy classifies the cooperative models based on two different aspects: the approach the model uses for decomposing the problem search space and the method used for placing the particles into the different cooperating swarms. The taxonomy helps in gathering all the proposed models under one roof and understanding the similarities and differences between these models. Secondly, a number of parameters that control the performance of cooperative PSO models are identified. These parameters give answers to the four questions: Which information to share? When to share it? Whom to share it with? and What to do with it? A complete empirical study is conducted on one of the cooperative PSO models in order to understand how the performance changes under the influence of these parameters. Thirdly, a new heterogeneous cooperative PSO model is proposed, which is based on the exchange of probability models rather than the classical migration of particles. The model uses two swarms that combine the ideas of PSO and Estimation of Distribution Algorithms (EDAs) and is considered heterogeneous since the cooperating swarms use different approaches to sample the search space. The model is tested using different PSO models to ensure that the performance is robust against changing the underlying population topology. The experiments show that the model is able to produce better results than its components in many cases. The model also proves to be highly competitive when compared to a number of state-of-the-art cooperative PSO algorithms. Finally, two different versions of the PSO algorithm are applied in the FPGA placement problem. One version is applied entirely in the discrete domain, which is the first attempt to solve this problem in this domain using a discrete PSO (DPSO). Another version is implemented in the continuous domain. The PSO algorithms are applied to several well-known FPGA benchmark problems with increasing dimensionality. The results are compared to those obtained by the academic <b>Versatile</b> <b>Place</b> and Route (VPR) placement tool, which is based on Simulated Annealing (SA). The results show that these methods are competitive for small and medium-sized problems. For higher-sized problems, the methods provide very close results. The work also proposes the use of different cooperative PSO approaches using the two versions and their performances are compared to the single swarm performance...|$|E

