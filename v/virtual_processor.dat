93|153|Public
50|$|The Mitrion Platform {{consists}} of the Mitrion <b>Virtual</b> <b>Processor</b> and Mitrion Software Development Kit. The SDK includes a parallel C-family language called Mitrion-C used to program the Mitrion <b>Virtual</b> <b>Processor.</b> Since the Mitrion <b>Virtual</b> <b>Processor</b> can be programmed in software, FPGAs become easier to use as computer accelerators than using hardware design tools such as VHDL or Verilog. The Mitrionics technology claims to make supercomputing performance acceleration accessible to an entire new market of scientists and developers previously unable to benefit from it because of high prices, complex design skills needed, and extremely long development times.|$|E
50|$|Tao <b>Virtual</b> <b>Processor</b> (VP) is {{a virtual}} machine from Tao Group.|$|E
5000|$|Second-generation Intel Virtualization Technology, which {{introduced}} Extended Page Table support, <b>virtual</b> <b>processor</b> identifiers (VPIDs), and non-maskable interrupt-window exiting ...|$|E
5000|$|Kernel {{scheduler}} {{has been}} enhanced to dynamically increase and decrease {{the use of}} <b>virtual</b> <b>processors.</b>|$|R
40|$|Hierarchical {{scheduling}} is {{an effective}} approach developed to support the integration of independently developed ap- plications on the same computing platform. In particular, the M-BROE framework has been recently proposed and an- alyzed to efflciently support component-based development on multiprocessor platforms through the virtual multipro- cessor abstraction implemented by reservation servers, {{in the presence of}} shared resources. However, the problems of partitioning applications to <b>virtual</b> <b>processors</b> and defining reservation parameters were not addressed. This paper fills this gap by proposing a design methodology as an optimization problem for partitioning applications to <b>virtual</b> <b>processors,</b> performing a synthesis of the component interface and allocating <b>virtual</b> <b>processors</b> to physical pro- cessors. Experimental results are also presented to evaluate the proposed methodology...|$|R
40|$|The {{functionality}} of {{embedded systems}} is ever increasing. This has lead to mixed time-criticality systems, where applications {{with a variety}} of real-time requirements co-exist on the same platform and share resources. Due to inter-application interference, verifying the real-time requirements of such systems is generally non trivial. In this paper, we present the CoMik microkernel that provides temporally predictable and composable <b>processor</b> virtualisation. CoMik's <b>virtual</b> <b>processors</b> are cycle-accurately composable, i. e. their timing cannot affect the timing of co-existing <b>virtual</b> <b>processors</b> by even a single cycle. Real-time applications executing on dedicated <b>virtual</b> <b>processors</b> can therefore be verified and executed in isolation, simplifying the verification of mixed time-criticality systems. We demonstrate these properties through experimentation on an FPGA prototyped hardware platform...|$|R
50|$|StarLisp {{operated}} on PVARS (Parallel Variables). PVARS represented Connection Machine memory, and were essentially vectors: one element per CM processor (or <b>virtual</b> <b>processor).</b>|$|E
5000|$|Valgrind runs {{programs}} on a <b>virtual</b> <b>processor</b> and can detect memory errors (e.g., misuse of malloc and free) and race conditions in multithread programs.|$|E
50|$|Francis Charig and Chris Hinsley founded Tao Group in 1992. In {{the same}} year, the company {{released}} {{the first generation}} of its virtual machine, called <b>Virtual</b> <b>Processor</b> (VP). In 1998, Tao Group released the second generation, VP2.|$|E
50|$|If {{the shared}} {{processor}} partition is DLPAR capable, {{the number of}} <b>virtual</b> <b>processors</b> and processing capacity can be altered dynamically for the partition.|$|R
5000|$|Today, their {{competitors}} include Trango's <b>Virtual</b> <b>Processors,</b> Open Kernel Labs's OKL4 and, {{to a lesser}} extent, open source hypervisors such as L4, XtratuM and Xen ...|$|R
50|$|Trango <b>Virtual</b> <b>Processors</b> {{competes with}} other {{providers}} of virtualization software, including VirtualLogix's VLX, Open Kernel Labs's OKL4, {{as well as}} open source hypervisors such as L4 and Xen.|$|R
50|$|The Intent {{platform}} {{could be}} run either as the native operating system {{or as an}} application. Service code was delivered in a format called <b>Virtual</b> <b>Processor</b> (VP), which was translated on the device to native machine code.|$|E
50|$|The {{addition}} of VT-x has added back {{the ability to}} run virtual 8086 mode from x86-64 long mode, {{but it has to}} be done by transitioning the (physical) processor to VMX root mode and launching a logical (<b>virtual)</b> <b>processor</b> itself running in virtual 8086 mode.|$|E
50|$|Tao Group was a {{software}} company with headquarters in Reading, Berkshire, UK. It developed the Intent software platform, which enabled content portability by delivering {{services in a}} platform-independent format called <b>Virtual</b> <b>Processor</b> (VP). The business was sold in May 2007 to Cross Atlantic Capital Partners.|$|E
50|$|In most of MacTechâ€™s tests, Parallels Desktop {{performed}} 14-20% {{faster than}} Fusion; however, Fusion ran 10% faster than Parallels Desktop when running Windows XP 32-bit on 2 <b>virtual</b> <b>processors.</b>|$|R
40|$|Little {{work has}} been done on {{operating}} systems for massively parallel computing. This paper proposes a framework for such an operating system. It is assumed that there are multiple jobs executing on a large MIMD computer. Each job is assumed to be data parallel, using as many <b>virtual</b> <b>processors</b> as necessary to exploit its inherent parallelism. We view the notion of <b>virtual</b> <b>processors</b> as playing a unifying role in the conceptual design of the operating system. Our main thesis is that the various functions performed by the operating system may be viewed as operations on the set of <b>virtual</b> <b>processors.</b> In the context of the above framework, several open theoretical problems are identified, and in particular, the twin problems of spatial and temporal scheduling are addressed. Preliminary analysis indicates the viability of horizontal spatial schedules and periodic temporal schedules. 3 This research {{was supported in part by}} the Air Force Office of Scientific Research under grant numbers F 4 [...] ...|$|R
40|$|We {{describe}} our {{implementation of}} several PRAM graph algorithms on the {{massively parallel computer}} MasPar MP- 1 with 16, 384 processors. Our implementation incorporated virtual processing and we present extensive test data. In a previous project [13], we reported {{the implementation of a}} set of parallel graph algorithms with the constraint that the maximum input size was restricted to be no more than the physical number of processors on the MasPar. The MasPar language MPL that we used for our code does not support virtual processing. In this paper, we describe a method of simulating <b>virtual</b> <b>processors</b> on the MasPar. We re-coded and fine-tuned our earlier parallel graph algorithms to incorporate the usage of <b>virtual</b> <b>processors.</b> Under the current implementation scheme, there is no limit on the number of <b>virtual</b> <b>processors</b> that one can use in the program {{as long as there is}} enough main memory to store all the data required during the computation. We also give two general optimization techniq [...] ...|$|R
50|$|The {{central concern}} of {{implementation}} step is optimization of the system. It {{is necessary to}} reduce the number of processes because it is impossible to provide each process that is contained in specification with its own <b>virtual</b> <b>processor.</b> By means of transformation, processes are combined in order to limit their number to the number of processors.|$|E
50|$|An {{extension}} of PAS labeled as SuperPas {{and later as}} EPAS addresses skeleton extensibility concerns. With the EPAS tool, new skeletons {{can be added to}} PAS. A Skeleton Description Language (SDL) is used to describe the skeleton pattern by specifying the topology with respect to a <b>virtual</b> <b>processor</b> grid. The SDL can then be compiled into native C++ code, which can be used as any other skeleton.|$|E
50|$|MikroSim is an {{educational}} software computer program for hardware-non-specific {{explanation of the}} general functioning and behaviour of a <b>virtual</b> <b>processor,</b> running on the Microsoft Windows operating system. Devices like miniaturized calculators, microcontroller, microprocessors, and computer can be explained on custom-developed instruction code on a register transfer level controlled by sequences of micro instructions (microcode). Based on this {{it is possible to}} develop an instruction set to control a virtual application board at higher level of abstraction.|$|E
3000|$|The first {{implementation}} described used {{a shared}} memory biprocessor with hyperthreading (i.e., four <b>virtual</b> <b>processors).</b> Taking {{into consideration the}} parallel algorithm proposed in Section 6.1 for four processors, the following grouping of tasks has been made: [...]...|$|R
50|$|Trango <b>Virtual</b> <b>Processors</b> {{was founded}} in 2004 by Pierre Coulombeau and Fabrice Devaux as a {{subsidiary}} of ELSYS Design group. Trango's purpose {{was to develop a}} real-time mobile hypervisor. It was acquired by VMware in October 2008.|$|R
5000|$|FOR-A {{manufactures}} 4K variable-rate, slow-motion {{digital video}} cameras, [...] digital video switchers, signal processing equipment, broadcast graphics products (such as <b>virtual</b> <b>processors</b> and studios), multi viewers, frame synchronizers and time base correctors, HD/SD converters, and video stabilizers.|$|R
50|$|Unix/NS (the NCR 3700 Operating System) {{is based}} on the Unix SVR4. It {{contains}} significant extensions for massively parallel systems, in particular Distributed Memory DBMSs. The extensions include the concepts of <b>virtual</b> <b>processor</b> and virtual disk, message and global synchronization system, segment system, and globally distributed objects. When compared to other parallel UNIX operating systems like Mach or Chorus, Unix/NS has a more powerful communication and message addressing paradigm, and richer process-group management and global synchronization mechanism.|$|E
50|$|EMIS {{prepares a}} system of mobile payment, i.e. {{transferring}} money via mobile phone, whereby EMIS intends {{to play the role}} of what they call an MVPO - Mobile <b>Virtual</b> <b>Processor</b> Operator. and describe as an entity which acts as the processor of the mobile payment services in the name of the banks being represented, using the technology and infrastructure of the Mobile Network Operators. EMIS would provide the direct interface to the user, acting in a collaborational model for the participating banks.|$|E
50|$|The minimum {{processing}} capacity per processor is 1/10 {{of a physical}} processor core, with a further granularity of 1/100, and the PHYP uses a 10 ms time slicing dispatch window for scheduling all shared processor partitions' <b>virtual</b> <b>processor</b> queues to the PHYP physical processor core queues. A shared processor partition can be either capped or uncapped. A capped partition can never exceed the currently configured {{processing capacity}}, whereas an uncapped partition can exceed the currently configured processing capacity up to 100% {{of the number of}} the currently configured virtual processors.|$|E
40|$|The {{design of}} a {{real-time}} architecture is governed by a trade-off between analyzability necessary for real-time formalism and performance demanded by high-end embedded systems. We reconcile this trade-off with a novel Real-time Virtual Multiprocessor (RVMP). RVMP virtualizes a single in-order superscalar processor into multiple interference-free different-sized <b>virtual</b> <b>processors.</b> This provides a flexible spatial dimension. In the time dimension, the number and size of <b>virtual</b> <b>processors</b> can be rapidly reconfigured. A simple real-time scheduling approach concentrates scheduling within a small time interval, producing a simple repeating space/time schedule that orchestrates virtualization. RVMP successfully combines the analyzability (hence real-time formalism) of multiple processors with the flexibility (hence high performance) of simultaneous multithreading (SMT). Worst-cas...|$|R
50|$|The {{structure}} of VPCode, the <b>Virtual</b> <b>Processor's</b> machine code, {{is intended to}} be able to represent the constructs required when compiling languages such as C, C++ and Java, and to allow efficient translation into the machine code of any real 32- or 64-bit CPU.|$|R
50|$|When {{a shared}} {{processor}} partition is activated by the PHYP, the LPAR is guaranteed a certain processing capacity, if needed, {{and a number}} of <b>virtual</b> <b>processors,</b> based on configuration and current availability. The processing capacity is drawn from a pool of shared processor resources.|$|R
5000|$|Unlike earlier Cray designs, the SV1 {{included}} a vector cache. It also introduced a feature called multi-streaming, {{in which one}} processor from each of four processor boards work {{together to form a}} <b>virtual</b> <b>processor</b> with four times the performance. The SV1 processor was clocked at 300 MHz. Later variants of the SV1, the SV1e and SV1ex, ran at 500 MHz, the latter also having faster memory and support for the SSD-I Solid-State Storage Device. Systems could include up to 32 processors with up to 512 shared memory buses.|$|E
50|$|Dynamic program {{analysis}} is {{the analysis of}} computer software that is performed by executing programs on a real or <b>virtual</b> <b>processor.</b> For dynamic program analysis to be effective, the target program must be executed with sufficient test inputs to produce interesting behavior. Use of software testing measures such as code coverage helps ensure that an adequate slice of the program's set of possible behaviors has been observed. Also, {{care must be taken}} to minimize the effect that instrumentation has on the execution (including temporal properties) of the target program. Inadequate testing can lead to catastrophic failures similar to the maiden flight of the Ariane 5 rocket launcher where dynamic execution errors (run time error) resulted in the destruction of the vehicle.|$|E
50|$|Long mode is the architecture's {{intended}} primary mode of operation; it is {{a combination}} of the processor's native 64-bit mode and a combined 32-bit and 16-bit compatibility mode. It is used by 64-bit operating systems. Under a 64-bit operating system, 64-bit programs run under 64-bit mode, and 32-bit and 16-bit protected mode applications (that do not need to use either real mode or virtual 8086 mode in order to execute at any time) run under compatibility mode. Real-mode programs and programs that use virtual 8086 mode at any time cannot be run in long mode unless those modes are emulated in software. However, such programs may be started from an operating system running in long mode on processors supporting VT-x or AMD-V by creating a <b>virtual</b> <b>processor</b> running in the desired mode.|$|E
40|$|In {{this paper}} I {{describe}} some {{results on the}} use of <b>virtual</b> <b>processors</b> technology for parallelize some SPMD computational programs in a cluster environment. The tested technology is the INTEL Hyper Threading on real processors, and the programs are MATLAB 6. 5 Release 13 scripts for floating points computation. By the use of this technology, I tested that a cluster can run with benefit a number of concurrent processes double the amount of physical processors. The conclusions of the work concern on the utility and limits of the used approach. The main result is that using <b>virtual</b> <b>processors</b> is a good technique for improving parallel programs not only for memory-based computations, {{but in the case of}} massive disk-storage operations too. ...|$|R
50|$|One of the {{earliest}} examples of a barrel processor was the I/O processing system in the CDC 6000 series supercomputers. These executed one instruction (or a portion of an instruction) from each of 10 different <b>virtual</b> <b>processors</b> (called peripheral processors) {{before returning to the}} first processor.|$|R
30|$|In FigureÂ  8, {{it can be}} {{seen that}} actual {{execution}} times are much longer than theoretical times. Moreover, {{it can be seen}} that threads vels_th suffer higher delays (81 % slower) than diff_th threads (48 % slower). This is because these threads, being all clones, compete for the same functional units of <b>virtual</b> <b>processors,</b> producing conflicts and delays.|$|R
