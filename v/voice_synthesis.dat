166|98|Public
2500|$|To {{mark the}} 100th {{anniversary of the}} sinking, the BBC World Service broadcast, on 10 April 2012, a radio {{documentary}} in the [...] "Discovery" [...] series, entitled Titanic – In Her Own Words. The programme was conceived and created by Susanne Weber and was narrated by Sean Coughlan, who had previously written {{a book on the}} Titanic radio messages. The programme used <b>voice</b> <b>synthesis</b> to re-create [...] "... the strange, twitter-like, mechanical brevity of the original Morse code messages ... transmitted by Titanic and neighbouring ships. Messages often included the fashionable slang expressions of the time, such as [...] "old man". The BBC noted that [...] "these messages were recorded at the time in copper-plate handwriting, now scattered across the world in different collections, but together forming a unique archive." ...|$|E
50|$|Sinsy (Singing <b>Voice</b> <b>Synthesis</b> System) (しぃんしぃ) is {{an online}} Hidden Markov model (HMM)-based singing <b>voice</b> <b>synthesis</b> system by the Nagoya Institute of Technology {{that was created}} under the Modified BSD license.|$|E
5000|$|The Amiga version {{featured}} <b>voice</b> <b>synthesis,</b> a {{first in}} a sports computer game. Players were announced at each plate appearance or substitution. The DOS version had some <b>voice</b> <b>synthesis</b> as well, but less than the Amiga and of lower quality.|$|E
50|$|CereProc is {{a speech}} {{synthesis}} {{company based in}} Edinburgh, Scotland, founded in 2005. The company specialises in creating natural and expressive-sounding text to speech <b>voices,</b> <b>synthesis</b> <b>voices</b> with regional accents, and in voice cloning.|$|R
40|$|This paper {{proposes a}} singing <b>voices</b> <b>synthesis</b> system to {{synthesize}} singing voices having characteristics of vocal registers, such as vocal fly, modal and falsetto. Human can sing songs naturally in {{wide range of}} frequency by training how to use vocal fold vibrations to represent vocal registers. However, even state-of-the-art singing <b>voices</b> <b>synthesis</b> systems cannot produce vocal registers appropriately. Naturalness of the synthesized singing voices using these systems is reduced in low and high frequency ranges. One of the methods for improving naturalness is adding characteristics of glottal sources for each vocal register. In this paper, the ARX-LF model that can formulate glottal sources for each vocal register by simulating human voice production mechanisms was applied. A model for controlling ARX-LF parameters corresponding to characteristics of glottal sources was constructed, and acoustic features corresponding to naturalness of singing voice were added. Singing voice data of each vocal register were analyzed by the ARX-LF model, and ARX-LF parameter values corresponding to glottal source of each vocal register were obtained. The control model was constructed using {{the results of the}} analysis. Singing voices were synthesized by the control model, and quality of the synthesized voices was evaluated. As the results, almost the same impressions were obtained from the synthesized singing voices as those from actual singing voices in each vocal register. Results revealed effectiveness of the proposed system for synthesizing singing voices to characterize vocal registers...|$|R
5000|$|Accomplished with text direct <b>synthesis</b> <b>voice</b> (TTS).The text {{could be}} {{transferred}} to fluent speech automatically.|$|R
5000|$|Police Radar / <b>Voice</b> <b>Synthesis</b> / Skin/Wrinkles Chat / Snake & Lizard (December 31, 1983) ...|$|E
5000|$|Covox Speech Thing. The {{simplest}} hardware DAC, bundled with {{speech synthesis}} software, marketed originally {{as part of}} <b>voice</b> <b>synthesis</b> and recognition system.|$|E
50|$|A speech {{translation}} system would typically integrate {{the following three}} software technologies: automatic speech recognition (ASR), machine translation (MT) and <b>voice</b> <b>synthesis</b> (TTS).|$|E
25|$|Vocaloid 2 was {{announced}} in 2007. Unlike the first engine, Vocaloid 2 based its results on vocal samples, rather than analysis of the human <b>voice.</b> The <b>synthesis</b> engine and the user interface were completely revamped, with Japanese Vocaloids possessing a Japanese interface.|$|R
50|$|Hubo has <b>voice</b> {{recognition}} and <b>synthesis</b> faculties, {{as well as}} sophisticated vision in which its two eyes move independently of one another.|$|R
50|$|Universal Access enhancements: {{significant}} improvements to applications including VoiceOver, along with increased support for Braille, closed captioning {{and a new}} high‐quality Speech <b>synthesis</b> <b>voice.</b>|$|R
50|$|B-17 Bomber is a single-player game {{released}} by Mattel for their Intellivision console in 1982. The game supports the Intellivoice <b>voice</b> <b>synthesis</b> module.|$|E
50|$|Microsoft Speech Server is a {{server-based}} {{package for}} <b>voice</b> <b>synthesis</b> and recognition. It {{is designed for}} network use with web applications and call centers.|$|E
5000|$|Customers/visitors {{are called}} by name, number, code etc., {{on a video}} screen, display, <b>voice</b> <b>synthesis</b> etc. {{and go to the}} window or counter indicated.|$|E
30|$|Thanks to the {{advanced}} <b>voice</b> recognition and <b>synthesis</b> system, it displays and reads out aloud incoming SMS messages, and understands the user’s vocal commands {{without the need}} for a voice learning phase.|$|R
40|$|This paper {{describes}} {{a pilot study}} into the mechanics of synthesizing severely pathological <b>voices.</b> Successful <b>synthesis</b> of suchvoices may ultimately provide a quantitative method for evaluating and documenting voice qualities. An analysis-by-synthesis approachusing the formantsynthesizer KLSYN was used to model the voices of 24 patients suffering from voice disorders. Results suggest a number of modifications to KLSYN that would facilitate <b>synthesis</b> of these <b>voices...</b>|$|R
5000|$|... "By {{listening}} to multiple <b>voices</b> and embodying <b>synthesis</b> {{in her own}} life and career, Joan has allowed us to see a Middle Ages that was always there but was waiting for a skilled interpreter to reveal it." [...] - Monica Green ...|$|R
50|$|Neptune: A voice {{synthesizer}} {{and pitch}} correction tool, capable of Vocoder-like polyphonic <b>voice</b> <b>synthesis</b> {{as well as}} robotic, AutoTune-like pitch adjustment and more subtle pitch corrections.|$|E
5000|$|In 1972, Isao Tomita {{produced}} a similar album of rock covers using the Moog synthesizer, titled Electric Samurai: Switched on Rock. Tomita also incorporated his experiments in <b>voice</b> <b>synthesis.</b>|$|E
50|$|Tools {{have been}} {{integrated}} for improving accessibility: an inverter color, a filter screen, {{direct access to}} documentation, a screen magnifier, copy and paste button, a virtual keyboard and <b>voice</b> <b>synthesis</b> integrated into the browser.|$|E
50|$|CereProc voice cloning {{technology}} {{is currently being}} used in the UK by MND sufferers, to create <b>synthesis</b> <b>voices</b> before they lose the power of speech. This process was featured in a BBC Radio 4 documentary, Giving the Critic Back His Voice, broadcast in August 2011.|$|R
40|$|This {{paper will}} discuss voicing {{characteristics}} of Czech plosives. In the theoretical {{part of the}} paper, vocal cords are described {{as well as their}} participation on voicing. Next, a brief history, division, and application of voice synthesisers is discussed. Synthesizers allow the user to manipulate individual characteristics of any speech signal. In the practical part of the paper, HLsyn is used to synthesize individual Czech plosives with various voicing characteristics. Perceived voicing is then evaluated based on preliminary perceptual verification. Keywords: <b>voicing,</b> plosives, <b>synthesis,</b> HLsyn, perception tes...|$|R
5|$|SGDs {{that use}} {{synthesized}} speech apply the phonetic {{rules of the}} language to translate the user’s message into <b>voice</b> output (speech <b>synthesis).</b> Users {{have the freedom to}} create novel words and messages and are not limited to those that have been pre-recorded on their device by others.|$|R
5000|$|Texas Instruments calls both {{of these}} serial roms (TMS6100 and TMS6125) [...] "VSM"s (<b>Voice</b> <b>Synthesis</b> Memory) on their {{datasheets}} and literature, {{and they will be}} referred to as such {{for the rest of this}} article.|$|E
5000|$|Other famous {{compositions}} include Turenas (1972), {{which was}} one of the first electronic compositions to have the illusion of sounds moving in a 360-degree space [...] With Phoné (1980-1981), he became the first to put FM over <b>voice</b> <b>synthesis</b> [...]|$|E
50|$|These works exhibit {{influences}} of Asian dramatic and musical forms, especially Balinese gamelan and shadow puppetry, Vedic chant, Tuva music from Central Asia, North Indian Tala, and shakuhachi music. Jazz elements and computer <b>voice</b> <b>synthesis</b> techniques are also incorporated into his music-theater works.|$|E
50|$|Bayesian program {{learning}} has potential applications <b>voice</b> recognition and <b>synthesis,</b> image recognition and natural language processing. It employs {{the principles of}} compositionality (building abstract representations from parts), causality (building complexity from parts) and learning to learn (using previously recognized concepts to ease {{the creation of new}} concepts).|$|R
50|$|SGDs {{that use}} {{synthesized}} speech apply the phonetic {{rules of the}} language to translate the user’s message into <b>voice</b> output (speech <b>synthesis).</b> Users {{have the freedom to}} create novel words and messages and are not limited to those that have been pre-recorded on their device by others.|$|R
40|$|Abstract—This paper {{describes}} a speaker-adaptive HMM-based speech synthesis system. The new system, called “HTS- 2007, ” employs speaker adaptation (CSMAPLR+MAP), feature-space adaptive training, mixed-gender modeling, and full-covariance modeling using CSMAPLR transforms, {{in addition to}} several other techniques that have proved effective in our previous systems. Subjective evaluation {{results show that the}} new system generates significantly better quality synthetic speech than speaker-dependent approaches with realistic amounts of speech data, and that it bears comparison with speaker-dependent approaches even when large amounts of speech data are available. In addition, a comparison study with several speech synthesis techniques shows the new system is very robust: It is able to build voices from less-than-ideal speech data and synthesize good-quality speech even for out-of-domain sentences. Index Terms—Average <b>voice,</b> HMM-based speech <b>synthesis,</b> HMM Speech Synthesis System, HTS, speaker adaptation, speech <b>synthesis,</b> <b>voice</b> conversion...|$|R
50|$|Werner Meyer-Eppler, a German {{scientist}} {{with a special}} interest in electronic <b>voice</b> <b>synthesis,</b> published a thesis in 1948 on electronic music and speech synthesis from the viewpoint of sound synthesis. Later he was instrumental in the founding of the Studio for Electronic Music of WDR in Cologne, in 1951.|$|E
50|$|In 1982 Mattel {{introduced}} a new peripheral for the Intellivision: the Intellivoice <b>Voice</b> <b>Synthesis</b> Module. A speech synthesizer which produces speech with compatible cartridges. The Intellivoice was original in two respects: human sounding male and female voices with distinct accents, and the speech-supporting games were designed with speech being {{an integral part of}} the game-play.|$|E
50|$|TTS (Text-to-Speech)TTS {{describes}} {{the conversion of}} computer readable text into audible speech. <b>Voice</b> <b>synthesis</b> technology is based on taking any plain text, analyzing it {{by means of a}} speech synthesis engine, processing the information and finally converting it to a voice stream form which can be stored or saved in various audio file formats.|$|E
50|$|Child composes {{music for}} orchestra, chorus, {{computer}} <b>synthesis,</b> <b>voice,</b> and chamber groups. His compositional style {{has been compared}} to Charles Ives, Benjamin Britten, and Gustav Mahler. Among his works are Embers (1984), a one-act chamber opera based on the play by Samuel Beckett, and Clare Cycle (1984), four settings from the poetry of John Clare.|$|R
5000|$|MTU made a [...] "Visible Memory" [...] card in 1978 {{that worked}} with the KIM-1 and AIM-65 computers, {{providing}} raster graphics display capability. MTU also made the first real time music synthesizer for a microcomputer; it {{worked with the}} KIM-1 and AIM-65, and featured a DAC with software providing 4 <b>voices</b> of 'wavetable-lookup <b>synthesis.</b>|$|R
50|$|Drishti is a {{wireless}} pedestrian navigation system. It integrates several technologies including wearable computers, <b>voice</b> recognition and <b>synthesis,</b> wireless networks, Geographic information system (GIS) and GPS. It augments contextual {{information to the}} visually impaired and computed optimized routes based on user preference, temporal constraints (e.g. traffic congestion), and dynamic obstacles (e.g. ongoing ground work, road blockade for special events).|$|R
