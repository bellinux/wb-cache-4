220|213|Public
50|$|An electroglottographic wavegram (short: EGG wavegram) is a {{tool for}} {{analyzing}} the <b>voice</b> <b>source</b> in speech and singing, based on electroglottographic (EGG) signals (and their first derivative, DEGG).|$|E
5000|$|On January 30, 2011, a user named [...] "Momomomo" [...] {{uploaded}} a {{cover of}} [...] "Nyanyanyanyanyanyanya!" [...] featuring the UTAU voice Momone Momo. The <b>voice</b> <b>source</b> used to create the Momone Momo voice was Momoko Fujimoto, a Japanese woman who lives in Tokyo.|$|E
50|$|Strident vowels (also called sphincteric vowels) are strongly-pharyngealized vowels {{accompanied}} by (ary)epiglottal trill, with the larynx being raised and the pharynx constricted. Either the epiglottis or the arytenoid cartilages thus vibrate {{instead of the}} vocal cords. That is, the epiglottal trill is the <b>voice</b> <b>source</b> for such sounds.|$|E
5000|$|There exist {{a number}} of {{well-developed}} microphone techniques used for miking musical, film, or <b>voice</b> <b>sources.</b> Choice of technique depends on {{a number of}} factors, including: ...|$|R
40|$|In {{this paper}} we examine three {{different}} approximation techniques for modeling packet loss in finite-buffer voice multiplexers. The performance models studied differ {{primarily in the}} manner in which the superposition of the <b>voice</b> <b>sources</b> (i. e., the arrival process) is modeled. The first approach models the superimposed <b>voice</b> <b>sources</b> as a renewal process and performance calculations are based only on the first two moments of the renewal process. The second approach is based on modeling the superimposed <b>voice</b> <b>sources</b> as a Markov Modulated Poisson Process (MMPP). Our choice of parameters for the MMPP attempts to capture aspects of the arrival process in an alternate, more intuitive, manner than previously proposed approaches for determining the MMPP parameters and is shown to compute loss more accurately. Finally, we also evaluate a fluid flow approximation for computing packet loss. For all three approaches, we consider as a unifying example, the case of multiplexing voice sou [...] ...|$|R
40|$|Multimedia is {{the future}} of today's {{communication}} field. Multimedia communications involve the transmission of different sources, such as video, voice, data and graphics, on the same network. This thesis focuses on the performance study of the Fibre Distributed Data Interface (FDDI) network when multimedia sources are integrated. In {{the first part of the}} study, Variable Bit Rate (VBR) video and data traffic are studied on FDDI. The second part of the study is the integration of VBR video and <b>voice</b> <b>sources.</b> In order to improve the multiplexing gain, the bit dropping algorithm is used on <b>voice</b> <b>sources.</b> It is shown that due to the dynamic bandwidth transfer property of FDDI, multimedia sources can be integrated without affecting the quality of service required by various media. Performance measures such as delay, variance and efficiency are calculated for each component of multimedia. Also using the bit dropping algorithm on <b>voice</b> <b>sources,</b> the delay and the probability of loss of voice packets decreases while the quality of voice is much higher than required...|$|R
50|$|HMM-based {{synthesis}} is {{a synthesis}} method based on hidden Markov models, also called Statistical Parametric Synthesis. In this system, the frequency spectrum (vocal tract), fundamental frequency (<b>voice</b> <b>source),</b> and duration (prosody) of speech are modeled simultaneously by HMMs. Speech waveforms are generated from HMMs themselves {{based on the}} maximum likelihood criterion.|$|E
50|$|Human spoken {{language}} {{makes use of}} the ability of almost all people in a given society to dynamically modulate certain parameters of the laryngeal <b>voice</b> <b>source</b> in a consistent manner. The most important communicative, or phonetic, parameters are the voice pitch (determined by the vibratory frequency of the vocal folds) {{and the degree of}} separation of the vocal folds, referred to as vocal fold adduction (coming together) or abduction (separating).|$|E
50|$|The {{voice quality}} when {{speaking}} {{with a voice}} prosthesis is influenced by pulmonary support, airflow resistance of the voice prosthesis, and airflow resistance of the new <b>voice</b> <b>source.</b> Although the voice prosthesis is only responsible {{for part of the}} total resistance - the neoglottis is responsible for the other part - favorable airflow characteristics are expected to enable the laryngectomized patient to speak with less effort.The voice sounds rather clear though not very loud as samples show.|$|E
40|$|This paper {{deals with}} the {{improvements}} and modifications done on {{the first edition of}} the Malay Language Text-to-Speech System, SUM (acronym for Sintesis Ucapan Melayu). A simple review on human speech production system and synthetic speech production system is discussed. Modifications on the <b>voicing</b> <b>source</b> include an additional KLGLOTT 88 model added into the software. Theory and methodology on the <b>voicing</b> <b>source</b> are discussed in this paper. Characteristics of natural speech such as breathiness and flutter are studied. In addition, more constructive rules are added to improve the capability of the previous Malay TTS SUM system. The synthesiser model is based on the Klatt’s formant synthesiser, KLSYN 88...|$|R
40|$|In this paper, {{we present}} a new formant-type speech analysissynthesis system based on the ARX (Auto-Regressive with Exogenous Input) speech {{production}} model. The model consists of cascade formant-antiformant synthesizers driven by a <b>voicing</b> <b>source</b> and an unvoiced turbulent noise source. One of the key features of the proposed method {{is that we have}} an algorithm to automatically measure the <b>voicing</b> <b>source,</b> unvoiced source and formant-antiformant parameters of the synthesizer directly from natural speech waveforms. After having automatically obtained estimates of the parameters from natural speech, one can manipulate the estimates using a flexible editing tool that has been developed {{as a part of the}} system. By changing values of the fundamental frequency, glottal open quotient, spectral tilt parameter, turbulent noise level, formant-antiformant frequencies and bandwidths, we can synthesize natural sounding speech with various voice qualities including modal, breathy, tense, and whisper voice...|$|R
40|$|In CDMA mobile {{communication}} systems, voice is encoded and packaged in variable length packets that are transported between the mobile {{station and the}} switching center. While the packetization provides a great flexibility in resource allocation, it poses a QOS challenge on voice. In this paper, we discuss link dimensioning for a typical CDMA system. We consider a communication link connecting a CDMA base station and Mobile Switching Center. We analyze the resulting queueing system using large deviations theory and provide results for the minimum link capacity needed to support a given number of CDMA <b>voice</b> <b>sources.</b> Our results show the potential gain {{that can be achieved}} by statistical multiplexing of <b>voice</b> <b>sources</b> and discuss the effects of the statistics of the voice process on the multiplexer performance...|$|R
5000|$|Lily {{originally}} {{appeared on}} the cover of the CD [...] "anim.o.v.e. 01" [...] released on Aug 19th, 2009 before the announcement of her VOCALOID development. Lily was introduced as [...] "Code Name: Lily" [...] on DTM MAGAZINE published in May, 2010. The <b>voice</b> <b>source</b> is the lead vocalist of m.o.v.e., Yuri Masuda. The idea of the developing a VOCALOID based on Yuri's voice occurred, as one of the members was a user of VOCALOID. The illustration of Lily's VOCALOID was used on the Anim.o.v.e album while the voicebank was in development.|$|E
5000|$|Integrated linear {{prediction}} residuals (ILPR) was {{an effective}} feature proposed by T V Ananthapadmanabha in 1995, which closely approximates the <b>voice</b> <b>source</b> signal. This {{proved to be}} very effective in accurate estimation of the epochs or the glottal closure instant. [...] A G Ramakrishnan et al. showed in 2015 that the discrete cosine transform coefficients of the ILPR contains speaker information that supplements the mel frequency cepstral coefficients. Plosion index is another scalar, time-domain feature that was introduced by T V Ananthapadmanabha et al. for characterizing the closure-burst transition of stop consonants.|$|E
50|$|Mozhi Vallan, the Tamil OCR product {{developed}} by MILE Lab, {{is being used}} by Worth Trust and Karna Vidya Technology Centre, Chennai for the conversion of printed school and college books to Braille format. Sri Ramakrishna Math, Chennai is using it to convert their printed philosophical books in Tamil to computer readable text. Lipi Gnani, the Kannada OCR {{developed by}} MILE Lab is being used by Braille Transcription Centers of Mitrajyothi and Canara Bank Relief & Welfare Society, Bangalore for similar purposes. Also, Thirukkural, the Tamil TTS system developed by MILE Lab is being used by some school teachers in Singapore for assignments. Madhura, the Kannada TTS developed by the lab, is being used by two blind students, integrated with a screen reader, to read aloud text OCR'ed with Lipi Gnani from Kannada books. Currently, the lab is researching on machine listening and a novel temporal feature named as plosion index has been proposed, which {{has been shown to}} be extremely effective in detecting closure-burst transitions of stop consonants and affricates from continuous speech, even in noise. Another feature proposed is DCTILPR, which is a <b>voice</b> <b>source</b> based feature vector that improves the recognition performance of a speaker identification system.|$|E
40|$|This paper {{presents}} {{an approach to}} estimate the glottal formant parameters of the <b>voicing</b> <b>source</b> in the frequency-domain. The method {{is based on a}} simplified pole-zero interpretion of the prevalent Liljencrants-Fant (LF) model of glottal flow, and gives approximations for a broad range of pulses shapes. An advantage of the method is that, unlike other methods, it does not rely on time-domain references...|$|R
40|$|This paper {{presents}} {{simulation results}} outlining {{the behavior of}} rate-adaptive voice communications over IP networks. In the considered architecture, voice coders adapt their rate to {{the current state of}} the network so as to generate only the bandwidth that the network is capable of carrying. An algorithm is proposed for driving the transmission rate of <b>voice</b> <b>sources</b> on the basis of estimations of the network conditions, measured in terms of packet delays and losses. The effectiveness of the proposed solution is then investigated in various scenarios which comprise: (i) a dedicated network in which the available bandwidth is exclusively shared between adaptive voice connections; (ii) a scenario in which adaptive <b>voice</b> <b>sources</b> compete with other TCP-like sources; and (iii) an uncontrolled network environment. We have compared the performance of the rate-adaptive against the non-adaptive (i. e. fixed-rate) approach for the transport of voice over IP. Using a rate-adaptive approach, more voice communications can be carried while maintaining a good quality of service, even on non-segregated networks...|$|R
30|$|A {{parametric}} {{model of}} the glottal flow derivative, equivalent to the LF model [26], {{is used for the}} <b>voiced</b> <b>source.</b> The model is described in the spectral domain, according to previous results [27]. The spectral approach is well suited to real-time implementation because of a low computational load. The perceptive parameters of voice quality are genuinely linked to spectral descriptions, such as spectral richness or harmonic amplitudes.|$|R
40|$|Much {{research}} has shown that the <b>voice</b> <b>source</b> has strong influence on the quality of speech processing [4][5][6]. But in most of the existing speech modification algorithms, the effect of the <b>voice</b> <b>source</b> variation is neglected. This work explains why the existing modification scheme can't truly reflect the <b>voice</b> <b>source</b> variation during pitch modification. We use synthesized voiced speech sound to compare an existing pitch modification scheme with our proposed <b>voice</b> <b>source</b> scaling based modification scheme. Results show that <b>voice</b> <b>source</b> scaling based pitch modification can be used for wider range pitch modification...|$|E
40|$|There is a {{need for}} {{automatic}} methods for parametrization of the <b>voice</b> <b>source</b> signals. Representatives of the two types of methods that have been used most often for parametrization were tested and compared. For this purpose a novel evaluation procedure is proposed which makes it possible to perform the numerous tests needed for a detailed comparison of the methods. This evaluation procedure revealed that {{in order to reduce the}} average error in the estimated <b>voice</b> <b>source</b> parameters the estimation methods should be able to estimate noninteger values of these parameters. The proposed evaluation method was also used to study the influence of low-pass filtering on the estimated <b>voice</b> <b>source</b> parameters. The factor low-pass filtering was chosen because low-pass filtering is probably used in all methods in which <b>voice</b> <b>source</b> parameters are estimated. It turned out that low-pass filtering causes an error in all estimated <b>voice</b> <b>source</b> parameters. On average, the smallest errors were found for a parametrization method in which a <b>voice</b> <b>source</b> model is fitted to the <b>voice</b> <b>source</b> signals, and in which the <b>voice</b> <b>source</b> model is low-pass filtered with the same filter as the <b>voice</b> <b>source</b> signals...|$|E
40|$|This paper {{presents}} a data-driven {{approach to the}} modelling of <b>voice</b> <b>source</b> waveforms. The <b>voice</b> <b>source</b> is a signal that is estimated by inverse-filtering speech signals with {{an estimate of the}} vocal tract filter. It is used in speech analysis, synthesis, recognition and coding to decompose a speech signal into its source and vocal tract filter components. Existing approaches parameterize the <b>voice</b> <b>source</b> signal with physically- or mathematically-motivated models. Though the models are well-defined, estimation of their parameters is not well understood and few are capable of reproducing the large variety of <b>voice</b> <b>source</b> waveforms. Here we present a data-driven approach to classify types of <b>voice</b> <b>source</b> waveforms based upon their melfrequency cepstrum coefficients with Gaussian mixture modelling. A set of ‘prototype ’ waveform classes is derived from a weighted average of <b>voice</b> <b>source</b> cycles from real data. An unknown speech signal is then decomposed into its prototype components and resynthesized. Results indicate that with sixteen <b>voice</b> <b>source</b> classes, low resynthesis errors can be achieved. Index Terms — <b>Voice</b> <b>source,</b> inverse-filtering, closed-phase analysis, LP...|$|E
50|$|The author Susan Power herself narrates the {{audiobook}} for The Grass Dancer, {{lending to}} the voice of the novel. Her tone lends well to the representation of the female characters. Power is exceptional in the role of reading her own writing. She is able to do this because she has a clear, relatable speaking <b>voice.</b> <b>Sources</b> for the audiobook rate it between 3 and 4.5 stars.|$|R
40|$|Code Division Multiple Access (CDMA) {{technology}} is gaining momentum as the preferred wireless {{system for the}} next generation Personal Communication Systems (PCS). In CDMA systems, voice is encoded and packaged in variable length packets that are transported between the mobile station and the switching center. Although the packetization provides a great flexibility in resource allocation, it poses a Quality of Service (QoS) problem on voice. In this paper, we discuss link dimensioning for a typical CDMA system. We consider a T 1 /E 1 link between a CDMA Basestation Transceiver System (BTS) and the Base Station Controller (BSC). Traffic from various <b>voice</b> <b>sources</b> is subject to a framing scheme, which presents a semi-periodic batch input at the T 1 /E 1 interface cards. We analyze the resulting queuing system using discrete-time analysis and large deviations theory and verify our results by simulation. We provide results for the minimum link capacity needed to support a given number of CDMA <b>voice</b> <b>sources.</b> Our results show the potential statistical gain that can be achieved by voice packetization for all practical values of link capacities...|$|R
40|$|The KLSYN speech {{synthesis}} program accepts user commands to create parametric data {{to control a}} digital speech synthesizer, and it produces an output waveform file with a user-specified name. {The IBM-PC version of KLSYN was first implemented by Keith Johnson & Yingyong Qi at Ohio State University in 1987. Since then several minor modifications have been added by Keith Johnson. } The synthesizer {{is the same as}} the one documented in some detail in Klatt (1980), except that the <b>voicing</b> <b>source</b> has been augmented so as to permit a choice between two glottal waveforms. The new <b>voicing</b> <b>source</b> waveform is intended to be more flexible and thus be capable of producing more natural changes in voice quality over the duration of a sentence, if controlled properly. The theory of control, and the new control parameters are all described herein. Introduction and overview {This section describes procedures and tools for speech syntheis at the Research Laboratory of Electronics at MIT. Although the procedural details differ from one implementation to the next, this section provides a valuable insight into the speec...|$|R
40|$|The {{behaviour}} of the <b>voice</b> <b>source</b> {{characteristics in}} connected speech was studied. <b>Voice</b> <b>source</b> parameters {{were obtained by}} automatic inverse filtering, followed by automatic fitting of a glottal waveform model to the data. Consistent relations between <b>voice</b> <b>source</b> parameters and prosodic features were observed...|$|E
40|$|Comparing {{methods for}} {{automatic}} extraction of <b>voice</b> <b>source</b> parameters from continuous speech Two methods are presented for automatic {{calculation of the}} <b>voice</b> <b>source</b> parameters from continuous speech. Both methods are {{used to calculate the}} <b>voice</b> <b>source</b> parameters for natural speech. However, for natural speech no objective test procedure seems available. Therefore, both methods were also tested on synthetic speech...|$|E
40|$|This paper {{outlines}} {{an approach}} to modelling the dynamics of <b>voice</b> <b>source</b> parameters as observed {{in the analysis of}} emotional portrayals, by a male speaker of Hiberno-English. The emotions portrayed were happy, angry, sad, bored, and surprised, as well as neutral. The <b>voice</b> <b>source</b> parameters extracted from emotionally coloured repetitions of a short utterance – by means of inverse filtering followed by source model matching – were modelled using classification and regression trees. Regression trees were built using the <b>voice</b> <b>source</b> parameters of the neutral repetition of the same short utterance, in order to transform the <b>voice</b> <b>source</b> parameters from neutral to one of the five emotions. Re-synthesis of emotion-portraying utterances using transformed <b>voice</b> <b>source</b> parameter dynamics resulted in synthesised utterances which were confirmed by listening tests to represent the targeted emotion categories. The results suggest that the addition of dynamic <b>voice</b> <b>source</b> information in parametric synthesis of emotion will improve the quality of emotion synthesis. 1...|$|E
40|$|This paper {{presents}} {{simulation results}} outlining {{the behavior of}} rate-adaptive voice communications over IP netwol cs. In the considered architecture, voice coders adapt their rate to {{the current state of}} the network so as to generate only the bandwidth that tl: network is capable of canTing. An algorithm is proposed for driving the transmission rate of <b>voice</b> <b>sources</b> on the basis of estimations of th network conditions, measured in terms of packet delays and losses...|$|R
40|$|I {{would like}} to open hiding clue in vocal {{techniques}} as an artistic treasure of Balinese culture. Many people who are expert in this particular genre designedly or involuntary have done and even in advance technique. The fact that traditional singers are usually busy struggling with the singing technique and its regulation, but less realized that is not many people knowing the meaning behind what they did. Which is including {{in the case of}} understanding about location of voices “penempatan suara”. This term in Western music vocal is called “vocal placement” identical with <b>voice</b> <b>sources</b> from where that voices come at a time when once singing. This vocal technique really need by a singer or penembang, because by using it properly, hence will be produced the beauty of voices as according to a song’s character. Brooding for determining precise locations of voices is reflection of singer professionals, even though in practice is is followed with separate processing according to voice requirements wanted. Vocal placement is absolutely important for singers. Besides processing of vocal technique it self which have been mastered, also need to be understood several <b>voice</b> <b>sources</b> to make <b>voice</b> appearance in higher quality...|$|R
40|$|Abstract. In {{this paper}} we propose a model-based {{admission}} control scheme for maintaining QoS of voice traffic over DiffServ networks. This CAC approach implies two main components. The first one is the application of the NJ (Negligible Jitter) conjecture extended to the case of heterogenous variable bit rate <b>voice</b> <b>sources.</b> The second one is the analysis of a finite queueing system with exhaustive service and multiple server vacations, which is motivated by the strict priority scheduling deployed in DiffServ-capable routers. Extensive analytical and simulation results are investigated to assess the applicability of the CAC proposal. ...|$|R
40|$|The paper {{presents}} a <b>voice</b> <b>source</b> waveform modeling techniques based on {{principal component analysis}} (PCA) and Gaussian mixture modeling (GMM). The <b>voice</b> <b>source</b> is obtained by inverse-filteirng speech with the estimated vocal tract filter. This decomposition is useful in speech analysis, synthesis, recognition and coding. Existing models of the <b>voice</b> <b>source</b> signal are based on function-fitting or physically motivated assumptions and although they are well defined, estimation of their parameters is not well understood and few are capable of reproducing the large variety of <b>voice</b> <b>source</b> waveforms. Here, a data-driven approach is presented for signal decomposition and classification based on the principal components of the <b>voice</b> <b>source.</b> The principal components are analyzed and the ‘prototype ’ <b>voice</b> <b>source</b> signals corresponding to the Gaussian mixture means are examined. We show how an unknown signal can be decomposed into its components and/or prototypes and resynthesized. We show how the techniques are suited for both low bitrate or high quality analysis/synthesis schemes...|$|E
40|$|The analysis, {{parameterization}} {{and modeling}} of <b>voice</b> <b>source</b> estimates obtained via inverse filtering of recorded speech {{are some of}} the most challenging areas of speech processing owing to the fact humans produce a wide range of <b>voice</b> <b>source</b> realizations and that the <b>voice</b> <b>source</b> estimates commonly contain artifacts due to the non-linear time-varying source-filter coupling. Currently, the most widely adopted representation of <b>voice</b> <b>source</b> signal is Liljencrants-Fant's (LF) model which was developed in late 1985. Due to the overly simplistic interpretation of <b>voice</b> <b>source</b> dynamics, LF model can not represent the fine temporal structure of glottal flow derivative realizations nor can it carry the sufficient spectral richness to facilitate a truly natural sounding speech synthesis. In this thesis we have introduced Characteristic Glottal Pulse Waveform Parameterization and Modeling (CGPWPM) which constitutes an entirely novel framework for <b>voice</b> <b>source</b> analysis, parameterization and reconstruction. In comparative evaluation of CGPWPM and LF model we have demonstrated that the proposed method is able to preserve higher levels of speakerdependant information from the <b>voice</b> <b>source</b> estimates and realize a more natural sounding speech synthesis. In general, we have shown that CGPWPM-based speech synthesis rate...|$|E
40|$|A voice {{synthesis}}er program {{based on}} adding sinusoids was written. Additive synthesis gives good flexibility {{in changing the}} <b>voice</b> <b>source</b> spectral characteristics {{at the cost of}} slower execution. The program allows some 20 <b>voice</b> <b>source</b> parameters to be programmed over time, such as spectral tilt, individual harmonic's levels, subharmonic content in different frequency ranges, the phase of the harmonics, F 0, flutter, vibrato and noise. The <b>voice</b> <b>source</b> is filtered by up to 32 formants...|$|E
40|$|In this paper, {{we discuss}} link {{dimensioning}} {{for a typical}} CDMA encoder. We consider a T 1 /E 1 link extending between a CDMA basestation and the Mobile Switching Center. Traffic from various <b>voice</b> <b>sources</b> is subject to a framing scheme, which presents a semi-periodic batch input at the T 1 /E 1 interface cards. We analyze the resulting queuing system using discrete-time analysis and verify our results through simulation. Our results show {{the accuracy of the}} analysis and the potential statistical gain that can be achieved by voice packetization...|$|R
40|$|In {{this paper}} we discuss the {{capacities}} of architecture alternatives for the interconnection of Base Transceiver Systems (BTS) and their Base Station Controller (BSC) in CDMA mobile communication networks. To this end, queuing models of architecture alternatives are derived. We analyze the models using discrete-time analysis techniques and verify the results by simulation. Numerical results are provided for {{the maximum number of}} CDMA <b>voice</b> <b>sources</b> that can be supported by a given capacity of the interconnecting links. This enables us to compare the architecture alternatives in terms of teletraffic capacit...|$|R
40|$|Speaker {{authentication}} {{has been}} developed rapidly {{in the last few}} decades. This research work attempts to extract the hidden features of human voice that is able to simulate human auditory system characteristics in speaker authentication. The hidden features are then presented as inputs to a Multi-Layer Perceptron Neural Network and Generic Self-organizing Fuzzy Neural Network to verify the speakers with high accuracy. Based on the experimental results, the two networks are able to verify speakers using two method in extracting hidden features from the recorded <b>voice</b> <b>sources.</b> r 2005 Elsevier B. V. All rights reserved...|$|R
