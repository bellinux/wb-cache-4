2|10000|Public
40|$|There {{are many}} {{complementing}} strategies {{to estimate the}} extrapolation errors of a model which was calibrated in least-squares fits. We consider the Skyrme-Hartree-Fock model for nuclear structure and dynamics and exemplify the following five strategies: uncertainties from statistical analysis, covariances between observables, trends of residuals, <b>variation</b> <b>of</b> <b>fit</b> data, dedicated variation of model parameters. This gives useful insight into {{the impact of the}} key fit data as they are: binding energies, charge r. m. s. radii, and charge formfactor. Amongst others, we check in particular the predictive value for observables in the stable nucleus $^{ 208 }$Pb, the super-heavy element $^{ 266 }$Hs, $r$-process nuclei, and neutron stars...|$|E
40|$|In this work, we {{have tested}} the optimal {{estimation}} (OE) algorithm for {{the reconstruction of}} the optical properties of a two-layered liquid tissue phantom from time-resolved single-distance measurements. The OE allows a priori information, in particular on the range of <b>variation</b> <b>of</b> <b>fit</b> parameters, to be included. The purpose of the present investigations was to compare the performance of OE with the Levenberg–Marquardt method for a geometry and real experimental conditions typically used to reconstruct the optical properties of biological tissues such as muscle and brain. The absorption coefficient of the layers was varied in a range of values typical for biological tissues. The reconstructions performed demonstrate the substantial improvements achievable with the OE provided a priori information is available. We note the extreme reliability, robustness, and accuracy of the retrieved absorption coefficient of the second layer obtained with the OE that was found for up to six fit parameters, with an error in the retrieved values of less than 10 %. A priori information on fit parameters and fixed forward model parameters clearly improves robustness and accuracy of the inversion procedure...|$|E
40|$|The {{analysis}} of sequences {{is one of}} the major research areas of bio-informatics. Inspired by this research, we investigate the discovery of sequential patterns for use in classification. We will define <b>variations</b> <b>of</b> a <b>fit</b> function that enables us to tell if one pattern better fits to a class than another. Furthermore we will show how domain knowledge can be used for faster discovery of better sequential patterns in specific types of databases, in our case a receptor database. ...|$|R
40|$|By {{observing the}} {{difference}} in optical depths between absorption spectra toward the two components of double sources, the variations in opacity over lengths of less than 0. 1 up to 10 pc inside diffuse interstellar clouds were measured. Significant variations were detected on scales larger than about 0. 2 pc, but not less. This may represent the minimum size for diffuse cloud structure. By comparing the <b>variations</b> <b>of</b> Gaussian <b>fitted</b> line parameters, {{it was found that}} variations in the internal velocity field of diffuse clouds explain the data better than tiny independent cloudlets...|$|R
40|$|AbstractFor {{rational}} {{estimation of}} users’ benefit, {{it is necessary}} to understand users’ willingness-to-pay (WTP). In several WTP studies, stated preference data have been analyzed using Mixed Logit (ML) model specification. In ML models, {{it is necessary to}} make an assumption regarding the distribution of random parameters. Researchers have developed ML models with different distributional assumptions of random parameters. However, the effect of distributional assumptions of random parameters in ML model on goodness-of-fit and WTP values has not been studied adequately. In the present work, an investigation is carried out in this regard taking reference to a case study of feeder service to bus stop in rural India. Various Mixed Logit models were attempted with different distributional assumptions of random parameters such as normal, log normal, triangular, uniform, constrained normal, constrained triangular, constrained uniform, etc. <b>Variation</b> <b>of</b> goodness <b>of</b> <b>fit</b> statistics and WTP values are observed across different ML models. The work indicates the importance of distributional assumption while developing ML model in WTP studies. The work also indicates that it is desirable to develop several ML models with different distributional assumptions and then select the superior one based on goodness <b>of</b> <b>fit</b> statistics...|$|R
40|$|Monte Carlo {{computer}} simulations {{are used to}} study transient cavities and the solvation of hard-spheroid solutes in dipolar hard sphere solvents. The probability distribution of spheroidal cavities in the solvent is shown to be well described by a Gaussian function, and the <b>variations</b> <b>of</b> <b>fit</b> parameters with cavity elongation and solvent properties are analyzed. The excess chemical potentials of hard-spheroid solutes with aspect ratios x in the range 1 / 5 ≤ x ≤ 5, and with volumes between one and twenty times that of a solvent molecule, are presented. It is shown that for a given molecular volume and solvent dipole moment (or temperature) a spherical solute has the lowest excess chemical potential and hence the highest solubility, while a prolate solute with aspect ratio x should be more soluble than an oblate solute with aspect ratio 1 /x. For a given solute molecule, the excess chemical potential increases with increasing temperature; this same trend is observed {{in the case of}} hydrophobic solvation. To help interpret the simulation results, comparison is made with a scaled-particle theory that requires prior knowledge of a solute-solvent interfacial tension and the pure-solvent equation of state, which parameters are obtained from simulation results for spherical solutes. The theory shows excellent agreement with simulation results over the whole range of solute elongations considered. Comment: 10 pages, 10 figure...|$|R
40|$|The {{structural}} {{design of a}} Venetian Blind direct converter {{will depend on the}} choice, for example, of: 1) Expander field, (2) Selective leakage, (3) Number of collector stages, (4) Method of cooling and (5) The general configuration and orientation. This note is intended to outline the major compromises that will result from the <b>variation</b> <b>of</b> parameters to <b>fit</b> a particular design. The relationships given are for a two-stage unit, but it is straightforward to extend them to multiple-stage units. (auth...|$|R
40|$|The {{in-plane}} London penetration depth, Δλ(T), {{was measured}} using a tunnel diode resonator in single crystals of Ba_ 1 -xK_xFe_ 2 As_ 2 for five doping levels x ranging from underdoped, T_c= 11 K (x= 0. 17), to optimally doped, T_c= 38 K (x_ opt= 0. 35). In the optimally doped samples, Δλ(T) shows exponential saturation in T → 0 limit suggesting a fully gapped superconductivity. The lowest-T_c samples show much stronger non-exponential <b>variation</b> <b>of</b> Δλ(T). <b>Fitting</b> the data to a power-law, Δλ(T) = AT^n, reveals a monotonic decrease of the exponent n with x towards the underdoped edge of the superconducting dome. Comparison with n ≈ 1. 2 reported in KFe_ 2 As_ 2 (T_c= 3. 5 K, x= 1), suggests a dome-like <b>variation</b> <b>of</b> n with x, implying an evolution of the topology of the superconducting gap from full and isotropic {{in the center of}} the dome towards strongly anisotropic and, eventually, nodal at the dome edges...|$|R
40|$|Modelling daily {{wind speed}} data {{by using the}} two {{parameter}} Weibull distribution for ten selected weather stations in Sri Lanka is presented. The daily wind speed data measured by the Department of Meteorology at the heights of 6 m- 15 m during the years 2001 and 2004 were used in this work. The annual <b>variation</b> <b>of</b> the <b>fitted</b> Weibull parameters, the shape parameter k and the scale parameter c ranged from 0. 80 to 3. 58 and 2. 79 ms- 1 to 19. 78 ms- 1 respectively. The highest values of the parameters were found in Hambantota and the lowest values were found in Kurunegala. It was seen that the daily wind speed distribution can be modelled with a reasonable accuracy, using the two parameter Weibull distribution for the stations considered in this work. 1...|$|R
40|$|This paper uses {{experiment}} design optimization {{to obtain the}} optimal placement of scans during dynamic contrast enhanced computed tomography. Here we construct and minimize an objective function based on the Cramer-Rao lower bound (CRLB) to optimize {{the accuracy of the}} estimators. Experiments based on simulated data are performed to compare our scheme with current sampling methods. Results reveal a significant reduction in error and <b>variation</b> <b>of</b> the <b>fitted</b> parameters while simultaneously reducing the number of scans, and thus the radiation dose received by the patient. We also show that our acquisition scheme is robust to the parameter values, easily adaptable to various parts of the body and therefore has great clinical potential. Index Terms — computed tomography, dynamic contrast enhanced imaging, optimal sampling, Cramer Rao lower bound 1...|$|R
50|$|The central {{element of}} the MMI {{terminal}} is the control dial. This dial can be rotated, to navigate up and down through menus, and pressed to activate a selected highlighted function. Starting with MMI 3G system an integrated joystick in the main control dial {{can be used to}} (for example) navigate the map. Depending on the MMI generation and configuration, four to eight function buttons surround the control dial which are used to launch the various features. The MMI screen is available as a five-inch monochrome black-and-red or seven-inch 16:9 full colour display, depending on the <b>variation</b> <b>of</b> MMI <b>fitted</b> in the car. MMI uses Media Oriented Systems Transport (MOST) technology to interconnect the various systems. Harman Becker Automotive Systems manufactures the MMI system, utilizing QNX Neutrino's Real Time Operating System (RTOS) software.|$|R
40|$|The {{two-dimensional}} Fourier transform (2 D-FT) is {{well suited}} to the extraction of features to differentiate image texture, and the classification of images based on information acquired from the frequency domain provides a complementary method to approaches based within the spatial domain. The intensity, I, of the Fourier-transformed images can be modelled by an equation of power law form, I = Ar, where A and are constants and r is the radial spatial frequency. The power law is fitted over annuli, centred at zero spatial frequency, and the parameters, A and, determined for each spatial frequency range. The <b>variation</b> <b>of</b> the <b>fitted</b> parameters across wedges of fixed polar angle provides a measure of directionality and the deviation from the fitted model can be exploited for classification. The classification results are combined with an existing method to classify individual objects within the crystallization drop to obtain an improved overall classification rate. ...|$|R
40|$|Transient {{black hole}} {{candidates}} are interesting objects {{to study in}} X-rays as these sources show rapid evolutions in their spectral and temporal properties. In this paper, we study the spectral properties of the Galactic transient X-ray binary MAXI~J 1659 - 152 during its very first outburst after discovery with the archival data of RXTE Proportional Counter Array instruments. We make a detailed study {{of the evolution of}} accretion flow dynamics during its 2010 outburst through spectral analysis using the Chakrabarti-Titarchuk two-component advective flow (TCAF) model as an additive table model in XSPEC. Accretion flow parameters (Keplerian disk and sub-Keplerian halo rates, shock location and shock strength) are extracted from our spectral fits with TCAF. We studied <b>variations</b> <b>of</b> these <b>fit</b> parameters during the entire outburst as it passed through three spectral classes: hard, hard-intermediate, and soft-intermediate. We compared our TCAF fitted results with standard combined disk black body (DBB) and power-law (PL) model fitted results and found that <b>variations</b> <b>of</b> disk rate with DBB flux and halo rate with PL flux are generally similar in nature. There appears to be an absence of the soft state unlike what is seen in other similar sources. Comment: 8 pages, 4 figures, 1 tabl...|$|R
40|$|Detailed {{experimental}} data on UPO₄Cl comprising single-crystal UV/vis/NIR spectra and temperature-dependent magnetic susceptibilities {{form the basis}} for the investigation of the electronic structure of the U⁴⁺ cation in UPO₄Cl. For modeling of the observed physical properties the angular overlap model (AOM) was successfully employed. The computations were performed using the newly developed computer program BonnMag. The calculations show that all electronic transitions and the magnetic susceptibility as well as its temperature dependence are well-reproduced within the AOM framework. Using Judd–Ofelt theory BonnMag allows estimation of the relative absorption coefficients of the electronic transitions with reasonable accuracy. Ligand field splitting for states originating from f-electron configurations are determined. Slater–Condon–Shortley parameters and the spin–orbit coupling constant for U⁴⁺ were taken from literature. The good transferability of AOM parameters for U⁴⁺ is confirmed by calculations of the absorption spectra of UP₂O₇ and (U₂O) (PO₄) ₂. The effect <b>of</b> <b>variation</b> <b>of</b> the <b>fit</b> parameters is investigated. AOM parameters for U⁴⁺ (5 f) are compared to those of the rare-earth elements (4 f) and transition metals (3 d) ...|$|R
40|$|A {{systematic}} approach {{is presented to}} obtain improved panel fit quality {{through the use of}} an optimum panel fitting strategy. The objective of the optimal panel fitting strategy is to determine the location of the panels on the automobile body such that the gap and flush <b>variation</b> <b>of</b> the panel <b>fit</b> are minimized. This approach uses measurement data from both the panels and the body-in-white (BIW) to determine the optimum position of multiple panels in an automobile body opening. First, some indices are defined to quantify the quality <b>of</b> a panel <b>fit.</b> Second, the sources <b>of</b> <b>variation</b> in the gap and flush are presented. Then the multiple panel fitting problem is formulated into a constrained optimization model. The effects of the optimization model and algorithm by reducing the within-car gap and flush variation on average by 24, 3 % and by as much as 43, 4 % in the case study presented...|$|R
40|$|An updated {{analysis}} using about 1. 5 million events recorded at √s = M Z with the DELPHI detector in 1994 is presented. Eighteen infrared and collinear safe event shape observables are measured {{as a function}} of the polar angle of the thrust axis. The data are compared to theoretical calculations in Ο(α s 2) including the event orientation. Detailed studies of the renormalization scale dependence of the Ο(α s 2) predictions have been performed, including fits applying experimentally optimized renormalization scale values as well as theoretically motivated scale setting prescriptions. It is found, that in general the predictions fail to describe the data if a renormalization scale value μ 2 = M Z 2 is applied. In this case, the slope of the observed distributions is badly described and the stability of α s (M Z 2) with respect to a <b>variation</b> <b>of</b> the <b>fit</b> range is poor. These deviations with respect to the data propagate into the matched predictions of O (α s 2) and next-to-leading log approximation (NLLA), making them also inappropriate for an accurate description of the high precision data. An excellent description of the 18 event shape distributions in Ο(α s 2) precision is obtained if the renormalization scale value is fitted to the individual data distributions. The stability <b>of</b> the <b>fits</b> with respect to a <b>variation</b> <b>of</b> the <b>fit</b> range is very good. The scale values obtained from the fits are found to be similar to those predicted by the effective charge method (ECH) and the principle of minimal sensitivity (PMS). The influence of higher order contributions was also investigated by using the method of Padé approximants to obtain an estimate of the uncalculated Ο(α s 3) contribution as well as for the sum of the perturbative series. The renormalization scale dependence of the Padé predictions is found to be largely reduced with respect to the Ο(α s 2) predictions. A combined <b>fit</b> <b>of</b> α s and of the renormalization scale in Ο(α s 2) to the 18 oriented event shape distributions yields a perfectly consistent set of 18 measurements of the strong coupling. A weighted average from 18 observables yields α s (M Z 2) = 0. 1174 ± 0. 0026. This result accounts for heavy quark mass effects and considers correlations between the individual measurements. The final result, derived from the jet cone energy fraction, the observable with the smallest theoretical and experimental uncertainty, is α s (M Z 2) = 0. 1180 ± 0. 0006 (exp.) ± 0. 0013 (hadr.) ± 0. 0008 (scale) ± 0. 0007 (mass). This value is in perfect agreement with recent α s determinations from renormalization group improved predictions for the Bjorken sum rule and the hadronic decay of the τ lepton. </FONT...|$|R
40|$|This {{paper offers}} a {{reflective}} {{review of a}} number of currently favoured methods of communicating between teachers and students in the specific context of higher education, in order to determine which methods may be useful in which contexts of learning. As teachers, we have to decide where to expend energy and time to best result amongst the different communication options now available. Experience of five principal communication channels are subject to reflective review: e-mail groups used outside a virtual learning environment (VLE), discussion forums used within VLE, synchronous conferencing (‘livechat’) within VLE, wikis within VLE based on ELGGTM software, and group blogs based on Mahara e-portfoliosoftware. While these five channels represent different stages of communications technology (CT) and do not include web-conferencing, it is proposed that a brief reflective analysis of these commonly available CTs will allow us to explore their value in learning and opportunities for collaboration and identify characteristics which help and hinder learning communities. Affordances of these CTs are found to include <b>variations</b> <b>of</b> structural <b>fit</b> to expected communication outcomes, and power and identity of communicators, as well as defined purpose, are seen to produce different results depending on the chosen channel of communication...|$|R
40|$|International audienceA {{state-of-the-art}} simulation {{technique that}} solves the {{equations of motion}} together with the set-valued contact and impulse laws by the time-stepping scheme of Moreau is introduced to the legged robotics community. An analysis is given that shows which <b>of</b> the many <b>variations</b> <b>of</b> the method <b>fits</b> best to legged robots. Two different methods to solve the discretized normal cone inclusions are compared: the projected over-relaxed Jacobi and Gauss-Seidel iteration. The methods are evaluated for an electrically-driven quadrupedal robot in terms of robustness, accuracy, speed and ease of use. Furthermore, the dependence of the simulation speed on {{the choice of the}} generalized coordinates is examined. The proposed technique is implemented in C++ and compared to a fast and simple approach based on compliant contact models. In conclusion, the introduced method with hard contacts is very beneficial for the simulation of legged robots...|$|R
40|$|Huang, 1998) is ap-plied to {{the series}} of annual and {{seasonal}} averages of temperature, cloudi-ness, air pressure and annual and seasonal sums of global radiation and pre-cipitation, all observed in Zagreb-Gri ~ in the period 1862 – 2002. The method itself decomposes the original series into so called intrincic mode functions (IMF), each being characterized by its own, intrinsic time scale. Sums of the low-frequency IMFs for the single element revealed pres-ent climatic fluctuations on the decade-to-century scale. It is confirmed that climatic fluctuations of every single element, particularly temperature and cloudiness, are the results <b>of</b> <b>variations</b> in the global atmospheric circulation above the whole Europe. Trend and long-term <b>variations</b> <b>of</b> Zagreb tempera-ture <b>fits</b> to globally observed increase of temperature but also to <b>variations</b> <b>of</b> zonal circulation index. Exchange of Hadley’s zonal and Rossby’s wave re-gime of the general atmospheric circulation {{at the beginning of}} the 20 th cen-tury is observed in the long-term <b>variations</b> <b>of</b> almost every element. Linear correlation coefficients between annual and seasonal long-term variations are calculated. It is shown that spring and winter variations mostly influ-enced annual fluctuations that is due to internal feed-back processes. Also, correlation coefficients for every pair of climatic element are calcu-lated, enabling conclusions about interaction between elements on long-term scales...|$|R
40|$|The aim of {{this work}} was the study a {{trickling}} biofilter, where water was circulated throughout the bed. In the first steady state experiment, the packing materials used were 25 mm Pall rings. The airflow rate was increased gradually and the concentration of styrene in the air stream was held constant. In the second experiment, 15 mm Pall rings were used. In this case, the feed contained both styrene and {{a small amount of}} acetone. The concentration of acetone and the air flow rate were kept constant, but the styrene inlet concentration was increased. The concentrations were measured at the input, and also at an intermediate and the outlet position in the biotrickling filter to determine the concentration profile along the reactor. Using the values of coefficient of determination (R 2) and the coefficient <b>of</b> <b>variation</b> <b>of</b> the <b>fitted</b> constant as criteria, a zero order model with diffusional limitation was chosen as the best representation of the data. Then a further, third, set of experiments were done at unsteady state, using step changes of the inlet concentration levels of both styrene and acetone at a steady air flow-rate. Inlet and outlet concentrations were measured as a function of time and the results were adequately described using a simpl...|$|R
40|$|This {{contribution}} {{reviews the}} present {{status of the}} Skyrme-Hartree-Fock (SHF) approach {{as one of the}} leading self-consistent mean-field models in the physics of atomic nuclei. It starts with a brief summary of the formalism and strategy for proper calibration of the SHF functional. The main emphasis lies on an exploration of the reliability of predictions, particularly in the regime of extrapolations. Various strategies are discussed to explore the statistical and systematic errors of SHF. The strategies are illustrated on examples from actual applications. <b>Variations</b> <b>of</b> model and <b>fit</b> data are used to get an idea about systematic errors. The statistical error is evaluated in straightforward manner by statistical analysis based on χ^ 2 fits. This also allows also to evaluate the correlations (covariances) between observables which provides useful insights into the structure of the model and of the fitting strategy. Comment: manuscrtip submitted to Physica Script...|$|R
40|$|Multichannel {{amplitude}} compression processing is used {{to reduce}} the level <b>variations</b> <b>of</b> speech to <b>fit</b> the reduced dynamic ranges of listeners with sensorineural hearing loss. This processing, however, can result in smearing of temporal information, artifacts due to spectral discontinuities at fixed channel edges, and spectral flattening due to reduced peak-to-valley ratios. An implementation of a time-varying compression processing algorithm based on a sinusoidal speech model (Col-SM) operates on a time-varying, stimulus-dependent basis {{to adjust to the}} speech variations and the listener's hearing profile. The algorithm provides fast-acting compression with minimal audible artifact, has time-varying frequency channels, is computationally inexpensive and preserves the important spectral peaks in speech. Presented here is a Col-SM based algorithm that determines the levels of key spectral peaks and valleys to achieve time-varying compression amplification with spectral sharpening. The amount of sharpening can be set individually based on the needs of the listener. The algorithm has been adapted to operate in noisy environment. Preliminary subject tests will be presented...|$|R
30|$|The Weibull shape {{parameters}} characterise the <b>variation</b> <b>of</b> bending strength. The {{higher value}} of shape parameter in LR direction indicates smaller variability of bending strength. Coefficient of determination for both directions {{was close to}} 1. The higher coefficient of determination for LT direction gives the greater goodness <b>of</b> <b>fit.</b>|$|R
30|$|To {{measure how}} well the factors {{describe}} the <b>variation</b> <b>of</b> the mean data, the F-test {{was used in this}} study. A greater F-value indicates that the factors adequately explain the variation in the data. A p-value[*]<[*] 0.05 indicates the significant model term. It was observed that the quadratic regression model (Eq. [3]) was highly significant because of a very low probability value (pmodel[*]>[*]F[*]=[*] 0.0001). Additionally, the lack <b>of</b> <b>fit</b> (LOF), which is a <b>variation</b> <b>of</b> the data around the fitted model, was also used to determine the adequacy <b>of</b> the model <b>fit.</b> If the model does not fit the data well, this term is significant. As shown in Table  7, LOF was not significant at the F-value and p-value of 1.93 and 0.2428, respectively. This result indicated that the model fitted the response well {{and that there is a}} 24.28 % chance that a lack <b>of</b> <b>fit</b> F-value could occur due to noise.|$|R
40|$|Active Appearance Models (AAMs) {{have been}} popularly used to {{represent}} the appearance and shape <b>variations</b> <b>of</b> human faces. <b>Fitting</b> an AAM to images recovers the face pose {{as well as its}} deformable shape and varying appearance. Successful fitting requires that the AAM is sufficiently generic such that it covers all possible facial appearances and shapes in the images. Such a generic AAM is often difficult to be obtained in practice, especially when the image quality is low or when occlusion occurs. To achieve robust AAM fitting under such circumstances, this paper proposes to incorporate the disparity data obtained from a stereo camera with the image fitting process. We develop an iterative multi-level algorithm that combines efficient AAM fitting to 2 D images and robust 3 D shape alignment to disparity data. Experiments on tracking faces in low-resolution images captured from meeting scenarios show that the proposed method achieves better performance than the original 2 D AAM fitting algorithm. We also demonstrate an application of the proposed method to a facial expression recognition task. ...|$|R
40|$|Abstract Background The {{clinical}} problem list is {{an important}} tool for clinical decision making, quality measurement and clinical decision support; however, problem lists are often incomplete and provider attitudes towards the problem list are poorly understood. Methods An ethnographic study of healthcare providers conducted from April 2009 to January 2010 was carried out among academic and community outpatient medical practices in the Greater Boston area across {{a wide range of}} medical and surgical specialties. Attitudes towards the problem list were then analyzed using grounded theory methods. Results Attitudes were variable, and dimensions <b>of</b> <b>variations</b> <b>fit</b> into nine themes: workflow, ownership and responsibility, relevance, uses, content, presentation, accuracy, alternatives, support/education and one cross-cutting theme of culture. Conclusions Significant variation was observed in clinician attitudes towards and use of the electronic patient problem list. Clearer guidance and best practices for problem list utilization are needed. </p...|$|R
30|$|To {{describe}} {{the level and}} random <b>variation</b> <b>of</b> pollen deposition onto leaves, a log-normal distribution was fitted to the observed data using a CML approach. This method was used to account for observational detection limits. The geometric mean <b>of</b> the <b>fitted</b> distribution, {{which is also the}} median, was used to characterise the deposition level. Random variation was described by quantiles <b>of</b> the <b>fitted</b> distribution.|$|R
40|$|First, {{we study}} the <b>fit</b> <b>of</b> the Higgs boson rates, {{based on all}} the latest {{collider}} data, in the effective framework for any Extra-Fermion(s) [EF]. The best-fit results are presented in a generic formalism allowing to apply those for the test of any EF scenario. The <b>variations</b> <b>of</b> the <b>fit</b> with {{each one of the}} five fundamental parameters are described, and, the obtained fits can be better than in the Standard Model (SM). We show how the determination of the EF loop-contributions to the Higgs couplings with photons and gluons is relying on the knowledge of the top and bottom Yukawa couplings (affected by EF mixings); for determining the latter coupling, the relevance of the investigation of the Higgs production in association with bottom quarks is emphasized. In the instructive approximation of a single EF, we find that the constraints from the fit already turn out to be quite predictive, in both cases of an EF mixed or not with SM fermions, and especially when combined with the extra-quark (-lepton) mass bounds from direct EF searches at the LHC (LEP) collider. In the case of an unmixed extra-quark, non-trivial fit constraints are pointed out on the Yukawa couplings for masses up to ~ 200 TeV. In particular, we define the extra-dysfermiophilia, which is predicted at 68. 27 % C. L. for any single extra-quark (independently of its electric charge). Another result is that, among any components of SM multiplet extensions, the extra-quark with a - 7 / 3 electric charge is the one preferred by the present Higgs fit. Comment: 27 pages, 10 figures. Subsection structure added and Higgs boson rates updated (in a separate Appendix) after the Moriond 2013 conferenc...|$|R
40|$|The {{large scale}} {{structure}} of the current sheet in the terrestrial magnetotail is often represented as the superposition of a constant northward-oriented magnetic field component (B(sub z)) and a component along the Earth-Sun direction (B(sub x)) that varies with distance {{from the center of}} the sheet (z(sub o) in GSM) as in a Hams neutral sheet. The latter implies that B(sub x) = B(sub Lx) tanh((z - z(sub o)) /h) where B(sub Lx) is the magnitude of the B(sub x) component in the northern lobe. Correspondingly, the cross-tail current should be approximated by J(sub y) = (B(sub Lx) /h) sech(sup 2) ((z - z(sub o)) /h). Using data from the fluxgate magnetometer (FGM) on the Cluster I 1 spacecraft tetrad, we have used measured fields and currents to ask if this model represents the large-scale properties of the system. During very quiet crossings of the plasmasheet, we find that the model gives a reasonable estimate of the trend of the average current and field distributions, but during disturbed intervals, the best fit fails to represent the data. If, however, the parameters z(sub o) and h of the model are taken as variable functions <b>of</b> time, the <b>fits</b> can be reasonably good. The temporal <b>variation</b> <b>of</b> the <b>fit</b> parameter h that characterizes the thickness of the current sheet can be interpreted in terms of thinning during the growth phase of a substorm and thickening following the expansion phase. Ground signatures that give insight into the local time of substorm onset can be used to interpret the response of the plasmasheet to substorm related changes of the global system. During a substorm, the field magnitude in the central plasmasheet fluctuates at the period of Pi 2 pulsations...|$|R
30|$|The {{accuracy}} <b>of</b> the <b>fitted</b> polynomial can {{be obtained}} from the R 2 value. It provides a measure of how well the observed outcomes are reflected by the model, based on the proportion <b>of</b> total <b>variation</b> <b>of</b> the outcomes.|$|R
5000|$|... "Nicholas Bernoulli (1710-1713) {{completes the}} {{analysis}} of Arbuthnot's data by showing that the larger part <b>of</b> the <b>variation</b> <b>of</b> the yearly number of male births can be explained as binomial with p = 18/35. This is the first example of fitting a binomial to data. Hence we here have a test of significance rejecting the hypothesis p = 0.5 followed by an estimation of p and {{a discussion of the}} goodness <b>of</b> <b>fit</b> …" ...|$|R
40|$|Object Imaging of the myelin water {{fraction}} (MWF) is conventionally performed using a multi-echo spin-echo sequence. This technique requires long acquisition {{times and}} therefore often {{suffers from a}} lack of volume coverage. In this work, the application of 3 D balanced steady-state free precession (bSSFP) sequences to extract high-resolution myelin water maps is discussed. Materials and Methods Based on a two-pool water exchange model, an approximate bSSFP signal equation is derived and applied to fit the flip angle dependence of the in vivo bSSFP signal. Thereby, the MWF and signal amplitude are fitted, while a priori assumptions are made for the other parameters of the two-pool system. Results The effects of magnetization transfer, finite RF pulses, B 0 and B 1 inhomogeneities, as well as <b>variation</b> <b>of</b> the constant <b>fit</b> parameters, are investigated. Acquisition and calculation of quantitative, high-resolution MWF maps from white matter of healthy volunteers based on bSSFP is feasible and averaged MWF fit results agree with literature. However, results from numerical simulations indicate a severe dependence of the derived MWF values on the constant two-pool parameters. Conclusion The demonstrated dependence of the MWF on the two-pool parameters considerably impairs the applicability of the proposed method...|$|R
40|$|ABSTRACT. Corn stover, a major crop‐based {{lignocellulosic}} biomass feedstock, {{is required}} to be at an optimum moisture content for efficient bioconversion processes. Environmental conditions surrounding corn stover, as in storage facilities, affect its moisture due to hygroscopic sorption or desorption. The measurement and modeling of sorption characteristics of corn stover and its leaf, husk, and stalk fractions are useful from utilization and storage standpoints, hence investigated in this article. A benchtop low‐temperature humidity chamber provided the test environments of 20 C, 30 C, and 40 C at a constant 95 % relative humidity. Measured sorption characteristics with three replications for each fraction were obtained from instantaneous sample masses and initial moisture contents. Observed sorption characteristics were fitted using exponential, Page, and Peleg models. Corn stover fractions displayed a rapid initial moisture uptake followed by a slower sorption rates and eventually becoming almost asymptotic after 25 h. Sorption characteristics of all corn stover fractions were significantly different (P 0. 05) on these fractions. The initial 30 min of sorption {{was found to be}} critical due to peak rates of sorption from storage, handling, and processing standpoints. The Page and Peleg models had comparable performance fitting the sorption curves (R 2 0. 995), however the exponential model (R 2 0. 91) was not found suitable because of patterned residuals. The Arrhenius type relationship (P < 0. 05; R 2 0. 80) explained the temperature <b>variation</b> <b>of</b> the <b>fitted</b> sorption model parameters. The Peleg model fitted constants, among the sorption models studied, had the best fit (R 2 0. 93) with the Arrhenius relationship. A developed method of mass proportion, involvin...|$|R
40|$|Measures <b>of</b> <b>variation</b> can be {{evaluated}} as the tools for testing the goodness <b>of</b> <b>fit</b> <b>of</b> the average values to entire data. It {{is impossible to}} calculate arithmetic mean when the data are qualitative. Similarly the measures <b>of</b> <b>variation</b> such as the variance and the standard deviation cannot be calculated for qualitative distributions. When the distribution is qualitative, mode {{can be used to}} determine central tendency. In literature there are some statistics offered for measuring qualitative variation...|$|R
40|$|A Fourier {{analytic}} {{development of}} the total time on test function (TTT) provides principal components that are scale free, and which provide criteria for lack <b>of</b> <b>fit.</b> Aggregated values <b>of</b> the squares of these principal components yield a decomposition of the squared coefficient <b>of</b> <b>variation,</b> and a discrete version of the Anderson-Darling type test statistic. Exponential Gini index Goodness <b>of</b> <b>fit</b> Principal component Normalized spacing Total time on test...|$|R
40|$|Bender element {{testing of}} {{unsaturated}} isotropically compacted speswhite kaolin samples {{was used to}} investigate the <b>variation</b> <b>of</b> small strain elastic shear modulus G under unsaturated conditions. Testing was performed in a suction-controlled triaxial cell and involved combinations of isotropic loading and unloading stages and wetting and drying stages. Analysis of the experimental {{results indicated that the}} <b>variation</b> <b>of</b> G could be represented by a simple expression involving only mean Bishop’s stress p* and specific volume v, with the only significant mismatches between measured and predicted values of G occuring at the end of final unloading. No significant improvement <b>of</b> <b>fit</b> was achieved by incorporating additional dependency on degree of saturation Sr or a bonding parameter ζ. The proposed expression for G reverts to a well-established form for saturated soils as Sr tends to 1...|$|R
