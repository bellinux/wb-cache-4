2225|303|Public
5|$|DragonFly BSD {{supports}} Amiga-style resident applications feature: {{it takes}} a snapshot of a large, dynamically linked program's <b>virtual</b> <b>memory</b> space after loading, allowing future instances of the program to start {{much more quickly than}} it otherwise would have. This replaces the prelinking capability that was being worked on earlier in the project's history, as the resident support is much more efficient. Large programs like those found in KDE Software Compilation with many shared libraries will benefit the most from this support.|$|E
5|$|System 6's Apple menu {{cannot be}} used to launch {{application}}s. The current application icon in the upper right-hand corner of the menu bar cycles between open applications; {{it is not a}} menu. System 6 supports 24bits of addressable random access memory (RAM), which allowed a maximum of 8megabytes of RAM with no provision for <b>virtual</b> <b>memory.</b> These limitations were fixed in System 7. The version of the HFS used by System 6 also has a hard drive capacity limit; it supports up to 2gigabytes (GBs) and 65,536 files on a drive. This limitation was not increased until System 7.5 which first increased the limit to 4GB.|$|E
25|$|All 64-bit {{versions}} of Microsoft operating systems currently impose a 16TB limit on address space. Processes created on the 64-bit editions of Windows Vista can have 8TB in <b>virtual</b> <b>memory</b> for user processes and 8TB for kernel processes {{to create a}} <b>virtual</b> <b>memory</b> of 16TB.|$|E
25|$|Game {{progress}} can {{be saved}} on <b>virtual</b> GameCube <b>Memory</b> Cards, emulated Wii flash memory, and save states. Dolphin features a Memory Card Manager which allows transfer of save files to and from <b>virtual</b> GameCube <b>memory</b> cards.|$|R
40|$|Paramagnetic {{centers in}} a solid hold promise in future sensing {{applications}}. Numerous sensing applications have been theoretically and experimentally demonstrated. However, {{the improvement of}} sensitivity remains challenging. One approach to overcome this is hybrid quantum sensing with quantum memories. The key to this approach is a trade-off {{between the number of}} memory and coherence times ($T_ 2 $) of spins. We propose a new concept of a hybrid quantum sensing with <b>virtual</b> <b>memories</b> using dressed states. We also observe the preliminarily generation of two dressed states in a single paramagnetic center based on Autler-Townes splitting (ATS). Furthermore, we estimate the sensitivity according to the number of dressed states generated in strong microwave driving fields. The results and our approach will pave the way to new hybrid quantum sensing, which can manipulate a higher sensitivity in accordance with the number of quantum <b>virtual</b> <b>memories.</b> Comment: 19 pages, 7 figure...|$|R
5000|$|Mathematica {{manages the}} interprocess {{communication}} such as queueing, <b>virtual</b> shared <b>memory,</b> and failure recovery.|$|R
25|$|A VAX {{computer}} was installed at Berkeley in 1978, but {{the port of}} Unix to the VAX architecture, UNIX/32V, did {{not take advantage of}} the VAX's <b>virtual</b> <b>memory</b> capabilities. The kernel of 32V was largely rewritten by Berkeley students to include a <b>virtual</b> <b>memory</b> implementation, and a complete operating system including the new kernel, ports of the 2BSD utilities to the VAX, and the utilities from 32V was released as 3BSD at the end of 1979. 3BSD was also alternatively called Virtual VAX/UNIX or VMUNIX (for <b>Virtual</b> <b>Memory</b> Unix), and BSD kernel images were normally called /vmunix until 4.4BSD.|$|E
25|$|Windows Vista {{features}} a Dynamic System Address Space that allocates <b>virtual</b> <b>memory</b> and kernel page tables on-demand. It also supports very large registry sizes.|$|E
25|$|Implementing {{certain parts}} in {{operating}} systems and networking requires systems programming, for example implementing paging (<b>virtual</b> <b>memory)</b> or a device driver for an operating system.|$|E
40|$|In case of {{algorithms}} with non-local {{data access}} patterns <b>virtual</b> shared <b>memory</b> implementations commonly {{result in a}} huge lack of performance because of <b>virtual</b> shared <b>memory</b> latency. In order to avoid this problem, a system providing access to distributed data structures has been developed, implemented as a C++ object library. By means of this library the programmer may use special access objects as agents to access the distributed data structures. In case of accessing arrays these access objects may be buffers or queues. If the algorithms are suited for using these access objects, the communication bandwidth instead of the communication latency becomes the major performance factor. 1. Introduction Data structures may be distributed over the processor network using <b>virtual</b> shared <b>memory</b> systems [1, 2, 3, 4]. In order to improve performance many <b>virtual</b> shared <b>memory</b> systems use a cache on each processing node. Nevertheless, a cache is not a perfect accelerating mechanism because a [...] ...|$|R
40|$|CORSO, a {{coordination}} system for <b>virtual</b> shared <b>memory,</b> allows bindings to different programming languages. Currently C, C++, Java, VisualBasic, and Oracle's Developer 2000 are supported. We implement an Ada binding to CORSO, thus opening {{the area of}} <b>virtual</b> shared <b>memory</b> to the Ada world. Our Ada CORSO binding enhances Ada with transaction-oriented, fault-tolerant, distributed objects in a straight-forward way without having to extend the Ada language...|$|R
50|$|Data {{diffusion}} {{machine is}} a historical <b>virtual</b> shared <b>memory</b> architecture where data is free to migrate through the machine.|$|R
25|$|As the {{computer}} kernel grows, so grows {{the size and}} vulnerability of its trusted computing base; and, besides reducing security, there {{is the problem of}} enlarging the memory footprint. This is mitigated to some degree by perfecting the <b>virtual</b> <b>memory</b> system, but not all computer architectures have <b>virtual</b> <b>memory</b> support. To reduce the kernel's footprint, extensive editing has to be performed to carefully remove unneeded code, which can be very difficult with non-obvious interdependencies between parts of a kernel with millions of lines of code.|$|E
25|$|An MMU {{effectively}} performs <b>virtual</b> <b>memory</b> management, handling at {{the same}} time memory protection, cache control, bus arbitration and, in simpler computer architectures (especially 8-bit systems), bank switching.|$|E
25|$|This {{approach}} {{eliminates the}} need for node pointers, substantially reducing the memory requirements. This in turn permits memory mapping and the use of <b>virtual</b> <b>memory</b> to efficiently load the data from disk.|$|E
40|$|The VAT-model (virtual address {{translation}} model) extends the EM-model (external memory model) {{and takes the}} cost of {{address translation}} in <b>virtual</b> <b>memories</b> into account. In this model, {{the cost of a}} single memory access may be logarithmic in the largest address used. We show that the VAT-cost of cache-oblivious algorithms is only a constant factor larger than their EM-cost; this requires a somewhat more stringent tall cache assumption than for the EM-model. ...|$|R
50|$|Two {{techniques}} for moving the <b>virtual</b> machine's <b>memory</b> state {{from the source}} to the destination are pre-copy memory migration and post-copy memory migration.|$|R
50|$|The {{most obvious}} {{resource}} {{in a virtual}} machine is the <b>virtual</b> store (<b>memory).</b> Other resources include peripherals, files, network connections, and so on.|$|R
25|$|Windows 3.0, {{released}} in May 1990, improved capabilities given to native applications. It also allowed users to better multitask older MS-DOS based software compared to Windows/386, {{thanks to the}} introduction of <b>virtual</b> <b>memory.</b>|$|E
25|$|Apart from portability, the CSRG {{worked on}} an {{implementation}} of the OSI network protocol stack, improvements to the kernel <b>virtual</b> <b>memory</b> system and (with Van Jacobson of LBL) new TCP/IP algorithms to accommodate {{the growth of the}} Internet.|$|E
25|$|Memory: 64MB (64 × 220 bytes) of DDR RAM, and 128MB of {{internal}} flash memory, of which about 64MB {{should be available}} to the user. Option for extended <b>virtual</b> <b>memory</b> (RS-MMC up to 1GB (2GB after flash upgrade)).|$|E
40|$|This paper {{presents}} {{an approach to}} formalize coherence protocols for shared <b>virtual</b> <b>memories</b> as multiset rewriting systems. The global state of the protocol is represented as a multiset and rewriting rules are used to describe state changes. Invariants are expressed as properties on the cardinality of subsets which characterize specific relations. We present an automatic algorithm to check that a property is an invariant of a protocol. Both the formalization and the verification steps are illustrated on the Li and Hudak single-writer/multiple-readers coherence protocol...|$|R
5000|$|C-Linda or TCP-Linda - the {{earliest}} commercial and a widespread implementation of <b>virtual</b> shared <b>memory</b> for supercomputers and clustered systems from Scientific Computing Associates, founded by Martin Schultz.|$|R
40|$|We {{report on}} the first formal {{pervasive}} verification of an operating system microkernel featuring the correctness of inline assembly, large non-trivial C portions, and concurrent devices in a single seamless formal proof. We integrated all relevant verification results we had achieved so far [21, 20, 2, 5, 4] into a single top-level theorem of microkernel correctness. This theorem states the simulation of user processes with own, separate <b>virtual</b> <b>memories</b> — via the microkernel — by the underlying hardware with devices. All models, theorems, and proofs are formalized in the interactive proof system Isabelle/HOL...|$|R
25|$|Windows 3.0, {{released}} in 1990, improved the design, {{mostly because of}} <b>virtual</b> <b>memory</b> and loadable virtual device drivers (VxDs) that allow Windows to share arbitrary devices between multi-tasked DOS applications. Windows 3.0 applications can run in protected mode, which gives them access to several megabytes of memory without the obligation {{to participate in the}} software <b>virtual</b> <b>memory</b> scheme. They run inside the same address space, where the segmented memory provides a degree of protection. Windows 3.0 also featured improvements to the user interface. Microsoft rewrote critical operations from C into assembly. Windows 3.0 is the first Microsoft Windows version to achieve broad commercial success, selling 2 million copies in the first six months.|$|E
25|$|The use of <b>virtual</b> <b>memory</b> {{addressing}} (such as paging or segmentation) {{means that}} the kernel can choose what memory each program may use at any given time, allowing the operating system {{to use the same}} memory locations for multiple tasks.|$|E
25|$|Microsoft Windows {{scored a}} {{significant}} success with Windows 3.0, released in 1990. In addition to improved capabilities given to native applications, Windows also allowed users to better multitask older MS-DOS based software compared to Windows/386, {{thanks to the}} introduction of <b>virtual</b> <b>memory.</b>|$|E
40|$|We {{consider}} algorithms {{for implementing}} mutual exclusion on the Cray-T 3 E <b>virtual</b> shared <b>memory</b> using various atomic operations. Our implementations of Anderson's and MCS Lock minimize network contention and dramatically improve performance for any system {{with more than}} two processors. Improvements over the Cray shmem lock library functions are above three orders of magnitude on a 64 -processor T 3 E- 900. Our results hold for both small, and large critical sections, and make the possibility of implementing concurrent data structures on the Cray-T 3 E <b>virtual</b> shared <b>memory</b> a viable one. 1 Introduction In low-level (<b>virtual)</b> shared <b>memory</b> programming, processors can access local and remote memory using read, write, and atomic operations. Synchronization is needed to avoid data consistency problems, called race conditions [14]. Data races arise when threads or parallel processes access shared variables and ffl at least one access is a write operation, while ffl there is no synchronization as [...] ...|$|R
40|$|We {{study the}} design of {{parallel}} algorithms for spectral atmospheric models on <b>virtual</b> shared <b>memory</b> computers. To illustrate our purpose, a simple barotropic vorticity equation (BVE) model is implemented on two BBN TC 2000 machines located at CERFACS and at LLNL 1. The BBN TC 2000 computer {{has been one of}} the first comercially available <b>Virtual</b> Shared <b>Memory</b> (VSM) multiprocessor. Its main characteristic - a global addressable memory physically distributed on nodes - is likely to become a standard for parallel computers. Memory references can be either remote (through the interconnection network, the so-called Butterfly switch) or local to one node 2. We briefly describe the BVE model and the spectral transform, then we introduce transposition strategies for <b>virtual</b> shared <b>memory</b> computers, and define a simple timing model. We especially consider the cost of transpositions using remote memory accesses and the cost of synchronization delays. Performances of two different strategies u [...] ...|$|R
40|$|We develop {{parallel}} {{versions of}} Buchbergers Gröbner Basis algorithm for a <b>virtual</b> shared <b>memory</b> KSR 1 computer. A coarse grain version does S-polynomial reduction concurrently and respects the same critical pair selection strategy as the sequential algorithm. A fine grain version parallelizes polynomial reduction in a pipeline {{and can be}} combined with the parallel S-polynomial reduction. The algorithms are designed for a <b>virtual</b> shared <b>memory</b> architecture and a dynamic memory management with concurrent garbage collection implemented in the MAS computer algebra system. We discuss the achieved speedup figures for up to 24 processors on some standard examples...|$|R
25|$|Techniques {{can also}} be combined. For sorting very large sets of data that vastly exceed system memory, even the index {{may need to be}} sorted using an {{algorithm}} or combination of algorithms designed to perform reasonably with <b>virtual</b> <b>memory,</b> i.e., {{to reduce the amount of}} swapping required.|$|E
25|$|DOS {{is not a}} {{multitasking}} operating system, but {{replacing the}} previous executable image has a great merit there due to harsh primary memory limitations and lack of <b>virtual</b> <b>memory.</b> The same API is used for overlaying programs in DOS and it has effects similar to ones on POSIX systems.|$|E
25|$|The same {{advantage}} exists {{with regards}} to other hierarchical storage systems, such as NUMA or <b>virtual</b> <b>memory,</b> {{as well as for}} multiple levels of cache: once a sub-problem is small enough, it can be solved within a given level of the hierarchy, without accessing the higher (slower) levels.|$|E
40|$|CCC is a {{high-level}} parallel programming language that supports both data and task parallelism. In CCC, data parallelism is specified in single-instruction-multiple-data model, while task parallelism is specified in multiple-instruction-multiple-data model. This paper describes {{the design of}} the runtime system for CCC and the implementations of the runtime system on both a symmetric multiprocessor and a symmetric multiprocessor cluster. The runtime system for CCC is based on a <b>virtual</b> shared <b>memory</b> machine that supports (distributed) shared memory and dynamic (remote) thread creation. This paper shows that based on the <b>virtual</b> shared <b>memory</b> machine, the compiler and the runtime system for CCC become highly retargetable. 1...|$|R
50|$|The Digital Equipment Computer Users' Society {{collected}} many {{patches and}} enhancements for FOCAL. There were even major enhanced offshoots of FOCAL, such as FOCAL-W, which added many features, including better mass storage file I/O and even <b>virtual</b> variable <b>memory.</b>|$|R
40|$|In {{the context}} of virtual environment, The Security {{problems}} are highly important. The work presents analysis of malware types and it‘s presence in virtualized environments. Work also presents some results of experiments that {{have been carried out}} within the real virtual machine environment through modeling aiming to identify dependencies between the malware type, called Rootkits, detection time and the <b>virtual</b> machine <b>memory</b> size. Rootkits exploit kernel vulnerabilities and gain privileges (popularity) within any system, virtual or not. The basic result of the work is as follows: 1) the malware detection methodology for the virtual environment when the memory size of a virtual machine is changing; 2) dependences between the <b>virtual</b> machine <b>memory</b> size and Rootkit detection time...|$|R
