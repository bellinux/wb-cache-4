18|32|Public
50|$|Blu-ray {{players can}} also {{use it as a}} {{low-power}} <b>video</b> <b>accelerator.</b>|$|E
5000|$|S3 Vision868, Vision968 - S3's first motion <b>video</b> <b>accelerator</b> (zoom and YUV->RGB conversion) ...|$|E
50|$|The G200 is a 2D, 3D, and <b>video</b> <b>accelerator</b> chip for {{personal}} computers designed by Matrox. It {{was released in}} 1998.|$|E
40|$|Hardware <b>video</b> <b>accelerators</b> {{are used}} on mobile devices {{to provide support}} for energy {{efficient}} real time High definition (HD) video decoding. Recently, the rise of multi-core archi-tectures on those devices increased their performances and make real time HD video decoding possible using parallel processing on the GPP cores only. What is even more in-teresting to know {{is the level of}} energy efficiency these kind of multi-core General Purpuse Processor (GPP) can achieve as compared to hardware <b>video</b> <b>accelerators.</b> In this paper, we propose an experimental evaluation of the energy effi-ciency of the two video decoding approaches. An accurate energy measurement was achieved on a recent low-power 40 nm mobile SoC containing a quad-core ARM processors and a <b>video</b> hardware <b>accelerator.</b> The results show that parallel multi-core HD decoding enhances both the performance and the energy efficiency as compared to the use of a single core. However, the hardware accelerated decoding is about three times more energy efficient. Based on the experimental ob-servations, some challenges for enhancing parallel multi-core video decoding energy efficiency are pointed out...|$|R
25|$|CL-GD546X – The Laguna VisualMedia {{family of}} 2D, 3D, and <b>video</b> <b>accelerators.</b> '64 and '65 include 3D acceleration. (PCI, AGP). These chips use a single channel of RDRAM memory, {{providing}} up to 600 MB/s bandwidth. The '62 lacks 3D acceleration. All include a BitBLT engine, video windows, and 64×64 hardware cursor.|$|R
5000|$|GCN 2nd {{generation}} {{introduced an}} entity called [...] "Shader Engine" [...] (SE). A Shader Engine comprises one geometry processor, up to 11 CUs (Hawaii chip), rasterizers, ROPs, and L1 cache. Not {{part of a}} Shader Engine is the Graphics Command Processor, the 8 ACEs, the L2 cache and memory controllers {{as well as the}} audio and <b>video</b> <b>accelerators,</b> the display controllers, the 2 DMA controllers and the PCIe interface.|$|R
5000|$|TGUI968x - Feature motion <b>video</b> <b>accelerator</b> (zoom + YUV to RGB {{color space}} conversion, DirectDraw overlay) and first chips with 64-bit DRAM {{interface}} ...|$|E
5000|$|... ix3D Road Rocket was a 2D/3D Cardbus <b>video</b> <b>accelerator</b> for the Apple Macintosh PowerBook G3 series, with 4 MB SGRAM {{and support}} for an {{extended}} desktop at 1280x1040.|$|E
50|$|OpenGL and OpenGL ES, as {{implemented}} on many <b>video</b> <b>accelerator</b> {{cards and}} mobile GPUs, can support multiple common kinds of texture compression - generally {{through the use}} of vendor extensions.|$|E
30|$|The host {{interface}} {{provides the}} architecture with necessary data for video processing. It can also control <b>video</b> <b>accelerators</b> {{to operate in}} sequential or parallel mode, {{in accordance with the}} H. 264 video codec specifications. The hardware-software partitioning is simplified so that the host interface can focus on the data communication as well as flow control for video tasks, while hardware accelerators deal with local memory accesses and video codec functions. Therefore, the software abstraction layer covers the feature of data exchange and video task flow control for hardware performance.|$|R
50|$|The Linutop XS is a {{professional}} packaging of the Raspberry Pi 2 and incorporates a 1080p HD <b>video</b> Hardware <b>accelerator.</b> With this compact configuration, designed for the fields of education, transport, trade and health for the dissemination of information.|$|R
50|$|MetaCDN is a {{cloud-based}} {{content delivery network}} company that also offers video transcoding, streaming <b>video</b> and web <b>accelerator</b> services.|$|R
50|$|The Mystique and Mystique 220 are 2D, 3D, and <b>video</b> <b>accelerator</b> {{cards for}} {{personal}} computers designed by Matrox, using the VGA connector. The original Mystique {{was introduced in}} 1996, with the slightly upgraded Mystique 220 having been released in 1997.|$|E
50|$|Low-power laptops use {{low-power}} {{processors and}} graphics chips, and therefore often struggle to play video at full frame rates. It isn't desirable or practical to port a full operating system onto a VideoCore chip, so only the video decoding need be offloaded onto a <b>video</b> <b>accelerator</b> board (e.g. using the BCM70015 chip).|$|E
50|$|Avenger {{was pushed}} to the {{forefront}} as it offered a quicker time to market than the already delayed Rampage. Avenger {{was no more than}} the Banshee core with a second texture mapping unit (TMU) added - the same TMU which Banshee lost compared to Voodoo2. Avenger was thus merely a Voodoo2 with an integrated 128-bit 2D <b>video</b> <b>accelerator</b> and twice the clock speed.|$|E
30|$|As {{the main}} video {{encoding}} functions (such as ME, DCT/Q, IDCT/Q- 1, MC, Deblocking Filter, and CAVLC) {{can be accelerated}} by IP modules, the interconnection between those <b>video</b> processing <b>accelerators</b> has an important impact on the overall system performance. To make the IP accelerators execute main computational encoding routines in full parallel and pipelining mode, the IP integration architecture has to be optimized. A few of caches are inserted between the <b>video</b> IP <b>accelerators</b> to facilitate the encoding concurrent performance. The caches can be organized as parallel dual-port memory (BRAM) or pipelined memory (FIFO). The interconnection control of data streaming between IP modules will be defined using those caches targeting to eliminate the extra overhead of processing routines, for encoding functions can be operated in full parallel and pipelining stages.|$|R
5000|$|RIVA 128 (Real-time Interactive <b>Video</b> and Animation <b>accelerator)</b> {{was one of}} {{the first}} {{consumer}} graphics chips to integrate 3D and video acceleration in 1997 ...|$|R
50|$|The Microsoft Windows version {{features}} slightly cut-down graphics {{compared to}} the PlayStation version but doesn't require a 3D <b>accelerator</b> <b>video</b> card. It also features multiplayer mode over a modem line or Internet.|$|R
50|$|C series laptops were {{notable for}} their {{consistent}} and interchangeable accessories across this {{wide range of}} processors. The series {{was one of the}} first to offer the UXGA 1600x1200 resolution display and included a NVidia GeForce MX400 32 MB <b>video</b> <b>accelerator</b> to complement the display requirements. A robust design made it a favorite in harsher climates; however, this design lacked the visual appeal of many of its competitors.|$|E
50|$|Using IMA bus, Tseng {{created the}} {{category}} of mainstream motion <b>video</b> <b>accelerator</b> {{with a series of}} video image processing circuits, branded VIPeR. VIPeR chips provided relatively high quality live and computer generated video. The chips were used in on high-end video solutions from companies like Matrox and Jazz Multimedia. Competitors integrated less elegant algorithms inside their mainstream graphics controllers - a trend Tseng followed with its latter generation of chips.|$|E
5000|$|On May 19, 2014, the {{crowdfunding}} campaign concluded having raised {{just over}} 280% of its target. The extra funding allowed {{the project to}} achieve 4 [...] "stretch goals": the development of free software graphics drivers for the on-board <b>video</b> <b>accelerator</b> (etnaviv); {{the inclusion of a}} general-purpose breakout board; the inclusion of a [...] "ROMulator" [...] breakout board; and the inclusion of the MyriadRF software defined radio with the [...] "system-level" [...] offerings. The goals were achieved during May, 2014.|$|E
30|$|The {{processing}} cores {{are connected}} through the heterogeneous integrated onplatform memory spaces for {{the exchange of}} control information. The PCI/PCMCIA standard bus provides a data transfer solution for the host connected to the platform framework, reconfigures and controls the platform in a flexible way. Desirable <b>video</b> IP <b>accelerators</b> will be integrated in the system platform architecture to improve the encoding performance for H. 264 [*]BP video applications.|$|R
5000|$|The Archos 7 offers {{hard drive}} sizes of 160GB and 320GB. It has a 7" [...] WVGA 800x480 pixels {{resistive}} touch screen and built in Wi-Fi and is an update to the 705 WiFi. Its processor core is formed by an OMAP3 model from Texas Instruments that {{is based upon the}} ARM Cortex A8 running at 600 MHz with further a <b>video</b> decoding <b>accelerator.</b>|$|R
40|$|Abstract – The Cell BE {{processor}} {{is capable}} of achieving very high levels of performance via parallel computation. The processors in <b>video</b> <b>accelerators,</b> known as GPUs, are also high performance parallel processors. The RapidMind Development Platform provides a simple data-parallel model of execution that {{is easy to understand}} and learn, is usable from any ISO standard C++ program without any special extensions, maps efficiently onto the capabilities of both the Cell BE processor and GPUs, and can be extended to other multicore processors in the future. The RapidMind platform acts as an embedded programming language inside C++. It is built around a small set of types {{that can be used to}} capture and specify arbitrary computations. Arbitrary functions, including control flow, can be specified dynamically. Parallel execution is primarily invoked by applying these functions to arrays, generating new arrays. Access patterns on arrays allow data to be collected and redistributed. Collective operations, such as scatter, gather, and programmable reduction, support other standard parallel communication patterns and complete the programming model. I...|$|R
5000|$|The Mystique was a 64-bit 2D GUI and <b>video</b> <b>accelerator</b> (MGA1064SG) with 3D {{acceleration}} support. Mystique has [...] "Matrox Simple Interface" [...] (MSI) rendering API. It {{was one of}} many early products by add-in {{graphics board}} vendors that attempted to achieve good combined 2D & 3D performance for consumer-level personal computers. The board used a 64-bit SGRAM memory interface (Synchronous Graphics RAM) instead of the more expensive WRAM (Window RAM) aboard the Matrox Millennium. SGRAM offered performance approaching WRAM, but it was cheaper. Mystique came in configurations ranging from 2 MB SGRAM up to 8 MB. Mystique also had various ports on the card for memory expansion and additional hardware peripherals. The 8 MB configuration used the memory expansion module. Add-on cards from Matrox included the Rainbow Runner Video, a board offering MPEG-1 and AVI video playback with video inputs and outputs. The other add-on was called Rainbow Runner TV, an ISA-based TV tuner card for watching TV on PC.|$|E
40|$|UltraSONIC is a <b>video</b> <b>accelerator</b> board {{consists}} of several reconfigurable processing units, called PIPEs. The system with UltraSONIC plugged in the PCI slot of PC motherboard {{can be represented}} as a heterogeneous multiprocessor system {{consists of}} a single processor (software) and multiple coprocessors (hardware). Tasks represented in directed acyclic graphs (DAG) are partitioned and scheduled by using tabu search and list scheduling respectively to find the minimum processing time. This paper presents two different models of UltraSONIC system: a tightly coupled and a loosely coupled multiprocessor model, {{and the impact of}} communication time and FPGA size of processing unit on processing time of these different models...|$|E
40|$|Windows-based {{tool for}} coding and {{retrieving}} texts, sounds, graphics, and videos. The major features, strengths, {{and limitations of}} this product are described; useful tips and hints are given for maximizing AFTER’s research potential. Emphasis is placed on procedures for coding files, analytical tools available in the software, and types of coded products that may be generated. AFTER will be of greatest value to those who work primarily with multimedia interview data and who wish to use AFTER primarily as a framework within which to code data and generate excerpts, summary tables of the relative frequencies of the study variables, or SAS or SPSS data files for subsequent quantitative analysis. Until the mid- 1990 s, computer tools for qualitative data analysis (QDA) were designed {{on the assumption that}} these data are primarily texts. The tex-tual bias {{had more to do with}} the state of the art in computing technology than with the needs of field workers. Simply put, most desktops did not have the RAM, the sound cards, and the <b>video</b> <b>accelerator</b> cards essential for analyz-ing sound and graphics files. The software design decision was therefore an easy one—you designed QDA programs for handling texts. As we head into the twenty-first century, good tools for analyzing texts are now widely available, some of them even as free downloads from the Inter-net. For example, several QDA packages developed by the Center for Disease Control and Prevention can be downloaded fro...|$|E
50|$|The 2700G {{performs}} Inverse Zig-Zag, Inverse Discrete Cosine Transform, and Motion Compensation {{to speed}} up MPEG-1, MPEG-2, MPEG-4 and WMV <b>video</b> decoding. The <b>accelerator</b> can decode MPEG-1, 2 and WMV at 720×480 (DVD Resolution) and MPEG-4 at 640×480, both at over 30 frames per second.|$|R
5000|$|Released in late 1997 by Nvidia, the RIVA 128, or [...] "NV3", {{was one of}} {{the first}} {{consumer}} graphics processing units to integrate 3D acceleration in addition to traditional 2D and video acceleration. Its name is an acronym for Real-time Interactive <b>Video</b> and Animation <b>accelerator.</b>|$|R
40|$|We {{demonstrate}} {{dynamic and}} arbitrary multisite two-photon excitation {{in three dimensions}} using the holographic projection method. Rapid response (fourth dimension) is achieved through high-speed noniterative calculation of the hologram using a <b>video</b> graphics <b>accelerator</b> board. We verify that the projected asymmetric spot configurations have sufficient spatiotemporal photon density for localized two-photon excitation. This system is a significant advance and {{can be applied to}} time-resolved photolysis of caged compounds in biological cells and complex neuronal networks, nonlinear microfabrication and volume holographic optical storage. © 2009 American Institute of Physics...|$|R
40|$|This {{document}} {{has been}} prepared to help MonaLisa Parallel <b>Video</b> <b>Accelerator</b> (ML-PVA) users in program development and running. It explains only the basic concepts. Further details exist in the forms of reports, manuals, and published papers given in the Bibliography section. MonaLisa (Modelling NAturaL Images for Synthesis and Animation) is a EU supported RACE II project whose main goal {{is to develop a}} virtual reality platform by means of both hardware and software, for TV studio production and post production by mixing environment for using synthetically generated images and real images together. ML-PVA, the parallel architecture for video processing has been developed at Queen Mary and Westfield College (QMW) under MonaLisa project. This manual replaces the first version of "MonaLisa Accelerator User's Manual", written by A V Sahiner and P Lefloch. However, to support the previously developed applications, the former directory structures has been kept. Users are expected to follow this manual from now on, eventhough backward support exists. Although ML-PVA is the actual parallel machine, there are two more separate platforms, performing different tasks, to build the complete system. The first one is a standard workstation running a number of user interface programs. The second one is a PC for compiling DSP programs. They are all attached to Ethernet and they all have TCP/IP based communication support. This manual explains the systems information upto Section 6. Programming ML-PVA is the main concern of the Section 6 and 7. Thus a user having systems information and willing to exercise programming could skip the first six chapter and begin with the Section 6. For any further help concerning the use of actual machine, providing related documentation send an email to [...] ...|$|E
40|$|M. Sc. The {{domain of}} {{computer}} graphics has undergone phenomenal changes and improvements {{over the past}} decade, {{to the extent that}} photorealistic renderings have now become possible. Evidence of the vast potential of such renderings is all too clear in movies such as The Titanic. In the manufacturing arena, however, it is rarely required to produce visualisations of this quality. The rendered image is, in fact, required merely to visualise the required data set effectively and unambiguously, a requirement that can be met without reverting to the latest rendering algorithms. What is considered more important, however, is the functionality that has become available to the user. Virtual-reality-type interfaces and displays, real-time object manipulation and interactive measuring utilities are but a few functions required effectively to reduce costs during the design phase of a project. Although handy, the latter functions serves exponentially to multiply the processing requirements of the underlying hardware platform. In order, therefore, to ensure that interactiveness be maintained, some rendering techniques may have to be omitted so as to render the visualised scene unambiguously. Traditionally, visualisations required specialised graphics workstations. Although this requirement still obtains to medium- and large-scale visualisations, the PC industry has seen a dramatic increase in computing power, {{to the extent that it}} might be possible to implement small-scale visualisations at PC level soon. DirectX constitutes a set of graphics libraries developed by Microsoft as a standard for game developers and <b>video</b> <b>accelerator</b> manufacturers. Although DirectX has very rarely been implemented in a non-gaming environment, it is possible through the use of effects such as texture mapping and Gourad shading, which effects are supported by DirectX, to create a small-scale visualisation of acceptable rendering quality. If this could be achieved, companies could use their existing computers to implement visualisations of this kind. In so doing, visualisation capabilities would be made available to a much bigger segment of the market...|$|E
40|$|Abstract 5 Figures list 9 1 Introduction 11 2 Mont Blanc project 13 2. 1 DB 8500 {{multimedia}} processor 14 2. 1. 1 ARM Cortex A 9 subsystem 14 2. 1. 2 DMA support 17 2. 1. 3 Interrupt system 17 2. 1. 4 Smart imaging accelerator (SIA) 18 2. 1. 5 Smart <b>video</b> <b>accelerator</b> (SVA) 18 2. 1. 6 Smart {{graphics accelerator}} (SGA) 18 2. 1. 7 Display interfaces 18 2. 1. 8 B 2 R 2 18 2. 1. 9 Multi-Clock SBAG 19 2. 1. 9. 1 MCSBAG TMS description 20 2. 2 Design metrics 22 3 Useful tools for architecture designers 24 3. 1 SBAG driver 25 3. 1. 1 Features 25 3. 2 PCACHE driver 26 3. 3 Systat utilities 26 3. 3. 1 Sar 27 3. 3. 2 Sadf 27 3. 4 Linux kernel tracing 27 3. 4. 1 Infrastructure 27 3. 4. 2 Limits 28 3. 5 LTTng 28 3. 5. 1 Features 29 3. 5. 2 Architecture and work 29 3. 5. 3 Time 31 3. 5. 4 Trace Analysis 31 3. 6 Limits and not implemented features 32 3. 6. 1 Improving features 32 3. 6. 2 ARM porting issues 33 4 What have I done? 35 4. 1 Log_stats applications 35 4. 1. 1 Features 36 4. 1. 1. 1 Configuration 36 4. 1. 1. 2 Logging 36 4. 1. 2 Architecture 37 4. 1. 2. 1 Daemon 39 4. 1. 2. 2 Controller 42 4. 1. 2. 3 How Daemon and Controller {{communicate with each}} other 43 4. 2 wxProfiler application 44 4. 2. 1 Features 45 4. 2. 1. 1 Establish connections 45 4. 2. 1. 2 Provide an operative terminal 46 4. 2. 1. 3 Handle Log_stats Daemon work 47 4. 2. 1. 4 Handle Log_stats Controller work 48 4. 2. 1. 5 Plot data retrieved 49 4. 2. 2 Architecture 50 4. 2. 2. 1 Data structure entities 50 4. 2. 2. 2 Application on work 51 4. 3 BoardStats Android application 53 4. 3. 1 Features 55 4. 3. 2 Architecture 57 4. 4 Existing instruments modified 59 4. 4. 1 Systat patch 59 4. 4. 2 ST-Ericsson Android package 59 5 Use cases 61 5. 1 Dhrystone 62 5. 2 Gaming 62 5. 3 Internal Android applications 63 6 Conclusions 65 Glossary 67 Bibliography 6...|$|E
50|$|An IBM PC {{version of}} Twisted Metal 2 exists. It {{features}} slightly cut-down graphics {{compared to the}} PlayStation version (minor details of some levels disappeared) but it doesn't require a 3D <b>accelerator</b> <b>video</b> card and played well on computers with lower processing capabilities. It also features multiplayer over a modem line or Internet.|$|R
30|$|To {{accelerate}} the performance on processing cores, parallelization will be demanded. The parallelization {{can take place}} at different levels, such as task, data, and instruction. Furthermore, the specific video processing algorithms performed by IP accelerators or processing cores can improve the execution efficiency significantly. Therefore, the requirements for H. 264 video applications are so demanding that multiple acceleration techniques may be combined to meet the real-time conditions. The programmable, reconfigurable, heterogeneous processors are the preferable choice for an implementation of H. 264 [*]BP video encoder. Architectures with the support for concurrent performance and hardware <b>video</b> IP <b>accelerators</b> are well applicable for achieving the real-time requirement imposed by the H. 264 standard.|$|R
30|$|An {{advanced}} {{application for}} this proposed architecture is {{to facilitate the}} development of H. 264 video encoding system. As the motion estimation is the most complicated and important task in video encoder, a block-based novel adaptive motion estimation search algorithm, ACQPPS, and its hardware architecture are developed for reducing the complexity to extremely low level, while keeping the encoding performance, in terms of PSNR and bit rate, as high as possible. It is beneficial to integrate <b>video</b> IP <b>accelerators,</b> especially ACQPPS motion estimator, into the architecture framework for improving the overall encoding performance. The proposed system architecture is mapped on an integrated FPGA device, WildCard- 4, toward an implementation for a simplified H. 264 [*]BP video encoder.|$|R
