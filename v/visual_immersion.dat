31|11|Public
2500|$|Virtual reality therapy (VRT) uses {{specially}} programmed computers, <b>visual</b> <b>immersion</b> {{devices and}} artificially created environments {{to give the}} patient a simulated experience {{that can be used}} to diagnose and treat psychological conditions that cause difficulties for patients. In many environmental phobias, reaction to the perceived hazards, such as heights, speaking in public, flying, close spaces, are usually triggered by visual and auditory stimuli. In VR-based therapies, the virtual world is a means of providing artificial, controlled stimuli in the context of treatment, and with a therapist able to monitor the patient's reaction. Unlike traditional cognitive behavior therapy, VR-based treatment may involve adjusting the virtual environment, such as for example adding controlled intensity smells or adding and adjusting vibrations, and allow the clinician to determine the triggers and triggering levels for each patient's reaction. VR-based therapy systems may allow replaying virtual scenes, with or without adjustment, to habituate the patient to such environments. Therapists who apply virtual reality exposure therapy, just as those who apply in-vivo exposure therapy, can take one of two approaches concerning the intensity of exposure. The first approach is called flooding, which refers to the most intense approach where stimuli that produce the most anxiety are presented first. For soldiers who have developed PTSD from combat, this could mean first exposing them to a virtual reality scene of their fellow troops being shot or injured followed by less stressful stimuli such as only the sounds of war. On the other hand, what is referred to as graded-exposure takes a more relaxed approach in which the least distressing stimuli are introduced first. VR-exposure, as compared to in-vivo exposure has the advantage of providing the patient a vivid experience, without the associated risks or costs. VRT has great promise since it historically produces a [...] "cure" [...] about 90% of the time at about half the cost of traditional cognitive behavior therapy authority, and is especially promising as a treatment for PTSD where there are simply not enough psychologists and psychiatrists to treat all the veterans with anxiety disorders diagnosed as related to their military service.|$|E
5000|$|Shane led a team {{to develop}} the <b>Visual</b> <b>Immersion</b> System (VIS), a visual {{curriculum}} to support the communication needs of people with disabilities. The curriculum makes use of communication technology, including the iPad, which allows people with autism to engage in visual activities that aid {{in the development of}} language skills. The effectiveness of the program is currently under study, with clinical evidence [...] "still emerging," [...] but, as Shane states, [...] "the excitement and interest in these technologies exist because they are working." ...|$|E
5000|$|Kathy Moses, in {{her book}} Outsider Art of the South, {{makes the point that}} Scott’s fascination for the methods and {{iconography}} of the Old Masters is not simple repetition: “He goes beyond those stylistic and cultural antecedents to create something highly individual. Through <b>visual</b> <b>immersion</b> with Renaissance Italian examples and repeated experimentation, he determinedly taught himself the technique of oil glazing, how to compose forms on a plane, and how to balance color and contrast. He applies oil in thin glazes on canvas or wood panel to achieve the solemn serenity of the fourteenth-century Italian Giottoesque portraits and figures and the Catholic themes dealing with Christ's life and the Madonna. His depictions are aesthetically quite refined.” ...|$|E
50|$|Magnet schools offer a {{wide range}} of {{distinctive}} education programs. Some emphasize academic subjects such as math, science, technology, language <b>immersion,</b> <b>visual</b> and performing arts, or humanities. Others use specific instructional approaches, such as the Montessori method, or approaches found in international baccalaureate programs or early college programs.|$|R
40|$|This article {{describes}} a prototype immersive musical instrument that expands {{the concepts of}} traditional musical elements and allows the integration of a spatial dimension using 3 D music and sound objects into the musical environment by employing physical, <b>visual,</b> and sound <b>immersion.</b> From the prototype's evaluation results, the authors conclude that immersive musical instruments naturally give users a way to perform, compose, or improvise music (in real time) {{with a high degree}} of control...|$|R
50|$|The engine {{received}} {{a variety of}} significant upgrades, including pre-baked Global Illumination, reflection mapping, volumetric fog, dynamic weather, and dynamic foliage to name but a few examples. For Unity {{there has been a}} similar upgrade, advanced control mechanics with Physically Based Rendering (PBR) being the stand-out addition, enabling materials, objects and surfaces to look and react more realistically to lighting, shading and shadowing. Furthermore, the Global Illumination system is now more realistic with the addition of volumetric technology, physics-led objects react more realistically, and cloth behaves in a realistic manner on the protagonist, in the environment, and on other characters. The world now supports larger landmasses, more objects, bigger buildings, building interiors that can be accessed without loading screens, and many other additions that enhance <b>visual</b> fidelity, <b>immersion,</b> and the gameplay.|$|R
5000|$|After {{its initial}} release, however, [...] "Cypher" [...] was patched {{a few times}} to polish the game's text parser and {{previous}} grammatical issues. Gaming Enthusiast named Cypher [...] "one of the 30 Best Text-Adventures/Interactive-Fiction Games Over 5 Decades" [...] while Penny Arcade referred to it as [...] "a sexy, violent, neo-noir adventure told through text, clever puzzles, and beautiful art" [...] The Verge ran an article praising the game's art and <b>visual</b> <b>immersion.</b> Armaan Khan of True PC Gaming gave Cypher a positive review, stating that [...] "the story is strong enough to make these typos seem inconsequential. It’s strong enough that once I got to the end I felt satisfied because the destination was worth the difficulty of the journey. It’s strong enough that I actually played the game a second time, just so I could experience it again. Few games manage to have that effect on me." [...] IndieGames named Cypher one of the Top 10 Indie Adventures of 2012, stating that [...] "Quite shockingly and despite its flaws it actually succeeded; must have been those amazing visuals, that interesting story and the incredible selection of feelies.". IndieLove gave Cypher a positive review stating that [...] "with complementary elements that seek to only tease the brain into stronger imagination, Cypher is a game that has evolved the text adventure genre".|$|E
5000|$|Virtual reality therapy (VRT) uses {{specially}} programmed computers, <b>visual</b> <b>immersion</b> {{devices and}} artificially created environments {{to give the}} patient a simulated experience {{that can be used}} to diagnose and treat psychological conditions that cause difficulties for patients. In many environmental phobias, reaction to the perceived hazards, such as heights, speaking in public, flying, close spaces, are usually triggered by visual and auditory stimuli. In VR-based therapies, the virtual world is a means of providing artificial, controlled stimuli in the context of treatment, and with a therapist able to monitor the patient's reaction. Unlike traditional cognitive behavior therapy, VR-based treatment may involve adjusting the virtual environment, such as for example adding controlled intensity smells or adding and adjusting vibrations, and allow the clinician to determine the triggers and triggering levels for each patient's reaction. VR-based therapy systems may allow replaying virtual scenes, with or without adjustment, to habituate the patient to such environments. Therapists who apply virtual reality exposure therapy, just as those who apply in-vivo exposure therapy, can take one of two approaches concerning the intensity of exposure. The first approach is called flooding, which refers to the most intense approach where stimuli that produce the most anxiety are presented first. For soldiers who have developed PTSD from combat, this could mean first exposing them to a virtual reality scene of their fellow troops being shot or injured followed by less stressful stimuli such as only the sounds of war. On the other hand, what is referred to as graded-exposure takes a more relaxed approach in which the least distressing stimuli are introduced first. VR-exposure, as compared to in-vivo exposure has the advantage of providing the patient a vivid experience, without the associated risks or costs. VRT has great promise since it historically produces a [...] "cure" [...] about 90% of the time at about half the cost of traditional cognitive behavior therapy authority, and is especially promising as a treatment for PTSD where there are simply not enough psychologists and psychiatrists to treat all the veterans with anxiety disorders diagnosed as related to their military service.|$|E
30|$|This {{research}} team and our students have greatly benefited {{from having a}} large high-resolution visualization system that also enabled us to see in real-time Event Displays that are generated at CERN on BU’s Hiperwall. The Hiperwall visualization system has indeed created an exciting atmosphere for undergraduate {{students to participate in}} data-intensive research and has created a multi-user collaboration environment with a sense of <b>visual</b> <b>immersion.</b>|$|E
30|$|In recent years, {{there has}} been a rapid {{increase}} in the development of 3 D contents and technologies, such as 3 D movies and virtual/augmented reality [32]. As interest in the use of 3 D technology increases, researchers have paid more attention to the effect of 3 D contents on user experiences. There have been many research efforts showing that the 3 D contents can improve <b>visual</b> realism, presence, <b>immersion</b> and even performance gains on some tasks, but at the same time, increase visual fatigue as compared to 2 D contents.|$|R
40|$|Abstract. In {{this paper}} we {{introduce}} the AUDIENCE project undergoing in the CAVERNA Digital of the University of São Paulo, whose main {{purpose is to}} implement flexible and scalable multichannel spatial audio solutions for this CAVE environment, to permit navigation through a 2 D/ 3 D audiovisual scene with both <b>visual</b> and auditory <b>immersion.</b> An architecture for spatial audio production has been proposed to build auralizators, and a whole infrastructure has been designed and installed in the CAVE, so to support several speaker array setups. We present our activities towards {{the construction of an}} Ambisonics auralizator, outline some details and challenges of the implementation. We also cover recent achievements of the project and future directions of investigations. 1...|$|R
40|$|This work {{concerns}} {{the development of}} smart coating technologies based on microencapsulation for the autonomous control of corrosion. Microencapsulation allows the incorporation of corrosion inhibitors into coating which provides protection through corrosion-controlled release of these inhibitors. One critical aspect of a corrosion protective smart coating is the selection of corrosion inhibitor for encapsulation and comparison of the inhibitor function before and after encapsulation. For this purpose, a systematic approach {{is being used to}} evaluate free and encapsulated corrosion inhibitors by salt <b>immersion.</b> <b>Visual,</b> optical microscope, and Scanning Electron Microscope (with low-angle backscatter electron detector) are used to evaluate these inhibitors. It has been found that the combination of different characterization tools provide an effective method for evaluation of early stage localized corrosion and the effectiveness of corrosion inhibitors...|$|R
40|$|Advances in {{computer}} graphics have {{enabled us to}} generate more compelling 3 D virtual environments. 'Immersive experience' in these environments result {{from a combination of}} immersion and interactivity. As such, various disciplines have started adopting 3 D technology for enhancing spatial understanding and experience. But the impact of the immersive experience on spatial understanding and experience remains unclear. This study utilized a controlled, between-subjects experiment to systematically manipulate a virtual reality system's technology affordances (stereoscopy, field of view, and navigability) and measure their impact. Participants, N= 120, explored a virtual office and completed a questionnaire on the experience and tasks evaluating their understanding of the space. The results indicated that <b>visual</b> <b>immersion</b> had the greatest impact on understanding but, better experiences were gained when <b>visual</b> <b>immersion</b> was combined with greater interactivity. These findings support the notion the immersive experience is important for the comprehension of virtual spaces. This study overall served to provide insight into the role of the immersive experience on the comprehension of virtual spaces. The findings advance theories of spatial presence and immersion, support the use of methods which look at technology as affordances rather than entities, and support the use of 3 D technology for communicating spatial information {{as in the case of}} architecture and fire-fighter training...|$|E
40|$|We {{present a}} method for {{creation}} and interaction of snow in a computer game engine. This is achieved by generating a local transformable mesh around the player camera and osetting this mesh by a height map. This height map is used both for smoothing the terrain into a random snow landscape {{as well as for}} modifying the snow where prints are made. Our method compared to previous implementations has the advantage of everlasting prints {{in the vicinity of the}} player. To enhance the <b>visual</b> <b>immersion</b> we make use of lighting eects such as glitter and bloom on a highly detailed surface. The main advantages of using our method is that it is fast and that the performance loss when adding more dynamic models in the local area around the player is minimal...|$|E
40|$|Recently we {{have built}} the largest Virtual Reality (VR) theatre {{in the world for}} the Kyongju World Culture EXPO 2000. Unlike single user VR systems, the VR theatre is {{characterized}} by a single shared screen and controlled by a kind of tightly coupled user inputs from several hundreds of people in the audience. The large computer-generated stereo images by the huge cylindrical screen provide the immersive feeling augmenting the physical audience space with of 3 D virtual space. In addition to the <b>visual</b> <b>immersion,</b> the theatre provides 3 D audio, vibration and olfactory display as well as keypads for the audience in their seats interactively controlling the virtual environment. This paper introduces the issues raised and addressed during the design of making such a versatile VR theatre, production and presentation of the virtual heritage at Kyongju, one thousand years ago. 1...|$|E
40|$|Effective data {{visualization}} {{is a key}} part of the discovery process in the era of “big data”. It is the bridge between the quantitative content of the data and human intuition, and thus an essential component of the scientific path from data into knowledge and understanding. Visualization is also essential in the data mining process, directing the choice of the applicable algorithms, and in helping to identify and remove bad data from the analysis. However, a high complexity or a high dimensionality of modern data sets represents a critical obstacle. How do we visualize interesting structures and patterns that may exist in hyper-dimensional data spaces? A better understanding of how we can perceive and interact with multidimensional information poses some deep questions in the field of cognition technology and human-computer interaction. To this effect, we are exploring the use of immersive virtual reality platforms for scientific {{data visualization}}, both as software and inexpensive commodity hardware. These potentially powerful and innovative tools for multi-dimensional data visualization can also provide an easy and natural path to a collaborative data visualization and exploration, where scientists can interact with their data and their colleagues in the same <b>visual</b> space. <b>Immersion</b> provides benefits beyond the traditional “desktop” visualization tools: it leads to a demonstrably better perception of a datascape geometry, more intuitive data understanding, and a better retention of the perceived relationships in the data...|$|R
40|$|Lighting design {{plays an}} {{important}} role in interactive 3 -D training environments; it influences scene perception, scene understanding, attention, <b>visual</b> search, presence, <b>immersion,</b> and emotional involvement. Although there are several research projects that measured the impact of lighting in 3 -D environments, little research focused on the development of new lighting design models to enhance the interactive experience. Current lighting design techniques rely on static manual designs. Since interactive training environments are dynamic and unpredictable, such static designs tend to be inflexible and do not adequately support the interaction. In this paper, I will discuss examples showing problems with current lighting design approaches. In addition, I will discuss ELE, an Expressive Lighting Engine, that automatically adapts the lighting to the interaction while accommodating scenario goals, user perception, attention, immersion, and emotional involvement. I also discuss the implication and the use of ELE in interactive 3 -D training environments. 1...|$|R
40|$|Evidence {{from studies}} of provocative motion {{indicates}} that motion sickness is tightly linked to the disturbances of thermoregulation. The major aim {{of the current study}} was to determine whether provocative <b>visual</b> stimuli (<b>immersion</b> into the virtual reality simulating rides on a rollercoaster) affect skin temperature that reflects thermoregulatory cutaneous responses, and to test whether such stimuli alter cognitive functions. In 26 healthy young volunteers wearing head-mounted display (Oculus Rift), simulated rides consistently provoked vection and nausea, with {{a significant difference between the}} two versions of simulation software (Parrot Coaster and Helix). Basal finger temperature had bimodal distribution, with low-temperature group (n = 8) having values of 23 - 29 °C, and high-temperature group (n = 18) having values of 32 - 36 °C. Effects of cybersickness on finger temperature depended on the basal level of this variable: in subjects from former group it raised by 3 - 4 °C, while in most subjects from the latter group it either did not change or transiently reduced by 1. 5 - 2 °C. There was no correlation between the magnitude of changes in the finger temperature and nausea score at the end of simulated ride. Provocative visual stimulation caused prolongation of simple reaction time by 20 - 50. ms; this increase closely correlated with the subjective rating of nausea. Lastly, in subjects who experienced pronounced nausea, heart rate was elevated. We conclude that cybersickness is associated with changes in cutaneous thermoregulatory vascular tone; this further supports the idea of a tight link between motion sickness and thermoregulation. Cybersickness-induced prolongation of reaction time raises obvious concerns regarding the safety of this technology...|$|R
40|$|International audienceImmersion is the {{subjective}} impression of being {{deeply involved in}} a specific situation, and can be sensory or cognitive. In this position paper, we use a basic model of visual perception to study how ultra-high resolution wall displays can provide <b>visual</b> <b>immersion.</b> With their large size, depending on the position of viewers in front of them, wall displays can provide a surrounding and vivid environment. Users close to the wall can have their visual field filled by the wall and {{they are able to}} see clearly a large amount information with a fine resolution. However, when close to the wall, visual distortion due to large possible viewing angles, can affect the viewing of data. On the contrary, from far away, distortion is no longer an issue, but the viewers' visual field is not fully contained inside the wall, and the information details seen are less fine...|$|E
40|$|Virtual view {{synthesis}} is a {{key component}} of multi-view imaging systems that enable <b>visual</b> <b>immersion</b> environments for emerging applications, e. g., virtual reality and 360 -degree video. Using a small collection of captured reference viewpoints, this technique reconstructs any view of a remote scene of interest navigated by a user, to enhance the perceived immersion experience. We carry out a convexity characterization analysis of the virtual view reconstruction error that is caused by compression of the captured multi-view content. This error is expressed {{as a function of the}} virtual viewpoint coordinate relative to the captured reference viewpoints. We derive fundamental insights about the nature of this dependency and formulate a prediction framework that is able to accurately predict the specific dependency shape, convex or concave, for given reference views, multi-view content and compression settings. We are able to integrate our analysis into a proof-of-concept coding framework and demonstrate considerable benefits over a baseline approach...|$|E
40|$|The {{introduction}} of multimedia on pervasive and mobile communication devices raises {{a number of}} perceptual quality issues, however, limited {{work has been done}} examining the 3 -way interaction between use of equipment, quality of perception and quality of service. Our work measures levels of informational transfer (objective) and user satisfaction (subjective) when users are presented with multimedia video clips at three different frame rates, using four different display devices, simulating variation in participant mobility. Our results will show that variation in frame-rate does not impact a user’s level of information assimilation, however, does impact a users ’ perception of multimedia video ‘quality’. Additionally, increased <b>visual</b> <b>immersion</b> can be used to increase transfer of video information, but can negatively affect the users ’ perception of ‘quality’. Finally, we illustrate the significant affect of clip-content on the transfer of video, audio and textual information, placing into doubt the use of purely objective quality definitions when considering multimedia presentations...|$|E
40|$|This {{research}} studies {{the durability of}} OPC mortar, geopolymer mortar based fly ash and geopolymer mortar based palm oil fuel ash in acidic environment like peat water and netral environment like aquadest. This mortars will testing by mechanics and physical behaviour likes visual inspection and compressive strength after submerged in that water at age 7, 28, 91 and 120 days. The range of pH by peat water are 4, 0 - 4, 5. Geopolymer mortar based fly ash and geopolymer mortar based palm oil fuel ash use modulus activator (Ms) = SiO 2 /Na 2 O= 1 and %Na 2 O = 19 %. This research show that the compressive strength of geopolymer mortar based fly ash (FA) increase in peat water and aquadest immersion, whereas the compressive strength of geopolymer mortar based palm oil fuel ash (POFA) decrease because the two type of this water immersion. The compressive strength of OPC mortar increase in aquadest immersion, but decrease in peat water <b>immersion.</b> <b>Visual</b> inspection of OPC mortar and geopoymer mortar based POFA changes become brown colored in peat water immersion...|$|R
40|$|Digital {{games with}} {{adaptive}} technologies offer more tailored experiences to their players, as gameplay {{is based on}} the players' performances and behaviours in the game. This could potentially lead to better gaming experiences. Though {{it is also possible that}} just the mere expectation of clever AI could affect players' first impressions and subsequently their perceived experiences. At the present moment, there is little empirical evidence supporting this claim. This research aims to gather empirical evidence to test the hypothesis that players' expectations of an adaptive digital game have an effect on their immersion. For this, three studies were conducted. First, preferences were explored as a form of expectations that could influence immersion. The results show no effect of preferences with regards to the <b>visual</b> perspective on <b>immersion.</b> A more controlled manipulation in the form of game descriptions was then used in the subsequent experiments. Participants played a game without adaptive features while being told that the game was adapting to their performance. As a result, players who believed that the game had adaptive AI experienced higher levels of immersion than the players who were not aware of it. Similarly, when playing the game twice people felt more immersed in the session that was supposedly adapting to their behaviour, in spite of experiencing the same gameplay as in the other session. This effect was then explored in more detail in games with adaptive features. For this, two games were developed to adapt in two distinct ways to players' performance in the game. Immersion was affected differently depending on the precision of information about these adaptive features. More detailed information prompts players to change their tactics to incorporate the adaptation into their play and experience the benefits of this feature. Merely being aware of the adaptation leads to more immersion, regardless of its presence in the game. Similarly, the presence of an adaptive feature in the game leads to heightened sense of immersion, which is enhanced by the precision of information players receive about it. Evidence also suggests that this effect is durable. Overall, this research provides empirical evidence to support the hypothesis that players' expectations of adaptive features in single-player games have a positive effect on immersion. This is a valuable contribution to the theoretical understanding of immersion, while it also provides some insights into the potential precautions that should be considered when conducting experiments into player experience in the lab and `in the wild', both in academic studies and during player testing sessions run by game developers...|$|R
40|$|A {{person is}} {{immersed}} {{when they feel}} part of an environment they experience and influence. While virtual immersion systems are usually designed {{on a case by}} case basis, and are not easily reusable or scalable, our goal is to specify and develop a framework for the design and integration of immersive systems. We address the issues raised in the design and implementation of the middleware components necessary for immersion, in a generic, extensible, modular architecture for Integrated Media Systems we have developed for efficient generic concurrent processing of data streams. Design principles are illustrated on specific <b>visual</b> <b>immersion</b> components. Utilization of these components is demonstrated with a real-time immersive interactive application. frameworks for immersion. A large number of independent libraries and toolkits implementing necessary functionalities are available from research and industry. However, they emphasize specific aspects of media processing, and do not address their integration. An example of such an heterogeneous set of libraries is Microsoft’s DirectX [1]. In order to address these issues, we have introduced the generic, extensible, modular architecture for Integrated Media Systems presented in figure 1 [2]. The middleware 1...|$|E
40|$|Abstract—Dismantling {{is a major}} {{challenge}} for nuclear companies, which {{are faced with the}} clean-up of former nuclear sites. In order to increase efficiency, optimize costs and planning, intervention designers must verify scenario key points, take into account unexpected situations and provide technical answers. Simulation is a good means of visualizing and therefore understanding constraints, of testing different alternatives, and a way to train workers prior to interventions. This paper describes an application of such a technology: dismantling a chemical cell in the APM (Marcoule Pilot Workshop) facility at Marcoule (France). This highly radioactive cell will be dismantled by a remote handling system using the Maestro slave arm. An immersive room has been used to design the dismantling scenarios. For these, the Maestro slave arm has been coupled with a haptic interface and, thanks to force feedback and <b>visual</b> <b>immersion,</b> accessibility, operational trajectories and maintainability on the carrier have been verified. If problems are found, updates of the carrier design are carried out before its final construction to guarantee the system will work properly. We describe the processes of building the 3 D model and verifying scenarios. Finally, we present the first results, which are encouraging, and the perspectives for the project. Keywords-virtual reality; dismantling operation; haptic interface; accessibility study; remote handling; collision detection; interactivity; real-tim...|$|E
40|$|This paper {{describes}} {{the use of}} a large screen virtual environment to induce the perception of translational and rotational self-motion. We explore two aspects of this problem. Our first study investigates how the level of <b>visual</b> <b>immersion</b> (seeing a reference frame) affects subjective measures of vection. For visual patterns consistent with translation, self-reported subjective measures of self-motion were increased when the floor and ceiling were visible outside of the projection area. When the visual patterns indicated rotation, the strength of the subjective experience of circular vection was unaffected by whether or not the floor and ceiling were visible. We also found that circular vection induced by the large screen display was reported subjectively more compelling than translational vection. The second study we present describes a novel way in which to measure the effects of displays intended to produce a sense of vection. It is known that people unintentionally drift forward if asked to run in place while blindfolded and that adaptations involving perceived linear self-motion can change the rate of drift. We showed {{for the first time that}} there is a lateral drift following perceived rotational self-motion and we added to the empirical data associated with the drift effect for translational self-motion by exploring the condition in which the only self-motion cues are visual...|$|E
40|$|International audienceDue to obvious {{portability}} constraints, {{mobile technology}} excludes large electronic displays for <b>visual</b> <b>immersion.</b> On the contrary, sound heard over headphones is ideally suited for mobile applications. The use of stereo headphones or stereo speakers on mobile devices enables {{to take advantage}} of binaural technology which can provide an immersive sound experience for a variety of applications ranging from stereo widening of music (creating an out of the head listening experience) to full 3 -D positional audio. Advances in audio are going to help bring in richer multimedia, increase quality of mobile music and help create more interactive and immersive audio applications. Interaction with sound in 3 D audio space is no more limited to indoor environment [8]. In this paper, we report on an architecture for multimedia applications on mobile devices separating content creation (audio and graphics) from content manipulation. We have developed a markup format for interactive and spatialized audio on mobiles which can be used an interface between the sound designer and the application programmer. After presenting an overview of the key concepts in designing a format for interactive and spatialized audio and the methodology used to build the corresponding sound API, we describe its use in a mobile immersive music application for Copenhagen Channels where interactivity with the music is done through GPS waypoints...|$|E
40|$|Head mounted {{displays}} (HMD) {{are widely}} used for <b>visual</b> <b>immersion</b> in virtual reality (VR) systems. It is ac-knowledged that the narrow field of view (FOV) for most HMD models {{is the leading cause}} of insufficient quality of immersion, resulting in suboptimal user performance in various tasks in VR and early fatigue, too. Proposed solutions to this problem range from hardware-based approaches to software enhancements of the viewing pro-cess. There exist three major techniques of view expansion; minification or rendering graphics with a larger FOV than the display’s FOV, motion amplification or amplifying user head rotation aiming to provide accelerated ac-cess to peripheral vision during wide sweeping head movements, and diverging left and right virtual cameras outwards in order to increase the combined binocular FOV. Static view expansion has been reported to increase user efficiency in search and navigation tasks, however the effectiveness of dynamic view expansion is not yet well understood. When applied, view expansion techniques modify the natural viewing process and alter familiar user reflex-response loops, which may result in motion sickness and poor user performance. Thus, it is vital to evaluate dynamic view expansion techniques in terms of task effectiveness and user workload. This paper details dynamic view expansion techniques, experimental settings and findings of the user study. In the user study, we investigate three view expansion techniques, applying them dynamically based on user behaviors. We evaluate th...|$|E
40|$|Due to obvious {{portability}} constraints, {{mobile technology}} excludes large electronic displays for <b>visual</b> <b>immersion.</b> On the contrary, sound heard over headphones is ideally suited for mobile applications. The use of stereo headphones or stereo speakers on mobile devices enables {{to take advantage}} of binaural technology which can provide an immersive sound experience for a variety of applications ranging from stereo widening of music (creating an out of the head listening experience) to full 3 -D positional audio. Advances in audio are going to help bring in richer multimedia, increase quality of mobile music and help create more interactive and immersive audio applications. Interaction with sound in 3 D audio space is no more limited to indoor environment [8]. In this paper, we report on an architecture for multimedia applications on mobile devices separating content creation (audio and graphics) from content manipulation. We have developed a markup format for interactive and spatialized audio on mobiles which can be used an interface between the sound designer and the application programmer. After presenting an overview of the key concepts in designing a format for interactive and spatialized audio and the methodology used to build the corresponding sound API, we describe its use in a mobile immersive music application for Copenhagen Channels where interactivity with the music is done through GPS waypoints. 1...|$|E
40|$|Abstract — Robots have {{replaced}} humans in the collaboration of performing those dreary and hazardous tasks which humans {{prefer not to}} do so or are unable to do. The principles of mechanics, electronics and computer science are helpful in making a robot intelligent. Tele-operation of robots is the great idea to handle threatened tasks in which human operates the robot without being at the place physically. In proposed work, a remote controlled robotic system is designed to implement in dangerous and labor intensive tasks. The work is comprised of two parts mainly: Hardware part and Software part. Hardware part includes the designing of robotic module, its interfacing with controller unit and sensing modules. Software part includes the programming of controller unit to process the sensory information and GUI (Graphical User Interface) is created to provide user with robot control capability and <b>visual</b> <b>immersion.</b> Robot’s physical design is based on the three sets of parallelogram wheeled leg mechanism that are circumferentially and symmetrically spaced out 120 o apart. This robot has Temperature Sensor and Smoke Sensor to measure the temperature and gaseous concentration around it respectively. This robot is constructed to act in Bore well rescue operation. The robot will bring the target out of the hole with safety and low risk. Hence the work is intended to design a robot which can be controlled remotely by the user and can perform the task according to the user’s commands...|$|E
40|$|International audienceOver {{the past}} few years, virtual reality (VR) has transitioned {{from the realm of}} {{expensive}} research prototypes and military installations into widely available consumer devices. These devices enable experiences that are highly immersive and entertaining, and have the potential to redefine the future of computer graphics. Yet, several challenges limit the practicality and accessibility of modern virtual reality Head-Mounted Displays (HMDs), including:Performance : The high pixel counts and frame rates of increase rendering costs by up to 7 times compared to 1920 × 1080 30 Hz gaming, and next-generation HMDs could easily double or triple costs again. Visual Quality / Immersion : <b>Visual</b> <b>immersion</b> using contemporary HMDs is limited due to several factors including image resolution and field-of-view. It is also subject to discomfort and even sickness because of various sparsely-explored factors such as incorrect visual cues and system latency. Physical Design and Ergonomics : Modern HMDs tend to be unwieldy and unsuitable for hours of continuous use. Further, while room-scale VR experiences successfully permit intuitive locomotion, they are limited {{by the size of the}} physical room. This course explores the role of ongoing and future research in visual perception to solve the above challenges. Human visual perception has repeatedly been shown to be an important consideration in improving the quality of computer graphics while keeping up with its performance requirements. Thus, an understanding of visual perception and its applications in real-time VR graphics is vital for HMD designers, application developers, and content creators...|$|E
40|$|The term "robot" {{was coined}} by the Czech playright Karel Capek in 1921 in his play Rossom&#x 2032;s Universal Robots. The word "robot" {{is from the}} check word robota which means forced labor. The era of robots in surgery {{commenced}} in 1994 when the first AESOP (voice controlled camera holder) prototype robot was used clinically in 1993 and then marketed as the first surgical robot ever in 1994 by the US FDA. Since then many robot prototypes like the Endoassist (Armstrong Healthcare Ltd., High Wycombe, Buck, UK), FIPS endoarm (Karlsruhe Research Center, Karlsruhe, Germany) {{have been developed to}} add to the functions of the robot and try and increase its utility. Integrated Surgical Systems (now Intuitive Surgery, Inc.) redesigned the SRI Green Telepresence Surgery system and created the daVinci Surgical System &#x 00 AE; classified as a master-slave surgical system. It uses true 3 -D visualization and EndoWrist &#x 00 AE;. It was approved by FDA in July 2000 for general laparoscopic surgery, in November 2002 for mitral valve repair surgery. The da Vinci robot is currently being used in various fields such as urology, general surgery, gynecology, cardio-thoracic, pediatric and ENT surgery. It provides several advantages to conventional laparoscopy such as 3 D vision, motion scaling, intuitive movements, <b>visual</b> <b>immersion</b> and tremor filtration. The advent of robotics has increased the use of minimally invasive surgery among laparoscopically na&# 959;ve surgeons and expanded the repertoire of experienced surgeons to include more advanced and complex reconstructions...|$|E
40|$|The term “robot” {{was coined}} by the Czech playright Karel Capek in 1921 in his play Rossom's Universal Robots. The word “robot” {{is from the}} check word robota which means forced labor. The era of robots in surgery {{commenced}} in 1994 when the first AESOP (voice controlled camera holder) prototype robot was used clinically in 1993 and then marketed as the first surgical robot ever in 1994 by the US FDA. Since then many robot prototypes like the Endoassist (Armstrong Healthcare Ltd., High Wycombe, Buck, UK), FIPS endoarm (Karlsruhe Research Center, Karlsruhe, Germany) {{have been developed to}} add to the functions of the robot and try and increase its utility. Integrated Surgical Systems (now Intuitive Surgery, Inc.) redesigned the SRI Green Telepresence Surgery system and created the daVinci Surgical System® classified as a master-slave surgical system. It uses true 3 -D visualization and EndoWrist®. It was approved by FDA in July 2000 for general laparoscopic surgery, in November 2002 for mitral valve repair surgery. The da Vinci robot is currently being used in various fields such as urology, general surgery, gynecology, cardio-thoracic, pediatric and ENT surgery. It provides several advantages to conventional laparoscopy such as 3 D vision, motion scaling, intuitive movements, <b>visual</b> <b>immersion</b> and tremor filtration. The advent of robotics has increased the use of minimally invasive surgery among laparoscopically naïve surgeons and expanded the repertoire of experienced surgeons to include more advanced and complex reconstructions...|$|E
40|$|The work {{presented}} in this thesis documents the design, development and evaluation of a high performance stereoscopic telepresence system. Such a system offers the ability to enhance the operator perception of a remote and potentially hazardous environment {{as an aid to}} performing a remote task. To achieve this sensation of presence demands the design of a highly responsive remote camera system. A high performance stereo platform has been designed which utilises state- of-the-art cameras, servo drives and gearboxes. It possesses four degrees of freedom; pan, elevation and two camera vergence motions, all of which are controlled simultaneously in real-time by an open architecture controller. This has been developed on a PC/AT bus architecture and utilises a PID control regime. The controller can be easily interfaced to a range of input devices such as electromagnetic head tracking systems which provide the trajectory data for controlling the remote mechatronic platform. Experiments have been performed to evaluate both the mechatronic system and operator oriented performance aspects of the telepresence system. The mechatronic system investigations identify the overall system latency to be 80 ms, which is considerably less than other current systems. The operator oriented evaluation demonstrates the necessity for a head tracked telepresence system with a head mounted display system. The need for a low latency period to achieve high operator performance and comfort during certain tasks is also established. This is evident during trajectory following experiments where the operator is required to track a highly dynamic target. The telepresence system has been fully evaluated and demonstrated to enhance operator spatial perception via a sensation of <b>visual</b> <b>immersion</b> in the remote environment...|$|E
40|$|The {{title of}} this {{research}} is constructed from: `via' - route and töp(os) -a place. Viatopias are urban spaces of continual travel or flux that incorporate multiple forms of perception and inscriptions of meaning. My aim has been to define and describe the increasingly important fluid perceptual spaces that have developed between static nineteenth century destinations. Viatopias such as passageways, underground tunnels, train tracks, and the North Circular escape a sense of destination, operating as ever-changing experiences or events. The practice has sought to produce digital representations of these urban travel spaces that exist in constant flux, to communicate the experience of Viatopias. The research explores themes such as: The North Circular as a Deleuzian Route exploring driving as performance; Plica, Replica, Explica an unfolding of experience through digital media; The Making of Baroque Videos, using Baroque architectures of viewing; Mobilizing Perception treating human vision as an artifact; Mirrors For Un-Recognition disassembling nineteenth century controlled vision; Sound as an Urban Compass considering urban audio experience; Narrative Practice in New Media Space analysing contemporary approaches in digital media; and Convergent Languages, Digital Poiesis investigating the dislocation of representation in different digital languages. These conceptual frameworks developed in symbiosis with the practice. The visual practice presents a collection of digital videos that extend and complicate these concepts through experimental visual and audio techniques such as layering, repetition, anamorphic distortion, and mirroring to produce <b>visual</b> <b>immersion</b> and the fracturing of space. The concluding digital works incorporate video with audio and text resulting in integrated visual statements that attempt to stretch the viewer's perception, in the process offering a glimpse of a new experience within urban space...|$|E
40|$|This paper {{examines}} the narrative challenges in developing guide-audience interaction {{in a museum}} setting when both the exhibit space and the guide are virtual. Specifically, we have developed a prototype narrative for a human controlled pedagogical agent (an electronic puppet) to engage with live audiences in an all digital theater. The topic is ancient Egyptian temples, the role of their priests, and their significance to ancient Egyptian society. Currently, audiences at Pittsburgh’s Carnegie Museum of Natural History enjoy guided tours through a virtual ancient Egyptian temple in their all-digital partial dome theater. The temple is an archetypical model of a “House of the Gods ” from the New Kingdom to Ptolemaic period, and thematically tied to the museum’s (physical) Egypt exhibit. Work on the temple is ongoing; PublicVR (the lead organization) partners with several educational institutions to design the temple’s digital components, create ambient sound, and advise for historical accuracy. In the tour, a live educator controls virtual movement through the temple, engaging with the audience in {{a guided tour of}} the temple. The educator discusses the symbolism in the architectural elements of the temple, with secondary focus on the temple’s position in ancient Egyptian society and religious ritual. This type of <b>visual</b> <b>immersion,</b> properly used for an appropriate topic, has been shown to enhance understanding and increase retention (Jacobson, 2010). While the existing tour is effective, it is limited by the lack of activity in the virtual space. The virtual priest, in the role of an in situ tour guide, provides another layer of human connection. It offers modern audiences a chance to make associations between themselves and the ancient Egyptians. Puppets evoke emotional response in the audience, and millennia of puppeteering practice inform the strength of interactive performance in a new generation o...|$|E
