416|1542|Public
5000|$|<b>Voice</b> <b>activity</b> <b>detection,</b> {{discontinuous}} transmission, {{comfort noise}} generator ...|$|E
5000|$|TX DTX handle {{performs}} speech encoding, {{comfort noise}} computation, <b>voice</b> <b>activity</b> <b>detection</b> ...|$|E
5000|$|<b>Voice</b> <b>activity</b> <b>detection</b> (VAD, {{integrated}} with VBR) (not working from version 1.2).|$|E
40|$|<b>Voice</b> <b>Activity</b> <b>Detections</b> (VAD) {{are used}} {{all over the}} speech {{processing}} applications such as speech recognition, speech enhancement etc. In Isolated word speech recognition, the end point detection reduces the computational process. In this paper, a comparative study of three VAD algorithms and the algorithms were analyzed using performance evaluation criteria. The algorithm suitable for the dataset used in the proposed research work is found using the performance criteria like misdetection, speech quality and compression...|$|R
40|$|Detecting when {{voice is}} or is not present is an {{outstanding}} prob-lem for speech transmission, enhancement and recognition. Here we present a novel multichannel source activity detector that ex-ploits the spatial localization of the target audio source. The detector uses an array signal processing technique to maximize the signal-to-interference ratio for the target source thus decreas-ing the <b>activity</b> <b>detection</b> error rate. We compare our two-channel <b>voice</b> <b>activity</b> detector (VAD) with the AMR voice detection algo-rithms on real data recorded in a noisy car environment. The new algorithm shows improvements in error rates of 55 - 70 % compared to the state-of-the-art adaptive multi-rate algorithm AMR 2 used in present voice transmission technology. ...|$|R
3000|$|... are {{explained}} in Section 6.1, Appendix Appendix 1 : basic fullband speaker <b>activity</b> <b>detection,</b> Appendix Appendix 2 : enhanced fullband speaker <b>activity</b> <b>detection</b> based on multipath-induced fading patterns, and Appendix Appendix 3 : frequency-selective speaker <b>activity</b> <b>detection.</b>|$|R
5000|$|In speech {{processing}} applications, <b>voice</b> <b>activity</b> <b>detection</b> {{plays an important}} role since non-speech frames are often discarded.|$|E
5000|$|Acoustic Echo Cancellation (acoustic echo cancellation, noise suppression, <b>voice</b> <b>activity</b> <b>detection,</b> {{automatic}} {{compensation for}} microphone input levels; desktop only) ...|$|E
50|$|A silence {{compression}} scheme include a <b>voice</b> <b>activity</b> <b>detection</b> (VAD), a silence insertion descriptor (SID) and a comfort noise generator (CNG) module.|$|E
40|$|In {{this paper}} {{we focus on}} {{improving}} the noise preprocessor (NPP) of the low-rate speech coder MELPe using information from the non-acoustic General Electromagnetic Motion Sensor (GEMS). A generalized linear model approach is proposed to improve the <b>voice</b> <b>activity</b> estimation both in the frame-level time domain and in the bin-level frequency domain with GEMS and context features. HMM based speech recognition techniques are also investigated to drive the estimators. The improved <b>voice</b> <b>activity</b> parameter estimators are shown to have significantly less error than the estimates from MELPe NPP. The improved frame-level <b>voice</b> <b>activity</b> estimator achieves 66 % reduction in error. The improved bin-level <b>voice</b> <b>activity</b> estimates has more than 50 % error reduction. With an optimal spectral amplitude estimation algorithm instead of the MM-LSA algorithm used in MELPe NPP, and the improved <b>voice</b> <b>activity</b> parameters, the processed noisy speech has much less residue noise and higher intelligibility in informal listening tests. ...|$|R
40|$|In-house {{automatic}} <b>activity</b> <b>detection</b> {{is highly}} important toward the automatic {{evaluation of the}} resident's cognitive state. However, current <b>activity</b> <b>detection</b> systems suffer from the demand for on-site acquisition of large amounts of ground truth data for training purposes, which poses a major obstacle to their real-world applicability. In this paper, focusing on resident location trajectory-based activity recognition through limited amount of low-cost cameras, we introduce a novel scheme for automatic ground truth data generation, via simulation of resident trajectories based on formal descriptions of activities. Additionally, we present an <b>activity</b> <b>detection</b> scheme capable of learning activity patterns from such synthetic ground truth data. Experimental results show that our methodology achieves <b>activity</b> <b>detection</b> performance that is comparable to state-of-art methods, while suppressing the need for any actual ground truth recordings, thus boosting the real-world applicability of practical <b>activity</b> <b>detection</b> systems. © 2014 IEEE...|$|R
40|$|Session FP 09 - FREE PRESENTATIONS: ICF {{model in}} {{communication}} disorders: no. FP 09. 4 Summary: Children with voice problems can suffer from significant functional impacts {{in their daily}} and social <b>voice</b> <b>activities.</b> Such functional impacts can be considered at the levels of activity limitation and participation restriction according to the ICF framework. This paper discusses the issues involved in developing tools for assessing <b>voice</b> <b>activity</b> and participation in dysphonic children. Learner Outcomes: The participant {{will be able to}} discuss issues involved in developing tools for assessing <b>voice</b> <b>activity</b> and participation in dysphonic children...|$|R
5000|$|AMR {{utilizes}} Discontinuous Transmission (DTX), with <b>Voice</b> <b>Activity</b> <b>Detection</b> (VAD) and Comfort Noise Generation (CNG) {{to reduce}} bandwidth usage during silence periods ...|$|E
50|$|Zero {{crossing}} {{rates are}} used for <b>Voice</b> <b>activity</b> <b>detection</b> (VAD), i.e., finding whether human speech is present in an audio segment or not.|$|E
5000|$|<b>Voice</b> <b>Activity</b> <b>Detection</b> (VAD): When enabled, <b>voice</b> <b>activity</b> <b>detection</b> detects {{whether the}} audio being encoded is speech or silence/background noise. VAD is always implicitly {{activated}} when encoding in VBR, so the option is only useful in non-VBR operation. In this case, Speex detects non-speech periods and encodes them {{with just enough}} bits to reproduce the background noise. This is called [...] "comfort noise generation" [...] (CNG). Last version VAD was working fine is 1.1.12, since v 1.2 it has been replaced with simple Any Activity Detection.|$|E
40|$|This {{paper is}} focused on {{identification}} of pauses in noisy speech signal and following filtering of the noise from the signal. Firstly the signal processing methods are theoretically described, then <b>voice</b> <b>activity</b> detectors {{and in the end}} noise filtering methods are described. Several <b>voice</b> <b>activity</b> detectors were created and their pause detection rate was compared...|$|R
50|$|Speech <b>activity</b> <b>detection</b> {{must occur}} very quickly, {{otherwise}} clipping might occur.|$|R
40|$|In {{this thesis}} two {{approaches}} for activity modeling and suspicious <b>activity</b> <b>detection</b> are examined. First is application of factorization theorem extension for deformable models in two dierent contexts. First is human <b>activity</b> <b>detection</b> from joint position information, and second is suspicious <b>activity</b> <b>detection</b> for tarmac security. It is {{shown that the}} first basis vector from factorization theorem {{is good enough to}} dierentiate activities for human data and to distinguish suspicious activities for tarmac security data. Second approach dierentiates individual components of those activities using semantic methodol- ogy. Although currently mainly used for improving search and information retrieval, we show that ontologies are applicable to video surveillance. We evaluate the domain ontologies from Challenge Project on Video Event Taxonomy sponsored by ARDA from the perspective of general ontology design principles. We also focused on the eect of the domain on the granularity of the ontology for suspicious <b>activity</b> <b>detection...</b>|$|R
5000|$|G.711 Appendix II {{defines a}} Discontinuous Transmission (DTX) {{algorithm}} which uses <b>Voice</b> <b>Activity</b> <b>Detection</b> (VAD) and Comfort Noise Generation (CNG) to reduce bandwidth usage during silence periods ...|$|E
50|$|Comfort noise (or comfort tone) is {{synthetic}} {{background noise}} used in radio and wireless communications {{to fill the}} artificial silence in a transmission resulting from <b>voice</b> <b>activity</b> <b>detection</b> or from the audio clarity of modern digital lines.|$|E
50|$|Silence {{suppression}} {{is achieved}} by recognizing the lack of speech through a speech processing mechanism called <b>voice</b> <b>activity</b> <b>detection</b> (VAD) which dynamically monitors background noise and sets a corresponding speech detection threshold. This technique {{is also known as}} speech activity detection (SAD).|$|E
5000|$|LibVAD is a {{commercial}} multi platform VAD C library that uses various dynamic energy signals to detect <b>voice</b> <b>activity.</b>|$|R
40|$|This paper {{presents}} {{a new approach}} for designing a speaker recognition system based on mel frequency cepstral coefficients (MFCCs) and <b>voice</b> <b>activity</b> detector (VAD). VAD has been employed to suppress the background noise and distinguish between silence and <b>voice</b> <b>activity.</b> MFCCs were extracted from the detected voice sample and are compared with the database for recognition of the speaker. A new criteria for detection is proposed which gives very good performance in noisy environment...|$|R
40|$|This paper {{presents}} a new electromyography <b>activity</b> <b>detection</b> technique in which 1 -D local binary pattern histograms {{are used to}} distinguish between periods of activity and inactivity in myoelectric signals. The algorithm is tested on forearm surface myoelectric signals occurring due to hand gestures. The novel features of the presented method are that: 1) <b>activity</b> <b>detection</b> is performed across multiple channels using few parameters and {{without the need for}} majority vote mechanisms, 2) there are no per-channel thresholds to be tuned, which makes the process of <b>activity</b> <b>detection</b> easier and simpler to implement and less prone to errors, 3) {{it is not necessary to}} measure the properties of the signal during a quiescent period before using the algorithm. The algorithm is compared to other offline single- and double-threshold <b>activity</b> <b>detection</b> methods and, for the data sets tested, it is shown to have a better overall performance with greater tolerance to the noise in the real data set used...|$|R
50|$|Some other {{disturbing}} limitations {{may occur}} too. For example, if a SIP device uses <b>voice</b> <b>activity</b> <b>detection</b> (VAD) and fails to send any voice packets initially, the SBC will not learn its address {{and will not}} forward incoming media to it as well.|$|E
50|$|VAD is an {{important}} enabling technology {{for a variety of}} speech-based applications. Therefore various VAD algorithms have been developed that provide varying features and compromises between latency, sensitivity, accuracy and computational cost. Some VAD algorithms also provide further analysis, for example whether the speech is voiced, unvoiced or sustained. <b>Voice</b> <b>activity</b> <b>detection</b> is usually language independent.|$|E
50|$|Robots may {{interpret}} strayed {{noise as}} speech instructions. Current <b>voice</b> <b>activity</b> <b>detection</b> (VAD) system uses the complex spectrum circle centroid (CSCC) method {{and a maximum}} signal-to-noise ratio (SNR) beamformer. Because humans usually look at their partners when conducting conversations, the VAD system with two microphones enable the robot to locate the instructional speech by comparing the signal strengths of the two microphones. Current system is {{able to cope with}} background noise generated by televisions and sounding devices that come from the sides.|$|E
30|$|Since EGG {{signal is}} only {{informative}} during voiced speech segments, the <b>voice</b> <b>activity</b> detector {{is replaced by}} a glottal activity detector.|$|R
50|$|Speech <b>activity</b> <b>detection</b> {{does not}} work well on non-speech calls (fax or modem communication, for example).|$|R
40|$|This paper {{compares the}} {{performance}} of the recently de-veloped multi-decision sub-band <b>voice</b> <b>activity</b> detector (MDSVAD) [1], with the ITU G. 729 B <b>voice</b> <b>activity</b> detector (VAD) scheme [2] and the SNRVAD scheme [3] for a speech enhancement application. The study shows the importance of more detailed VAD decisions in the time-frequency plane to better maintain speech features. This is in keeping with the observation that typically a speech signal will not simul-taneously excite all frequency components at any one time instant. Here, the MDSVAD exploits the spectral structure of speech versus background noise to make independent <b>voice</b> <b>activity</b> decisions in separate subbands, resulting in multiple decisions for any frame. Results show that the decisions in separate sub-bands reduce the infamous musical tones sig-nificantly in the conventional spectral subtraction algorithm compared to the other two VADs. 1...|$|R
50|$|<b>Voice</b> <b>{{activity}}</b> <b>detection</b> (VAD), {{also known}} as speech activity detection or speech detection, is a technique used in speech processing in which {{the presence or absence}} of human speech is detected. The main uses of VAD are in speech coding and speech recognition. It can facilitate speech processing, and can also be used to deactivate some processes during non-speech section of an audio session: it can avoid unnecessary coding/transmission of silence packets in Voice over Internet Protocol applications, saving on computation and on network bandwidth.|$|E
50|$|The {{algorithm}} includes <b>voice</b> <b>activity</b> <b>detection</b> (VAD) {{followed by}} an elaborate frame classification scheme. Silence/background noise and stationary unvoiced frames are represented by spectrum-modulated noise and coded at 1/4 or 1/8 rate. The SMV uses 4 subframes for full rate and two/three subframes for half rate. The stochastic (fixed) codebook structure is also elaborate and uses sub-codebooks each tuned for {{a particular type of}} speech. The sub-codebooks have different degrees of pulse sparseness (more sparse for noise like excitation). SMV scores a high of 3.6 MOS at full rate with clean speech.|$|E
50|$|Some modern {{telephone}} systems (such as wireless and VoIP) use <b>voice</b> <b>activity</b> <b>detection</b> (VAD), {{a form of}} squelching where low volume {{levels are}} ignored by the transmitting device. In digital audio transmissions, this saves bandwidth of the communications channel by transmitting nothing when the source volume is under a certain threshold, leaving only louder sounds (such as the speaker's voice) to be sent. However, improvements in background noise reduction technologies can occasionally result in the complete removal of all noise. Although maximizing call quality is of primary importance, exhaustive removal of noise may not properly simulate the typical behavior of terminals on the PSTN system.|$|E
40|$|The {{uncertainties}} {{associated with}} airborne gamma spectrometry (AGS) measurements analysed using a spectral windows method, and associated detection limits, have been investigated. For individual short measurements over buried 137 Cs <b>activity</b> <b>detection</b> limits of are achieved. These detection limits are reduced for superficial activity and longer integration times. For superficial <b>activity,</b> <b>detection</b> limits below are achievable. A comparison {{is made with}} the detection limits for other data processing methods...|$|R
40|$|We {{describe}} {{the development of}} a speech <b>activity</b> <b>detection</b> system using an HMM-based segmenter for automatic speech recognition on individual headset microphones in multispeaker meetings. We look at cross-channel features (energy and correlation based) to incorporate into the segmenter for the purpose of addressing errors related to cross-channel phenomena such as crosstalk. Results demonstrate that these features provide a marked improvement (18 % relative) over a baseline system using single-channel features as well as an improvement (8 % relative) over our previous solution of separate speech <b>activity</b> <b>detection</b> and cross-channel analysis. In addition, the simple cross-channel energy features are shown to be more robust—and consequently better performing— than the more common correlation-based features. Index Terms: speech <b>activity</b> <b>detection,</b> multi-channel audio, crosstalk...|$|R
40|$|Abstract — This paper {{presents}} {{a new approach}} for designing a speaker recognition system based on mel frequency cepstral coefficients (MFCCs) and <b>voice</b> <b>activity</b> detector (VAD). VAD has been employed to suppress the background noise and distinguish between silence and <b>voice</b> <b>activity.</b> MFCCs were ext racted from the detected voice sample and are compared with the database for recognition of the speaker. A new criteria for detection is proposed which gives very good performance in noisy environment. Index Terms — Mel frequency cepstral coefficients...|$|R
