106|547|Public
50|$|Revocation {{improvements}} include native {{support for}} the Online Certificate Status Protocol (OCSP) providing real-time certificate <b>validity</b> <b>checking,</b> CRL prefetching and CAPI2 Diagnostics. Certificate enrollment is wizard-based, allows users to input data during enrollment and provides clear information on failed enrollments and expired certificates. CertEnroll, a new COM-based enrollment API replaces the XEnroll library for flexible programmability. Credential roaming capabilities replicate Active Directory key pairs, certificates and credentials stored in Stored user names and passwords within the network.|$|E
5000|$|A {{few million}} reed relays were used from the 1930s to the 1960s for memory {{functions}} in Bell System electromechanical telephone exchanges. Often a multiple-reed relay was used, {{with one of}} the reeds latching the relay, and the other or others performing logic or memory functions. Most reed relays in the crossbar switching systems of the 1940s through the 1970s were packaged in groups of five. Such a [...] "reed pack" [...] was able to store one decimal digit, encoded in a two-out-of-five code (74210 variant) for easy <b>validity</b> <b>checking</b> by wire spring relay logic.|$|E
40|$|Abstract. We {{show that}} one can recover the PIN from a {{standardised}} RSA-based PIN encryption algorithm from {{a small number of}} queries to a ciphertext <b>validity</b> <b>checking</b> oracle. The <b>validity</b> <b>checking</b> oracle required is rather special and we discuss whether such oracles could be obtained in the real world. Our method works using a minor extension to the ideas of Bleichenbacher and Manger, in particular we obtain information from negative, as well as positive, responses from the <b>validity</b> <b>checking</b> oracle. ...|$|E
30|$|Simple face <b>validity</b> <b>checks</b> will be {{used for}} the {{innovation}} model.|$|R
50|$|<b>Validity</b> <b>checks</b> - {{controls}} that ensure only valid data is input or processed.|$|R
3000|$|... {{describe}} regular packet processing in {{the absence}} of packet loss. If the key-chain <b>validity</b> <b>check</b> in step [...]...|$|R
40|$|Abstract. Duration Calculus (DC) is a {{real-time}} logic with {{measurement of}} duration of propositions in observation intervals. It {{is a highly}} expressive logic with continuous time behaviours (also called signals) as its models. <b>Validity</b> <b>checking</b> of DC is undecidable. We propose a method for <b>validity</b> <b>checking</b> of Duration Calculus by reduction to a sampled time version of this logic called well sampled Interval Duration Logic (WSIDL). This reduction relies on representing a continuous time behaviour by a well-sampled behaviour with 1 -oversampling. We provide weak and strong reductions (abstractions) of logic DC to logic WSIDL which respectively preserve the validity and the counter examples. By combining these reductions with previous work on deciding IDL, we implement a tool for <b>validity</b> <b>checking</b> of Duration Calculus. This provides a partial but practical method for <b>validity</b> <b>checking</b> of Duration Calculus. We present some preliminary experimental results to measure {{the success of this}} approach. ...|$|E
40|$|Abstract In this paper, we {{introduce}} a new <b>validity</b> <b>checking</b> problem over linear arithmetic constraints and present a decision procedure for the problem. Instead of considering the validity of any particular linear arithmetic constraint, we consider the following problem: Given a finite automaton accepting linear arithmetic constraints, does the automaton produce any constraint that is a tautology? This problem arises {{in the context of}} static verification of meta-programs, i. e., programs dynamically generating other programs. This paper gives the first decision procedure to perform <b>validity</b> <b>checking</b> of finite automata over linear arithmetic constraints. Our algorithm will enable advanced verification of meta-programs. ...|$|E
40|$|This survey covers basic {{information}} about public key infrastructures and summarizes the predominant technology and standards. Special attention {{is given to}} mechanisms for certificate revocation. Methods for CRL distribution and <b>validity</b> <b>checking</b> are compared. 1 Supported by KDD R&D Laboratories, Inc...|$|E
40|$|Bid {{opening in}} {{e-auction}} is e#cient when a homomorphic secret sharing function is employed {{to seal the}} bids and homomorphic secret reconstruction is employed to open the bids. However, this high e#ciency {{is based on an}} assumption: the bids are valid (e. g. within a special range). An undetected invalid bid can compromise correctness and fairness of the auction. Unfortunately, validity verification of the bids is ignored in the auction schemes employing homomorphic secret sharing (called homomorphic auction in this paper). In this paper, an attack against the homomorphic auction in the absence of bid <b>validity</b> <b>check</b> is presented and a necessary bid <b>validity</b> <b>check</b> mechanism is proposed. Then a batch cryptographic technique is introduced and applied to improve the e#ciency of bid <b>validity</b> <b>check...</b>|$|R
30|$|Conduct three <b>validity</b> <b>checks</b> {{to ensure}} {{reasonable}} RT thresholds. (The following two steps are {{performed with the}} validated RT thresholds).|$|R
3000|$|As a first <b>validity</b> <b>check,</b> a null model {{without any}} {{mechanism}} in the utility functions is run, that is, ∀k:β [...]...|$|R
30|$|Software {{code for}} the data fusion methods is {{presented}} in Additional file 1 : Annex A and software code for implementing the validity checks is given in Additional file 1 : Annex B for the hot deck matching method only. <b>Validity</b> <b>checking</b> for the other methods would be implemented in the same way.|$|E
40|$|QDDC is a logic for specifying {{quantitative}} timing {{properties of}} reactive systems. An automata theoretic decision procedure for QDDC reduces each formula to a finite state automaton accepting precisely {{the models of}} the formula. This construction has been implemented into a validity/model checking tool for QDDC called DCVALID. Unfortunately, {{the size of the}} final automaton as well as the intermediate automata which are encountered in the construction can some times be prohibitively large. In this paper, we present some validity preserving transformations to QDDC formulae which result into more efficient construction of the formula automaton and hence reduce the <b>validity</b> <b>checking</b> time. The transformations can be computed in linear time. We provide a theoretical as well as an experimental analysis of the improvements in the formula automaton size and <b>validity</b> <b>checking</b> time due to our transformations...|$|E
40|$|Attribute-based {{encryption}} (ABE) is {{a popular}} cryptographic technology to protect the security of users’ data in cloud computing. In order to reduce its decryption cost, outsourcing the decryption of ciphertexts is an available method, which enables users to outsource {{a large number of}} decryption operations to the cloud service provider. To guarantee the correctness of transformed ciphertexts computed by the cloud server via the outsourced decryption, it is necessary to check the correctness of the outsourced decryption to ensure security for the data of users. Recently, Li et al. proposed a full verifiability of the outsourced decryption of ABE scheme (ABE-VOD) for the authorized users and unauthorized users, which can simultaneously check the correctness of the transformed ciphertext for both them. However, in this paper we show that their ABE-VOD scheme cannot obtain the results which they had shown, such as finding out all invalid ciphertexts, and checking the correctness of the transformed ciphertext for the authorized user via checking it for the unauthorized user. We first construct some invalid ciphertexts which can pass the <b>validity</b> <b>checking</b> in the decryption algorithm. That means their “verify-then-decrypt” skill is unavailable. Next, we show that the method to check the validity of the outsourced decryption for the authorized users via checking it for the unauthorized users is not always correct. That is to say, there exist some invalid ciphertexts which can pass the <b>validity</b> <b>checking</b> for the unauthorized user, but cannot pass the <b>validity</b> <b>checking</b> for the authorized user...|$|E
5000|$|Widespread use of {{electronic}} handheld devices (PDAs and smartphones) and software designed by LAPOP to allow multilingual interviews and extensive <b>validity</b> <b>checks</b> ...|$|R
50|$|It is {{necessary}} that data streams {{be subject to}} accurate <b>validity</b> <b>checks</b> {{before they can be}} considered as being correct or trustworthy. Such checks are of a temporal, formal, logic and forecasting kind.|$|R
5000|$|It will {{be shown}} that the field {{equations}} are a generalization of Poisson's classical field equation. The reduction to the classical limit, besides being a <b>validity</b> <b>check</b> on the field equations, gives as a byproduct {{the value of the}} constant [...]|$|R
40|$|The {{problem of}} {{checking}} or optimally simplifying bisimulation formulas {{is likely to}} be computationally very hard. We take a different view at the problem: we set out to define a very fast algorithm, and then see what we can obtain. Sometimes our algorithm can simplify a formula perfectly, sometimes it cannot. However, the algorithm is extremely fast and can, therefore, be added to formula-based bisimulation model checkers at practically no cost. When the formula can be simplified by our algorithm, this can have a dramatic positive effect on the better, but also more time consuming, theorem provers which will finish the job. 1 Introduction The need for <b>validity</b> <b>checking</b> or optimal simplification of first order bisimulation formulas has arisen from recent work on symbolic bisimulation checking of value-passing calculi [4, 9, 15]. The NP-completeness of checking satisfiability of propositional formulas [3] implies that <b>validity</b> <b>checking</b> of that class of formulas is co-NP complete. Addit [...] ...|$|E
40|$|Abstract. UCLID is a {{tool for}} term-level {{modeling}} and verication of in nite-state systems expressible in the logic of counter arithmetic with lambda expressions and uninterpreted functions (CLU). In this paper, we describe {{a key component of}} the tool, the decision procedure for CLU. Apart from <b>validity</b> <b>checking,</b> the decision procedure also provides other useful features such as concrete counterexample generation and proof-core generation. ...|$|E
40|$|Model {{checking}} is {{an automatic}} technique for the verification of temporal properties of a system. In this technique, {{a system is}} represented as a labelled graph and the specification as a temporal logic formula. The core of temporal logic model checking is the reachability problem, which is not expressible in first-order logic (FOL); as a result, model checking of finite/infinite state systems {{without the use of}} iteration or abstraction is considered beyond the realm of automated FOL theorem provers. In this thesis, we focus on formulating the temporal logic model checking problem as a FOL theorem proving problem and use automated tools, such as SAT/SMT solvers to directly model check a system without the need for a fixed-point calculation or abstraction. We present CTL-Live: a fragment of computational tree logic whose model checking for (infinite) Kripke structures is reducible to FOL <b>validity</b> <b>checking.</b> CTL-Live includes the CTL connectives that are often used to express liveness properties. We also derive decidability results about CTL-Live model checking by examining decidable subsets of FOL. We evaluate our reduction technique for CTL-Live model checking. Our case studies show that state-of-the-art SMT solvers are capable of verifying CTL-Live properties of infinite systems; moreover, the verification of an infinite state model can sometimes complete more quickly than verifying a finite version of the model. We prove the maximality of CTL-Live: we show that CTL-Live is the largest fragment of CTL whose model checking is reducible to FOL <b>validity</b> <b>checking.</b> The maximality of CTL-Live implies that model checking safety properties requires a logic more expressive than FOL; as a result, we examine FOL plus transitive closure (FOLTC). We can reduce model checking of a more expressive fragment of CTL, which we call CTL, to <b>validity</b> <b>checking</b> in FOLTC. CTL is more expressive than CTL-Live and yet less expressive than CTL. By adding a finiteness restriction, we can reduce model checking of all of CTL with fairness constraints (CTLFC) formulas to <b>validity</b> <b>checking</b> in FOLTC. The finiteness restriction requires that the system under-study must have a finite number of states, but it does not require this number to be known. Reduction of CTLFC to FOLTC allows us to use the Alloy Analyzer for model checking. Our case studies show that the Alloy Analyzer can analyze CTLFC formulas up to the same scopes that Alloy models are analyzed...|$|E
30|$|Problematic handwritings {{are no more}} {{applicable}} in EHR systems, {{the data}} collected via these systems are not mainly gathered for analytical purposes and contain many issues—missing data, incorrectness, miscoding—due to clinicians’ workloads, not user friendly user interfaces, and no <b>validity</b> <b>checks</b> by humans [66].|$|R
50|$|The keys to {{the success}} of pcc were its {{portability}} and improved diagnostic capabilities. The compiler was designed so that only a few of its source files were machine-dependent. It was relatively robust to syntax errors and performed more thorough <b>validity</b> <b>checks</b> than its contemporaries.|$|R
40|$|The paper {{describes}} a {{development of a}} mathematical model for a lay-on instrument capacitor that takes into account an actual electrode thickness. <b>Validity</b> <b>check</b> of the mathematical model has been carried out in the paper. The paper contains quantitative evaluations and recommendations on design optimization of the lay-on instrument capacitor. </p...|$|R
40|$|Abstract. This paper {{gives an}} account of St˚almarck’s method for <b>validity</b> <b>checking</b> of propositional-logic formulas, and {{explains}} each of the key components in terms of concepts from thefield of abstract interpretation. We then use these insights to present a framework for propositional-logic validity-checking algorithms that is parametrized by an abstract domain and operations on that domain. St˚almarck’s method is one instantiation of the framework; other instantiations lead to new decision procedures for propositional logic. ...|$|E
40|$|The STL {{de facto}} data {{exchange}} standard for Solid Freeform Fabrication represents CAD models {{as a collection}} of unordered triangular planar facets. No topological connectivity information is provided; hence the term Òbucket of facets. Ó Such topological information can, however, be quite useful for performing model <b>validity</b> <b>checking</b> and speeding subsequent processing operations such as model slicing. This paper discusses model topology and how to derive it given a collection of unordered triangular facets which represent a valid model. ...|$|E
40|$|The {{property}} of Positive Equality [2] dramatically speeds up <b>validity</b> <b>checking</b> of formulas in {{the logic of}} Equality with Uninterpreted Functions and Memories (EUFM) [4]. The logic expresses correctness of high-level microprocessors. We present EVC (Equality Validity Checker) —a tool that exploits Positive Equality and other optimizations when translating a formula in EUFM to a propositional formula, which can then be evaluated by any Boolean satisfiability (SAT) procedure. EVC {{has been used for}} the automatic formal verification of pipeli ned,superscalar, and VLIW microprocessors...|$|E
50|$|UOWHFs {{are thought}} to be less {{computationally}} expensive than CRHFs, and are most often used for efficiency purposes in schemes where the choice of the hash function happens at some stage of execution, rather than beforehand. For instance, the Cramer-Shoup cryptosystem uses a UOWHF as part of the <b>validity</b> <b>check</b> in its ciphertexts.|$|R
40|$|The {{popularity}} of online research is increasing but {{the validity of}} the results obtained is not yet clear. The {{purpose of this study was}} to examine the factors that influence the validity of computerized data collection in an undergraduate sample. Participants were 99 university students randomly assigned to one of three data collection conditions: online survey platform, in-person computerized survey platform, and in-person pencil-and-paper survey. Results from statistical analyses suggest self-reported inattention symptoms, exposure to more stressors, and computerized platforms predict more invalid responding. In contrast, personality, self-reported impulsivity symptoms, and shorter completion times do not predict invalid responding. Overall, more than half of the participants failed at least one <b>validity</b> <b>check</b> and 11 % failed three or more <b>validity</b> <b>checks.</b> Researchers, particularly those working with undergraduate samples, should consider implementing procedures to ensure the data collected are valid...|$|R
3000|$|... [...]. As the {{differential}} equations themselves are unchanged {{from the above}} well-known problem, the validity of our study lies {{in the implementation of}} boundary conditions (32) to (35). In the next section, we compare our results to those of Dunham and Ogden (2012) for a <b>validity</b> <b>check,</b> although their study adopted a long-wave approximation.|$|R
40|$|A {{great deal}} of {{attention}} has recently been given to Artificial Intelligence {{research in the area of}} computer aided diagnostics. Due to the dynamic and complex nature of space shuttle red-line parameters, a research effort is under way to develop a real time diagnostic tool that will employ historical and engineering rulebases as well as a sensor <b>validity</b> <b>checking.</b> The capability of AI software development tools (KEE and G 2) will be explored by applying object oriented programming techniques in accomplishing the diagnostic evaluation...|$|E
40|$|Abstract. The {{property}} of Positive Equality [2] dramatically speeds up <b>validity</b> <b>checking</b> of formulas in {{the logic of}} Equality with Uninterpreted Functions and Memories (EUFM) [4]. The logic expresses correctness of high-level microproces-sors. We present EVC (Equality Validity Checker) —a tool that exploits Positive Equality and other optimizations when translating a formula in EUFM to a proposi-tional formula, which can then be evaluated by any Boolean satisfiability (SAT) procedure. EVC {{has been used for}} the automatic formal verification of pipelined, superscalar, and VLIW microprocessors. ...|$|E
40|$|Background: Depression was {{translated}} into Chinese as yiyu, {{with reference to the}} yu syndrome in traditional Chinese medicine. Literally meaning 'not flowing, entangled or clogged', yu, or 'stagnation' in English, is, however, a construct distinct from depression. Objective: The study aimed to explore the construct of stagnation through scale development. Method: A concept-driven approach was adopted to generate candidate items for the Stagnation Scale. Other measures were a <b>validity</b> <b>checking</b> item, a Beck Depression Inventory (BDI) and a twelve-item General Health Questionnaire (GHQ- 12). Respondents were recruited by convenience and snowball sampling, resulting in 602 questionnaires being completed by adults between the ages of eighteen and sixty-five. Results: Exploratory factor analysis provided a three-factor, sixteen-item solution. The three factors were named Overattachment, Body-Mind Obstruction and Affect-Posture Inhibition. Cronbach's alphas of the entire scale and subscales ranged from 0. 82 to 0. 91. Correlations of the scale total with the <b>validity</b> <b>checking</b> item, BDI and GHQ- 12 were 0. 71, 0. 53 and 0. 48, respectively. Stagnation showed a pattern of associations with demographic variables different from depression. Conclusion: The Stagnation Scale has good psychometric properties, and has meaningful factor structures. The evidence supports the contention that stagnation is a clinical syndrome distinct from depression. The new concept has important implications for social work practice. link_to_subscribed_fulltex...|$|E
5000|$|Content {{validation}} (also called face <b>validity)</b> <b>checks</b> {{how well}} {{the content of the}} research are related to the variables to be studied; it seeks to answer whether the research questions are representative of the variables being researched. It is a demonstration that the items of a test are drawn from the domain being measured.|$|R
40|$|ATLAS reconstructs primary {{vertices}} {{with high}} efficiency and resolution. These vertices serve as input to other mission critical analysis tools, and are relied on by many physics analyses. This presentation surveys the ATLAS primary vertex reconstruction algorithms, and describes <b>validity</b> <b>checks</b> done using real data. The complications introduced by pileup are discussed, along with refinements currently under study...|$|R
3000|$|The loop {{that starts}} at line three {{contains}} another loop over dom(C) ∪{NULL} (starting at line 7), where | dom(C)| ∝ N. Within this second loop, when ϕ _k is a variable CFD, the algorithm does a <b>validity</b> <b>check</b> that requires {{as many as}} N times string comparisons. Thus, the computational cost of IncRepair is O(N^ 3).|$|R
