134|452|Public
2500|$|The {{revenues}} from Travelcard sales are divided {{according to a}} scheme agreed by Transport for London and the Association of Train Operating Companies. A quarterly survey known as the Travelcard Diary Survey is undertaken, where travelcard holders are asked to record all the bus, rail and tube trips they have made using their travelcard. [...] Both [...] "in-boundary" [...] and [...] "out-boundary" [...] (i.e. Travelcards in or outside of the zonal areas) are surveyed, as well as day and monthly, weekly and annual Travelcards. Ensuring that a statistically <b>valid</b> <b>sample</b> that will give a fair and accurate allocation presents a challenge. [...] The average mileage recorded on each mode is then calculated to give allocation factors of the Travelcard revenue to tube, bus and rail.|$|E
50|$|During {{the period}} 2001 to 2007, Barrett experimented using the Cultural Transformation Tools {{to map the}} values of nations. Between 2007 and 2010, these tools were used to map the {{personal}} values, current culture values, and the desired cultural values of a statistically <b>valid</b> <b>sample</b> 12 nations and several communities. In many of these nations, {{the results of the}} values assessments have been used to begin nationwide dialogues on values. In Latvia and Iceland, the results of the values assessments have been instrumental in reorienting public policies.|$|E
50|$|In {{internet}} marketing, multivariate {{testing is}} a process by which more than one component of a website may be tested in a live environment. It {{can be thought of}} in simple terms as numerous A/B tests performed on one page at the same time. A/B tests are usually performed to determine the better of two content variations; multivariate testing uses multiple variables to find the ideal combination. The only limits on the number of combinations and the number of variables in a multivariate test are the amount of time it will take to get a statistically <b>valid</b> <b>sample</b> of visitors and computational power.|$|E
30|$|For the six {{industry}} characteristics, banks, insurance companies, bills finance corporations, security firms, {{trust business}} companies and investment companies, respectively, {{the numbers of}} population were 73, 51, 136, 13, 3 and 18; and the numbers of the returned <b>valid</b> <b>samples</b> were 23 (31.5  %), 13 (25.5  %), 25 (18.4  %), 4 (30.8  %), 3 (100.0  %) and 9 (50.0  %). This study further adopted Chi square test to examine the representativeness of the samples. The test p value was > 0.05 at 0.106, indicating that no significant differences existed between these two groups (population and the returned <b>valid</b> <b>samples),</b> and existed sufficient sample sizes to achieve adequate representation.|$|R
30|$|Analyses were {{conducted}} based on 1017 <b>valid</b> <b>samples,</b> with {{a response rate}} of 63.6 %. Social-demographic characteristics of the survey participants, weather information acquisition pattern, and the public health significance of smart weather information acquisition during the cold weather were analyzed and interpreted.|$|R
40|$|Bandpass {{sampling}} is {{a useful}} alternative for direct digital downconversion in software radio. It significantly relaxes the analog-to-digital converter (ADC) sampling rate requirement and facilitates the design goal of moving the ADC {{as close as possible}} to the antenna. This paper presents a modified interpretation to the graph of allowable sampling frequencies in uniform bandpass sampling. It is shown that the position and guard bands of a downconverted bandpass signal band are highly related to the order of the <b>valid</b> <b>sampling</b> range, called wedge order. An efficient algorithm is then proposed, which significantly reduces the computational load in determining the <b>valid</b> <b>sampling</b> frequencies to downconvert multiple distinct bandpass signals. Conditions for the placement of bandpass signals to utilize a given sampled bandwidth are also discussed. published_or_final_versio...|$|R
5000|$|The {{revenues}} from Travelcard sales are divided {{according to a}} scheme agreed by Transport for London and the Association of Train Operating Companies. A quarterly survey known as the Travelcard Diary Survey is undertaken, where travelcard holders are asked to record all the bus, rail and tube trips they have made using their travelcard. Both [...] "in-boundary" [...] and [...] "out-boundary" [...] (i.e. Travelcards in or outside of the zonal areas) are surveyed, as well as day and monthly, weekly and annual Travelcards. Ensuring that a statistically <b>valid</b> <b>sample</b> that will give a fair and accurate allocation presents a challenge. The average mileage recorded on each mode is then calculated to give allocation factors of the Travelcard revenue to tube, bus and rail.|$|E
5000|$|Statistically valid {{measurements}} require {{even and}} representative samples. Biases due tosampling must be minimized, to ensure validity in PES's audit and merit assessment functions.At the same time, sample size must be minimized for cost reasons. Striking {{a balance between}} astatistically <b>valid</b> <b>sample</b> and minimum surveyor cost is not simple. Historical data analysessuggest PES scores are correlated with time-of-day, location, and service route, even thoughindicators themselves are independent. PES scores are also subject to clustering effects: datacollected sequentially {{on the same day}} may be adversely affected by common factors such as aschool condition, weather conditions, or special events. A pure random sample is an inefficientmethod of collecting such data, but observations made sequentially cannot be treated asindependent observations.Generally, a good statistical sample should fulfill three criteria: ...|$|E
30|$|Of the 217 households, 47 % (n =  102) {{participated in}} the {{intervention}} training sessions and completed the pre- and post-intervention questionnaires in 2014. The final <b>valid</b> <b>sample</b> size in 2014 was 100.|$|E
5000|$|The EF English Proficiency Index {{has been}} criticized for its lack of {{representative}} sampling in each country. [...] The report states that participants in the tests are self-selected and must have access to the internet. It is an online survey rather than a statistically <b>valid</b> <b>sampling</b> of the population.|$|R
30|$|The rest of {{the paper}} is {{structured}} as follows. The motivation for this work is discussed in Section 2. In Section 3, we derive Monte Carlo localization methods based on differential evolution optimization (MCL-DE) for <b>valid</b> <b>samples</b> in mobile wireless sensor networks. In Section 4, a comparative performance evaluation is carried out. Finally, concluding remarks and future work are given in Section 5.|$|R
40|$|Although not as {{efficient}} as simple random sampling, cluster sampling has been regarded as a <b>valid</b> <b>sampling</b> technique when the researcher is attempting to save cost. In order to do so, {{it is necessary that}} random selection occurs in all stages of sampling. This simulation study examines purposeful selection of cluster sampling in the second stage of a two stage cluster design...|$|R
30|$|In {{order to}} explore the {{changing}} divorce pattern over different historical periods, the total <b>valid</b> <b>sample</b> is split into four marriage cohorts for analysis: before 1980, 1980 – 1989, 1990 – 1999, and after 2000. The rationale for grouping is mainly based on the transitional stages of the Chinese economic structure (Qiu & Liu 2013).|$|E
30|$|In phase I a {{questionnaire}} {{was designed to}} measure the entrepreneurial intensity. Phase II included the validation of questionnaire from phase I by applying it on students pursuing professional education. Initially a sample size of 1500 students was planned (who are pursuing full time professional education in Delhi National Capital Region of India). A <b>valid</b> <b>sample</b> of 1255 was achieved with the response rate of 83.6  %.|$|E
40|$|Abstract—We have {{proposed}} a novel method for Synthetic High Range Resolution (HRR) profiling, under the condition of missing frequency domain samples. This new approach estimates the autocovariance function (ACF) of the signal by <b>valid</b> <b>sample</b> pairs. Autocovariance matrix is formed from ACF estimations. Even with large part of data missing, new approach exhibits robust profiling result. Simulations are presented to show a advantage over other approaches in missing data case. Moreover, a real radar experiment was conducted to validate the new approach. Index Terms—Missing Data, Sampled Covariance, HRR I...|$|E
50|$|The bill {{directed}} the Inspector General of each federal agency to: (1) review a statistically <b>valid</b> <b>sampling</b> {{of the spending}} data submitted under this Act by the federal agency; and (2) submit to Congress and make publicly available a report assessing the completeness, timeliness, quality, and accuracy of the data sampled and the implementation and use of data standards by the federal agency.|$|R
40|$|We {{present a}} novel, simple, {{efficient}} algorithm to generate random samples uniformly on the directional {{space of a}} cone. This algorithm has three advantages over the conventional non-uniform approach. First, {{to the best of}} our knowledge, this algorithm is original for uniformly sampling smaller areas of cones. Second, it is faster. Third, it always generates <b>valid</b> <b>samples,</b> which is not possible for the conventional approach...|$|R
30|$|To {{evaluate}} {{the effects on}} the localization algorithm by setting different parameters, the average localization error {{and the number of}} candidate samples are regarded as key indicators. Among them, the number of candidate samples reflects the number of times as the sampling process is executed for obtaining the <b>valid</b> <b>samples.</b> Usually, the lesser the number of candidate samples is, the higher the success rate of sampling can obtain.|$|R
40|$|We {{examined}} the convergent {{validity of the}} Chinese Personality Assessment Inventory (CPAI; Cheung, Leung, et al., 1996), an indigenously constructed measure, by comparing its patterns of correlations with the MMPI- 2 (Butcher et al., 2001). A <b>valid</b> <b>sample</b> of 147 Chinese students took both the CPAI and the MMPI- 2. Results provide preliminary support for the convergence between most of the CPAI clinical scales and the relevant MMPI- 2 scales. The CPAI personality scales further illustrated the patterns of personality features associated with the MMPI- 2 scales in a Chinese cultural context. We discuss discrepancies in the correspondence between a number of CPAI and MMPI- 2 clinical scales. We {{examined the}} convergent validity of the Chinese Personality Assessment Inventory (CPAI; Cheung, Leung, et al., 1996), an indigenously constructed measure, by comparing its patterns of correlations with the MMPI- 2 (Butcher et al., 2001). A <b>valid</b> <b>sample</b> of 147 Chinese students took both the CPAI and the MMPI- 2. Results provide preliminary support for the convergence between most of the CPAI clinical scales and the relevant MMPI- 2 scales. The CPAI personality scales further illustrated the patterns of personality features associated with the MMPI- 2 scales in a Chinese cultural context. We discuss discrepancies in the correspondence between a number of CPAI and MMPI- 2 clinical scales...|$|E
40|$|This paper {{analyses}} {{the role}} of SMEs in regional development, focusing the particular case of This paper analyses {{the role of}} SMEs in regional development, focusing the particular case of Lublin Region in Poland. By using a questionnaire presented to firms that are operating in manufacturing and construction sectors were analysed several issues related to firms themselves, and their sustainability strategies. The sustainability strategy was measured through {{the combination of the}} three main perspectives in sustainable development: Economic, Social, and Environmental. This study aims, in a first stage, to analyse entrepreneurs? view of their role in local and regional development, by the adoption of sustainability strategies at the three identified levels. After that, it will also be explored the relation between sustainable development and other variables such as: business local integration, firm age, number of years in the actual location, or firm legal form. As mentioned, the methodology adopted was the questionnaire, in order to get entrepreneurs opinion. In order to guarantee a <b>valid</b> <b>sample,</b> and considering the number of firms operating in this region, it was calculated the number of a <b>valid</b> <b>sample,</b> and due to the results obtained after a pilot study it was identified a <b>valid</b> <b>sample</b> of 44 questionnaires. However, due to the number of firms operating in the manufacturing and construction businesses (above 34. 000) it was decided to collect some more questionnaires. At the end 314 questionnaires answered by managers from SMEs operating the in region of Lublin, acting the in the manufacturing and construction sectors, were accepted for this analysis. As main results it was identified that the major concern of entrepreneurs is related to the economic perspective. The second most important perspective was the environmental and at last the social one. In general the results were very positive. Most of firms present a proactive attitude towards to sustainable development, arguing that they adopt sustainability strategies (Economic, Social, and Environmental) at their management policies and strategies. However it was noticed that while older firms (above 10 years old) present greater concern with social and environmental issues, younger firms, are focusing in the economic perspective...|$|E
40|$|Abstract. Sliding window {{accumulation}} detector {{and order}} statistics-sliding window accumulation detector for missile-borne high-resolution radar target detection {{are presented in}} this paper. Their performance under space-time correlated K-distributed clutter background has been investigated. Under null hypothesis, the approximate probability density function expressions for the test statistics are derived, the relationship between false-alarm probability, CFAR detection threshold and clutter parameters are established, based on the theory of generalized K-distribution fitting, moment matching, <b>valid</b> <b>sample</b> size estimation of relevant data and fractional order statistics computing. Both the theoretical analyses and simulation experiments demonstrate {{the effectiveness of the}} proposed methods...|$|E
40|$|We {{propose a}} method called PacketTwins for {{estimating}} {{the capacity of}} heavy-loaded paths. Unlike popular packet pair methods, which probe a path {{with a series of}} two equal-sized packets, PacketTwins uses a series of twin probe packets that are slightly different in size. By sending twin probe packets alternately, we can obtain new information about selecting <b>valid</b> <b>samples</b> for capacity estimation when a network path is heavy loaded...|$|R
5000|$|In statistics, the {{bootstrap}} error-adjusted single-sample technique (BEST or the BEAST) is a non-parametric {{method that}} {{is intended to}} allow an assessment {{to be made of}} the validity of a single sample. It is based on estimating a probability distribution representing what can be expected from <b>valid</b> <b>samples.</b> [...] This is done use a statistical method called bootstrapping, applied to previous samples that are known to be valid.|$|R
30|$|As a {{fundamental}} requirement in Internet of Things (IoT) and other wireless sensor applications, localization awareness {{is an important}} part of network design. Due to the complexity of related algorithms, researchers in this area have acquired significant progress but still exists quite a few deficiencies. Most of the solutions are static localization algorithms for node’s positioning, but the performance of those algorithms in mobile wireless sensor network is unsatisfactory. In the real scene, such as target tracking, the sensor nodes are usually mobile and the node localization mechanism should be suitable for mobile wireless sensor networks. Considering that the mobile sensors change their locations frequently over time, Monte Carlo localization algorithm utilizes the moving characteristics of nodes and employs the probability distribution function (PDF) in the previous time slot to estimate the current location by using a weighted particle filter. However, it also has the problem of insufficient number of <b>valid</b> <b>samples,</b> which further affects the node’s localization accuracy. Therefore, it is necessary to increase the number of <b>valid</b> <b>samples</b> to improve the localization accuracy under low anchor node density.|$|R
40|$|A {{new method}} for the formal {{solution}} of the 2 D radiative transfer equation in axial symmetry {{in the presence of}} arbitrary velocity fields is presented. The combination of long and short characteristics methods is used to solve the radiative transfer equation. We include the velocity field in detail using the Local Lorentz Transformation. This allows us to obtain a significantly better description of the photospheric region, where the gradient of the global velocity is too small for the Sobolev approximation to be <b>valid.</b> <b>Sample</b> test calculations for the case of a stellar wind and a rotating atmosphere are presented. Comment: 11 pages, 19 figures. accepted by Astronomy and Astrophysic...|$|E
40|$|Past {{research}} examining {{the effects of}} psychological expert testimony concerning future dangerousness in sexual violent predator commitment trials has produced equivocal results on whether mock jurors are more influenced by intuitive clinical expert testimony than empirically based actuarial testimony. This study advances this line of research by examining these effects using a more ecologically <b>valid</b> <b>sample</b> of 156 venire jurors who watched a simulated, videotaped SVP trial based on a case transcript. As predicted, jurors were more influenced by the less scientific, clinical expert testimony. The data provided only limited support for a theoretical explanation based on Cognitive-Experiential Self-Theory (CEST). The policy im-plications of these results are discussed...|$|E
40|$|In this Chapter {{we discuss}} the load-balancing issues arising in {{parallel}} mesh based computational mechanics codes for which the processor loading changes during the run. We briefly touch on geometric repartitioning ideas and then focus on different ways of using a graph both to solve the load-balancing problem and the optimisation problem, both locally and globally. We also briefly discuss whether repartitioning is always <b>valid.</b> <b>Sample</b> illustrative results are presented and we conclude that repartitioning is an attractive option if the load changes are not too dramatic {{and that there is}} a certain trade-off between partition quality and volume of data that the underlying application needs to migrate...|$|E
30|$|Under this background, {{we study}} the traffic {{congestion}} impacts on travelers and {{their reactions to}} congestion. A random sampling survey was taken in Shanghai, China during August 1 st to August 31 st in 2009 to collect data for this research, including transportation users’ attitudes about road traffic congestion, baseline transportation characteristics of transportation users, their reactions to traffic congestion and sociodemographics. Totally, 274 <b>valid</b> <b>samples</b> were collected, covering most of districts of Shanghai.|$|R
5000|$|... {{the above}} {{approximation}} is only <b>valid</b> for <b>sample</b> size [...] {{much larger than}} the number [...] of parameters in the model.|$|R
40|$|We {{present a}} new {{approach}} to perform molecular sim-ulations using evolutionary algorithms. The main ap-plication of this work is the simulation of dense amor-phous polymers and the goal is to improve the efficiency of sampling, in other words to obtain <b>valid</b> <b>samples</b> from the phase state more rapidly. Our approach is based on parallel Markovian Monte Carlo simulations of the same physico-chemical system, where we optimise some Monte Carlo parameters by means of a real coded genetic algo-rithm. ...|$|R
40|$|The NAHMS Dairy ' 96 Study was {{designed}} to provide both participants and the industry with information on the nation's dairy animal population for education and research. The USDA's National Agricultural Statistics Service (NASS) collaborated with NAHMS to select a statistically <b>valid</b> <b>sample</b> yielding 2, 542 producers. Included {{in the study were}} 20 states that represented 83. 1 percent of the U. S. milk cows as of January 1, 1996. NASS interviewers collected data for Part I via a questionnaire administered on-farm from January 1 through 26, 1996. Contact for this paper: Steven OttNAHMS, dairy, cattle, milk, feed, weaning, culls, health, vaccination, morbidity, mortality, births, housing, biosecurity, Livestock Production/Industries,...|$|E
40|$|During {{their birth}} all stars undergo periods of copious mass loss, {{frequently}} {{characterized by the}} occurrence of bipolar outflows. These outflows are believed to play {{a fundamental role in}} the star formation process. However the exact outflow generating method is obscure at present. To elucidate this problem we are investigating whether the flow properties are correlated over the entire protostellar mass spectrum. Progress in this area requires that we assemble a statistically <b>valid</b> <b>sample</b> of high-mass outflow systems. This is necessary since existing catalogues of such objects are heterogeneous and statistically incomplete. Comment: 2 pages, 1 figure, uses newpasp. sty. To appear in "Hot Star Workshop III: The Earliest Phases of Massive Star Birth" (ed. P. A. Crowther...|$|E
40|$|A {{computerized}} {{procedure is}} presented for calculating instantaneous velocity changes due to discrete imposition of constraints, impact or discrete inertial changes. Such discrete changes are impulsive in nature, involve wave propagation and therefore usually require detailed modeling for accurate prediction. It is demonstrated that when modeling is coarse, physically unrealistic {{results can be}} produced. The present procedure, which concentrates on finite element analysis, reduces the need for detailed modeling by assuming that only those velocities {{in the neighborhood of}} grid points involved in the constraint or those rigidly connected to grid points involved in the constraint need be considered in calculating velocity changes. The procedure utilizes Newton's second law and as such conserves momentum where <b>valid.</b> <b>Sample</b> problems are provided...|$|E
40|$|Oriented biotite {{inclusions}} in diamond coat NATURAL diamonds contain mineral inclusions {{that represent}} <b>valid</b> <b>samples</b> {{of the upper}} mantle of the Earth (where diamond crystallisation occurred) provided that they are totally enclosed within the diamond and do not derive from material ater infiltrating via cracks. Inclusions satisfying this condition, and which are also of macroscopic size (diameters> 100 gm, say), have been studied over many ears. Some important reports and reviews of this work are by William...|$|R
30|$|Mechanically {{ventilated}} {{critically ill}} adult patients, with an indwelling arterial line and {{admitted to the}} ICU for either medical or surgical conditions, were eligible for this study. Severe coagulopathy (prothrombin time[*]>[*] 2.5 ratio, platelet count[*]<[*] 10, 000 units/dl) and inability to obtain informed consent by the patient or next of kin were exclusion criteria. Sample size estimation for comparing capillary versus arterial samples {{was based on the}} method described by Walter and Shoukri [10, 11]. In order to compare the two methods using the Concordance Correlation Coefficient (CCC) approach, a minimum of 30 valid data points where needed. Due to an unexpected high sampling failure ratio, 55 patients were included in a non-consecutive fashion in order to obtain 31 <b>valid</b> <b>samples.</b> Two interim analyses were performed after the inclusion of the 15 th and 45 th patients in order to monitor sampling success, and to adjust patient inclusion for the observed data acquisition rate and the required number of <b>valid</b> <b>samples.</b> The study protocol was in accordance with the amended Declaration of Helsinki and was approved by an Independent Ethics Committee (IRB: 2009593. Comité Ètic d’Investigació Clínica, Corporació Sanitària Universitària Parc Taulí. Sabadell, Spain).|$|R
5000|$|The {{approach}} seen in [...] {{attempts to}} further simplify the pre-distorter feedback system by applying subsampling {{in order to}} eliminate a down conversion stage. This reference focuses on the subsampling portion {{of the system and}} characterizing the ranges of <b>valid</b> <b>sampling</b> frequencies based on carrier location and spacing. The advantage of this approach is the obvious advantage of the elimination of a mix stage. The disadvantage of this approach is the restriction of the carrier location and spacing that is inherent to achieving proper subsampling.|$|R
