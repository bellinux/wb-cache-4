55|1252|Public
5000|$|The Caltech 101 {{data set}} {{was used to}} train and test several {{computer}} <b>vision</b> <b>recognition</b> and classification algorithms. The first paper to use Caltech 101 was an incremental Bayesian approach to one shot learning, [...] an attempt to classify an object using only a few examples, by building on prior knowledge of other classes.|$|E
50|$|Industrial AI can be {{embedded}} {{to existing}} {{products or services}} {{to make them more}} effective, reliable, safer, and last longer. One example is the automobile industry uses <b>vision</b> <b>recognition</b> to avoid accidents, stay in lane, and use speech recognition to facilitate safer driving. In manufacturing, one example is the prediction of blade life for self-aware band saw machines, so that users will be able to rely on evidence of degradation rather than experience, which is safer, will extend blade life, and build up blade usage profile to help blade selection.|$|E
5000|$|Peter Nordin has a PhD in Computer Science at University of Dortmund (1997) and {{a degree}} in {{computer}} science and engineering from Chalmers University of Technology in Gothenburg, Sweden (1988). His current research include commercial evolutionary robotics software and software for a complete cognitive system for robots. [...] His earlier research includes: Evolutionary software architecture for robotics, the invention of evolutionary induction of mathematical proofs and of binary machine language, speech and <b>vision</b> <b>recognition,</b> and linear genetic programming for internet search. He pioneered analysis of genetic programming through complexity theory. Nordin's research belongs to the top 200 most cited in computer science.|$|E
5000|$|Wendy S. Hesford, Spectacular Rhetorics: Human Rights <b>Visions,</b> <b>Recognitions,</b> Feminisms. (2011). International Journal of Communication 5.|$|R
5000|$|The Conference on Computer <b>Vision</b> and Pattern <b>Recognition</b> is {{an annual}} conference on {{computer}} <b>vision</b> and pattern <b>recognition,</b> by several measures {{regarded as the}} top conference in computer vision.|$|R
50|$|Maihar Sharda Devi temple <b>vision</b> of <b>recognition</b> after Maihar {{philosophy}} {{is to have}} his wish is fulfilled.|$|R
50|$|In {{practice}} {{it is not}} possible to obtain the quoted theoretical maximum throughput rate for machines in a placement system. It is necessary to derate the theoretical numbers to obtain realistic values, due to unexpected downtime, board load and unload time and machine configuration. Other factors include PWB size, component mix, and the requirement for more complex <b>vision</b> <b>recognition</b> for fine-pitch components. There are many techniques of derating. Global derating considers system-wide stops, slow-downs and set ups as well as machine factors. To calculate the amount of global or system derating, one should take the average of the number of total components placed per hour in a long period (i.e. an entire product shift). Regularly scheduled stops should be included when determining the level of global derating the system requires.Rigorous derating, which considers each piece of equipment in service for a particular product individually, must be conducted by specific machine model for the line balancing. Rigorous derating values are necessary for full optimization of the process.|$|E
40|$|This paper {{analyzes}} {{the necessity of}} cherry picking robot <b>vision</b> <b>recognition</b> system. It introduces the system function and the system structure, and provides the system operation environment, the development platform and the database design. This paper designs and implements the cherry picking robot <b>vision</b> <b>recognition</b> system, based on C# technology, using MATLAB, using face recognition technology...|$|E
40|$|Abstract: In the {{computer}} <b>vision</b> <b>recognition</b> of incomplete symbols in Russian symbols, the traditional identification methods can only identify {{a small number}} of complete Russian symbols, and have a low recognition rate of the incomplete Russian symbols. To this end, this paper presents a method for computer <b>vision</b> <b>recognition</b> of incomplete symbols in Russian symbols based on Hough transform algorithm. According to the mapping from the image space to the parameter space, the complex edge feature information in image space is transformed into the clustering problem in the parameter space, and the discrimination function and the rules are developed and employed to recognize the image need to be recognized. Experiments show that with Hough transform algorithm to identify incomplete symbols in Russian symbols, the incomplete symbol in Russian symbols can be identified quickly and effectively, which improves the performance of recognition method and meet the needs of many scholars. ...|$|E
30|$|As {{in natural}} <b>vision,</b> both <b>recognition</b> and {{learning}} in the SP system is robust {{in the face of}} errors of omission, commission and substitution.|$|R
25|$|Deep {{learning}} in artificial neural networks with many layers has transformed many important subfields of artificial intelligence, including computer <b>vision,</b> speech <b>recognition,</b> {{natural language processing}} and others.|$|R
5000|$|... #Article: Conference on Computer <b>Vision</b> and Pattern <b>Recognition</b> ...|$|R
40|$|Abstract. An {{embedded}} <b>vision</b> <b>recognition</b> {{system is}} developed for a regular UAH to provide guidance information during hovering and landing. An innovative landing mark {{has been designed}} to facilitate the image processing while provide relative heading, height, and coordinate for navigation. The system can provide 30 Hz updating rate to the UAH avionic system. Simulation and real-world tests have shown promising performance and results for future applications...|$|E
40|$|This book {{constitutes}} the refereed {{proceedings of the}} Second International Workshop on Biologically Motivated Computer Vision, BMCV 2002, held in Tübingen, Germany, in November 2002. The 22 revised full papers and 37 revised short papers presented together with 6 invited papers were carefully reviewed and selected from 97 submissions. The papers are organized in topical sections on neurons and features, motion, mid-level <b>vision,</b> <b>recognition</b> - from scenes to neurons, attention, robotics, and cognitive vision...|$|E
40|$|Suddenly encountering light sources {{at night}} will reduce drivers' dynamic {{distance}} of visual cognition. In order {{to investigate the}} law of quantitative changes of the visual recognition distance under the conditions of different speeds and different environmental luminosity around drivers, calibration experiments were conducted on an actual road. And {{on the basis of}} the data set from the experiments, using the method of curved surface regression analysis, the function models describing the rule of the visual recognition distance changing with the environmental luminosity around drivers and running speeds were established. The models were effective via statistical tests. Furthermore, combined with the automobile braking distance, the reaction time allowed for drivers and the critical speeds were analyzed then. Verification tests were also designed to test the established function model. Results showed that as the environmental luminosity around drivers increases, <b>vision</b> <b>recognition</b> distance decreases; as vehicle speed increases, <b>vision</b> <b>recognition</b> distance decreases. Therefore, the sudden showing-up light sources will affect the environmental luminosity in the cab and lead to the reduction in the visual recognition distance as well as the reaction time for drivers. In this circumstance, drivers must control the speed lower than the critical speed to avoid collision...|$|E
50|$|All {{mathematical}} {{aspects of}} computer science, including computational complexity theory, logic of programming languages, analysis of algorithms, cryptography, computer <b>vision,</b> pattern <b>recognition,</b> information processing and modelling of intelligence.|$|R
5000|$|John Daugman, Professor of Computer <b>Vision</b> and Pattern <b>Recognition</b> ...|$|R
40|$|Key words: feature extraction; wavelet moment invariants; binary wavelet Abstract: in {{the process}} of {{studying}} on computer <b>vision</b> feature <b>recognition</b> method, with the current algorithm for feature recognition, the amount of calculation is large, and noise is strong, recognition rate is low. For this, a computer <b>vision</b> feature <b>recognition</b> method based on Improved Wavelet arithmetic is put forward. Firstly, spline binary wavelet decomposition is fused in the method to extract edge feature from collected images, and then wavelet moment invariants of the processed image is calculated and acted as the characteristic quantity of computer vision, so as to complete the accurate identification of the characteristics of computer vision. Characteristic quantity extracted through this method can not only solve the problem of uneven illumination, illumination variation and noise interference, also translation, rotation and zoom. Simulation results show that accuracy of computer <b>vision</b> feature <b>recognition</b> based on improved wavelet algorithm is great, and effect is ideal...|$|R
40|$|Diagrams are an {{essential}} means of capturing and communicating information {{in many different}} domains. They are also a valuable part of the early design process, helping us explore ideas and solutions in an informal environment. This paper presents {{a new approach to}} sketched symbol recognition that preserves as much of the visual nature of the symbol as possible. Our method is robust to differences in drawing style, computationally efficient, and achieves excellent performance for several different domains. Author Keywords Sketch Recognition, symbol recognition, <b>vision</b> <b>recognition</b> algorithm...|$|E
30|$|With the {{continuous}} improvement of precision requirements for industrial inspection, the basic pixel-level accuracy in machine <b>vision</b> <b>recognition</b> {{has not been}} able to meet the requirements of actual measurement, so it needs a more accurate edge extraction algorithm [14, 15], that is, sub-pixel algorithm[16]. The sub-pixel algorithm [17] generally needs to find the position of the edge pixel [18] using the classical algorithm first and then use the gray value of the surrounding pixel [18] as the supplementary information for judgment, using interpolation, fitting, and so on [19 – 21] to position the edge in a more precise position.|$|E
40|$|Deep {{learning}} {{has been extensively}} used various aspects of computer vision area. Deep learning separate itself from traditional neural network by having a much deeper and complicated network layers in its network structures. Traditionally, deep neural network is abundantly used in computer vision tasks including classification and detection and has achieve remarkable success {{and set up a}} new state of the art results in these fields. Instead of using neural network for <b>vision</b> <b>recognition</b> and detection. I will show the ability of neural network to do image registration, synthesis of images and image retrieval in this report...|$|E
25|$|Neural {{networks}} {{have been used}} {{on a variety of}} tasks, including computer <b>vision,</b> speech <b>recognition,</b> machine translation, social network filtering, playing board and video games, medical diagnosis and in many other domains.|$|R
5000|$|Sensor applications: 2/3D <b>Vision</b> (including object <b>recognition),</b> Force, Infrared, and Acceleration ...|$|R
50|$|Specific {{applications}} of FPGAs include digital signal processing, software-defined radio, ASIC prototyping, medical imaging, computer <b>vision,</b> speech <b>recognition,</b> cryptography, bioinformatics, computer hardware emulation, radio astronomy, metal detection {{and a growing}} range of other areas.|$|R
40|$|Abstract-Schema-based {{representations}} {{for visual}} knowledge are integrated with constraint satisfaction techniques. This integration {{is discussed in}} a progression of three sketch map interpretation pro-grams: Mapsee- 1, Mapsee- 2, and Mapsee- 3. The programs are evalu-ated by the criteria of descriptive and procedural adequacy. The eval-uation indicates that a schema-based representation used in combination with a hierarchical arc consistency algorithm constitutes a modular, efficient, and effective approach to the structured represen-tation of visual knowledge. The schemata used in this representation are embedded in composition and specialization hierarchies. Speciali-zation hierarchies are further expanded into discrimination graphs. Index Terms-Constraint satisfaction, discrimination graphs, hier-archical arc consistency, model-based <b>vision,</b> <b>recognition,</b> schema rep-resentations, sketch maps. I...|$|E
40|$|Unsupervised {{dictionary}} {{learning has}} been a key com-ponent in state-of-the-art computer <b>vision</b> <b>recognition</b> ar-chitectures. While highly effective methods exist for patch-based dictionary learning, these methods may learn redun-dant features after the pooling stage in a given early vi-sion architecture. In this paper, we offer a novel dictionary learning scheme to efficiently {{take into account the}} invari-ance of learned features after the spatial pooling stage. The algorithm is built on simple clustering, and thus enjoys ef-ficiency and scalability. We discuss the underlying mecha-nism that justifies the use of clustering algorithms, and em-pirically show that the algorithm finds better dictionaries than patch-based methods with the same dictionary size. 1...|$|E
40|$|Feedforward visual object {{perception}} recruits a {{cortical network}} that {{is assumed to}} be hierarchical, progressing from basic visual features to complete object representations. However, the nature of the intermediate features related to this transformation remains poorly understood. Here, we explore how well different computer <b>vision</b> <b>recognition</b> models account for neural object encoding across the human cortical visual pathway as measured using fMRI. These neural data, collected during the viewing of 60 images of real-world objects, were analyzed with a searchlight procedure as in Kriegeskorte, Goebel, and Bandettini (2006) : Within each searchlight sphere, the obtained patterns of neural activity for all 60 objects were compared to model responses for each computer recognition algorithm using representational dissimilarity analysis (Kriegeskorte et al., 2008). Although each of the computer vision methods significantly accounted for some of the neural data, among the different models, the scale invariant feature transform (Lowe, 2004), encoding local visual properties gathered from 2 ̆ 2 interest points, 2 ̆ 2 was best able to accurately and consistently account for stimulus representations within the ventral pathway. More generally, when present, significance was observed in regions of the ventral-temporal cortex associated with intermediate-level object perception. Differences in model effectiveness and the neural location of significant matches may be attributable to the fact that each model implements a different featural basis for representing objects (e. g., more holistic or more parts-based). Overall, we conclude that well-known computer <b>vision</b> <b>recognition</b> systems may serve as viable proxies for theories of intermediate visual object representation...|$|E
5000|$|Escolano, Suau, Bonev, Information Theory in Computer <b>Vision</b> and Pattern <b>Recognition,</b> Springer, 2009.|$|R
25|$|Scientific {{conferences}} where <b>vision</b> based activity <b>recognition</b> work often appears are ICCV and CVPR.|$|R
5000|$|... "For {{contributions}} to computer <b>vision</b> and pattern <b>recognition,</b> and for outstanding leadership in IAPR".|$|R
40|$|Machine {{recognition}} of objects {{is the task}} of locating and recognizing a given object in an image and con-sists of the following steps: object detection, feature extraction, and recognition. Background Early computer <b>vision</b> <b>recognition</b> schemes focused primarily on the {{recognition of}} rigid three-dimensional (3 D) objects, such as machine parts, tools, and cars. This is a challenging problem because the same object can have markedly different appearances when viewed from different directions. It proved possible to deal successfully with this difficulty by using detailed 3 D models of the viewed objects, which were compared with the projected 2 D image (e. g., [14, 18, 33]). Over {{the last decade or}} so, computational models have mad...|$|E
40|$|Automated feature {{extraction}} and object recognition are large research {{areas in the}} field of image processing and computer <b>vision.</b> <b>Recognition</b> is largely based on the matching of descriptions of shapes. Numerous shapes description techniques have been developed, such as scalar features (dimension, area, number of corners etc.), Fourier descriptors and moment invariants. These techniques numerically describe shapes independent of translation, scale and rotation and can be easily applied to topographical data. The applicability of the moment invariants technique to classify objects on large-scale maps is described. From the test data used, moments are fairly reliable at distinguishing certain classes of topographic object. However, their effectiveness will increase when fused with the results of other techniques. 1...|$|E
40|$|In this paper, we {{investigate}} {{the utility of}} static anthropometric distances as a biometric for human identification. The 3 D landmark data from the CAESAR database is used to form a simple biometric consisting of distances between fixed rigidly connected body locations. This biometric is overt, and invariant to view and body posture. We use this to quantify the asymmetry of human bodies, and to characterize the interpersonal and intrapersonal distance distributions. The former is computed directly and the latter by adding zero-mean gaussian noise to the landmark points. This simulation framework is applicable to arbitrary shape based biometrics. We use gross body proportions information to model a computer <b>vision</b> <b>recognition</b> system. 1...|$|E
50|$|It {{is a very}} {{important}} and challenging problem to track and understand the behavior of agents through videos taken by various cameras. The primary technique employed is computer <b>vision.</b> Vision-based activity <b>recognition</b> has found many applications such as human-computer interaction, user interface design, robot learning, and surveillance, among others.Scientific conferences where <b>vision</b> based activity <b>recognition</b> work often appears are ICCV and CVPR.|$|R
40|$|Computer <b>Vision,</b> Pattern <b>Recognition,</b> Machine Learning, Robotics, and Scientific Computing. My {{primary focus}} has been on: {{efficient}} algorithms for large-scale problems, real-time object tracking, robust similarity measures, camera calibration, autonomous navigation systems, and probabilistic analysis of Hough transform...|$|R
50|$|Rectified linear units find {{applications}} in computer <b>vision</b> and speech <b>recognition</b> using deep neural nets.|$|R
