54|110|Public
25|$|Voice/sound recognition: This form of {{interaction}} may be used either to interact with agents within the simulation (e.g., virtual people) or to manipulate objects in the simulation (e.g., information). <b>Voice</b> <b>interaction</b> presumably increases the level of immersion for the user.|$|E
5000|$|XHTML+Voice [...] - [...] Enabling the {{multimodal}} Web via <b>voice</b> <b>interaction</b> ...|$|E
50|$|Brigitt is {{referenced}} in-game {{during a}} <b>voice</b> <b>interaction</b> between Mercy and Reinhardt, {{in which she}} voices disapproval of Reinhardt bringing such a young woman on increasingly dangerous adventures.|$|E
50|$|Call transcription: Captures <b>voice</b> <b>interactions</b> by transcribing conversations, IVR responses, {{and voice}} messages.|$|R
40|$|The {{objective}} {{of the current study}} was to assess the effect of <b>voice</b> <b>interactions</b> with an in-vehicle system on drivers’ guidance of attention. Our approach was to examine the effect of <b>voice</b> <b>interactions</b> on endogenous control of attention using a modified Posner cue-target paradigm. Consistent with the bottleneck hypothesis, dual-task slowing was observed when drivers responded to an auditory task and to a pedestrian detection task concurrently. This interference contributed to disrupted attention allocation, especially when drivers could not rely on their endogenous control of attention...|$|R
30|$|Video: Practice frequency. Defined as {{the count}} of IVIS <b>voice</b> <b>interactions</b> during the 5 -day {{practice}} session where participants practiced using the voice assistant to call a contact, dial a number, tune the radio, or engage in other voice tasks.|$|R
50|$|The Unified Computer Intelligence Corporation has {{launched}} a device called Ubi - The Ubiquitous Computer {{that is designed to}} allow <b>voice</b> <b>interaction</b> with the home and provide constant access to information.|$|E
50|$|Voice/sound recognition: This form of {{interaction}} may be used either to interact with agents within the simulation (e.g., virtual people) or to manipulate objects in the simulation (e.g., information). <b>Voice</b> <b>interaction</b> presumably increases the level of immersion for the user.|$|E
50|$|A matrix {{design of}} 360 {{wrap-around}} perception that utilizes more than 60 sensors gives Sanbot better than human-like awareness. The robot is capacity of <b>Voice</b> <b>Interaction,</b> Facial Recognition, Voice Localization, Video Chat, Obstacle Avoidance and Auto charging, giving users feeling of Magic Audio-visual.|$|E
40|$|This {{research}} {{explores the}} possibility of using a combination of a phonetic feature based binary encoding format for phonemes and dedicated coprocessors to improve computer <b>voice</b> <b>interactions.</b> While both speech synthesis and speech recognition have made great strides recently current performance still leaves much to be desired. Dedicated graphics cards and binary encoding have had a huge impact on computer graphics in the last two decades, and could do the same for <b>voice</b> <b>interactions.</b> Sources for this research consist primarily of course text books and documentation from open source software projects. At the time that this research was conducted it was purely speculative, but since then advances such as Google 2 ̆ 7 s TensorFlow AI, and NVIDIA 2 ̆ 7 s CUDA development kit make experimental research practical. This research indicates that it would be worthwhile to conduct experimental research on dedicate...|$|R
40|$|This paper {{examines}} {{patterns of}} voicing agreement between consonants (Cs) at a distance. I {{argue that the}} agreement stems from a correspondence relation between similar Cs in the output, a relation with foundation in mechanisms of production processing. The occurrence of long distance <b>voicing</b> <b>interactions</b> is predicted under this approach. The account also brings explanation to an observed similarity effect whereby the agreement preferentially targets pairs of near-identical (or identical) Cs. 1...|$|R
40|$|This thesis {{presents}} Convivo, a VoIP {{system designed}} to provide reliable voice communication for poor quality networks, especially those found in rural areas of the developing world. Convivo introduces an original approach to maintain <b>voice</b> communication <b>interaction</b> in presence of poor network performance: an Interface-Adaptation mechanism that suggests adjusting the application user interface to conform {{to one of three}} voice communication modalities (full duplex, half duplex, and voice messaging). The thesis proposes that changes in communication modality are an option to sustain <b>voice</b> communication <b>interaction</b> despite poor network performance. The goals of the changes in communication modality are to reduce the impact of high latency and low bandwidth on <b>voice</b> communication <b>interaction,</b> to facilitate turn taking for a high latency connection, and to sustain voice communication for extremely low bandwidth or high error links. The system was tested via a user study in Bohechio, a small village in the Dominican Republic...|$|R
50|$|Alexa is an {{intelligent}} personal assistant developed by Amazon, made popular by the Amazon Echo and the Amazon Echo Dot devices developed by Amazon Lab126. It {{is capable of}} <b>voice</b> <b>interaction,</b> music playback, making to-do lists, setting alarms, streaming podcasts, playing audiobooks, and providing weather, traffic, and other real time information, such as news. Alexa can also control several smart devices using itself as a home automation system.|$|E
5000|$|Amazon Echo (shortened and {{referred}} to as Echo) is a smart speaker developed by Amazon.com. The device consists of a 9.25 inch (23.5 cm) tall cylinder speaker with a seven-piece microphone array. The device connects to the voice-controlled intelligent personal assistant service Alexa, which responds to the name [...] "Alexa". This [...] "wake word" [...] can be changed by the user to [...] "Amazon", [...] "Echo" [...] or [...] "Computer". The device is capable of <b>voice</b> <b>interaction,</b> music playback, making to-do lists, setting alarms, streaming podcasts, playing audiobooks, and providing weather, traffic and other real time information. It can also control several smart devices using itself as a home automation hub. As of July 2017, the Echo maintained an 83% score on GearCaliber, a review aggregator. The Echo Dot maintained a 93% score.|$|E
40|$|This paper {{reviews the}} current state of {{knowledge}} in the field of driver distraction, its causes and correlates, its effects on driving performance and accident hazard, and the role of <b>voice</b> <b>interaction</b> for a better driving safety. It summarizes the results of an extensive literature review in the field of driver distraction and <b>voice</b> <b>interaction</b> and presents an overview of relevant findings from 35 selected publications between 2000 and 2011. Driver distraction caused by interacting with technology while driving is a predominant and increasingly relevant accident hazard. The interaction with ICT products can be associated with cognitive and visual driver distraction. The actual level of driver distraction depends on characteristics of the secondary task and the used interaction mode. Cognitive distraction is mainly determined by interaction complexity whereas visual distraction can be avoided by using <b>voice</b> <b>interaction</b> instead of manually controlled systems with agraphical display. Compared to cognitive distraction, visual distraction has much stronger effects on driving performance and accident hazard. As a consequence, <b>voice</b> <b>interaction</b> is consistently shown to be superior in terms of driver distraction, driving performance and accident hazard when compared with manual control and graphical displays. Therefore, <b>voice</b> <b>interaction</b> {{is often referred to as}} an important and indispensable contribution to safer driving. However, the design and implementation of a speechbased system play an essential role for the effectiveness and safety of <b>voice</b> <b>interaction</b> in the car. An accurate speech recognizer and an easy-to-use voice user interface are the main prerequisites in order to make full use of the potentials of <b>voice</b> <b>interaction.</b> In summary, well-designed speech-based in-vehicle systems will allow drivers to keep their eyes on the road and their hands on the wheel, making it possible to improve driving performance and reduce accident hazard...|$|E
40|$|Although talkhtg is an {{integral}} part of collaborative activity, there has been little computer support for acquiring and accessing the contents of conversations. Our approach has focused on ubiquitous audio, or the unobtrusive capture of <b>voice</b> <b>interactions</b> in everyday work environments. Because the words themselves are not available for organizing the captured interactions, structure is derived from acoustical information inherent in the stored voice and augmented by user interaction during or after capture. This paper describes applications for capturing and structuring audio from office discussions and telephone calls, and mechanisms for later retrieval of these stored interactions...|$|R
50|$|While the {{association}} seeks to promote {{all aspects of}} speech sciences in Italy, {{the association}} is especially concerned with phonetics, speech signal processing, and the automatic treatment of language in <b>voice</b> man-machine <b>interaction.</b>|$|R
40|$|This thesis {{presents}} Convivo, a VoIP {{system designed}} to provide reliable voice communication for poor quality networks, especially those found in rural areas of the developing world. Convivo introduces an original approach to maintain <b>voice</b> communication <b>interaction</b> in presence of poor network performance: an Interface-Adaptation mechanism that suggests adjusting the application user interface to conform {{to one of three}} voice communication modalities (full duplex, half duplex, and voice messaging). The thesis proposes that changes in communication modality are an option to sustain <b>voice</b> communication <b>interaction</b> despite poor network performance. The goals of the changes in communication modality are to reduce the impact of high latency and low bandwidth on <b>voice</b> communication <b>interaction,</b> to facilitate turn taking for a high latency connection, and to sustain voice communication for extremely low bandwidth or high error links. The system was tested via a user study in Bohechio, a small village in the Dominican Republic. The study found that Interface-Adaptation helped users to maintain <b>voice</b> communication <b>interaction</b> when network performance degrades. Transitions from full duplex to voice messaging were found particularly valuable. Initial results suggest that as users get more experience with the application they would like to manually control transitions based on feedback provided by the application and their own perceived voice quality. by Marco Antonio Escobedo Gonzalez Maiz. Thesis (S. M.) [...] Massachusetts Institute of Technology, School of Architecture and Planning, Program in Media Arts and Sciences, 2002. Includes bibliographical references (leaves 100 - 102) ...|$|R
40|$|In this paper, we {{describe}} an XML based 3 D-Voice Enabled Single Transmission Multiple Display Multimedia Language (3 D-VE STMDML) model and its implementation. We describe 3 D-scenes, mesh based 3 D objects, integration of 2 D and 3 D objects, object animations with collision avoidance, and voice based animation control. This {{model has been}} used to download object based movies over the Internet, dynamically modify the existing movies using <b>voice</b> <b>interaction</b> in real time, and retransmit the modified movies to others over the Internet. The performance analysis shows that voice-based modification to objects in a scene is done in real time. Keywords: human-computer interaction, Internet, <b>voice</b> <b>interaction,</b> web movies, XML...|$|E
40|$|This chapter {{examines}} {{the potential for}} voice activities to enhance online learning. Although research related to online writing tools (such as e-mail, discussion threads, blogs, and wikis) is growing {{and the use of}} synchronous and asynchronous voice tools (such as internet phone, VoiceThread and multimodal web conferencing) has developed rapidly, {{little is known about the}} effects of systematically implementing these voice tools in formal educational settings (Millard, 2010). This chapter first provides a brief overview of the available online voice systems, the design principles of online <b>voice</b> <b>interaction,</b> and prior research and frameworks regarding <b>voice</b> <b>interaction</b> in online and blended learning. It then reports on a study of a systematic application of an asynchronous voice recording system integrated into a learning management system in an undergraduate blended-learning English course. The research found that the voice system was adequately usable and was associated with a positive change in the students‘ perceptions of speaking English over the semester. Half of the students were reluctant to talk to an online program, whereas the other half were willing to do so. Regular use of online voice assignments encouraged high attendance rates for the in-person classes. This suggests the potential power of asynchronous online <b>voice</b> <b>interaction</b> to help support students‘ learning...|$|E
40|$|The {{desire for}} {{ubiquitous}} access to web applications like online shopping, {{combined with the}} coming of age of speech technology, creates unique challenges as we design for multi-channel interaction. Usable and cost-effective addition of spoken access to these applications requires: • Identifying user scenarios that benefit from <b>voice</b> <b>interaction,</b> implying the ability to trea...|$|E
5000|$|Vedics (<b>Voice</b> Enabled Desktop <b>Interaction</b> and Control System) is {{a speech}} {{assistant}} for GNOME Environment ...|$|R
40|$|We {{present an}} {{immersive}} system for exploring numerically simulated flow data through {{a model of}} a coronary artery graft. This tightly-coupled interdisciplinary project is aimed at understanding how to reduce the failure rate of these grafts. The visualization system provides a mechanism for exploring the effect of changes to the geometry, to the flow, and for exploring potential sources of future lesions. The system uses gestural and <b>voice</b> <b>interactions</b> exclusively, moving away from more traditional windows/icons/menus/point-and-click (WIMP) interfaces. We present an example session using the system and discuss our experiences developing, testing, and using it. We describe some of the interaction and rendering techniques that we experimented with and describe their level of success. Our experience suggests that systems like this are exciting to clinical researchers, but conclusive evidence of their value is not yet available...|$|R
40|$|An {{architecture}} for voice dialogue machines {{is described}} {{with emphasis on}} the problem solving and high level decision making mechanisms. The architecture provides facilities for generating <b>voice</b> <b>interactions</b> aimed at cooperative human-machine problem solving. It assumes that the dialogue will consist {{of a series of}} local selfconsistent subdialogues each aimed at subgoals related to the overall task. The discourse may consist of a set of such subdiaiogues with jumps from one subdialogue to the other in a search for a successful conclusion. The architecture maintains a user model to assure that interactions properly account for the level of competence of the user, and it includes an ability for the machine to take the initiative or yield the initiative to the user. It uses expectation from the dialogue processor to aid in the correction of errors from the speech recognizer...|$|R
40|$|This paper {{describes}} the <b>Voice</b> <b>Interaction</b> ToolKIT(VitKit), a C++ class library for building telephone-based user interfaces. Rather than use a high-level specification approach, {{it is intended}} that programmers use the classes directly to compose interfaces, although the possibility of developing code-generators for building (parts of) interfaces is not excluded. The toolkit supports dynamic construction and re-configuration of interfaces and adopts a very flexible approach to interfacing with underlying applications...|$|E
40|$|VEC 3 D is a {{language}} {{learning and teaching}} project that promises 3 -D immersion, live <b>voice</b> <b>interaction</b> and social context. Building on goal-based instructional design, VEC 3 D learners embody avatars and {{meet each other in}} virtual spaces. VEC 3 D can be integrated into various educational settings, student needs, paces, styles and research goals. This article summarizes the VEC 3 D curriculum, system, and communication architecture for graphics and voice...|$|E
30|$|These modules {{facilitate}} {{the use of}} the system for the elderly. The display of a smartwatch is relatively small and some people find it difficult to interact with. The <b>voice</b> <b>interaction</b> module allows the user to control the watch with a small number of simple voice commands. It also converts the watch’s feedback into voice/sound alerts. Another simplification is the NFC album, which allows triggering of a predetermined action by approaching a chosen NFC tag in the album.|$|E
40|$|Leadership and {{credibility}} perceptions influenced by voice pitch and gender was examined. A sample of 184 participants was recruited from California State University, Los Angeles. There were 51 men and 133 women {{ranging in age}} from 18 to 65 years (M = 19. 88, SD = 2. 42). Majority of the participants reported being Hispanic/Latino/a (58. 1 %). Participants were asked to listen to an online pre-recorded message given by a candidate of a fictitious non-profit organization, then asked to indicate whether she or he would elect the candidate for president, and lastly asked to fill out the perceived Online Source Credibility Measure (Jin et al., 2009) and Faculty Ratings of Leadership Behavior Measure (Schneider et al., 1999). Overall, female and male participants rated high-pitched voices more favorably than low-pitched <b>voices.</b> <b>Interactions</b> showed that male and female participants viewed same-gendered voices more positively than the opposite gender. Future directions include considerations to visual cues...|$|R
40|$|Recently, {{language}} learners {{have the possibility}} of communicating with target language speakers and peer learners using online voice and text chat communication programs. In order to examine the process of learning, voice and text chat programs were used simultaneously to facilitate communication and assist in the acquisition process. This study examines the effectiveness of visual input and noticing which may assist in the acquisition of Korean. The learners of Korean in this project interacted with their teachers using both voice and text chat programs. The text chat was used during the <b>voice</b> <b>interactions</b> for two purposes: 1. asking questions among one another and their teachers, and 2. {{as a form of}} visual input feedback to each other. The data for this study consists of 1. text chat data, 2. voice communication transcriptions, and 3. learners 2 ̆ 7 journals and reflections. Examining places where noticing occurred, the results show that the learners incorporated the visual input into the <b>interaction</b> in the <b>voice</b> communication sessions...|$|R
50|$|Voice leading is {{the term}} used to {{describe}} the linear progression of melodic lines (<b>voices)</b> and their <b>interaction</b> with one another to create harmonies, according to the principles of common-practice harmony and counterpoint.|$|R
40|$|International audienceDurian the {{promotion}} and applications of rural information, different geographical dialect <b>voice</b> <b>interaction</b> {{is a very}} complex issue. Through in-depth analysis of TTS core technologies, this paper presents the methods of intelligent segmentation, word segmentation algorithm and intelligent voice thesaurus construction in the different dialects context. And then COM based development methodology for specific context voice processing system implementation and programming method. The method has a certain reference value for the rural dialect and voice processing applications...|$|E
40|$|Three {{examples}} of applied systems with a speech interface are {{considered in the}} article. The first two of these provide the end user {{with the opportunity to}} ask verbally the question and to hear the response from the system, creating an addition to the traditional I / O via the keyboard and computer screen. The third example, the «IntonTrainer» system, provides the user with the possibility of <b>voice</b> <b>interaction</b> and is designed for in-depth self-learning of the intonation of oral speech...|$|E
40|$|This paper {{describes}} {{several key}} components of a speech based dialog system. This system was developed to explore opportunities for speech recognition in an integrated office en-vironment. In order to achieve adequate performance despite speech recognition errors, {{it was necessary to}} develop a robust parser and a dialog generator which uses speech syn-thesis to converse with the user. Although designed for a specific application and recog-nition hardware, the underlying approach of the parser and dialog generator may be generalized to facilitate human-computer <b>voice</b> <b>interaction</b> in other environments. ...|$|E
40|$|Abstract—Current {{approaches}} for <b>voice</b> based <b>interaction</b> {{do not meet}} the special requirements of pervasive environments. While there is an increasing trend towards distributed systems, the concept of the classical client/server paradigm still prevails. We describe a framework wherein functional components are orchestrated dynamically, taking into account the users context and the changing availability and suitability of services in pervasive environments. Keywords-voice user interface; modality speech; pervasive environments; ubiquitous computing; I...|$|R
40|$|AbstractAt present, {{virtual world}} environments {{have a huge}} {{potential}} on changing {{the manner in which}} people can interact, navigate on Internet, and make business. Due {{to the fact that the}} virtual world environments become more pervasive, it is important for the researchers to be deeply involved in the understanding of those spaces. The paper describes the main aspects met by tutors and students on working in the Second Life environment, during the on-line course “Designing Technology-Enhanced Learning”, organized in the frame of the European LLP-KA 3 project: “Enabling Creative Collaboration through Supportive Technologies” (code 511733 -LLP- 1 - 2010 - 1 -FI-KA 3 -KA 3 MP). Second Life was chosen due to the fact that provides a strong collaborative environment equipped with modern features: <b>voice</b> <b>interactions,</b> chat and instant messenger, expanding the ways of communication and the possibilities for collaboration. For many Romanian students who participated to the course, it was a unique experience - they were involved in the collaborative work, together with their colleagues from Finland, Estonia and Norway, but also engaged in learning processes that enhanced creative collaboration...|$|R
40|$|HCI International 2009 : 13 th International Conference on Human-Computer Interaction, July 19 - 24, 2009, San Diego, CA, USA. We have {{developed}} a speech input method called “w 3 voice” to build practical and handy voice-enabled Web applications. It is constructed using a simple Java applet and CGI programs comprising free software. In our website ([URL] we have released automatic speech recognition and spoken dialogue applications that are suitable for practical use. The mechanism of voice-based interaction is developed {{on the basis of}} raw audio signal transmissions via the POST method and the redirection response of HTTP. The system also aims at organizing a voice database collected from home and office environments over the Internet. The purpose of the work is to observe actual <b>voice</b> <b>interactions</b> of human-machine and human-human. We have succeeded in acquiring 8, 412 inputs (47. 9 inputs per day) captured by using normal PCs over a period of seven months. The experiments confirmed the user-friendliness of our system in human-machine dialogues with trial users...|$|R
