3|10000|Public
40|$|In this paper, an {{adaptive}} evolutionary multiobjective selection method of RBF Networks structure is discussed. The candidates of RBF Network structures are encoded into particles in Particle Swarm Optimization (PSO). These particles evolve toward Pareto-optimal front defined by several objective functions with model accuracy and complexity. The problem of unsupervised and supervised learning is discussed with Adaptive Multi-Objective PSO (AMOPSO). This study suggests an approach of RBF Network training through simultaneous optimization of architectures and weights with Adaptive PSO-based multi-objective algorithm. Our {{goal is to}} determine whether Adaptive Multi-objective PSO can train RBF Networks, and the performance is <b>validated</b> <b>on</b> <b>accuracy</b> and complexity. The experiments are conducted on two benchmark datasets obtained from the machine learning repository. The results show that our proposed method provides an effective means for training RBF Networks that is competitive with PSO-based multi-objective algorithm. ...|$|E
40|$|The {{problem of}} {{unsupervised}} and supervised learning of RBF networks is discussed with Multi-Objective Particle Swarm Optimization (MOPSO). This study presents an evolutionary multi-objective selection method of RBF networks structure. The candidates of RBF networks structures are encoded into particles in PSO. These particles evolve toward Pareto-optimal front defined by several objective functions with model accuracy and complexity. This study suggests an approach of RBF network training through simultaneous optimization of architectures and connections with PSO-based multi-objective algorithm. Present {{goal is to}} determine whether MOPSO can train RBF networks and the performance is <b>validated</b> <b>on</b> <b>accuracy</b> and complexity. The experiments are conducted on two benchmark datasets obtained from the machine learning repository. The results show that; the best results are obtained for our proposed method that has obtained 100 and 80. 21 % classification accuracy from the experiments made on the data taken from breast cancer and diabetes diseases database, respectively. The results also show that our approach provides an effective means to solve multi-objective RBF networks and outperforms multi-objective genetic algorithm...|$|E
30|$|Content {{validity}} {{was performed}} by two experts in physics education, who reviewed the materials and provided revisions to the learning design, the simulation tools and assessment instruments. These materials were <b>validated</b> <b>on</b> content <b>accuracy</b> and correctness. <b>On</b> {{the basis of the}} evaluation by the experts, some items were revised in terms of wording to provide clarification. The experts also validated the appropriateness of the topics and questions targeted, as well as the alignment of the assessment materials with the technology and other learning materials.|$|R
40|$|The {{reconstruction}} of trees from point clouds that were acquired with terrestrial LiDAR scanning (TLS) {{may become a}} significant breakthrough {{in the study and}} modelling of tree development. Here, we develop an efficient method and a tool based on extensive modifications to the skeletal extraction method that was first introduced by Verroust and Lazarus in 2000. PypeTree, a user-friendly and open-source visual modelling environment, incorporates a number of improvements into the original skeletal extraction technique, making it better adapted to tackle the challenge of tree perennial tissue reconstruction. Within PypeTree, we also introduce the idea of using semi-supervised adjustment tools to address methodological challenges that are associated with imperfect point cloud datasets and which further improve reconstruction accuracy. The performance of these automatic and semi-supervised approaches was tested with the help of synthetic models and subsequently <b>validated</b> <b>on</b> real trees. <b>Accuracy</b> of automatic reconstruction greatly varied in terms of axis detection because small (length < 3. 5 cm) branches were difficult to detect. However, as small branches account for little in terms of total skeleton length, mean reconstruction error for cumulated skeleton length only reached 5. 1 % and 1. 8 % with automatic or semi-supervised reconstruction, respectively. In some cases, using the supervised tools, a perfect {{reconstruction of}} the perennial tissue could be achieved...|$|R
40|$|Alternative {{splicing}} acts on transcripts {{from almost}} all human multi-exon genes. Notwithstanding its ubiquity, fundamental ramifications of splicing on protein expression remain unresolved. The number and identity of spliced transcripts that form stably folded proteins remain {{the sources of}} considerable debate, due largely to low coverage of experimental methods and the resulting absence of negative data. We circumvent this issue by developing a semi-supervised learning algorithm, positive unlabeled learning for splicing elucidation (PULSE; [URL] which uses 48 features spanning various categories. We <b>validated</b> its <b>accuracy</b> <b>on</b> sets of bona fide protein isoforms and directly on mass spectrometry (MS) spectra for an overall AU-ROC of 0. 85. We predict that around 32 % of “exon skipping” alternative splicing events produce stable proteins, suggesting that the process engenders {{a significant number of}} previously uncharacterized proteins. We also provide insights into the distribution of positive isoforms in various functional classes and into the structural effects of alternative splicing...|$|R
40|$|We {{introduce}} {{machine learning}} models of quantum mechanical observables of atoms in molecules. Instant out-of-sample predictions for proton and carbon nuclear chemical shifts, atomic core level excitations, and forces <b>on</b> atoms reach <b>accuracies</b> <b>on</b> par with density functional theory reference. Locality is exploited within nonlinear regression via local atom-centered coordinate systems. The approach is <b>validated</b> <b>on</b> a diverse set of 9 k small organic molecules. Linear scaling of computational cost in system size is demonstrated for saturated polymers {{with up to}} submesoscale lengths...|$|R
40|$|Therapists and clinicians {{have been}} {{combining}} virtual reality (VR) systems for rehabilitation purposes with motion capture systems to accurately {{keep track of}} the users' movements and better analyze their kinematic performance. The current state-of-the-art motion capture technology is limited to the clinical setting due to its cost, the necessity for a controlled environment, requirement of additional equipment, among others. Given the benefits of home-based rehabilitation protocols, more portable and cost-effective technology is being coupled with the VR systems. In this work, we focus <b>on</b> <b>validating</b> the <b>accuracy</b> of the Kinect™ camera from Microsoft. We compare its performance to a current state-of-the-art motion capture system. Namely, we 1) analyze the difference between the outcome metrics computed with data collected with the Kinect™ camera and the outcome metrics computed with data collected with the motion capture system, and 2) compare the spatial trajectories generated by both systems for the hand, elbow, and shoulder joints. Data were collected from ten able-bodied adults to quantify these comparisons. In general, results from both analyzes support the validity and feasibility of using the Kinect™ camera for home-based rehabilitation purposes...|$|R
40|$|This paper reports two novel {{algorithms}} {{based on}} time-modulo reconstruction method intended for detection of the parametric faults in analogue-to-digital converters (ADC). In both algorithms, a pulse signal, in its slightly adapted form to allow sufficient time for converter settling, {{is taken as}} the test stimulus reliving the burden placed <b>on</b> <b>accuracy</b> requirement of excitation source. The objective of the test scheme is not to completely replace traditional specificationbased tests, but to provide a reliable method for early identification of excessive parameter variations in production test that allows quickly discarding {{of most of the}} faulty circuits before going through the conventional test. The efficiency of the methods is <b>validated</b> <b>on</b> a 6 -bit flash ADC...|$|R
40|$|Abstract—Non-collinear edge pixels are {{equivalent}} to noise for the linear Hough transform (LHT). Existing methods that {{reduce the number}} of points for Hough voting are based on random and/or probabilistic selection. Such methods select both collinear and noisy pixels, thereby incurring unwanted computational costs. In this paper, we propose a novel gradient angle histogram based technique to generate modified straight line edge map (SLEM), which largely retains the straight line edges and eliminates noisy edge pixels. A block-based SLEM generation is proposed to increase the robustness of straight line extraction and <b>validated</b> <b>on</b> test images. Further, effect of varying block sizes <b>on</b> <b>accuracy</b> of straight line detection is studied and appropriate block settings are derived. The proposed gradient angle histogram based method reduces the number of edge pixels by as much as 85 %. I...|$|R
50|$|Original 37-39 {{passenger}} {{version that}} entered service in 1984. The original engine was the PW120A (CAA <b>validated</b> <b>on</b> December 13, 1985); later units used the PW121 (CAA <b>validated</b> <b>on</b> February 22, 1990). Rated engine power is 1,800 shp (1,340 kW).|$|R
40|$|Nucleoside reverse {{transcriptase}} inhibitors (NRTIs) {{are a key}} class of drugs {{for the treatment of}} HIV infection. NRTIs are intracellularly phosphorylated to their active triphosphate metabolites and compete with endogenous deoxynucleotides (dNTP) for substrate binding. It is therefore important to analyze the intracellular concentrations of these compounds to understand drug efficacy and toxicity. To that purpose an analytical platform was developed that is capable of analyzing 8 NRTIs, 12 phosphorylated NRTIs and 4 dNTPs in small numbers of peripheral blood mononuclear cells, i. e. 1 × 106 cells. The platform consists of two liquid chromatography-tandem mass spectrometry (LC-MS/MS) methods: a reversed-phase method for NRTIs using positive electrospray ionization (ESI) and an ion-pair LC-MS/MS method for the phosphorylated compounds using negative ESI. The methods use the same LC-MS system and column and changing from one method to the other only includes changing the mobile phase. The methods were partially <b>validated,</b> focussing <b>on</b> sensitivity, <b>accuracy</b> and precision. Successful transfer of the methods to ultra performance liquid chromatography (UPLC) led to a significant improvement of speed for the analysis of NRTIs and sensitivity for both NRTIs and phosphorylated NRTIs. The latter was demonstrated by the improved separation by UHPLC of dGTP vs. AZT-TP and ATP which made direct analysis of dGTP possible using the optimal MS/MS transition thereby significantly improving the detection limit of dGTP. Typically LLOQs observed for both the NRTIs and phosphorylated NRTIs were 1 nM, while the mean accuracy varied between 82 and 120 % and inter- and intra-assay precision was generally < 20 %. © 2011 Elsevier B. V...|$|R
40|$|The down {{conversion}} of radio frequency components around the harmonics {{of the local}} oscillator (LO), and its impact <b>on</b> the <b>accuracy</b> of white space detection using integrated spectrum sensors, is studied. We propose an algorithm to mitigate the impact of harmonic downconversion by utilizing multiple parallel downconverters in the system architecture. The proposed algorithm is <b>validated</b> <b>on</b> a test-board using commercially available integrated circuits and a test-chip implemented in a 130 -nm CMOS technology. The measured data show {{that the impact of}} the harmonic downconversion is closely related to the LO characteristics, and that much of it can be mitigated by the proposed technique...|$|R
5000|$|The models used {{to produce}} the data are <b>validated</b> <b>on</b> a case by case basis.|$|R
50|$|The sole miracle {{needed for}} his sanctification was {{investigated}} and was <b>validated</b> <b>on</b> 25 November 2005.|$|R
40|$|Major {{advances}} in Question Answering technology were needed for IBM Watson 1 to play Jeopardy! 2 at championship level – the show requires rapid-fire answers to challenging natural language questions, broad general knowledge, high precision, and accurate confidence estimates. In addition, Jeopardy! features {{four types of}} decision making carrying great strategic importance: (1) Daily Double wagering; (2) Final Jeopardy wagering; (3) selecting the next square when {{in control of the}} board; (4) deciding whether to attempt to answer, i. e., “buzz in. ” Using sophisticated strategies for these decisions, that properly account for the game state and future event probabilities, can significantly boost a player’s overall chances to win, when compared with simple “rule of thumb ” strategies. This article presents our approach to developing Watson’s game-playing strategies, comprising development of a faithful simulation model, and then using learning and Monte-Carlo methods within the simulator to optimize Watson’s strategic decision-making. After giving a detailed description of each of our game-strategy algorithms, we then focus in particular <b>on</b> <b>validating</b> the <b>accuracy</b> of the simulator’s predictions, and documenting performance improvements using our methods. Quantitative performance benefits are shown with respect to both simple heuristic strategies, and actual human contestant performance in historical episodes. We further extend our analysis of human play to derive a number of valuable and counterintuitive examples illustrating how human contestants may improve their performance on the show. 1...|$|R
30|$|Effect of {{question}} types <b>on</b> <b>accuracy</b> score.|$|R
30|$|Effect of zoom level <b>on</b> <b>accuracy</b> score.|$|R
30|$|Effect {{of number}} of changes <b>on</b> <b>accuracy</b> score.|$|R
30|$|Effect {{of number}} of correct answers <b>on</b> <b>accuracy.</b>|$|R
30|$|Effect {{of number}} of drags <b>on</b> <b>accuracy</b> score.|$|R
30|$|Effect of {{staleness}} of data <b>on</b> <b>accuracy</b> score.|$|R
30|$|Effect of time {{to answer}} <b>on</b> <b>accuracy</b> score.|$|R
30|$|Effects of {{ordering}} of questions <b>on</b> <b>accuracy</b> score.|$|R
2500|$|... insistence <b>on</b> <b>accuracy</b> for all {{scientific}} instruments and observations; ...|$|R
30|$|Effect {{of number}} of zoom in/out <b>on</b> <b>accuracy</b> score.|$|R
30|$|Effect of {{staleness}} of {{the data}} <b>on</b> <b>accuracy</b> score.|$|R
5000|$|... insistence <b>on</b> <b>accuracy</b> for all {{scientific}} instruments and observations; ...|$|R
50|$|The {{score was}} <b>validated</b> <b>on</b> the dataset from 17,440 adult medical/surgical {{intensive}} care unit (ICU) admissions at 40 US hospitals.|$|R
30|$|Effect {{of total}} number of answer choices <b>on</b> <b>accuracy</b> score.|$|R
3000|$|..., are <b>validated</b> <b>on</b> data {{simulated}} {{in shallow}} water for different configurations. The performance of localization, in depth and distance, is very satisfactory.|$|R
3000|$|Reproducibility and {{clinical}} value of radiomic features should be firstly tested with internal cross-validation and then <b>validated</b> <b>on</b> independent external cohorts [...]...|$|R
30|$|The {{model is}} <b>validated</b> <b>on</b> three {{important}} aspects: container load, observed peak demand, and handling time. All three aspects are discussed below.|$|R
30|$|Methods are <b>validated</b> <b>on</b> {{a limited}} set of {{vertebrae}} {{in terms of}} scope (lumbar, thoracic, or cervical) and healthiness (middle-aged patient, healthy cases).|$|R
50|$|On 7 March 2014, Keirrison agreed a free {{transfer}} with Coritiba {{which was}} <b>validated</b> <b>on</b> 1 July, after {{his contract with}} Barcelona terminated.|$|R
30|$|Predict S cv and get {{the cross}} {{validation}} (CV) (based <b>on</b> <b>accuracy</b> rate).|$|R
50|$|Physical {{exercise}} can also include training that focuses <b>on</b> <b>accuracy,</b> agility, power, and speed.|$|R
