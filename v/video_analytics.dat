233|82|Public
5|$|In February 2013, in {{partnership}} with DriveCam, Greyhound deployed video cameras across its entire fleet to increase safety and driver compliance by combining data and <b>video</b> <b>analytics</b> with real-time driver feedback and coaching.|$|E
25|$|Xbox One {{consoles}} {{ship with}} {{an updated version}} of Kinect; the new Kinect uses a wide-angle time-of-flight camera, and processes 2 gigabits of data per second to read its environment. The new Kinect has greater accuracy with three times the fidelity over its predecessor and can track without visible light by using an active IR sensor. It has a 60% wider field of vision that can detect a user up to 3 feet from the sensor, compared to six feet for the original Kinect, and can track up to 6 skeletons at once. It can also detect a player's heart rate, facial expression, the position and orientation of 25 individual joints (including thumbs), the weight put on each limb, speed of player movements, and track gestures performed with a standard controller. The color camera captures 1080p video that can be displayed in the same resolution as the viewing screen, allowing for a broad range of scenarios. In addition to improving video communications and <b>video</b> <b>analytics</b> applications, this provides a stable input on which to build interactive applications. Kinect's microphone is used to provide voice commands for actions such as navigation, starting games, and waking the console from sleep mode.|$|E
50|$|Online <b>video</b> <b>analytics</b> (also {{known as}} Web <b>video</b> <b>analytics)</b> is the measurement, {{analysis}} and reporting of videos viewed online. It {{is used for}} the purposes of understanding the consumption patterns (behavioral analysis) and optimizing viewing experience (quality of service analysis).|$|E
40|$|Movement {{classification}} {{or activity}} analysis {{is one of}} the most important areas in video surveillance. However, manually detecting, classifying and analyzing interesting moving objects by humans does not guarantee absolute correctness. When considering thereal environment and trying to relate the way objects interact in a surveillance covered area, it is not so easy interpreting every activity correctly. These challenges posed by defining and classifying objects ‟ behaviours as normal or abnormalmovements. These challengescan be tackled using <b>video</b> <b>analytic</b> technologies. The objective of <b>video</b> <b>analytic</b> technologies is to detect the presence of objects that are moving in its field of view and to classify their movements for security, traffic monitoring and safety applications. There are a lot of hurdles faced by <b>video</b> <b>analytic</b> systems that impede their ability to perform accurately. This study presents a review of movement classification techniques and algorithms, which can tackle the challenges of realistic and practical outdoor surveillance scenarios. Keywords movement classification; video forensic; cortical learning algorithms; post incidence analysis; <b>video</b> <b>analytic</b> 1...|$|R
50|$|Several {{articles}} {{provide an}} overview of the modules involved in the development of <b>video</b> <b>analytic</b> applications.This is a list of known functionalities and a short description.|$|R
50|$|In March 2015, Integral {{acquired}} Veenome, a DC-based <b>video</b> advertising <b>analytics</b> company.|$|R
5000|$|Media {{measurement}} (<b>video</b> <b>analytics</b> for websites; desktop only) ...|$|E
5000|$|Signal Innovations Group - signal, image, and <b>video</b> <b>analytics</b> ...|$|E
50|$|The v1.0 <b>Video</b> <b>Analytics</b> Specification (VAS) {{specifies}} an interface {{that enables}} IP devices and video management/surveillance systems to communicate <b>video</b> <b>analytics</b> {{data in a}} standardized way. The scope for the initial release of the specification focuses entirely on <b>video</b> <b>analytics</b> capabilities discovery and analytic data output. Video analytic capabilities discovery will include standard configuration data exchange to enable any analytic device to communicate to another device or application its basic analytic capabilities at the device level and the video channel level (for multichannel devices). This includes information such as the PSIA VAS version number supported, analytic vendor information (name, software version number, etc.), event types and mechanisms supported, and other supported configurations. From an analytic output perspective, the v1.0 VAS includes the definition of multiple types of analytic events, including alerts and counts, as well as <b>video</b> <b>analytics</b> metadata output.|$|E
40|$|Intelligent Surveillance Systems is {{attracting}} unprecedented attention from research and industry. In this paper, we describe a real-life trial system where various <b>video</b> <b>analytic</b> systems {{are used to}} detect events and objects of interests in a mass transport environment. The system configuration and architecture of this system is presented. In addition to implementation and scalability challenges, we discuss issues related to on-going trials in public spaces incorporating existing surveillance hardware...|$|R
40|$|Myotonia congenita {{is a human}} muscle {{disorder}} caused by mutations in CLCN 1, which encodes human chloride channel 1 (CLCN 1). Zebrafish is becoming an increasingly useful model for human diseases, including {{muscle disorder}}s. In this study, we generated transgenic zebrafish expressing, {{under the control of}} a muscle specific promoter, human CLCN 1 carrying mutations that have been identified in human patients suffering from myotonia congenita. We developed <b>video</b> <b>analytic</b> tools that are able to provide precise quantitative measurements of movement abnormalities in order to analyse the effect of these CLCN 1 mutations on adult transgenic zebrafish swimming. Two new parameters for body-wave kinematics of swimming reveal changes in body curvature and tail offset in transgenic zebrafish expressing the disease-associated CLCN 1 mutants, presumably due to their effect on muscle function. The capability of the developed <b>video</b> <b>analytic</b> tool to distinguish wild-type from transgenic zebrafish could provide a useful asset to screen for compounds that reverse the disease phenotype, and may be applicable to other movement disorders besides myotonia congenita...|$|R
40|$|Abstract- Intelligent Surveillance Systems is {{attracting}} unprecedented attention from research and industry. In this paper, we describe a real-life trial system where various <b>video</b> <b>analytic</b> systems {{are used to}} detect events and objects of interests in a mass transport environment. The system configuration and architecture of this system is presented. In addition to implementation and scalability challenges, we discuss issues related to on-going trials in public spaces incorporating existing surveillance hardware. I...|$|R
5000|$|Virtual Center of Excellence for Ethically-guided and Privacy-respecting <b>Video</b> <b>Analytics</b> (VIDEOSENSE) ...|$|E
50|$|In many domains VCA is {{implemented}} on CCTV systems, either distributed on the cameras (at-the-edge) or centralized on dedicated processing systems. <b>Video</b> <b>Analytics</b> and Smart CCTV are commercial terms for VCA {{in the security}} domain. In the UK the BSIA has developed an introduction guide for VCA in the security domain. In addition to <b>video</b> <b>analytics</b> and to complement it, audio analytics can also be used.|$|E
5000|$|Distributed {{intelligence}} such as <b>video</b> <b>analytics</b> can {{be placed}} in the camera itself allowing the camera to analyze images.|$|E
3000|$|Figures 1, 2, 3, 4 and 7, 8, 9, 10, 11, 12, 13 {{result from}} <b>video</b> <b>analytic</b> {{research}} at the Department for Philosophy of Education at Humboldt-University Berlin. Rights {{to the use of}} the images are with the authors. Figures 5 and 6 result from work with the program Feldpartitur ([URL] The symbols of different gestures of showing in Fig. 6 were developed by the Feldpartitur-team following a suggestion of the research team at the Department Humboldt-University ([URL] [...]...|$|R
50|$|Video content {{analysis}} (also <b>Video</b> content <b>analytics,</b> VCA) is {{the capability of}} automatically analyzing video to detect and determine temporal and spatial events.|$|R
5000|$|The EU {{is funding}} a FP7 project called P-REACT [...] to {{integrate}} <b>video</b> content <b>analytics</b> on embedded systems with police and transport security databases.|$|R
50|$|Ipsotek is an {{organisation}} that specialises in Video Content Analysis (VCA) , {{also known}} as Video Content (VA) or Intelligent <b>Video</b> <b>Analytics</b> (IVA).|$|E
50|$|With the {{introduction}} of real-time <b>video</b> <b>analytics</b> into its video processors, the company is targeting the automotive camera/HUD, surveillance, and cloud-based consumer camera markets.|$|E
50|$|The <b>Video</b> <b>Analytics</b> {{industry}} {{was estimated to}} be worth $7.5bn in 2012 and is forecasted to reach $21bn by 2020 according to Homeland Security Marketing Research report.|$|E
5000|$|<b>Video</b> Pulse, an <b>analytics</b> {{tool that}} can collect {{feedback}} from any recorded video ...|$|R
40|$|A {{synthetic}} video dataset, scenario, and task {{were included in}} the 2009 VAST Challenge, to allow participants an opportunity to demonstrate visual analytic tool use on video data. This is the first time a video challenge had been presented as part of the VAST contest and provided interesting challenges in task and dataset development, <b>video</b> <b>analytic</b> tool development, and metrics for judging entries. We describe the considerations and requirements for generation of a usable challenge, the video creation itself, and some submissions and assessments from that mini-challenge. Categories and Subject Descriptors H 5. 1. [Information interfaces and presentation]: Multimedia Information Systems – evaluation / methodology...|$|R
40|$|Kinematic {{analysis}} of the upper extremity has been conducted using {{a wide variety of}} techniques, philosophies, and analytic methods. We describe a simple, marker-based three-dimensional <b>video</b> <b>analytic</b> technique that borrows concepts from lower extremity kinematic analysis. A sequential rotation order about orthogonal axes is described, although alternate methods are examined as well. The method has been verified by application to a mechanical model. In certain positions, gimbal lock may occur, and a different sequence of rotational decomposition may be required. Agreement on standardization of technique would assist in the dissemination of upper extremity scientific data. © 2002 Elsevier Science B. V. All rights reserved...|$|R
50|$|In 2008, {{the company}} {{launched}} Aimetis Symphony intelligent video management software, {{which has become}} {{the cornerstone of the}} company’s product line. Aimetis Symphony combines both video management and <b>video</b> <b>analytics</b> into a single product. After the release of Symphony, the company was subsequently awarded the 2008 Global <b>Video</b> <b>Analytics</b> Product Innovation of the Year Award from Frost & Sullivan. Also in 2008, Aimetis broke into the Top 10 market share for VMS in terms of revenue for the first time, ranking seventh overall for software-only vendors of open platform network video management software.|$|E
5000|$|Ipsotek holds i-LIDS Primary Classification for sterile zone monitoring. i-LIDS is a {{government}} initiative to benchmark <b>video</b> <b>analytics</b> (VA) systems and give classification to those that meet Government requirements.|$|E
50|$|Conviva sells {{a control}} {{platform}} said to pre-emptively locate video streaming issues and make adjustments to avoid buffering and low quality. Conviva also provides online <b>video</b> <b>analytics</b> on viewer engagement and video performance.|$|E
5000|$|... #Subtitle level 3: 4th Generation: <b>Video</b> and WiFi <b>Analytics</b> with <b>Video</b> Footage (2017 to Present) ...|$|R
40|$|A <b>video</b> <b>analytic</b> system {{includes}} a depth stream sensor, spatial analysis module, temporal analysis module, and analytics module. The spatial analysis module iteratively identifies objects of interest based on local maximum or minimum depth stream values within each frame, removes identified objects of interest, and repeats until all objects of interest have been identified. The temporal analysis module associates each {{object of interest}} in the current frame with an object of interest identified in a previous frame, wherein the temporal analysis module utilizes the association between current frame objects of interest and previous frame objects of interest to generate temporal features related to each object of interest. The analytics module detects events based on the received temporal features...|$|R
40|$|Abstract—This paper {{proposes a}} color-based <b>video</b> <b>analytic</b> system for {{quantifying}} limb movements in epileptic seizure monitoring. The system utilizes colored pyjamas to facilitate limb segmentation and tracking. Thus, it is unobtrusive and requires no sensor/marker attached to patient’s body. We employ Gaussian mixture models in background/foreground modeling, and detect limbs through a coarse-to-fine paradigm with graphcut-based segmentation. Next, we estimate limb parameters with domain knowledge guidance, and extract displacement and oscillation features from movement trajectories for seizure detection/analysis. We report studies on sequences captured in an epilepsy monitoring unit. Experimental evaluations {{show that the}} proposed system has achieved comparable performance to EEG-based systems in detecting motor seizures. Index Terms—Epilepsy, seizure, movement quantification, video, monitoring, color-based. I...|$|R
50|$|In February 2013, in {{partnership}} with DriveCam, Greyhound deployed video cameras across its entire fleet to increase safety and driver compliance by combining data and <b>video</b> <b>analytics</b> with real-time driver feedback and coaching.|$|E
50|$|In February 2008, TubeMogul raised $3 {{million in}} Series A funding led by Trinity Ventures. In October 2008, they {{acquired}} Illuminex, a <b>video</b> <b>analytics</b> company founded by Jason Lopatecki and Adam Rose, {{for an undisclosed}} amount.|$|E
5000|$|IP Camera Reference Design runs {{standard}} Linux 2.6 {{and supports}} multiple simultaneous codecs (e.g. H.264, MPEG-4 and MJPEG), arbitrary resolutions, CMOS and CCD sensor processing {{as well as}} <b>video</b> <b>analytics</b> in a fully software programmable platform ...|$|E
2500|$|There are {{considerable}} {{differences between}} the video game genres preferred, on average, by women and men. According to a 2017 report by the <b>video</b> game <b>analytics</b> company Quantic Foundry, based on surveys of about 270,000 gamers, the following proportions of gamers within a genre are women or men, respectively: ...|$|R
5000|$|Enpocket Platform: {{a mobile}} {{campaign}} management and delivery system combining multi-modal mechanics, including SMS, MMS, WAP advertising, and <b>video</b> with predictive <b>analytics</b> ...|$|R
50|$|The <b>Video</b> Coding & <b>Analytics</b> {{department}} is researching actively the efficient encoding, transport, {{processing and analysis}} of video signals as well as machine learning.|$|R
