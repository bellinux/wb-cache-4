33|91|Public
5000|$|He {{assumes that}} the {{solutions}} are monochromatic and uses the phasor expressions [...] , [...] The time average of the Poynting vector momentum density is then given by We have used Maxwell's equations in passing from the first to {{the second and third}} lines, and in expression such as [...] the scalar product is between the fields so that the <b>vector</b> <b>character</b> is determined by the [...]|$|E
50|$|Like the {{previous}} installments of the series, the player takes control of Shantae, a half-genie who can use her hair as a whip to attack enemies. Throughout the game, Shantae can obtain dances that {{allow her to}} transform into various forms, each with their own abilities. Along with returning abilities, such as the monkey and elephant transformations, new forms include a bat that can cross long gaps, a crab that can maneuver underwater, and a mouse that can crawl into small mazes. These transformations can be further upgraded with new abilities. The game is divided up into several action stages, which can be replayed to obtain new items that become accessible {{with the use of}} certain powers, some of which are required to progress through the story. A new magic meter is added to the game, which allows Shantae to use unlocked spells at will instead of purchasing them individually. The game is presented in high definition, with 2D <b>vector</b> <b>character</b> sprites on 3D environments, unlike previous entries' dedicated pixel art aesthetic.|$|E
40|$|We {{develop a}} field theory {{approach}} to light propagation in a gas of resonant atoms {{taking into account}} <b>vector</b> <b>character</b> of light and atom-atom interactions. Within this approach, we calculate the propagator of the electric field for both short and long-range density-density correlation functions of the gas. Comment: 22 pages, 1 figur...|$|E
5000|$|Any simple ALGOL 68RS object {{could be}} cast into a <b>vector</b> of <b>characters</b> using the spell operator: ...|$|R
40|$|When {{a person}} composes a {{document}} by hand, there is random variability {{in what is}} produced. That is, every letter is different from all others. If the person produces seven a s, none will be the same. This is not true when a computer prints something. When the computer produces seven a s they are all exactly the same. However, even with the variability inherent in a person s handwriting, when two people write something and they are compared side by side, they often appear as different as fonts from two computer families. In fact, if the two were intermixed to produce some text that has characters from each hand, it would not look right! The goal of this application {{is to improve the}} ability to digitally create testing materials (i. e., data collection documents) that give the appearance of being filled out manually (that is, by a person). We developed a set of capabilities that allow us to generate digital test decks using a raster database of handprinted characters, organized into hands (a single person s handprint). We wish to expand these capabilities using <b>vector</b> <b>characters.</b> The raster database has much utility to produce digital test deck materials. <b>Vector</b> <b>characters,</b> it is hoped, will allow greater control to morph the digital test data, within certain constraints. The long-term goal is to have a valid set of computer-generated hands that is virtually indistinguishable from characters created by a person...|$|R
5000|$|... #Caption: Arkham Knight's <b>character</b> <b>vector,</b> {{featured}} in the mobile version of the 2013 game, Injustice.|$|R
40|$|CNC. ? ?????? ??????? ???????? ????????? ???????? ??????? ???????????, ? ????? ???????????? ????? ????????????? ??????? ????????? ?????????? ???? ??? ??????? ?????. Offered {{paper is}} {{the second part of}} a cycle of papers devoted to a {{substantiation}} of the term of zoned accuracy of machine tools with CNC. In the second part <b>vector</b> <b>character</b> of an error of measurement is shown, and also the choice of the mathematical device of a gradient of a scalar field for its description is proved. ???????????? ?????? ???????? ?????? ?? ?????? ????? ?????? ??????????? ??????????? ??????? ?????? ???????? ??????? ? ???. ?? ?????? ????? ??????? ????????? ???????? ??????????? ?????????, ? ????? ????????? ????? ??????????????? ???????? ????????? ?????????? ???? ??? ?? ????????...|$|E
40|$|The “hard problem ” is {{considered}} vis-à-vis Gödel’s work on formal systems, tensor network theory, the <b>vector</b> <b>character</b> of sensory qualities, the symmetries and phase relations of those qualities and Heisenberg’s matrix formulation of quantum theory. An identity {{is considered}} vis-à-vis the secondary properties of perception and (1) the hidden variables of quantum theory; (2) the internal spaces of gauge theory; and (3) the additional dimensions of M-theory...|$|E
40|$|We {{develop a}} perturbative {{treatment}} of induced dipole-dipole interactions in the diffusive transport of electromagnetic waves through disordered atomic clouds. The approach is exact at order {{two in the}} atomic density and accounts for the <b>vector</b> <b>character</b> of light. It {{is applied to the}} calculation of the electromagnetic energy stored in the atomic cloud - which modifies the energy transport velocity - and of the light scattering and transport mean free paths. Results are compared to those obtained from a purely scalar model for light. Comment: revised versio...|$|E
40|$|The U. S. Nuclear Regulatory Commission’s (USNRC) Standardized Plant Analysis Risk (SPAR) Level 2 {{models for}} U. S. {{commercial}} {{nuclear power plants}} has historically used a partitioning approach for plant damage state (PDS) binning and model quantification since late 1990 s [1]. While this approach has the advantage {{to be able to}} identify the details of the severe accident sequences with one or more individual PDS <b>vector</b> <b>characters,</b> the Level 2 model quantification process is tedious and error-prone with multiple steps involved. A new approach to quantify Level 2 SPAR models was recently developed and implemented in the latest SAPHIRE Version 8 [2]. The new approach removes the partition rules and greatly simplifies the quantification process...|$|R
5000|$|... #Caption: Visualized motion <b>vectors.</b> The {{foreground}} <b>character's</b> rotating downward {{head movement}} is visible, {{as well as}} the background character's slower upward head movement.|$|R
40|$|Weak {{interactions}} are {{described by the}} Standard Model which uses the basic assumption of a pure “V(ector) -A(xial <b>vector)</b> ” <b>character</b> for the interaction. However, after {{more than half a}} century of model development and experimental testing of its fundamental ingredients, experimental limits for possible admixtures of scalar and/or tensor {{interactions are}} still as high as 7...|$|R
40|$|Abstract: We {{construct}} a lattice gauge theory using reduced staggered fermions and gauge fields {{which provides a}} non-perturbative realization of a complete technicolor model; one which treats both strong and weakly coupled gauge symmetries on an equal footing. We show that the model is capable of developing a Higgs phase at non zero lattice spacing via the formation of fermion condensates. We further show that while the broken symmetry associated with this phase has a <b>vector</b> <b>character</b> in the lattice theory it is realized as an axial symmetry in the continuum limit {{in agreement with the}} Vafa Witten theorem...|$|E
40|$|Giant caloric {{effects were}} {{reported}} in elasto-, electro- and magnetocaloric materials near phase transformations. Commonly, their entropy change is indirectly evaluated by a Maxwell relation. We report the fundamental failure of this approach. We analyze exemplarily the Ni-Mn-Ga magnetic shape memory alloy. An applied field results in magnetically induced reorientation of martensitic variants, which form during the phase transformation. This results in a spurious magnetocaloric effect, which only disappears when repeating the measurement a second time. This failure is universal as the <b>vector</b> <b>character</b> of the applied field is not considered in the common scalar evaluation of a Maxwell relation. Comment: 8 pages, 4 figure...|$|E
40|$|As {{discovered}} by Philip Anderson in 1958, strong disorder can block propagation of waves {{and lead to}} the localization of wave-like excitations in space. Anderson localization of light is particularly exciting in view of its possible applications for random lasing or quantum information processing. We show that, surprisingly, Anderson localization of light cannot be achieved in a random three-dimensional ensemble of point scattering centers that is the simplest and widespread model to study the multiple scattering of waves. Localization is recovered if the <b>vector</b> <b>character</b> of light is neglected. This shows that, at least for point scatterers, the polarization of light {{plays an important role}} in the Anderson localization problem. Comment: 5 pages, 3 figures. Definitions after Eq. (2) and a couple of misprints correcte...|$|E
40|$|Chain­coded {{contours}} are informative in off­line character recognition. As approximations to contours, {{sequences of}} pseudo­strokes consisting of both positional and directional information make up feature <b>vectors</b> for <b>character</b> images. In order {{to carry out}} fast pattern matching, a scheme of generating fixed­length feature vectors that combine information about outer contour and inner contours into a uniform data structure is proposed and tested on CEDAR databases...|$|R
40|$|Microsoft, Motorola, Siemens, Hitachi, IAPR, NICI, IUF Chain­coded {{contours}} are informative in off­line character recognition. As approximations to contours, {{sequences of}} pseudo­strokes consisting of both positional and directional information make up feature <b>vectors</b> for <b>character</b> images. In order {{to carry out}} fast pattern matching, a scheme of generating fixed­length feature vectors that combine information about outer contour and inner contours into a uniform data structure is proposed and tested on CEDAR databases. ...|$|R
30|$|We denote scalar {{values by}} either lower or upper case {{standard}} weight <b>characters,</b> <b>vectors</b> as lower case bold characters and matrices as bold uppercase characters. For simplicity, {{we have not}} distinguished between random variables and instances of random variables, as such can be ascertained through context.|$|R
40|$|How {{does the}} {{experience}} of a riding in a roller coaster loop depend on your position in the train? This question has been investigated by first year engineering physics students, using multiple representations of force and motion. Theoretical considerations for a circular loop show that the differences between the forces on a rider in the front, middle or back of the train depend on the ratio between train length and radius of the loop, which can be estimated from a photograph. Numerical computations complement the analysis of a video clip, accelerometer data and measurements of time needed for the train to move over the highest point. A roller coaster ride gives striking examples of Newton’s laws applied to your own body, and demonstrates that the experience depends on the <b>vector</b> <b>character</b> of velocity and acceleration...|$|E
40|$|We {{construct}} a lattice gauge theory using reduced staggered fermions and gauge fields {{which provides a}} non-perturbative realization of a complete technicolor model; one which treats both strong and weakly coupled gauge sectors on an equal footing. We show that the model is capable of developing a Higgs phase at non zero lattice spacing via the formation of fermion condensates. We further show that while the broken symmetry associated with this phase has a <b>vector</b> <b>character</b> in the lattice theory it is realized as an axial symmetry in the continuum limit {{in agreement with the}} Vafa Witten theorem. We discuss our result in the context of universalityComment: 13 pages, 6 figures. New figures added and minor changes to text. arXiv admin note: text overlap with arXiv: 1306. 566...|$|E
40|$|In {{this paper}} have written {{the results of}} the {{information}} analysis of structures. The obtained information estimation (IE) are based on an entropy measure of C. Shannon. Obtained IE is univalent both for the non-isomorphic and for the isomorphic graphs, algorithmically, it is asymptotically steady and has <b>vector</b> <b>character.</b> IE can be used for the solution of the problems ranking of structures by the preference, the evaluation of the structurization of subject area, the solution of the problems of structural optimization. Information estimations and method of the information analysis of structures it can be used in many fields of knowledge (Electrical Systems and Circuit, Image recognition, Computer technology, Databases and Bases of knowledge, Organic chemistry, Biology and others) and it can be base for the structure calculus. Comment: PDF, 5 pages, 2 figure...|$|E
40|$|We {{introduce}} {{a model for}} constructing vector representations of words by composing characters using bidirectional LSTMs. Relative to traditional word representation models that have independent vectors for each word type, our model requires only a single <b>vector</b> per <b>character</b> type and a fixed set of parameters for the compositional model. Despite the compactness of this model and, more importantly, the arbitrary nature of the form-function relationship in language, our "composed" word representations yield state-of-the-art results in language modeling and part-of-speech tagging. Benefits over traditional baselines are particularly pronounced in morphologically rich languages (e. g., Turkish) ...|$|R
40|$|The spatial {{correlations}} of the monomer displacements are studied via molecular-dynamics simulations of a melt of fully flexible, unentangled polymer chains with different length, interacting potential, density, and temperature. Both the scalar and the <b>vector</b> <b>characters</b> of the correlations are considered and their extension quantified {{in terms of}} suitable dynamical correlation lengths. Displacements performed at both short, i. e., vibrational, and long times, i. e., comparable to the structural relaxation time, are investigated. On both time scales the spatial correlations are modulated according to the radial distribution function g(r) to an extent which {{is determined by the}} character of the correlations, the time scale of the displacements and the structural slowing down. The spatial {{correlations of}} the short-time displacements have clear directional character. The modulus correlations of the long-time displacements are more marked, especially for sluggish states. Analogous findings are found by experiments on colloids. By inspecting the dynamical heterogeneities of states with slowed-down dynamics, it is observed that fast monomers exhibit correlations which are stronger and more differing from the bulk than the slow ones. It is shown that states with identical average vibrational monomer displacement exhibit identical spatial correlations of the monomer displacements pertaining to the subsets of the fast and the slow monomers characterizing both the short-time and the long-time dynamical heterogeneities. (C) 2012 American Institute of Physics. [[URL]...|$|R
50|$|Common Lisp {{supports}} multidimensional arrays, and can dynamically resize adjustable arrays if required. Multidimensional arrays can be {{used for}} matrix mathematics. A vector is a one-dimensional array. Arrays can carry any type as members (even mixed types in the same array) or can be specialized to contain a specific type of members, as in a vector of bits. Usually only a few types are supported. Many implementations can optimize array functions when the array used is type-specialized. Two type-specialized array types are standard: a string is a <b>vector</b> of <b>characters,</b> while a bit-vector is a vector of bits.|$|R
40|$|Polarization state selection, {{polarization}} state dynamics, and polarization switching of a quantum-well Vertical Cavity Surface Emitting Laser for {{the lowest}} order transverse spatial mode of the laser is explored using a recently developed model that incorporates material birefringence, the saturable dispersion characteristic of semiconductor physics,and {{the sensitivity of the}} transitions in the material to the <b>vector</b> <b>character</b> of the electric field amplitude. Three features contribute to the observed linearly polarized states of emission: linear birefringence, linear gain or loss anisotropies, and an intermediate relaxation rate for imbalances in the populations of the magnetic sublevels. In the absence of either birefringence or saturable dispersion, the gain or loss anisotropies dictate stability for the stronger linearly polarized mode and switching is only possible if the relative strength of the gain for the two modes is reversed. When birefringence and saturable dispersion are b [...] ...|$|E
40|$|Polarization state selection, {{polarization}} state dynamics, and polarization switching of a quantum-well Vertical Cavity Surface Emitting Laser is explored using {{a recently}} developed model that incorporates semiconductor physics, material birefringence, and material {{sensitivity to the}} <b>vector</b> <b>character</b> of the electric field amplitude. For the lowest order transverse spatial mode of the laser, we find conditions of switching of the polarization from one linearly polarized state to the other. Switching is induced {{by a combination of}} increased injection current, saturable dispersion, and the splitting of the optical frequencies of the two linearly polarized "modes" by the material birefringence. We demonstrate conditions of bistability, monostability, and dynamical instability. The results of our model satisfactorily match recent experimental results on bistability and switchings caused by changes in the injection current and changes in an injected optical signal. I. Introduction Control [...] ...|$|E
40|$|Abstract:- We {{present the}} {{development}} of the project “Física Interactiva ” (Interactive Physics) that addresses the special needs of students that enter at a Polytechnic University with a deficient background in Physics. The project tries to make an interactive tool available to the students through a web site. We choose Moodle as the Course Management System due to its cooperative philosophy and its open-source and free development model. The emphasis is put on fundamental concepts of first year Physics: <b>vector</b> <b>character</b> of magnitudes, point mechanics, electric and magnetic fields. Interactive materials (developed as Flash animations) are conceived to reinforce concepts through critical thinking and active enrolment. We discuss our experience developing these materials, with {{the pros and cons of}} the tools chosen, and preliminary results of the use of the site with students at our University...|$|E
30|$|Hence, {{by using}} three <b>vectors,</b> the <b>characters</b> are {{classified}} into 8 groups, and only group 311 requires extra processing {{to identify the}} character. This is achieved through zoning feature extraction technique which divides the image into zones. The technique is explained in more details in the following subsection. On the other hand, the disadvantage of this algorithm {{is that it is}} unable to identify the images that contain ‘noise’ instead of characters. Therefore, to enhance ‘noise’ recognition, it is assumed that every image contains ‘noise’ unless it satisfies one of the characters’ conditions. Algorithm  1 shows the pseudo code of the vector crossing algorithm.|$|R
40|$|FIGURE 14. Craniometric {{discrimination}} among intraspecific clades of D. dorsalis: (a) CVA analysis {{among the}} three clades and (b) respective <b>vector</b> correlations among <b>characters</b> and CVA axes. Bivariate plot {{of the two most}} discriminant craniometric characters (c) between the Mantiqueira and Serra do Mar clades, and (d) between the Mantiqueira and Southern clades, also depicting the allocation of taxonomically important samples...|$|R
30|$|Our new {{embedding}} {{can also}} be visualized and doing so creates braille-like results; however, it is far denser than Zhang and LeCun’s 1 -of-m embedding and its vertical dimension is far smaller, as seen in Fig. 1. Applying our approach to any alphabet size, such as the 70 used by Zhang and Chen, reduces <b>character</b> <b>vector</b> size from m to log_ 2 (m). Thus, using 256 <b>characters</b> requires a <b>vector</b> of size 8, while using 70 requires a vector of size 7. From this, we see that greatly increasing alphabet size has minimal impact {{on the size of}} <b>character</b> <b>vectors</b> using our embedding approach. As it reduces vector size from m to log_ 2 (m) we choose to call it log-m embedding. In our experiments comparing 1 -of-m embedding and log-m embedding, we chose alphabets of 70 and 256 characters and denote the four approaches as log- 70, log- 256, 1 -of- 256 and 1 -of- 70 {{for the remainder of the}} paper.|$|R
40|$|We {{present an}} {{analytical}} {{approach to the}} theory of nonlinear propagation in gases of femtosecond optical pulses with broad-band spectrum. The <b>vector</b> <b>character</b> of the nonlinear third-order polarization of the electrical field in air is investigated in details. A new polarization state is presented by using left-hand and right-hand circular components of the electrical field. The corresponding system of vector amplitude equations is derived in the rotating basis. We found that this system of nonlinear equations has $ 3 D+ 1 $ vector soliton solutions with Lorentz shape. The solution presents a relatively stable propagation and rotation with GHz frequency of the vector of the electrical field in a plane orthogonal to the direction of propagation. The evolution of the intensity profile demonstrates a weak self-compression and a week spherical wave in the first milliseconds of propagation. Comment: arXiv admin note: substantial text overlap with arXiv: 1503. 0095...|$|E
40|$|We present here a {{model to}} explain how the weak {{large-scale}} diffuse magnetic fields of the Sun migrate poleward in contrast to the sunspots which migrate equatorward with the progress of the solar cycle. We study the evolution of the Sun's poloidal field in the convection zone by assuming that it is produced by an equatorward-propagating dynamo wave {{at the base of the}} convection zone and is then subject to turbulent diffusion and a meridional circulation with a poleward surface flow. The magnetic fieldlines in the lower part of the convection zone first move towards the equator where they are pushed upward by the upwelling meridional flow there to form magnetic bubbles by joining with their opposite hemisphere counterparts. After reaching the surface, these bubbles drift to higher latitudes with the poleward meridional flow. Our model incorporates the three-dimensional <b>vector</b> <b>character</b> of the magnetic field, whereas the previous flux transport models treated the magnetic field as a scalar on the two-dimensional solar surface...|$|E
40|$|A qqq BSE {{formalism}} {{based on}} an input 4 -fermion Lagrangian of ‘current’ u,d quarks interacting pairwise via a gluon-exchange-like propagator in its nonperturbative regime, is employed {{for the construction of}} a relativistic qqq-wave function under the Covariant Instantaneity Ansatz (CIA). The chiral invariance of the input Lagrangian is automatically ensured by the <b>vector</b> <b>character</b> of the gluonic propagator, while the ‘constituent ’ masses are the low momentum limits of the dynamical mass function m(p) generated by the standard mechanism of DBχS in the solution of the Schwinger Dyson Equation (SDE). The CIA gives an exact reduction of the BSE to a 3 D form which is appropriate for baryon spectroscopy, while the reconstructed 4 D form identifies the hadron quark vertex function as the key ingredient for evaluating transition amplitudes via quark-loop integrals. In this paper the second stage of this ‘two-tier ’ BSE formalism is extended from the 4 D q¯q-meson to the 4 D qqq-baryon vertex reconstruction through a reversal of steps offered by the CIA structure. As a first application of this 4 D qqq wave function, we evaluat...|$|E
30|$|Recently, Zhang and LeCun [1] {{proposed}} {{a novel approach}} for text learning tasks where {{they were able to}} use CNNs to train classifiers by representing text in an image like, character-level fashion. This enabled them to train a deep convolutional neural network for text classification tasks involving high-level concepts from scratch with no prior feature engineering or extraction. They accomplished this by employing 1 -of-m embedding, where each character is represented by a vector of size m, where m is the number of characters in their alphabet. Each character in a text instance was represented as a <b>character</b> <b>vector</b> and the instance as a sequence of <b>character</b> <b>vectors.</b> When visualized, a braille like output is generated. Using this embedding, they fed their data into a network with six 1 D temporal convolutional layers and three fully connected layers. Their results showed training a deep CNN from character-level data outperformed networks trained on data with features generated with bag-of-words, bag-of-centroids and the deep learning approach Word 2 Vec.|$|R
40|$|Information in phylogenetic {{systematic}} analysis has been conceptualized, defined, quantified, and used differently by different authors. In this paper, {{we start with}} the Shannon Uncertainty Measure information measure I, applying it to cladograms containing only consistent character states. We formulate a general expression for I, utilizing a standard format for taxon-character matrices, and investigate the effect that adding data to an existing taxon-character matrix has on I. We show that I may increase when <b>character</b> <b>vectors</b> that encode autapomorphic or synapomorphic character states are added. However, as added <b>character</b> <b>vectors</b> accumulate, I tends to a limit, which generally is less than the maximum I. We show computationally and analytically that limc→∞ I = log 2 t, in which t enumerates taxa and c enumerates characters. For any particular t, upper and lower bounds in I exist. We use our observations to suggest several interpretations about the relationship between information and phylogenetic {{systematic analysis}} that have eluded previous, precise recognition...|$|R
40|$|Automatic {{estimation}} of crowd density {{is very important}} for the safety management of the crowds. In particular, when the density of the crowds exceeds a critical level, the safety of people in the crowd may be compromised. This paper describes a novel method to estimate the crowd density based on the combination of multi-scale analysis and a support vector machine. The algorithm will first transform the crowd image into multi-scale formats using wavelet transform. The first-order and second-order statistical features at each scale of the transformed images are then extracted as density <b>character</b> <b>vectors.</b> Furthermore, a classifier based on a support vector machine is designed to classify the extracted density <b>character</b> <b>vectors</b> into different density levels. Compared with the conventional statistical techniques and wavelet energy techniques used in single-scale images, the test results of a set of 300 images show that the proposed algorithm can achieve much improved performance and more detailed information of the crowd density can be captured by the new feature extraction method...|$|R
