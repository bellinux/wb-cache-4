9|40|Public
40|$|This paper {{extends the}} concept of chain {{sampling}} to <b>variables</b> <b>inspection</b> when the standard deviation of the normally distributed characteristic is known. A discussion of {{the shape of the}} known sigma single-sampling variables plan is given. The chain sampling plan for <b>variables</b> <b>inspection</b> will be useful when testing is costly or destructive. ...|$|E
40|$|This paper {{introduces}} {{the concept of}} repetitive group sampling (RGS) for <b>variables</b> <b>inspection.</b> The repetitive group sampling plan for <b>variables</b> <b>inspection</b> will be useful when testing is costly and destructive. The advantages of the variables RGS plan over variables single sampling plan, variables double sampling plan and attributes RGS plan are discussed. Tables are also constructed for the selection of parameters of known and unknown standard deviation variables repetitive group sampling plan indexed by acceptable quality level and limiting quality level. Acceptable quality level, average sample number, limiting quality level, repetitive group sampling, sampling by variables,...|$|E
40|$|We present CCD {{photometry}} of SX Phe {{variables in}} the field of the globular cluster M 55. We have discovered 27 variables, three of which are probable members of the Sagittarius dwarf galaxy. All of the SX Phe stars in M 55 lie in the blue straggler region of the cluster color-magnitude diagram. Using period ratio information we have identified the radial pulsation modes for one of the observed <b>variables.</b> <b>Inspection</b> of the period-luminosity distribution permits the probable identifications of the pulsation modes for {{most of the rest of}} the stars in the sample. We have determined the slope of the period-luminosity relation for SX Phe stars in M 55 pulsating in the fundamental mode. Using this relation and the HIPPARCOS data for SX Phe itself, we have estimated the apparent distance modulus to M 55 to be (m-M) _V= 13. 86 +- 0. 25 mag. Comment: A&A accepted, 11 figure...|$|E
40|$|Abstract: 100 % {{inspection}} {{plays an}} important role in today’s environment, such as airport security. The same is true for some industrial or other decision-making processes where the consequences of excessive deviations from target values are very high. We investigate the economic and statistical effects of inspection error on the design of specifications due to imperfect measurement systems. Two models are developed for single quality characteristic with consideration of inspection error under assumptions of constant and <b>variable</b> <b>inspection</b> costs. Models for bivariate quality characteristics are also proposed with considerations of inspection error. Numerical examples are given to illustrate the presented models which can be applied for the disposition of the output of any process for quality improvement...|$|R
50|$|The {{government}} of John Major, concerned about <b>variable</b> local <b>inspection</b> regimes, decided {{to introduce a}} national scheme of inspections though a reconstituted HMI, which {{became known as the}} Office for Standards in Education (Ofsted). Under the Education (Schools) Act 1992, HMI would supervise the inspection of each state-funded school in the country, and would publish its reports for the benefit of schools, parents, and government instead of reporting to the Secretary of State.|$|R
5000|$|Although the {{explicit}} {{form of the}} function f looks complicated, it is clearthat we may and do choose the value of ε so that the potential VT is equal to VS plus a constant independent of the <b>variable</b> Δd. By <b>inspection,</b> this occurs when ...|$|R
40|$|We {{investigate}} the optimal designing of chain sampling {{plan for the}} application of normally distributed quality characteristics. The chain sampling plan is one of the conditional sampling procedures and this plan under <b>variables</b> <b>inspection</b> will be useful when testing is costly and destructive. The advantages of this proposed variables plan over variables single sampling plan and variables double sampling plan are discussed. Tables are also constructed for the selection of optimal parameters of known and unknown standard deviation variables chain sampling plan for specified two points on the operating characteristic curve, namely, the acceptable quality level and the limiting quality level, along with the producer’s and consumer’s risks. The optimization problem is formulated as a nonlinear programming where the objective function to be minimized is the average sample number and the constraints are related to lot acceptance probabilities at acceptable quality level and limiting quality level under the operating characteristic curve...|$|E
40|$|This study {{investigated}} {{the relationships between the}} scales of the Adult Career Concerns Inventory (ACCI) and those of the Career Attitudes and Strategies Inventory (CASI). The scores of 202 South African adults for the two inventories were subjected to a canonical correlation analysis. Two canonical variates made statistically significant contributions to the explanation of the relationships between the two sets of <b>variables.</b> <b>Inspection</b> of the correlations of the original variables with the first canonical variate suggested that a high level of career concerns in general, as measured by the ACCI, is associated with high levels of career worries, more geographical barriers, a low risk-taking style and a non-dominant interpersonal style, as measured by the CASI. The second canonical variate suggested that concerns with career exploration and advancement of one’s career is associated with low job satisfaction, low family commitment, high work involvement, and a dominant style at work...|$|E
40|$|We present {{four new}} {{sampling}} schemes by <b>variables</b> <b>inspection</b> {{to deal with}} the first-order autoregressive model between linear profiles. The first plan is based on exponentially weighted moving average (EWMA) and the rest of three plans are using the resubmitted sampling, repetitive group sampling (RGS), and multiple dependent state (MDS) sampling schemes. The nonlinear optimization problem is developed to find the number of profiles and the corresponding acceptance criteria, such that the producer’s and consumer’s risk are satisfied simultaneously. The efficiency of the proposed plans is compared with the conventional single sampling plan in terms of average sample number and the probability of acceptance. The result implies that all of the proposed sampling plans are superior to the single acceptance sampling plan by variables. In addition, the EWMA method appeared to be better than the others. The applications of proposed plans are shown with the help of industrial examples taken from calibration of an optical imaging system, and tire cornering stiffness test...|$|E
40|$|The reseach aim to test {{impact of}} {{motivation}} variable to productivity of employee in local goverment of Karanganyar. Result {{of the research}} indicated the motivation variable have negatif significant impact on productivity and <b>inspection</b> <b>variable</b> have positif significant impact on productivity. Analysis of the research use multinomial logistic model (MLM) ...|$|R
40|$|Lot-by-Lot {{acceptance}} sampling plans provide the practitioner with decision rules for acceptance or rejection of a current delivery. Acceptance sampling plans {{can be classified}} into variable plans when features from the lot are measured on numerical scale and attributive plans when features are measured that classify items as defective or non-defective. We will treat the case where sampling takes place from lots that are coming from a supplier's process which is of high quality, i. e. a proportion defects near zero is associated to the process. Traditional sampling plans won't work in this case since any sample of reasonable size will probably contain zero defects. We will propose a generalization of the modified chain sampling plans proposed in [1] that is applicable for as well attributive as <b>variable</b> <b>inspection.</b> For this purpose, {{it is assumed that}} lots are drawn from a continuing stream of lots of a process with an unknown but constant fraction defects. Chain sampling plans are able to accumulate information from samples drawn from historical lots to estimate the suppliers quality. The proposed plans allow to go further into history than the standard chain sampling plans of Dodge [2]. In contrast to zero acceptance number single sampling plans, this enables the design of steep operating characteristic (OC) -curves that possess an inflection point near zero. Algorithms will be proposed to design the proposed plans when the OC-curve have to pass through two predetermined points that define producer’s and consumer’s risk. Experiments will show that for small fraction defects the required sample size is smaller compared to the classical chain sampling plans of Dodge. status: publishe...|$|R
40|$|Cyanogen bromide {{fragments}} {{were isolated}} from the heavy chains of three human IgG myeloma proteins of the VHIII subgroup, sequenced by an automated method, and localized to the <b>variable</b> region. <b>Inspection</b> of these sequences, together with corresponding stretches from both human and animal proteins (studied in other laboratories) led to the detection of two additional hypervariable regions characteristic of the VH segment of immunoglobulin heavy chains. These areas of hypervariability, involving heavy-chain residues 86 - 91 and 101 - 109, were separated by a region of relative constancy. The close relationship of these two hypervariable regions, and the previously described first heavy-chain hypervariable region (residues 31 - 37), to the first heavy-chain disulphide bridge implies that the three hypervariable areas might be in close steric approximation in native immunoglobulin molecules...|$|R
40|$|The e ects of modi®ed {{atmosphere}} packaging on physicochemical and sensorial characteristics (contents of free fatty acids, lac- tose, {{lactic acid}} and moisture, {{as well as}} pH and rigidity) in Portuguese whey cheese (RequeijaÄo) were studied following a response surface methodology using storage time, storage temperature and fraction of CO 2 in the ¯ushing gas as manipulated <b>variables.</b> <b>Inspection</b> of the sensorial optima {{in terms of the}} di erent parameters indicated that it is convenient to set the storage temperature equal to 4 C because no signi®cant lipolysis takes place, irrespective of overhead atmosphere. Plain CO 2 as ¯ushing gas will in general ensure more constant composition until 15 days and will provide protection against extensive lipolysis. In terms of overall visual aspect, all packaged cheeses were preferred to their unpackaged counterparts; however, in terms of acidic smell, only whey cheeses stored at 4 C exhibited signi®cant di erences relative to those stored at higher temperatures...|$|E
40|$|Software {{inspection}} {{is said to}} {{be inevitable}} in order to ensure software quality assurance. Nevertheless, there have been controversies on which defect detection techniques should be applied in software document inspection. This work comparatively study the effectiveness of three software inspection techniques: Ad Hoc, Perspective-based and Checklist-based defect detection techniques. Paper-based inspections of software artifact were carried out on an industrial code artifact seeded with forty bugs. An experimental 3 x 3 x 4 factorial design with three defect detection techniques (checklist-based, Adhoc and perspective-based) as independent variables, three dependent <b>variables</b> (<b>inspection</b> effectiveness, effort and false positives) and four teams for each defect detection methods was used for the experiment. The data obtained were subjected to tests of hypotheses using One-way ANOVA, Post-Hoc tests and Mean coefficients. Results from the study indicate that there were significant differences in the defect detection effectiveness and effort in terms of time taken in minutes reported by the reviewers using perspective-based, ad hoc and checklist-based based reading techniques in the industrial settings...|$|E
40|$|Denne masteroppgåva byggjer på eit DCE-MRI (Dynamic Contrast Enhaced Magnetic Resonance Imaging) -studium av 88 pasientar med livmorhalskreft, gjennomført på Det Norske Radiumhospitalet (no ein del av Oslo universitetssykehus) i perioden 2001 - 2004. I DCE-MRI-undersøkingane målast den {{relative}} signalauken RSI frå vevet etter injisering av eit kontrastmiddel, og dette gjev ein tidsserie på 14 bilete. Målingane har blitt tilpassa ein farmakokinetisk modell kalla Brix-modellen, som reduserer tidsserien frå kvar voksel ned til tre modellparameterar. Alle pasientane har så fått behandling i form av stråleterapi, med jamleg oppfølging i etterkant. Målet med denne oppgåva er å undersøkje om parameterane frå Brix-modellen kan knyttast til behandlingsutfall i form av progresjonsfri overleving, det vil seie om pasienten vert frisk att eller ikkje. Analysane i denne oppgåva skil ikkje mellom tilbakefall i form av metastasar og lokalt tilbakefall. Til skilnad frå tidlegare studium, nyttar denne oppgåva multivariate statistiske metodar. Dei multivariate metodane nytta i oppgåva er prinsipalkomponentanalyse (PCA), diskriminant analyse (LDA og QDA), klyngeanalyse, PLS, lineær regresjon, SIMCA og støttevektormaskiner (SVM). Vi kombinerer også LDA med ein variabelseleksjon, for å fjerne variablar som gjev lite informasjon. I analysane nyttar vi deskriptive statistiske parameterar, som til dømes gjennomsnitt, standardavvik og persentilverdiar, berekna ut i frå Brix-parameterane for kvar svulst. I èin analyse nyttar vi også histogramframstilling av Brix-parameterane over svulsten. PCA syner at datasettet beståande av alder på pasienten, stadiet av sjukdom, svulstvolum og dei deskriptive statistiske parameterane kan reduserast til få prinsipalkomponentar utan å miste mykje informasjon. Det trengst berre åtte komponentar for å forklare over 90 % av den totale variansen i dei 64 variablane. Inspeksjon av skårplott syner ikkje grupperingar som samsvarar med behandlingsutfall, det vile seie pasientar som vert friske og pasientar som får tilbakefall, med unntak av eitt av dei tredimensjonale skårplotta. PLS med dei same forklaringsvariablane som i PCA og anten behandlingsutfall, stadium eller svulstvolum som respons, gjev forklart varians på 50 % - 60 % i kalibrering, men residualvarians på over 100 % etter full kryssvalidering. Heller ikkje lineær regresjon med utvalde komponentar frå PCA-modellen forklarer behandlingsutfall godt. Ikkje-overvaka klassifisering i form av K-means- og K-medians-klyngeanalyse gjev ikkje gruppeinndeling som samsvarar med utfallet av stråleterapi. Overvaka klassifisering i form av LDA og QDA lukkast betre i å skilje mellom utfalla. LDA etter variabelseleksjon, der variablane som forklarer 90 % av totalvariansen vert nytta som forklaringsvariablar, syner seg å klassifisere signifikant, med ein p-verdi på 0, 011 for både tilbakefallspasientane og pasientane som vert friske att. Dei ikkje-lineære metodane SIMCA og SVM er dei som gjev mest nøyaktig klassifikasjon, det vil seie dei som plasserer flest pasientar i riktig gruppe. SIMCA gjev ei nøyaktigheit på 91 %, sensitivitet (andel riktig klassifiserte pasientar av pasientane som vart friske) på 100 % og spesifisitet (andel riktig klassifiserte tilbakefallspasientar) på 78 %, medan SVM gjev nøyaktigheit på 93 %, sensitivitet på 96 % og spesifisitet på 88 %. SVM-modellen er også god etter full kryssvalidering, med 88 % nøyaktigheit, trass i mange støttevektorar. Konklusjonen er at multivariate metodar kan vere nyttige i analyse av DCE-MRI-bilete, sidan dei gjev kvantitative mål på nøyaktigheita til klassifiseringane og gjer det mogleg å identifisere kva svulstar som vert feilklassifiserte. Det er også ein fordel at metodane automatisk tek omsyn til samspel mellom variablar. This master's {{thesis is}} based on a DCE-MRI (Dynamic Contrast Enhaced Magnetic resonance Imaging) study of 88 patients with cervical cancer, performed at the Norwegian Radium Hospital (now a part of Oslo Universty Hospital) in the period from 2001 to 2004. The DCE-MRI examination measures the relative signal increase (RSI) from the tissue after injection of a contrast agent, and this gives a time series of 14 images. The measurements have been fitted to a pharmacokinetic model, the Brix model, and this reduces the time series from each voxel to three model parameters. All patients have been treated with radiotherapy, and have been followed up afterwards. The aim of this thesis is to examine whether the parameters from the Brix model can be associated with treatment outcome measured by progression free survival, that is whether the patient is cured from the cancer or not. We do not separate between locoregional and distant relapse. In contrast to earlier studies, this study uses multivariate statistical methods. The multivariate methods used in this study are principal component analysis (PCA), discriminant analysis (LDA and QDA), cluster analysis, PLS, linear regression, SIMCA and support vector machines (SVM). We also combine LDA with a variable selection, on order to remove variables that provide little information. In the analyses we use descriptive statistical parameters, such as average, standard deviation and percentile values, calculated from the Brix parameters for each tumour. In one of the analyses we also use histogram values of the Brix parameters over each tumour. PCA shows that the data set consisting of patient age, tumour stage, tumour volume, and the descriptive statistical parameters, can be reduced to few principal components without losing much information. We only need eight principal components to explain 90 % of the total variance of the 64 <b>variables.</b> <b>Inspection</b> of score plots show no grouping consistent with treatment outcome, that is patients that are cured and patients with relapse, with one exeption in one of the three dimensional score plots. PLS with the same explanatory variables as in PCA and either treatment outcome, tumour stage or tumour volume as response variable, gives explained variance of 50 %- 60 % in calibration, but over 100 % residual variance after full cross validation. Nor linear regression with chosen principal component from the PCA model can explain treatment outcome well. Unsupervised classification, in the form of K-means and K-medians cluster analysis, does not give grouping consistent with treatment outcome. Supervised classification, LDA and QDA, is more successful in separating the two treatment outcomes. LDA after a variable selection where the variabels needed to explain 90 % of the total variance is used as explanatory variables, gives significant classification with p-value 0. 011 for both patients with relapse and patients that were cured. The nonlinear methods SIMCA and SVM gives the most accurate classification, that is they predict the correct treatment outcome for most patients. SIMCA gives accuracy 91 %, sensitivity 100 % (the fraction of cured patients correctly classified as cured) and specificity 78 % (the fraction of correctly classified relapse patients), while SM gives accuracy 93 %, sensitivity 96 % and specificity 88 %. The SVM model is still accurate after full cross validation, then with 88 % accuracy, despite having many support vectors. The conclusion is that multivariate methods can be of use in analysis of DCE-MRI-images, because they give quantitative measurements on the accuracy of the classifications and provide the possibility to identify the tumours that are incorrectly classified. It is also an advantage that the metods automatically take into concideration the interaction between variables...|$|E
50|$|Kingfisher {{is one of}} {{the oldest}} fiber optic test companies, and is {{regarded}} by industry elders as having a significant influence on the development of the industry. Kingfisher products are used by professional technicians when installing and maintaining fiber optic cabling and systems, and its fiber optic test equipment range includes such items as, optical power meters, optical light sources, optical loss test sets, optical test and <b>inspection</b> kits, <b>variable</b> optical attenuators, <b>inspection</b> microscopes and various optical fault locators.|$|R
40|$|Plan for {{the fatigue}} damage {{evaluation}} of the full-penetration butt welds bridges requires the development of reliability-based analysis, inspection and maintenance procedure. To account for the uncertainties in the material properties and environmental conditions, a stochastic fatigue crack growth model is proposed here. Recent calculations using the Monte-Carlo Simulation technique shows that the first-order reliability method gives very accurate result. The sensitivity and capability of ultrasonic inspection are investigated in this study. The reliability of inspections for various events is formulated. Efficient algorithms for updating the reliability model through inspection are proposed. A case study is conducted for MARTRA's steel bridges system. Analysis of results includes fatigue reliability index, inspection, repair, updating of random <b>variables</b> and <b>inspection</b> plan. Results indicate the proposed model gives an accurate and practical approach to the fatigue control in the steel structures...|$|R
40|$|This article {{proposes a}} {{variables}} two-plan sampling system called tightened-normal-tightened (TNT) sampling inspection scheme where the quality characteristic follows a normal distribution or a lognormal distribution {{and has an}} upper or a lower specification limit. The TNT <b>variables</b> sampling <b>inspection</b> scheme will be useful when testing is costly and destructive. The advantages of the variables TNT scheme over variables single and double sampling plans and attributes TNT scheme are discussed. Tables are also constructed for the selection of parameters of known and unknown standard deviation variables TNT schemes for a given acceptable quality level (AQL) and limiting quality level (LQL). The problem is formulated as a nonlinear programming where the objective function to be minimized is the average sample number and the constraints are related to lot acceptance probabilities at AQL and LQL under the operating characteristic curve. average sample number, OC curve, sampling system, two-plan system,...|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedIn this paper, tables {{of the joint}} distribution of the sample mean and the largest observation in a sample for a random sample from the standard normal distribution are presented for a <b>variables</b> sampling <b>inspection</b> procedure which guarantees acceptance of perfectly screened lots. The quality of each item in the lot is described by a single quality characteristic. It is assumed that this quality characteristic has a normal density function with known variances Tables of standard truncated normal distribution required to compute the tables of the joint distribution of X and X(n). are also presented. The two sets of tables are also used to show how operating characteristic curves may be computed. Sample size is shown to affect the existence of levels of significance. For small sample sizes (a < 10), certain large levels of significance do not exist for tests of hypothesis concerning truncated normal distributions. [URL] United States Air Forc...|$|R
40|$|This paper studies a {{well-known}} monetary {{model of the}} inflation process. The monetary approach to inflation control is investigated by employing an equation describing the monetary system augmented by a Phillips curve and the equation from Okun 2 ̆ 7 s law. This simple three-equation model is specified in the non-linear framework {{with the use of}} the smooth transition regression. The coefficients in a smooth transition regression model are assumed to be continuous functions of a properly chosen transition variable. The resulting non-linear model thus captures the structural changes in the relationships between the observed economic <b>variables.</b> From the <b>inspection</b> of dynamic properties, asymmetric policy reactions can be derived...|$|R
40|$|Connections between {{building}} {{damage and}} vibration intensity has been examined by few researcher. Indeedtackling of effort about bigger {{damage has been}} examined too. But connections between traffic character andbig vibration in the street edge isn 2 ̆ 7 t much inspect. Some of literature almost study about connections betweenvibration and traffic micro and too specify, such as to look vibration character and it 2 ̆ 7 s relation with vehiclecharacteristic. Generally details like it is less applicative, Theoretically it 2 ̆ 7 s better do by perform a formula. To aim {{this study is to}} examine of connections between vibration in the street edge and traffic characteristic athighway. Traffic characteristic which examined covering are traffic volume and average of traffic speed. To support the aim, survey and analysis is needed. Survey material needs are vibration survey, traffic speed,traffic volume and few road characteristic. Survey did at the street edge with three location where everylocation have few different road characteristic, in this case wide of drainage as of attentuation wide. Everylocations inspected by <b>variable</b> <b>inspection</b> distance are 5 m. 15 m and 25 m. Speed and traffic volume datarecorded in every location by using manual record, While vibration data recorded at every point of everylocation by using vibration record Vibecheck meter. Result of recording processed and analyzed to obtain average value and it data distribution. To viewconnections between vibration and traffic characteristic, distance and attentuation, to perform correlation andregretion examine. Regretion examine used for mode calibration connections between vibration and trafficcharacteristic, distance and attentuation based on Watt style. Exams result show that 1) There is strong relation between vibration with distance of examine and attentuationwide, where that connections is negative identifying, 2) There is strong relation between vibration and trafficspeed but not with traffic volume and heave vehicle on the traffic, where that connections is positive identifying, 3) Watt style calibration examine result gave good enough result if we look R² value of correlation examineresult which reach 0, 96. From analysis result we can concluded some cases, 1) cause vibration is effected by traffic speed then decreaseof vibration effect can performed by limitation speed especially at residence area and 2) cause vibration iseffected by distance and attentuation, then decrease of vibration effect can performed by widest distancebetween building and street edge and widest attentuation in this case is drainag...|$|R
40|$|This thesis {{documents}} the research; development methodology {{and evaluation of}} „Progranimate‟, a visual programming environment and associated pedagogy that helps novices overcome their difficulties in learning programming via an imperatives first (non object oriented) approach. In particular it focuses on problem solving and its prerequisite skills, these {{are known to be}} particularly troublesome for novice programmers. Progranimate is a unique, web deliverable, simplified development environment that utilises dynamic structured flowchart program construction, generated code in several selectable languages and animated execution. Progranimate uses a structured flowchart visualisation to convey the key concepts and underlying abstractions of programming, whilst allowing the novice to focus on the development of problem solving skills. Progranimate utilises an easy to use, uncluttered development environment and removes the necessity of writing complex code. This allows the user to focus solely on problem solving and on conceptualising the underlying abstractions and semantics of programming. In Progranimate, programs are constructed and executed visually via dynamic flowchart and code based representations. The visual synchronisation between the flowchart and code representations allow the user to draw an effective correlation between the flowchart and the logical code structure that it represents. Program animation features provide the user with an accurate mental model of program execution by emphasising the interaction and behaviour of the key structures and components used in programming. A <b>variable</b> <b>inspection</b> feature is also provided, allowing the user to observe the changes in data as a program is executed. Coupled to Progranimate is a scaffolding pedagogy designed to assist novice programmers in the development of problem solving skill. The pedagogy is underpinned by the theories of scaffolding support and the zone of proximal development. This pedagogy has been utilised within a range of contextual, fun, and gender neutral programming activities designed for use with Progranimate. This thesis hypothesises that using Progranimate on its own or with the scaffolding pedagogy for the creation of simple programs, will help novices strengthen their conceptual understanding of programming and problem solving skills. Evaluations of Progranimate with secondary schoolpupils, their teachers and first year university students support this hypothesis. The evaluations also show that Progranimate coupled to the scaffolding pedagogy and associated programming problems is a very motivating way to introduce secondary school pupils to programming. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|The paper {{concerns}} the acceptance sampling plans when {{the remainder of}} rejected lots is inspected. Two types of AOQL plans are considered – for <b>inspection</b> by <b>variables</b> and for <b>inspection</b> by <b>variables</b> and attributes (all items from the sample are inspected by variables, the remainder of rejected lots is inspected by attributes). These plans are compared with the corresponding Dodge–Romig AOQL plans for inspection by attributes. An algorithm allowing the calculation of these plans (with the use of software Mathematica) was presented. From the results of numerical investigations it follows that under the same protection of consumer the AOQL plans for <b>inspection</b> by <b>variables</b> areAOQL, sampling plans, acceptance plan, economical aspects, software Mathematica...|$|R
40|$|This {{work was}} {{undertaken}} {{to determine if}} human factors research has yielded information applicable to upgrading requirements in ASME Boiler and Pressure Vessel Code Section XI, improving methods and techniques in Section V, and/or suggesting relevant research. A preference was established for information and recommendations which have become accepted and standard practice. Manual Ultrasonic Testing/Inservice Inspection (UT/ISI) is a complex task subject to influence by dozens of variables. This review frequently revealed equivocal findings regarding effects of environmental variables as well as repeated indications that inspection performance may be more, and more reliably, influenced by the workers` social environment, including managerial practices, than by other situational variables. Also of significance are each inspector`s relevant knowledge, skills, and abilities, and determination of these {{is seen as a}} necessary first step in upgrading requirements, methods, and techniques as well as in focusing research in support of such programs, While understanding the effects and mediating mechanisms of the <b>variables</b> impacting <b>inspection</b> performance is a worthwhile pursuit for researchers, initial improvements in industrial UTASI performance may be achieved by implementing practices already known to mitigate the effects of potentially adverse conditions. 52 refs., 2 tabs...|$|R
40|$|Appropriate {{inspection}} is {{a significant}} component of production systems. In this paper a model is developed to determine the optimal placement of inspection stations within n-stage linear production systems. This model accommodates two types of inspector fallibility: "predictable," which implies that the error rates are known and constant, and "erratic," which requires a random variable to describe inspector performance. Cost per good unit accepted by the customer is used as the optimizing criterion. The cost-quality response surface is explored through a sequential sensitivity analysis. Our results indicate that under certain conditions the level of predictable inspector fallibility significantly impacts the number and placement of inspection stations as well as cost per good unit produced. The modeled systems, however, were quite insensitive to the variability of inspector performance. This production-inspection model provides management with information on the optimal number and placement of inspection stations for specific planned or existing serial production systems. It {{can also be used}} by management to explore various policy options, such as the cost implications of increasing the quality vs. the quantity of inspection stations. The data required by the model can be obtained at reasonable cost provided management is willing to estimate or determine judgementally certain of the <b>variables.</b> reliability: <b>inspection,</b> facilities/equipment planning, reliability: quality control...|$|R
30|$|The {{system we}} {{consider}} {{in this paper}} consists of n machines, n fixed-size buffers, and m+ 1 inspection stations (one inspection station {{is at the end}} of the line and m are internal) in series. We explore the impact of quality constraints on the system performance and (numerical) complexity. The objective is to simultaneously minimize the combined storage and shortage costs, determine the optimal buffers’ sizes, and specify the optimal number and positions of the m internal inspection stations. The resulting mathematical model is an intractable combinatorial nonlinear optimization model; it is difficult to find an exact solution in a reasonable time, especially when the production line is large. This paper develops an efficient evolutionary heuristic for this complex model. While the number of machines considered in the literature does not exceed 10 (to the best of our knowledge), this paper aims at solving larger production lines and a <b>variable</b> number of <b>inspection</b> stations.|$|R
40|$|AbstractIn {{this paper}} we shall {{deal with the}} AOQL single {{sampling}} plans when the remainder of rejected lots is inspected. We shall consider two types of AOQL plans – for <b>inspection</b> by <b>variables,</b> and for <b>inspection</b> by <b>variables</b> and attributes (all items from the sample are inspected by variables, remainder of rejected lots is inspected by attributes) – see Klufa (1997). These plans we shall compare with the corresponding Dodge-Romig AOQL plans by attributes. From the results of numerical investigations it follows (see Klufa (2008)) that under the same protection of consumer the AOQL plans for <b>inspection</b> by <b>variables</b> are in many situations more economical than the corresponding Dodge-Romig attribute sampling plans (saving of the inspection cost is 70 % in any cases). The calculation of these new plans is considerably difficult (in Klufa (2008) is only approximate solution). The problem of finding the optimal sampling plan for <b>inspection</b> by <b>variables</b> we shall solve in this paper by original method...|$|R
40|$|This paper {{illustrates}} a channel coordination and quantity discounts between a vendor and a buyer with single-setup multi-delivery (SSMD) strategy {{to reduce the}} joint total cost among supply chain players. The benefit of the coordination between a buyer and a vendor is considered as the vendor requests to the buyer for changing the ordering quantity such that the vendor can be benefited from lower inventory costs. After accepting the buyer’s condition, the vendor compensates the buyer for his increased inventory cost and gives consent for additional savings by offering a quantity discount. The centralized decision making is examined for {{the effect of this}} strategy with the presence of backorder for buyer and inspection cost for the vendor. The quantity discount strategy, with the presence of <b>variable</b> backorder and <b>inspections,</b> can allow more savings for all players of supply chain. Some numerical examples, sensitivity analysis, and graphical representations are given to illustrate more savings from existing literature and comparisons between the several demand values...|$|R
40|$|This study {{explored}} {{whether a}} meridian-based intervention termed the Emotional Freedom Techniques (EFT) could reduce Type I 'yips' symptoms. EFT {{was applied to}} a single figure handicap golfer {{in an attempt to}} overcome the performance decrements the player had suffered. The participant underwent four 2 -hr sessions of EFT. The EFT involved the stimulation of various acupuncture points on the body. The appropriate acupuncture points were tapped while the participant was tuned into the perceived psychological causes (significant life event) associated with his 'yips' experience. Dependent <b>variables</b> included: visual <b>inspection</b> of the 'yips', putting success rate and motion analysis data. Improvements in 'yips' symptoms occurred across all dependent measures. Social validation data also illustrated that these improvements transferred to the competitive situation on the golf course. It is possible that significant life events may be a causal factor in the 'yips' experience and that EFT may be an effective treatment for the 'yips' condition...|$|R
40|$|The {{relationship}} between visual inspections {{carried out by}} environmental health officers and microbiological examination was studied in 89 restaurants. Using 30 <b>variables</b> a standardized <b>inspection</b> procedure was developed {{and each of the}} premises was assessed in six main areas-structure and design, cleaning and cleanliness, personal hygiene, risk of contamination, temperature control, and training and knowledge about food hygiene. Selected foods and specimens from hands, surfaces, and wiping cloths were examined. There were significant associations between all six areas of the inspections. The structure and design were significantly related to the combined score from all the other areas (P less than 0. 001). There were no highly significant associations between microbiological examination and visual assessments. The microbial contamination of wiping cloths, however, was related to the cleaning and cleanliness (P = 0. 005). Microbial sampling provided additional information to inspections and was a valuable aid. Further development of this risk-assessment approach could provide an effective system for monitoring potential health risks in high-risk food premises...|$|R
40|$|The buoyant {{research}} {{interest in}} the constructs emotional intelligence (EI) and transformational leadership (TFL) {{is a testament to}} the crucial role of emotional skills at work. EI is often described as an antecedent of TFL, and several empirical studies report a positive relationship between these <b>variables.</b> On closer <b>inspection,</b> however, there may be methodological factors, such as common method variance, that potentially undermine the validity of findings. Using a multi-rater assessment (N = 227), this study sought to overcome the problem of method variance, whilst at the same time evaluate its potential presence by comparing same-source and non-same-source data. Findings suggest that, when using a strong methodological design, no relationship between EI and TFL is found. Thus, these findings renew the demand for scientific rigour in the design of studies to enhance their validity. The theoretical ramifications of this study are such that management scholars need to re-conceptualize the relationship between EI and TFL...|$|R
40|$|Acceptance {{sampling}} plays {{a crucial}} role in food quality assurance. However, safety inspection represents a substantial economic burden due to the testing costs and the number of quality characteristics involved. This thesis presents six pieces of work on the design of attribute and <b>variables</b> sampling <b>inspection</b> plans for food safety and quality. Several sampling plans are introduced with the aims of providing a better protection for the consumers and reducing the sample sizes. The effect of factors such as the spatial distribution of microorganisms and the analytical unit amount is discussed. The quality in accepted batches has also been studied, which is relevant for assessing the impact of the product in the public health system. Optimum design of sampling plans for bulk materials is considered and different scenarios in terms of mixing efficiency are evaluated. Single and two-stage sampling plans based on compressed limits are introduced. Other issues such as the effect of imperfect testing and the robustness of the plan have been also discussed. The use of the techniques is illustrated with practical examples. We considered numerous probability models for fitting aerobic plate counts and presence-absence data from milk powder samples. The suggested techniques have been found to provide a substantial sampling economy, reducing the sample size by a factor between 20 and 80 % (when compared to plans recommended by the International Commission on Microbiological Specification for Food (ICMSF) and the CODEX Alimentarius). Free software and apps have been published, allowing practitioners to design more stringent sampling plans. Keywords: Bulk material, Composite samples, Compressed limit, Consumer Protection, Double sampling plan, Food safety, Measurement errors, Microbiological testing, Sampling inspection plan...|$|R
40|$|House mice (Mus musculus) {{produce a}} {{variable}} {{number of major}} urinary proteins (MUPs), and studies suggest that each individual produces a unique MUP profile that provides a distinctive odor signature controlling individual and kin recognition. This ‘barcode hypothesis’ requires that MUP urinary profiles show high individual variability within populations and also high individual consistency over time, but tests of these assumptions are lacking. We analyzed urinary MUP profiles of 66 wild-caught house mice from eight populations using isoelectric focusing. We found that MUP profiles of wild male house mice are not individually unique, and though they were highly <b>variable,</b> closer <b>inspection</b> revealed that the variation strongly depended on MUP band type. The prominent (‘major) bands were surprisingly homogenous (and hence most MUPs are not polymorphic), but we also found inconspicuous (‘minor’) bands that were highly variable and therefore potential candidates for individual fingerprints. We also examined changes in urinary MUP profiles of 58 males over time (from 6 to 24 weeks of age), and found that individual MUP profiles and MUP concentration were surprisingly dynamic, and showed significant changes after puberty and during adulthood. Contrary to what we expected, however, the minor bands were the most variable over time, thus no good candidates for individual fingerprints. Although MUP profiles do not provide individual fingerprints, we found that MUP profiles were more similar among siblings than non-kin despite considerable fluctuation. Our findings show that MUP profiles are not highly stable over time, they do not show strong individual clustering, and thus challenge the barcode hypothesis. Within-individual dynamics of MUP profiles indicate a different function of MUPs in individual recognition than previously assumed and advocate an alternative hypothesis (‘dynamic changes’ hypothesis) ...|$|R
40|$|Abstract—This paper {{presents}} {{a model for}} optimal asset main-tenance inspection services. The model is designed to support through-life service {{in the form of}} multiple nested inspections and maintenance to meet defined asset availability and capability requirements, as well as achieving successful through-life tech-nology insertions. The inspections and maintenance activities are assumed to be performed at more than one level, but nested and aimed at different types of defects or subsystems over a fixed period of time (the designed asset life). This practice is common in many industries, particularly in the defense industry. The impact of technological insertions is reflected through changes in the failure behavior of the asset. We use the delay time concept to model the failure mechanism of the asset, and the arrivals of defects are assumed to follow Poisson processes. The decision <b>variables</b> are the <b>inspection</b> intervals, while the objective function can be expressed in terms of cost, downtime, or reliability. The model is demonstrated through a numerical example. The model can be used for optimizing two-level inspection intervals with technological insertions. Index Terms—Delay time, inspection, maintenance, technolog-ical insertions...|$|R
40|$|In this paper, {{we develop}} {{integrated}} inventory inspection models {{with and without}} replacement of nonconforming items. Inspection policies include no inspection, sampling inspection, and 100 % inspection. We consider a buyer who places an order from a supplier when his inventory level drops to a certain point, due to demand which is stochastic in nature. When a lot is received, the buyer uses some type of inspection policy. The fraction nonconforming {{is assumed to be}} a random variable following a beta distribution. The order quantity, reorder point and the inspection policy are decision <b>variables.</b> In the <b>inspection</b> policy involving determining sampling plan parameters, constraints on the buyer and manufacturer risks is set in order to obtain a fair plan for both parties. A solution procedure for determining the operating policies for inventory and inspection consisting of order quantity, sample size, and acceptance number is proposed. Numerical examples are presented to conduct a sensitivity analysis for important model parameters and to illustrate important issues about the developed models. (c) 2007 Elsevier B. V. All rights reserved...|$|R
40|$|Using {{the case}} study of water {{pollution}} in the Flemish textile industry, we discuss three empirical questions concerning the use of emission standards. We find that the Becker result ("maximal fine / minimal inspection") does not hold if we include rule making, implementation and enforcement costs into the model. There is {{a balance between the}} fine and the <b>inspection</b> <b>variables.</b> Making enforcement more stringent does not mean to put the fine levels as high as possible and only then increase the inspections. We have also shown that is extremely important to have correct estimates of people's willingness to pay for environmental improvement. These WTP estimates determine in great part the optimal environmental strategy and its associated optimal monitoring and enforcement policy. Moreover, it really pays off to optimise the monitoring and enforcement strategy associated with an emission standard. This optimisation {{does not necessarily mean that}} monitoring and enforcement should be as stringent as possible. It is often possible to obtain the desired result by some intermediate value of the monitoring and enforcement parameters. This is due to the balancing of costs and benefits associated with monitoring and enforcement. Environmental Law; Illegal behaviour; Enforcement of Law...|$|R
