0|14|Public
5000|$|... #Caption: Data Matrix barcode of the <b>URL</b> for <b>Wikipedia's</b> {{article on}} Semacode ...|$|R
5000|$|... #Caption: [...] High Capacity Color Barcode of the <b>URL</b> for <b>Wikipedia's</b> {{article on}} High Capacity Color Barcode ...|$|R
2500|$|In August 2002, {{shortly after}} Jimmy Wales {{announced}} that he would never run commercial advertisements on <b>Wikipedia,</b> the <b>URL</b> of <b>Wikipedia</b> was changed from wikipedia.com to wikipedia.org (see: [...]com and [...]org).|$|R
5000|$|... #Caption: The QR Code for the <b>Wikipedia</b> <b>URL.</b> [...] "Quick Response", {{the most}} popular 2D barcode in Japan, is {{promoted}} by Google. It is open in that the specification is disclosed and the patent is not exercised.|$|R
500|$|On 5 December 2008 the Internet Watch Foundation {{added the}} <b>Wikipedia</b> <b>URLs</b> for the Virgin Killer article and the [...] to its blacklist. After the blacklisting, users of major UK ISPs, {{including}} BT, Vodafone, Virgin Media/Tesco.net, Be/O2, EasyNet/UK Online/Sky Broadband, Orange, Demon, and TalkTalk (Opal Telecom), {{were unable to}} access the content.|$|R
40|$|The SQAD {{database}} {{consists of}} 3301 records obtained from Czech Wikipedia articles. The record structure is following: - the original sentence(s) from Wikipedia - {{a question that}} is directly answered in the text - the expected {{answer to the question}} as it appears in the original text - the <b>URL</b> of the <b>Wikipedia</b> web page from which the original text was extracted - name of the author of this SQAD recor...|$|R
5000|$|Semapedia {{have created}} a system for linking {{physical}} objects and Wikipedia articles using the Semacode tagging scheme. Graphical tags can be created that link to the <b>URLs</b> of individual <b>Wikipedia</b> articles. These tags can then {{be attached to the}} physical objects mentioned in the Wikipedia articles. Reading a tag with a camera phone will then retrieve an article from Wikipedia and display it on the phone screen, creating a [...] "Mobile Wikipedia".|$|R
40|$|We {{present a}} {{resource}} for automatically associating strings of text with English Wikipedia concepts. Our machinery is bi-directional, {{in the sense that}} it uses the same fundamental probabilistic methods to map strings to empirical distributions over Wikipedia articles as it does to map article URLs to distributions over short, language-independent strings of natural language text. For maximal interoperability, we release our resource as a set of flat line-based text files, lexicographically sorted and encoded with UTF- 8. These files capture joint probability distributions underlying concepts (we use the terms article, concept and <b>Wikipedia</b> <b>URL</b> interchangeably) and associated snippets of text, as well as other features that can come in handy when working with Wikipedia articles and related information. Keywords: cross-language information retrieval (CLIR), entity linking (EL), Wikipedia. 1...|$|R
40|$|New {{forms of}} conceiving the web such as web 2. 0 and the {{semantic}} web have emerged for numerous purposes ranging from professional activities to leisure. The semantic web {{is based on}} associating concepts with web pages, rather than only identifying hyperlinks and repeated literals. ITACA is a project whose aim is to add semantic annotations to web pages, where semantic annotations are <b>Wikipedia</b> <b>URLs.</b> Therefore, users can write, read and vote on semantic annotations of a webpage. Semantic annotations of a webpage are ranked according to users' votes. Building upon the ITACA project, we propose a transparent, reputation-based architecture. With this proposal, semantic annotations are stored in the users' local machines instead of web servers, so that web servers transparency is preserved. To achieve transparency, an indexing server {{is added to the}} architecture to locate semantic annotations. Moreover, users are grouped into reputation domains, providing accurate semantic annotation ranking when retrieving annotations of a web page. Cache copies of semantic annotations in annotation servers are done to improve eficiency of the algorithm, reducing the number of sent messages...|$|R
500|$|The IWF {{said they}} were first {{notified}} of the <b>Wikipedia</b> <b>URL</b> on 4 December 2008. This followed the May 2008 reporting of the cover image on Wikipedia by U.S.-based social conservative site WorldNetDaily to the Federal Bureau of Investigation. A subsequent investigation by the FBI concluded that the artwork did not violate any US laws. An officer of the Concerned Women for America, a conservative Christian advocacy group, commented, [...] "By allowing that image to remain posted, Wikipedia is helping to further facilitate perversion and paedophilia". EContent magazine subsequently reported that the discussion page associated with the article declared [...] "Prior discussion has determined by broad consensus that the Virgin Killer cover will not be removed", and asserted that Wikipedia contributors [...] "favour inclusion {{in all but the}} most extreme cases". However, according to The Guardian because [...] "the IWF doesn't talk to people outside of the UK they weren't able to appreciate what was going on". Internet security expert Richard Clayton explained that [...] "We see this borderline stuff all the time; it's a no-win", before adding that the decision seems to have been based on taking the image out of context, particularly [...] "given that you can go into HMV and buy a copy on the high street". [...] On 9 December 2008 the IWF reversed its blacklist of the Wikipedia pages {{on the basis of the}} [...] "contextual issues involved in this specific case and, in light of the length of time the image has existed and its wide availability".|$|R
40|$|Tesis Doctoral leída en la Universidad Rey Juan Carlos de Madrid en 2011. Director de la Tesis: Jesús M. González BarahonaWikipedia {{stands as}} the most {{important}} wiki-based platform and continues providing the overall society with a vast set of contents and media resources related to all the branches of knowledge. Undoubtedly,Wikipedia constitutes {{one of the most remarkable}} facts in the evolution of encyclopedias and, also, a complete revolution in the area of knowledge management. Perhaps, its most innovative aspect is the underlying approach that promotes the collaboration and cooperation of users in the building of contents in a voluntary and altruistic manner. The growth of Wikipedia has never stopped since its beginning as well as its popularity. In fact, the number of visits to its different editions has placed its web site within the top-six most visited pages all over the Internet. Such kind of success has spread the use of Wikipedia beyond typical academic environments and has made it become a complete mass phenomenon. Due to this significant relevance, Wikipedia has revealed as a topic of increasing interest for the research community. However, most of the developed research is concerned with the quality and reliability of the offered contents. This previous research focuses on subjects such as reputation and trust, or addresses topics related to the evolution of Wikipedia and its growth tendencies. By contrast, this thesis is aimed to provide and empirical study and an in-depth analysis about the manner in which the different editions Wikipedia are being used by their corresponding communities of users. In this way, our main objective is the finding of temporal and behavioral patterns describing the different kinds of contents and interactions requested by Wikipedia users. Users¿ requests are expressed in the form of <b>URLs</b> submitted to <b>Wikipedia</b> as a part of the traffic directed to its supporting servers. The analysis presented here, basically, consists in the characterization of this traffic and has been developed by parsing and filtering the information elements extracted from the URLs contained in it. As we, necessarily, have had to work with a sample of all the requests to Wikipedia due to their incommensurable volume, we have, first, validated our results comparing them with trusted sources. After having analyzed the traffic to Wikipedia during a whole year, this study presents a complete characterization of the different types of requests that make part of it. Furthermore, we have found several patterns related to the temporal distributions of such kind of requests as well as to the actions and contents involved in them. The influence of the most frequently searched topics and other contents positively considered by the community, as the featured articles, in the attention that articles get is also considered as a matter of interest. Finally, we have also analyzed the different categories of articles that attract more visits and search operations in the considered editions of Wikipedia. Most of the objectives accomplished here are based on the results provided by the application developed ad-hoc to feed this study. The software engineering of this tool has been undertaken under the WikiSquilter project. We expect that this application can serve as a useful tool to characterize the traffic directed to wiki-based sites, particularly to any project supported by theWikimedia Foundation. Up to this work, no other analysis had been undertaken to study the use of Wikepedia in such a wide and thoroughgoing way. We hope that our efforts and results can serve as a significant contribution in the examination of the dynamics of use when interacting with knowledge management platforms like Wikipedia. Sistemas Telemáticos y Computació...|$|R

