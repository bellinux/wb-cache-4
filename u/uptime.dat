825|36|Public
5|$|Twitter had {{approximately}} ninety-eight percent <b>uptime</b> in 2007 (or {{about six}} full days of downtime). The downtime was particularly noticeable during events {{popular with the}} technology industry such as the 2008 Macworld Conference & Expo keynote address.|$|E
5|$|To {{capitalise}} {{on the benefits}} of cloud computing, Eagle Boys shifted its ordering system to Microsoft Azure in 2015. Through providing improved website performance and <b>uptime</b> and providing more sophisticated performance metrics, the new hosting system should support more online orders, which the Eagle Boys IT chief says are worth 1.5 times the orders which are made in-store or by telephone.|$|E
25|$|In September, 2013 the <b>Uptime</b> Institute {{announced}} {{the creation of}} the Brill Awards (named in honor of the late founder of the <b>Uptime</b> Institute, Ken Brill). The Awards are described as having been created 'to recognize efficiency in the broadest sense of the word—efficiency of capital deployment, technology, design, operations, and overall management'.|$|E
50|$|Fault {{tolerance}} is notably {{successful in}} computer applications. Tandem Computers built their entire business on such machines, which used single-point tolerance {{to create their}} NonStop systems with <b>uptimes</b> measured in years.|$|R
40|$|This {{document}} {{describes the}} methods and programs, opensource or freeware, used to benchmark processors, memory and disk subsystems and network connection architectures. These tools are also useful to stress test new machines, before their acquisition or before their introduction in a production environment, where high <b>uptimes</b> are requeste...|$|R
40|$|This paper {{presents}} a measurement-based dependability study using event logs collected during about 3 years from 133 Windows NT and 2 K workstations and servers interconnected through a LAN. We {{focus on the}} identification of machine reboots, the classification of their causes, and the evaluation of statistics characterizing the <b>uptimes,</b> downtimes, {{and the availability of}} the Windows NT and 2 K machines. 1...|$|R
25|$|<b>Uptime</b> Institute serves all {{stakeholders}} responsible for IT service availability through industry leading standards, education, peer-to-peer networking, consulting, and award programs delivered to enterprise organizations and third-party operators, manufacturers, and providers. <b>Uptime</b> Institute is recognized globally {{for the creation}} and administration of the Tier Standards & Certifications for Data Center Design, Construction, and Operations, along with its Management & Operations (M) Stamp of Approval, FORCSS® methodology, and Efficient IT Stamp of Approval.|$|E
25|$|In July 2014, Google {{announced}} that Hangouts {{would be covered}} under the same 99.9% <b>uptime</b> guarauntee that Gmail and Google Drive have, as well as 24/7 phone and email support.|$|E
25|$|<b>Uptime</b> Institute – The Global Data Center Authority®, a {{division}} of The 451 Group, has office locations in the U.S., Mexico, Costa Rica, Brazil, U.K., Spain, U.A.E., Russia, Taiwan, Singapore, and Malaysia. Visit www.uptimeinstitute.com for more information.|$|E
50|$|While {{conventional}} {{systems of the}} era, including large mainframes, had mean-time-between-failures (MTBF) {{on the order of}} a few days, the NonStop system was designed to failure intervals 100 times longer, with <b>uptimes</b> measured in years. Nevertheless, the NonStop was designed to be price-competitive with {{conventional systems}}, with a simple 2-CPU system priced at just over twice that of a competing single-processor mainframe, as opposed to four or more times of other fault-tolerant solutions.|$|R
40|$|In {{this paper}} {{we report on}} a new MOVPE process for {{horizontal}} reactors in which care was taken to avoid the contact of group III source with the heated reactor walls. This effectively reduces parasitic deposition and leads to higher reproducibility and higher <b>uptimes</b> of the reactor without maintenance. A comparison between the standard and the new process for GaN growth is made. Results of modeling and experiments are presented. (C) 2004 Elsevier B. V. All rights reserved...|$|R
40|$|We study a {{stochastic}} {{scheduling problem}} with a single machine subject to random breakdowns. We address the preemptive-repeat model; that is, if a breakdown occurs during the processing of a job, the work done on this job is completely lost and the job has to be processed from the beginning when the machine resumes its work. The objective is to complete all jobs so that the the expected weighted flow time is minimized. Limited results {{have been published in}} the literature on this problem, all with the assumption that the machine <b>uptimes</b> are exponentially distributed. This article generalizes the study to allow that (1) the <b>uptimes</b> and downtimes of the machine follow general probability distributions, (2) the breakdown patterns of the machine may be affected by the job being processed and are thus job dependent; (3) the processing times of the jobs are random variables following arbitrary distributions, and (4) after a breakdown, the processing time of a job may either remain a same but unknown amount, or be resampled according to its probability distribution. We derive the necessary and sufficient condition that ensures the problem with the flow-time criterion to be well posed under the preemptive-repeat breakdown model. We then develop an index policy that is optimal for the problem. Several important situations are further considered and their optimal solutions are obtained. Department of Applied Mathematic...|$|R
25|$|Since then, the Seattle-based <b>Uptime</b> Institute {{has been}} an {{independent}} division of The 451 Group (which is headquartered in New York) with worldwide offices in locations including San Francisco, Washington DC, London, Boston, Seattle, Denver, São Paulo, Dubai, Shanghai and Singapore.|$|E
25|$|Shipments of the NXE:3350 system {{began at}} the end of 2015, with claimed {{throughput}} of 1,250 wafers/day or 65 wafers per hour (WPH) assuming 80% <b>uptime.</b> By comparison, the 300-unit installed base of NXT 193-nm immersion systems had 96% availability and 275WPH in 2015.|$|E
25|$|Although Google has a 99.9% <b>uptime</b> {{guarantee}} for Google Drive for G Suite customers, Google Drive {{has suffered}} downtimes for both consumers and business users. During significant downtimes, Google's App Status Dashboard gets updated {{with the current}} status of each service Google offers, along with details on restoration progress. Notable downtimes occurred in March 2013, October 2014, and January 2016.|$|E
40|$|International audienceThis paper {{presents}} a measurement-based availability study of networked Unix systems, {{based on data}} collected during 11 months from 298 workstations and servers interconnected through a local area computing network. The data corresponds to event logs recorded by the Unix operating system via the Syslogd daemon. Our study focuses on the identification of machine reboots and the evaluation of statistical measures characterizing: (a) the distribution of reboots (per machine, time), (b) the distribution of <b>uptimes</b> and downtimes associated to these reboots, (c) the availability of machines including workstations and servers, and (d) error dependencies between clients and servers...|$|R
40|$|Accurately {{estimate}} {{performance of}} currently available processors {{is becoming a}} key activity, particularly in HENP environment, where high computing power is crucial. This document describes the methods and programs, opensource or freeware, used to benchmark processors, memory and disk subsystems and network connection architectures. These tools are also useful to stress test new machines, before their acquisition or before their introduction in a production environment, where high <b>uptimes</b> are requested. Comment: Talk from the 2003 Computing in High Energy and Nuclear Physics (CHEP 03), La Jolla, Ca, USA, March 2003, 2 pages, PDF. PSN TUDP 00...|$|R
40|$|This paper {{presents}} a measurement-based availability study of networked Unix systems, {{based on data}} collected during 11 months from 298 workstations and servers interconnected through a local area computing network. The data corresponds to event logs recorded by the Unix operating system via the Syslogd daemon. Our study focuses on the identification of machine reboots and the evaluation of statistical measures characterizing: a) the distribution of reboots (per machine, time), b) the distribution of <b>uptimes</b> and downtimes associated to these reboots, c) the availability of machines including workstations and servers, and d) error dependencies between clients and servers. 1...|$|R
25|$|Informix is {{generally}} considered to be optimized for environments with very low or no database administration, including use as an embedded database. It has a long track record of supporting very high transaction rates and providing <b>uptime</b> characteristics needed for mission critical applications such as manufacturing lines and reservation systems. Informix has been widely deployed in the retail sector, where the low administration overhead makes it useful for in-store deployments.|$|E
25|$|February 22, 2007 - Google {{introduced}} Google Apps Premier Edition, which {{differed from}} the free version by offering more storage (10 GB per user), APIs for business integration, 99.9% <b>uptime</b> for Gmail, and 24/7 phone support. It cost $50 per user account per year. According to Google, early adopters of Google Apps Premier Edition included Procter & Gamble, San Francisco Bay Pediatrics, and Salesforce.com. Additionally, all editions of Google Apps were then able to use Google Documents and Spreadsheets, users could access Gmail on BlackBerry mobile devices, and administrators gained more application control.|$|E
25|$|Technopark offers 100% power backup, {{uninterrupted}} {{water supply}} and ambient air conditioning for all buildings Technopark offers {{state of the art}} infrastructure facilities. 100% power is availed through Kerala State Electricity Board Limited (KSEBL) and the annual Diesel Generator operations are at < 5% time. (95% <b>uptime</b> on electricity). Technopark offers electricity Transformers capacity i.e., 110kV substation, 25 MVA dedicated internal power distribution system with built-in redundancies at all levels. Technopark is a licensee for distribution of power in the campus. The water supply is maintained by Technopark through a dedicated distribution system (dedicated power & water distribution system).|$|E
40|$|Bayesian {{forecasting}} models provide distributional {{estimates for}} random parameters, and relative to classical schemes, {{have the advantage}} that they can rapidly capture changes in nonstationary systems using limited historical data. Stochastic programs, unlike deterministic optimization models, explicitly incorporate distributions for random parameters in the model formulation, and thus have the advantage that the resulting solutions more fully hedge against future contingencies. In this paper, we exploit the strengths of Bayesian prediction and stochastic programming in a rolling-horizon approach {{that can be applied}} to solve real-world problems. We illustrate the methodology on an employee scheduling problem with uncertain <b>uptimes</b> of manufacturing equipment and uncertain production rates...|$|R
40|$|We {{consider}} {{the problem of}} routing in delay tolerant networks deployed in developing regions. Although these environments experience intermittent connectivity (hence the desire to use DTN), {{in many cases the}} topology has an underlying stability that we can exploit when designing routing protocols. By making small, yet critical, modifications to classical link state routing, we derive a more effective algorithm capable of leveraging predictions of future link <b>uptimes.</b> We describe a complete and fully-implemented protocol, capable of being deployed in the DTN reference implementation without modification. Using a simulation incorporating real-world network characteristics, we demonstrate that our system operates effectively when conventional routing and forwarding may fail...|$|R
40|$|The National Research Council of Canada 2 ̆ 019 s Institute for Ocean Technology {{employs the}} use of HP OpenVMS systems for the {{purposes}} of project data collection and storage. The Computer Systems group has chosen these VMS systems for their robust and secure nature. VMS systems are known for lengthy <b>uptimes</b> (sometimes several years) as well as their secure file system and networking model. The people of IOT need a method of conveniently accessing files through Windows file shares. The current method used for accessing these files has become problematic and so investigation into an alternative is required. Peer reviewed: NoNRC publication: Ye...|$|R
25|$|The {{refueling}} {{machine is}} mounted on a gantry crane and remotely controlled. The fuel assemblies can be replaced without shutting down the reactor, a factor significant for production of weapon-grade plutonium and, in a civilian context, for better reactor <b>uptime.</b> When a fuel assembly has to be replaced, the machine is positioned above the fuel channel, mates to it, equalizes pressure within, pulls the rod, and inserts a fresh one. The spent rod is then placed in a cooling pond. The capacity of the refueling machine with the reactor at nominal power level is two fuel assemblies per day, with peak capacity of five per day.|$|E
25|$|Google Drive for Work is a {{business}} version, a part of G Suite (formerly Google Apps for Work), announced at the Google I/O conference on June 25, 2014 and made available immediately. The service features unlimited storage, advanced file audit reporting and eDiscovery services, along with enhanced administration control and new APIs specifically useful to businesses. Users can upload files as large as 5 TB. A press release posted on Google's Official Enterprise Blog assured businesses that Google will encrypt data stored on its servers, {{as well as information}} being transmitted to or from them. Google will deliver 24/7 phone support to business users and has guaranteed 99.9% <b>uptime</b> for its servers.|$|E
25|$|However, the {{distinction}} between measuring and improving software quality in an embedded system (with emphasis on risk management) and software quality in business software (with emphasis on cost and maintainability management) is becoming somewhat irrelevant. Embedded systems now often include a user interface and their designers are as much concerned with issues affecting usability and user productivity as their counterparts who focus on business applications. The latter are in turn looking at ERP or CRM system as a corporate nervous system whose <b>uptime</b> and performance are vital {{to the well-being of}} the enterprise. This convergence is most visible in mobile computing: a user who accesses an ERP application on their smartphone is depending on the quality of software across all types of software layers.|$|E
40|$|International audienceIn {{semiconductor}} manufacturing, {{machines are}} usually qualified to process {{a limited number}} of recipes related to products. It is possible to qualify recipes on machines to better balance the workload on machines in a given toolset. However, all machines of a toolset do not have equal <b>uptimes</b> and may further suffer from scheduled and unscheduled downtimes. This may heavily impact an efficient recipe-to-machine qualification configuration. In this paper, we propose indicators for recipe-to-machine qualification management based on the overall toolset workload balance under capacity constraints. The models, deployed in industry, demonstrate that the toolset capacity must be considered while managing qualifications. Industrial experiments show how capacity consideration leads to an optimal qualification configuration and therefore capacity utilization...|$|R
40|$|This paper {{studies the}} problem of {{scheduling}} a set of jobs on a single machine subject to stochastic breakdowns, where jobs have to be restarted if preemptions occur because of breakdowns. The breakdown process of the machine is independent of the jobs processed on the machine. The processing times required to complete the jobs are constants if no breakdown occurs. The machine <b>uptimes</b> are independently and identically distributed (i. i. d.) and are subject to a uniform distribution. It is proved that the Longest Processing Time first (LPT) rule minimizes the expected makespan. For the large-scale problem, it is also showed that the Shortest Processing Time first (SPT) rule is optimal to minimize the expected total completion times of all jobs...|$|R
40|$|We {{consider}} an architecture for a serverless distributed file system {{that does not}} assume mutual trust among the client computers. The system provides security, availability, and reliability by distributing multiple encrypted replicas of each file among the client machines. To assess the feasibility of deploying this system on an existing desktop infrastructure, we measure and analyze a large set of client machines in a commercial environment. In particular, we measure and report results on disk usage and content; file activity; and machine <b>uptimes,</b> lifetimes, and loads. We conclude that the measured desklop infrastructure would passably support our proposed system, providing availability {{on the order of}} one unfilled file request per user per thousand days. Keywords Serverless distributed file system architecture, personal compute...|$|R
2500|$|The <b>Uptime</b> Institute's Tier Certification {{does not}} {{pertain to the}} Telecommunications Industry Association's standard, TIA-942. <b>Uptime</b> Institute and TIA agree on clear {{separation}} between their respective benchmarking systems ...|$|E
2500|$|... 99.9% {{guaranteed}} <b>uptime</b> {{with zero}} scheduled downtime for maintenance ...|$|E
2500|$|The full Tier Standard: Topology is {{available}} on the <b>Uptime</b> Institute website ...|$|E
40|$|Special {{issue on}} the Eight International Conference on Matrix-Analytic Methods in Stochastic Models, 6 - 10 Janueri 2014, Kerala, India This article {{presents}} an approximation method for fluid flow production lines with multi-server workstations and finite buffers. Each workstation consists of parallel identical servers, which are subject to operation-dependent failures with exponentially distributed <b>uptimes</b> and downtimes. The proposed method decomposes the production line into single-buffer subsystems, each described by a continuous state Markov process, the parameters of which are determined iteratively. The approximation method is appropriate {{for the analysis of}} longer production lines, able to accurately estimate performance characteristics (e. g., throughput and mean buffer content), and shown to perform well on a large test set. Keywords: Approximate analysis; Decomposition technique; Multi-server production lines; Operation dependent failure...|$|R
50|$|Often, an IRC bot is {{deployed}} as {{a detached}} program running from a stable host. It sits on an IRC channel {{to keep it}} open and prevents malicious users from taking over the channel. It can be configured to give channel operator status to privileged users when they join the channel, and can provide a unified channel operator list. Many of these features require that the bot be a channel operator. Thus, most IRC bots are run from computers which have long <b>uptimes</b> (generally running a BSD derivative or Linux) and a fast, stable Internet connection. As IRC has become popular with many dial-up users as well, shell accounts at shell providers have become popular as a stable Linux server with a decent connection to run a bot from.|$|R
40|$|The {{aim of this}} {{research}} is verify the validity and reliability of the organizational trust ofschool scale that advanced by Daboval, Comish, Swindle and Gaster; translated in Turkish byKamer and readvanced by us. Datas about frame validity of the scale were tested with factoranalyze. At the end of this analyiz, four sub factors (sensibility to workers, trust to administrator,openes to modernity and communication climate) were reached. Total reliabiliyt coefficient ofscale was found 0. 97. Each subfactor reliability coefficient was found for sensibility to workers 0, 95, for trust to administrator 0, 95, for openes to modernity 0, 75 and for communicationclimate 0, 92. Findings show that internal-structure reliability coefficients of subfactors werefound high. At the sama time, trust level to school organization in viewpoint of teacher wasfound in difference by way of variable of sex but not by way of teachers <b>uptimes...</b>|$|R
