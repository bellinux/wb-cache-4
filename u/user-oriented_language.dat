8|12|Public
40|$|Abstract. The {{intrinsic}} {{flexibility and}} dynamism of service-centric applications preclude their pre-release validation {{and demand for}} suitable probes to monitor their behavior at run-time. Probes must be suitably activated and deactivated according to {{the context in which}} the application is executed, but also according to the confidence we get on its quality. The paper supports the idea that significant data may come from very different sources and probes must be able to accommodate all of them. The paper presents: (1) an approach to specify monitoring directives, called monitoring rules, and weave them dynamically into the process they belong to; (2) a proxy-based solution to support the dynamic selection and execution of monitoring rules at run-time; (3) a <b>user-oriented</b> <b>language</b> to integrate data acquisition and analysis into monitoring rules. ...|$|E
40|$|The ATLAS system {{provides}} an extensive set of integrated technical computer-program modules {{for the analysis}} and design of general structural configurations, as well as capabilities that are particularly suited for the aeroelastic design of flight vehicles. The system {{is based on the}} stiffness formulation of the finite element structural analysis method and can be executed in batch and interactive computing environments on CDC 6600 /CYBER computers. Problem-definition input data are written in an engineering-oriented language using a free field format. Input-data default values, generation options, and data quality checks provided by the preprocessors minimize the amount of data and flowtime for problem definition/verfication. Postprocessors allow selected input and calculated data to be extracted, manipulated, and displayed via on-line and off-line prints or plots for monitoring and verifying problem solutions. The sequence and mode of execution of selected program modules are controlled by a common <b>user-oriented</b> <b>language...</b>|$|E
40|$|High quality {{mathematical}} illustration {{has long}} been a specialized craft, akin to the layout of musical scores or mathematical formulæ. Illustrating a proof, or drawing a graph, used to be difficult, and it is easy to find errors in the drawings in old books. Drawing errors are of course a problem for the understanding of a proof. Unfortunately, such cases are still common in the current scientific literature, perhaps because mouse-made drawings do not take full advantage of the power now available. The shift of power, from hand-quality drawings to computer-quality drawings, goes back to the 1970 s and started with the advent of good printers. New computer languages were developed for graphical tasks. In 1981, Brian Kernighan described his high-level PIC language for typesetting graphics [3]. At about the same time, the first version of the PostScript language was made public. Unlike languages such as PIC, PostScript was designed not as a <b>user-oriented</b> <b>language</b> but rather as a page description language to serve as an interface between graphics-producing software and printers. Printers with PostScript interpreters were then manufactured, and consequently software was written to produce PostScript files. These files were Denis Roegel is maître de conférences at Université Nancy. Hi...|$|E
40|$|The {{automated}} {{engineering design}} (AED) is reviewed, {{consisting of a}} high level systems programming language, a series of modular precoded subroutines, {{and a set of}} powerful software machine tools that effectively automate the production and design of new languages. AED is used primarily for development of problem and <b>user-oriented</b> <b>languages.</b> Software production phases are diagramed, and factors which inhibit effective documentation are evaluated...|$|R
40|$|International audienceTo {{improve the}} link between {{operators}} and equipment, communication systems have begun using natural (<b>user-oriented)</b> <b>languages</b> such as speech and gestures. Our goal is to present gesture recognition based on the fusion of measurements from different sources. Sensors {{must be able to}} capture at least the location and orientation of the hand, as is done by Dataglove and a video camera. Datagloge gives the hand position and the video camera gives the general arm gesture representing the gesture's physical and spatial properties based on the two-dimensional (2 D) skeleton representation of the arm. Measurement is partly complementary and partly redundant. The application is distributed over intelligent co-operating sensors. We detail the measurement of hand positioning and arm gestures, fusion processes, and implementation...|$|R
40|$|Because of the {{differences}} in informational needs among medical practices, medical record systems should be flexible. The use of data base management and <b>user-oriented</b> command <b>languages</b> helps to achieve flexibility. The Regenstrief Medical Record System is based upon a data base management system and two <b>user-oriented</b> command <b>languages</b> (the RDB Command Language and CARE). Most batch reports, file maintenance procedures and ad hoc retrievals can be specified by the user by means of these two languages. This means that the user can specify which reports he wants and how they should look. Daily on-line activities are performed by application programs. The data base system also provides flexibility to these programs since the content and format of many of the display screens are defined by statements that are similar to the command language statements and stored within a text file. The Regenstrief Medical Record System now carries records for 60, 000 patients...|$|R
40|$|In {{this paper}} a {{software}} project supporting architectural design is outlined. Such a project aims {{to develop the}} new design language PLASM (a Programming Language for Architectural Symbolic Modelling), which is planned {{to be a very}} high-level, <b>user-oriented</b> <b>language,</b> belonging to the class of constraint languages. The language PLASM will support a small set of abstract data types which are significant in various outstanding problems of architectural design, and will offer both procedural features and non-procedural constraints satisfaction. It will allow the designer to make use of a large set of computing tools in any phase of architectural design, in order to explore a wider set of design solutions. Customizable evaluation functions will be available in the language. The execution of a PLASM program may result either in generating or in updating a semantic network over a set of data objects solving the geometric problem under consideration. The proposed language will support both abstract data types significant in the design domain, and tools performing automatized data generation and transformations between different data types. The modification of any object in such a system, both performed by editing a daemon program and/or by interactively modifying a data object, will result in the immediate propagation of changes into the problem network, by activating a message passing mechanism. ...|$|E
40|$|Abstract Background Process {{orientation}} {{is one of}} the essential elements of quality management systems, including those in use in healthcare. Business processes in hospitals are very complex and variable. BPMN (Business Process Modelling Notation) is a <b>user-oriented</b> <b>language</b> specifically designed for the modelling of business (organizational) processes. Previous experiences of the use of this notation in the processes modelling within the Pathology in Spain or another country are not known. We present our experience in the elaboration of the conceptual models of Pathology processes, as part of a global programmed surgical patient process, using BPMN. Methods With the objective of analyzing the use of BPMN notation in real cases, a multidisciplinary work group was created, including software engineers from the Dep. of Technologies and Information Systems from the University of Castilla-La Mancha and health professionals and administrative staff from the Hospital General de Ciudad Real. The work in collaboration was carried out in six phases: informative meetings, intensive training, process selection, definition of the work method, process describing by hospital experts, and process modelling. Results The modelling of the processes of Anatomic Pathology is presented using BPMN. The presented subprocesses are those corresponding to the surgical pathology examination of the samples coming from operating theatre, including the planning and realization of frozen studies. Conclusion The modelling of Anatomic Pathology subprocesses has allowed the creation of an understandable graphical model, where management and improvements are more easily implemented by health professionals. </p...|$|E
40|$|AbstractThe {{importance}} of the analysis, modelling and management of a business process is not restricted to a specific enterprise sector. In {{the field of health}} management, {{as a result of the}} nature of the service offered, health institutions’ processes are also the basis for decision making which is focused on achieving their objective of providing quality medical assistance. Business processes in hospitals are very complex and variable. BPMN (Business Process Model and Notation) is a <b>user-oriented</b> <b>language</b> specifically designed for the modelling of business (organizational) processes. The objective of this work is to show the experience obtained in the creation of the conceptual models of certain hospital processes which can be used as a basis for others in collaboration with hospitals in order to model their processes using BPMN. In first instance, the processes were modeled with purposes to apply metrics for measuring the usability as a software quality attribute according to standard ISO 9126. The next challenge is to evaluate the usability of the models from the point of view of the user according to standard ISO 9241 - 11 that defines usability as “the extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency and satisfaction in a specified context of use”. Starting from usability engineering, a proposal of a framework that considers evaluation criteria about previously modeled processes with BPMN results necessary. In order to achieve the framework are considered studies on the usability evaluation for business process modeling tools and languages...|$|E
40|$|An {{automatic}} Navaids Checkout System {{for use in}} Space Shuttle {{development is}} discussed. The groundwork leading to the development is presented, followed by {{a description of the}} hardware. Finally, system utilization including operator interface and system software is discussed. The Navaids Checkout System is extremely flexible with capability to handle different test articles with a minimum of hardware reconfiguration. Application software is written in a high level <b>user-oriented</b> test <b>language.</b> The checkout system has been in operation for approximately one year with capability to handle VOR, ILS, TACAN, ATC Radar Beacon, and UHF/VHF communications equipment...|$|R
40|$|This {{paper is}} a {{preliminary}} report on SAL, a Semistructured ALgebra. SAL is an algebraic query language that we are designing {{to serve as a}} target language for translation from declarative <b>user-oriented</b> query <b>languages</b> for XML. Like existing algebras, it can serve to provide a concise representation of query execution, that still leaves room for various decisions about actual execution plans, and supports rewritebased and cost-based optimizations. It has been influenced by the work in [6, 7], with extensions that we believe are relevant to the XML format...|$|R
40|$|Recent {{database}} {{applications are}} typically oriented towards a large set of non-expert users, and therefore, {{they need to}} be equipped with suitable interfaces facilitating the interaction with the system. Moreover, the incorporation of the time dimension in database systems is a desirable feature. Indeed, several temporal data models and the corresponding textual query languages have been proposed. However, there is a limited amount of research concerning the investigation of <b>user-oriented</b> <b>languages</b> for querying temporal databases. Our proposal addresses such a need. In particular, we propose a visual query environment, namely Temporal Visual Query Environment (TVQE) which provides an easier interaction of the user with temporal databases. The system adopts a diagrammatic representation of the database schema (including temporal classes and relationships) and a "graphical notebook" as interaction metaphor. In our approach, non-database experts are released from syntactical difficulties which are typical of textual languages, and they can easily express temporal queries by means of elementary graphical operations (e. g. click on a node label). Differently from many proposals in the field of visual query languages, the language underlying TVQE is provided with formal syntax and semantics. It is based on a minimal set of temporal graphical primitives (TGPs), which are defined on a Temporal Graph Model (TGM), with visual syntax and object-based semantics. In this paper we mainly concentrate on the formal aspects of TVQE, and provide some hints on the visual interaction mechanisms and implementation issues. (C) 2002 Elsevier Science Ltd. All rights reserved...|$|R
40|$|This {{report is}} aimed at people with {{scientific}} background, such as physicists, chemists, biologists, etc. as well as management personnel. Its purpose is to stimulate scientists of all disciplines to consider the advantages of using a generalized data management system (GDMS) for storage, manipulation and retrieval of the data they collect and often need to share. The report should also {{be of interest to}} managers and programmers who need to make decisions on the management of scientific (numeric or nonnumeric) data. Another goal of this report is to expose the features that a GDMS should have which are specifically necessary to support scientific data, such as data types and special manipulation functions. It is hoped that the way the report is organized, starting with basic concepts and the terminology of GDMS, then discussing the requirements of GDMS for scientific data, and describing case studies, will be of value to people who have not been exposed to GDMS before. At the same time, the reader more familiar with GDMS can benefit from guidance on available systems, from discussion of other users’ experience, and capabilities in GDMS helpful in handling scientific data. More specifically, the report will: a. Give a clear introduction to what GDMS are, why they may be useful, and what computing hardware is needed. b. Include a list of the capabilities required in a Generalized Database Management System for handling scientific data. Presented at a time when considerable effort is being invested in GDMS software development, such an inventory may be in time to influence the specifications of this third generation of Data Management Systems. c. Compare possible alternatives: do-it-yourself software, APL, file management systems. d. Show by case studies of a variety of existing and potential GDMS applications to scientific data (in different fields, with more or less numerical content) what is involved in GDMS use, and what advantages may result. e. Survey the direction of development work in GDMS: hardware development trends, software development trends, distributed Database systems, and database conversion. A GDMS is a system that provides generalized tools for the purpose of defining a database structure, for loading the data, for modification of the data, and for organizing the database for efficient retrieval and formatted output. A data management system is ’’generalized" when it provides a <b>user-oriented</b> <b>language</b> for the different functions, so {{that it is possible to}} define any new database, its internal organization, and to retrieve and modify the data without the need to develop special purpose software (program) for each new database. The main purposes of a GDMS are quoted from a recent survey [1]: • to make an integrated collection of data available to a wide variety of users; • to provide for quality and integrity of the data; • to ensure retention of privacy through security measures within the system; and • to allow centralized control of the database, which is necessary for efficient data administration. From the user point of view GDMS should provide: • data independence, i. e. that application software does not need to be modified when data or data structures are changed • languages and facilities to perform the spectrum of data management functions: data definition, data entry and updating, conditional search and data retrieval, and data output and report generation. These facilities could be available in on-line or batch mode depending on the needs of the application. • the representation and access of both numerical and literal data. The above points will be discussed in more detail in the next section of the report. The advantages of using a GDMS are numerous, but for scientists and other users who are not computer specialists (and who cannot afford the time to become expert programmers) the main advantage is the immediate availability of a system for database handling. If their data handling requirements are relatively simple, these may perhaps be satisfied without further programming by use of the query language/report writer facilities of a suitable GDMS. Where user requirements are more complicated, applications programs in a high-level ’host language’ (such as COBOL or FORTRAN) may be linked to the database by embedding GDMS Data Manipulation Language statements in those programs. The available programming effort can be concentrated on the specific problems in hand. The generality of GDMS can sometimes degrade the efficiency of an application compared to a specially developed program, but this consideration is usually outweighed by the savings in software development time and cost, by the availability of the data for numerous applications, and by facilities providing integrity and security and easy modification and manipulation of the data. Database management, like the use of highlevel programming languages instead of assembler, is the latest in a long series of compromises in which increased user convenience is traded against computer efficiency. Although initially these trade-offs are expensive, hardware and software have historically tended to evolve in a way which reduces the cost of convenience. Recognizing that scientific data may have different characteristics from ’’commercial” data, it is the aim of this study to explore the differences and point out systems that have features amenable to the handling of scientific data. Therefore, the people involved in the study were selected both from the scientific community and the computer field. In particular, cases where GDMS were used for the handling of scientific data are described. The report introduces first the spectrum of GDMS approaches, techniques and terminology. This is done at a level which describes the functionality of GDMS without going into the details of how it is achieved. Then a survey of (mostly commercially) available systems is given, together with comparative features. This is followed by a discussion of requirements and capabilities needed to deal with scientific data and a description of several data management systems designed specifically to handle scientific data. In the next sections several example scientific applications that use GDMS successfully are described, followed by examples of potential applications now under consideration. Finally, a discussion of future trends in the development of GDM S and related areas is given so that the reader may consider their possible effect on his environment. In the conclusion section (part of the epilogue) we summarize the viewpoints of participants relative to when should G D M S be used and what to expect in using them. 347 page...|$|E
40|$|The IDAPS (Image Data Processing System) is a <b>user-oriented,</b> computer-based, <b>language</b> {{and control}} system, which {{provides}} a framework or standard for implementing image data processing applications, simplifies set-up of image processing runs so that the system may be used without a working knowledge of computer programming or operation, streamlines operation of the image processing facility, and allows multiple applications to be run in sequence without operator interaction. The control system loads the operators, interprets the input, constructs the necessary parameters for each application, and cells the application. The overlay feature of the IBSYS loader (IBLDR) provides the means of running multiple operators which would otherwise overflow core storage...|$|R
40|$|International audienceThis paper {{proposes a}} notion of fuzzy graph {{database}} and describes a fuzzy query algebra {{that makes it possible}} to handle such database, which may be fuzzy or not, in a flexible way. The algebra, based on fuzzy set theory and the concept of a fuzzy graph, is composed of a set of operators {{that can be used to}} express preference queries on fuzzy graph databases. The preferences concern i) the content of the vertices of the graph and ii) the structure of the graph. In a similar way as relational algebra constitutes the basis of SQL, the fuzzy algebra proposed here underlies a <b>user-oriented</b> query <b>language</b> and an associated tool implementing this language that are also presented in the paper...|$|R
40|$|A {{simulation}} {{study of}} library-based information retrieval systems is described. Basic models {{for each of}} several important aspects-are presentecl. (1) user behavior, emphasizing response to quahty and delays in services; (2) the scheduling of services {{and the organization of}} the machine-readable files; and (3) the distribution of conventional library materials. Many of the variables in the model (e. g [...] user expectations of service time, delays involved in providing services, etc.) are random. An adaptive element is present in the form of admitting changes in user expectations in response to system changes. The need for frequent model change and the merging of component models into a comprehensive model for the entire system is established as the basis for use of a <b>user-oriented</b> simulation <b>language.</b> Statistical facility beyond that supplied in the language used (GPSS/ 360) is required to achieve the goals of this and related investigations. (Author...|$|R
40|$|This thesis effort {{developed}} a <b>user-oriented</b> query <b>language</b> interface, patterned after IBM 2 ̆ 7 s Query-by-Example, for the Mistress relational database. The interface, Mistress/QBE, is written entirely in C {{and uses the}} UNIX curses library of subroutines to allow full screen input and output. Mistress /QBE allows the user to issue commands to draw pictorial representations of tables which exist in the database. The user then enters values and operators into the tables to specify a query by indicating attributes {{to be used in}} conditional selections, sort and grouping orders, and output formats. Mistress /QBE decodes the information entered on the screen and formulates a Mistress Query Language command which is passed to the Mistress standard C language interface for execution. With a few minor exceptions, any query which can be written in the Mistress Query language can also be written in Mistress/QBE. The interface also includes a high-level operator- called grouping, which is supported by IBM 2 ̆ 7 s QBE but not by native Mistress...|$|R
40|$|Workflow {{modeling}} is {{a challenging}} activity and designers {{are likely to}} introduce errors, especially in complex industrial processes. Effective process verification is essential at design time because the cost of fixing errors during runtime is substantially higher. However, most <b>user-oriented</b> workflow modeling <b>languages</b> lack formal semantics that hinders such verification. In this paper, we propose a generic approach based on the model transformation to verify workflow processes. The model transformation includes two steps: first, it formalizes the desirable semantics of each modeling element; secondly, it translates a workflow process with clear semantics to an equivalent Petri net. Thus, we can verify the original workflow process using existing Petri net theory and analysis tools. As a comprehensive case study, verifying workflow processes in an industrial modeling language (TiPLM) is presented. Experimental evaluations on verifying real-world business processes validate our approach...|$|R
40|$|Abstract. Emergent {{workflows}} {{constitute a}} particular category of adaptive workflows. An emergent workflow {{is described by}} a partially structured process model that emerges from the workflow itself; i. e. process definition and enactment are intertwined. The dynamic and ad-hoc work that is becoming increasingly important in today’s knowledge intensive organisations has an emergent nature. We describe a prototype cooperation support environment for such work currently being developed. This WORKWARE system includes task management and interactive workflow enactment with contextual awareness support, available through a simple web browser interface. The architecture is highly tailorable, allowing users to add and interconnect new tools and information types. Our workflow definition language is simple, yet expressive, and it narrows the semantic gap between the planning (definition) of the workflow {{and the performance of}} the work, enabling ordinary end users to do both. The <b>user-oriented</b> workflow modelling <b>language</b> has its focus on process instances, not on process types. It targets in situ articulation work and temporarily circumvents complexity stemming from the need to consider future instances of "similar " processes. Since the user-oriented process instance models are mutable and possibly incomplete, the environment is extended to include interactive workflow enactment, where the enactment service and users cooperate in managing the workflow. ...|$|R

