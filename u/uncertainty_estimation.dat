794|1437|Public
50|$|K. J. Beven and J. W. Hall (Eds.), 2014, Applied <b>Uncertainty</b> <b>Estimation</b> in Flood Risk Management, Imperial College Press: London.|$|E
5000|$|Beven, K.J. and Freer, J., 2001a. Equifinality, data assimilation, and <b>uncertainty</b> <b>estimation</b> in {{mechanistic}} modelling {{of complex}} environmental systems, Journal of Hydrology, 249, 11-29.|$|E
5000|$|GLUE - Generalized Likelihood <b>Uncertainty</b> <b>Estimation</b> (when {{modeling}} environmental systems {{there are}} many different model structures and parameter sets that may be behavioural or acceptable in reproducing the behaviour of that system) ...|$|E
40|$|Recent {{advances}} in deep learning have led various applications to unprecedented achievements, which could potentially bring higher intelligence {{to a broad}} spectrum of mobile and ubiquitous applications. Although existing studies have demonstrated the effectiveness and feasibility of running deep neural network inference operations on mobile and embedded devices, they overlooked the reliability of mobile computing models. Reliability measurements such as predictive <b>uncertainty</b> <b>estimations</b> are key factors for improving the decision accuracy and user experience. In this work, we propose RDeepSense, the first deep learning model that provides well-calibrated <b>uncertainty</b> <b>estimations</b> for resource-constrained mobile and embedded devices. RDeepSense enables the predictive uncertainty by adopting a tunable proper scoring rule as the training criterion and dropout as the implicit Bayesian approximation, which theoretically proves its correctness. To reduce the computational complexity, RDeepSense employs efficient dropout and predictive distribution estimation instead of model ensemble or sampling-based method for inference operations. We evaluate RDeepSense with four mobile sensing applications using Intel Edison devices. Results show that RDeepSense can reduce around 90 % of the energy consumption while producing superior <b>uncertainty</b> <b>estimations</b> and preserving at least the same model accuracy compared with other state-of-the-art methods...|$|R
25|$|The {{matched filter}} may be {{generalized}} to an analogous procedure based on a Student-t distribution by also considering <b>uncertainty</b> (e.g. <b>estimation</b> <b>uncertainty)</b> in the noise spectrum. On the technical side, this entails repeated or iterative matched-filtering.|$|R
40|$|This article {{seeks to}} make an {{assessment}} of <b>estimation</b> <b>uncertainty</b> in a multi-rating class loan portfolio. Relationships are established between <b>estimation</b> <b>uncertainty</b> and parameters such as probability of default, intra- and inter-rating class correlation, degree of inhomogeneity, number of rating classes used, number of debtors and number of historical periods used for parameter estimations. In addition, by using an exemplary portfolio based on Moody’s ratings, {{it becomes clear that}} <b>estimation</b> <b>uncertainty</b> does indeed have an effect on interest rates. credit portfolio risk, <b>estimation</b> <b>uncertainty,</b> bootstrapping, economic equity...|$|R
50|$|Roxar Software Solutions {{develops}} {{and supplies}} software for 3D modelling, analysis andIntegrated simulation of oil reservoirs. Flagship software products include Roxar’s reservoir modelling suite Roxar RMS and its Roxar Tempest reservoir simulation, history matching and <b>uncertainty</b> <b>estimation</b> software.|$|E
50|$|NNPDF is {{the acronym}} used to {{identify}} the parton distribution functions from the NNPDF Collaboration. NNPDF parton densities are extracted from global fits to data based {{on a combination of}} a Monte Carlo method for <b>uncertainty</b> <b>estimation</b> and the use of neural networks as basic interpolating functions.|$|E
50|$|In hydrology, {{generalized}} likelihood <b>uncertainty</b> <b>estimation</b> (GLUE) is {{a statistical}} method for quantifying {{the uncertainty of}} model predictions. The method has been introduced by Beven and Binley (1992). The basic idea of GLUE is that given our inability to represent exactly in a mathematical model how nature works, {{there will always be}} several different models that mimic equally well an observed natural process (such as river discharge). Such equally acceptable or behavioral models are therefore called equifinal.|$|E
40|$|Abstract: This paper {{describes}} the way {{by which the}} National Pressure Laboratory in Brazil has been calculating its calibration measurement capabilities (CMC) using the <b>uncertainty</b> <b>estimations</b> contained in the ISO GUM 95 and declared in the appendix C of the BIPM, and verifying {{if there is any}} convergence and consistency between the measurements results calculate with both methods...|$|R
40|$|The use of {{probability}} of default estimates to assess the risks of a credit portfolio should not ignore <b>estimation</b> <b>uncertainty.</b> The latter can be quantified by confidence intervals. But assumptions about dependencies of these intervals are inconsistent with assumptions of conventional credit portfolio models. Based on simulation studies this paper shows, that a model which include <b>estimation</b> <b>uncertainty</b> but ignore default correlation might estimate the real credit risk more correctly than a model that implicates default correlation but ignore <b>estimation</b> <b>uncertainty.</b> The latter is a trait of conventional credit portfolio models. In this paper quantifying of <b>estimation</b> <b>uncertainty</b> {{based on the idea}} of confidence intervals and the underlying probability distributions of these intervals. {{probability of default}}, <b>estimation</b> <b>uncertainty,</b> risk assessment...|$|R
40|$|International audienceThis paper {{presents}} {{parts of}} investigations {{done in a}} VHF spherical Near-Field system in order to estimate measurement uncertainties. First is briefly presented the mono-probe Near-Field system and <b>uncertainties</b> <b>estimations</b> challenges due to low frequencies. Then are described the specific and appropriated approaches for the considered errors terms. Classical pattern comparison is used. Finally is provided a global budget error with and without time filtering to appreciate the benefit of such an approach...|$|R
5000|$|Performance characterization, {{and figures}} of merit Like most arenas in the {{physical}} sciences, chemometrics is quantitatively oriented, so considerable {{emphasis is placed on}} performance characterization, model selection, verification & validation, and {{figures of merit}}. The performance of quantitative models is usually specified by root mean squared error in predicting the attribute of interest, and the performance of classifiers as a true-positive rate/false-positive rate pairs (or a full ROC curve). A recent report by Olivieri et al. provides a comprehensive overview of figures of merit and <b>uncertainty</b> <b>estimation</b> in multivariate calibration, including multivariate definitions of selectivity, sensitivity, SNR and prediction interval estimation. [...] Chemometric model selection usually involves the use of tools such as resampling (including bootstrap, permutation, cross-validation).|$|E
50|$|His main {{research}} interests are in hydrological modelling {{and understanding the}} prediction uncertainties associated with environmental models. He was the originator with Mike Kirkby of the TOPMODEL Concepts and the originator of the Generalised Likelihood <b>Uncertainty</b> <b>Estimation</b> (GLUE) methodology. GLUE {{has been applied to}} a wide variety of fields including rainfall-runoff modelling, flood inundation, water quality modelling, sediment transport, recharge and groundwater modelling, vegetation growth models, aphid populations, forest fire and tree death modelling. He is working on novel modelling of flow and transport on hillslopes and in catchments, modelling the impacts of climate and land management on flood runoff and flood frequency, nonparametric estimation of the rainfall-flow nonlinearity, and flood forecasting. He has published 10 books and over 350 peer reviewed papers.|$|E
50|$|In {{metrology}} at macro scale achieving traceability {{is quite}} easy and artefacts like scales, laser interferometers, step gauges, and straight edges are used. At nanoscale a crystalline highly oriented pyrolytic graphite (HOPG), mica or silicon surface is considered suitable used as calibration artefact for achieving traceability. But {{it is not}} always possible to ensure traceability. Like what is a straight edge at nanoscale and even if take the same standard as that for macroscale {{there is no way to}} calibrate it accurately at nanoscale. This so because the requisite internationally or nationally accepted reference standards are not always there. Also the measurement equipment required to ensure traceability has not been developed. The generally used for traceability are miniaturisation of traditional metrology standards hence there is a need for establishing nanoscale standards. Also there is a need to establish some kind of <b>uncertainty</b> <b>estimation</b> model. Traceability is one of the fundamental requirements for manufacturing and assembly of products when multiple producers are there.|$|E
40|$|Abstract—We {{develop a}} new linear {{estimator}} for estimating an unknown parameter vector x in a linear model {{in the presence of}} bounded data uncertainties. The estimator is designed to minimize the worst-case regret over all bounded data vectors, namely, the worst-case difference between the mean-squared error (MSE) attainable using a linear estimator that does not know the true parameters x and the optimal MSE attained using a linear estimator that knows x. We demonstrate through several examples that the minimax regret estimator can significantly increase the performance over the conventional least-squares estimator, as well as several other least-squares alternatives. Index Terms—Deterministic parameter estimation, linear estimation, mean squared error bounded data <b>uncertainties</b> <b>estimation,</b> minimax estimation, regret. I...|$|R
40|$|International audienceThis work applies {{sensitivity}} analysis to a kinetic model of hydrotreating processes. The proposedapproach is subdivided into several steps: The {{first step is}} to build the kinetic model. The second stepis to develop a simplified model (meta model) on which easy calculations can be performed in the nextstep. The third step is to use the meta model to estimate the influence of each input on the model outputwithout Monte Carlo methods which are difficult to manage. Sensitivity analyses are very useful formodel comparison and <b>uncertainties</b> <b>estimation...</b>|$|R
40|$|This {{application}} note describes the quantification of cadmium, chromium, lead and mercury in plastic materials by external calibration using the Agilent 7500 ce ICP-MS system {{equipped with an}} Octopole Reaction System (ORS). Isotope dilution analysis with ICP-MS {{was used as a}} confirmatory technique. Good agreement of the results obtained by the two calibration approaches was achieved. The sample digestion methodology, tuning considerations, results and <b>uncertainty</b> <b>estimations</b> are dis-cussed. The method validated with IDMS results has potential as a fast analytical tool for compliance testing laboratories...|$|R
40|$|Method {{based on}} Richardson {{extrapolation}} using {{the concept of}} Grid Convergence Index (GCI) proposed by Roache [4] is {{the most commonly used}} and the most convincing ap-proach for numerical <b>uncertainty</b> <b>estimation.</b> With a carefully designed grid set, the GCI approach can give reliable <b>uncertainty</b> <b>estimation</b> for global quantity such as the resis...|$|E
40|$|Method of {{expanded}} <b>uncertainty</b> <b>estimation</b> {{was introduced}} and investigated. The methods {{is based on}} procedure of data normalization due to Jonson transformation. The expanded uncertainty evaluation precision of investigated method versus method of substitution to Gauss distribution was explore. The advantage of method of measuring result?s expanded <b>uncertainty</b> <b>estimation</b> based on Jonson transformation was shown. ????????? ? ?????????? ????? ?????????? ?????????? ???????????????? ?????????? ?????????. ????? ?????????? ?? ????????? ???????????? ?????? ? ??????? ????????? ????????????? ????????. ??????????? ???????? ??????????? ??????????? ???????????????? ???????????? ??????? ? ????????? ? ??????? ?????? ??????????????? ?????? ????????????? ???????????????? ??????????? ??????????????. ???????? ???????????? ?????? ?????????? ??????????? ???????????????? ??? ?????? ?????????????? ????????...|$|E
40|$|The {{uncertainty}} of temperature prediction {{from the heat}} flux error is estimated using first and second order adjoint equations. The adjoint codes developed for the inverse heat transfer problems provide the <b>uncertainty</b> <b>estimation</b> for the corresponding forward problems. Numerical tests corroborate the feasibility of fast <b>uncertainty</b> <b>estimation</b> using Hessian maximum eigenvalue obtained via second orde...|$|E
30|$|The {{hydrological}} balance has a {{high limit}} of groundwater estimation; this is principally due to the high <b>uncertainty</b> in the <b>estimation</b> of Real evapotranspiration (Turc, Penman, and Thornthwaite) methods. For this problem the model of Chibane et al. was derived to solve these problems. To minimize the high <b>uncertainty</b> in <b>estimation</b> of recharge using the Hydrological water budget (some hydrological balance in semi-arid give a negative balance) which makes estimation of recharge very complicated.|$|R
40|$|Fault {{tolerance}} and safety verification of control {{systems that have}} state variable <b>estimation</b> <b>uncertainty</b> are essential {{for the success of}} autonomous robotic systems. A software control architecture called mission data system, developed at the Jet Propulsion Laboratory, uses goal networks as the control program for autonomous systems. Certain types of goal networks can be converted into linear hybrid systems and verified for safety using existing symbolic model checking software. A process for calculating the probability of failure of certain classes of verifiable goal networks due to state <b>estimation</b> <b>uncertainty</b> is presented. A verifiable example task is presented and the failure probability of the control program based on <b>estimation</b> <b>uncertainty</b> is found...|$|R
40|$|This paper studies how {{the optimal}} energy {{management}} of a {{hybrid electric vehicle}} and a {{plug-in hybrid electric vehicle}} is affected by uncertain estimates of the battery state of charge. A simple model for the battery dynamics and the state of charge estimation is postulated, inspired by the known characteristics of previously proposed estimation schemes. Based {{on the assumption that the}} drive cycle is perfectly known, the effects of state of charge <b>estimation</b> <b>uncertainty</b> is studied by including the <b>estimation</b> <b>uncertainty</b> in the optimization of the energy management strategy. The simulations indicate lower battery usage and higher fuel consumption as the <b>estimation</b> <b>uncertainty</b> increases...|$|R
40|$|Although the {{scanning}} white light interferometer can provide measurement results with subnanometer resolution, the measurement accuracy {{is far from}} perfect. The surface roughness and surface gradient have significant influence on the measurement uncertainty since the corresponding height differences within a single CCD pixel cannot be resolved. This paper presents an <b>uncertainty</b> <b>estimation</b> method for estimating the measurement uncertainty due to the surface gradient of the workpiece. The method is developed based on the mathematical expression of an <b>uncertainty</b> <b>estimation</b> model which is derived and verified {{through a series of}} experiments. The results show that there is a notable similarity between the predicted uncertainty from the <b>uncertainty</b> <b>estimation</b> model and the experimental measurement uncertainty, which demonstrates the effectiveness of the method. With the establishment of the proposed <b>uncertainty</b> <b>estimation</b> method, the uncertainty associated with the measurement result can be determined conveniently. Department of Industrial and Systems Engineerin...|$|E
30|$|However, <b>uncertainty</b> <b>estimation</b> for the ICA output signals {{should be}} {{improved}} further, {{in order to}} approximate more closely the ideally achievable performance of this strategy. For this purpose, {{it will be interesting}} to compare the proposed <b>uncertainty</b> <b>estimation</b> to other approaches. Specifically, the <b>uncertainty</b> <b>estimation</b> described in [7] is of interest for use with any type of recognition feature and preprocessing method, but it requires learning of a regression tree for the given specific feature set and environment. In contrast, feature-specific methods described for example in [2, 3] are applicable only to the feature domain they have been derived for, but can be used without the need for additional training stages.|$|E
40|$|Abstract. The {{chemical}} quantity pH is {{a quality}} control parameter used in several industrial processes. Therefore, its proper determination and <b>uncertainty</b> <b>estimation</b> are {{extremely important to}} provide reliability and traceability to pH measurements. The <b>uncertainty</b> <b>estimation</b> procedures recommended in ISO-GUM are largely used by several laboratories and institutes. This work compares the ISO-GUM approach and the Monte Carlo simulation method for the Ag/AgCl electrode potential uncertainty (UEo) determination used in pH <b>uncertainty</b> <b>estimation</b> in a phosphate solution at 25 oC. The Monte Carlo simulation showed very similar results {{in comparison to the}} ISO-GUM approach. It can be concluded that both methods are applicable for UEo determination and give reliable results...|$|E
40|$|Parameter <b>estimation</b> <b>uncertainty</b> {{is often}} {{neglected}} in reliability studies, i. e. point estimates of distribution parameters {{are used for}} representative fractiles, and in probabilistic models. A numerical example examines {{the effect of this}} uncertainty on structural reliability using Bayesian statistics. The study reveals that the neglect of parameter <b>estimation</b> <b>uncertainty</b> might lead to an order of magnitude underestimation of failure probability...|$|R
3000|$|... [...]. Therefore, the evitable noisy <b>estimation</b> <b>uncertainty</b> in {{wireless}} environments may further paralyze receiving performance [39].|$|R
40|$|Abstract — In this paper, {{adaptive}} control is studied {{for a class}} of nonlinear discrete-time systems in parameter-strict-feedback form with both parametric and non-parametric uncertainties. The non-parametric uncertainty function is assumed to sat-isfy the Lipschitz condition. To achieve asymptotical tracking performance, <b>estimation</b> of both <b>uncertainties</b> is constructed. Future states are predicted to overcome the noncausal problem. Based on future states prediction and <b>uncertainties</b> <b>estimation,</b> a novel {{adaptive control}} is proposed. An augmented tracking error of equal growth order of the output tracking error {{is used in the}} parameter estimation law. The proposed adaptive control achieves asymptotical tracking performance and guarantees the boundedness of all closed-loop signals. The effectiveness of the proposed control law is demonstrated in the simulation. I...|$|R
30|$|Three simple {{examples}} will {{be presented}} to illustrate the least-squares approach to <b>uncertainty</b> <b>estimation.</b>|$|E
40|$|An <b>uncertainty</b> <b>estimation</b> and ensitivity {{analysis}} is performed on multi-step de-embedding for SiGe HBT small-signal modeling. The <b>uncertainty</b> <b>estimation</b> {{in combination with}} uncertainty model for deviation in measured S-parameters, quantifies the possible error value in de-embedded two-port parameters (Y and Z-parameters). The {{analysis is}} applied to a 0. 35 µm 60 GHz fT SiGe HBT in frequency range 45 MHz to 26 GHz...|$|E
40|$|Abstract. We {{present a}} new method for the <b>uncertainty</b> <b>estimation</b> of {{diffusion}} parameters for quantitative body DW-MRI assessment. Dif-fusion parameters <b>uncertainty</b> <b>estimation</b> from DW-MRI {{is necessary for}} clinical applications that use these parameters to assess pathology. However, <b>uncertainty</b> <b>estimation</b> using traditional techniques requires re-peated acquisitions, which is undesirable in routine clinical use. Model-based bootstrap techniques, for example, assume an underlying linear model for residuals rescaling and cannot be utilized directly for body diffusion parameters <b>uncertainty</b> <b>estimation</b> due to the non-linearity of the body diffusion model. To offset this limitation, our method uses the Unscented transform to compute the residuals rescaling parameters from the non-linear body diffusion model, and then applies the wild-bootstrap method to infer the body diffusion parameters uncertainty. Validation through phantom and human subject experiments shows that our method identify the regions with higher uncertainty in body DWI-MRI model parameters correctly with realtive error of ∼ 36 % in the un-certainty values. ...|$|E
40|$|The authors {{propose a}} short run {{model for the}} {{monetary}} transmission mechanism in which the output gap is model as an unobserved variable. By estimating this model using maximum likelihood on a Kalman Filter, the authors find {{an estimate of the}} unobserved output gap as well as its <b>estimation</b> <b>uncertainty.</b> The performance of monetary rules is studied both with certainty on the output gap values as well as with <b>estimation</b> <b>uncertainty.</b> ...|$|R
40|$|Multiconfiguration Dirac-Hartree-Fock (MCDHF) {{calculations}} and relativistic configuration interaction (RCI) calculations are performed for {{states of the}} 3 s 23 p 2, 3 s 3 p 3 and 3 s 23 p 3 d configurations in the Si-like ions Ti IX – Ge XIX, Sr XXV, Zr XXVII and Mo XXIX. Valence and core-valence electron correlation e ects are accounted for through large configuration state function expansions. Calculated energy levels are compared with data from other {{calculations and}} with experimental data from the reference databases. Lifetime and transition rates along with <b>uncertainty</b> <b>estimations</b> are given for all ions. Energies from the calculations are in excellent agreement with observations and computed wavelength are almost of spectroscopic accuracy, aiding line identification in spectra...|$|R
40|$|According to the {{requirement}} of efficiency for rapid detection during the search and rescue in ruins, this paper proposes a subjective exploration strategy {{in the framework of}} simultaneous localization and mapping (SLAM). To balance the accuracy of SLAM algorithm and the efficiency of exploration, the problem of the subjective exploration of active SLAM is converted into an issue of multi-objective optimization. An objective function is presented to evaluate the <b>uncertainties</b> of <b>estimation,</b> the cost of movement and the gain of exploration. Furthermore, considering the <b>uncertainty</b> of <b>estimation</b> that is measured by the information entropy, an active constraint of loop closure is used for a backtracking correction of accumulated errors. Finally, the feasibility and validity of the proposed algorithm are verified by contrastive simulations and experiments...|$|R
