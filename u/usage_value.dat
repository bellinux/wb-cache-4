48|235|Public
5000|$|Step 2: Arrange {{the items}} in {{descending}} order of the <b>usage</b> <b>value</b> calculated above.|$|E
5000|$|Step 3: Make a {{cumulative}} total {{of the number}} of items and the <b>usage</b> <b>value.</b>|$|E
5000|$|Step 1: Compute {{the annual}} <b>usage</b> <b>value</b> for every {{item in the}} sample by {{multiplying}} the annual requirements by the cost per unit.|$|E
5000|$|Step 4: Convert the {{cumulative}} total {{of the number}} of items and <b>usage</b> <b>values</b> into a percentage of their grand totals.|$|R
30|$|To conduct authorship {{analysis}} and visualization of web content, data {{must first be}} collected and processed for use in research. Many recent studies utilizing web-based content commonly make use of automated crawlers for data collection [31],[32]. Automated crawlers allow for large amounts of text to be collected very rapidly when compared to manual approaches. After web pages containing text are collected, automated parsers and feature extraction programs can be developed to strip relevant text out of web pages and compute feature <b>usage</b> <b>values</b> [3]. Feature <b>usage</b> <b>values</b> are often times stored permanently in a database and/or transformed into vectors for further analysis utilizing statistical techniques.|$|R
40|$|Vendor-provided {{electronic}} {{resource usage}} statistics are not currently standardized across vendors. This {{study investigated the}} feasibility of using locally collected data to check the reliability of vendor-provided data. Vendor-provided data were compared with local data collected from the NCSU Libraries 2 ̆ 7 Web servers. The study finds that {{the two types of}} use patterns, but that actual <b>usage</b> <b>values</b> differ for many products...|$|R
5000|$|Step 5: Draw a graph {{connecting}} cumulative % {{items and}} cumulative % <b>usage</b> <b>value.</b> The graph is divided approximately into three segments, where the curve sharply changes its shape. This indicates the three segments A, B and C.|$|E
30|$|Generally, {{adaptive}} utilization threshold algorithms {{are more}} robust than static CPU utilization threshold algorithms {{in case of}} dynamic environments. However, these algorithms provide a poor prediction, {{and most of them}} depend on single resource <b>usage</b> <b>value,</b> which can lead to hasty decisions, unnecessary live migration overhead and stability issues [128].|$|E
40|$|This paper {{presents}} an empirical investigation on how information and guidance {{offered by the}} bank influence on the barriers to adoption of mobile banking. Data were collected from a questionnaire from college students who attend Islamic Azad university in city of Tehran, Iran. Structural equation modeling of data from 425 respondents {{was used to test}} 5 hypotheses. The results show the information and instructions offered by bank have negative effect on 5 evaluated barriers including <b>usage,</b> <b>value,</b> risk, tradition and image to adoption of mobile banking...|$|E
25|$|In October 1900, {{another issue}} was {{launched}} but that time for common <b>usage,</b> the <b>values</b> are in lepta and drachm.|$|R
40|$|This {{study is}} carried out in between 2006 - 2012 years. Materials of it {{collected}} {{from all over the}} country and identified by the classic systematic literatures. Voucher specimens are deposited in GUL Herbarium of Süleyman Demirel University in Isparta. In this paper, important new systematic, geographical and ecological characters, and also economical <b>usage</b> <b>values</b> of all Türkiye’s roses were determined by literature and field observations. In addition to this, some known characters in the genus were broadene...|$|R
40|$|SEcure Neighbor Discovery (SEND) {{utilizes}} X. 509 v 3 certificates {{for performing}} router authorization. This document specifies a certificate profile for SEND based on resource certificates along with extended key <b>usage</b> <b>values</b> required for SEND. Status of This Memo This is an Internet Standards Track document. This document {{is a product}} of the Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|R
40|$|This is an {{engineering}} study {{requested by the}} New World Foundation. A team from Engineers without Borders, a student agency at UCT, looked at designing and building a low cost fence for a playground at their pre-school in Lavender Hill. The objective was to provide affordable fencing that would overcome the challenges of theft that the community faces. The conditions for the material was {{that it should not}} have fuel <b>usage</b> <b>value</b> such as wood, no scrap material value and it should not block visibility...|$|E
40|$|Less {{productive}} agricultural soil, that is solonetz type, {{could be}} ameliorated {{in order to}} enhance <b>usage</b> <b>value</b> and broaden agricultural land. Grain weight per spike and spike weight of wheat grown on solonetz soil were examined in the article. Phenotypic variation of these traits as a response to environmental condition in six bread wheat varieties was followed through genotype by environment interaction in three vegetation periods. The results were compared on pure solonetz (control) and ameliorated solonetz (25 and 50 t/ha phosphor-gypsum) to determine effect of amelioration on these two yield components...|$|E
40|$|The {{detection}} of motifs within and among families of protein sequences can provide useful {{information regarding the}} function, structure and evolution of a protein. With {{the increasing number of}} computer programs available for motif detection, a comparative evaluation of the programs from a biological perspective is warranted. This study uses a set of 20 reverse transcriptase (RT) protein sequences to test and compare the ability of 7 different computational methods to locate the ordered-series-of-motifs that are well characterized in the RT sequences. The results provide insight to biologists as to the <b>usage,</b> <b>value,</b> and reliability of the numerous methods available. ...|$|E
40|$|This {{document}} specifies an Internet standards track {{protocol for}} the Internet community, and requests discussion {{and suggestions for}} improvements. Please refer to the current edition of the "Internet Official Protocol Standards " (STD 1) for the standardization state and status of this protocol. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2004). All Rights Reserved. This document defines two EAP extended key <b>usage</b> <b>values</b> and a public key certificate extension to carry Wireless LAN (WLAN) System Service identifiers (SSIDs). 1...|$|R
40|$|The {{focus of}} the work here was an {{empirical}} analysis of the aggregate independent demand behaviour for spare parts inventories, principally in the automotive industry. In particular, using the pioneering work of RG Brown (1959), who showed that inventory <b>usage</b> <b>values</b> are often log normally distributed, we set out and developed models that go some considerable way to explaining the underlying stochastic basis for this phenomena, why it occurs and some limiting conditions. The justification for this approach was {{on the grounds that}} by providing a more fundamental understanding of the underlying stochastic processes that explain the emergent aggregate demand behaviour, a sound starting point would be provided for developing more sophisticated analytical ways to view an inventory range, as a total entity, for planning and control purposes. The analysis was based on extensive data collected from the DAF Trucks (GB) Ltd. spare parts systems spanning the period 1975 to 1986, together with supporting studies from a number of other systems. The analysis showed that in the systems studied spare parts prices are lognormally distributed and this is most likely {{to be the result of}} a stochastic process known as the 'theory of breakage'. Analysis also showed that in the DAF Trucks case aggregated and volumes in very short time periods are distributed as a combined Log Series /Negative Binomial distribution (LSD/NBD). The combined LSD/NBD model of aggregate demand volumes is itself fully explained by a stochastic model known as the Afwedson model, which in turn is derived from more elementary conditions based on the Poisson process. We then demonstrated that if these short period aggregate demand distributions are cumulated period by period they converge to a log normal distribution as the stable long run model of aggregate demand volumes. As a result of the lognormality of prices and volumes the resultant inventory <b>usage</b> <b>values</b> are also log normal. Furthermore from insight into the underlying factors that explain the lognormality we have identified the factors and variables that govern the valueso f the parameterso f the particular log normal models of <b>usage</b> <b>values.</b> - The research protocol used in this work incorporated the law verifying process know as 'retroduction' after work and discussions of Uji Ijiri and Herbert Simon (1977); and to a lesser extent we utilised simulation for validation and verification of the derived models. From the proven log normality of demand volumes and <b>usage</b> <b>values</b> we have demonstrated that a number of related key inventory factors are also lognormal, in particular inventory- item turnover rates. Furthermore our conclusions show that some standard inventory performance measures, such as the inventory wide 'stock turnover rate' and the 'stock to sales' ratio, are poor measures to use in the case of highly skewed inventory variables. Finally we have suggested several potentially fruitful areas for developing improved methods of monitoring inventory performance in a variety of circumstances...|$|R
40|$|This paper {{examines}} the disposition problems of spare parts in inventory echelons. In particular a method is developed which can jointly optimise both the stock level and stock location problem. It {{is based on}} a so called optimum rate of stock turnover which is shown to minimise the real net margin earned by an inventory item at a given location. The paper also gives some consideration to the traditional methods for measuring aggregate stock performance when the inventory factors such as <b>usage</b> <b>values</b> are highly skewed and invariably follow a lognormal distribution in the spare parts case. inventory control spare parts...|$|R
40|$|Abstract: Functional {{annotation}} of new gene sequences is {{an important}} challenge for computational biology systems. While much {{progress has been made}} towards improving experimental methods for functional assignment to putative genes, most current genomic annotation methods rely on computational solutions for homology modeling via sequence or structural similarity. With the increasing number of computer methods available for protein remote homologies detection, a comparative evaluation of the methods from biological prospective is warranted. This study uses benchmark SCOP dataset to test and compare the ability of five different computational methods for protein homologies detection. The results provide insight to biologist as to <b>usage,</b> <b>value,</b> and reliability of the numerous methods available...|$|E
40|$|This {{paper is}} a {{preliminary}} {{exploration of the}} role of information as a barrier to innovation adoption. Earlier literature has suggested five barriers namely <b>Usage,</b> <b>Value,</b> Risk, Tradition and Image barriers to explain consumer resistance to innovations. We will seek to ascertain if the information constitutes the sixth barrier. The study was conducted in a mobile banking context representing an innovation with currently relatively low usage rates by consumers but with high future success expectations {{on the part of the}} service providers. An online questionnaire was developed and 1, 540 responses among mobile banking non-users were collected. The results of the Principal Component Analysis suggest that information constitutes a distinct sixth factor explaining consumer resistance to innovations...|$|E
40|$|The article {{relates the}} {{experience}} of two associations that have worked for years in Mesina, {{in the south of}} Italy, in relation to fundamental problems for the area they work in, and not only that one. How to think big and experience in small? What economy is necessary and natural in a structure founded on responsibility? How to remake the relationships between creativity and organisation? How to create educational itineraries that allow for the putting into play of the relationship between reality and representation? What is productive and what is unproductive? What relationship is there between voluntary work and work? How to restore <b>usage</b> <b>value</b> to research? The author responds to these questions by bringing out to the light the elements and the proposals that have arisen out of her educational experience and political passion. The article relates {{the experience of}} two associations that have worked for years in Mesina, in the south of Italy, in relation to fundamental problems for the area they work in, and not only that one. How to think big and experience in small? What economy is necessary and natural in a structure founded on responsibility? How to remake the relationships between creativity and organisation? How to create educational itineraries that allow for the putting into play of the relationship between reality and representation? What is productive and what is unproductive? What relationship is there between voluntary work and work? How to restore <b>usage</b> <b>value</b> to research? The author responds to these questions by bringing out to the light the elements and the proposals that have arisen out of her educational experience and political passion...|$|E
40|$|The study focuses {{attention}} on a grouping procedure {{for the purpose of}} joint inventory replenishments from a single supplier. The grouping procedure exploits the group discounts available on the total purchase value of a group of index and the economies of scale of order placing costs. In particular it is shown that the optimal groups are formed such that the annual (dollar) <b>usage</b> <b>values</b> of the items do not decrease (may increase or stay the same), from the first to the last group. This is similar in concept to the well-known ABC classification of inventory items. The grouping problem is modeled as a "shortest-path" using the above property. inventory models, joint replenishment, group discounts...|$|R
40|$|Reducing {{costs and}} {{increasing}} the efficiency of their use should be a primary goal {{in order to increase}} the performance of the firm’s activity. Any firm for obtaining <b>usage</b> <b>values</b> using an array of resources, human and financial materials whose use is materialized by spending. Structure, volume and their dynamics in a synthetic manner reflects the use and management of resources. The article highlights how the tracking of the evolution of total revenue expenses using the efficiency ratio total expenditure, and the results of this research will highlight: the evolution and structure of revenues and expenses, the factorial analysis of the efficiency ratio of total expenses and the analysis of the effect of the modification of the level of the efficiency ratio...|$|R
3000|$|Qualitative: The pricing way {{of income}} and {{expenses}} is pricing according to time, <b>usage</b> amount or <b>value</b> quantity; [...]...|$|R
40|$|The paper {{presents}} {{the implementation of}} an improved inventory management control system in a small company. The project took place at Trojan Mine, a company involved in mining mineral resources. Firstly, a conceptual framework {{for the design of}} an inventory control management system is developed. Secondly, a very effective user-friendly inventory control tool for determining the category A items was developed using EXCEL spreadsheet; a tool that is an asset to the company since it can be used in future. Finally, key performance indicators were also established to give benchmark to operations. The improved inventory control management system developed is found to offer improvement to the performance of the company since capital tied up in overstocking items of high annual <b>usage</b> <b>value</b> is released...|$|E
40|$|This chapter {{considers}} {{the representation of}} female musicianship in recent UKpress obituaries, {{with a focus on}} the theme of motherhood. The research data setconsidered was taken over a nine month period, between July 2011 and February 2012. Over this time the popular music industry and fans across the worldmourned the deaths of three of its best-selling female artists: Amy Winehouse(1983 – 2011), Whitney Houston (1963 – 2012) and Donna Summer (1948 – 2012). The UK press coverage of their deaths intriguingly indicates that motherhood wasused as a journalistic hook to compare them, regardless of whether the artists wereactually parents, {{as in the case of}} Houston and Summer, or not (Winehouse). Thischapter will unpack the meanings of motherhood (Eid, 2002), that most genderedof themes, and its <b>usage,</b> <b>value</b> and cultural politics...|$|E
40|$|The {{efficiency}} of libraries and information services has been legitimately put to test. However, most evaluations of libraries and information services have measured <b>usage</b> <b>value</b> only and exclude option value. Measuring both values might clear existing doubts {{on the value}} and {{efficiency of}} libraries and information services. The paper argues that many previous evaluations of libraries and information services used ineffective methods and approaches, evaluates some of these methods, and suggests a model that might overcome previous approaches ’ shortcomings. Libraries are faced with budget cuts, limited resources, and decisions that are crucial in determining either their survival or demise. Such decisions include {{but are not limited}} to whether to cancel subscriptions to certain journals, or to buy extra computers, or to extend library hours, etc. As libraries grapple with such problems and decisions, th...|$|E
25|$|Technically, digest {{authentication}} is {{an application}} of MD5 cryptographic hashing with <b>usage</b> of nonce <b>values</b> to prevent replay attacks. It uses the HTTP protocol.|$|R
40|$|Includes bibliographical {{references}} (pages 69 - 70) The UNIX* process scheduler uses a prioritized {{round robin}} scheduling algorithm. Priorities are adjusted periodically: priorities of processes {{waiting in the}} ready queue are incremented; priorities of processes that just used CPU resources are decreased according {{to the amount of}} resources used. This feedback ensures good response time for interactive processes and prevents starvation for processes with low initial priorities. This computer-assisted lesson graphically simulates the scheduling of processes by the standard UNIX process scheduler. A number of processes are initially in the system. A partial process table shows the process identification number, priority, and CPU usage factor for each process. The logical ready queues are also depicted. Each time the scheduler runs, the priority and CPU <b>usage</b> <b>values</b> in the process table and the graphic * UNIX is a registered trademark of AT&T...|$|R
50|$|In early 1960s, the Grayling Air-to-Ground Gunnery Range Negotiations {{began and}} early {{during the decade}} the range was {{constructed}} on 1,900 acres near Grayling, Michigan. Soon after, aircraft could be seen using the site to fly sorties for aircraft gunnery and bombing exercises. This added asset increased the <b>usage</b> and <b>value</b> of the base immensely.|$|R
40|$|Energy use in {{commercial}} buildings constitutes a major {{proportion of the}} energy consumption and anthropogenic emissions in the USA. Cogeneration systems offer an opportunity to meet a building¡¦s electrical and thermal demands from a single energy source. To {{answer the question of}} what is the most beneficial and cost effective energy source(s) {{that can be used to}} meet the energy demands of the building, optimizations techniques have been implemented in some studies to find the optimum energy system based on reducing cost and maximizing revenues. Due to the significant environmental impacts that can result from meeting the energy demands in buildings, building design should incorporate environmental criteria in the decision making criteria. The objective of this research is to develop a framework and model to optimize a building¡¦s operation by integrating congregation systems and utility systems in order to meet the electrical, heating, and cooling demand by considering the potential life cycle environmental impact that might result from meeting those demands as well as the economical implications. Two LCA Optimization models have been developed within a framework that uses hourly building energy data, life cycle assessment (LCA), and mixed-integer linear programming (MILP). The objective functions that are used in the formulation of the problems include:„XMinimizing life cycle primary energy consumption, „XMinimizing global warming potential, „XMinimizing tropospheric ozone precursor potential, „XMinimizing acidification potential,„XMinimizing NOx, SO 2 and CO 2, and„XMinimizing life cycle costs, considering a study period of ten years and the lifetime of equipment. The two LCA optimization models can be used for: (a) long term planning and operational analysis in buildings by analyzing the hourly energy use of a building during a day and (b) design and quick analysis of building operation based on periodic analysis of energy use of a building in a year. A Pareto-optimal frontier is also derived, which defines the minimum cost required to achieve any level of environmental emission or primary energy <b>usage</b> <b>value</b> or inversely the minimum environmental indicator and primary energy <b>usage</b> <b>value</b> that can be achieved and the cost required to achieve that value...|$|E
40|$|The {{constructive}} {{conception of}} a product results from uniting subsystems with basic usage values. These basic usage values make up {{the functions of the}} product. The notion of product function is the basic notion that product value analysis/value engineering(VA/VE) operates with, and function analysis together with creative thinking constitutes ???the oxygen of value engineering???. The present paper defines the notion of rank of a product function, establishes the formula for calculating its value and it reviews some ways of determining the levels of importance of product functions, with the aim of proposing a new distribution of the importance of these functions within the total <b>usage</b> <b>value.</b> Establishing the rank of a function can be reduced to the issue of comparing product functions by experts, consumers, team members for VA/VE. Subsequently, the ensuing results are subjected to adequate mathematical operations in order to determin the levels of importance and the quotients of each function within the product ussage value, as well as the distribution of these quotients. Due {{to the fact that the}} quota or quotient of a function within the product <b>usage</b> <b>value</b> plays an important role in conceiving and designing products, more precisely, in the economical shaping of functions, the distribution law to which this parametre is subjected is also very important. A critical study of the methods currently used to determine function quotients shows that these methods conduct to a linear distribution of these quotients, and, under these circumstances, the ratio between the highest level of importance and the lowest level of importance is equal to the number of functions ??? number that is very high indeed for complex products. On the other hand, it is rightly assumed that there is a considerable number of products for which the functions do not follow a linear distribution. The Zipf distribution or its generalised form, the Pareto-Zipf-Mandelbrot distribution, can be an alternative to the linear distribution. This distribution is valid in very many fields, of which most relevant for the present paper is the field of prices...|$|E
30|$|The new {{application}} environment capacity {{is generated by}} considering two factors: the secondary metric data-reflected capacity; the current combined CPU utilizations of all involved VMs towards the specified green limit. They produce two provisional capacity values: the first is extracted by dividing {{the sum of all}} VMs’ regulated monitor usage values by the optimal <b>usage</b> <b>value</b> (the average value of the green up and down limits); the second is produced by dividing the latest secondary metric monitor value by the CapacityRatio. Using (5), the final identical capacity values (number of VMs needed) is determined, which is the average value of the two provisional values. Additionally, OCSO PaaS optimization utilizes similar dynamic green limit and threshold evolution as for its IaaS optimization using (2.1), (2.3), (3.1), (3.3), except that there is a gap of 30 (at least) between the new up and down limit, which is to prevent fault scaling.|$|E
40|$|The WRON Alliance is a {{group of}} key government, {{academic}} and industry partners who have formed a coalition to improve the <b>usage</b> and <b>value</b> of water resources information {{for the benefit of the}} nation. Members of the WRON Alliance involved with the development of Australian Water Resources 2005, which is an initiative of the National Water Commission...|$|R
40|$|Regression {{dependencies}} {{are derived}} for determination of equipment usage rate in machining areas and {{lines on the}} results of the simulation modeling. The peculiar features of the dependencies are versatility and broad incidence of factors. Determination accuracy of an average equipment <b>usage</b> rate <b>value</b> is equal to 0. 035 with confidential probability of 0. 95. </p...|$|R
50|$|However, {{as noted}} in the first segment of this article, in common <b>usage</b> the term <b>value</b> {{judgment}} has a much simpler meaning with context simply implied, not specified.|$|R
