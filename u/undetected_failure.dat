13|58|Public
50|$|If the <b>undetected</b> <b>failure</b> {{allows the}} system to remain in a safe / working state, a second failure {{situation}} should be explored {{to determine whether or}} not an indication will be evident to all operators and what corrective action they may or should take.|$|E
3000|$|... (t) {{represents}} {{the probability that}} PE exceeds AL without detection. This dangerous <b>undetected</b> <b>failure</b> is the most feared failure of the system.|$|E
3000|$|... (t), {{accuracy}} can be lost (PE > AL) while integrity (timely warning) is provided. Alternatively, in {{the case}} of safe <b>undetected</b> <b>failure</b> PF [...]...|$|E
3000|$|... (t). C(t) is {{not only}} equal to R(t) as {{position}} is also provided when a failure is not revealed by GNSS diagnostics. It is obvious that <b>undetected</b> <b>failures</b> (DU, SU) can be revealed by additional diagnostics based on physically diverse sensors.|$|R
3000|$|The {{integrity}} of service is guaranteed when the GNSS receiver provides correct information. The probability IR(t) {{is the measure}} of integrity risk. It refers to the probability of the incorrect position due to the failures mentioned in the cause analysis of section  3. Therefore, the probability of dangerous <b>undetected</b> <b>failures</b> describes the integrity risk, i.e. IR(t) = PF [...]...|$|R
30|$|Note that {{dangerous}} detected failures (true alert) are not {{as dangerous}} as dangerous <b>undetected</b> <b>failures.</b> They {{can be converted to}} fail-safe state. For example, a train can be stopped. However, it shall be done only in an extreme case, if no other possibility exists. Relatively frequent interruptions of Galileo Signal-In-Space SoL Level A Service (MTBF[*]=[*] 521  h) can be substituted by a relative position determination, by means of sensors [8].|$|R
40|$|An optimum {{checking}} {{schedule is}} one that minimizes the expected cost, which {{is the sum of}} the cost of checking and the expected loss due to an <b>undetected</b> <b>failure.</b> The problem is made tractable by supposing that checking is so frequent that it can be described by a continuous density n(t) of checks per unit time. The optimum n(t) is found by the methods of the calculus of variations. An explicit result is given when the loss is proportional to the duration of an <b>undetected</b> <b>failure.</b> A minimax solution is also given for the case in which the probability of failure is not known. ...|$|E
40|$|In the {{introduction}} of this article the purpose and operation principle of railway interlocking systems is briefly explained. Further there are presented results of an analysis, which aim was to prove validity of a formula recommended by EN 50129 standard for a hazard rate calculation of the interlocking systems with a redundant structure 2 oo 2. Hazard rate was calculated by two independent ways, namely for different failure rates of single channels and for a different safe-down time. In the first case the formula presented in EN 50129 was used, {{in the latter case}} a calculation was carried out by RBD method. Results of both methods were matched. In most cases both results coincide. Greater diversions arise only in such cases, when a safe-down time of a single fault is comparable in order of magnitude with a mean time to failure of a single channel of the redundant structure. This can occur for instance during long term system storage, or if an <b>undetected</b> <b>failure</b> occurs during a system operation. Possibility of an <b>undetected</b> <b>failure</b> is not quantitatively captured in EN 50129 standard (each single random failure is considered to be detected {{at the end of the}} test), therefore the last aim of the work was to analyse in detail a mechanism of origin, detection and negation of double random faults. The results of this analysis can be used for a quantitative evaluation of the impact of undetected random failures on a hazard rate of a redundant structure 2 out of 2. The main risk for the technical safety of redundant systems, besides common cause failures, are undetected failures. One point of this paper is a recommendation that the data comparison and the fault negation should be carried out in such a way that would minimize or completely eliminate the possibility of undetected malfunction of these key safety functions...|$|E
40|$|Results of {{an ongoing}} {{research}} program into the reliability of terrestrial solar cells are presented. Laboratory accelerated testing procedures are used to identify failure/degradation modes which are then related to basic physical, chemical, and metallurgical phenomena. In the most recent tests, ten different types of production cells, both with and without encapsulation, from eight different manufacturers were subjected {{to a variety of}} accelerated tests. Results indicated the presence of a number of hitherto <b>undetected</b> <b>failure</b> mechanisms, including Schottky barrier formation at back contacts and loss of adhesion of grid metallization. The mechanism of Schottky barrier formation is explained by hydrogen, formed by the dissociation of water molecules at the contact surface, diffusing to the metal semiconductor interface. This same mechanism accounts for the surprising increase in sensitivity to accelerated stress conditions that was observed in some cells when encapsulated...|$|E
40|$|Abstract: This paper {{describes}} a procedure {{to reduce the}} probability of failure on demand (PFD) for systems and to extend the proof test interval by using partial stroke test (PST). The goal of partial stroke tests is to discover {{a part of the}} dangerous <b>undetected</b> <b>failures</b> at an earlier time. The difference between a partial stroke test and a proof test (PT) is that a component is only partially tested by a PST. However, after carrying out a PST, the system has a residual of dangerous <b>undetected</b> <b>failures.</b> This residual can be eliminated by a proof test. The probability of failure can be improved with the diagnostic coverage factor for partial stroke tests. It is important to know the difference between probability of failure PFD and the average probability of failure PFDavg. The values of both PFDs with partial stroke test are lower than the probability of failure without partial stroke test. The factor B shows the improvement between a system with and without partial stroke tests {{at the time of the}} proof test. The larger the factor B is the larger is the system’s improvement...|$|R
40|$|Herein, {{we propose}} a commit {{protocol}} and an associated recovery protocol that is resilient to site failures, lost messages, and network partitioning. The protocols {{do not require}} that a failure be correctly identified or even detected. The only potential effect of <b>undetected</b> <b>failures</b> is a degradation in performance. The protocols use a weighted voting scheme that supports an arbitrary degree of data replication (including none) and allows unilaterally aborts by any site. This last property facilitates the integration of these protocols with concurrency control protocols. Both protocols are centralized protocols with low message overhead...|$|R
5000|$|Failed but <b>undetected,</b> dormant <b>failure</b> (q = 0). (e.g. standby {{equipment}} unavailable {{in the event}} of failure of duty equipment. Thus a problem may not be apparent until a failure of the duty equipment occurs.) ...|$|R
40|$|The study {{concerns}} {{the reliability of}} active display cases to be used at the Dutch Maritime Museum located in Amsterdam. The paper presents HAM models of display cases and the indoor climate of the zone surrounding them. Furthermore, data from measurements arc provided for validation purposes. It is concluded that in case of failure of the climate system, responsible for the indoor climate surrounding the active display case, the climate inside the active display case will stay within the required limits {{for more than five}} hours during the winter and for more than half an hour during the summer. However, some <b>undetected</b> <b>failure</b> scenarios could be responsible for exceeding the required limits of the indoor climate inside the display case within five minutes. The latter shows the importance of the presence of reliable failure detection and handling system...|$|E
40|$|In {{these days}} of high technology, the steam trap is often treated as a {{commodity}} item, forgotten by many and respected by a relative few. Yet, in many facilities, widespread <b>undetected</b> <b>failure</b> of steam traps has wasted 5 - 15 % of a plant's total steam generation. Stopping this waste represents a major energy conservation treasure characterized by low investment and a fast payback. The proper application of steam trap technology requires the experience and judgment of a dedicated champion at each location. This paper will present an overview of a working steam trap program starting with the initial survey and loss estimates. Trap characteristics and performance by generic type will be discussed with practical examples utilized to illustrate the myths in steam trap sizing {{and the consequences of}} over-sizing. Standardization of trap inventory, training and follow-up are the other key program elements addressed...|$|E
40|$|The {{experience}} gained in digital fly-by-wire technology through a flight test program {{being conducted by}} the NASA Dryden Flight Research Center in an F- 8 C aircraft is described. The system requirements are outlined, along with the requirements for flight qualification. The system is described, including the hardware components, the aircraft installation, and the system operation. The flight qualification experience is emphasized. The qualification process included the theoretical validation of the basic design, laboratory testing of the hardware and software elements, systems level testing, and flight testing. The most productive testing was performed on an iron bird aircraft, which used the actual electronic and hydraulic hardware and a simulation of the F- 8 characteristics to provide the flight environment. The iron bird was used for sensor and system redundancy management testing, failure modes and effects testing, and stress testing in many cases with the pilot in the loop. The flight test program confirmed {{the quality of the}} validation process by achieving 50 flights without a known <b>undetected</b> <b>failure</b> and with no false alarms...|$|E
40|$|Operations in {{hazardous}} and/or remote environments {{are often}} performed by robots. The hostile {{nature of these}} environments, however, significantly {{increases the likelihood of}} failures in the robots 2 ̆ 7 subsystems. The difficulty and delay in the detection and subsequent correction of these faults makes the post-fault performance of the robots particularly important. An approach to dealing with failures is to build failure-tolerant manipulators, where the damaged system can be operated with minimal performance degradation. Though there has been considerable work in the area of failure tolerance, existing methods rely on effective failure detection. However, the issue of coping with failures prior to detection, or if they remain undetected, remains unaddressed. This work focuses on the analysis and design of inverse kinematic control schemes for manipulators experiencing <b>undetected</b> locked joint <b>failures.</b> ^ The first part of this work focuses on the post-fault analysis of a manipulator, emphasizing the effects of <b>undetected</b> locked-joint <b>failures</b> on the global/convergence behavior of the manipulator. Tools for identifying failure-tolerant regions of a manipulator 2 ̆ 7 s workspace are developed so that task completion can be guaranteed with common control schemes even if <b>failures</b> remain <b>undetected.</b> The second part of this work concentrates on the design of inverse kinematic control schemes to minimize the performance degradation due to the local effects of <b>undetected</b> locked-joint <b>failures.</b> Specifically, three different failure-tolerance schemes are proposed. Using a set of proposed performance measures, these schemes are experimentally evaluated ^ and compared with a commonly used control scheme for tasks performed under both computer and human-control (i. e., teleoperation). Results {{of this study indicate that}} the post-failure performance of a manipulator, even with <b>undetected</b> <b>failures,</b> can be significantly improved through the use of appropriate failure-tolerant control schemes such as those proposed here. ...|$|R
40|$|A {{maintenance}} {{model for}} a system subject to both unrevealed catastrophic failures or revealed minor failures is presented. The former are detected {{by means of an}} inspection policy at periodic times kT, k= 1, 2,…. Moreover it is assumed a less than perfect testing, that is, false alarms as well as <b>undetected</b> <b>failures</b> after an inspection. Revealed failures are removed by a minimal repair whereas a perfect repair follows the unrevealed failures. A renewal of the system after the thN revealed failure completes the maintenance actions. The times of inspections and repairs are also taken into account. The expected cost-minimizing policy along an infinite time span is also analyzed...|$|R
50|$|Today, machines, {{plants and}} safety systems {{are stuck in}} a rigid scheme made up of {{hardware-based}} safety functions. The consequences of this are cost-intensive cabling and limited diagnostic options. The solution is the integration of safety relevant application data into the standard serial control protocol. OpenSAFETY allows both publish/subscriber and client/server communication. Safety relevant data is transmitted via an embedded data frame inside of standard communication messages. Measures to avoid any <b>undetected</b> <b>failures</b> due to systematic or stochastic errors {{are an integral part}} of a functional safety protocol. OpenSAFETY is in conformance with IEC 61508. The protocol fulfills the requirements of SIL 3. Error detection techniques have no impact on existing transport layers.|$|R
40|$|The {{ability to}} detect and isolate {{component}} faults in a railway suspension system is important for improved train safety and maintenance. An <b>undetected</b> <b>failure</b> in the suspension systems can cause severe wheel-rail wear, reduce ride comfort, worsen passenger safety and increase unexpected maintenance costs. Existing fault detection methods are limited in several respects, such as effectiveness/sensitivity for fault detection, or robustness to external condition changes. This thesis investigates a model-less fault detection and isolation approach using cross correlation and/or relative variance techniques, developed to overcome these limitations. This thesis treats a conventional bogie vehicle with a symmetrical structure. Excited by the track irregularities, {{the dynamics of the}} vehicle are studied under the normal conditions, with an emphasis on the vertical and related motions of the bogies and the carbody. Two fault detection schemes employing data processing using data directly from measurement are discussed. One uses cross correlation evaluation of the basic bogie motions to detect component fault; the other takes advantage {{of the relationship between the}} relative variances of the suspension accelerations. Finally, the fault isolation schemes are assessed based on the comparison of fault detection performances in different conditions. The proposed approach does not require detailed knowledge of the vehiclelbogie and external track irregularities. The effectiveness of the approach is verified by computer simulations in Matlab/Simulink. ...|$|E
40|$|Background: Depression is {{a common}} health {{condition}} affecting up {{to a third of}} patients attending primary care, where most of the care for people with depression is provided. Adequate recognition of depression is the critical step in the path to effective care, particularly in low income countries. As part of the Programme for Improving Mental healthcare (PRIME), a project supporting the implementation of integrated mental healthcare in primary care, we evaluated the level of recognition of depression by clinicians working in primary care in rural Ethiopia prior to in service training. We hypothesised that the detection rate of depression will be under 10 % and that detection would be affected by gender, education and severity of depression. Methods: Cross-sectional survey in eight health centres serving a population of over 160, 000 people. A validated version of the 9 -item patient health questionnaire (PHQ- 9) was administered as an indicator of probable depression. In addition, primary care clinicians completed a clinician encounter form. Participants were consecutive primary care attendees aged 18 years and above. Results: A total of 1014 participants were assessed. Primary care clinicians diagnosed 13 attendees (1. 3 %) with depression. The PHQ 9 prevalence of depression at a cut-off score of ten was 11. 5 % (n = 117), of whom 5 % (n = 6 / 117) had received a diagnosis of depression by primary care clinicians. Attendees with higher PHQ scores and suicidality {{were significantly more likely to}} receive a diagnosis of depression by clinicians. Women (n = 9 / 13) and participants with higher educational attainment were more likely to be diagnosed with depression, albeit non-significantly. All cases diagnosed with depression by the clinicians had presented with psychological symptoms. Conclusion: Although not based on a gold standard diagnosis, over 98 % of cases with PHQ- 9 depression were <b>undetected.</b> <b>Failure</b> of recognition of depression may pose a serious threat to the scale up of mental healthcare in low income countries. Addressing this threat should be an urgent priority, and requires a better understanding of the nature of depression and its presentation in rural low-income primary care setting...|$|E
40|$|Testing {{of safety}} {{instrumented}} systems {{is vital to}} ensure {{they are able to}} perform the required safety function when the need arises. These tests are carried out at specified time intervals. The verification of the ability of the safety systems to perform as required is carried out by reliability assessment. This is the calculation of how likely it is that the safety instrumented system will function when needed. In carrying out reliability assessment, proof testing of safety systems is assumed to be perfect which is not always the case in reality. This thesis is important because it looks at how to evaluate this assumption to achieve a realistic estimate since testing is a key factor in reliability calculation. This study identifies the main causes of imperfectness which are classified with the five M-factors namely: Method, Machine, Manpower, Milieu and Material. Based on these, the situations where perfect test may not be realistic with examples are reviewed and documented. I have studied and compared different ways that the effects of tests can be treated. Three approaches to consider imperfectness of test were identified: the IEC 61508 approach where we consider the proportion (fraction) of dangerous undetected failures that are revealed by the proof test, the probability of detecting a dangerous <b>undetected</b> <b>failure</b> during a given proof test and the PDS method of adding a constant probability of test independent failures. The analysis carried out compared the first and second approach. Based on the analysis, the second approach was proposed to be the most suitable of the first two approaches. Furthermore, we present different reliability assessment methods for estimating the probability of failure on demand of a safety system. The methods used are: analytical formulas, multi-phase Markov, fault tree approach and Petri net. The principles of application and limitation with each of these approaches are presented in this thesis. In the course of this work, we discovered that some complicated cases and systems can only be analyzed by simulation. Finally, a chemical reactor protection system is used as a case study to demonstrate the principles and methods discussed in this thesis...|$|E
40|$|As {{manufacturing}} processes have grown increasingly complex, demand for robust methods that automatically detect failures in these systems has skyrocketed. <b>Undetected</b> <b>failures</b> in a high-volume manufacturing process {{can result in}} tremendous cost if the failure is not detected in a timely manner. In this work, we {{address the problem of}} automatic excursion detection based on parametric tests. Contrary to the complexity of many fabrication processes, we propose two structurally simple excursion detection models: Nave Bayes classifier and boosted decision stumps. We test the variations of these models, on the domain of semiconductor manufacturing, against o#-the-shelf classification techniques and show a significant improvement in the precision and recall of detected excursions. Preliminary results encourage our future work that should primarily focus on increasing the recall of the models...|$|R
40|$|Abstract. This work {{describes}} a maintenance {{model for a}} system that presents failures of two types, revealed minor failures (type R) and unrevealed catastrophic failures (type U). The latter are detected {{by means of an}} inspection policy at periodic times kT, k = 1, 2, [...] . Moreover it is assumed the possibility of imperfect inspections, that is, false alarms of failure as well as <b>undetected</b> <b>failures</b> after an inspection. Type R failures are removed by a minimal repair whereas a perfect repair follows the type U failures. The maintenance procedure is completed with a renewal of the system after the Nth type R failure. The objective function is the expected cost in an infinite time span and interest centers on the existence of a finite optimum policy...|$|R
40|$|Electro-Mechanic {{actuators}} {{are usually}} driven by Brushless-DC motors. Those ones {{can be affected}} by damages caused by fatigue and usage. At incipient stage, failures like partial short-circuit and rotor static eccentricity do not influences overall actuator performance, causing however oscillations in speed and command signals. Focusing on these oscillations, which presents periodic behaviour over the rotor revolution, neural networks are designed and trained to detect and quantify the damage entity. A different approach to this problem is performed, ignoring electrical measures of phase currents and potential drops, which are usually noisy and hardly available as actuator output. Classification results shows good performance in every speed-torque combination, reducing <b>undetected</b> <b>failures</b> and being capable {{to distinguish between the}} two kids of failures implemente...|$|R
40|$|International audienceReceiver Autonomous Integrity Monitoring (RAIM) {{has been}} {{certified}} to provide lateral guidance in flight operations ranging from En-route to Non-Precision Approach (NPA) [1]. Recent {{developments in the}} RAIM algorithm science, namely Advanced RAIM (ARAIM), have suggested a future role in vertically guided operations down to LPV with a decision height of 200 ft [2, 3]. However, to meet the more stringent requirements of such operations, in particular the necessary integrity, a supporting ground network is envisioned whose role will be to verify the standards provided by the GNSS service providers. The exact allocation of responsibility and risk between this ground segment, the accompanying airborne segment and the existing space segment remains to be fully defined [3, 4]. The ground monitoring may ultimately perform real-time signal monitoring akin to the SBAS concept {{or none at all}} {{as is the case in}} traditional RAIM. More likely, an offline or near real-time bounding methodology will be employed. This paper analyses in further detail how this bounding methodology may be applied. What is certain is that the airborne component will require inputs of the probabilities of failure for both individual satellites known as narrow faults, and constellations known as wide faults. In addition, inputs are needed for the bounds on maximum biases and the nominal and worst case error variances applied at the airborne receiver [5]. How these inputs will be provided to the airborne receiver algorithms will directly depend on the bounding methodology outlined above, whether fixed in the standards in the case of offline or no monitoring; or conversely, provided by a real time communications channel via a satellite or ground link. This paper addresses the question of how ARAIM performance will vary as a function of the ground network characteristics. This analysis determines how the ground network architecture - which depends on the risk allocated to the ground segment - impacts the probability of failure assumed by the airborne component. The paper quantifies the probability of satellite failure for two potential architectures [3]: firstly, based on offline monitoring employed purely in the long term to validate that the space segment assumptions are not unsound; secondly, a bounding methodology which shares the allocation of integrity risk between the ground and airborne segments and with a medium latency message update rate. In the offline monitoring case, the real-time monitoring responsibility is fully allocated to the airborne component, the total navigation system integrity risk being shared with the space segment. As such, the real probability of failure at a particular epoch is a function of the failure onset probability and temporal correlation of the nominal errors. The paper presents a derivation of the onset probability by considering the relationship of the true probability of failure onset, the empirically estimated probability of failure onset (as done historically for GPS RAIM) and the proposed ARAIM probability of failure onset [6]. In the case of near real-time monitoring, the intention of the ARAIM ground infrastructure is not to replicate the relatively dense monitoring of the current single frequency SBAS. A number of reference network baselines have been defined which vary in their density and coverage, be it regional or global [4]. This paper considers that each satellite has single reference station coverage with various elevation masks, such a network falls under the sparse global setting. Assuming this network enables an equally simple but informative ground monitoring algorithm to be chosen. Moreover, its monitoring accuracy may be determined analytically which enables the failure detection power to be computed. Naturally, many variations in the design of ground monitoring algorithms are possible and the approach taken is not intended to be optimal in any sense. Rather, it is chosen for its simplicity but also reflects the real observability of ranging errors whilst remaining conservative in the capabilities of the ground segment. The monitoring accuracy obtained as an output is a function of the residual error sources at the reference station, which in turn depend upon the minimum satellite elevation (or assumed station mask). Using the single station model, we derive the monitoring power as a function of the coverage (i. e. minimum satellite elevation of each satellite) under this simple ground segment model. In addition, simulations of the ARAIM airborne component have been performed as part of a CNES ARAIM project. These simulations have been used to generate statistics on the Minimum Hazardous Bias (biases in the multiple failure case), or equivalently, the magnitude of failure which has the potential to cause an integrity failure for the user [7, 8]. Using this input in combination with the monitoring accuracy from the ground segment, the risk of <b>undetected</b> <b>failure</b> at the time of ISM is computed. This is achieved for two cases of ISM dissemination: the first approach includes the monitoring accuracy metric described above in addition to satellite integrity flags; and the second approach is limited to the flag. In the latter limited data bandwidth scenario, the user computes a worst case monitoring accuracy based on the assumptions outlined in the paper. The final result of this analysis is to derive the threat of a single failure which occurred prior to the last ISM message arriving at the user. The risk of failure onset after the ISM message as a function of the latency is then added to give the total probability of single failure used as input to the airborne component. This system analysis cumulates in a presentation of the feasibilities and performances of the ARAIM system including the sensitivities in terms of the onset probability assumptions, the ground network dimensioning and the ISM message content and latency...|$|E
40|$|Detecting and {{diagnosing}} {{failures of}} Unmanned Aerial Vehicles during their mission {{is a key}} challenge for their effective deployment. On-board diagnostic systems are able to provide {{a huge amount of}} information {{about the state of the}} vehicle during the flight, by monitoring sensors, software, and hardware components. However, the ability of processing such data in an online manner is a serious obstacle to a timely detection and diagnosis of failures. This paper proposes a method to progressively focus the data collection on signals providing the most reliable information about the system failure probability, so as to reduce considerably the number of false alarms and/or <b>undetected</b> <b>failures,</b> and to ease the online data processing. We set a simulation experiment showing that the proposed approach is able to select the most informative subset of signals in few iterations in an effective and efficient way...|$|R
40|$|A design {{method is}} {{presented}} which integrates control action and fault detection and isolation. Control systems operating under potentially faulty conditions are considered, {{and it is}} demon-strated how to design a single unit which handle both the required control action, as well as identifying faults occuring in actuators and sensors. This unit is able to: (1) follow references and reject disturbances robustly, (2) control the system such that <b>undetected</b> <b>failures</b> do not have disastrous eects, (3) {{reduce the number of}} false alarms, and (4) identify which faults have occured. The method uses a type of separation principle which makes the design process very transparent, and a polynomial H 1 formulation which makes weight selection straightforward. As a consequence of the separation between control and diagnosis, we shall prove that the controller needs not be detuned in order to get good diagnosis results, in contrast to common beliefs. ...|$|R
40|$|Robots are {{frequently}} used for operations in hostile environments. The {{very nature of}} these environments, however, {{increases the likelihood of}} robot failures. Common failure tolerance techniques rely on effective failure detection. Since a failure may not always be successfully detected, or even if detected, may not be detected soon enough, it becomes important to consider the behavior of manipulators with <b>undetected</b> <b>failures.</b> This work focuses on developing techniques to analyze a manipulator's workspace and identify regions in which tasks, characterized by sequences of point-to-point moves, can be completed even with such failures. Measures of fault tolerance are formulated to allow for the evaluation of the workspace. I. Introduction Failures in robots occur frequently in industrial operations [1]. The likelihood of failures is far greater when robots are operated in harsh environments [2]. Since the control of the individual joints is essentially independent in a typical robotic s [...] ...|$|R
40|$|Probability {{theory is}} {{used to assess the}} {{deficiencies}} of safety schemes which rely on devices which can fail either in an undetected manner only, or in both undetected and detected ways. Three quantities are used to express the deficiencies of these schemes; the mean period during which devices are ineffective, the proportion of time for which they are ineffective and the distribution of the durations of their ineffective periods. Analytical expressions are derived for these quantities for a scheme in which only <b>undetected</b> <b>failures</b> occur and devices are replaced at regular intervals. Monte Carlo simulation techniques are used to estimate the measures of deficiency for situations in which both types of failure are possible. Consideration is given to the "cost-benefit " aspects of safety schemes in simple circumstances in which the rate of occurrence of the hazards involved, and the penalty to be paid {{in the event of a}} catastrophe, are known. 1...|$|R
40|$|A high-angle-of-attack flush airdata {{sensing system}} was {{installed}} and flight tested on the F- 18 High Alpha Research Vehicle at NASA-Dryden. This system uses {{a matrix of}} pressure orifices arranged in concentric circles on {{the nose of the}} vehicle to determine angles of attack, angles of sideslip, dynamic pressure, and static pressure as well as other airdata parameters. Results presented use an arrangement of 11 symmetrically distributed ports on the aircraft nose. Experience with this sensing system data indicates that the primary concern for real-time implementation is the detection and management of overall system and individual pressure sensor failures. The multiple port sensing system is more tolerant to small disturbances in the measured pressure data than conventional probe-based intrusive airdata systems. However, under adverse circumstances, large <b>undetected</b> <b>failures</b> in individual pressure ports can result in algorithm divergence and catastrophic failure of the entire system. How system and individual port failures may be detected using chi sq. analysis is shown. Once identified, the effects of failures are eliminated using weighted least squares...|$|R
40|$|Test {{sets for}} path delay faults in {{circuits}} {{with large numbers}} of paths are typically generated for path delay faults associated with the longest circuit paths. We show that such test sets may not detect faults associated with the next-to-longest paths. This may lead to <b>undetected</b> <b>failures</b> since shorter paths may fail without any of the longest paths failing. In addition, paths that appear to be shorter may actually be longer than the longest paths if the procedure used for estimating path length is inaccurate. We propose a test enrichment procedure that increases significantly the number of faults associated with the next-to-longest paths that are detected by a (compact) test set. This is achieved by allowing the underlying test generation procedure the flexibility of detecting or not detecting the faults associated with the next-to-longest paths. Faults associated with next-to-longest paths are detected without increasing the number of tests beyond that required to detect the faults associated with the longest paths. The proposed procedure thus improves the quality of the test set without increasing its size...|$|R
5|$|Speakers at {{the inquiry}} have also testified that a {{significant}} volume of city traffic regularly cut across the roof deck as a bypass of the traffic lights {{at the corner of}} Hillside Drive and Ontario Avenue, resulting in more stress on the structure than it had been designed to handle. The NORR report speculated that a heavy vehicle might have contributed to a previously <b>undetected</b> partial <b>failure</b> of the support structure a few months prior to the final collapse.|$|R
40|$|Abstract: An {{increasing}} {{range of}} industries have a growing dependence on embedded software systems, {{many of which}} are safety-critical, real-time applications that require extremely high dependability. Two fundamental approaches − fault avoidance and fault tolerance − have been proposed to increase the overall dependability of such systems. However, the increased cost of using the fault tolerance approach may mean that this increase in dependability is not worth the extra expense involved. We describe an experiment undertaken in order to establish whether or not software redundancy (or the multi-version design method) can offer increased dependability over the traditional single-version development approach when given the same level of resources. The results of this and a subsequent follow-up study are then given. The analytic results from these experiments show that despite the poor quality of individual versions, the multi-version method results in a safer system than the single-version solution. It is evident that regarding the single-version method as a “seem-to-be ” safer design decision for critical applications is not generally justifiable. Key words: Detected and <b>undetected</b> <b>failures,</b> embedded fault-tolerant systems, multiversion programming, safety-critical applications, software development cost 1...|$|R
40|$|Big data means big datacenters, {{comprised}} of {{hundreds or thousands}} of machines. With so many machines, failures are commonplace. Failure detection is crucial: <b>undetected</b> <b>failures</b> may lead to data loss and outages. Recent health monitoring approaches use anomaly detec-tion to forecast failures – anomalous machines are considered to be at risk of future failures. Our previous work focused on detecting latent faults in large web services, which are often characterized by scale-out architecture where load is dynam-ically balanced. We proposed a robust and unsupervised latent fault detector for such systems, with statistical bounds on the rate of false positives. That detector, however, is unsuitable for applications without dynamic load balancing, such as statically-balanced key-value stores, Hadoop jobs, and supercomputer applications. We describe an improved latent fault detection method for unbalanced workloads. It retains the advantages of our previous methods: it is unsupervised, robust to changes, and statistically sound. Moreover, the statistical bounds for the new method scale better with the number of machines, and so dramatically reduce the number of measurements needed. Preliminary evaluation on supercomputer logs shows that the new method is able to correctly predict some failures, while our previous methods completely fail in this setting...|$|R
50|$|The {{incident}} {{shows the}} risks that banks connected to the SWIFT system are exposed to {{as a result of}} the security vulnerabilities of other member banks. By breaching the Bangladesh Central Bank's security firewalls, hackers were able to hack the system and transfer the funds through the established global banking networks almost <b>undetected.</b> The <b>failure</b> of the Bangladeshi government to build adequate safeguards for its financial system became the starting point for a global, multi-million money laundering scheme whose effect was felt beyond the country's borders.|$|R
40|$|It is {{important}} to have multi-agent robotic system specifications that ensure correctness properties of safety and liveness. As these systems have concurrency, and often have dynamic environment, the formal specification and verification of these systems along with step-wise refinement from abstract to concrete concepts {{play a major role in}} system correctness. Formal verification is used for exhaustive investigation of the system space thus ensuring that <b>undetected</b> <b>failures</b> in the behavior are excluded. We construct the system incrementally from subcomponents, based on software architecture. The challenge is to develop a safe multi-agent robotic system, more specifically to ensure the correctness properties of safety and liveness. Formal specifications based on model-checking are flexible, have a concrete syntax, and play vital role in correctness of a multi-agent robotic system. To formally verify safety and liveness of such systems {{is important}} because they have high concurrency and in most of the cases have dynamic environment. We have considered a case-study of a multi-agent robotic system for the transport of stock between storehouses to exemplify our formal approach. Our proposed development approach allows for formal verification during specification definition. The development process has been classified in to four major phases of requirement specifications, verification specifications, architecture specifications and implementation. Comment: arXiv admin note: text overlap with arXiv: 1501. 0512...|$|R
