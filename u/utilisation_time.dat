13|125|Public
40|$|Abstract: Introduction: The aim of {{this study}} is to assess the effect of body mass index (BMI) and body weight on theatre <b>utilisation</b> <b>time</b> during primary total hip (THR) and knee {{replacements}} (TKR). Methods: A total of 1859 cases were included (820 THR and 1039 TKR). Patients were divided into groups based on BMI and body weight. The time interval from ‘starting anaesthesia ’ to ‘transfer back to recovery ’ was used as total theatre time. Hierarchal regression analysis was then used to study the effect of BMI and body weight while controlling the effec...|$|E
40|$|The life of {{bucket teeth}} in shovel and {{dragline}} deployed in handling of overburden rock {{is an important}} contributor to the stores cost and is also responsible {{for the loss of}} valuable availability and <b>utilisation</b> <b>time</b> of these critical equipment. To ascertain the effect of rock type on longevity of bucket teeth a study has been conducted in two large opencast mines of Singrauli Coalfields. The results of this study is presented in this paper. There was a significant variation as compared to the actual figures of the mine it establish useful relationship between the type of mineral present in the overburden and the life of bucket teeth of shovel and dragline...|$|E
40|$|The study {{concerns}} the application techniques of agrochemical products and especially {{focuses on the}} wear of spraying nozzles. This one leads to a modification of the spraying characteristics and the homogeneity of distribution deteriorates. An accelerated wear process of nozzles {{is defined by the}} standard ISO 5682 - 1, which makes it possible to compare the wear resistance of the different nozzles available on the market. In order to accelerate the process, an erosive suspension is used in the test rig, but this suspension looses its characteristics during the <b>utilisation</b> <b>time.</b> This is the reason why a system measuring continuously the erosive power has been set up. This system is validated by different discontinuous measurement and the correlation observed have a coefficient of about 0, 99. From the signal detected by the new device, two calculations have been carried out. A first one determining continuously the total wear quantity of the nozzles. A second one identifying continuously the erosive power of the suspension. On the one hand, we obtain a basis allowing to compare the wear resistance of nozzles and on the other hand, a parameter indicating the appropriate time to change the suspension...|$|E
40|$|Abstract — Feature Selection (FS) is a {{dimensionality}} reduction {{technique that}} aims to select {{a subset of the}} original features of a dataset which offer the most useful information. The benefits of feature selection include improved data visualisation, transparency, reduction in training and <b>utilisation</b> <b>times</b> and improved prediction performance. Methods based on fuzzy-rough set theory (FRFS) have employed the dependency function to guide the process with much success. This paper presents a novel fuzzy-rough FS technique which is guided by fuzzy entropy. The use of this measure in fuzzy-rough feature selection can result in smaller subset sizes than those obtained through FRFS alone, with little loss or even an increase in overall classification accuracy. I...|$|R
30|$|Reasons for {{cancellations}} can {{be roughly}} divided into non-modifiable patient factors, i.e., the patient cancels or is unfit to undergo the procedure and modifiable system factors relating to poor theatre <b>time</b> <b>utilisation</b> such as late starts, overrunning lists and no separate emergency list disrupting theatre time [6]. A {{number of studies}} have demonstrated the extent of poor <b>utilisation</b> of theatre <b>time,</b> showing in some cases that 50 % of lists over-ran their scheduled time [10] and 43.6 % started late [12].|$|R
40|$|N. Mac Parthalain, R. Jensen and Q. Shen. Fuzzy entropy-assisted fuzzy-rough feature selection. Proceedings of the 15 th International Conference on Fuzzy Systems (FUZZ-IEEE' 06). 2006. Feature Selection (FS) is a {{dimensionality}} reduction {{technique that}} aims to select {{a subset of the}} original features of a dataset which offer the most useful information. The benefits of feature selection include improved data visualisation, transparency, reduction in training and <b>utilisation</b> <b>times</b> and improved prediction performance. Methods based on fuzzy-rough set theory (FRFS) have employed the dependency function to guide the process with much success. This paper presents a novel fuzzy-rough FS technique which is guided by fuzzy entropy. The use of this measure in fuzzy-rough feature selection can result in smaller subset sizes than those obtained through FRFS alone, with little loss or even an increase in overall classification accuracy. Non peer reviewe...|$|R
40|$|To {{optimise}} {{district heating}} (DH) systems and simplify the transition towards the fourth generation of district heating, {{it is important}} to remove any bottlenecks existing in the DH network. DH bottlenecks are in this study defined as pipes with too high flow relative to the pipe diameter, resulting in difficulties to maintain sufficient differential pressure in the area beyond the pipe. The aim {{of this study is to}} investigate how well possible measures to solve bottleneck problems work in different DH network configurations and how much they cost. This was achieved by a simulation study and a cost analysis. The results showed that DH systems with a lower flow rate demanded more extensive measures than other systems and that different problems might arise in different types of networks. The economic results showed that a lot of varying parameters, such as the internal rate of return, the fuel and electricity prices and the annual <b>utilisation</b> <b>time</b> of the measure could have a large impact on the outcome. An increase of the supply temperature could however easily become very expensive. Before any bottleneck measures are implemented in a DH system, calculations and analysis based on the local situations should thus be performed...|$|E
40|$|PURPOSE: Office space {{planning}} requires design skills and {{space planning}} norms to ensure space efficient office areas allowing occupants to perform optimally. No specific space norms exist for South African municipalities. Municipal facilities are unique and fulfil many functions, challenging {{the application of}} space norms. This study was part of work commissioned by the Development Bank of South Africa (DBSA) to understand municipal office space use in preparing a guideline for future municipal office building funding applications. The study evaluated current South African municipal office space allocation, compared it to office space planning norms for South African organs of state and identified possible challenges to applying the said space planning norms to municipal office space planning. DESIGN: The study was {{based on data from}} fieldwork surveys by professional quantity surveyors and valuators on municipal office space <b>utilisation.</b> <b>Time</b> and cost constraints restricted the survey to non-metropolitan municipalities in four provinces. The study adopted qualitative and quantitative methods to reach the findings. FINDINGS: The study revealed significant comparisons and deviations from South African and international space planning norms and identified challenges for municipalities to apply space planning norms. VALUE: This study provides insight into the current state and efficiency of municipal office space utilisation. By identifying challenges for applying space planning norms to municipalities the study suggests where future action should be focused to address the problem. [URL]...|$|E
40|$|Purpose: The aim of {{the study}} was to {{evaluate}} the various donor and recipient factors associated with short-term prevalence of surface epithelial keratopathy after optical penetrating keratoplasty (OPK). Methods: Preoperative and postoperative data of 91 eyes of 91 patients were reviewed retrospectively who had undergone OPK from March 2013 to February 2016. Donor and recipient data were analyzed for age and sex of the donor, cause of death, death to enucleation time (DET), death to preservation time (DPT), enucleation to <b>utilisation</b> <b>time</b> (EUT) and total time (TT), age and sex of recipient, indications of penetrating keratoplasty (PK), associated glaucoma and recipient size (RS). The presence of various epitheliopathies were recorded at various postoperative visits. Results: The range of age of recipient in this study was 10 – 83  yrs (mean 49. 19  ±  19. 35  yrs). The donor age ranged in between 17 and 95 years (70. 27  ±  15. 11 years). Age and preoperative diagnosis of host showed significant influence on epitheliopathy till two weeks and one month post-PK (P =  0. 032 and 0. 05), respectively. Donor's age and gender showed significant impact on surface keratopathy (SK) till two weeks follow-up with P value of 0. 04 and 0. 004, respectively. DET, DPT, EUT, and TT affected the surface epithelium significantly with P value of 0. 007, 0. 001, 0. 05, and 0. 03, respectively. On first postoperative day 33 (36. 26 %) eyes developed epithelial defect involving > 1 / 2 of cornea. Conclusion: Various donor and recipient factors showed influence on various epithelial abnormalities of surface epithelium in early postoperative period...|$|E
40|$|Abstract — Feature Selection (FS) is a {{technique}} for dimensionality reduction. Its aims are to select {{a subset of the}} original features of a dataset which are rich in the most useful information. The benefits include improved data visualisation, transparency, a reduction in training and <b>utilisation</b> <b>times</b> and potentially, improved prediction performance. Many approaches based on rough set theory have employed the dependency function which is based on the information contained in the lower approximation as an evaluation step in the FS process with much success. This paper presents a novel rough set FS technique which uses the information of both the lower approximation dependency value and a distance metric for the consideration of objects in the boundary region. The use of this measure in rough set feature selection can result in smaller subset sizes than those obtained using the dependency function alone. I...|$|R
40|$|Abstract—Dataset {{dimensionality}} {{is undoubtedly}} {{the single most}} significant obstacle which exasperates any attempt to apply effective computational intelligence techniques to problem domains. In order {{to address this problem}} a technique which re-duces dimensionality is employed prior to the application of any classification learning. Such feature selection (FS) techniques attempt to select a subset of the original features of a dataset which are rich in the most useful information. The benefits can include improved data visualisation and transparency, a reduction in training and <b>utilisation</b> <b>times</b> and potentially, im-proved prediction performance. Methods based on fuzzy-rough set theory have demonstrated this with much success. Such methods have employed the dependency function which is based on the information contained in the lower approximation as an evaluation step in the FS process. This paper presents three novel feature selection techniques employing fuzzy entropy to locate fuzzy-rough reducts. This approach is compared with two other fuzzy-rough feature selection approaches which utilise other measures for the selection of subsets. I...|$|R
40|$|N. Mac Parthal?in, Q. Shen, and R. Jensen. Distance Measure Assisted Rough Set Feature Selection. Proceedings of the 16 th International Conference on Fuzzy Systems (FUZZ-IEEE? 07), pp. 1084 - 1089. 2007. Feature Selection (FS) is a {{technique}} for dimensionality reduction. Its aims are to select {{a subset of the}} original features of a dataset which are rich in the most useful information. The benefits include improved data visualisation, transparency, a reduction in training and <b>utilisation</b> <b>times</b> and potentially, improved prediction performance. Many approaches based on rough set theory have employed the dependency function which is based on the information contained in the lower approximation as an evaluation step in the FS process with much success. This paper presents a novel rough set FS technique which uses the information of both the lower approximation dependency value and a distance metric for the consideration of objects in the boundary region. The use of this measure in rough set feature selection can result in smaller subset sizes than those obtained using the dependency function alone. Non peer reviewe...|$|R
40|$|Taxis are {{the main}} mode of {{transport}} used by commuters in South Africa. The management of transport utilized by commuters in developing countries has become problematic more especially in large metropolitan areas. The main cause of this is urbanization which is the movement of people to cities for better opportunities accessible, therefore this results in massive demand of public transport especially minibus-taxis. In South Africa {{little research has been}} conducted on the management of minibus-taxi, improvement of the service and scheduling route for taxis. Scheduling bus system approach is used to solve scheduling problems within the taxi industry. A number of countries like Taiwan and Lisbon experience public transport problems. Therefore less attention given to public transportation may lead to commuter utilising private transportation which may result in congestion of roads. The government has introduced Bus Rapid Transport (BRT) system in four cities which are Pretoria, Johannesburg, Cape Town and Nelson Mandela bay. This system will help in integrating bus, train and taxis into one but BRT is still under development in all the cities. Passengers encounter long queues in ranks during pick hours which in most cases results in long waiting period. In certain routes passengers wait long for taxis because they pass the area full especial on peak hours. This study discusses the waiting time for passengers and taxi <b>utilisation</b> <b>time</b> cycle for each destination. The findings of this study will be used for recommendations on how the taxi services can be improved. Thesis (B Eng. (Industrial and Systems Engineering)) [...] University of Pretoria, 2011...|$|E
40|$|Shovels, haul {{trucks and}} {{conveyors}} {{are used in}} surface mines for material haulage of which trucks are have been most widely used. This paper presents a comprehensive comparison study {{in terms of the}} operating efficiency of trucks and conveyors as applied in surface mining operations. Three key time usage metrics are used to assess the efficiency of both haulage systems namely: Utilised Time, Operating Time and Valuable Operating Time. The notion that measurement of equipment performance should focus on a multi instead of a single- factor approach is proposed. Comparison of the two systems based on these measures indicates that although trucks lend themselves to high flexibility and lower upfront capital outlay, conveyor haulage offers a better measure of performance on all the three metrics of measuring equipment performance. This opportunity lies in the high Valuable Operating Time achievable with the conveyors compared to the trucks. The results of analysis on 308, 912 load records and 12 months equipment usage indicates that while the truck fleet achieve much higher Available Time and <b>Utilisation</b> <b>Time,</b> the conveyors achieve a higher Valuable Operating Time (25 % higher) compared to the truck fleet. The conveyors achieved an average of 3, 509 hours in Valuable Operating Time compared to the average Valuable Operating Time of 2, 638 hours for the truck fleet. The inference made from this observation is that, the higher effective utilisation of a continuous haulage system for example In-Pit Crusher Conveying (IPCC) could significantly improve the operating efficiency of the loading equipment...|$|E
40|$|The {{passage of}} time is unrelenting. Time is an omnipresent feature of our existence, serving as a context to frame change driven by events and {{phenomena}} in our personal lives and social constructs. Accordingly, various elements of time are woven throughout information itself, and information behaviours such as creation, seeking and <b>utilisation.</b> <b>Time</b> plays {{a central role in}} many aspects of information retrieval (IR). It can not only distinguish the interpretation of information, but also profoundly influence the intentions and expectations of users' information seeking activity. Many time-based patterns and trends - namely temporal dynamics - are evident in streams of information behaviour by individuals and crowds. A temporal dynamic refers to a periodic regularity, or, a one-off or irregular past, present or future of a particular element (e. g., word, topic or query popularity) - driven by predictable and unpredictable time-based events and phenomena. Several challenges and opportunities related to temporal dynamics are apparent throughout IR. This thesis explores temporal dynamics from the perspective of query popularity and meaning, and word use and relationships over time. More specifically, the thesis posits that temporal dynamics provide tacit meaning and structure of information and information seeking. As such, temporal dynamics are a ‘two-way street’ since they must be supported, but also conversely, can be exploited to improve time-aware IR effectiveness. Real-time temporal dynamics in information seeking must be supported for consistent user satisfaction over time. Uncertainty about what the user expects is a perennial problem for IR systems, further confounded by changes over time. To alleviate this issue, IR systems can: (i) assist the user to submit an effective query (e. g., error-free and descriptive), and (ii) better anticipate what the user is most likely to want in relevance ranking. I first explore methods to help users formulate queries through time-aware query auto-completion, which can suggest both recent and always popular queries. I propose and evaluate novel approaches for time-sensitive query auto-completion, and demonstrate state-of-the-art performance of up to 9. 2...|$|E
40|$|Objectives: To {{describe}} {{the pattern of}} sickbay <b>utilisation</b> and lost <b>time</b> aboard a RAN Major Fleet Unit during a prolonged overseas deployment. Methods: A prospective cohort analysis {{was performed on the}} ships company of an Australian warship (n = 226) over a 100 day overseas deployment to multiple ports, to analyse sickbay utilisation (number of consultations) and lost time (number of days on reduced duties). Statistical analysis was performed using regression analysis, ANOVA and partitioning methods. Results: Female gender and smoking were associated with increased sickbay <b>utilisation</b> and lost <b>time.</b> Males with MEC class 1 or non-smoking males with MEC 201 or worse were protective of sickbay utilisation. Being a non-smoking male over 22 years was protective of lost time. Gender, rank, MEC, age and smoker were all found to be discriminators. BMI was not related to either sickbay <b>utilisation</b> or lost <b>time.</b> Conclusions: Being a male with no medical restrictions at the time of deployment was protective of sickbay utilisation, and being a non-smoking male older than 22 was associated with reduced morbidity. No association was found between BMI and either sickbay utilisation or morbidity. ...|$|R
40|$|N. Mac Parthal?in, R. Jensen, and Q. Shen. Finding Fuzzy-Rough Reducts with Fuzzy Entropy. Proceedings of the 2008 IEEE Conference on Fuzzy Systems, Hong Kong. 2008 Dataset {{dimensionality}} {{is undoubtedly}} {{the single most}} significant obstacle which exasperates any attempt to apply effective computational intelligence techniques to problem domains. In order {{to address this problem}} a technique which reduces dimensionality is employed prior to the application of any classification learning. Such feature selection (FS) techniques attempt to select a subset of the original features of a dataset which are rich in the most useful information. The benefits can include improved data visualisation and transparency, a reduction in training and <b>utilisation</b> <b>times</b> and potentially, improved prediction performance. Methods based on fuzzy-rough set theory have demonstrated this with much success. Such methods have employed the dependency function which is based on the information contained in the lower approximation as an evaluation step in the FS process. This paper presents three novel feature selection techniques employing fuzzy entropy to locate fuzzy-rough reducts. This approach is compared with two other fuzzy-rough feature selection approaches which utilise other measures for the selection of subsets. Non peer reviewe...|$|R
40|$|This paper {{examines}} {{developments in}} Trade Practices Act law {{during the period}} 1999 - 2001 with specific references to Part IV of that Act which deals with Restrictive Trade Practices. The analysis focuses attention upon whether a finality of amendments to the Act has been attained and a consideration is made and whether the case law principles yield certainty and predictability when applied to given factual situations. Attention is also given to whether the decisions have involved a proper <b>utilisation</b> of <b>time.</b> 10 page(s...|$|R
40|$|BACKGROUND: A recent Dutch mono-centre {{randomised}} controlled {{trial has}} shown that occupational therapy improves daily functioning in dementia. The aim of this present study is to compare {{the effects of the}} Dutch community occupational therapy programme with a community occupational therapy consultation on daily functioning in older people with mild or moderate dementia and their primary caregivers in a German multi-centre context. METHODS/DESIGN: A multi-centre single blind {{randomised controlled trial}} design is being used in seven health care centres (neurological, psychiatric and for older people) in urban regions. Patients are 1 : 1 randomised to treatment or control group. Assessors are blind to group assignment and perform measurements on both groups at baseline, directly after intervention at 6 weeks and at 16, 26 and 52 weeks follow-up. A sample of 140 community dwelling older people (aged > 65 years) with mild or moderate dementia and their primary caregivers is planned. The experimental intervention consists of an evidence-based community occupational therapy programme including 10 sessions occupational therapy at home. The control intervention consists of one community occupational therapy consultation based on information material of the Alzheimer Society. Providers of both interventions are occupational therapists experienced in treatment of cognitively impaired older people and trained in both programmes. 'Community' indicates that occupational therapy intervention occurs in the person's own home. The primary outcome is patients' daily functioning assessed with the performance scale of the Interview for Deterioration in Daily Living Activities in Dementia and video tapes of daily activities rated by external raters blind to group assignment using the Perceive, Recall, Plan and Perform System of Task Analysis. Secondary outcomes are patients' and caregivers' quality of life, mood and satisfaction with treatment; the caregiver's sense of competence, caregiver's diary (medication, resource <b>utilisation,</b> <b>time</b> of informal care); and the incidence of long-term institutionalisation. Process evaluation is performed by questionnaires and focus group discussion. DISCUSSION: The transfer from the Dutch mono-centre design to the pragmatic multi-site trial in a German context implicates several changes in design issues including differences in recruitment time, training of interventionists and active control group treatment. The study is registered under DRKS 00000053 at the German register of clinical trials, which is connected to the International Clinical Trials Registry Platform...|$|E
40|$|In recent years, it {{has become}} {{standard}} practice to consider Combined Heat-and-Power (CHP) systems for commercial buildings. CHP schemes are used, because they are an efficient means of power generation. Unlike conventional power stations, they produce electricity locally and thus minimise the distribution losses, however, they also utilise the waste heat from the generation process. In applications {{where there is a}} combined heating and electricity requirement, a very efficient means of energy production is achieved compared to the conventional methods of providing heating and electricity. With new initiatives from the UK government on reduced energy-use, energy-efficient systems such as CHP have been considered for new applications. This paper summarises the results of an investigation into the viability of CHP systems in supermarkets. The viability of conventional CHP has been theoretically investigated using a mathematical model of a typical supermarket. This has demonstrated that a conventional CHP system may be practically applied. It has also been shown that compared to the traditional supermarket design, the proposed CHP system will use slightly less primary energy and the running costs will be significantly reduced. An attractive payback period of approximately 4 years has been calculated. Despite these advantages a considerable quantity of heat is rejected to atmosphere with this system and this is because the configuration utilises the heat mainly for space heating which is only required for part of the year. To increase the <b>utilisation</b> <b>time,</b> a novel CHP/absorption system has been investigated. This configuration provides a continuous demand for the waste heat, which is used to drive an absorption chiller that refrigerates propylene glycol to - 10 Â°C for cooling the chilled-food cabinets. The results show this concept to be theoretically practical. The system has also been shown to be extremely efficient, with primary energy savings of approximately 20 %, when compared to traditional supermarket designs and this would result in significant revenue cost savings as well as environmental benefits. Based upon these savings a payback period for this system of approximately 5 years has been demonstrated. Supermarkets Absorption cooling Combined heat and power CHP Food refrigeration...|$|E
40|$|This project aims to {{investigate}} the parameters that affect the swell factor used in design and reported volumes for {{different parts of the}} mining process and cast blasting methods at various locations around Callide mine. The Callide coal mine along with most mines worldwide have been using a swell factor as a variable in open cut mine design and volume removed calculations throughout history. At Callide coal mine a swell factor with now unknown origins or validity is being used. The current swell factor appears to be correct which can be seen by design being achieved however, after the annual Audit by Anglo BCO, the validity of this figure has been requested. As well as validating the swell factor, this report aims to predict the swell factor for future cast blasting applications. This report is an investigation and includes the identification of the properties affecting the swelling of overburden material during the drill and blast process. These properties include those within the drill pattern design, explosives used and the geological makeup of the overburden. The report then validates the swell factor through measurement using traditional survey techniques. Upon identifying the drill, explosive and geological properties and the swell factor, the use of projection modelling and linear regression techniques for the analysis are employed. This is to discover which of the design and geological properties affect the swell factor the most and attempt to predict site specific swell factors based upon them. The research needed {{to investigate}} the previously mentioned aims is based in their relative industries and professions. These include the mining industry, surveying and spatial science, geology and geotechnical engineering, drill and blast engineering, mathematics and data analysis. This investigation will provide background knowledge and {{a review of the literature}} applied, information on the application and methodology used and a detailed analysis of captured data and resulting conclusions for the swell factor. The exploration and use of survey techniques employed for calculating the swell factor and the data collection and analysis will use aerial scanning, I-Site terrestrial scanning, three dimensional modelling as well as standard survey procedures. The geological study has required research into geological properties, in specific those affected by the drill and blast process, the lithology of Callide mine and methods of testing and acquisition. Research into drill and blast engineering includes desired fragmentation size and maximum cast, the effect of drill and blast techniques on the overburden and which properties affect a change in overburden volume. To obtain an accurate prediction of the swell factors a model must be created that amalgamates the information from the three professions, eliminates superfluous data and has the ability to be validated. To facilitate this, projection modelling and linear regression techniques are used in an effort to identify the a priori components to mathematically and graphically represent the relationship of properties within the data sets and the swell factor. Developing a method of calculating the overburden swell factor will greatly affect mine design and reporting. If the swell factor is accurately known there is a possibility that design constraints can be tightened leading to better equipment <b>utilisation,</b> <b>time</b> management and an overall increase in efficiency. An increase in efficiency will lead to improved production and ultimately enhance capital gain. ...|$|E
50|$|Nodal {{officer for}} SutharyaKeralam phone-in-programme and SutharyaKeralam I&PRD cell and manages {{production}} of video documentary-short film, oversees proper <b>utilisation</b> of purchased <b>time</b> slots, visual communication works, liaison works of outhouse producers, validate the appropriate utilisation of allotted fund from respective Head of account, in house-out house documentary works, audio-video archives works etc.|$|R
40|$|AbstractAn {{increase}} in train traffic is a politically welcomed trend, which {{on the other}} hand has led to too high capacity <b>utilisation</b> at <b>times</b> and a railway network sensitive to disturbances. Delays are easily spread, causing high cost. A mean of controlling the secondary delays is to use efficient operational prioritisation rules for trains in conflict. This paper presents an evaluation of the current Swedish prioritisation rule. For two frequent conflict situations the associated cost related to applying the rule is calculated. The result indicates a poor economic efficiency and show that significant savings can be achieved by changing strategy...|$|R
40|$|The authors {{report on}} {{an attempt to}} examine the theory, {{practical}} feasibility and benefits of making vehicle build information accessible to second and third-tier component suppliers. A description is provided of a case study used to demonstrate the impact on supply chain performance of sharing vehicle build information with the upstream suppliers of a high-volume vehicle manufacturer. A range of performance measures aggregated {{in the form of}} a ''supply chain scorecard'' demonstrated that suppliers are able to synchronise manufacturing more closely with the vehicle manufacturer and make capacity <b>utilisation,</b> lead <b>time</b> and inventory improvements with access to vehicle production schedules...|$|R
40|$|Abstract: Problem statement: Efficient {{scheduling}} of {{the tasks}} to heterogeneous processors for any application is critical {{in order to achieve}} high performance. Finding a feasible schedule for a given task set to a set of heterogeneous processors without exceeding the capacity of the processors, in general, is NP-Hard. Even if there are many conventional approaches available, people have been looking at unconventional approaches for solving this problem. This study uses a paradigm using Ant Colony Optimisation (ACO) for arriving at a schedule. Approach: An attempt is made to arrive at a feasible schedule of a task set on heterogeneous processors ensuring load balancing across the processors. The heterogeneity of the processors is modelled by assuming different <b>utilisation</b> <b>times</b> for the same task on different processors. ACO, a bio-inspired computing paradigm, is used for generating the schedule. Results: For a given instance of the problem, ten runs are conducted based on an ACO algorithm and the average wait time of all tasks is computed. Also the average utilisation of each processor is calculated. For the same instance, the two parameters: average wait time of tasks and utilisation of processors are computed using the First Come First Served (FCFS). The results are tabulated and compared and it is found that ACO performs better than the FCFS with respect to the wait time. Although the processor utilisation is more for some processors using FCFS algorithm, it is found that the load is better balance...|$|R
40|$|N. Mac Parthal?in, Q. Shen, and R. Jensen. A A Distance Measure Approach to Exploring the Rough Set Boundary Region for Attribute Reduction. IEEE Transactions on Knowledge and Data Engineering, vol. 22, no. 3, pp. 306 [...] 317, 2010. Feature Selection (FS) or Attribute Reduction {{techniques}} are employed for dimensionality reduction and aim {{to select a}} subset of the original features of a dataset which are rich in the most useful information. The benefits of employing FS techniques include improved data visualisation and transparency, a reduction in training and <b>utilisation</b> <b>times</b> and potentially, improved prediction performance. Many approaches based on rough set theory up to now, have employed the dependency function, which is based on lower approximations as an evaluation step in the FS process. However, by examining only that information which is considered to be certain and ignoring the boundary region, or region of uncertainty, much useful information is lost. This paper examines a rough set FS technique which uses the information gathered from both the lower approximation dependency value and a distance metric which considers the number of objects in the boundary region and the distance of those objects from the lower approximation. The use of this measure in rough set feature selection can result in smaller subset sizes than those obtained using the dependency function alone. This demonstrates that there is much valuable information to be extracted from the boundary region. Experimental results are presented for both crisp and real-valued data and compared with two other FS techniques in terms of subset size, runtimes and classification accuracy. Peer reviewe...|$|R
40|$|Comparative {{analysis}} of linear, non-linear and multiple temporal dimensions {{in music and}} film reveals that the understanding and <b>utilisation</b> of <b>time</b> in these two arts reflect not only the aesthetic inclinations of its creators and their subjective experiences of temporality but also their philosophical views and, sometimes, spiritual beliefs. Viewed {{in the context of}} contemporary theories about Time, particularly Shallis' interpretation of different temporalities as symbolic of various levels of reality and J. T. Fraser's concept of time as a hierarchical nest of different temporalities or Umwelts, the results of this comparison lead {{to the conclusion that the}} time in which music and film unfold belongs to a separate, artificial Umwelt of its own - art-temporality...|$|R
40|$|Problem statement: Efficient {{scheduling}} of {{the tasks}} to heterogeneous processors for any application is critical {{in order to achieve}} high performance. Finding a feasible schedule for a given task set to a set of heterogeneous processors without exceeding the capacity of the processors, in general, is NP-Hard. Even if there are many conventional approaches available, people have been looking at unconventional approaches for solving this problem. This study uses a paradigm using Ant Colony Optimisation (ACO) for arriving at a schedule. Approach: An attempt is made to arrive at a feasible schedule of a task set on heterogeneous processors ensuring load balancing across the processors. The heterogeneity of the processors is modelled by assuming different <b>utilisation</b> <b>times</b> for the same task on different processors. ACO, a bio-inspired computing paradigm, is used for generating the schedule. Results: For a given instance of the problem, ten runs are conducted based on an ACO algorithm and the average wait time of all tasks is computed. Also the average utilisation of each processor is calculated. For the same instance, the two parameters: average wait time of tasks and utilisation of processors are computed using the First Come First Served (FCFS). The results are tabulated and compared and it is found that ACO performs better than the FCFS with respect to the wait time. Although the processor utilisation is more for some processors using FCFS algorithm, it is found that the load is better balanced among the processors in ACO. There is a marginal increase in the time for arriving at a schedule in ACO compared to FCFS algorithm. Conclusion: This approach to the tasks assignment problem using ACO performs better with respect to the two parameters used compared to the FCFS algorithm but the time taken {{to come up with the}} schedule using ACO is slightly more than that of FCFS...|$|R
40|$|Demersal trawl {{fisheries}} generate {{large quantities of}} discards which temporarilyincrease the amount of carrion available to benthic communities and lead to a faster energetic turnover. This study examines the availability of discarded material to the benthos, assesses consumptiontimes of different items and identifies scavengers attracted to those invertebrates most frequently discardedfrom Clyde Sea Nephrops trawlers. In field and laboratory trials, heavy-shelled dead whelks(Buccinum undatum, Neptunea antiqua) sank faster than softer-bodied species like cephalopods(Allotheuthis subulata, Rossia macrosoma) or echinoderms (Ophiura ophiura, Asterias rubens), makingmost discards available to the benthos (at ca. 60 m CD [chart datum]) within minutes after discarding. SCUBA and time-lapse camera observations in the Clyde Sea and Loch Sween indicatedbait <b>utilisation</b> <b>times</b> between 24 and 48 h. Fast-moving animals like brachyuran crabs were the firstto arrive at discard bait piles whose composition mimicked typical discards from the Clyde SeaNephrops fishery. Bimonthly deployments of traps baited with invertebrate discards in the north ofthe Clyde Sea showed that A. rubens, followed by Pagurus bernhardus, Liocarcinus depurator andwhelks, were the most abundant megafaunal scavengers. Fine-meshed funnel traps deployed insidethose creels yielded up to 2819 amphipods per trap, with Scopelocheirus hopei and Orchomenenanus accounting {{for most of the}} catch. Together with whelks, A. rubens and Carcinus maenas,O. nanus showed a clear preference for crustacean bait. By contrast, Pagurus bernhardus was moreattracted to A. rubens and, in 1 trial, to O. ophiura bait. Traps deployed in the south of the Clyde Seayielded generally lower numbers and species diversity in the catch, with Nephrops being the mostabundant megafaunal scavenger. It showed a preference for L. depurator and conspecific bait. Whilethe results show that a range of epibenthic species readily utilise invertebrates discarded from ClydeSea Nephrops trawlers, it is unknown to what extent discards subsidise benthic communities as informationon the ecological energetics of the species involved locally is currently lacking...|$|R
30|$|The lower travel speeds for {{freight train}} stem from many factors, {{including}} acceleration and braking systems [21], priority of train paths {{being given to}} passenger trains in mixed running [12], an institutional neglect of rail freight in network planning [22]. The overall transit time of rail freight services can be affected by these and also other {{factors such as the}} stopping the freight trains at marshalling yards, terminals and borders, and operational processes that favour efficient utilisation of space/weight over the <b>utilisation</b> of <b>time.</b> To attract the shippers of time sensitive cargos, that customers wish to track in real time, rail freight transport operators must adopt novel tracking and tracing solutions that go beyond the tracking of trains by the infrastructure manager, and which instead track the goods themselves [15, 23].|$|R
40|$|This paper {{presents}} {{a case study}} of using simulation in planning a new Printed Circuit Board (PCB) manufacturing system. The process simulation technique and expert system are proposed to evaluate the design alternatives and logistics management. Simulation results, such as machine <b>utilisation,</b> waiting <b>time,</b> and throughput of system are generated for evaluation. Simulation models were developed using software package SIMPROCESS, which is based on the concept of visual interactive simulation. Besides, the formation of the models is assisted by the expert system package VP-EXPERT. Each approach was found to accurately model the PCB manufacturing plant layout, provide operational and logistics performance in terms of throughput, waiting <b>time,</b> and resource <b>utilisation,</b> and provide a basis for suggesting the best modes of logistics operation. © 2004 Elsevier Ltd. All rights reserved. link_to_subscribed_fulltex...|$|R
40|$|This paper {{explores the}} {{operational}} problems of flexible manufacturing systems (FMS) through simulation. The {{purpose of this}} study is to evaluate various combinations of scheduling rules in the FMS system, i. e. given a set of dispatching rules applied at the workstations, the effect of different machine selection rules to the system performance are analysed. Various measures, such as makespan, lead <b>time,</b> machine <b>utilisation,</b> net profit, <b>time</b> delay and inventory level at local input buffer are examined. link_to_subscribed_fulltex...|$|R
50|$|Rates {{are drawn}} from the {{exponential}} distribution and PEPA models are finite-state and so {{give rise to a}} stochastic process, specifically a continuous-time Markov process (CTMC). Thus the language can be used to study quantitative properties of models of computer and communication systems such as throughput, <b>utilisation</b> and response <b>time</b> as well as qualitative properties such as freedom from deadlock. The language is formally defined using a structured operational semantics in the style invented by Gordon Plotkin.|$|R
40|$|This is {{a conference}} paper. Made {{available}} by kind {{permission of the}} publisher. As the National Health Service (NHS) of England continues to face tighter cost saving and utilisation government set targets, finding the optimum between costs, patient waiting <b>times,</b> <b>utilisation</b> of resources, and user satisfaction is increasingly challenging. Patient scheduling is a subject which has been extensively covered in the literature, with many previous studies offering solutions to optimise the patient schedule for a given metric. However, few analyse a large range of metrics pertinent to the NHS. The tool {{presented in this paper}} provides a discrete-event simulation tool for analysing a range of patient schedules across nine metrics, including: patient waiting, clinic room utilisation, waiting room utilisation, staff hub utilisation, clinician <b>utilisation,</b> patient facing <b>time,</b> clinic over-run, post-clinic waiting, and post-clinic patients still being examined. This allows clinic managers to analyse a number of scheduling solutions to find the optimum schedule for their department by comparing the metrics and selecting their preferred schedule. Also provided is an analysis of the impact of variations in appointment durations and their impact on how a simulation tool provides results. This analysis highlights the need for multiple simulation runs to reduce the impact of non-representative results from the final schedule analysis...|$|R
30|$|Due to the {{low cost}} of reusing {{existing}} functionally equivalent services, called variant services, several approaches based on design diversity exist to support fault-tolerant Service-Oriented Architecture (SOA). These solutions operate in the communication between clients and variant services, which are structured in fault-tolerant compositions. Regarding fault tolerance based on software diversity, three major design issues need to be considered, namely, selection of variants; variant execution schemes; and judgement on results acceptability. These design issues may be realised by different design solutions. Different design decisions involve different measures of quality requirements (e.g. memory <b>utilisation,</b> execution <b>time,</b> reliability, financial costs and availability). With respect to service-oriented computing, {{it is well known}} that SOA systems (i) exhibit highly dynamic characteristics, and changes in the quality of services are likely to occur frequently and (ii) should support conflicting user requirements. Therefore, effective SOA solutions should address these design challenges.|$|R
40|$|The {{quality of}} the {{programmes}} and courses in ODL depends on the academics that plan the programmes, develop the curriculum, manage courses and programmes and carry out administrative duties. It is observed that the academics often complain of work overload. It also appears there is a mix-up in integrating the mode of planning workload in the conventional universities into the open and distance education universities. This {{may be attributed to}} inadequate spread in the duties assigned, which if not checked could affect the quality of teaching and learning. This necessitated the study that was carried out to determine academic workload in NOUN. The findings revealed a gap between academic activities and adequate <b>utilisation</b> of <b>time.</b> Also, inadequate spread of activities affects the {{quality of the}} academic inputs. This {{led to the development of}} academic workload model to guide the spread of academic activities in open and distance learning...|$|R
