194|312|Public
25|$|In {{computer}} science, a rough set, {{first described}} by Polish computer scientist Zdzisław I. Pawlak, is a formal approximation of a crisp set (i.e., conventional set) {{in terms of}} a pair of sets which give the lower and the <b>upper</b> <b>approximation</b> of the original set. In the standard version of rough set theory (Pawlak 1991), the lower- and upper-approximation sets are crisp sets, but in other variations, the approximating sets may be fuzzy sets.|$|E
2500|$|In summary, {{the lower}} {{approximation}} {{of a target}} set is a conservative approximation consisting of only those objects which can positively be identified {{as members of the}} set. (These objects have no indiscernible [...] "clones" [...] which are excluded by the target set.) The <b>upper</b> <b>approximation</b> is a liberal approximation which includes all objects that might be members of target set. (Some objects in the <b>upper</b> <b>approximation</b> may not be members of the target set.) From the perspective of , the lower approximation contains objects that are members of the target set with certainty (probability = 1), while the <b>upper</b> <b>approximation</b> contains objects that are members of the target set with non-zero probability (probability > 0).|$|E
2500|$|The -upper {{approximation}} is {{the union}} of all equivalence classes in [...] which have non-empty intersection with the target set – in the example, , {{the union of}} the three equivalence classes in [...] that have non-empty intersection with the target set. The <b>upper</b> <b>approximation</b> is the complete set of objects that in [...] that cannot be positively (i.e., unambiguously) classified as belonging to the complement (...) of the target set [...] In other words, the <b>upper</b> <b>approximation</b> is the complete set of objects that are possibly members of the [...] target set [...]|$|E
3000|$|When [...] X = X_ 1, {{the lower}} and <b>upper</b> <b>approximations</b> of [...] X_ 1 {{with respect to}} the {{knowledge}} P and Q are identical, and the classification granularities in the <b>upper</b> <b>approximations</b> u [...]...|$|R
40|$|In this note, we {{show some}} {{improvements}} for Theorem 7 and Example 8 in Shiping Wang[Information Sciences 263 (1), 186 - 197, 2014]. Concretely, we study further the sixth lower and <b>upper</b> <b>approximations</b> of sets for covering approximation spaces. Furthermore, we present the sixth dual lower and <b>upper</b> <b>approximations</b> of sets for covering approximation spaces. We also construct the sixth dual lower and <b>upper</b> <b>approximations</b> of sets from {{the view of}} matrix. Throughout, we use the same notations as Shiping Wang[Information Sciences 263 (1), 186 - 197, 2014]...|$|R
5000|$|Thus, only classes [...] and [...] {{cannot be}} {{approximated}} precisely. Their <b>upper</b> <b>approximations</b> are as follows: ...|$|R
2500|$|The tuple [...] {{composed}} of the lower and <b>upper</b> <b>approximation</b> is called a rough set; thus, a rough set is {{composed of}} two crisp sets, one representing a lower boundary of the target set , and the other representing an upper boundary of the target set [...]|$|E
2500|$|The LEM2 {{algorithm}} {{is based on}} an idea of an attribute-value pair block. [...] Let [...] be a nonempty lower or <b>upper</b> <b>approximation</b> of a concept represented by a decision-value pair [...] [...] Set [...] depends on a set [...] of attribute-value pairs [...] if and only if ...|$|E
2500|$|Rules induced {{from the}} lower {{approximation}} of the concept certainly describe the concept, hence such rules are called certain. [...] On the other hand, rules induced from the <b>upper</b> <b>approximation</b> of the concept describe the concept possibly, so these rules are called possible. [...] For rule induction LERS uses three algorithms: LEM1, LEM2, and IRIM.|$|E
40|$|The {{purpose of}} this paper is to {{introduce}} and discuss the concept of lower and <b>upper</b> <b>approximations.</b> A simple and straightforward way for interpreting rough sets is to use membership functions. We investi-gate the similarity between rough membership function and conditional probability. We also consider the fundamental relation kr defined on an Hy-group H and interprets the lower and <b>upper</b> <b>approximations</b> as sub-sets of the group Hi/` and give some properties of such subsets...|$|R
40|$|This paper {{presents}} and compares two {{views of the}} theory of rough sets. The operator-oriented view interprets rough set theory as an extension of set theory with two additional unary operators. Under such a view, lower and <b>upper</b> <b>approximations</b> are related to the interior and closure operators in topological spaces, the necessity and possibility operators in modal logic, and lower and <b>upper</b> <b>approximations</b> in interval structures. The set-oriented view focuses on the interpretation and characterization of members of rough sets. Iwinski type rough sets are formed by pairs of definable (composed) sets, which are related to the notion of interval sets. Pawlak type rough sets are defined based on equivalence classes of an equivalence relation on the power set. The relation is defined by the lower and <b>upper</b> <b>approximations.</b> In both cases, rough sets may be interpreted, or related to, families of subsets of the universe, i. e., elements of a rough set are subsets of the universe. Alternatively, r [...] ...|$|R
40|$|This paper proposes new {{definitions}} of lower and <b>upper</b> <b>approximations</b> which are basic concepts of rough set theory. These definitions follow naturally from {{the concepts of}} ambiguity and definability introduced in this paper. The new definitions are compared to the classical definitions and are shown to be more general {{in the sense that}} they are the only ones which can be used for any type of indiscernibility or similarity relation. Key words: rough sets, lower and <b>upper</b> <b>approximations,</b> similarity relation. 1 Introduction Classical {{definitions of}} lower and <b>upper</b> <b>approximations</b> (see, e. g., Pawlak, 1982, 1991) were originally introduced with reference to an indiscernibility relation which was assumed to be an equivalence relation (reflexive, symmetric and transitive). It is quite interesting to extend these concepts to the case of more general relations. In particular, considering a similarity or tolerance relation instead of an indiscernibility relation is quite relevant (see, e. g. Nie [...] ...|$|R
2500|$|That is, the {{accuracy}} of the rough set representation of , , , is the ratio of the number of objects which can positively be placed in [...] to the number of objects that can possibly be placed in [...] – this provides a measure of how closely the rough set is approximating the target set. Clearly, when the upper and lower approximations are equal (i.e., boundary region empty), then , and the approximation is perfect; at the other extreme, whenever the lower approximation is empty, {{the accuracy}} is zero (regardless {{of the size of the}} <b>upper</b> <b>approximation).</b>|$|E
2500|$|The LEM2 {{algorithm}} of LERS {{is frequently}} used for rule induction {{and is used}} not only in LERS but also in other systems, e.g., in RSES (Bazan et al. (2004). [...] LEM2 explores the search space of attribute-value pairs. [...] Its input data set is a lower or <b>upper</b> <b>approximation</b> of a concept, so its input data set is always consistent. [...] In general, LEM2 computes a local covering and then converts it into a rule set. [...] We will quote a few definitions to describe the LEM2 algorithm.|$|E
5000|$|In summary, {{the lower}} {{approximation}} {{of a target}} set is a conservative approximation consisting of only those objects which can positively be identified {{as members of the}} set. (These objects have no indiscernible [...] "clones" [...] which are excluded by the target set.) The <b>upper</b> <b>approximation</b> is a liberal approximation which includes all objects that might be members of target set. (Some objects in the <b>upper</b> <b>approximation</b> may not be members of the target set.) From the perspective of , the lower approximation contains objects that are members of the target set with certainty (probability = 1), while the <b>upper</b> <b>approximation</b> contains objects that are members of the target set with non-zero probability (probability > 0).|$|E
30|$|Strictly speaking, this {{algorithm}} {{does not}} implement all properties {{set out for}} rough sets [21] and hence belongs to the reduced interpretation of rough sets as lower and <b>upper</b> <b>approximations</b> of data [22].|$|R
40|$|AbstractThis paper {{presents}} and compares two {{views of the}} theory of rough sets. The operator-oriented view interprets rough set theory as an extension of set theory with two additional unary operators. Under such a view, lower and <b>upper</b> <b>approximations</b> are related to the interior and closure operators in topological spaces, the necessity and possibility operators in modal logic, and lower and <b>upper</b> <b>approximations</b> in interval structures. The set-oriented view focuses on the interpretation and characterization of members of rough sets. Iwinski type rough sets are formed by pairs of definable (composed) sets, which are related to the notion of interval sets. Pawlak type rough sets are defined based on equivalence classes of an equivalence relation on the power set. The relation is defined by the lower and <b>upper</b> <b>approximations.</b> In both cases, rough sets may be interpreted by, or related to, families of subsets of the universe, i. e., elements of a rough set are subsets of the universe. Alternatively, rough sets may be interpreted using elements of the universe based on the notion of rough membership functions. Both operator-oriented and set-oriented views are useful in the understanding and application {{of the theory of}} rough sets...|$|R
40|$|Rough {{set theory}} uses {{the concept of}} <b>upper</b> and lower <b>approximations</b> to {{encapsulate}} inherent inconsistency in real-world objects. Information multisystems are represented using multisets instead of crisp sets. This paper begins with an overview of recent works on multisets and rough sets. Rough multiset is introduced in terms of lower and <b>upper</b> <b>approximations</b> and explores related properties. The paper concludes with an example of certain types of information multisystems...|$|R
5000|$|The -upper {{approximation}} is {{the union}} of all equivalence classes in [...] which have non-empty intersection with the target set - in the example, , {{the union of}} the three equivalence classes in [...] that have non-empty intersection with the target set. The <b>upper</b> <b>approximation</b> is the complete set of objects that in [...] that cannot be positively (i.e., unambiguously) classified as belonging to the complement (...) of the target set [...] In other words, the <b>upper</b> <b>approximation</b> is the complete set of objects that are possibly members of the target set [...]|$|E
5000|$|The LEM2 {{algorithm}} {{is based on}} an idea of an attribute-value pair block. Let [...] be a nonempty lower or <b>upper</b> <b>approximation</b> of a concept represented by a decision-value pair [...] Set [...] depends on a set [...] of attribute-value pairs [...] if and only if ...|$|E
5000|$|The tuple [...] {{composed}} of the lower and <b>upper</b> <b>approximation</b> is called a rough set; thus, a rough set is {{composed of}} two crisp sets, one representing a lower boundary of the target set , and the other representing an upper boundary of the target set [...]|$|E
40|$|Although some information-theoretic {{measures}} of uncertainty or granularity {{have been proposed}} in rough set theory, these measures are only dependent on the underlying partition and the cardinality of the universe, independent of the lower and <b>upper</b> <b>approximations.</b> It seems somewhat unreasonable since the basic idea of rough set theory aims at describing vague concepts by the lower and <b>upper</b> <b>approximations.</b> In this paper, we thus define new information-theoretic entropy and co-entropy functions associated to the partition and the approximations to measure the uncertainty and granularity of an approximation space. After introducing the novel notions of entropy and co-entropy, we then examine their properties. In particular, we discuss the relationship of co-entropies between different universes. The theoretical development is accompanied by illustrative numerical examples...|$|R
40|$|Abstract. For {{completely}} specified decision tables, where {{lower and}} up-per approximations are unique, the lower approximation {{is the largest}} definable set contained in the approximated set X and the upper ap-proximation of X is the smallest definable set containing X. For incom-plete decision tables the existing definitions of <b>upper</b> <b>approximations</b> provide sets that, in general, are not minimal definable sets. The {{same is true for}} approximations based on relations that are generalizations of the equivalence relation. In this paper we introduce two definitions of approximations, local and global, such that the corresponding upper ap-proximations are minimal. Local approximations are more precise than global approximations. Global lower approximations may be determined by a polynomial algorithm. However, algorithms to find both local ap-proximations and global <b>upper</b> <b>approximations</b> are NP-hard. ...|$|R
40|$|AbstractIn this paper, we {{introduce}} new generalizations concepts of lower and <b>upper</b> <b>approximations</b> of Pawlak rough sets by using two topological structures (bitopologies). Also, we study {{the concept of}} the generalized topological rough set and some of their basic properties. Applications for data reduction are done on medical data...|$|R
50|$|Rules induced {{from the}} lower {{approximation}} of the concept certainly describe the concept, hence such rules are called certain. On the other hand, rules induced from the <b>upper</b> <b>approximation</b> of the concept describe the concept possibly, so these rules are called possible. For rule induction LERS uses three algorithms: LEM1, LEM2, and IRIM.|$|E
50|$|In {{computer}} science, a rough set, {{first described}} by Polish computer scientist Zdzisław I. Pawlak, is a formal approximation of a crisp set (i.e., conventional set) {{in terms of}} a pair of sets which give the lower and the <b>upper</b> <b>approximation</b> of the original set. In the standard version of rough set theory (Pawlak 1991), the lower- and upper-approximation sets are crisp sets, but in other variations, the approximating sets may be fuzzy sets.|$|E
50|$|The LEM2 {{algorithm}} of LERS {{is frequently}} used for rule induction {{and is used}} not only in LERS but also in other systems, e.g., in RSES (Bazan et al. (2004). LEM2 explores the search space of attribute-value pairs. Its input data set is a lower or <b>upper</b> <b>approximation</b> of a concept, so its input data set is always consistent. In general, LEM2 computes a local covering and then converts it into a rule set. We will quote a few definitions to describe the LEM2 algorithm.|$|E
40|$|Abstract—Covering-based {{rough set}} theory is an {{extension}} to classical rough set. The main {{purpose of this paper}} is to study covering rough sets from a topological point of view. The relationship among <b>upper</b> <b>approximations</b> based on topological spaces are explored. Index Terms — approximation operators, covering rough sets, topological space. I...|$|R
40|$|Notions {{of lower}} and <b>upper</b> <b>approximations</b> are {{proposed}} for multiple-source tolerance approximation spaces which {{consist of a}} number of tolerance relations over the same domain. A modal logic is proposed for reasoning about the defined notions of approximations. A sound and complete deductive system for the logic is presented. Decidability is also proved...|$|R
40|$|This study {{extends the}} rough set in interval-valued {{information}} systems to the multi-granulation rough set in interval-valued information systems. The lower and <b>upper</b> <b>approximations</b> {{of a set}} in interval-valued information systems based on multi-granulations are defined and some basic properties are introduced. In order to substantiate the conceptual arguments numerical examples are given...|$|R
5000|$|That is, the {{accuracy}} of the rough set representation of , , , is the ratio of the number of objects which can positively be placed in [...] to the number of objects that can possibly be placed in [...] - this provides a measure of how closely the rough set is approximating the target set. Clearly, when the upper and lower approximations are equal (i.e., boundary region empty), then , and the approximation is perfect; at the other extreme, whenever the lower approximation is empty, {{the accuracy}} is zero (regardless {{of the size of the}} <b>upper</b> <b>approximation).</b>|$|E
5000|$|Lower approximations {{group the}} objects which {{certainly}} belong to class union [...] (respectively [...] ). This certainty {{comes from the}} fact, that object [...] belongs to the lower approximation [...] (respectively [...] ), if no other object in [...] contradicts this claim, i.e. every object [...] which P-dominates , also belong to the class union [...] (respectively [...] ). Upper approximations group the objects which could belong to [...] (respectively [...] ), since object [...] belongs to the <b>upper</b> <b>approximation</b> [...] (respectively [...] ), if there exist another object [...] P-dominated by [...] from class union [...] (respectively [...] ).|$|E
30|$|Step 1. Each data {{sample is}} {{randomly}} assigned to one lower approximation. Since the lower approximation of a cluster is a subset of its <b>upper</b> <b>approximation,</b> this also automatically assigns the sample to the <b>upper</b> <b>approximation</b> of the same cluster.|$|E
50|$|In the {{mathematical}} theory of decisions, decision-theoretic rough sets (DTRS) is a probabilistic extension of rough set classification. First created in 1990 by Dr. Yiyu Yao, the extension {{makes use of}} loss functions to derive '''''' and '''''' region parameters. Like rough sets, the lower and <b>upper</b> <b>approximations</b> of a set are used.|$|R
30|$|On {{the other}} hand, {{in order to}} deal with vague {{description}} of objects, rough set theory was initialized by Pawlak [4] in 1982, which provides a new powerful mathematical approach to handling imperfect knowledge in the real world. A fundamental assumption in this theory is that objects are perceived through, and thus can be represented by, available information on their attributes, but such information may not be sufficient to characterize these objects exactly. One way is approximating a set by other sets. Thus a rough set may be defined by a pair of crisp sets which give the lower and <b>upper</b> <b>approximations</b> of the original set. Liu [5] defined a rough variable to be a measurable function from a rough space to the set of real numbers and gave the definition of the lower and <b>upper</b> <b>approximations</b> of the rough variable.|$|R
40|$|We {{investigate}} the modeling of uncertain concepts via rough description logics (RDLs), which are {{an extension of}} traditional description logics (DLs) by a mechanism to handle approximate concept definitions via lower and <b>upper</b> <b>approximations</b> of concepts based on a rough-set semantics. This allows to apply RDLs to modeling uncertain knowledge. Since these approximations are ultimately grounded on an indiscernibility relation, we explore possible logical and numerical ways for defining such relations based on the considered knowledge. In particular, we introduce the notion of context, allowing for the definition of specific equivalence relations, which are directly used for lower and <b>upper</b> <b>approximations</b> of concepts. The notion of context also allows for defining similarity measures, which are used for introducing a notion of tolerance in the indiscernibility. Finally, we describe several learning problems in our RDL framework. </p...|$|R
