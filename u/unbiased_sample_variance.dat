14|2659|Public
25|$|The <b>unbiased</b> <b>sample</b> <b>variance</b> is a U-statistic for the {{function}} ƒ(y1,y2) =(y1−y2)2/2, {{meaning that it}} is obtained by averaging a 2-sample statistic over 2-element subsets of the population.|$|E
25|$|Consider now a {{function}} of the unknown parameter: an estimator is a statistic used to estimate such function. Commonly used estimators include sample mean, <b>unbiased</b> <b>sample</b> <b>variance</b> and sample covariance.|$|E
25|$|Firstly, if the omniscient mean {{is unknown}} (and is {{computed}} as the sample mean), then the sample variance is a biased estimator: it underestimates the variance {{by a factor}} of (n−1) / n; correcting by this factor (dividing by n−1 instead of n) is called Bessel's correction. The resulting estimator is unbiased, and is called the (corrected) sample variance or <b>unbiased</b> <b>sample</b> <b>variance.</b> For example, when n=1 the variance of a single observation about the sample mean (itself) is obviously zero regardless of the population variance. If the mean is determined in some other way than from the same samples used to estimate the variance then this bias does not arise and the variance can safely be estimated as that of the samples about the (independently known) mean.|$|E
40|$|Four {{separate}} {{approaches to}} the problem of assessing variation in categorical data are developed, each of which results in an identical index of dispersion (D). An <b>unbiased</b> <b>sample</b> estimator of D is pre-sented, which bears an analogy with the common <b>unbiased</b> <b>sample</b> estimator of <b>variance</b> for quantitative data. An additional index, re-lated to a measure of entropy for categorical data, is mentioned and some applications are discussed...|$|R
5000|$|... is {{the sample}} mean.This is true {{regardless}} {{of the distribution of}} the random variable X, provided of course that the theoretical means and covariances exist. The reason for the factor n − 1 rather than n is essentially the same as the reason for the same factor appearing in <b>unbiased</b> estimates of <b>sample</b> <b>variances</b> and <b>sample</b> covariances, which relates {{to the fact that the}} mean is not known and is replaced by the sample mean.|$|R
40|$|In {{estimating}} parameter of {{the underlying}} distribution, the statistician may have prior information about parameter such that the true value of parameter lies {{in the neighborhood of}} a known value. We consider the problem of estimating variance of normal distribution when it is preliminarily conjectured that the true of variance lies in the interval. We suggest two estimators and compare these two estimators with the preliminary test estimator and the <b>sample</b> <b>unbiased</b> <b>variance</b> by using the mean square error...|$|R
2500|$|An {{unbiased}} estimator for the variance {{is given by}} applying Bessel's correction, using N−1 instead of N to yield the <b>unbiased</b> <b>sample</b> <b>variance,</b> denoted s2: ...|$|E
5000|$|... s2 is the <b>unbiased</b> <b>sample</b> <b>variance</b> (i.e. with Bessel's correction) ...|$|E
50|$|The {{degrees of}} freedom of the weighted, <b>unbiased</b> <b>sample</b> <b>variance</b> vary {{accordingly}} from N &minus; 1 down to 0.|$|E
2500|$|Hence [...] {{gives an}} {{estimate}} of the population variance that is biased by a factor of [...] For this reason, [...] {{is referred to as the}} biased <b>sample</b> <b>variance.</b> Correcting for this bias yields the <b>unbiased</b> <b>sample</b> variance: ...|$|R
5000|$|For the sequel, use the <b>sample</b> mean:and the (<b>unbiased)</b> <b>sample</b> variance: ...|$|R
40|$|Abstract — <b>Unbiased</b> <b>sampling</b> {{of online}} social {{networks}} (OSNs) {{makes it possible}} to get accurate statistical properties of large-scale OSNs. However, the most used sampling methods, Breadth-First-Search (BFS) and Greedy, are known to be biased towards high-degree nodes, yielding inaccurate statistical results. To give a general requirement for <b>unbiased</b> <b>sampling,</b> we model the crawling process as a Markov Chain and deduce a necessary and sufficient condition, which enables us to design various efficient <b>unbiased</b> <b>sampling</b> methods. To the best of our knowledge, we are among the first to give such a condition. Metropolis-Hastings Random Walk (MHRW) is an example which satisfies the condition. However, walkers in MHRW may stay at some low-degree nodes for a long time, resulting considerable self-loops on these nodes, which adversely affect the crawling efficiency. Based on the condition, a new <b>unbiased</b> <b>sampling</b> method, called USRS, is proposed to reduce the probabilities of self-loops. We use the dataset of Renren, the largest OSN in China, to evaluate the performance of USRS. The results have demonstrated that USRS generates <b>unbiased</b> <b>samples</b> with low self-loop probabilities, and achieves higher crawling efficiency. I...|$|R
5000|$|This is {{unbiased}} (its {{expected value}} is [...] ), hence {{also called the}} <b>unbiased</b> <b>sample</b> <b>variance,</b> and its MSE is ...|$|E
5000|$|For {{a normal}} {{distribution}} with unknown mean and variance, the sample mean and (<b>unbiased)</b> <b>sample</b> <b>variance</b> are the MVUEs {{for the population}} mean and population variance.|$|E
50|$|Consider now a {{function}} of the unknown parameter: an estimator is a statistic used to estimate such function. Commonly used estimators include sample mean, <b>unbiased</b> <b>sample</b> <b>variance</b> and sample covariance.|$|E
40|$|Microblogging services, such as Twitter, {{are among}} the most {{important}} online social networks(OSNs). Different from OSNs such as Facebook, the topology of microblogging service is a directed graph instead of an undirected graph. Recently, due to the explosive increase of population size, graph sampling has started to {{play a critical role in}} measurement and characterization studies of such OSNs. However, previous studies have only focused on the <b>unbiased</b> <b>sampling</b> of undirected social graphs. In this paper, we study the <b>unbiased</b> <b>sampling</b> algorithm for directed social graphs. Based on the traditional Metropolis-Hasting Random Walk (MHRW) algorithm, we propose an <b>unbiased</b> <b>sampling</b> method for directed social graphs(USDSG). Using this method, we get the first, to the best of our knowledge, <b>unbiased</b> <b>sample</b> of directed social graphs. Through extensive experiments comparing with the ”ground truth ” (UNI, obtained through uniform sampling of directed graph nodes), we show that our method can achieve excellent performance in directed graph sampling and the error to UNI is less than 10 %...|$|R
5000|$|The biased {{weighted}} <b>sample</b> <b>variance</b> [...] {{is defined}} similarly {{to the normal}} biased <b>sample</b> <b>variance</b> : ...|$|R
5000|$|The {{classifier}} {{created from}} the training set using a Gaussian distribution assumption would be (given <b>variances</b> are <b>unbiased</b> <b>sample</b> variances): ...|$|R
50|$|The <b>unbiased</b> <b>sample</b> <b>variance</b> is a U-statistic for the {{function}} ƒ(y1, y2) = (y1 − y2)2/2, {{meaning that it}} is obtained by averaging a 2-sample statistic over 2-element subsets of the population.|$|E
5000|$|... where [...] is {{the sample}} mean and [...] is the <b>unbiased</b> <b>sample</b> <b>variance.</b> Since {{the right hand}} side of the second {{equality}} exactly matches the characterization of a noncentral t-distribution as described above, T has a noncentral t-distribution with n−1 degrees of freedom and noncentrality parameter [...]|$|E
5000|$|An {{unbiased}} estimator for the variance {{is given by}} applying Bessel's correction, using N − 1 instead of N to yield the <b>unbiased</b> <b>sample</b> <b>variance,</b> denoted s2:This estimator is unbiased if the variance exists and the sample values are drawn independently with replacement. N − 1 corresponds {{to the number of}} degrees of freedom in the vector of deviations from the mean, ...|$|E
30|$|F = S_x^ 2 /S_Y^ 2; the F-ratio, where S_x^ 2  = larger <b>sample</b> <b>variance</b> and S_y^ 2  = smaller <b>sample</b> <b>variance.</b>|$|R
50|$|This {{effectively}} {{proves the}} use of the divisor n &minus; 1 in the calculation of an <b>unbiased</b> <b>sample</b> estimate of &sigma;2.|$|R
40|$|Stability of the {{estimator}} of <b>sampling</b> <b>variance</b> is {{very important}} in using the estimator for estimation of <b>sampling</b> <b>variance.</b> In this paper the stability of the estimator of <b>sampling</b> <b>variance</b> of Modified Murthy (1957) estimator given by Shahbaz (2004) has been carried out by using the super population model...|$|R
50|$|Firstly, if the omniscient mean {{is unknown}} (and is {{computed}} as the sample mean), then the sample variance is a biased estimator: it underestimates the variance {{by a factor}} of (n − 1) / n; correcting by this factor (dividing by n − 1 instead of n) is called Bessel's correction. The resulting estimator is unbiased, and is called the (corrected) sample variance or <b>unbiased</b> <b>sample</b> <b>variance.</b> For example, when n = 1 the variance of a single observation about the sample mean (itself) is obviously zero regardless of the population variance. If the mean is determined in some other way than from the same samples used to estimate the variance then this bias does not arise and the variance can safely be estimated as that of the samples about the (independently known) mean.|$|E
50|$|Note that, when a {{transformation}} {{is applied to}} a mean-unbiased estimator, the result {{need not be a}} mean-unbiased estimator of its corresponding population statistic. By Jensen's inequality, a convex function as transformation will introduce positive bias, while a concave function will introduce negative bias, and a function of mixed convexity may introduce bias in either direction, depending on the specific function and distribution. That is, for a non-linear function f and a mean-unbiased estimator U of a parameter p, the composite estimator f(U) need not be a mean-unbiased estimator of f(p). For example, the square root of the unbiased estimator of the population variance is not a mean-unbiased estimator of the population standard deviation: the square root of the <b>unbiased</b> <b>sample</b> <b>variance,</b> the corrected sample standard deviation, is biased. The bias depends both on the sampling distribution of the estimator and on the transform, and can be quite involved to calculate - see unbiased estimation of standard deviation for a discussion in this case.|$|E
50|$|An <b>unbiased</b> (representative) <b>sample</b> {{is a set}} {{of objects}} chosen from a {{complete}} sample using a selection process that does not depend on the properties of the objects. For example, an <b>unbiased</b> <b>sample</b> of Australian men taller than 2m might consist of a randomly sampled subset of 1% of Australian males taller than 2m. But one chosen from the electoral register might not be unbiased since, for example, males aged under 18 will not be on the electoral register. In an astronomical context, an <b>unbiased</b> <b>sample</b> might consist of that fraction of a complete sample for which data are available, provided the data availability is not biased by individual source properties.|$|R
40|$|Motivated by {{steady-state}} simulation experiments, {{we consider}} the problem of estimating the marginal variance of a stationary time series. The usual estimator, the <b>sample</b> <b>variance</b> is biased for autocorrelated data. To reduce bias, other authors have suggested interlaced estimators. These estimators which like the <b>sample</b> <b>variance</b> are sums of squares are a generalization of the <b>sample</b> <b>variance</b> and a special case of quadratic forms. We show that, despite their smaller bias interlaced estimators have larger mean squared error than the <b>sample</b> <b>variance.</b> In addition we show that general quadratic forms provide little statistical advantage over the computationally less expensive sums-of-squares estimators. We conclude that the <b>sample</b> <b>variance</b> should he used in practice. 1...|$|R
50|$|Then our {{estimate}} for the <b>sampling</b> <b>variance</b> of the statistic {{is the average}} of (ai &minus; a)2. This is (at least in the ideal case) an unbiased estimate of the <b>sampling</b> <b>variance.</b>|$|R
40|$|Using <b>sample</b> <b>variances</b> for {{estimating}} a {{variance function}} is intuitively more appealing than using residuals. Main advantage of <b>sample</b> <b>variances</b> over residuals {{is that they}} are robust to misspecification of the mean function. However, due to the replication requirement neither standard response surface designs nor small designs generated by design construction algorithms can be used to estimate the variance by means of <b>sample</b> <b>variances.</b> Based on maximum likelihood and weighted least squares estimation, two alternative approaches for the construction of optimal designs for variance function estimation with <b>sample</b> <b>variances</b> are proposed. A generic exchange algorithm and computational results are presented. Irrespective of the link function between the variance and the linear predictor, the algorithm serves as a useful tool to construct tailor-made designs for variance function estimation by means of <b>sample</b> <b>variances.</b> status: publishe...|$|R
30|$|We first {{compared}} the relative {{size of the}} two variances using an F-ratio with {{the largest of the}} two <b>sample</b> <b>variances</b> as numerator and the smaller of the two <b>sample</b> <b>variances</b> as denominator.|$|R
25|$|For non-normal <b>samples,</b> the <b>variance</b> of the <b>sample</b> <b>variance</b> {{depends on}} the kurtosis; for details, please see variance.|$|R
40|$|Avian {{biologists}} routinely estimate <b>sampling</b> <b>variance</b> for parameter estimates such as daily nest survival, fecundity, annual survival, and density. However, many biologists are {{not certain}} of methods to derive <b>sampling</b> <b>variance</b> for parameters when survival rates change temporal scales. Similar methods {{are needed to}} obtain <b>sampling</b> <b>variance</b> when biologists combine parameter estimates to calculate an indirect demographic parameter, such as population growth rate. The delta method is a useful technique for approximating <b>sampling</b> <b>variance</b> when the desired demographic parameter {{is a function of}} at least one other demographic parameter. However, the delta method is rarely taught in most graduate-level biology or ecology courses, and application of this method may be discouraged by seemingly daunting formulas in reference books. Here, I provide five examples of <b>sampling</b> <b>variance</b> approximations for common situations encountered by avian ecologists, with step-by-step explanations of the equations involved...|$|R
40|$|The basic {{formula to}} {{calculate}} <b>sample</b> <b>variance</b> {{is based on}} the sum of squared differences from mean. From computational perspective, mean calculation is nondesired as it can introduce computing errors. Previous researches have proposed to use weighted formula of the successive differences to calculate <b>sample</b> <b>variance</b> to avoid mean calculation. But their weighted formula is not in a unified format {{in the sense that it}} has to be represented as two formulas. This paper proposes a unified weight formula for <b>sample</b> <b>variance</b> calculation from weighted successive differences. A proof is provided to show that <b>sample</b> <b>variance</b> calculated using the proposed unified weighted formula is mathematically equivalent to the basic definition...|$|R
5000|$|It is {{sometimes}} used, incorrectly, to mean <b>sample</b> <b>variance</b> - {{the difference between}} different finite samples of the same parent population. Such differences follow a Poissonian distribution, {{and in this case}} the term <b>sample</b> <b>variance</b> should be used instead.|$|R
40|$|In this paper, {{we present}} a new {{technique}} to generate <b>unbiased</b> <b>samples</b> on isosurfaces. An isosurface, F(x,y,z) = c, of a function, F, is implicitly defined by trilinear interpolation of background grid points. The key idea of our approach is that of treating the isosurface within a grid cell as a graph (height) function {{in one of the}} three coordinate axis directions, restricted to where the slope is not too high, and integrating / sampling from each of these three. We use this <b>unbiased</b> <b>sampling</b> algorithm for applications in Monte Carlo integration, Poisson-disk sampling, and isosurface meshing...|$|R
