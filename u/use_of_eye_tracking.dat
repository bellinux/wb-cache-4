69|10000|Public
40|$|This paper {{studies the}} <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> in a First-Person Shooter (FPS) {{game as a}} {{mechanism}} to (1) control {{the attention of the}} player's avatar according to the attention deployed by the player and (2) guide the gameplay and game's procedural content generation, accordingly. This results in a more natural <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> in comparison to a use in which the eye tracker directly substitutes control input devices, such as gamepads. The study was conducted on a custom endless runner FPS, Zombie Runner, using an affordable eye tracker. Evaluation sessions showed that the proposed <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> provides a more challenging and immersive experience to the player, when compared to its absence. However, a strong correlation between eye tracker calibration problems and player's overall experience was found. This means that eye tracking technology still needs to evolve but also means that once technology gets mature enough players are expected to benefit greatly from the inclusion of eye tracking in their gaming experience. Comment: This article is an extended version of the published poster paper "Gaze-Oriented Gameplay in First-Person Shooter Games" (2017...|$|E
40|$|Objective: The aims of this {{quasi-experimental}} before-and-after study were to first {{determine whether the}} <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> technology combined with video debriefing techniques {{has the potential to}} improve the quality of feedback and enhance situation awareness (SA) in simulated settings and second to determine students 2 ̆ 7 satisfaction towards simulated learning...|$|E
40|$|Van Mierlo, C. M. (2010, 15 November and 2 December). Eye tracking: Applications within {{cognitive}} science. Workshop {{given at}} the Open University of the Netherlands, Heerlen, The Netherlands. Detailed examples of the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> within the area of Visual Search in Cognitive Psychology. Discussion of the methods used, {{the advantages and disadvantages}} of using eye tracking in your studies and possible pitfalls you might encounter...|$|E
40|$|AbstractThe {{clinical}} vision examination routinely {{includes an}} evaluation of ocular motor function. In a number of diverse situations, thorough objective recording <b>of</b> <b>eye</b> movements is warranted, <b>using</b> any <b>of</b> a variety of eye-tracking technologies that are available currently to clinicians. Here we review the clinical <b>uses</b> <b>of</b> <b>eye</b> <b>tracking,</b> with both an historical and contemporary view. We also consider several new imaging technologies that are becoming available in clinics and include inbuilt eye-tracking capability. These highly sensitive eye trackers should be useful for evaluating a variety of subtle, but important, oculomotor signs and disorders...|$|R
40|$|In {{this paper}} we present the {{application}} <b>of</b> an <b>eye</b> tracker as an innovative real-time virtual environment interaction device, that enables {{a new level}} of control, and forms a base for many realistic sight-dependent visual effects. Current use and main stream <b>of</b> research regarding <b>eye</b> <b>tracking</b> technology aims at marketing and usability testing, as well as help for people who suffer from manual disabilities. The goal of our work is to spread interest in other <b>uses</b> <b>of</b> this advanced and impressive technology. Apart from the discussion about possible <b>uses</b> <b>of</b> <b>eye</b> <b>tracking</b> in the computer-generated worlds, we provide a complete case study of a depth of field post processing effect for realtime graphics, that relates on the user’s gaze point...|$|R
40|$|<b>Eye</b> <b>Tracking</b> for User Experience Design {{explores the}} many {{applications}} <b>of</b> <b>eye</b> <b>tracking</b> {{to better understand}} how users view and interact with technology. Ten leading experts in <b>eye</b> <b>tracking</b> discuss how they {{have taken advantage of}} this new technology to understand, design, and evaluate user experience. Real-world stories are included from these experts who have used <b>eye</b> <b>tracking</b> during the design and development of products ranging from information websites to immersive games. They also explore recent advances in the technology which tracks how users interact with mobile devices, large-screen displays and video game consoles. Methods for combining <b>eye</b> <b>tracking</b> with other research techniques for a more holistic understanding of the user experience are discussed. This is an invaluable resource to those who want to learn how <b>eye</b> <b>tracking</b> can be used to better understand and design for their users. * Includes highly relevant examples and information for those who perform user research and design interactive experiences* Written by numerous experts in user experience and <b>eye</b> <b>tracking.</b> * Highly relevant to anyone interested in <b>eye</b> <b>tracking</b> & UX design * Features contemporary <b>eye</b> <b>tracking</b> research emphasizing the latest <b>uses</b> <b>of</b> <b>eye</b> <b>tracking</b> technology in the user experience industry...|$|R
40|$|This article {{surveys the}} <b>use</b> <b>of</b> <b>eye</b> <b>{{tracking}}</b> in investiga-tions of online search. Three eye tracking experiments that we undertook are discussed and compared to additional {{work in this}} area, revealing recurring behaviors and trends. The first two studies are described in greater detail in Granka, Joachims, & Gay (2004), Lorigo et al. (2006), and Pan et al. (2007), and the third study is de-scribed {{for the first time}} in this article. These studies reveal how users view the ranked results on a search engine results page (SERP), the relationship between the search result abstracts viewed and those clicked on, and whether gender, search task, or search engine influence these behaviors. In addition, we discuss a key challenge that arose in all three studies that applies to the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> in studying online behaviors which is due to the limited support for analyzing scanpaths, or sequences of eye fixations. To meet this challenge, we present a preliminary approach that involves a graphical visualization to compare a path with a group of paths. We conclude by summarizing our findings and discussing future work in further understanding online search be-havior with the help of eye tracking...|$|E
40|$|In {{everyday}} {{and learning}} tasks, the eyes have, firstly, {{the roles of}} locating and recognizing objects and then, secondly, directing the actions {{to make use of}} them (Land & Tatler 2009). The <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> can reveal important aspects about students’ learning processes. Because eye tracking provides insights into the allocation of visual attention, it is very suited to study differences in learners’ attentional processes. In this section of the book, the contributions focus on the visual processes that occur when participants are performing a task...|$|E
40|$|The {{possibility}} to track human eye gaze is not new. Different eye tracking devices {{have been available}} for several years. The technology has for instance been used in psychological research, usability evaluation and in equipment for disabled people. The devices have often required the user to utilize a chinrest, a bite board or other cumbersome equipment. Hence, the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> has been limited to restricted environments. In recent years, new non-intrusive eye tracking technology has become available. This {{has made it possible}} to use eye tracking in new, natural environments. The aim {{of this study was to}} evaluate the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> in computer games. A literature study was made to gather information about eye tracker systems, existing eye gaze interfaces and computer games. The analysis phase included interviews with people working with human-computer interaction and game development, a focus group session and an evaluation of computer games. The result from the analysis constituted of a summary of interaction sequences, presumable suitable to control with the eyes. Three different prototypes of eye controlled computer games were developed. The first was a shoot’em up game where the player aimed with his eyes to shoot monsters that appeared in random places. The two other prototypes were developed with the Half Life Softwar...|$|E
5000|$|The 1980s {{also saw}} the birth <b>of</b> <b>using</b> <b>eye</b> <b>tracking</b> to answer {{questions}} related to human-computer interaction. Specifically, researchers investigated how users search for commands in computer menus. [...] Additionally, computers allowed researchers to use eye-tracking results in real time, primarily to help disabled users.|$|R
40|$|We {{present a}} {{technique}} for switching between active applications by <b>using</b> a combination <b>of</b> keyboard (or any other trigger) and eye gaze. In particular, our approach combines the <b>use</b> <b>of</b> a two-dimensional layout visualization for showing the user all open applications and the <b>use</b> <b>of</b> <b>eye</b> gaze <b>tracking</b> for selecting the desired window. Our {{studies show that}} this combination of gaze and the visual representation of active tasks allows users to switch between applications quickly and naturally. Users strongly preferred this technique of switching between applications compared to other alternatives...|$|R
40|$|In this paper, we {{describe}} the <b>use</b> <b>of</b> <b>eye</b> gaze <b>tracking</b> and trajectory analysis in the testing {{of the performance of}} input devices for cursor control in Graphical User Interfaces (GUIs). By closely studying the behavior of test subjects performing pointing tasks, we can gain a more detailed understanding of the device design factors that may influence the overall performance with these devices. Our Results show there are many patterns <b>of</b> hand <b>eye</b> coordination at the computer interface which differ from patterns found in direct hand pointing at physical targets (Byrne, Anderson, Douglass, & Matessa, 1999). Keywords <b>Eye</b> <b>tracking,</b> gaze, hand <b>eye</b> coordination, pointing, target selection, mouse, touchpad, pointing stick, motor control 1...|$|R
30|$|Eye {{tracking}} {{is used in}} interface usability studies, advertising as well as developmental psychology. As {{regards to}} ITSs, the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> to increase student model bandwidth for educational purposes was first discussed in Gluck et al. (2000). Eye tracking was also used {{as a form of}} input (Wang et al. 2006), by allowing students to select a topic to study by simply looking at a portion of the screen for a pre-specified time or answer questions using eye movements. Other researchers used eye-tracking data to analyse how students interpret open learner models (Bull et al. 2007; Mathews et al. 2012).|$|E
40|$|In this contribution, {{we propose}} the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> {{technology}} to support video analysts. To reduce workload, we implemented two new interaction techniques {{as a substitute}} for mouse pointing: gaze-based selection of a video of interest from a set of video streams, and gaze-based selection of moving targets in videos. First results show that the multi-modal interaction technique gaze + key press allows the selection of fast moving objects in a more effective way. Moreover, we discuss further application possibilities like gaze behavior analysis to measure the analyst's fatigue, or analysis of the gaze behavior of expert analysts to instruct novices...|$|E
40|$|The <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> in {{usability}} {{research has}} increased in the past years. The work {{presented in this paper}} reports on an empirical study that took place at the University of Aveiro. 58 participants were asked to read news on the SAPO homepage while their eye movements and mouse interaction were recorded. An analysis of their visual and interactive behavior on the news areas of interest was made as well as other areas of the homepage. Acquired results were considered, and reinforced interaction design criteria used in the reconceptualization of the actual SAPO homepage. SAPO/UA R&D Lab...|$|E
40|$|In {{this paper}} we {{introduce}} {{a method for}} acceleration of the real time ray tracing by <b>using</b> characteristic traits <b>of</b> visual perception. Ray tracing is a demanding rendering technique which is much slower than currently dominating scanline methods. Performance hit especially arise when we <b>use</b> huge amount <b>of</b> samples for anti-aliasing or other sample-based effects. We show how to decreases number of rays by increasing the perceptual size of selected pixels by <b>using</b> combination <b>of</b> <b>eye</b> <b>tracking</b> and the human gaze-dependent contrast sensitivity. Our study shows that num-ber of processed pixels can be reduced three times without perceptually noticeable quality loss. As a result, we can greatly increase performance of ray tracing. ...|$|R
40|$|The {{theoretical}} {{part of this}} thesis deals with the description of sensory processes, human eye and visual perception. The following are traffic participant and get data <b>using</b> the method <b>of</b> <b>eye</b> <b>tracking.</b> The practical part consisted {{in the evaluation of}} driving video recordings describing the driver's observation. The frequency and length of the pedestrian observation was evaluated, and the graphical processing was performed depending on whether the pedestrian actually crossed the road or simulated walking {{on the side of the}} roadway...|$|R
40|$|We {{investigate}} gaze {{patterns and}} other nonverbal behavior that people use when providing and receiving explanations of complex healthcare documents, and <b>use</b> a model <b>of</b> this behavior {{as the basis}} of a system that provides automated, proactive assistance. We present the results of the human analog study along with results from a preliminary evaluation of the automated system. We also demonstrate the feasibility <b>of</b> <b>using</b> <b>eye</b> <b>tracking</b> to automatically assess the health literacy of people reading healthcare documents...|$|R
40|$|This article {{investigates the}} {{potential}} <b>use</b> <b>of</b> <b>Eye</b> <b>Tracking</b> as a neuromarketing tool {{and its potential}} for marketing in general. We sought to identify {{some of the main}} applications within the mainstream of marketing. The objective of this research was achieved by means of a conceptual literature review. The results of our research indicate important potential uses for Eye Tracking in practical marketing applications, such as brand equity, segmentation, new product development, pricing decisions, place decisions, promotion decisions, and social marketing studies. It is believed that in the near future, neuromarketing tools such as Eye Tracking will be part of mainstream marketing studies...|$|E
30|$|We have {{categorised}} related studies {{under three}} categories: eye tracking for user classification, eye tracking and attention/affective state and eye tracking and graphics/visualisations. In the first category, eye tracking {{is used to}} directly augment the student model or understand different groups of students. We then outline the research work involving the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> to understand or predict the students’ affective state, in particular to determine when students are struggling. A review of the research into using eye tracking {{to learn more about}} students’ behaviour when viewing visualisations and graphics follows, and a summary of the findings of the related work concludes this section.|$|E
40|$|Interactive {{evolution}} {{has shown the}} potential to create amazing and complex forms in both 2 -D and 3 -D settings. However, the algorithm is slow and users quickly become fatigued. We propose that the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> for interactive evolution systems will both reduce user fatigue and improve evolutionary success. We describe a systematic method for testing the hypothesis that eye tracking driven interactive evolution will be a more successful and easierto-use design method than traditional interactive evolution methods driven by mouse clicks. We provide preliminary results that support the possibility of this proposal, and lay out future work to investigate these advantages in extensive clinical trials. 1...|$|E
40|$|We {{propose a}} head-free, easy-setup gaze {{tracking}} system {{designed for a}} gaze-based Human-Computer Interaction. Our system enables the user {{to interact with the}} computer soon after catching the user's eye blinks. The user can move his/her head freely since the system keeps <b>tracking</b> the user's <b>eye.</b> In addition, our system only needs a 10 second calibration procedure at the very first time <b>of</b> <b>use.</b> An <b>eye</b> <b>tracking</b> method based on our unique eye blink detection and a sophisticated gaze estimation method using the geometrical eyeball model realize these advantages...|$|R
40|$|In some investigative and {{interrogative}} contexts, {{the investigator}} {{is seeking to}} identify the location of an object (e. g. implanted bomb) which is known to a given subject (e. g. a terrorist). In this paper, we present a non-intrusive methodology for uncovering the loci of a concealed object by analyzing the subject's eye movements. <b>Using</b> a combination <b>of</b> <b>eye</b> <b>tracking,</b> psychological manipulation and a search algorithm, we have performed two experiments. In the first experiment, we have gained 58 % hit rate in identifying {{the location of the}} concealed object and in the second experiment 56 % hit rate. The pros and cons of the methodology for forensic investigation are discussed...|$|R
40|$|The {{research}} group from Humanities laboratory at Lund University, Sweden, presents three strands {{of research on}} language and cognition where eye-tracking methodology {{has been used as}} a window on the mind. The paper includes: (1) <b>eye</b> <b>tracking</b> studies on picture viewing and picture description showing the dynamics of how speakers perceive, conceptualize and spontaneously describe complex visual scenes on higher levels of discourse, (2) studies <b>using</b> a combination <b>of</b> <b>eye</b> <b>tracking</b> and spoken scene descriptions to study mental imagery and to track the ability of “seeing something in the mind’s eye”, and (3) <b>eye</b> <b>tracking</b> studies conducted in order to study ’thinking for speaking’ and linguistic diversity by investigating language-specific cognitive effects. The paper ends with a visionary outlook for future applications <b>of</b> <b>eye</b> <b>tracking</b> methodology in the study of language and cognition...|$|R
40|$|The article aims {{to present}} {{experimental}} protocol for investigation of visual cognitive function {{in children and adolescents}} with autism spectrum disorders. Description of experimental design is introduced by theoretical review of visual attention, perception and visual-motor control development in children with idiopathic autism and those with Fragile X mental retardation syndrome. Research method presented in the article is based on recent studies of visual cognitive function development under normal and pathological condition. The protocol includes three experimental paradigms: “antisaccade test”, “big/ figures”, and “photos test” performed by making <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> recording. This work was supported by grant RFBR 14 - 06 - 3128...|$|E
40|$|The {{research}} {{presented in}} this thesis concerns the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> to both enhance and understand avatar-mediated communication (AMC) performed by users of immersive collaborative virtual environment (ICVE) systems. AMC, in which users are embodied by graphical humanoids within a shared virtual environment (VE), is rapidly emerging as a prevalent and popular form of remote interaction. However, compared with video-mediated communication (VMC), which transmits interactants’ actual appearance and behaviour, AMC fails to capture, transmit, and display many channels of nonverbal communication (NVC). This is a significant hindrance to the medium’s ability to support rich interpersonal telecommunication. In particular, oculesics (the communicative properties of the eyes), including gaze, blinking, and pupil dilation, are central nonverbal cues during unmediated social interaction. This research explores the interactive and analytical application of eye tracking to drive the oculesic animation of avatars during real-time communication, and as the primary method of experimental data collection and analysis, respectively. Three distinct but interrelated questions are addressed. First, the thesis considers {{the degree to which}} quality of communication may be improved through the <b>use</b> <b>of</b> <b>eye</b> <b>tracking,</b> to increase the nonverbal, oculesic, information transmitted during AMC. Second, the research asks whether users engaged in AMC behave and respond in a socially realistic manner in comparison with VMC. Finally, the degree to which behavioural simulations of oculesics can both enhance the realism of virtual humanoids, and complement tracked behaviour in AMC, is considered. These research questions were investigated over a series of telecommunication experiments investigating scenarios common to computer supported cooperative work (CSCW), and a further series of experiments investigating behavioural modelling for virtual humanoids. The first, exploratory, telecommunication experiment compared AMC with VMC in a three-party conversational scenario. Results indicated that users employ gaze similarly when faced with avatar and video representations of fellow interactants, and demonstrated how interaction is influenced by the technical characteristics and limitations of a medium. The second telecommunication experiment investigated the impact of varying methods of avatar gaze control on quality of communication during object-focused multiparty AMC. The main finding of the experiment was that quality of communication is reduced when avatars demonstrate misleading gaze behaviour. The final telecommunication study investigated truthful and deceptive dyadic interaction in AMC and VMC over two closely-related experiments. Results from the first experiment indicated that users demonstrate similar oculesic behaviour and response in both AMC and VMC, but that psychological arousal is greater following video-based interaction. Results from the second experiment found that the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> to drive the oculesic behaviour of avatars during AMC increased the richness of NVC to the extent that more accurate estimation of embodied users’ states of veracity was enabled. Rather than directly investigating AMC, the second series of experiments addressed behavioural modelling of oculesics for virtual humanoids. Results from the these experiments indicated that oculesic characteristics are highly influential to the perceived realism of virtual humanoids, and that behavioural models are able to complement the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> in AMC. The research {{presented in this}} thesis explores AMC and eye tracking over a range of collaborative and perceptual studies. The overall conclusion is that eye tracking is able to enhance AMC towards a richer medium for interpersonal telecommunication, and that users’ behaviour in AMC is no less socially ‘real’ than that demonstrated in VMC. However, there are distinct differences between the two communication mediums, and the importance of matching the characteristics of a planned communication with those of the medium itself is critical...|$|E
40|$|Click-based {{graphical}} passwords {{have been}} proposed as alternatives to text-based passwords, despite being potentially vulnerable to shoulder-surfing, where an attacker can learn passwords by watching or recording users as they log in. Cued Gaze-Points (CGP) is a graphical password system which defends against such attacks by using eye-gaze password input, instead of mouse-clicks. A first user study revealed that CGP’s unique <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> required special techniques to improve gaze precision. In this paper, we present two enhancements that we developed and tested: a nearest-neighbour gaze-point aggregation algorithm and a 1 -point calibration before each password entry. We found that these enhancements made a substantial improvement to users ’ gaze accuracy and system usability...|$|E
40|$|The {{aim of the}} Integrated Navigation System (INS) on a ship bridge {{should be}} to provide the {{navigator}} with added value and aid in the complex task of conducting a safe and efficient passage in high speeds in demanding waters. This article presents a method for analysing <b>eye</b> <b>tracking</b> data to reveal sub-optimal design in the bridge layout and in the software graphical user interface on a maritime navigation display. The analysis <b>of</b> <b>eye</b> <b>tracking</b> data with focus on scan path events indicates sub-optimal design, and the paper provides suggestions for improvement in design and interface. Pros and cons <b>of</b> <b>using</b> <b>Eye</b> <b>Tracking</b> Glasses in a maritime environment is presented. The importance of not affecting the normal behaviour of the navigator by collecting data is stressed, and also how the software should provide good visualisation and interpretation <b>of</b> the <b>eye</b> <b>tracking</b> data...|$|R
40|$|Commercial head-mounted eye {{trackers}} {{provide useful}} fea-tures to customers in industry and research but are expensive {{and rely on}} closed source hardware and software. This lim-its the application areas and <b>use</b> <b>of</b> mobile <b>eye</b> <b>tracking</b> to expert users and inhibits user-driven development, customisa-tion, and extension. In this paper we present Pupil – an acces-sible, affordable, and extensible open source platform for mo-bile <b>eye</b> <b>tracking</b> and gaze-based interaction. Pupil comprises 1) a light-weight headset with high-resolution cameras, 2) an open source software framework for mobile <b>eye</b> <b>tracking,</b> as well as 3) a graphical user interface (GUI) to playback and visualize video and gaze data. Pupil features high-resolution scene and eye cameras for monocular and binocular gaze esti-mation. The software and GUI are platform-independent and include state-of-the-art algorithms for real-time pupil detec-tion and tracking, calibration, and accurate gaze estimation. Results of a performance evaluation show that Pupil can pro-vide an average gaze estimation accuracy of 0. 6 degree of visual angle (0. 08 degree precision) with a latency of the pro-cessing pipeline of only 0. 045 seconds...|$|R
40|$|Cognitive load is {{concerned}} with the amount of mental effort imposed on working memory at an instant of time. Changes in cognitive load cause very small dilations of the pupils. The aim {{of this paper is to}} examine the role of cog-nitive load while learning to program through the <b>use</b> <b>of</b> remote <b>eye</b> <b>tracking.</b> Although numerous studies have been carried out to evaluate cognitive load using this approach, very few can be found that have focused on programming comprehension especially with students learning to program for the first time. This study will develop a suite of programming tasks, designed to induce different levels of cognitive load (low to high). The programming tasks will be completed by novice programmers whilst a remote <b>eye</b> <b>tracking</b> system monitors pupil dilation. It is hypothesised that, once environmental factors (ambient light etc) have been controlled, programming tasks designed to induce a high level of cognitive load will result in dilations of the pupils, whilst easier tasks will not result in such a change...|$|R
40|$|Due to {{the rapidly}} growing {{of the amount of}} information, a {{stronger}} need emerges for efficient and flexible strategies for personalisation of the educational content. E-learning systems are very helpful for learners, however, people differ in knowledge level, learning styles and may seek for different information when they access web based e-learning systems. Therefore, content adapted to the user’s needs should be supported by the e-learning systems. In this paper we introduce a new e-learning environment that makes <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> mechanism to follow learner interest in certain topics and to perform content personalisation. The framework of the e-learning system is presented. Furthermore, an exemplification of the e-learning environment is provided...|$|E
40|$|In {{this paper}} we {{describe}} the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> to quantitatively evaluate and analyse the variations in data interpretation performed by various geoscientists, measuring this against their ability to spot geological targets. We also describe an approach to evaluate the impact data preprocessing (i. e. enhancement) has on one’s ability to perform the interpretation task. We adapted a mobile eye tracker to enable it to accurately map the point of gaze to the actual image coordinate instead of the forward facing eye tracker camera allowing the user to move their head as they view. Several visual interpretation tasks were performed by six geoscientists {{and the results are}} described in this paper...|$|E
40|$|In {{a virtual}} {{learning}} environment, learners can lose motivation and concentration easily, {{especially in a}} platform that isnot tailored to their needs. Our research is based on studying learner’s behavior on an online learning platform to create asystem able to clustering learners based on their behavior, and adapting educational content to their needs. Eye tracking {{is a set of}} techniques for recording eye movements. This technology is used to measure eye positions and eyemovement for research in psychology, psycholinguistics, ergonomics, e-learning and pre-testing of advertising. This paper introduces the <b>use</b> <b>of</b> <b>eye</b> <b>tracking</b> technology to track and analyze the learners' behavior and emotion on e-learning platform like level of attention, stress, relaxation, problem solving and tiredness...|$|E
40|$|<b>Eye</b> <b>tracking</b> is a {{research}} tool that has great potential for advancing {{our understanding of how}} we watch movies. Questions such as how differences in the movie influences where we look and how individual differences between viewers alters what we see can be operationalised and empirically tested <b>using</b> a variety <b>of</b> <b>eye</b> <b>tracking</b> measures. This special issue collects together an inspiring interdisciplinary range of opinions on what <b>eye</b> <b>tracking</b> can (and cannot) bring to film and television studies and practice. In this article I will reflect on each of these contributions with specific focus on three aspects: how subtitling and digital effects can reinvigorate visual attention, how audio can guide and alter our visual experience of film, and how methodological, theoretical and statistical considerations are paramount when trying to derive conclusions from eyetracking data...|$|R
40|$|<b>Eye</b> <b>tracking</b> gives {{communication}} scholars {{the opportunity}} to move beyond self-reported measures by examining more precisely how much visual {{attention is paid to}} information. However, we lack insight into how eye-tracking data is used in communication research. This literature review provides an overview <b>of</b> how <b>eye</b> <b>tracking</b> is <b>used</b> in communication research by examining published articles from the top- 25 ranked communication journals between 2005 and 2015. Our results showed that most eye-tracking research was employed in the field of advertising. Furthermore, most studies used <b>eye</b> <b>tracking</b> to measure (visual) attention and used this as the study’s dependent variable. A wide variety of eye-tracking measures were reported, including fixation time, fixation count, and visual shifts, and a wide variety of eye-tracking devices were used. Our results highlight opportunities for using <b>eye</b> <b>tracking</b> as well as identify other ways <b>of</b> <b>using</b> <b>eye</b> <b>tracking</b> to maximize its potential in communication research...|$|R
40|$|Abstract—Visual {{attention}} allows user {{to select}} {{the most relevant information}} to ongoing behaviour. This paper presents a study on; i) the performance of people measurements, ii) accurateness of people measurement of the peaks that correspond to chemical quantities from the Magnetic Resonance Spectroscopy (MRS) graphs and iii) affects of people measurements to the algorithm-based diagnosis. Participant’s eye-movement was recorded using eye-tracker tool (Eyelink II). This experiment involves three participants for examining 20 MRS graphs to estimate the peaks of chemical quantities which indicate the abnormalities associated with Cerebellar Tumours (CT). The status of each MRS is verified by using decision algorithm. Analysis involves determination <b>of</b> humans’s <b>eye</b> movement pattern in measuring the peak of spectrograms, scan path and determining the relationship of distributions of fixation durations with the accuracy of measurement. In particular, the eye-tracking data revealed which aspects of the spectrogram received more visual attention and in what order they were viewed. This preliminary investigation provides a proof <b>of</b> concept for <b>use</b> <b>of</b> the <b>eye</b> <b>tracking</b> technology as the basis for expanded CT diagnosis. A. Background Decision algorithms are devised to assist CT diagnosis during inspecting MRS graphs. An example of an MRS graph is given in Fig. 1, showing peaks for the constituents of interest...|$|R
