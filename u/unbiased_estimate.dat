821|2033|Public
25|$|Consequently, the TMRCA {{estimated}} from {{a relatively}} small sample of viral genetic sequences is an asymptotically <b>unbiased</b> <b>estimate</b> for {{the time that the}} viral population was founded in the host population.|$|E
25|$|When only {{a sample}} of data from a {{population}} is available, the term standard deviation of the sample or sample standard deviation can refer to either the above-mentioned quantity as applied to those data or to a modified quantity that is an <b>unbiased</b> <b>estimate</b> of the population standard deviation (the standard deviation of the entire population).|$|E
2500|$|... {{but this}} is a biased estimate. Its inverse (rnbsp&+nbsp&k)/r, is an <b>unbiased</b> <b>estimate</b> of 1/p, however.|$|E
40|$|Computing {{partition}} functions, the normalizing constants {{of probability}} distributions, is often hard. Variants of importance sampling give <b>unbiased</b> <b>estimates</b> of a normalizer Z, however, <b>unbiased</b> <b>estimates</b> of the reciprocal 1 /Z {{are harder to}} obtain. <b>Unbiased</b> <b>estimates</b> of 1 /Z allow Markov chain Monte Carlo sampling of "doubly-intractable" distributions, such as the parameter posterior for Markov Random Fields or Exponential Random Graphs. We demonstrate how to construct <b>unbiased</b> <b>estimates</b> for 1 /Z given access to black-box importance sampling estimators for Z. We adapt recent work on random series truncation and Markov chain coupling, producing estimators with lower variance and {{a higher percentage of}} positive estimates than before. Our debiasing algorithms are simple to implement, and have some theoretical and empirical advantages over existing methods...|$|R
5000|$|It {{provides}} statistically <b>unbiased</b> <b>estimates</b> of the mean, proportions, and variability.|$|R
50|$|The Tobit {{procedure}} is robust to top coding, and gives <b>unbiased</b> <b>estimates.</b>|$|R
2500|$|... be an <b>unbiased</b> <b>estimate</b> of the {{variance}} from the sample. [...] It can be shown that the random variable ...|$|E
2500|$|... where k4 is {{the unique}} {{symmetric}} unbiased estimator {{of the fourth}} cumulant, k2 is the <b>unbiased</b> <b>estimate</b> of the second cumulant (identical to the <b>unbiased</b> <b>estimate</b> of the sample variance), m4 is the fourth sample moment about the mean, m2 is the second sample moment about the mean, x'i is the ith value, and [...] is the sample mean. Unfortunately, [...] is itself generally biased. For the normal distribution it is unbiased.|$|E
2500|$|For {{unbiased}} {{estimation of}} standard deviation, {{there is no}} formula that works across all distributions, unlike for mean and variance. Instead, s {{is used as a}} basis, and is scaled by a correction factor to produce an <b>unbiased</b> <b>estimate.</b> For the normal distribution, an unbiased estimator is given by s/c4, where the correction factor (which depends on N) is given in terms of the Gamma function, and equals: ...|$|E
50|$|It {{was widely}} {{believed}} {{that it was impossible to}} make <b>unbiased</b> <b>estimates</b> from snowball samples, but a variation of snowball sampling called respondent-driven samplinghas been shown to allow researchers to make asymptotically <b>unbiased</b> <b>estimates</b> from snowball samples under certain conditions. Snowball sampling and respondent-driven sampling also allows researchers to make estimates about the social network connecting the hidden population.|$|R
3000|$|... 2 will be <b>unbiased</b> <b>estimates</b> of {{the effects}} of the program if the {{treatment}} randomization was effective.|$|R
40|$|AbstractIn this paper, we derive {{the best}} linear <b>unbiased</b> <b>estimates</b> (BLEUs) and the maximum {{likelihood}} estimates (MLEs) {{of the location}} and scale parameters from the Exponentiated Pareto distribution based on progressively Type-II right censored order statistics. In addition, we use Monte-Carlo simulation method to obtain the mean square error of the best linear <b>unbiased</b> <b>estimates</b> and the maximum likelihood estimates and make comparison between them. Finally, we present numerical example...|$|R
2500|$|Planning the research, {{including}} {{finding the}} number of replicates of the study, using the following information: [...] preliminary estimates regarding the size of treatment effects, alternative hypotheses, and the estimated experimental variability. Consideration of the selection of experimental subjects and the ethics of research is necessary. Statisticians recommend that experiments compare (at least) one new treatment with a standard treatment or control, to allow an <b>unbiased</b> <b>estimate</b> {{of the difference in}} treatment effects.|$|E
2500|$|For example, {{the sample}} mean (estimator), denoted , {{can be used}} as an {{estimate}} of the mean parameter (estimand), denoted μ, of the population from which the sample was drawn. Similarly, the sample variance (estimator), denoted S2, can be used to estimate the variance parameter (estimand), denoted σ2, of the population from which the sample was drawn. (Note that the sample standard deviation (S) is not an <b>unbiased</b> <b>estimate</b> of the population standard deviation (σ): see Unbiased estimation of standard deviation.) ...|$|E
2500|$|For a {{distribution}} with unknown parameters, a direct approach to prediction is {{to estimate the}} parameters and then use the associated quantile function – for example, one could use the sample mean [...] as estimate for μ and the sample variance s2 as an estimate for σ2. Note {{that there are two}} natural choices for s2 here – dividing by [...] yields an <b>unbiased</b> <b>estimate,</b> while dividing by n yields the maximum likelihood estimator, and either might be used. One then uses the quantile function with these estimated parameters [...] to give a prediction interval.|$|E
40|$|Purpose – We {{know that}} {{estimates}} of terminal value of long-term investment horizons are biased. <b>Unbiased</b> <b>estimates</b> exist only for investment horizon of one time-period. The {{purpose of this}} paper is to suggest a method based on the arithmetic mean in order to obtain <b>unbiased</b> <b>estimates</b> for the terminal value of long-term investment horizons. Design/methodology/approach – The method used for the investigation was to employ loss functions or error statistics. Namely, the mean error, the mean absolute error, the root mean squared error, and the mean absolute percentage error was used. Findings – The suggested method produced the closest values to the actual ones than any other suggested averaging method when the authors examined ten-year investment horizons for Standard & Poor's 500 index and on Dow Jones Industrial index. Practical implications – Portfolio managers and individual investors may use this paper's suggestion if they wish to obtain <b>unbiased</b> <b>estimates</b> for investment horizons greater than one time-period. Originality/value – The suggestion to equate the time-period of the observed data to the time-period of the investment horizons is novel and useful to practitioners since it produces <b>unbiased</b> <b>estimates.</b> Arithmetic, Estimation, Geometric mean, Long-term planning, Portfolio investment...|$|R
3000|$|A key {{obstacle}} to obtaining (asymptotically) <b>unbiased</b> <b>estimates</b> of β 1 and β 2 in (1) {{is the possibility}} of measurement error in [...]...|$|R
25|$|Under the {{condition}} that the errors are uncorrelated with the predictor variables, LLSQ yields <b>unbiased</b> <b>estimates,</b> but even under that condition NLLSQ estimates are generally biased.|$|R
2500|$|This [...] {{formula is}} valid {{only if the}} eight values with which we began form the {{complete}} population. If the values instead were a random sample drawn from some large parent population (for example, they were 8 marks randomly and independently chosen from a class of 2million), then one often divides by [...] instead of [...] in the denominator of the last formula. In that case {{the result of the}} original formula would be called the sample standard deviation. Dividing by n−1 rather than by n gives an <b>unbiased</b> <b>estimate</b> of the variance of the larger parent population. This is known as Bessel's correction.|$|E
2500|$|In {{the early}} 20th century Western {{scholarly}} views of Muhammad changed, including critical views. In the 1911 Catholic Encyclopedia Gabriel Oussani states that Muhammad {{was inspired by}} an [...] "imperfect understanding" [...] of Judaism and Christianity, but that the views of Luther and those who call Muhammad a [...] "wicked impostor", a [...] "dastardly liar" [...] and a [...] "willful deceiver" [...] are an [...] "indiscriminate abuse" [...] and [...] "unsupported by facts." [...] Instead, 19th-century Western scholars such as Aloys Sprenger, Theodor Noldeke, Gustav Weil, William Muir, Sigismund Koelle, Grimme and D. S. Margoliouth [...] "give us a more correct and <b>unbiased</b> <b>estimate</b> of Muhammad's life and character, and substantially agree as to his motives, prophetic call, personal qualifications, and sincerity." ...|$|E
50|$|Suppose that {{a problem}} {{involves}} independent and identically-distributed random variables and that estimation of a certain parameter is required. Suppose that a simple <b>unbiased</b> <b>estimate</b> can be constructed based on only a few observations: this defines the basic estimator based on a given number of observations. For example, a single observation is itself an <b>unbiased</b> <b>estimate</b> of the mean {{and a pair of}} observations can be used to derive an <b>unbiased</b> <b>estimate</b> of the variance. The U-statistic based on this estimator is defined as the average (across all combinatorial selections of the given size from the full set of observations) of the basic estimator applied to the sub-samples.|$|E
40|$|The {{importance}} of measurement error {{in studies of}} asymmetry has been acknowledged for a long time. It is now common practice to acquire independent repeated measurements of trait values and to estimate the degree of measurement error relative {{to the amount of}} asymmetry. Methods also allow obtaining <b>unbiased</b> <b>estimates</b> of asymmetry, both at the population and individual level. One aspect that has been ignored is potential between-individual variation in measurement error. In this paper, I develop a new method to investigate this variation in measurement error and to generate <b>unbiased</b> <b>estimates</b> of individual asymmetries. Simulations show that variation in measurement error can indeed result in biased estimates of individual asymmetry and that the proposed method adequately provides <b>unbiased</b> <b>estimates.</b> The method is applied to two empirical datasets and shows that, at least in some traits, substantial variations in measurement occur. The limitations of the model are discussed...|$|R
40|$|Summary. Randomized {{controlled}} trials (RCTs) {{can provide}} <b>unbiased</b> <b>estimates</b> of sample average treatment effects. However, a common {{concern is that}} RCTs may fail to provide <b>unbiased</b> <b>estimates</b> of population average treatment effects. We derive the assumptions required to identify population average treatment effects from RCTs. We provide placebo tests, which formally follow from the identifying assumptions and can assess whether they hold. We offer new research designs for estimating population effects that use non-randomized studies (NRSs) to adjust the RCT data. This approach is considered in a cost-effectiveness analysis of a clinical intervention...|$|R
40|$|For Gaussian process models, {{likelihood}} based {{methods are}} {{often difficult to}} use with large irregularly spaced spatial datasets, because exact calculations of the likelihood for n observations require O(n 3) operations and O(n 2) memory. Various approximation methods {{have been developed to}} address the computational difficulties. In this paper, we propose new <b>unbiased</b> <b>estimating</b> equations based on score equation approximations that are both computationally and statistically efficient. We replace the inverse covariance matrix that appears in the score equations by a sparse matrix to approximate the quadratic forms, then set the resulting quadratic forms equal to their expected values to obtain <b>unbiased</b> <b>estimating</b> equations. The sparse matrix is constructed by a sparse inverse Cholesky approach to approximate the inverse covariance matrix. The statistical efficiency of the resulting <b>unbiased</b> <b>estimating</b> equations are evaluated both in theory and by numerical studies. Our methods are applied to nearly 90, 000 satellite-based measurements of water vapor levels over a region in the Southeast Pacific Ocean...|$|R
5000|$|The usual [...] "pooled" [...] <b>unbiased</b> <b>estimate</b> of {{the common}} {{variance}} &sigma;2 is then ...|$|E
5000|$|Computing an <b>unbiased</b> <b>estimate</b> of the {{probability}} of the training set given a hypothesis (...) is non-trivial.|$|E
50|$|The {{sample mean}} is a Fisher {{consistent}} and <b>unbiased</b> <b>estimate</b> {{of the population}} mean, but not all Fisher consistent estimates are unbiased. Suppose we observe a sample from a uniform distribution on (0,θ) and we wish to estimate θ. The sample maximum is Fisher consistent, but downwardly biased. Conversely, the sample variance is an <b>unbiased</b> <b>estimate</b> of the population variance, but is not Fisher consistent.|$|E
5000|$|Thus , and {{therefore}} [...] is an unbiased estimator {{of the population}} variance, σ2. The ratio between the biased (uncorrected) and <b>unbiased</b> <b>estimates</b> of the variance is known as Bessel's correction.|$|R
3000|$|Does either SMI or MMI {{of missing}} values on {{background}} variables lead to <b>unbiased</b> <b>estimates</b> of standard errors of subpopulation proficiency means, the mean subpopulation proficiency difference, and regression coefficients? [...]...|$|R
40|$|Natalya Verbitsky-SavitzAbstract: Randomized {{controlled}} trials (RCTs) {{are considered}} the gold standard in estimating treatment effects. When an RCT is infeasible, regression modeling or statistical matching are often used instead. Nonexperimental methods such as these could produce <b>unbiased</b> <b>estimates</b> if the underlying assumptions hold, but those assumptions are usually not testable. Most prior studies testing nonexperimental designs find that they fail to produce <b>unbiased</b> <b>estimates,</b> but these studies have examined weaker evaluation designs. The present study addresses these limitations. The use of baseline data that are strongly predictive of the key outcome measures considerably reduces but might not completely eliminate bias...|$|R
5000|$|Suppose δ(X) is an <b>unbiased</b> <b>estimate</b> of an {{arbitrary}} scalar function g:&thinsp;Rn → R of θ, i.e., ...|$|E
5000|$|... be an <b>unbiased</b> <b>estimate</b> of the {{variance}} from the sample. It can be shown that the random variable ...|$|E
5000|$|... {{but this}} is a biased estimate. Its inverse (r + k)/r, is an <b>unbiased</b> <b>estimate</b> of 1/p, however.|$|E
40|$|James (1991, Biometrics 47, 1519 - 1530) {{constructed}} <b>unbiased</b> <b>estimating</b> {{functions for}} estimating the two parameters in the von Bertalanffy growth curve from tag-recapture data. This paper provides <b>unbiased</b> <b>estimating</b> functions {{for a class}} of growth models that incorporate stochastic components and explanatory variables. a simulation study using seasonal growth models indicates that the proposed method works well while the least-squares methods that are commonly used in the literature may produce substantially biased estimates. The proposed model and method are also applied to real data from tagged rack lobsters to assess the possible seasonal effect on growth...|$|R
40|$|Abstract: Randomized {{controlled}} trials (RCTs) {{are considered}} the gold standard in estimating treatment effects. When an RCT is infeasible, regression modeling or statistical matching are often used instead. Nonexperimental methods such as these could produce <b>unbiased</b> <b>estimates</b> if the underlying assumptions hold, but those assumptions are usually not testable. Most prior studies testing nonexperimental designs find that they fail to produce <b>unbiased</b> <b>estimates,</b> but these studies have examined weaker evaluation designs. The present study addresses these limitations. The use of baseline data that are strongly predictive of the key outcome measures considerably reduces but might not completely eliminate bias...|$|R
40|$|In this paper, {{we shall}} {{make use of}} the {{properties}} of the k -th upper record values to develop the inferential procedures such as point estimation. We shall obtain the best linear <b>unbiased</b> <b>estimates</b> of parameters of a two-parameter rectangular distribution based on k -th record values. The efficiency of the best linear <b>unbiased</b> <b>estimates</b> of the parameters based on two k -th record values has been compared with that of the corresponding estimates based on a complete set of k -th record values. At the end we give the characterization of the two-parameter rectangular distribution using k -th upper record values...|$|R
