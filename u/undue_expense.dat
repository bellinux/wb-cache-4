14|10|Public
25|$|The {{basic duty}} of the {{receiver}} was to realise value for the floating charge holder, although all preferential debts, or those with priority, {{would have to be}} paid. For other unsecured creditors, the possibility of recovering money was remote. The floating owed no duty to other creditors with regard to the timing of the appointment of a receiver, even if it could have an effect on negotiations for refinancing the business. It was accepted that a receiver had a duty to act only for the proper purpose of realising debts, and not for some ulterior motive. In Downsview Nominees Ltd v First City Corp Ltd, a company had given floating charges to two banks (Westpac first, and First City Corp second). The directors, wishing to install a friendly figure in control asked Westpac to assign its floating charge to their friend Mr Russell, who proceeded to run the business with further losses of $500,000, and refused to pass control to First City Corp, even though they offered the company discharge of all the money owed under the first debenture. The Privy Council advised that Mr Russell, as administrative receiver, had acted for an improper purpose by refusing this deal. A further case of breach of duty occurred in Medforth v Blake where the administrative receiver of a pig farm ignored the former owner's advice on how to get discounts on pig food of £1000 a week. As a result, larger debts were run up. Sir Richard Scott VC held this was a breach of an equitable duty of exercising due diligence. However, a more general duty to creditors was tightly constrained, and general liability for professional negligence was denied to exist. In Silven Properties Ltd v Royal Bank of Scotland a receiver of a property business failed to apply for planning permission on houses that could have significantly raised their value, and did not find tenants for the vacant properties, before selling them. It was alleged that the sales were at an undervalue, but the Court of Appeal held that the receiver's power of sale was exercisable without incurring any <b>undue</b> <b>expense.</b> Everything was subordinate to the duty to the receiver to realise a good price. In this respect, an administrator is not capable of disregarding other creditors, at least in law. One {{of the reasons for the}} partial abolition of administrative receivership was that after the receiver had performed his task of realising assets for the floating charge holder, very little value was left in the company for other creditors because it appeared to have fewer incentives to efficiently balance all creditors' interests. Ordinarily, once the receiver's work was done, the company would go into liquidation.|$|E
5000|$|... • <b>Undue</b> <b>expense</b> {{is needed}} to protect {{susceptible}} workers by lowering {{the level of the}} toxic substance in the workplace.|$|E
5000|$|The {{construction}} work proceeded since 1927 without delay or <b>undue</b> <b>expense,</b> {{and the first}} servicing station {{was established in the}} eastern part of the city; the line opened on 21 December 1930. The several stations do include: ...|$|E
50|$|In addition, the Cour des Comptes {{supports}} and provides {{half of the}} judges of the Cour de discipline financière et budgétaire (Court of financial and budgetary discipline), the other half being provided by the Conseil d'État. This court tries ordonnateurs — that is, the persons who order expenses and the recovery of debts, and may fine them for <b>undue</b> <b>expenses</b> or for sums {{that they should have}} decided to recover. However, the court cannot try government ministers, or (in almost all cases), local elected officials; thus, with few exceptions, the only ordonnateurs that face the court are civil servants.|$|R
5000|$|Current {{guidance}} {{notes for}} the insolvency profession should not put any <b>undue</b> burden or <b>expense</b> {{on the proposed}} administrator to provide much {{or all of the}} information required to the court at the time the application for an administration order is made.|$|R
40|$|The {{overriding}} {{philosophy of}} the Uniform Civil Procedure Rules 1999 in Queensland is to facilitate the just and expeditious resolution of the issues in a civil proceeding at minimum expense. The court is enjoined to apply the rules to avoid <b>undue</b> delay, <b>expense</b> and technicality. Parties impliedly undertake to the court and each other to proceed expeditiously. These rules adopt management theories developed to contain delay and cost in the civil justice system. A survey was designed {{to determine whether the}} overriding objective is being achieved in practice. The results indicate a reduction in the time from initiation of a proceeding to termination as compared to a sample of similar cases determined under the repealed Rules of the Supreme Court...|$|R
50|$|Queen Victoria had {{suggested}} that the civil servants in India should have an official dress uniform, as did {{their counterparts in the}} Colonial Service. However, the Council of India decided that prescribing a dress uniform would be an <b>undue</b> <b>expense</b> for their officials.|$|E
50|$|Hearsay {{evidence}} {{is covered by}} sections 16-22 of the Evidence Act 2006. Previously inadmissible, the 1989 decision of the Court of Appeal in R v Baker created a common law exception to the hearsay rule based on reliability, which was codified in the Evidence Act. Pursuant to s 4(1) of the Act, a hearsay statement is a statement made by someone other than a witness (in the proceedings) that is offered to prove the truth of its contents. Under section 17 of this Act a hearsay statement is generally not admissible in any court proceeding. Though section 18 states when a hearsay statement {{may be able to}} be given in court. This is when the statement is reliable, the statement maker is unavailable to be called as a witness or it would provide <b>undue</b> <b>expense</b> and delay if that person was required to be a witness. There are also a number of specific exceptions such as statements in business records. Other exceptions include state of mind evidence (see R v Blastland) and whether the statement is tendered to prove the fact it was uttered or made, rather than to prove the truth of its contents (see DPP v Subramaniam).|$|E
50|$|The {{basic duty}} of the {{receiver}} was to realise value for the floating charge holder, although all preferential debts, or those with priority, {{would have to be}} paid. For other unsecured creditors, the possibility of recovering money was remote. The floating owed no duty to other creditors with regard to the timing of the appointment of a receiver, even if it could have an effect on negotiations for refinancing the business. It was accepted that a receiver had a duty to act only for the proper purpose of realising debts, and not for some ulterior motive. In Downsview Nominees Ltd v First City Corp Ltd, a company had given floating charges to two banks (Westpac first, and First City Corp second). The directors, wishing to install a friendly figure in control asked Westpac to assign its floating charge to their friend Mr Russell, who proceeded to run the business with further losses of $500,000, and refused to pass control to First City Corp, even though they offered the company discharge of all the money owed under the first debenture. The Privy Council advised that Mr Russell, as administrative receiver, had acted for an improper purpose by refusing this deal. A further case of breach of duty occurred in Medforth v Blake where the administrative receiver of a pig farm ignored the former owner's advice on how to get discounts on pig food of £1000 a week. As a result, larger debts were run up. Sir Richard Scott VC held this was a breach of an equitable duty of exercising due diligence. However, a more general duty to creditors was tightly constrained, and general liability for professional negligence was denied to exist. In Silven Properties Ltd v Royal Bank of Scotland a receiver of a property business failed to apply for planning permission on houses that could have significantly raised their value, and did not find tenants for the vacant properties, before selling them. It was alleged that the sales were at an undervalue, but the Court of Appeal held that the receiver's power of sale was exercisable without incurring any <b>undue</b> <b>expense.</b> Everything was subordinate to the duty to the receiver to realise a good price. In this respect, an administrator is not capable of disregarding other creditors, at least in law. One {{of the reasons for the}} partial abolition of administrative receivership was that after the receiver had performed his task of realising assets for the floating charge holder, very little value was left in the company for other creditors because it appeared to have fewer incentives to efficiently balance all creditors' interests. Ordinarily, once the receiver's work was done, the company would go into liquidation.|$|E
40|$|FDA is {{currently}} developing a policy regarding {{application of the}} Food, Drug and Cosmetic Act in the medical software marketplace. It should be available for review in draft form in summer or early fall 1986. This paper reviews the Agency's device regulation program {{and its implications for}} any medical software products deemed to be medical devices under that policy. It is anticipated that implementation will proceed smoothly, without <b>undue</b> delay or <b>expense</b> to industry or government...|$|R
50|$|Ideally and usually, {{discovery}} {{takes place}} without direct involvement by the court. Except for medical examinations and inspection of medical records, discovery requests {{need not be}} authorized by the court. The recipient of a discovery request may seek a protective order denying certain discovery or limiting its scope if the discovery requested will cause annoyance, embarrassment, oppression, or <b>undue</b> burden or <b>expense,</b> or will inquire into privileged or irrelevant matters, and the party requesting discovery may request that the court intervene and order compliance.|$|R
40|$|This {{creative}} project {{involved the}} development of a series of case studies in response to the 4 million plus fair housing violations that occur every year. The seven case studies developed were based on actual court cases involving the seven areas of fair housing violations. It is known that the use of case studies in training can be better remembered and more helpful than just explaining the rules. Through this project the researcher hopes to raise awareness of and help prevent these infractions from happening, thus saving <b>undue</b> duress and <b>expense</b> to a property management company. Department of Family and Consumer SciencesThesis (M. A. ...|$|R
40|$|All Commonwealth, {{state and}} {{territory}} judges in Australia {{are subject to}} mandatory retirement ages. While the 1977 referendum, which introduced judicial retirement ages for the Australian federal judiciary, commanded broad public support, this article argues that the aims of judicial retirement ages are no longer valid in a modern society. Judicial retirement ages may be causing <b>undue</b> <b>expense</b> to the public purse and depriving the judiciary of skilled adjudicators. They are also contrary to contemporary notions of age equality. Therefore, demographic change warrants a reconsideration of s 72 of the Constitution and other statutes setting judicial retirement ages. This article sets out three alternatives to {{the current system of}} judicial retirement ages. It concludes that the best option is to remove age-based limitations on judicial tenure.  ...|$|E
40|$|Concrete shear-friction {{properties}} are a fundamental material property of concrete {{which is known}} to govern not only the shear capacity of reinforced concrete beams and columns but also the flexural ductility that {{is the ability to}} rotate and form hinges. In a companion paper, it has been shown how the shear-friction material properties can be extracted from simple confined cylinder tests which will allow these properties to be extracted {{for a wide range of}} concrete without <b>undue</b> <b>expense.</b> Also in the companion paper, the shear-friction material properties were derived for normal strength concrete and presented in a generic form suitable for application. In this paper, it will be shown how these generic shear-friction material properties can be used to simulate and quantify the shear-sliding behaviour of initially uncracked concrete generally obtained directly from relatively expensive tests. Furthermore, how these shear-sliding capacities can then be used to quantify the shear capacity of RC beams without stirrups and without the need for size factors as the mechanics based approach automatically, through mechanics, allows for member size. Y. Chen, T. Zhang, P. Visintin and D. J. Oehler...|$|E
40|$|In {{residential}} tenancies, it is {{usual for}} the landlord {{to be responsible}} for the fabric of the building and the main appliances, and for the tenant {{to be responsible for}} paying for electricity, gas and other fuel. It is also the tenant who is affected by the building’s heating and ventilation performance – whether it can be kept warm and dry without <b>undue</b> <b>expense.</b> A landlord has no financial incentive to invest in extra insulation or better appliances, because the benefits will be reaped by the tenant in lower energy bills and higher levels of comfort, and because the improvements do not have a direct influence on the rent that the landlord can charge. The result is that energy efficiency investments tend not to get made. In policy terms, the interests of the landlord and tenant are not aligned; the incentives are split. It {{is a classic example of}} a principal-agent gap, and as the “landlord-tenant problem” is one of the market failures that affects efficiency in markets for energy and energy products. 1 The energy use affected by the principal-agent problem in the United States residential sector for refrigerators, space heating, water heating and lighting has been estimated as 31. 4 per cent of the total sectoral energy use; 2 so the issue is a substantial one. The problem of energy efficiency in rental accommodation is therefore the subject of this article...|$|E
40|$|Issues of {{reasonableness}} arise regularly throughout American law. Reasonableness is {{a concept}} central to tort law, which imposes a reasonable person standard in ascertaining duty. Criminal guilt turns on a reasonable doubt standard. And in civil discovery, the concept of reasonableness features prominently: discovery 2 ̆ 7 s scope reaches information that is reasonably calculated {{to lead to the}} discovery of admissible evidence, and discovery cannot be unreasonably cumulative or duplicative. Reasonableness standards require judges to undertake an objective, rather than subjective, evaluation. E-discovery specifically has two significant overarching reasonableness components: reasonable accessibility for production and reasonable care in preservation and disclosure. The interpretation of these two components plays a central and determinative role in the effectiveness and burdensomeness in discovering electronically stored information. This Symposium Article addresses the first of these two components - reasonable accessibility - analyzing the guidance available on this issue from the case law and commentators and concluding that current approaches to reasonable accessibility often fail to employ the required objective reasonableness standard. Current approaches tend to err in two prominent ways: (1) by relying inappropriately on informational classifications, and (2) by merging distinct standards into a single standard. Of particular significance, Federal Rule 26 creates a twofold reasonableness interpretation - both with respect to what constitutes reasonable accessibility and also with respect to what constitutes <b>undue</b> burden or <b>expense.</b> However, rather than undertaking an objective, fact-specific inquiry of reasonable accessibility, some courts are relying on categories for presumptive accessibility or inaccessibility. In addition, many courts appear to be evaluating 2 ̆ 2 <b>undue</b> burden or <b>expense</b> 2 ̆ 2 as one conflated standard that considers only cost...|$|R
5000|$|The defendant, arguing <b>undue</b> {{burden and}} <b>expense,</b> {{requested}} {{the court to}} shift the cost of production to the plaintiff, citing the Rowe decision. The court stated that whether the production of documents is unduly burdensome or expensive [...] "turns primarily on whether it is kept in an accessible or inaccessible format". [...] The court concluded {{that the issue of}} accessibility depends on the media on which data are stored. It described five categories of electronic repositories: (1) online data, including hard disks; (2) near-line data, including optical disks; (3) offline storage, such as magnetic tapes; (4) backup tapes; (5) fragmented, erased and damaged data. The last two were considered inaccessible, that is, not readily available and thus subject to cost-shifting. The court, then discussing the Rowe decision (the balance test), concluded that it needed modification and created a new seven-factor test: ...|$|R
40|$|Finite element and {{finite volume}} methods {{are used in}} a variety of design {{simulations}} when it is necessary to compute fields throughout regions that contain varying materials or geometry. Convergence of the simulation can be assessed by uniformly increasing the mesh density until an observable quantity stabilizes. Depending on the electrical size of the problem, uniform refinement of the mesh may be computationally infeasible due to memory limitations. Similarly, depending on the geometric complexity of the object being modeled, uniform refinement can be inefficient since regions that do not need refinement add to the computational expense. In either case, convergence to the correct (measured) solution is not guaranteed. Adaptive mesh refinement methods attempt to selectively refine the region of the mesh that is estimated to contain proportionally higher solution errors. The refinement may be obtained by decreasing the element size (h-refinement), by increasing the order of the element (p-refinement) or by {{a combination of the two}} (h-p refinement). A successful adaptive strategy refines the mesh to produce an accurate solution measured against the correct fields without <b>undue</b> computational <b>expense.</b> This is accomplished by the use of a) reliable a posteriori error estimates, b) hierarchal elements, and c) automatic adaptive mesh generation. Adaptive methods are also useful when problems with multi-scale field variations are encountered. These occur in active electronic devices that have thin doped layers and also when mixed physics is used in the calculation. The mesh needs to be fine at and near the thin layer to capture rapid field or charge variations, but can coarsen away from these layers where field variations smoothen and charge densities are uniform. This poster will present an adaptive mesh refinement package that runs on parallel computers and is applied to specific microelectronic device simulations. Passive sensors that operate in the infrared portion of the spectrum as well as active device simulations that model charge transport and Maxwell's equations will be presented...|$|R
40|$|There is a {{widespread}} perception that our judicial system needschanging. It is expensive, unnecessarily technical, intrusive on privaterelations, and it gives unfair advantage to the wealthy and powerful. Labor arbitration, by contrast, is frequently pointed to as the paradigmof private justice. It is understandable that labor arbitration is widely admired. Whenit functions properly it achieves in an impressive fashion the goals bywhich any system of dispute resolution should be measured. These are:(1) Finality. Once decided, are cases likely to be retried or appealed?(2) Obedience. Are the decisions put into effect or are they renderedmeaningless by subsequent refusals to carry them out?(3) Guidance. Do the decisions provide necessary guidance to theparties involved in the dispute? Can they subsequently structure behaviorin a reasonable fashion and avoid future litigation?(4) Efficiency. Are the majority of disputes settled without a formalhearing? When cases are tried, are the procedures adequate, flexible,and suited to the particular issue? Are the benefits achieved from thesystem economical compared to the costs?(5) Availability. Is the dispute-resolution machinery routinely availablewithout <b>undue</b> <b>expense</b> to people whose behavior is governed bythe system, and are they provided with adequate representation?(6) Neutrality. Do the decision makers avoid favoritism and bias forone side or another?(7) Conflict Reduction. Does the entire process, including the adjudication,lead to more amicable relations and contribute to mutual respectamong the potential disputants?(8) Fairness. Will the disputes be resolved {{in a way that}} appropriatelyrecognizes the interests of the various parties likely to come before thesystem...|$|E
40|$|Network {{measurement}} is {{an important}} tool in network research and operations, and is increasingly utilized in end-user applications. However, active measurements compete with other applications for limited network resources. These measurements are typically performed by individual users and applications, with limited coordination or planning. ^ This dissertation addresses network measurement {{in the context of}} a measurement infrastructure, which can coordinate measurements, monitor and control their resource consumption, and even improve the quality of measurement results. We address three specific areas of operation in a measurement infrastructure. ^ We present an architecture for an infrastructure that uses admission control to bound the resource consumption of measurements. We use estimates of the resources consumed by real-world measurement tools in the admission control mechanism. We evaluate methods of estimating the resource consumption of measurements in terms of network bandwidth, and show that these estimates are important to the accuracy of admission control. ^ We propose several algorithms for determining when network measurements can be replaced by a network inference mechanism to reduce measurement load in the network at a cost of measurement accuracy. We experimentally evaluate these algorithms on measurement patterns designed to present difficulties, measurement patterns based on real-world peer-to-peer distributed communication, and random measurements. We show that the algorithms successfully reduce the measurement load on the first two types of graphs, and that they do not incur <b>undue</b> <b>expense</b> on the latter. ^ We design and evaluate a family of methods for selecting vantage points from which to take active measurements to increase reachability into the Internet. We show that two of these methods perform substantially better than selecting vantage points at random, allowing a larger number of hosts to be probed with direct measurements with the same number of vantage points. ...|$|E
40|$|Beginning in {{the early}} 19702 ̆ 7 s, {{insurance}} companies nationwide began {{dropping out of the}} medical malpractice market. Medical malpractice had become an unprofitable field for investment partly because of a sharp and continuing increase both in the number of malpractice suits being brought against health-care providers and in the size of damage awards and settlements in medical malpractice cases. In response to increasing pressure from the medical profession and the insurance industry, many states in the mid- 19702 ̆ 7 s began to experiment with ways of limiting the number of claims being entered against physicians and hospitals, and reducing the size of malpractice awards and settlements. New York passed its first medical malpractice reforms in 1974. 2 ̆ 7 Despite these initial efforts, malpractice insurance premiums, the number of suits being brought against physicians, and the size of damage awards all continued to increase. New York then attempted to address this continuing problem through Program Bill No. 75 which Governor Cuomo signed into law on July 2, 1985. Thus, New York launched its second attempt to reform its medical malpractice tort claims systems. Present and past reform efforts both in New York and in other states have concentrated on reducing malpractice insurance premiums by limiting awards and hindering access to litigation, but have failed to address the most important flaws in the medical malpractice tor claims system. These flaws include a failure to compensate most victims of medical accidents, a failure to compensate promptly, and a failure to compensate without <b>undue</b> <b>expense.</b> Furthermore, the tort claims system has had a number of deleterious side-effects on the medical profession, including the proliferation of defensive medicine. In contrast, a no-fault system of compensation would provide immediate compensation to a larger number of those injured as the result of medical accidents. In addition, such a system would eliminate the physician 2 ̆ 7 s need to protect himself in ways that are ultimately costly or otherwise harmful to the health care consumer. Experts have not yet determined whether a no-fault system of recovery would, in the long run, be more successful in reducing malpractice insurance premiums than past and current reforms. Such an innovation, however, would address the most glaring flaws in our current system of malpractice compensation. This Note will first examine the courts 2 ̆ 7 response to malpractice reform legislation, focusing on other states 2 ̆ 7 counterparts to the Bill 2 ̆ 7 s major provisions. 2 ̆ 2 This Note will then examine the history of the malpractice crisis in New York State, including a discussion of the first reform efforts. Furthermore, this Note will discuss the Bill 2 ̆ 7 s major provisions in terms of their stated purpose and their relation to prior law. Finally, this Note will examine the Bill 2 ̆ 7 s probable impact on the malpractice problem, the Bill 2 ̆ 7 s major shortcomings, and an alternative direction for future reform efforts...|$|E
40|$|Using {{automated}} {{and standardized}} computer tools {{to calculate the}} pertinent test result values has several advantages such as: 1. allowing high-fidelity solutions to complex nonlinear phenomena that would be impractical to express in written equation form, 2. eliminating errors associated with the interpretation and programing of analysis procedures from the text of test standards, 3. lessening the need for expertise {{in the areas of}} solid mechanics, fracture mechanics, numerical methods, and/or finite element modeling, to achieve sound results, 4. and providing one computer tool and/or one set of solutions for all users for a more "standardized" answer. In summary, this approach allows a non-expert with rudimentary training to get the best practical solution based on the latest understanding with minimum difficulty. Other existing ASTM standards that cover complicated phenomena use standard computer programs: 1. ASTM C 1340 /C 1340 M- 10 - Standard Practice for Estimation of Heat Gain or Loss Through Ceilings Under Attics Containing Radiant Barriers by Use of a Computer Program 2. ASTM F 2815 - Standard Practice for Chemical Permeation through Protective Clothing Materials: Testing Data Analysis by Use of a Computer Program 3. ASTM E 2807 - Standard Specification for 3 D Imaging Data Exchange, Version 1. 0 The verification, validation, and round-robin processes required of a computer tool closely parallel the methods that are used to ensure the solution validity for equations included in test standard. The use of automated analysis tools allows the creation and practical implementation of advanced fracture mechanics test standards that capture the physics of a nonlinear fracture mechanics problem without adding <b>undue</b> burden or <b>expense</b> to the user. The presented approach forms a bridge between the equation-based fracture testing standards of today and the next generation of standards solving complex problems through analysis automation...|$|R
40|$|Graduation date: 1964 The {{purpose of}} this study was to test a {{proposed}} procedure for providing seniors in small high schools of Oregon with information in regard to the private colleges and universities of the state. It included the development of an audio-visual technique and its trial on a sample group. Scope and Procedure: For this study a sample of high school seniors was drawn from thirteen secondary schools within the state of Oregon whose senior class enrollments were 75 students or fewer. These schools were selected by random sampling procedures from a total population of 131 schools. A master tape recording providing functional and timely information characteristic of the 11 Northwest private colleges and universities was prepared and presented to 13 class "B" and "C" secondary schools. The study was designed to test the following hypotheses: 1. That audio-visual techniques for presenting college and university information will help the college-directed student in his selection of a school of higher education. 2. That such audio-visual techniques will not place <b>undue</b> <b>expense</b> or other burden upon the high school or the colleges or universities. The effectiveness of the program was evaluated by the following procedure: 1. A test of general knowledge about private schools of higher education in Oregon was administered prior to the commencement of the program of audio-tape and slides. 2. The eight minute tape with slides was presented. 3. The program concluded with a second administration of the same test given in the beginning. From the comparison of the results of the pre- and post-test a determination of the influence of the master tape and slides was made. 4. When the pre-test was given the students were asked to list in rank order their list of college choices, and the basis for their selection. At the end of the post-test they were again asked to list their choice of colleges. A comparison of the two lists and the accompanying reasons yielded answers to the questions: a. Did the program cause the student to broaden his choice of colleges? b. Did the program influence his choice and in what way? The significance of the results was determined by the following: 1. the value of the Critical Ratio of the difference between the Means of the pre- and post-test for each high school. 2. the value of the Critical Ratio of the difference between the Means of the pre- and post-test for the sample taken as a whole. 3. the results of the paired "t" test for each high school. Findings: The statistics of the study empirically demonstrated that: 1. this type of presentation is effective as an instructional instrument capable of providing college information to high school seniors. The critical ratios in every case were significant. 2. the program did not appreciably affect college choice. 3. the program as presented was instructional to high school seniors who had taken part in a "College Day" program sponsored by the private colleges. Further findings not indicated in the statistics were: 1. The class "B" and "C" secondary schools have the capability to present an audio-visual program as suggested in this thesis. 2. The cost is reasonable in comparison with what it would cost to send a college representative to these "small" high schools. It is expected that the Northwest Association of Private Colleges and Universities will use the results and procedures of the study in their admissions programs...|$|E
40|$|This Executive Summary {{presents}} the major conclusions and {{recommendations of the}} International Workshop on Seismic Design and Reassessment of Offshore Structures. Full versions of the text of all invited lecturers and complete working group reports are contained elsewhere in these Proceedings. Site Seismic Hazard and Ground Motion Continuous improvements {{have been made in}} the state-of-the-art of estimation of seismic ground motion for design and reassessment of offshore platforms. C. B. Crouse of Dames & Moore provides an overview of methods used to determine seismic design parameters for offshore structures. A site&# 64979;specific analysis is generally performed to develop seismic design parameters for a particular site. The first step is to define the seismic sources in the site region, and develop a model of the attenuation of ground motion that is appropriate for the region. Next, probabilistic and/or deterministic analyses are performed to estimate the ground motion parameters. For new designs, both approaches are commonly used. For reassessment and requalification, a probabilistic approach is generally preferred. There are three basic inputs needed for a probabilistic approach; 1) identification of earthquake sources in the site region, 2) definition of the earthquake recurrence for each source, and 3) definition of the attenuation of earthquake ground motion, usually expressed as a function of distance from the source and earthquake magnitude. An example is given of a typical offshore platform located in a subduction zone environment. This example is used to illustrate some of the more important issues in the determination of seismic parameters. These issues include: extrapolation from available data to larger design level events, inclusion of basin effects on soil amplification, the relationship between vertical and horizontal earthquake motions, and the effect of the water column on vertical acceleration. It is concluded that estimation of ground motion for offshore structural design and reassessment is a challenging process involving several technical disciplines including seismology, geology, geotechnical and structural engineering, as well as political considerations. Unfortunately, many uncertainties still exist in the specification of seismic design parameters based on site-specific seismic hazard analyses. The Working Group on Site Seismic Hazard and Ground Motion, co&# 64979;chaired by Allin Cornell of Stanford University and Paul Somerville of Woodward Clyde Consultants, makes the following major conclusions and recommendations: 1. There is a critical need for more recorded earthquake seafloor motion data in regions where offshore facilities are proposed or currently constructed. 2. There is a need for the application of the latest state-of-the-art techniques in the prediction of ground motion, especially in the period range of 1 - 4 seconds. 3. Further research should be undertaken related to defining the subsurface input reference point for strong ground motion. 4. Deep geophysical data is needed to better characterize offshore seismic sources. Design, Reassessment And Requalification Robert Bea of the University of California observes that the primary objectives of a seismic design methodology are to assure that a new offshore structure will have sufficient strength and ductility to satisfy its intended purposes without <b>undue</b> <b>expense</b> or risk. He argues that the primary focus of the platform designer should be on the response that develops after first significant yielding occurs in the structural elements and components that comprise the structural system of the platform, and the damage states that can lead to collapse of the platform. In the design criteria, member resistance and factors should be chosen to provide acceptable reliability against significant damage or collapse. A strength level earthquake is not anticipated to induce significant damage or inelastic response in the structural elements. Static push-over analyses have been used extensively to demonstrate the capacity and ductility of offshore platforms. The margin of safety beyond the elastic performance requirement is often expressed by a platform Reserve Strength Ratio (RSR) which is the ratio of the maximum lateral load capacity of the platform to a reference load induced by the strength level earthquake. Bea has found that platforms designed according to current American Petroleum Institute (API) guidelines generally have an RSR 2. In contrast to a seismic design methodology, a seismic requalification methodology should provide a set of processes and parameters to insure that an existing platform will be able to develop acceptable performance during its proposed service period. Bea summarizes his "comprehensive" seismic requalification methodology. In this methodology, the judgment of fitness for purpose is based on the total probability of failure of the platform system, including topside equipment and operations, the potential costs, and the consequences associated with failure. If a platform is judged not fit-for-purpose, guidance is provided as to how to improve its performance characteristics. Two different approaches may be used to define the fitness-for-purpose criteria in this methodology: "utility optimization" or "standard of practice. " The utility optimization approach is based on an evaluation of the positive and negative utilities associated with different risks. Utility may be measured in a variety of ways. Costs and benefits are commonly measured in monetary terms. The objective is usually expressed in terms of minimization of total expected cost. The standard-of-practice approach is based on current design and requalification decisions which have been made for other platforms. The underlying premise of this approach is that, over time, the profession, industry, and regulatory agencies have defined acceptable combinations of probabilities of failure and consequences associated with failure. In the standard-of-practice approach, the decision on whether a structure is fit-for-purpose is based upon its probability of failure and total cost of failure as compared to other new and existing platforms. Straight line "acceptable" and "marginal" boundaries have been proposed in a log-log total probability vs. total cost space. Bea expresses the opinion that none of the available seismic requalification methodologies are as highly developed as seismic design methodologies. It is argued that the industry has the necessary technology to develop definitive engineering guidelines from the available requalification methodologies and that high priority should be given to developing such guidelines. It is further asserted that generally accepted fitness-for-purpose criteria that are dependent on consequences and likelihoods of failure need to be developed for both new and existing offshore structures. David Wisch of Texaco Corporation {{presents the}} results of a 1992 API requalification project. A panel, consisting of Wilfred Iwan (Chairman), Allin Cornell, George Housner and Charles Thiel, was constituted by the API to recommend an approach to seismic requalification of offshore structures. The API Panel's strategy is based on the establishment of separate acceptable levels of risk for life safety and environmental hazards. The Panel reasoned that life safety and environment hazards are essentially different in character and need not, indeed cannot, be measured by a common scale such as dollars. The Panel's acceptable risk for life safety is based on the concept that the risk to a worker on an offshore platform should be comparable to that for a worker in a similar facility onshore. This was believed to be a publicly acceptable level of risk. Acceptable environmental risk is based upon the risk of spills that occur from other sources in the same region which are deemed publicly acceptable. The Panel uncovered no safety or environmental issues associated with the seismic safety reassessment process that indicated platforms should be subject to risk criteria more restrictive than those for land-based industrial facilities. The Panel argued that the focus of seismic safety reassessment should be on limiting, to an acceptable level, the risk due to catastrophic impacts of earthquakes, where a catastrophic impact is defined as one that has unacceptable large life and/or environmental safety consequences. It was further argued that offshore facilities should have more rigorous site hazard and engineering behavior analysis than onshore facilities in order to achieve these goals, even though they have comparable quantitative risk limits. The Panel recommend that decisions related to cost and economic return be left to platform owners and not be included in reassessment or requalification requirements imposed by regulatory agencies. The Panel concluded that use of the design and analysis guidelines presented in the API recommended practice document, RP 2 A, 19 th edition, will produce a structure with life safety comparable to that of well-engineered structures onshore provided that: 1) the hazard study and structural analyses are peer reviewed, 2) the seismic hazards are determined in accordance with strength and ductility level earthquakes with 200 and 1, 000 year return periods, respectively, 3) a ductility level earthquake analysis is always performed, and 4) proper allowance is made for life&# 64979;safety risks associated with platform appurtenances. For structures which do not meet the guidelines of RP 2 A, the Panel determined that an objective of an annual probability of failure (collapse) of less than 1 x 10 - 3 would be consistent with providing a level of life safety comparable to that of onshore structures. The Panel also concluded that median value results from hazard analyses should be used in any probabilistic analyses to verify satisfaction of this objective. For Southern California waters, the Panel recommended an environmental performance objective of a release of no more than 2, 000 barrels from any possible source including wells, pipelines, and onboard storage. Wisch notes that the API Panel study is only one of a series of steps being undertaken by the offshore industry. Some of the questions that are being and will be answered by these studies include: 1) whether platforms can be categorized as to their expected response based on type or age, 2) whether an effective screening procedure can be developed to avoid detailed case-by-case assessment of offshore structures, 3) how independent review and peer review should best be incorporated into the reassessment process, 4) the different issues that must be addressed in reassessment outside the U. S., and 5) how acceptability criteria should relate to recommended industry practice, codes, regulatory requirements, and economic considerations. The Working Group on Design, Reassessment and Requalification, co-chaired by Kris Digre of Shell Oil Co. and William Ibbs of U. C. Berkeley, arrives at the following conclusions and recommendations: 1. The strength level and ductility level earthquakes employed in current API recommended practice need to be more precisely specified; perhaps tied to some other criteria. 2. A ductility level analysis should always be required. 3. Accelerographs should be installed in all offshore structures for the purpose of acquiring data on structural performance during actual earthquake excitation. 4. Technology should be further developed and shared regarding the following: joint and member capacities (including in-frames), mass coefficients for wave loading, effects of marine growth on structural response, and the relation between static and dynamic load analysis procedures. 5. A majority of the working group felt that there should be a separation of life safety, environmental consequences, and economic decisions for requalification but a consensus on this matter could not be reached. 6. A full probability-of-failure risk analysis should be performed rather than a mere determination of the survival of a structure for a given return period earthquake. 7. A strength level earthquake analysis need not be performed for requalification as long as a ductility level analysis is performed. 8. A careful peer review should be conducted of both the structural and seismic hazard elements of any design, reassessment, or requalification process. More work is needed to develop an appropriate peer review process and guidelines for reviewer qualification. 9. Research is needed to more precisely define manned and unmanned operations, and catastrophic consequences of environmental pollution. 10. There is a need to build greater consensus on the appropriate criteria for safety goals for design and requalification. Further research is needed on such issues as: specification of life safety and environmental safety objectives, the use engineering judgment, and how to properly incorporate the consequences of failure into any performance objective...|$|E

