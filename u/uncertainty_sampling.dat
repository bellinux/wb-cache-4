100|707|Public
40|$|We aim to {{investigate}} methods balancing exploitation with exploration in active learning {{to improve the}} performance of <b>uncertainty</b> <b>sampling.</b> Two exploration guided sampling methods are compared to <b>uncertainty</b> <b>sampling</b> on various real-life datasets from the 2010 Active Learning Challenge. Our initial experiments {{seems to indicate that}} combining exploration with <b>uncertainty</b> <b>sampling</b> improves performance on certain datasets but not all...|$|E
40|$|Active {{learning}} {{reduces the}} amount of manually annotated sentences necessary when training state-ofthe-art statistical parsers. One popular method, <b>uncertainty</b> <b>sampling,</b> selects sentences for which the parser exhibits low certainty. However, this method does not quantify confidence about the current statistical model itself. In particular, we should be less confident about selection decisions based on low frequency events. We present a novel twostage method which first targets sentences which cannot be reliably selected using <b>uncertainty</b> <b>sampling,</b> and then applies standard <b>uncertainty</b> <b>sampling</b> to the remaining sentences. An evaluation shows that this method performs better than pure <b>uncertainty</b> <b>sampling,</b> and better than an ensemble method based on bagged ensemble members only. ...|$|E
40|$|Abstract. <b>Uncertainty</b> <b>sampling</b> is an {{effective}} method for performing active learning that is computationally efficient compared to other active learning methods such as loss-reduction methods. However, unlike lossreduction methods, <b>uncertainty</b> <b>sampling</b> cannot minimize total misclassification costs when errors incur different costs. This paper introduces a method for performing cost-sensitive <b>uncertainty</b> <b>sampling</b> that makes use of self-training. We show that, even when misclassification costs are equal, this self-training approach results in faster reduction of loss {{as a function of}} number of points labeled and more reliable posterior probability estimates as compared to standard <b>uncertainty</b> <b>sampling.</b> We also show why other more naive methods of modifying uncertainty samplin...|$|E
30|$|To reduce {{measurement}} <b>uncertainty,</b> <b>samples</b> {{were not}} taken from within a 1 -cm wide margin of a document. Similarly, areas containing ink, stains or mould were not used.|$|R
30|$|As we {{mentioned}} before, the <b>sampling</b> <b>uncertainty</b> surrounding the <b>sample</b> mean μ is asymptotically inconsequential because the information matrix is block diagonal. The <b>sampling</b> <b>uncertainty</b> surrounding the other parameters, say ϑ, {{is not necessarily}} so.|$|R
40|$|Abstract: This paper {{discusses}} the {{theoretical and practical}} aspects of new methods for solving DEA problems under real-life geometrical uncertainty and probability <b>uncertainty</b> of <b>sample</b> data. The proposed minimax approach to solve problems with geometrical <b>uncertainty</b> of <b>sample</b> data involves an implementation of linear programming or minimax optimization, whereas the problems with probability <b>uncertainty</b> of <b>sample</b> data are solved through implementing of econometric and new stochastic optimization methods, using the stochastic frontier functions estimation. ...|$|R
40|$|One of {{the biggest}} {{challenges}} in building effective anti-spam solutions is designing systems to defend against the everevolving bag of tricks spammers use to defeat them. Because of this, spam filters that work well today may not work well tomorrow. The adversarial nature of the spam problem makes large, up-to-date, and diverse e-mail corpora critical for the development and evaluation of new anti-spam filtering technologies. Gathering large collections of messages can actually be quite easy, especially {{in the context of a}} large, corporate or ISP environment. The challenge is not necessarily in collecting enough mail, however, but in collecting a representative distribution of mail types as seen “in the wild ” and in then accurately labeling the hundreds of thousands or millions of accumulated messages as spam or non-spam. In the field of machine learning <b>Uncertainty</b> <b>Sampling</b> is a well-known Active Learning algorithm which uses a collaborative model to minimize the human effort required to label large datasets. While conventional <b>Uncertainty</b> <b>Sampling</b> has been shown to be very effective, it is also computationally very expensive since the learner must reclassify all the unlabeled instances during each learning iteration. We propose a new algorithm, Approximate <b>Uncertainty</b> <b>Sampling</b> (AUS), which is nearly as efficacious as <b>Uncertainty</b> <b>Sampling,</b> but has substantially lower computational complexity. The reduced computational cost allows Approximate <b>Uncertainty</b> <b>Sampling</b> to be applied to labeling larger datasets and also makes it possible to update the learned model more frequently. Approximate <b>Uncertainty</b> <b>Sampling</b> encourages the building of larger, more topical, and more realistic example e-mail corpora for evaluating new anti-spam filters. While we focus on the binary labeling of large volumes of e-mail messages, as with <b>Uncertainty</b> <b>Sampling,</b> Approximate <b>Uncertainty</b> <b>Sampling</b> can be used with a wide range of underlying classification algorithms for a variety of categorization tasks. 1...|$|E
40|$|Introduction At ACM SIGIR ' 94, I {{compared}} {{the effectiveness of}} <b>uncertainty</b> <b>sampling</b> with that of random sampling and relevance sampling in choosing training data for a text categorization data set [1]. (Relevance sampling is the application of relevance feedback [3] to producing a training sample.) I have discovered a bug in my experimental software which caused the relevance sampling results reported in the SIGIR ' 94 paper to be incorrect. (The <b>uncertainty</b> <b>sampling</b> and random sampling results in that paper were correct.) I have since fixed the bug and rerun the experiments. This note presents the corrected results, along with additional data supporting the original claim that <b>uncertainty</b> <b>sampling</b> has an advantage over relevance sampling in most training situations...|$|E
40|$|This {{paper is}} {{concerned}} with pool-based active learning for deep neural networks. Motivated by coreset dataset compression ideas, we present a novel active learning algorithm that queries consecutive points from the pool using farthest-first traversals {{in the space of}} neural activation over a representation layer. We show consistent and overwhelming improvement in sample complexity over passive learning (random sampling) for three datasets: MNIST, CIFAR- 10, and CIFAR- 100. In addition, our algorithm outperforms the traditional <b>uncertainty</b> <b>sampling</b> technique (obtained using softmax activations), and we identify cases where <b>uncertainty</b> <b>sampling</b> is only slightly better than random sampling...|$|E
40|$|This paper {{discusses}} the {{theoretical and practical}} aspects of new methods for solving DEA problems under real-life geometrical uncertainty and probability <b>uncertainty</b> of <b>sample</b> data. The proposed minimax approach to solve problems with geometrical <b>uncertainty</b> of <b>sample</b> data involves an implementation of linear programming or minimax optimization, whereas the problems with probability <b>uncertainty</b> of <b>sample</b> data are solved through implementing of econometric and new stochastic optimization methods, using the stochastic frontier functions estimation. DEA, <b>Sample</b> data <b>uncertainty,</b> Linear programming, Minimax optimization, Stochastic optimization, Stochastic frontier functions...|$|R
30|$|The {{modeling}} {{was implemented}} in Analytica 4.5. Combining the uncertainties {{in all the}} inputs was performed with a Median Latin Hypercube 1 analysis with the maximum <b>uncertainty</b> <b>sample</b> of 32, 000 (run time on a personal computer was seconds). The assumption {{is that all the}} uncertainties are independent except where noted.|$|R
30|$|The {{indication}} of quantitative results from standard calibration experiments below the reporting limit of 1.5  µg/L (samples 3, 6, 16, and 17) {{needs to be}} specified including the expanded measurement <b>uncertainty.</b> <b>Sample</b> 17 showed a measurement uncertainty up to 100  % and samples 12, 15, and 20 uncertainties above 100  %. The latter ones need to be reported <  1.5  µg/L [38].|$|R
40|$|International audienceActive {{learning}} {{has been successfully}} applied {{to a number of}} NLP tasks. In this paper, we present a study on Information Extraction for natural language licenses that need to be translated to RDF. The final purpose of our work is to automatically extract from a natural language document specifying a certain license a machine-readable description of the terms of use and reuse identified in such license. This task presents some peculiarities that make it specially interesting to study: highly repetitive text, few annotated or unannotated examples available, and very fine precision needed. In this paper we compare different active learning settings for this particular application. We show that the most straightforward approach to instance selection, <b>uncertainty</b> <b>sampling,</b> does not provide a good performance in this setting, performing even worse than passive learning. Density-based methods are the usual alternative to <b>uncertainty</b> <b>sampling,</b> in contexts with very few labelled instances. We show that we can obtain a similar effect to that of density-based methods using <b>uncertainty</b> <b>sampling,</b> by just reversing the ranking criterion, and choosing the most certain instead of the most uncertain instances...|$|E
40|$|Active {{learning}} provides promising {{methods to}} optimize the cost of manually annotating a dataset. However, practitioners in many areas do not massively resort to such methods because they present technical difficulties and do not provide a guarantee of good performance, especially in skewed distributions with scarcely populated minority classes and an undefined, catch-all majority class, which are very common in human-related phenomena like natural language. In this paper we present {{a comparison of the}} simplest active learning technique, pool-based <b>uncertainty</b> <b>sampling,</b> and its opposite, which we call reversed <b>uncertainty</b> <b>sampling.</b> We show that both obtain results comparable to the random, arguing for a more insightful approach to active learning...|$|E
40|$|In this paper, {{we address}} the issue of {{deciding}} when to stop active learning for building a labeled training corpus. Firstly, this paper presents a new stopping criterion, classification-change, which considers the potential ability of each unlabeled example on changing decision boundaries. Secondly, a multi-criteriabased combination strategy is proposed {{to solve the problem of}} predefining an appropriate threshold for each confidence-based stopping criterion, such as max-confidence, min-error, and overalluncertainty. Finally, we examine the effectiveness of these stopping criteria on <b>uncertainty</b> <b>sampling</b> and heterogeneous <b>uncertainty</b> <b>sampling</b> for active learning. Experimental results show that these stopping criteria work well on evaluation data sets, and the combination strategies outperform individual criteria. ...|$|E
5000|$|In statistics, spatial {{autocorrelation}} between {{sample locations}} also helps one estimate mean value <b>uncertainties</b> when <b>sampling</b> a heterogeneous population.|$|R
40|$|The <b>sampling</b> <b>uncertainty</b> is a {{considerable}} factor {{of the majority of}} geological investigations. It is an integrated part of <b>sample's</b> total <b>uncertainty</b> and the validation of the investigations is just achievable if it is governed by internationally valuable standards. The <b>sampling</b> <b>uncertainty</b> consists of numerous distinct influences which has been estimated according to their specific target. To estimate the <b>sampling</b> <b>uncertainty,</b> reliable for a practical employment, a profound database is required. This thesis examines {{for the first time the}} quality of the correct implementation of instructions for sampling. Thus 100 expertises, reporting soil sampling of contaminated land, were evaluated and constrained to a statistical approach. With reference to the available documents it can be stated that the database evaluating the <b>sampling</b> <b>uncertainty</b> was insufficient and from that less robust. Introductory a detailed compilation and review of the existing literature was carried out. The most essential measures, subdivided in sampling strategy, sampling person and sampling quantity, were inspected and discussed. Concerning the estimation of <b>sampling</b> <b>uncertainty</b> the practical execution of the presented approaches is outlined and previously implemented applications had been carefully assessed. As the available literature is predominantly focussed to particular influences and for reasons of an accurate determination of the <b>sampling</b> <b>uncertainty</b> the individual were listed and estimated. To relate the measures, estimating the <b>sampling</b> <b>uncertainty,</b> to international demands the approaches practiced in Europe were screened. This thesis illustrates, that the <b>uncertainty</b> between the <b>sampling</b> procedure consisting of homogenous solid phases differs significantly from the sampling of heterogenous matter. Hence, the differences considering the influencing of bottom air, organic and anorganic compounds are identified and their effects to the sampling error are described. Beyond it, the thesis demonstrates that comparing sampling can be an adequate measure concerning the determination of <b>sampling</b> <b>uncertainty.</b> The definition of <b>sampling</b> <b>uncertainty</b> comprising all influencing criterions is less practicable since the commonly available data base is insufficient. </p...|$|R
40|$|AbstractThe aim of {{this paper}} is to present {{information}} about currently used standard and routine methods for radon analysis in drinking waters. An overview is given about the current situation and the performance of different measurement methods based on literature data. The following parameters are compared and discussed: initial sample volume and sample preparation, detection systems, minimum detectable activity, counting efficiency, interferences, measurement <b>uncertainty,</b> <b>sample</b> capacity and overall turnaround time. Moreover, the parametric levels for radon in drinking water from the different legislations and directives/guidelines on radon are presented...|$|R
40|$|Abstract — In {{the active}} {{learning}} challenge, {{we aim to}} improve the area under the learning curve (ALC), the global score in the challenge, by optimizing the classification methods and feature selection methods, and most importantly by refining the querying algorithm to select the most informative instances in the early iteration of active learning. For six different datasets in the development phase, we applied general and specific methods to resolve unbalanced class, sparse data, and missing value problems. We designed a voting system based on multi models to combine good prediction with robust performance in different types of datasets. For querying methods, we modified the approach of information density, firstly, to avoid the exhaustive comparison for all samples, and secondly to find more representative samples. We also propose two modified versions of <b>uncertainty</b> <b>sampling</b> based methods: <b>uncertainty</b> <b>sampling</b> with bias, which {{takes into account the}} high imbalance of data, and <b>uncertainty</b> <b>sampling</b> with prediction, which predicts the most uncertain samples based on the change of uncertain values during the active learning process. We present our preliminary results of the development datasets in the active learning challenge and discuss their significance in this paper. I...|$|E
40|$|Active {{learning}} is a process through which classiﬁers can be built from collections of unlabelled examples through the cooperation of a human oracle who can label {{a small number of}} examples selected as most informative. Typically the most informative examples are selected through <b>uncertainty</b> <b>sampling</b> based on classiﬁcation scores. However, previous work has shown that, contrary to expectations, there is not a direct relationship between classiﬁcation scores and classiﬁcation conﬁdence. Fortunately, there exists a collection of particularly eﬀective techniques for building measures of classiﬁcation conﬁdence from the similarity information generated by k-NN classiﬁers. This paper investigates using these conﬁdence measures in a new active learning sampling selection strategy, and shows how the performance of this strategy is better than one based on <b>uncertainty</b> <b>sampling</b> using classiﬁcation scores...|$|E
40|$|Abstract—Active {{learning}} methods aim {{to choose}} the most informative instances to effectively learn a good classifier. <b>Uncertainty</b> <b>sampling,</b> arguably the most frequently utilized active learning strategy, selects instances which are uncertain according to the model. In this paper, we propose a framework that distinguishes between two types of uncertainties: a model is uncertain about an instance due to strong and conflicting evidence (most-surely uncertain) vs. a model is uncertain about an instance {{because it does not}} have conclusive evidence (least-surely uncertain). We show that making a distinction between these uncertainties makes a huge difference to the performance of active learning. We provide a mathematical formulation to distinguish between these uncertainties for naive Bayes, logistic regression and support vector machines and empirically evaluate our methods on several real-world datasets. Keywords-Active learning; <b>uncertainty</b> <b>sampling</b> I...|$|E
40|$|This paper {{considers}} {{issues relating}} to the measurement of water quality parameters in the laboratory, especially an external (usually commercial) laboratory. Many organisations now use testing laboratories for water quality measurements, a process that has advantages and some limitations. The interaction between the testing laboratory and the organization requiring the data is crucial, and this paper looks at some aspects where a full appreciation {{of the role of}} each partner is important. These include limits of detection and reporting, measurement <b>uncertainty,</b> <b>sample</b> storage and preservation times, and various quality control procedures...|$|R
40|$|Model {{selection}} {{is one of}} the fundamental tasks of scientific inquiry. The most widely used methods such as ROC analysis do not take sampling un-certainty into account. To improve the robustness of model selection, we de-velop a model selection method capable to incorporate <b>sampling</b> <b>uncertainty.</b> We capture the <b>sampling</b> <b>uncertainty</b> by using the bootstrap technique, and quantify the <b>sampling</b> <b>uncertainty</b> by introducing fuzzy numbers. We apply our model selection system to a variety of real-world databases with respect to binary classifications. Among the tested datasets, our method performs in line with the traditional ROC analysis, whereas it provides the fuzzy presen-tation of ROC curves based on which not only the predictive accuracy but also the degree of <b>sampling</b> <b>uncertainty</b> can be addressed. In addition, we develop a computer tool implementing our system, which eases the tedious procedures in model selection...|$|R
40|$|The aim of {{this paper}} is to present {{information}} about currently used standard and routine methods for radon analysis in drinking waters. An overview is given about the current situation and the performance of different measurement methods based on literature data. The following parameters are compared and discussed: initial sample volume and sample preparation, detection systems, minimum detectable activity, counting efficiency, interferences, measurement <b>uncertainty,</b> <b>sample</b> capacity and overall turnaround time. Moreover, the parametric levels for radon in drinking water from the different legislations and directives/guidelines on radon are presented. JRC. G. 2 -Standards for Nuclear Safety, Security and Safeguar...|$|R
40|$|Training machine {{learning}} algorithms for land cover classification is labour intensive. Applying active learning strategies tries to alleviate this, but can lead to unexpected results. We demonstrate what can go wrong when <b>uncertainty</b> <b>sampling</b> with an SVM is applied to real world remote sensing data. Possible causes and solutions are suggested...|$|E
40|$|Abstract. Active {{learning}} {{has been successfully}} applied to many natural language processing tasks for obtaining annotated data in a cost-effective manner. We propose several extensions to an active learner that adopts the margin-based <b>uncertainty</b> <b>sampling</b> framework. Experimental results on a cause detection problem involving the classification of aviation safety reports demonstrate the effectiveness of our extensions. 1...|$|E
40|$|Histological image {{analysis}} methods often employ machine-learning classifiers {{in order to}} adapt to the huge variability of histological images. To train these classifiers, the user must select samples of the relevant image objects. In the field of active learning, there has been much research on sampling strategies that exploit the uncertainty of the current classification in order to guide the user to maximally informative samples. Although these approaches have the potential to reduce the training effort and increase the classification accuracy, they are very rarely employed in practice. In this paper, we investigate the practical value of <b>uncertainty</b> <b>sampling</b> in the context of histological {{image analysis}}. To obtain practically meaningful results, we have devised an evaluation algorithm that simulates the way a human interacts with a user interface. The results show that <b>uncertainty</b> <b>sampling</b> outperforms common random or error sampling strategies by achieving more accurate classification results with a lower number of training images...|$|E
40|$|A simple {{approach}} for incorporating tolerant rough sets (TRS) into a multi-class {{support vector machine}} (SVM) classifier for land-cover classification was presented. TRS was used to perform the sample preprocessing of the original samples set to reduce the <b>uncertainty</b> of <b>sample</b> set and make {{the influence of the}} <b>uncertainty</b> from <b>sample</b> set on the final classification accuracy least. SVM was employed after the TRS preprocessing. An application of the integrated classifiers using an ETM+ remote sensing image has been presented. The classification results were compared with those of only-SVM classifier. According to the overall accuracy and the k coefficient, the result of integrated classifier with TRS and SVM is better than that of only-SVM classifier in the experiment...|$|R
40|$|Hybrid tumor-tracking in image-guided {{radiation}} therapy (IGRT) :- Continuous monitoring of external respiration surrogate- Predict internal tumor position from surrogate using correlation model- Low-dim. surrogates cannot depict complexity of respiratory motion- Involve patient preparation and reproducible marker placement Goal: Dense marker-less 4 -D motion fields to improve correlation [1, 2] Marker-less range imaging (RI) in clinical solutions:- Consecutive laser sweep / light sectioning (C-RAD, LAP) - Active stereo vision (VisionRT) Limitations regarding motion management:- Measurement <b>uncertainties</b> (<b>sampling</b> principle) - Lack of real-time capability (designed for patient setup) Multi-line active triangulation (AT) sensor [3]: + Accurate 3 -D sampling (light sectioning) at 30 Hz + Simultaneous sampling of multiple lines in a grid structure + Compact housing, inexpensive hardwar...|$|R
40|$|Satellite {{measurements}} sample continuous {{fields of}} atmospheric constituents at discrete locations and times. However, insufficient or inhomogeneous sampling, if not taken into account, {{can result in}} inaccurate average estimates and even induce spurious features. We propose to characterize the spatiotemporal inhomogeneity of atmospheric measurements by a measure, which is a linear combination of the asymmetry and entropy of a sampling distribution. It is shown that this measure {{is related to the}} so-called <b>sampling</b> <b>uncertainty,</b> which occurs due to non-uniform sampling patterns. We have estimated the <b>sampling</b> <b>uncertainty</b> of zonal mean ozone profiles for six limb-viewing satellite instruments participating in the European Space Agency Ozone Climate Change Initiative project using the high-resolution ozone field simulated with the FinROSE chemistry-transport model. It is shown that the <b>sampling</b> <b>uncertainty</b> for the instruments with coarse sampling is not negligible and can be as large as a few percent. It is found that the standard deviation of the <b>sampling</b> <b>uncertainty</b> in the monthly zonal mean data allows for a simple parameterization in terms of the product of the standard deviation of natural variations and the proposed inhomogeneity measure. The <b>sampling</b> <b>uncertainty</b> estimates improve the uncertainty quantification and can be used in comprehensive data analyses. The focus of this work is the vertical ozone distributions measured by limb-viewing satellite instruments, but the developed methods can also be applied to different satellite, ground-based and in situ measurements...|$|R
40|$|In many cost-sensitive environments class {{probability}} {{estimates are}} used by decision makers to evaluate the expected utility from a set of alternatives. Supervised learning {{can be used to}} build class probability estimates; however, it often is very costly to obtain training data with class labels. Active learning acquires data incrementally, at each phase identifying especially useful additional data for labeling, and can be used to economize on examples needed for learning. We outline the critical features of an active learner and present a sampling-based active learning method for estimating class probabilities and class-based rankings. BOOT- STRAP-LV identifies particularly informative new data for learning based on the variance in probability estimates, and uses weighted sampling to account for a potential example's informative value {{for the rest of the}} input space. We show empirically that the method reduces the number of data items that must be obtained and labeled, across a wide variety of domains. We investigate the contribution of the components of the algorithm and show that each provides valuable information to help identify informative examples. We also compare BOOTSTRAP- LV with <b>UNCERTAINTY</b> <b>SAMPLING,</b> an existing active learning method designed to maximize classification accuracy. The results show that BOOTSTRAP-LV uses fewer examples to exhibit a certain estimation accuracy and provide insights to the behavior of the algorithms. Finally, we experiment with another new active sampling algorithm drawing from both <b>UNCERTAINTY</b> <b>SAMPLING</b> and BOOTSTRAP-LV and show that it is significantly more competitive with BOOTSTRAP-LV compared to <b>UNCERTAINTY</b> <b>SAMPLING.</b> The analysis suggests more general implications for improving existing active sampling [...] ...|$|E
40|$|Which active {{learning}} methods {{can we expect}} to yield good performance in learning logistic regression classifiers? Addressing this question is a natural first step in providing robust solutions for {{active learning}} across {{a wide variety of}} exponential models including maximum entropy, generalized linear, loglinear, and conditional random field models. We extend previous work on active learning using explicit objective functions by developing a framework for implementing a wide class of loss functions for active learning of logistic regression, including variance (A-optimality) and log loss reduction. We then run comparisons against the most widely used heuristic schemes: query by committee and <b>uncertainty</b> <b>sampling,</b> to discover which methods work best for different classes of problems and why. ^ Our empirical evaluations are the largest effort to date to evaluate explicit objective function methods in active learning. We employed ten data sets in the evaluation from domains such as image recognition and document classification. The data sets vary in number of categories from 2 to 26 and have as many as 6, 191 predictors. This work establishes the benefits of these often cited (but rarely used) strategies, and counters the claim that experimental design methods are too computationally complex to run on interesting data sets. The two loss functions were the only methods we tested that always performed at least as well as a randomly selected training set. ^ The same data were used to evaluate several heuristic methods including variants of <b>uncertainty</b> <b>sampling</b> and query by committee. <b>Uncertainty</b> <b>sampling</b> was tested using two different measures of uncertainty: Shannon entropy and margin size. Margin-based <b>uncertainty</b> <b>sampling</b> was found to be superior; however, both methods perform worse than random sampling at times. We show that these failures to match random sampling can be caused by predictor space regions of varying noise or model mismatch. The various heuristics produced mixed results overall in the evaluation, and it is impossible to select one as particularly better than the others when using classifier accuracy as the sole criterion for performance. Margin sampling is the favored approach when computational time is considered along with accuracy. ...|$|E
40|$|We {{introduce}} a technique for quantifying and then exploiting uncertainty in nonlinear stochastic control systems. The approach is suboptimal though robust and relies upon the approximation of the forward and inverse plant models by neural networks, which also estimate the intrinsic <b>uncertainty.</b> <b>Sampling</b> from the resulting Gaussian distributions of the inversion based neurocontroller {{allows us to}} {{introduce a}} control law which is demonstrably more robust than traditional adaptive controllers...|$|E
40|$|This paper {{presents}} {{evidence that}} model prediction uncertainty {{does not necessarily}} rise with parameter dimensionality (the number of parameters). Here by prediction we mean future simulation of a variable of interest conditioned on certain future values of input variables. We utilize a relationship between prediction <b>uncertainty,</b> <b>sample</b> size and model complexity based on Vapnik–Chervonenkis (VC) generalization theory. It suggests that models with higher complexity tend to have higher prediction <b>uncertainty</b> for limited <b>sample</b> size. However, model complexity is not necessarily related {{to the number of}} parameters. Here by limited sample size we mean a sample size that is limited in representing the dynamics of the underlying processes. Based on VC theory, we demonstrate that model complexity crucially depends on the magnitude of model parameters. We do this by using two model structures, SAC-SMA and its simplification, SIXPAR, and 5 MOPEX basin data sets across the United States. We conclude that parsimonious model selection based on parameter dimensionality may lead to a less informed model choice. Water ManagementCivil Engineering and Geoscience...|$|R
40|$|A {{workshop}} on <b>uncertainty</b> in <b>sampling</b> {{was held in}} Hillerød, Denmark, on 12 ¿ 13 April 2007 to launch a new handbook on sampling quality assurance and uncertainty estimation. The participants of the workshop were approximately 60 delegates from 15 European countries, representing institutions performing sampling, users of the data, research institutions, as well as accreditation bodies. Materials from the workshop, including examples, tools, and calculation aids for the work {{can be found at}} [URL] The Nordtest handbook <b>Uncertainty</b> from <b>sampling</b> will be made available on the Nordtest web site at [URL] under NT technical reports, report number NT tec 604. Until the final report is available on the Nordtest web site, an advance draft of the Nordtest handbook is available from [URL]...|$|R
30|$|Figure  4 a {{shows the}} {{combination}} of <b>sampled</b> <b>uncertainty</b> values for hourly wind direction and wind speed. For example, when uncertainty had a positive signal, the sampled value {{was added to the}} reference value, and vice versa, i.e. when a 10  km/h wind speed <b>uncertainty</b> value was <b>sampled,</b> this value was added to the input hourly wind streams. Since uncertainty for both variables was defined considering normal distributions centred on 0, the combination is a bell-shaped probability surface. Figure  4 b shows an example of the combination between sampled ROS adjustment factor (for fuel model 6) and <b>sampled</b> <b>uncertainty</b> of daily relative humidity. The surface {{is quite different from the}} one shown in Fig.  4 a, since the adjustment factor PDF presents a bimodal configuration with two distinct peaks centred in values close to 1 and between 2 and 3.|$|R
