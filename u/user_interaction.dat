5697|3594|Public
5|$|Graphical user {{interfaces}} (GUIs) may be developed using Perl. For example, Perl/Tk and WxPerl {{are commonly used}} to enable <b>user</b> <b>interaction</b> with Perl scripts. Such interaction may be synchronous or asynchronous, using callbacks to update the GUI.|$|E
5|$|In July 2017 the {{critical}} WiFi vulnerability BroadPwn affecting many iOS devices, including the iPad 2 was published. It allows an attacker to remotely {{take control of}} all affected devices within WiFi range without any <b>user</b> <b>interaction.</b> Since iOS 9 is in its end of life the iPad 2 won't receive a security patch for this vulnerability, making it dangerous to use them further.|$|E
25|$|In 2017, reCAPTCHA was {{improved}} to require no <b>user</b> <b>interaction.</b>|$|E
40|$|Electronic health records (EHRs) are complex. Clinicians must {{interact}} with patient data, order entry, decision support, reporting services, messaging programs, administrative data, {{and many other}} services. These services require user input and decision making, known as <b>user</b> <b>interactions,</b> between clinician and the EHR. EHRs have features designed to facilitate users’ interactions, such as alerts, reminders, keyboard shortcuts, and mouse click menus. These features can lead to unintended consequences, which combine with <b>user</b> <b>interactions,</b> thus making the EHR complicated and difficult to use. Awareness of <b>user</b> <b>interactions</b> and the unintended consequences will improve EHR design and lead to greater clinician acceptance of EHRs...|$|R
5000|$|The user {{interface}} domain {{model of the}} <b>user</b> <b>interactions</b> with the system.|$|R
30|$|Most of the {{investigation}} is done to represent the existence of relationships between user personality and <b>user</b> <b>interactions</b> in social networks focus on investigating how single features correlate, on the average, with personal properties. In this approach, having data of a given <b>user’s</b> <b>interactions</b> in social networks would {{make it possible to}} predict his personality, at least regarding some personality qualities.|$|R
25|$|The {{window manager}} handles <b>user</b> <b>interaction</b> with {{multiple}} client windows much like other X window managers.|$|E
25|$|Offline {{gestures}}: Those gestures {{that are}} processed after the <b>user</b> <b>interaction</b> with the object. An {{example is the}} gesture to activate a menu.|$|E
25|$|There {{are also}} various social aspects, like {{sitting around a}} campfire, playing music, having a {{friendly}} chat, sharing food, as well as making use of different facial expressions to make <b>user</b> <b>interaction</b> more colorful.|$|E
40|$|Abstract. We {{present a}} novel {{solution}} for intelligent analysis and visualization of <b>user</b> <b>interactions</b> with Web applications through mobile devices {{in order to}} help identify usability issues. The proposed tool is also able to support comparison of optimal use with actual <b>user</b> <b>interactions.</b> We also report on an example application of our tool to the evaluation of a real mobile Web site...|$|R
40|$|Without <b>user</b> <b>interactions,</b> {{multimedia}} presentations {{are just}} fancy slide shows with sound and video supports. <b>User</b> <b>interactions</b> by themselves {{do not change}} the temporal relationships among multimedia objects, such as texts, graphics, images, audio, and video, but affect the play-back schedules. In this paper, we propose a synchronization mechanism to guarantee the quality of multimedia presentation with <b>user</b> <b>interactions.</b> In our protocol, each presentation site requests media transmission from the required media servers at certain time intervals prior to the play-back deadlines, where these time intervals are the response times to cover possible experienced end-to-end delays and packet losses, and waits for an initial setup time to ensure intermedia synchronization before starting the presentation. Users may interact with the presentation. This synchronization mechanism solves the problems incurred by <b>user</b> <b>interactions</b> by determining the new presentation scenario produced by the interactive operation, calculating the corresponding setup time, and then rendering the new playback and retrieval schedules. link_to_subscribed_fulltex...|$|R
40|$|Accurate medical image {{segmentation}} {{is essential for}} diagnosis, surgical planning and many other applications. Convolutional Neural Networks (CNNs) have become the state-of-the-art automatic segmentation methods. However, fully automatic results may {{still need to be}} refined to become accurate and robust enough for clinical use. We propose a deep learning-based interactive segmentation method to improve the results obtained by an automatic CNN and to reduce <b>user</b> <b>interactions</b> during refinement for higher accuracy. We use one CNN to obtain an initial automatic segmentation, on which <b>user</b> <b>interactions</b> are added to indicate mis-segmentations. Another CNN takes as input the <b>user</b> <b>interactions</b> with the initial segmentation and gives a refined result. We propose to combine <b>user</b> <b>interactions</b> with CNNs through geodesic distance transforms, and propose a resolution-preserving network that gives a better dense prediction. In addition, we integrate <b>user</b> <b>interactions</b> as hard constraints into a back-propagatable Conditional Random Field. We validated the proposed framework in the context of 2 D placenta segmentation from fetal MRI and 3 D brain tumor segmentation from FLAIR images. Experimental results show our method achieves a large improvement from automatic CNNs, and obtains comparable and even higher accuracy with fewer user interventions and less time compared with traditional interactive methods. Comment: 14 pages, 15 figure...|$|R
25|$|Oracle Fusion Middleware is {{a family}} of {{middleware}} software products, including (for instance) application server, system integration, business process management (BPM), <b>user</b> <b>interaction,</b> content management, identity management and business intelligence (BI) products.|$|E
25|$|On Windows {{versions}} {{prior to}} Windows XP, an autorun.inf file on any drive type will be read and its instructions followed. The AutoRun task, if specified, is executed immediately without <b>user</b> <b>interaction.</b> This includes DRIVE_REMOVABLE, DRIVE_FIXED and DRIVE_REMOTE drive types.|$|E
25|$|Google Wave {{extensions}} are add-ins {{that may}} be installed on Google Wave to enhance its functionality. They may be Internet bots (robots) to automate common tasks, or gadgets to extend or change <b>user</b> <b>interaction</b> features, e.g., posting blips on microblog feeds or providing RSVP recording mechanisms.|$|E
50|$|User {{interface}} designer constructs the <b>user</b> <b>interactions</b> {{and feedback}} interface, like menus or heads-up displays.|$|R
5000|$|... to have {{easy to use}} {{graphical}} CASE {{tools to}} support simple and efficient <b>user</b> <b>interactions</b> ...|$|R
5000|$|IFML {{describes}} <b>user</b> <b>interactions</b> {{and control}} behaviors of front-end of applications {{belonging to the}} following domains: ...|$|R
25|$|However, {{the main}} {{limitation}} of electron diffraction in TEM remains the comparatively {{high level of}} <b>user</b> <b>interaction</b> needed. Whereas both the execution of powder X-ray (and neutron) diffraction experiments and the data analysis are highly automated and routinely performed, electron diffraction requires a much higher level of user input.|$|E
25|$|Instrumented GIMP (ingimp): Created at the University of Waterloo {{to track}} and report <b>user</b> <b>interaction</b> with the program to {{generate}} statistics about how GIMP is used, first released on 5 May 2007. Statistics collected by ingimp were publicly available freely of charge on the project's site after being anonymized. The ingimp site is no longer functioning as of 2014.|$|E
25|$|Support for 5250 display {{operations}} is provided via display files, an interface between workstations, keyboards and displays, and interactive applications, {{as opposed to}} batch processing {{with little or no}} <b>user</b> <b>interaction.</b> ASCII terminals and PC workstations are equally and well supported, also via internet or LAN network access supplemented by either IBM or non-IBM communication software, for example TELNET or TELNET 5250.|$|E
40|$|Part 2 : Interactive PostersInternational audienceWe {{present a}} novel {{solution}} for intelligent analysis and visualization of <b>user</b> <b>interactions</b> with Web applications through mobile devices {{in order to}} help identify usability issues. The proposed tool is also able to support comparison of optimal use with actual <b>user</b> <b>interactions.</b> We also report on an example application of our tool to the evaluation of a real mobile Web site...|$|R
40|$|A GUI (graphical userinterface) {{has been}} {{developed}} with aUIMS (user interface m;ulagement system) that has been build up us-ing exclusively non-proprietary software. A graphics server encapsulates completely representational spects, mediates be-tween <b>user</b> <b>interactions</b> and application v‘ariahles and takes care of a consistent state of graphical and applicational objects. The most flexible and powerful client of the graphics server has a built-in inlerprotcr section. On <b>user</b> <b>interactions</b> the graphics server passes code fragments in a C type language to this ap-plication program where the requested operations arc executed. Graphical representations, em;lntics of <b>user</b> <b>interactions</b> ‘and in-terpreter instructions are defined in a database written in a simple and comprehensible UJDL (user interface dcfinjtion l;ulguag~). ...|$|R
40|$|In {{interactive}} multimedia presentations, users {{should have the}} exibility to decide on various scenar-ios they want to see. This means that two-way commu-nications should be captured by the conceptual model. An abstract semantic model, the augmented transition network (ATN), is proposed for modeling user inter-actions in multimedia presentations. In ATNs, each state node allows multiple outgoing arcs to model po-tential <b>user</b> <b>interactions.</b> At the decision point, the multimedia presentation system can use this informa-tion to display selection buttons so users can make their choices. The superiority of modeling <b>user</b> <b>interactions</b> with ATN instead of the Timeline model or the Object Composition Petri Net model is discussed in this pa-per. Our {{results show that the}} ATN is eective for modeling <b>user</b> <b>interactions</b> in a multimedia presenta-tion environment. ...|$|R
25|$|Windows XP and Windows 2000 Service Pack 3 include Background Intelligent Transfer Service, a {{protocol}} for transferring files {{in the background}} without <b>user</b> <b>interaction.</b> As a system component, {{it is capable of}} monitoring the user's Internet usage, and throttling its own bandwidth usage in order to prioritize user-initiated activities. The Automatic Updates client for these operating systems was updated to use this system service.|$|E
25|$|Shortly {{after moving}} to Georgia Tech, Foley founded the GVU Center, which in 1996 was ranked first by U.S. News & World Report for {{graduate}} computer science work in graphics and <b>user</b> <b>interaction.</b> That same year, he was appointed director of the Mitsubishi Electric Research Laboratories (MERL) in Cambridge, Massachusetts. Foley also served as editor-in-chief of ACM Transactions on Graphics from 1991 to 1995.|$|E
25|$|Chromium 16.0 was {{released}} on 10 September 2011, with 16.0.877.0 as the initial version. Early {{in the development of}} version 16 an experimental Offscreen Tabs Module was incorporated which allows simultaneous <b>user</b> <b>interaction</b> with multiple web pages. This version for macOS included a move to Google's Skia 2D graphics library in place of Apple's core graphics as previously used. This aligned Chromium for macOS with the Windows and Linux versions.|$|E
50|$|Interactive {{narration}} {{refers to}} works where the linear narrative is driven by, rather than influenced by, the <b>users</b> <b>interaction.</b>|$|R
5000|$|... {{test cases}} by {{transforming}} recordings of <b>user</b> <b>interactions</b> {{with the system}} under test via a graphical user interface (Dashboard) ...|$|R
5000|$|In 2015 Mixpanel {{announced}} Codeless Mobile Analytics with point-and-click interface {{to track}} <b>user</b> <b>interactions</b> in their Android or iOS app.|$|R
25|$|Rosetta {{is part of}} Mac OS X for Intel {{operating}} systems prior to Lion. It translates G3, G4, and AltiVec instructions; however, it does not translate G5 instructions. Therefore, applications that rely on G5-specific instruction sets must be modified by their developers to work on Rosetta-supported Intel-based Macs. According to Apple, applications with heavy <b>user</b> <b>interaction</b> but low computational needs (such as word processors) are well suited to translation via Rosetta, while applications with high computational needs (such as AutoCAD, games, or Adobe Photoshop) are not.|$|E
25|$|Geomodelling and CAD share a lot {{of common}} technologies. Software is usually {{implemented}} using object-oriented programming technologies in C++, Java or C# on one or multiple computer platforms. The graphical user interface generally consists of one or several 3D and 2D graphics windows to visualize spatial data, interpretations and modelling output. Such visualization is generally achieved by exploiting graphics hardware. <b>User</b> <b>interaction</b> is mostly performed through mouse and keyboard, although 3D pointing devices and immersive environments {{may be used in}} some specific cases. GIS (Geographic Information System) is also a widely used tool to manipulate geological data.|$|E
25|$|During the {{development}} cycle for QuickTime 3.0, {{part of the}} engineering team {{was working on a}} more advanced version of QuickTime to be known as QuickTime interactive or QTi. Although similar in concept to the wired movies feature released as part of QuickTime 3.0, QuickTime interactive was much more ambitious. It allowed any QuickTime movie to be a fully interactive and programmable container for media. A special track type was added that contained an interpreter for a custom programming language based on 68000 assembly language. This supported a comprehensive <b>user</b> <b>interaction</b> model for mouse and keyboard event handling based in part on the AML language from the Apple Media Tool.|$|E
50|$|Moreover, <b>user</b> <b>interactions</b> UZ, Z ∈ {V, H, CV, CH} are an {{integral}} part of the visual analytics process. <b>User</b> <b>interactions</b> can either effect only visualizations UV : V → V (i.e., selecting or zooming), or can effect only hypotheses UH : H → H by generating a new hypotheses from given ones. Furthermore, insight can be concluded from visualizations UCV : V → I or from hypotheses UCH : H → I.|$|R
3000|$|Definition {{of a set}} of new IFML {{components}} {{allowing the}} modeling of the IoT <b>user</b> <b>interactions</b> (responding to RQ 2); [...]...|$|R
50|$|OkTrends, the {{official}} blog of OkCupid, presents statistical observations from OkCupid <b>user</b> <b>interactions,</b> to explore {{data from the}} online dating world.|$|R
