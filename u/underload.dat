170|260|Public
50|$|The {{relationship}} between workload and performance is complex. It {{is not always}} the case that as workload increases performance decreases. Performance can be affected by workload being too high or too low (Nachreiner, 1995). Sustained low workload (<b>underload)</b> can lead to boredom, loss of situation awareness and reduced alertness. Also as workload increases performance may not decrease as the operator may have a strategy for handling task demands.|$|E
5000|$|There {{is no one}} agreed {{definition}} of workload and consequently not one agreed method of assessing or modelling it. One example definition by Hart and Staveland (1988) describes workload as [...] "the perceived relationship {{between the amount of}} mental processing capability or resources and the amount required by the task". Workload modelling is the analytical technique used to measure and predict workload. The main objective of assessing and predicting workload is to achieve evenly distributed, manageable workload and to avoid overload or <b>underload.</b>|$|E
5000|$|Reloadable {{cartridge}} {{cases may}} {{be produced by}} resizing and trimming 9mm Winchester Magnum brass. A reasonable starting point for load development would be [...]38 ACP (not [...]38 Super) load data. The [...]38 Super data may possibly be more consistent with the original factory loading, as these had a claimed muzzle velocity of approx. 1362 fps with a 128 gr. bullet. The 8th edition of Cartridges of the World has a listing in the entry for 9mm Mauser using a 125 gr. bullet with a heavier charge of Blue Dot powder than is normally listed as the maximum for 124 gr. jacketed bullets in the [...]38 Super. Old loading data may incorporate more powerful loads than is intended with modern components, but care should be taken not to <b>underload</b> the cartridge to ensure proper cycling in an auto-loading firearm.|$|E
30|$|Any {{overloaded}} node initiates {{the migration}} process. It chooses randomly one <b>underloaded</b> node as destination from its neighborhood [4]. Hence, in each cycle, an overloaded node can send only one job but an <b>underloaded</b> one may receive several jobs from different nodes.|$|R
30|$|A node is {{considered}} overloaded or <b>underloaded</b> {{according to the}} average load of its neighborhood. Nodes in a neighborhood are classified into three categories: overloaded, intermediate, and <b>underloaded.</b> Intermediate nodes do not {{take part in the}} load balancing process (except possibly as receiver in sandpile strategy).|$|R
30|$|The {{capacity}} {{region of}} the K-user MISO BC with imperfect CSIT remains an open problem. As an alternative, recent {{progress has been made}} to characterize the DoF {{region of the}} <b>underloaded</b> and overloaded MISO BC with imperfect CSIT. In [26], a novel information theoretic upperbound on the sum DoF of the K-user <b>underloaded</b> MISO BC with imperfect CSIT was derived. Interestingly, this sum DoF coincides with the sum DoF achieved by a linearly precoded RS strategy at the transmitter with SIC at the receivers [27, 28]. RS (with SIC) is therefore optimum to achieve the sum DoF of the K-user <b>underloaded</b> MISO BC with imperfect CSIT, in contrast with MU–LP that is clearly suboptimum (and so is SC–SIC since it achieves a sum DoF of unity 8) [28]. It turns out that RS with a flexible power allocation is not only optimum for the sum DoF but for the entire DoF region of an <b>underloaded</b> MISO BC with imperfect CSIT [29]. The DoF benefit of RS in imperfect CSIT settings were also shown in more complicated <b>underloaded</b> networks with multiple transmitters in [30] and multi-antenna receivers [31]. Considering user fairness, the optimum symmetric DoF (or max-min DoF), i.e., the DoF that can be achieved by all users simultaneously, of the <b>underloaded</b> MISO BC with imperfect CSIT with MU–LP and RS was studied in [32]. RS symmetric DoF was shown to outperform that of MU–LP. Finally, moving to the overloaded MISO BC with heterogeneous CSIT qualities, a multi-layer power partitioning strategy that superimposes degraded symbols on top of linearly precoded rate-splitted symbols was shown in [33] to achieve the optimal DoF region.|$|R
5000|$|Some {{cognitive}} {{scientists and}} graphic designers {{have emphasized the}} distinction between raw information and information in a form we can use in thinking. In this view, information overload may be better viewed as organization <b>underload.</b> That is, they suggest {{that the problem is}} not so much the volume of information but the fact that we can not discern how to use it well in the raw or biased form it is presented to us. Authors who have taken this tack include graphic artist and architect Richard Saul Wurman and statistician and cognitive scientist Edward Tufte. Wurman uses the term information anxiety to describe our attitude toward the volume of information in general and our limitations in processing it. Tufte primarily focuses on quantitative information and explores ways to organize large complex datasets visually to facilitate clear thinking. Tufte's writing is important in such fields as information design and visual literacy, which deal with the visual communication of information. Tufte coined the term [...] "chartjunk" [...] to refer to useless, non-informative, or information-obscuring elements of quantitative information displays, such as the use of graphics to overemphasize the importance of certain pieces of data or information.|$|E
30|$|Host <b>underload</b> detection: used {{to decide}} whether a host is underloaded.|$|E
30|$|With the {{automation}} of one {{or several}} driving tasks, driving may become radically simplified; this entails potential mental <b>underload,</b> meaning that that the driving task may become oversimplified, resulting in boredom, cognitive <b>underload,</b> and eventually increased drowsiness and loss of situation awareness. In the long run, {{there is also a}} risk of skill degeneration [22].|$|E
40|$|Motivated by service {{systems with}} {{time-varying}} customer arrivals, we consider a fluid model as a macroscopic approximation for many-server Markovian queues alternating between <b>underloaded</b> and overloaded intervals. Our main {{result is a}} refinement of the piecewise stationary approximation (PSA) for the stationary distribution of the fluid model. The form of the refined approximation suggests simple metrics for assessing the accuracy of PSA for <b>underloaded</b> and overloaded intervals respectively. © 2012 Elsevier B. V. All rights reserved...|$|R
30|$|Beloglazov and Buyya [3] {{analyzed}} {{historical data}} of resource usage of VMs and proposed dynamic VM consolidation {{that can be}} split into four parts. First, they checked whether a host is overloaded. If it is, then decision is made to migrate some VMs from this particular host to another. Second, selection of VMs is done to decide the list of VMs that should be migrated from overloaded host. Third, checking is done to decide whether a host is <b>underloaded</b> and all VMs are needed to migrate to other hosts. Fourth, hosts have been selected to place the migrated VMs from overloaded and <b>underloaded</b> hosts. For VM placement optimization, they propose an algorithm which scans through the list of hosts and then tries to detect the hosts that are overloaded. If overloaded hosts are found then the algorithm tries to pick the VMs that are needed to be migrated from one host to another by applying any of the suitable VM selection policies. Once the list of VMs are created, the VM placement algorithm is executed {{to find a new}} placement for the migrated VMs. VM placement for <b>underloaded</b> host works in the similar fashion. After finding suitable host for all VMS from the <b>underloaded</b> host, the host is shut down or put in sleeping mode. The algorithm then returns the migration map which has the combined information of new VM placement which is needed to be migrated from both overloaded and <b>underloaded</b> hosts. They proposed a modified version of BFD (best fit decreasing) for VM placement solution.|$|R
3000|$|More {{results of}} <b>underloaded</b> two-user {{deployments}} with imperfect CSIT {{are given in}} Appendix 2. The rate regions of different strategies for varied SNR, N [...]...|$|R
40|$|There is {{considerable}} {{evidence in the}} ergonomics literature that automation can significantly reduce operator mental workload. Furthermore, reducing mental workload {{is not necessarily a}} good thing, particularly in cases where the level is already manageable. This raises the issue of mental <b>underload,</b> which can be at least as detrimental to performance as overload. However, although it is widely recognised that mental <b>underload</b> is detrimental to performance, there are very few attempts to explain why this may be the case. It is argued in this paper that, until the need for a human operator is completely eliminated, automation has psychological implications relevant in both theoretical and applied domains. The present paper reviews theories of attention, as well as the literature on mental workload and automation, to synthesise a new explanation for the effects of mental <b>underload</b> on performance. Malleable Attentional Resources Theory proposes that attentional capacity shrinks to accommodate reductions in mental workload, and that this shrinkage is responsible for the <b>underload</b> effect. The theory is discussed with respect to the applied implications for ergonomics research...|$|E
40|$|Abstract — Although {{instability}} in packet networks has been traditionally associated with overload conditions (because queueing network models show that, in simple configurations, only overload generates instability), some results showing {{instability in}} underloaded packet networks {{have appeared in}} the recent literature. In [1] we studied, with fluid models and with adversarial queueing theory, possible <b>underload</b> instabilities due to complex scheduling algorithms, that closely resemble Quality of Service (QoS) schedulers considered today for packet networks, when sources are non-adaptive. In this paper we extend the study of the <b>underload</b> instabilities to packet networks carrying the traffic generated by elastic (rate-adaptive) sources. In particular, we consider Additive-Increase, Multiplicative-Decrease (AIMD) sources, and we show this type of adaptivity is not sufficient to mitigate the phenomena leading to <b>underload</b> instabilities and to reduced network throughput. I...|$|E
30|$|Static Threshold: It {{depends on}} {{the mean of the}} latest CPU {{utilization}} measurements and compares it with a predefined threshold. If the mean CPU utilization is lower than the threshold, a host <b>underload</b> is detected. Put in Kashyap et al [100] use 0.2 for host CPU <b>underload</b> threshold. The problem is that using constant values of the threshold will be useless especially in a heterogeneous environment. Because it is difficult to find an optimal value of this threshold useful for all host.|$|E
40|$|Fretting {{fatigue tests}} have been {{conducted}} on 7075 -T 7351 aluminum alloy coupons with fretting pads of the same material. Three different stress ratios were used, the otherwise constant amplitude axial loads being interrupted every 1000 cycles by either tensile overloads to 400 MPa or compressive <b>underloads</b> to- 200 MPa. Tensile overloads greatly prolonged fatigue life for low stresses where the overload ratios were 1. 6 and above; compressive <b>underloads</b> had comparatively little effect. The results are {{discussed in terms of}} crack growth retardation phenomena...|$|R
30|$|Source and destination: {{when the}} {{decision}} is taken to move some load, characteristics of source (among overloaded nodes) and of destination (among <b>underloaded</b> ones) should be specified.|$|R
3000|$|More {{results of}} <b>underloaded</b> three-user {{deployments}} with perfect CSIT and imperfect CSIT {{are given in}} Appendices 3 and Appendix 5, respectively. The WSRs of different strategies for varied SNR, N [...]...|$|R
40|$|This {{paper will}} discuss the effects of digital signal {{processing}} errors caused by improper analog to digital conversion settings. Four signal types will be analyzed: overload and <b>underload</b> on the input channel; and, overload and <b>underload</b> on the response channel. The errors will be shown to affect the quality and accuracy of the measured frequency response function. The errors which {{are present in the}} measurement will also be shown to exist as an inaccurate estimate of the modal residue obtained through curvefitting...|$|E
30|$|Host <b>underload</b> {{refers to}} the state of a host in which all VMs should be {{migrated}} from. In the literature, the two common techniques used for determining host <b>underload</b> state are the least utilized host and static threshold [14]. It is the process of finding the host with the minimum utilization compared to the other hosts. i.e. the host that all VMs should be migrated from, so it should be switched off. If all VMs from the source host cannot be allocated, the host is kept active.|$|E
40|$|Instability in packet-switching {{networks}} {{is normally}} associated with overload conditions, since queueing network models show that, in simple configurations, only overload generates instability. However, some results showing that instability can happen also in underloaded queueing networks {{appeared in the}} recent literature. <b>Underload</b> instabilities can be produced by complex scheduling algorithms, that bear significant resemblance to the Quality of Service (QoS) schedulers considered today for packet networks. In this paper, we study with fluid models and with adversarial queueing theory possible <b>underload</b> instabilities due to strict-priority schedulers and to Generalized Processor Sharing (GPS) schedulers...|$|E
40|$|Abstract. Earliest {{deadline}} rst (edf) is {{a widely}} used algorithm for online deadline scheduling. It {{has been known for}} long that edf is optimal for scheduling an <b>underloaded,</b> single-processor system; recent results on the extra-resource anal-ysis of edf further revealed that edf when using moderately faster processors can achieve optimal performance in the <b>underloaded,</b> multi-processor setting. This pa-per initiates the extra-resource analysis of edf for overloaded systems, showing that edf supplemented with a simple form of admission control can provide a similar performance guarantee in both the single and multi-processor settings. Key words: online algorithms, extra-resource analysis, rm deadline scheduling, earli-est deadline rst. ...|$|R
40|$|Earliest {{deadline}} first (EDF) is {{a widely}} used algorithm for online deadline scheduling. It {{has been known for}} long that EDF is optimal for scheduling an <b>underloaded,</b> single-processor system; recent results on the extra-resource analysis of EDF further revealed that EDF when using moderately faster processors can achieve optimal performance in the <b>underloaded,</b> multi-processor setting. This paper initiates the extra-resource analysis of EDF for overloaded systems, showing that EDF supplemented with a simple form of admission control can provide a similar performance guarantee in both the single and multi-processor settings. © 2003 Elsevier Inc. All rights reserved. postprin...|$|R
3000|$|... = 2) {{and serves}} three single-antenna users. The channel realizations and {{beamforming}} initialization follows {{the methods used}} in the <b>underloaded</b> three-user deployment. The channel of users are realized as h 1 =[1, 1] [...]...|$|R
40|$|The {{aim of this}} {{research}} is to investigate the role of information system in supporting companies to face with information overload. Specifically, the study provides an empirical analysis aimed to examine whether the quality of information systems is able to abate the negative effects of information overload/underload inside a company. Through a survey we assess the managerial feelings about the information overload (and <b>underload)</b> and the managerial assessment of the Information System (IS) quality. Preliminary empirical findings of our survey confirm, by performing a factor analysis, previous literature and suggest the items to be monitored for assessing the information <b>underload</b> and information overload phenomena and the dimensions to take into account for evaluating the IS quality, namely, information processing capacity, technical equipment and communication. Furthermore, results show that when the information <b>underload</b> increases, the information processing capacity of IS decreases and vice versa. This relation suggests that the IS quality could affect the information overload/underload phenomena...|$|E
40|$|A {{workshop}} {{was conducted}} whose specific {{purpose was to}} build on earlier work of the United States National Research Council, United States Federal government agencies, and the larger human factors community to: (1) clarify human factors issues pertaining to degraded performance in advanced human-machine systems (e. g., nuclear production, transportation, aerospace) due to human work <b>underload</b> and workload transition, and (2) develop strategies for resolving these issues. Recent history demonstrates that: (1) humans often react adversely to their diminishing roles in advanced human-machine systems, and therefore (2) new allocation models and strategies are required if humans are to be {{willing and able to}} assume diminishing and shifting roles assigned to them in these systems, and are to accept new technologies making up these systems. Problems associated with theses diminishing and shifting human roles are characterized as work <b>underload</b> and workload transitions. The workshop affirmed that: (1) work <b>underload</b> and workload transition are issues {{that will have to be}} addressed by designers of advanced human-machine systems, especially those relying on automation, if cost, performance, safety, and operator acceptability are to be optimized, (2) human machine allocation models, standards, and guidelines which go beyond simple capability approaches will be needed to preclude or seriously diminish the work <b>underload</b> and workload transition problems, and (3) the 16 workload definition, measurement, situational awareness, and trust issues identified during the workshop, need resolution if these models, standards, and guidelines are to be achieved...|$|E
40|$|A {{workshop}} {{was conducted}} in which the specific purpose was to build on earlier work by the National Research Council, Federal Government agencies, and the larger human factors community to: (1) clarify human factors issues pertaining to degraded performance in advanced transportation systems due to human work <b>underload</b> and workload transition; and (2) develop strategies for resolving these issues. The workshop affirmed that: (1) work <b>underload</b> and workload transition are issues {{that will have to}} be addressed by designers of human-automation operating configurations, if cost, performance, safety, and user acceptability are to be optimized, (2) human function allocation models, standards, and guidelines which go beyond simple capability approaches will be needed to preclude or seriously diminish the work <b>underload</b> and workload transition problems, and (3) the issues identified during the workshop, need resolution if these models, standards, and guidelines are to be achieved. In trod uc t ion Research on issues unique to human workload allocation, particularly with regard to advanced mechanical technologies (e. g., "smart " vehicle...|$|E
30|$|This {{strategy}} is RID, except that an <b>underloaded</b> node demands a migration from the maximum loaded node in its neighborhood. Hence, a heavily loaded node may respond to many requests of migrations during one cycle.|$|R
30|$|A node classifies entries {{of local}} cache into 40 % <b>underloaded,</b> 20 % intermediate, and 40 % overloaded. It compares its own load and takes {{decision}} {{of participating in}} load balancing according to the selected strategy.|$|R
40|$|Earliest {{deadline}} first (EDF) is a widely-used online algorithm for scheduling {{jobs with}} deadlines in real-time systems. Yet, existing {{results on the}} performance guarantee of EDF are limited to <b>underloaded</b> systems [4, 12, 10]. This paper initiates the study of EDF for overloaded systems, attaining similar performance guarantees as in the <b>underloaded</b> setting. Speci cally, we show that EDF with a simple form of admission control is optimal for scheduling on both uniprocessor and multiprocessors when moderately faster processors are available (our analysis actually admits a tradeoff between speed and extra processors). This is the first result attaining optimality under overload. Another contribution {{of this paper is}} an improved analysis of the competitiveness for weighted deadline scheduling...|$|R
30|$|When VM {{needs to}} be {{migrated}} to another datacenter in VM placement phase or <b>underload</b> detection phase, the destination host {{needs to be}} judged {{whether it will be}} overloaded in future by using overload detection method.|$|E
40|$|Fatigue {{crack growth}} tests were {{conducted}} on 0. 09 inch thick, 3. 0 inch wide middle-crack tension specimens cut from sheets of 2024 -T 3 aluminum alloy. The {{tests were conducted}} using a load sequence that consisted of a single block of 2, 500 cycles of constant amplitude loading followed by an overload/underload combination. The largest fatigue crack growth life occurred for the tests with the overload stress equal to 2 times the constant amplitude stress and the <b>underload</b> stress equal to the constant amplitude minimum stress. For the tests with compressive underloads, the fatigue crack growth life decreased with increasing compressive <b>underload</b> stress...|$|E
40|$|The {{ultimate}} goal of research efforts directed at <b>underload,</b> boredom, or complacency in high-technology work environments is to detect conditions or states of the operator that can be demonstrated to lead to performance degradation, and then {{to intervene in the}} environment to restore acceptable system performance. Physiological measures may provide indices of changes in condition or state of the operator that may be of value in high-technology work environments. The focus {{of the present study was}} on the use of physiological measures in the assessment of operator condition or state in a task <b>underload</b> scenario. A fault acknowledgement task characterized by simple repetitive responses with minimal novelty, complexity, and uncertainty was employed to place subjects in a task <b>underload</b> situation. Physiological measures (electrocardiogram (ECG), electroencephalogram (EEG), and pupil diameter) were monitored during task performance over a one-hour test session for 12 subjects. Each of the physiological measures exhibited changes over the test session indicative of decrements in subject arousal level. While high correlations between physiological measures were found across subjects, individual differences between subjects support the use of profiling techniques to establish baselines unique to each subject...|$|E
40|$|Unstructured P 2 P {{networks}} support {{distributed applications}} whose workload may vary significantly {{over time and}} between nodes. Self-optimizing systems {{try to keep the}} load in the network balanced despite the frequent load fluctuations. Several P 2 P systems exhibit a number of related features but fail to avoid centralisation under high-load situations. ERGO aims to balance the overloaded nodes by rewiring some of their incoming links to <b>underloaded</b> ones via a set of interconnected servers which index the <b>underloaded</b> nodes. In two simulated environments, ERGO load-balancing on Gnutella network increases the balanced nodes and network availability by preserving its efficiency and even reducing its messages. © 2008 Elsevier B. V. All rights reserved...|$|R
40|$|The {{object of}} this study was to {{determine}} whether prostaglandin E 2 (PGE 2) can prevent disuse (<b>underloading)</b> -induced cancellous bone loss. Thirteen-month-old retired female Sprague-Dawley breeders served as controls or were subjected to right hindlimb immobilization by bandaging and simultaneously treated subcutaneously daily with 0, 1, 3, or 6 mg PGE 2 /kg/d for two and six weeks. Histomorphometric analyses were performed on the cancellous bone using double-fluorescent labeled, 20 micron thick, undecalcified distal femoral metaphysis sections. We found that PGE 2 administration not only prevented disuse-induced bone loss, but also added extra bone to disuse cancellous bone in a dose-response manner. PGE 2 prevented the disuse-induced osteopenia by stimulating more bone formation than and shortening the period of bone remodeling. It activated woven bone formation, stimulated lamellar bone formation, and increased the eroded bone surface above that caused by disuse alone. While <b>underloading</b> increased the remodeling period (sigma), PGE 2 treatment of <b>underloaded</b> bone shortened the time for osteoclastic bone resorption and bone remodeling, and thus reduced the remodeling space. The study shows that PGE 2 is a powerful anabolic agent that prevents disuse-induced osteopenia and adds extra bone to these same bones...|$|R
30|$|An <b>underloaded</b> node {{looks in}} its {{neighborhood}} for overloaded nodes to migrate loads from. A possible source node is chosen at random. Hence, in each cycle, the initiator can receive only one job while the sender may send several jobs to different nodes.|$|R
