1378|482|Public
2500|$|Conceptual {{clustering}} is {{a machine}} learning paradigm for <b>unsupervised</b> <b>classification</b> developed mainly during the 1980s. [...] It is distinguished from ordinary data clustering by generating a concept description for each generated class. [...] Most conceptual clustering methods {{are capable of}} generating hierarchical category structures; [...] see Categorization {{for more information on}} hierarchy. [...] Conceptual clustering is closely related to formal concept analysis, decision tree learning, and mixture model learning.|$|E
2500|$|Class {{discovery}} analysis: This analytic approach, {{sometimes called}} <b>unsupervised</b> <b>classification</b> or knowledge discovery, tries to identify whether microarrays (objects, patients, mice, etc.) or genes cluster together in groups. Identifying naturally existing groups of objects (microarrays or genes) which cluster together can enable {{the discovery of}} new groups that otherwise were not previously known to exist. During knowledge discovery analysis, various <b>unsupervised</b> <b>classification</b> techniques can be employed with DNA microarray data to identify novel clusters (classes) of arrays. This type of approach is not hypothesis-driven, but rather is based on iterative pattern recognition or statistical learning methods to find an [...] "optimal" [...] number of clusters in the data. Examples of unsupervised analyses methods include self-organizing maps, neural gas, k-means cluster analyses, hierarchical cluster analysis, Genomic Signal Processing based clustering and model-based cluster analysis. For some of these methods the user also has to define a distance measure between pairs of objects. Although the Pearson correlation coefficient is usually employed, several other measures have been proposed and evaluated in the literature. The input data used in class discovery analyses are commonly based on lists of genes having high informativeness (low noise) based on low values of the coefficient of variation or high values of Shannon entropy, etc. The determination of the most likely or optimal number of clusters obtained from an unsupervised analysis is called cluster validity. Some commonly used metrics for cluster validity are the silhouette index, Davies-Bouldin index, Dunn's index, or Hubert's [...] statistic.|$|E
5000|$|A {{variety of}} {{supervised}} and <b>unsupervised</b> <b>classification</b> algorithms; ...|$|E
40|$|Land cover {{information}} {{derived from}} LANDSAT is being utilized by Piedmont Planning District Commission {{located in the}} State of Virginia. Progress to date is reported on a level one land cover classification map being produced with nine categories. The nine categories of classification are defined. The computer compatible tape selection is presented. Two <b>unsupervised</b> <b>classifications</b> were done, with 50 and 70 classes respectively. Twenty-eight spectral classes were developed using the supervised technique, employing actual ground truth training sites. The accuracy of the <b>unsupervised</b> <b>classifications</b> are estimated through comparison with local county statistics and with an actual pixel count of LANDSAT information compared to ground truth...|$|R
40|$|In this paper, {{we discuss}} about hyperspectral image {{processing}} where it {{plays an important}} role in remote sensing, hyperspectral verses multispectral image processing and image classifications. Where these classifications includes image sensors, image preprocessing, object detection, object segmentation, feature extraction and object classification. Mainly there are two types of classifications we are describing they are supervised and <b>unsupervised</b> <b>classifications...</b>|$|R
40|$|Abstract – Satellite data, such as {{obtained}} by Landsat 5 or 7 sensors, can be effectively used for large-area land cover classifications. Given that approximately 50 % {{of the earth}} is covered in cloud at any time, one of the significant challenges in creating repeatable and robust classifications is to understand and appropriately address cloud contamination in Landsat images. The scope {{of many of the}} large area mapping projects and the associated large volumes of data to be processed suggest that <b>unsupervised</b> <b>classifications</b> and automated processes may be necessary to obtain timely results. An experiment was developed to investigate the effect of cloud contamination on <b>unsupervised</b> <b>classifications.</b> It was determined that when a small number of classes are used cloud effects in the cloud-free portion of the scene can often be managed by allocating the majority of clusters to clouds. When a large number of classes are required, clouds significantly skew the non-cloud cluster characteristics. I...|$|R
5000|$|... {{supervised}} and <b>unsupervised</b> <b>classification</b> and typology, {{artificial intelligence}} applications ...|$|E
5000|$|Supervised and <b>unsupervised</b> <b>classification</b> {{operations}} in all {{versions of the}} software currently can process only four image bands at a time.|$|E
50|$|In case of <b>unsupervised</b> <b>classification</b> {{no prior}} {{knowledge}} {{is required for}} classifying {{the features of the}} image. The natural clustering or grouping of the pixel values, i.e. the gray levels of the pixels, are observed. Then a threshold is defined for adopting the number of classes in the image. The finer the threshold value, the more classes there will be. However, beyond a certain limit the same class will be represented in different classes in the sense that variation in the class is represented. After forming the clusters, ground truth validation is done to identify the class the image pixel belongs to. Thus in this <b>unsupervised</b> <b>classification</b> apriori information about the classes is not required. One of the popular methods in <b>unsupervised</b> <b>classification</b> is K means classifier algorithm.|$|E
40|$|Information on the {{location}} and evolution of shorelines is valuable. This information {{can be obtained from}} satellite Synthetic Aperture Radar (SAR) imagery. Direct, <b>unsupervised</b> <b>classifications</b> methods give poor results because of the high noise level in SAR images and the scattering properties of (wet) land and water. In this project is investigated how the phase information in Single Look Complex (SLC) SAR data can be used to give better results...|$|R
40|$|Data mining is an {{iterative}} development {{within which}} evolution {{is defined by}} discovery, through either usual or manual methods. In this paper using the data mining concept to CDMCA classifies two types supervised and <b>unsupervised</b> <b>classifications.</b> Here illustrate the classification of supervised data mining algorithms base on diabetes disease dataset. It encompass the diseases plasma glucose at least mentioned value. The research describes algorithmic discussion of C 4. 5...|$|R
40|$|We {{present a}} method for <b>unsupervised</b> content based <b>classification</b> of images. The idea is to first segment the images using {{centroid}} models common to all the images in the set and then through bringing an analogy between models /images and words/documents to apply algorithms {{from the field of}} <b>unsupervised</b> document <b>classification</b> to cluster the images...|$|R
5000|$|Image Classification — Categorization of pixels {{based on}} {{reflectance}} into different land cover classes (e.g. Supervised classification, <b>Unsupervised</b> <b>classification</b> and Object Oriented Classification) ...|$|E
5000|$|... band-ratioed, band-differenced, thermal, {{multiband}} (including derived panchromatic), NDVI, <b>unsupervised</b> <b>classification,</b> spectral classification and stereo anaglyph displays {{added to}} the gray-level, multiband (pseudo-color only) and supervised classification displays of MicroMSI for DOS ...|$|E
50|$|<b>Unsupervised</b> <b>classification</b> (also termed cluster analysis) is also {{commonly}} used to discover patterns in complex data sets, and again many of the core techniques used in chemometrics are common to other fields such as machine learning and statistical learning.|$|E
40|$|<b>Unsupervised</b> data <b>classification</b> (or clustering) {{analysis}} {{is one of}} the most useful tools and a descriptive task in data mining that seeks to classify homogeneous groups of objects based on similarity and is used in many medical disciplines and various applications. In general, there is no single algorithm that is suitable for all types of data, conditions, and applications. Each algorithm has its own advantages, limitations, and deficiencies. Hence, research for novel and effective approaches for <b>unsupervised</b> data <b>classification</b> is still active. In this paper a heuristic algorithm, Biogeography-Based Optimization (BBO) algorithm, was adapted for data clustering problems by modifying the main operators of BBO algorithm, which is inspired from the natural biogeography distribution of different species. Similar to other population-based algorithms, BBO algorithm starts with an initial population of candidate solutions to an optimization problem and an objective function that is calculated for them. To evaluate the performance of the proposed algorithm assessment was carried on six medical and real life datasets and was compared with eight well known and recent <b>unsupervised</b> data <b>classification</b> algorithms. Numerical results demonstrate that the proposed evolutionary optimization algorithm is efficient for <b>unsupervised</b> data <b>classification...</b>|$|R
40|$|This paper {{presents}} a contextual algorithm for the computation of Baum’s {{forward and backward}} probabilities, which are intensively used {{in the framework of}} Hidden Markov Chain (HMC) models. The method differs from the original algorithm since it only takes into account a neighborhood of limited length and not all the chain for computations. Comparative experiments with respect to the neighborhood size have been conducted on both Markovian (simulations) and not Markovian (images) data, by mean of supervised and <b>unsupervised</b> <b>classifications.</b> 1...|$|R
40|$|<b>Unsupervised</b> image <b>classification</b> of Landsat MSS imagery {{entails a}} {{significant}} part of the remote sensing, image analysis effort. Expert systems, a technology developed in the field of artificial intelligence, offers the potential to automate this process, thus greatly increasing the efficiency with which an analyst can perform <b>unsupervised</b> image <b>classification</b> and making the knowledge of the image analyst available to a community of nonexperts. Such a system, under development at the NASA/Ames Research Center, is described and planned enhancements are discussed...|$|R
5000|$|MML {{has been}} in use since 1968. MML coding schemes have been {{developed}} for several distributions, and many kinds of machine learners including <b>unsupervised</b> <b>classification,</b> decision trees and graphs, DNA sequences, Bayesian networks, neural networks (one-layer only so far), image compression, image and function segmentation, etc.|$|E
50|$|<b>Unsupervised</b> <b>classification</b> (also {{known as}} clustering) {{is a method}} of {{partitioning}} remote sensor image data in multispectral feature space and extracting land-cover information. <b>Unsupervised</b> <b>classification</b> require less input information from the analyst compared to supervised classification because clustering does not require training data. This process consists {{in a series of}} numerical operations to search for the spectral properties of pixels. From this process, a map with m spectral classes is obtained. Using the map, the analyst tries to assign or transform the spectral classes into thematic information of interest (i.e. forest, agriculture, urban). This process may not be easy because some spectral clusters represent mixed classes of surface materials and may not be useful. The analyst has to understand the spectral characteristics of the terrain to be able to label clusters as a specific information class. There are hundreds of clustering algorithms. Two of the most conceptually simple algorithms are the chain method and the ISODATA method.|$|E
50|$|Conceptual {{clustering}} is {{a machine}} learning paradigm for <b>unsupervised</b> <b>classification</b> developed mainly during the 1980s. It is distinguished from ordinary data clustering by generating a concept description for each generated class. Most conceptual clustering methods {{are capable of}} generating hierarchical category structures; see Categorization {{for more information on}} hierarchy. Conceptual clustering is closely related to formal concept analysis, decision tree learning, and mixture model learning.|$|E
40|$|<b>Unsupervised</b> data <b>classification</b> can be {{considered}} one of the most important initial steps in the process of data mining. Numerous algorithms have been developed and are being used in this context in a variety of application domains, albeit, only little evidence is available as to which algorithms should be used in which context, and which techniques offer promising results when being combined for a given task. In this paper we present an empirical evaluation of some prominent <b>unsupervised</b> data <b>classification</b> techniques with respect to their usability and the interpretability of their result representation...|$|R
40|$|<b>Unsupervised</b> image <b>classification</b> is {{the process}} by which each image in a dataset is {{identified}} {{to be a member of}} one of the inherent categories present in the image collection without the use of labelled training samples. Unsupervised categorisation of images relies on unsupervised machine learning algorithms for its implementation. This paper identifies clustering algorithms and dimension reduction algorithms as the two main classes of unsupervised machine learning algorithms needed in unsupervised image categorisation, and then reviews how these algorithms are used in some notable implementation of <b>unsupervised</b> image <b>classification</b> algorithms...|$|R
40|$|This paper {{proposes a}} novel {{approach}} for processing digital mammograms to detect micro-calcifications. They may be so small that they are almost undetectable visually, {{but it could be}} indicators of a possible malignancy. An analysis algorithm based on optical holographic property of images and clustering principles are proposed to detect the micro-calcifications. This process consists of three stages. In the first stage the mammographic patterns are subjected to optical holographic analysis. The resulting images are passed to the second stage, in which morphological operations are performed. The third stage detects the malignant portions of the mammographic pattern using <b>unsupervised</b> texture <b>classification</b> by extracting laws features. Texture classification is an important image processing task with a broad application range. Many different techniques for texture classification have been explored. This paper explores the <b>unsupervised</b> <b>classifications</b> of digital mammograms using K-means and Fuzzy C-means approaches. Results show that the proposed techniques detect the malignant portions of the breast very well thus enabling earlier detection of tumor...|$|R
5000|$|Class {{discovery}} analysis: This analytic approach, {{sometimes called}} <b>unsupervised</b> <b>classification</b> or knowledge discovery, tries to identify whether microarrays (objects, patients, mice, etc.) or genes cluster together in groups. Identifying naturally existing groups of objects (microarrays or genes) which cluster together can enable {{the discovery of}} new groups that otherwise were not previously known to exist. During knowledge discovery analysis, various <b>unsupervised</b> <b>classification</b> techniques can be employed with DNA microarray data to identify novel clusters (classes) of arrays. This type of approach is not hypothesis-driven, but rather is based on iterative pattern recognition or statistical learning methods to find an [...] "optimal" [...] number of clusters in the data. Examples of unsupervised analyses methods include self-organizing maps, neural gas, k-means cluster analyses, hierarchical cluster analysis, Genomic Signal Processing based clustering and model-based cluster analysis. For some of these methods the user also has to define a distance measure between pairs of objects. Although the Pearson correlation coefficient is usually employed, several other measures have been proposed and evaluated in the literature. The input data used in class discovery analyses are commonly based on lists of genes having high informativeness (low noise) based on low values of the coefficient of variation or high values of Shannon entropy, etc. The determination of the most likely or optimal number of clusters obtained from an unsupervised analysis is called cluster validity. Some commonly used metrics for cluster validity are the silhouette index, Davies-Bouldin index, Dunn's index, or Hubert's [...] statistic.|$|E
5000|$|Categorization {{tasks in}} which {{category}} labels are {{provided to the}} learner for certain objects {{are referred to as}} supervised classification, supervised learning, or concept learning. Categorization tasks in which no labels are supplied are referred to as <b>unsupervised</b> <b>classification,</b> unsupervised learning, or data clustering. The task of supervised classification involves extracting information from the labeled examples that allows accurate prediction of class labels of future examples. This may involve the abstraction of a rule or concept relating observed object features to category labels, or it may not involve abstraction (e.g., exemplar models). The task of clustering involves recognizing inherent structure in a data set and grouping objects together by similarity into classes. It is thus a process of generating a classification structure.|$|E
5000|$|There is {{an ongoing}} debate about how to judge {{the results of these}} methods, as biclustering allows overlap between {{clusters}} and some algorithms allow the exclusion of hard-to-reconcile columns/conditions. Not all of the available algorithms are deterministic and the analyst must pay attention to the degree to which results represent stable minima. Because this is an <b>unsupervised</b> <b>classification</b> problem, the lack of a gold standard makes it difficult to spot errors in the results. One approach is to utilize multiple biclustering algorithms, with majority or super-majority voting amongst them deciding the best result. Another way is to analyse the quality of shifting and scaling patterns in biclusters. Biclustering has been used in the domain of text mining (or classification) where it is popularly known as co-clustering [...] Text corpora are represented in a vectorial form as a matrix D whose rows denote the documents and whose columns denote the words in the dictionary. Matrix elements Dij denote occurrence of word j in document i. Co-clustering algorithms are then applied to discover blocks in D that correspond to a group of documents (rows) characterized by a group of words(columns).|$|E
40|$|Cluster {{analysis}} of morphometric variable is {{reported in this}} paper to support characterization of rock masses and deposits. The first technique is related to fast mechanical characterization of bedrock and the second one on the mapping of the depth of superficial deposits. In order to extrapolate site-specific information to the whole study area two techniques are applied to morphometric space: supervised and <b>unsupervised</b> <b>classifications</b> through the algorithms maximum likelihood and ISODATA, respectively. The {{analysis of}} morphometric space with these techniques has provided significant results in order to discriminate bedrocks with different mechanical characteristics {{and the depth of}} superficial deposits...|$|R
40|$|A {{wetlands}} monitoring {{study was}} initiated {{as part of}} Delaware's LANDSAT applications demonstration project. Classifications of digital data are conducted {{in an effort to}} determine the location and acreage of wetlands loss or gain, species conversion, and application for the inventory and typing of freshwater wetlands. A multi-seasonal approach is employed to compare data from two different years. <b>Unsupervised</b> <b>classifications</b> were conducted for two of the four dates examined. Initial results indicate the multi-seasonal approach allows much better separation of wetland types for both tidal and non-tidal wetlands than either season alone. Change detection is possible but generally misses the small acreages now impacted by man...|$|R
40|$|We {{present a}} method for a {{supervised}} classification of Normalized Difference Vegetation Index (NDVI) time series that identifies vegetation type and vegetation coverage, absolute in %coverage or relative to a reference NDVI cycle. The shape of the NDVI cycle, which is diagnostic for certain vegetation types, is our primary classifier. A Discrete Fourier Filter is applied to time series data {{in order to minimize}} the influence of high-frequency noise on class assignments. Similarity between filtered NDVI cycles is evaluated using a linear regression technique. The correlation coefficients calculated between the Fourier filtered reference cycle and likewise filtered target cycles describe the similarity of their phenology, and the corresponding regression coefficients are an expression of coverage relative to the reference. The regression coefficients are correlated with field measured vegetation coverage. The Fourier Filtered Cycle Similarity method (FFCS) compensates phenological shifts, which are typical in areas with a strong climate gradient, and prevents the break-up of classes of identical vegetation types on the basis of vegetation coverage. Some other advantages compared to traditional <b>unsupervised</b> <b>classifications</b> are: synoptic visualization of vegetation type and coverage variation, independence from scene statistics, and consistent classification of biophysical characteristics only, without rock/soil reflectance dominating class assignment as it often does in <b>unsupervised</b> <b>classifications</b> of sparsely vegetated areas. Using the FFCS classification we differentiated a total of five rangeland vegetation types for the area of Syria including their intra-class coverage variation. Classified classes are dominated by one of two shrub types, one of two annual grass types or a bare soil/sparsely vegetated type. 1...|$|R
40|$|A popular {{method for}} <b>unsupervised</b> <b>classification</b> of high-dimensional data via {{decision}} trees is characterized as minimizing the empirical estimate of a concave information functional. It is shown that minimization of such functionals under the true distributions leads to perfect classification. Key words: Decision trees, clustering, <b>unsupervised</b> <b>classification,</b> information functionals, disjoint supports...|$|E
40|$|<b>Unsupervised</b> <b>classification</b> methods learn a discriminative {{classifier}} from unlabeled data, {{which has}} been proven {{to be an effective}} way of simultaneously clustering the data and training a classifier from the data. Various <b>unsupervised</b> <b>classification</b> methods obtain appealing results by the classifiers learned in an unsupervised manner. However, existing methods do not consider the misclassification error of the unsupervised classifiers except unsupervised SVM, so the performance of the unsupervised classifiers is not fully evaluated. In this work, we study the misclassification error of two popular classifiers, i. e. the nearest neighbor classifier (NN) and the plug-in classifier, in the setting of <b>unsupervised</b> <b>classification.</b> Comment: Submitted to ALT 201...|$|E
40|$|Knee scans is {{very useful}} and {{effective}} technique {{to detect the}} knee joint defects. <b>Unsupervised</b> <b>Classification</b> is useful {{in the absence of}} domain expert. Real Knee Magnetic Resonance Images have been collected from the MRI centres. Segmentation is implemented using Active Contour without Edges. DICOM, Haralick and some Statistical features have been extracted out. A database file of 704 images with 46 features per images has been prepared. <b>Unsupervised</b> <b>Classification</b> is implemented with clustering using EM model and then classification using different classifiers. Learning rate of 5 classifiers (ID 3, J 48, FID 3 new, Naive Bayes, and Kstar) has been calculated. At the obtained learning rate minimal feature set has been obtained for <b>unsupervised</b> <b>classification</b> of Knee MR Images...|$|E
40|$|Abstract — In {{this paper}} the {{potential}} of combining polarimetric and interferometric classification approaches to classify forest is evaluated. First, forest classes, obtained from the application of polarimetric classification algorithms based on second order statistical properties and scattering properties of the data, are examined for their correlations with ground truth measurements of forest types and growth stages. Then optimal coherences will be utilized to increase the separation between classes. Both supervised and <b>unsupervised</b> <b>classifications</b> will be compared, and a new forest classification technique will be developed. In addition, we will evaluate the effect of interferometric coherences on forest classification for various spatial and temporal baselines. Keywords- Polarimetric SAR; forest classification; polarimetric SAR interferometr...|$|R
40|$|Analyst {{variability}} in the labeling of <b>unsupervised</b> <b>classifications</b> is tested for Landsat 5 Thematic Mapper image products covering two test sites in southern California. The accuracy of results are tested using samples from a photo interpreted base map of the area. The significance of differences between analysts is indicated by comparing Kappa statistics derived from error matrices. Analyst variability {{is found to be}} statistically significant in most cases. Certain analysts provided consistently better results for a given study area or degree of training. This work demonstrates the potential influence of analyst bias on what would otherwise seem to be a fairly objective method and suggests that controls for this subjectivity should be factored into experimental designs...|$|R
40|$|To obtain {{potentially}} interesting {{patterns and}} relations from large, distributed, heterogeneous databases, {{it is essential}} to employ an intelligent and automated KDD (Knowledge Discovery in Databases) process. One of the most important methodologies is an integration of diverse learning strategies that cooperatively performs a variety of techniques and achieves high quality knowledge. AqBC is a multistrategy knowledge discovery approach that combines supervised inductive learning and <b>unsupervised</b> Bayesian <b>classification.</b> This study investigates creating a more suitable knowledge representation space with the aid of <b>unsupervised</b> Bayesian <b>classification</b> system, AutoClass. AutoClass discovers various kinds of patterns and implications in databases. Via constructive induction, these patterns modify the knowledge representation space so that the robust inductive learning system, AQ 15 c, learns useful concept descriptions of a taxonomy. AqBC applied to two different sample problems yields not only simple but also meaningful knowledge due to the systems that implement its parent approaches. Two statistical classification techniques (K-means centroid & Ward hierarchical clustering) are also applied to the data for comparison. AqBC's good performance appears to be due to its integration of reliable <b>unsupervised</b> Bayesian <b>classification,</b> constructive induction and rule induction, and not to th...|$|R
