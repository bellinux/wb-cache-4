16|26|Public
50|$|For small samples the chi-squared {{approximation}} is overly sensitive, often {{rejecting the}} null hypothesis when it is true. Furthermore, the distribution of p-values departs from a uniform distribution and becomes a right-skewed <b>uni-modal</b> <b>distribution,</b> especially for small p-values. This leads to a large Type I error rate. The table below shows some p-values approximated by a chi-squared distribution that differ from their true alpha levels for small samples.|$|E
40|$|Happiness in {{nations is}} {{typically}} measured in surveys using a single question. A common question is: ‘all things considered, how satisfied or dissatisfied {{are you with}} your life as-a-whole these days {{on a scale from}} 0 to 10 ?’. The responses typically follow a <b>uni-modal</b> <b>distribution</b> with highest frequencies between 5 and 8. Yet in some nations, the percentage of 10 responses stands out and is higher than the percentage of 9 responses. This is particularly present in Latin America and in the Middle East. In this paper we explore the prevalence of the ‘ 10 -excess’ pattern and check some possible explanations. We conclude that the 10 -excess phenomenon is partly due to cultural influence...|$|E
40|$|Evidence {{points to}} the {{existence}} of a “missing middle ” in the size distribution of firms in developing countries. Furthermore, the “missing middle ” seems to disappear as a country develops. In this paper, we develop a dynamic model to understand the evolution of the firm size distribution in developing countries. Unlike existing explanations, our model does not rely on frictions to generate the bi-modality in size distribution. Rather, the bi-modality arises due to agents optimally selecting into a traditional and a modern sector. The key parameter in our model is the mean knowledge of the newborns. For a low mean, the two sectors co-exist. As the mean rises, the size distribution converges from a bi-modal to an <b>uni-modal</b> <b>distribution.</b> We present some evidence to support our hypothesis. ...|$|E
40|$|Using a {{microscopic}} model for stochastic transport through a single quantum dot that is modified by the Coulomb interaction of environmental (weakly coupled) quantum dots, we derive generic {{properties of the}} full counting statistics for multi-stable Markovian transport systems. We study the temporal crossover from multi-modal to broad <b>uni-modal</b> <b>distributions</b> depending on the initial mixture, the long-term asymptotics and the divergence of the cumulants {{in the limit of}} a large number of transport branches. Our findings demonstrate that the counting statistics of a single resonant level may be used to probe background charge configurations. Comment: slighly expanded explanations, PRB in pres...|$|R
40|$|Docking {{calculations}} {{have been}} conducted on 36 cellulase enzymes {{and the results were}} evaluated by a machine learning algorithm to determine the nature of the enzyme (i. e. endo- or exo- enzymatic activity). The docking calculations have also been used to identify crucial substrate-enzyme interactions, and establish structure-function relationships. The use of carboxymethyl cellulose as a docking substrate is found to correctly identify the endo- or exo- behavior of cellulase enzymes with 92 % accuracy while cellobiose docking calculations resulted in an 86 % predictive accuracy. The binding distributions for cellobiose have been classified into two distinct types; distributions with a single maximum or distributions with a bi-modal structure. It is found that the <b>uni-modal</b> <b>distributions</b> correspond to exo- type enzyme while a bi-modal substrate docking distribution corresponds to endo- type enzyme. These results indicate that the use of docking calculations and machine learning algorithms are a fast and computationally inexpensive method for predicting if a cellulase enzyme possesses primarily endo- or exo- type behavior, while also revealing critical enzyme-substrate interactions...|$|R
40|$|Abstract We {{develop an}} {{abstract}} notion of regression {{which allows for}} a non-parametric formulation of unbiasedness. We prove then that least quantile regression is unbiased in this sense even in the heteroscedastic case if the error distribution has a continuous, symmetric, and uni-modal density. An example shows that unbiasedness may break down even for smooth and symmetric but not <b>uni-modal</b> error <b>distributions.</b> We compare these results to those for least MAD and least squares regression...|$|R
40|$|Identifying lesions in the retinal {{vasculature}} using Retinal imaging is {{most often}} done on the green channel. However, the effect of colour and single channel analysis on feature extraction {{has not yet been}} studied. In this paper an adaptive colour transformation has been investigated and validated on retinal images associated with 10 -year stroke prediction, using principle component analysis (PCA). Histogram analysis indicated that while each colour channel image had a <b>uni-modal</b> <b>distribution,</b> the second component of the PCA had a bimodal distribution, and showed significantly improved separation between the retinal vasculature and the background. The experiments showed that using adaptive colour transformation, the sensitivity and specificity were both higher (AUC 0. 73) compared with when single green channel was used (AUC 0. 63) for the same database and image features...|$|E
40|$|Quality specifications, {{the level}} of {{performance}} required to facilitate clinical decision-making, not only have {{a central role in}} quality management in clinical laboratories, but are also essential for assuring the interpretation and utilization of laboratory information by clinicians. Laboratory tests have been grouped into five categories and the most suitable ways to communicate quality specifications to clinicians have been proposed. In particular, for tests with a <b>uni-modal</b> <b>distribution,</b> decision limits should replace the traditional reference values. For tests with a bi-modal distribution, in addition to reference values, some flags based on the uncertainty of laboratory data, can be included in the report. For tests used in patients monitoring and in evaluating the response to therapy, the reference change value or the most effective threshold of the difference between two consecutive results should be indicated. For tests/test batteries that require interpretative comments, these should be added on a regular basis. Lastly, pre- and post-test counseling is mandatory for genetic testing...|$|E
40|$|A new dataset for {{estimating}} {{the development of}} global inequality between 1820 and 2000 is presented, based on a large variety of sources and methods for estimating (gross household) income inequality. On this basis, and two sets of benchmarks for estimating between-country inequality (the Maddison 1990 benchmark and the recent 2005 ICP round), we estimate the evolution of global income inequality and {{of the number of}} people below various poverty lines over the past two centuries. We find that between 1820 and 1950 increasing per capita income is combined with increasing global inequality, and with an increase in the absolute number of people below the poverty line. After 1950 global inequality as measured by the Gini coefficient remains more or less constant, and also the number of poor starts to decline in absolute terms. It also appears that the global income distribution was uni-modal in the 19 th century, became increasingly bi-modal between 1910 and 1970 with two world wars, a depression and de-globalization, and was suddenly transformed back into a <b>uni-modal</b> <b>distribution</b> between 1980 and 2000. income inequality, historical development, world, regional development, Gini, global inequality, poverty lines, per capita income, income distribution...|$|E
40|$|Gaussian process emulators of {{computationally}} expensive computer codes provide fast statistical approximations {{to model}} physical processes. The training of these surrogates {{depends on the}} set of design points chosen to run the simulator. Due to computational cost, such training set is bound to be limited and quantifying the resulting uncertainty in the hyper-parameters of the emulator by <b>uni-modal</b> <b>distributions</b> is likely to induce bias. In order to quantify this uncertainty, this paper proposes a computationally efficient sampler based on an extension of Asymptotically Independent Markov Sampling, a recently developed algorithm for Bayesian inference. Structural uncertainty of the emulator is obtained as a by-product of the Bayesian treatment of the hyper-parameters. Additionally, the user can choose to perform stochastic optimisation to sample from a neighbourhood of the Maximum a Posteriori estimate, even in the presence of multimodality. Model uncertainty is also acknowledged through numerical stabilisation measures by including a nugget term in the formulation of the probability model. The efficiency of the proposed sampler is illustrated in examples where multi-modal distributions are encountered. For the purpose of reproducibility, further development, and use in other applications the code used to generate the examples is freely available for download at [URL] Computational Statistics & Data Analysis, Volume 103, November 201...|$|R
40|$|We {{develop an}} {{abstract}} notion of regression {{which allows for}} a non-parametric formulation of unbiasedness. We prove then that least quantile regression is unbiased in this sense even in the heteroscedastic case if the error distribution has a continuous, symmetric, and uni-modal density. An example shows that unbiasedness may break down even for smooth and symmetric but not <b>uni-modal</b> error <b>distributions.</b> We compare these results to those for least MAD and least squares regression. Key words Least Quantile { Regression { Unbiasedness { Fisher consistency { Quantile Derivative { Lord's paradox...|$|R
3000|$|..., and α 0 are {{the four}} {{parameters}} which fully describe the DMC and noise characteristics of each sub-band and are {{gathered in the}} DMC and noise parameter vector θdan. In this work, we will assume that the DMC is spatially white at the transmit and receive side of the measurement system, meaning that they have constant angular power densities. It {{should be noted that}} recent works will assume the DMC to be spatially correlated with the SMC. For example, [25, 45] report a correlation between the location of SMC and DMC in the angular domain. In [27], the DMC is modeled as local clusters around the SMC. In [20, 46], it is proposed that the Power Angular Profile (PAP) is to be modeled by a <b>uni-modal</b> Von-Mises <b>distribution.</b>|$|R
40|$|A high γ' volume {{fraction}} Ni-base superalloy (RR 1000) {{has been studied}} and its microstructural and mechanical response to the inertia welding process assessed. The bond line microstructure has been characterised in terms of process parameters and associated modelled temperature distributions. The high temperature mechanical behaviour has been interrogated via sustained load crack growth testing in air and vacuum. The weld microstructure is characterised by a <b>uni-modal</b> <b>distribution</b> of ultrafine γ' and a meta-dynamically recrystallised grain structure. The recrystallised grain size {{is determined by the}} width of the shear zone and the associated deformation behaviour, which varies with process parameter selection. Of particular importance is the welding pressure, which controls the upset rate, thereby limiting the shear zone width. A restricted shear zone can be related to increases in the peak bond line temperature and cooling rate. The high temperature crack growth behaviour is controlled by grain boundary oxide formation and crack tip stress state. In inertia welded RR 1000 this stress state is governed by the reprecipitated γ'. The steady state crack growth rate increases with temperature, which is due to an increased rate of oxide formation. Near threshold growth behaviour is also dependent on localised microstructural features. ...|$|E
40|$|This paper {{analyzes}} and {{predicts the}} changes of relationship between income and fertility rate of cross-countries using a bivariate mixture model and a latent change score model. This paper {{has shown that}} there is a negative relationship between income and fertility rate, which is presented in the form of inverted S-shaped curve which shows the three regimes of demographic transition. Some developed countries have completed their demographic transition in fertility rate, and in developing countries, the demographic transition in fertility rate is still in progress. This paper has also shown that the number of peaks of income distribution has increased in recent years comparing to 1960 s and the number won't decrease in the future. However, the number of peaks of fertility rate distribution hasn't changed from 1960 s to recent years but due to the shift, finally, the distribution will change to a <b>uni-modal</b> <b>distribution</b> in the future. The income will be applied to the conditional convergence and the fertility rate will be applied to the absolute convergence. The fertility gap among cross-countries will disappear, but the income gap won't. Although the population conditions in developing countries will improve, income inequality in cross-country may not be improved after all...|$|E
40|$|We {{present a}} {{photometric}} study of I-band {{variability in the}} young cluster IC 348. The main {{purpose of the study}} was to identify periodic stars. In all we find 50 periodic stars, of which 32 were previously unknown. For the first time in IC 348, we discover periods in significant numbers of lower-mass stars (M 0. 25 M⊙) showing a bi-modal period distribution concentrated around periods of 2 and 8 days, and the lower-mass stars showing a <b>uni-modal</b> <b>distribution,</b> heavily biassed towards fast rotators. Closer inspection of the period distribution shows that the higher mass stars show a significant dearth of fast rotators, compared to the Orion Nebula Cluster, whilst the low mass stars are rotating significantly faster than those in Orion. We find no correlation between rotation period and K − L colour or Hα equivalent width. We also present a discussion of our own IC 348 data in the context of previously published period distributions for the Orion Nebula Cluster, the Orion Flanking Fields and NGC 2264. We find that the previously claimed correlation between infrared excess and rotation period in the ONC might in fact result from a correlation between infrared excess and mass. We also find a marked difference in period distributions between NGC 2264 and IC 348, which presents a serious challenge to the disc locking paradigm, given the similarity in ages and disc fractions between the two clusters. Key words: accretion, accretion discs, stars:pre-main-sequence planetary systems: protoplanetary discs...|$|E
40|$|A {{parametric}} {{regression model}} for right-censored data with a log-linear me-dian regression function and a transformation in both response and regression parts, named parametric Transform-Both-Sides (TBS) model, is presented. The TBS model has a parameter that handles data asymmetry while al-lowing various different distributions for the error, {{as long as}} they are <b>uni-modal</b> symmetric <b>distributions</b> centered at zero. The discussion is focused on the estimation procedure with five important error distributions (normal, double-exponential, Student’s t, Cauchy and logistic) and presents proper-ties, associated functions (that is, survival and hazard functions) and estima-tion methods based on maximum likelihood and on the Bayesian paradigm. These procedures are implemented in TBSSurvival, an open-source fully doc-umented R package. The use of the package is illustrated and the performance of the model is analyzed using both simulated and real data sets...|$|R
40|$|Advances in neural variational {{inference}} have facilitated {{the learning of}} powerful directed graphical models with continuous latent variables, such as variational autoencoders. The hope is that such models will learn to represent rich, multi-modal latent factors in real-world data, such as natural language text. However, current models often assume simplistic priors on the latent variables - such as the <b>uni-modal</b> Gaussian <b>distribution</b> - which are incapable of representing complex latent factors efficiently. To overcome this restriction, we propose the simple, but highly flexible, piecewise constant distribution. This distribution {{has the capacity to}} represent an exponential number of modes of a latent target distribution, while remaining mathematically tractable. Our results demonstrate that incorporating this new latent distribution into different models yields substantial improvements in natural language processing tasks such as document modeling and natural language generation for dialogue. Comment: 19 pages, 2 figures, 8 tables; EMNLP 201...|$|R
40|$|In {{this paper}} {{we present a}} {{symmetric}} KL divergence based agglomerative clustering framework to segment mul-tiple levels of depigmentation in Vitiligo images. The pro-posed framework starts with a simple merge cost based on symmetric KL divergence. We extend the recent body of work related to Bregman divergence based agglomerative clustering and prove that the symmetric KL divergence is an upper-bound for <b>uni-modal</b> Gaussian <b>distributions.</b> This leads to a very powerful yet elegant method for bottom-up agglomerative clustering with strong theoretical guaran-tees. We introduce albedo and reflectance fields as features for the distance computations. We compare against other established methods to bring out possible {{pros and cons of}} the proposed method. Figure 1. Vitiligo patch and its annotation by an expert. The red boundary marks the completely depigmented skin. The yellow boundary is for the partially depigmented skin. All figures are best viewed in colour. 1...|$|R
30|$|In {{order to}} handle various {{background}} types, statistical approaches were introduced. Among these approaches, Gaussian modeling {{methods have been}} widely used. Initially, <b>uni-modal</b> <b>distribution</b> was used to model pixel values[5]. In[6], a background subtraction method using the HSV color space was presented based on single Gaussian modeling. A fast and stable linear discriminant approach based on <b>uni-modal</b> <b>distribution</b> and Markov random field was proposed[7]. Rambabu and Woo proposed a background subtraction method which is robust against noisy and changing illumination based on single Gaussian modeling[8]. Although these models have low complexity levels and produce satisfactory performances in controlled backgrounds, {{it is difficult to}} use them for dynamic scenes. The Gaussian mixture model (GMM) is usually used to model various background types. Stuffer and Grimson used the GMM for background subtraction in[9], and it is still a popular method for background subtraction[10 – 20]. A spatio-temporal GMM (STGMM) was proposed to handle complex background[10]. Using a GMM, a statistical framework was investigated to localize a foreground object[11] and a dynamic background was modeled for highly dynamic conditions such as active cameras and high motion activities in background regions[12]. Also, the subtraction of two Gaussian kernels (difference of Gaussians) was used to eliminate background regions in embedded platforms[13]. A general framework of regularized online classification EM for GMM was proposed[14]. Wang et al. proposed an adaptive local-patch GMM to detect moving objects in dynamic background regions[15]. In[16], a new update algorithm was proposed for learning adaptive mixture models, and Bin et al. proposed a self-adaptive moving object detection algorithm. The method improved the original GMM in order to adapt to sudden or gradual illumination changes[17]. In[18], in order to improve GMM performance, a new rate control method based on high-level feedback was developed. An improved adaptive-K GMM method was presented for updating background regions[19], and GMM was used for modeling background regions in a Bayer-pattern domain[20]. A disadvantage of these multimodal Gaussian modeling methods is that they require pre-defined parameters such as the number of the Gaussian distributions and the standard deviations of those distributions. Also, dynamic backgrounds cannot be accurately modeled by a few Gaussian distributions. In order to overcome parameter background modeling methods, nonparametric background modeling techniques have been developed for estimating background probabilities. Nonparametric background modeling methods have been used to estimate background distribution based on pixel values observed in the past. In[21], the Gaussian kernel was used for pixel-based background modeling. This nonparametric method is usually used to handle multiple modes of dynamic backgrounds without pre-defined parameters. However, these nonparametric methods use kernel density estimation (KDE), which requires heavy computational complexity and a large amount of memory. Various efforts have been made to address these problems. Using Parzen density estimation and foreground object detection, a fast estimation method was presented[22] and an automatic background modeling based on multivariate non-parametric KDE was proposed[23]. In[24], a non-parametric method was proposed for foreground and background modeling, which did not require any initialization. Han et al. proposed an efficient algorithm for recursive density approximation based on density mode propagation[25]. Also, depth information, on-line auto-regressive modeling, and Gaussian family distribution were used to eliminate background regions[26 – 28]. In[29], new object segmentation was proposed based on a recursive KDE. It used the mean-shift method to approximate the local maximum value of the density function. The background was modeled using real-time KDE based on online histogram learning[30].|$|E
40|$|Volume {{concentration}} data of submicron particles (0. 1 - 1. 0 mu m) in on-road vehicle plumes (NOx > 400 ppb) {{gathered by the}} Mobile Real-time Air Monitoring Platform (MAP) on city streets, highways and in tunnels in Hong Kong are used to study the size distributions and growth of vehicular submicron particles due to gas condensation and, particularly, its dependency on ambient temperature. Three particle volume size distributions are observed: a <b>uni-modal</b> <b>distribution</b> with an accumulation mode at 0. 2 +/- 0. 1 mu m, and two bi-modal distributions with a minor mode at 0. 2 +/- 0. 1 mu m and the dominant mode at either 0. 5 +/- 0. 1 or 0. 7 +/- 0. 1 pm. In tunnels, the ratio of particle volume concentration to black carbon (BC) mass concentration correlates negatively with ambient temperature (r(2) = 0. 57); the dominant mode tends {{to be at the}} large particle size when the temperature is low, and when the temperature is high, the uni-mode appears at the small particle size. Thus temperature seems to exert a significant influence on the condensation growth of fresh vehicular particles. On the other hand, this ratio correlates positively with ambient particle concentrations (r(2) = 0. 35). Ambient particles measured in this study are mostly > 0. 3 mu m while BC in vehicle plumes is generally believed to be mainly in the < 0. 3 pm size range in the literature. Temperature-dependent gas-condensation competition between fresh BC and ambient particles is suggested {{to play a role in}} the bi-modal formation. (C) 2007 Elsevier Ltd. All rights reserved...|$|E
40|$|We {{present an}} {{extensive}} spectroscopic follow-up campaign of 29 strong lensing (SL) selected galaxy clusters discovered {{primarily in the}} Second Red-Sequence Cluster Survey (RCS- 2). Our spectroscopic analysis yields redshifts for 52 gravitational arcs present {{in the core of}} our galaxy clusters, which correspond to 35 distinct background sources that are clearly distorted by the gravitational potential of these clusters. These lensed galaxies span a wide redshift range of 0. 8 < z < 2. 9, with a median redshift of z_s = 1. 8 ± 0. 1. We also measure reliable redshifts for 1004 cluster members, allowing us to obtain robust velocity dispersion measurements for 23 of these clusters, which we then use to determine their dynamical masses by using a simulation-based σ_DM - M_ 200 scaling relation. The redshift and mass ranges covered by our SL sample are 0. 22 < z < 1. 01 and 5 × 10 ^ 13 < M_ 200 /h^- 1 _ 70 M_< 1. 9 × 10 ^ 15, respectively. We analyze and quantify some possible effects that might bias our mass estimates, such as the presence of substructure, the region where cluster members are selected for spectroscopic follow-up, the final number of confirmed members, and line-of-sight effects. We find that 10 clusters of our sample with N_mem≳ 20 show signs of dynamical substructure. However, the velocity data of only one system is inconsistent with a <b>uni-modal</b> <b>distribution.</b> We therefore assume that the substructures are only marginal and not of comparable size to the clusters themselves. Consequently, our velocity dispersion and mass estimates can be used as priors for SL mass reconstruction studies and also represent an important step toward {{a better understanding of the}} properties of the SL galaxy cluster population. Comment: Accepted for publication in Ap...|$|E
40|$|Run-and-tumble {{dynamics}} is a wide-spread {{mechanism of}} swimming bacteria. The accumulation of run-and-tumble microswimmers near impermeable surfaces is studied theoretically and numerically in the low-density limit {{in two and}} three spatial dimensions. Both <b>uni-modal</b> and exponential <b>distributions</b> of the run lengths are considered. Constant run lengths lead to {peaks and depletions regions} in the density distribution of particles near the surface, in contrast to {exponentially-distributed run lengths}. Finally, we present a universal accumulation law for large channel widths, which applies not only to run-and-tumble swimmers, but also to many other kinds of self-propelled particles...|$|R
40|$|We {{study the}} {{potential}} benefits of unlabeled data to classification prediction to the learner. We compare learning in the semi-supervised model to the standard, supervised PAC (distribution free) model, considering both the realizable and the unrealizable (agnostic) settings. Roughly speaking, our conclusion is that access to unlabeled samples cannot provide sample size guarantees that are better than those obtainable without access to unlabeled data, unless one postulates very strong assumptions about the distribution of the labels. In particular, we prove that for basic hypothesis classes over the real line, if the distribution of unlabeled data is ‘smooth’, knowledge of that distribution cannot improve the labeled sample complexity by more than a constant factor (e. g., 2). We conjecture that a similar phenomena holds for any hypothesis class and any unlabeled data distribution. We also discuss the utility of semi-supervised learning under the common cluster assumption concerning the distribution of labels, and show that even in the most accommodating cases, where data is generated by two <b>uni-modal</b> label-homogeneous <b>distributions,</b> common SSL paradigms may be misleading and inflict poor prediction performance...|$|R
40|$|The {{evolution}} of aggregate size distributions resulting from sweep flocculation {{has been investigated}} using laser light scattering technique. By measuring the (volume) distributions of floc size, {{it is possible to}} distinguish clearly among floc formation, growth and breakage. Sweep flocculation of stable kaolin suspensions with ferric chloride under conditions of the rapid/slow mixing protocol produces <b>uni-modal</b> size <b>distributions.</b> The size distribution is shifted to larger floc size especially during the rapid mixing step. The variation of the distributions is also shown in the plot of cumulative percent finer against floc size. From this plot, the distributions maintain the same S-shape curves over the range of the mixing intensities/times studied. A parallel shift of the curves indicates that self-preserving size distribution occurred in this flocculation. It is suggested that some parameters from mathematical functions derived from the curves could be used to construct a model and predict the flocculating performance. These parameters will be useful for a water treatment process selection, design criteria, and process control strategies. Thus the use of these parameters should be employed in any further study...|$|R
40|$|BACKGROUND: Quality specifications, {{the level}} of {{performance}} required to facilitate clinical decision-making, not only have {{a central role in}} quality management in the laboratory but are also essential for assuring the interpretation and utilization of laboratory data by physicians. Consensus has been reached on the hierarchy of criteria for quality specifications. However, the information on quality specifications that should be communicated to clinicians, {{and the way in which}} this information should be given, is still widely debated. METHODS: Laboratory tests have been grouped into four categories including uni-modal, and bi-modal distributions, tests used in patients monitoring and in evaluating the response to therapy (serial measurements), and, finally, tests that require interpretive comments. The most suitable and informative ways to communicate quality specifications to clinicians have been proposed for each category. RESULTS: For tests with a <b>uni-modal</b> <b>distribution,</b> the decision limits should replace traditional reference values in the report. For tests with a bi-modal distribution, in addition to traditional reference values, some flags based on the uncertainty (i. e., analytical and biological variability) of laboratory data, can be included to help clinicians interpret laboratory data. For tests used in monitoring patients and in evaluating the response to therapy (serial measurements), the reference change value or the most effective threshold of the difference between two consecutive results should be indicated. For tests/test batteries that require interpretive comments, these should be added to the report and discussed in multidisciplinary meetings and interpretive rounds to promote knowledge of a more objective evaluation of laboratory data. CONCLUSIONS: A proposal has been made to improve the way laboratory results are communicated to clinicians, with practical information derived from quality specifications. By providing clinicians with information on quality characteristics and the degree of uncertainty, a more objective interpretation of laboratory data may be possible, and data may be more appropriately utilized for diagnosis and monitoring...|$|E
40|$|The Burdekin River Catchment is {{situated}} in the dry tropics region of Northern Queensland, Australia and covers 130, 000 km 2. As the second largest catchment in the state it impacts significantly upon the Great Barrier Reef shelf system in terms of water, sediment and nutrient exports, but due to the seasonal nature of rainfall in the region, these impacts are highly episodic. In 1989, the Burdekin Falls Dam was built {{in order to provide}} a storage reservoir for irrigation. It was expected to act as a sediment trap, however the reservoir fills and overflows during flood events, which carry large amounts of suspended particulate matter. The reservoir is chronically turbid (> 100 NTU) and consequently discharge from the dam is no longer clear during the dry season, which may potentially cause adverse affects downstream. Our investigation into the characteristics, source and fate of sediment in the Upper Burdekin catchment and its behaviour within the system has been undertaken within the two major inflowing rivers (Suttor and Burdekin Rivers) and impoundment area during baseflow and stormflow periods. Preliminary results indicate that the high turbidity relates to fine clay minerals of generally < 10 μm (kaolinite, smectite, muscovite), while sediment deposition within the reservoir has been minimal. A bi-modal distribution implies a second grainsize population related to an organic component. Benthic sediment exhibits a <b>uni-modal</b> <b>distribution</b> and as expected is coarser grained than suspended sediment. XRD work has shown that the composition of the suspended sediment in the inflowing rivers is similar and representative of catchment geology. Suspended sediment grainsize patterns from samples collected post-wet season in the Suttor river and reservoir are virtually identical, which along with turbidity and conductivity data implies that the persistent turbidity in the dam is largely controlled by inflow from the Suttor River...|$|E
40|$|Forest {{fires are}} an {{important}} disturbance factor of boreal forests, annually burning about 0. 5 % of the forested area in Canada. Wildfire regimes are influenced by climate {{and a number of}} studies project an increase in wildfire activity with climate change. Another factor influencing wildfires is human intervention (fire suppression), and one factor that has rarely been assessed is fuel fragmentation. Studies evaluating the effect of forest fire suppression concluded that in areas with strong suppression effort the burned area as well as the fire size decreased. Here we evaluate wildfire distributions over the last three decades for two areas that differ mainly in their level of forest management and fire suppression: the Boreal Shield (unmanaged) and the Boreal Plain regions (intensively managed) in the Canadian Province of Saskatchewan. We calculate a fuel fragmentation index and relate fire sizes and burned areas to fire weather. We use the concept of the characteristic fire size (CFS); hence we analyze how much burned area is contributed to the total burned area per fire size class. Both areas show a <b>uni-modal</b> <b>distribution</b> of the CFS, indicating that the majority of burned area was contributed by medium sized fires (Boreal Shield 6. 39 · 104 ha, the Boreal Plain 8. 79 · 104 ha). Burned area as well as fuel fragmentation is lower in the managed forest compared to the unmanaged area. The fuel fragmentation index constantly increased since the 1980 s in both regions. Despite the large efforts of fire suppression in the Boreal Plains, the CFS is slightly larger in this managed region. Neither the burned area nor the fire size could be linked statistically to the weather conditions, {{at the time of the}} fire (using the Canadian Fire Weather Index). We argue that the high fragmentation over the last decades have decreased the burned area. The slightly higher characteristic fire size in the managed area might be explained by the considerably lower fragmentation, counteracting fire suppression efforts. Fuel fragmentation is likely to decrease over the next decades due re-growth. Though a strong link between fire weather and burned area at the fine scale of this study could not be detected we expect that a decrease in fragmentation in combination with an increase in fire prone weather conditions (as expected for the future) might increase the risk of large fires in both areas. We suggest that future fire risk analysis should include an assessment of the effect of fuel fragmentation...|$|E
40|$|The {{evolution}} of aggregate (floc) size distributions resulting from hydrophobic flocculation {{has been investigated}} using a laser light scattering technique. By measuring floc size distributions {{it is possible to}} distinguish clearly among floc formation, growth and breakage. Hydrophobic flocculation of hematite suspensions with sodium oleate under a variety of agitating conditions produces <b>uni-modal</b> size <b>distributions.</b> The size distribution of the primary particles is shifted to larger floc sizes when the dispersed suspension is coagulated by pH adjustment. By adding sodium oleate to the pre-coagulated suspension, the distribution progresses further to the larger size. However, prolonged agitation degrades the formed flocs, regressing the distribution to the smaller size. Median floc size derived from the distribution is also used as performance criterion. The median floc size increases rapidly at the initial stage of the flocculation, and decreases with the extended agitation time and intensity. Relatively weak flocs are produced which {{may be due to the}} low dosage of sodium oleate used in this flocculation study. It is suggested that further investigation should focus on optimum reagent dosage and non-polar oil addition to strengthen these weak flocs...|$|R
40|$|The {{influence}} of the seed size, loadings and the batch time on crystallization kinetics and granulometric properties of the obtained pentaerythritol crystals has been investigated. Experiments have been performed in the laboratory batch cooling crystallizer (Rushton dimensions). The solubility curve and the metastable zone width have been determined at the defined cooling profile. In order to compare the obtained results, an experiment of unseeded crystallization was performed. The experiments have been performed within the metastable zone width. For estimation of the growth kinetics, from the desupersaturation curve during batch seeded experiments, the Garside et al. method was used. The crystal growth {{is controlled by the}} surface integration (polynuclear or birth and spread mechanism of grow), since the values of the exponent of growth, g, are very high (g> 2). The crystal size distribution can be approximated with the RRSB function. The smaller seed size and lower seed loadings leads to a <b>uni-modal</b> size <b>distribution</b> of the final crystals and the higher crystal growth rate. Decreasing the batch time from 80 min to 35 min, improves the final crystal size distribution. (unimodal for lower seed loadings). 1...|$|R
40|$|The Bayesian {{inference}} {{of models}} associated with large-scale simulations is prohibitively expensive even for massively parallel architectures. We demonstrate {{that we can}} drastically reduce this cost by combining adaptive kriging with the population-based Transitional Markov Chain Monte Carlo (TMCMC) techniques. For <b>uni-modal</b> posterior probability <b>distribution</b> functions (PDF), the proposed hybrid method can reduce the computational cost by {{an order of magnitude}} with the same computational resources. For complex posterior PDF landscapes we show {{that it is necessary to}} further extend the TMCMC by Langevin adjusted proposals. The proposed hybrid method exhibits high parallel efficiency. We demonstrate the capabilities of our method on test bed problems and on high fidelity simulations in structural dynamics. (C) 2015 Elsevier B. V. All rights reserved...|$|R
40|$|In this study, {{biometric}} {{and structural}} engineering tool {{have been used}} to examine a possible relationship within Chuaria-Tawuia complex and micro-FTIR (Fourier Transform Infrared Spectroscopy) analyses to understand the biological affinity of Chuaria circularis Walcott, collected from the Mesoproterozoic Suket Shales of the Vindhyan Supergroup and the Neoproterozoic Halkal Shales of the Bhima Group of peninsular India. Biometric analyses of well preserved carbonized specimens show wide variation in morphology and <b>uni-modal</b> <b>distribution.</b> We believe and demonstrate to a reasonable extent that C. circularis most likely was a part of Tawuia-like cylindrical body of algal origin. Specimens with notch/cleft and overlapping preservation, mostly recorded in the size range of 3 - 5 mm, are of special interest. Five different models proposed earlier on the life cycle of C circularis are discussed. A new model, termed as 'Hybrid model' based on present multidisciplinary study assessing cylindrical and spherical shapes suggesting variable cell wall strength and algal affinity is proposed. This model discusses and demonstrates varied geometrical morphologies assumed by Chuaria and Tawuia, and also shows the inter-relationship of Chuaria-Tawuia complex. Structural engineering tool (thin walled pressure vessel theory) was applied to investigate the implications of possible geometrical shapes (sphere and cylinder), membrane (similar to cell wall) stresses and ambient pressure environment on morphologically similar C circularis and Tawuia. The results suggest that membrane stresses developed on the structures similar to Chuaria-Tawuia complex were directly proportional to radius and inversely proportional to the thickness in both cases. In case of hollow cylindrical structure, the membrane stresses in circumferential direction (hoop stress) are twice of the longitudinal direction indicating that rupture or fragmentation in the body of Tawuia would have occurred due to hoop stress. It appears that notches and discontinuities seen in some of the specimens of Chuaria may be related to rupture suggesting their possible location in 3 D Chuaria. The micro-FTIR spectra of C. circularis are characterized by both aliphatic and aromatic absorption bands. The aliphaticity is indicated by prominent alkyl group bands between 2800 - 3000 and 1300 - 1500 cm(- 1). The prominent absorption signals at 700 - 900 cm(- 1) (peaking at 875 and 860 cm(- 1)) are due to aromatic CH out of plane deformation. A narrow, strong band is centred at 1540 cm(- 1) which could be COOH band. The presence of strong aliphatic bands in FTIR spectra suggests that the biogeopolymer of C. circularis is of aliphatic nature. The wall chemistry indicates the presence of 'algaenan'-a biopolymer of algae. (C) 200...|$|E
40|$|We {{present results}} of a gravitational-lensing and optical study of MACS,J 1423. 8 + 2404 (z= 0. 545, MACS, J 1423). Our {{analysis}} uses high-resolution images taken with the Hubble Space Telescope in the F 555 W and F 814 W passbands, ground based imaging in eight optical and near-infrared filters obtained with Subaru and CFHT, as well as extensive spectroscopic data gathered with the Keck telescopes. At optical wavelengths the cluster exhibits no sign of substructure and is dominated by a cD galaxy that is 2. 1 magnitudes (K-band) brighter than the second brightest cluster member, suggesting that MACS, J 1423 is close to be fully virialized. Analysis of the redshift distribution of 140 cluster members reveals a Gaussian distribution, mildly disturbed {{by the presence of}} a loose galaxy group that may be falling into the cluster along the line of sight. Combining strong-lensing constraints from two spectroscopically confirmed multiple-image systems near the cluster core with a weak-lensing measurement of the gravitational shear on larger scales, we derive a parametric mass model for the mass distribution. All constraints can be satisfied by a <b>uni-modal</b> mass <b>distribution</b> centred on the cD galaxy and exhibiting very little substructure. The derived projected mass of M(< 65 [415 kpc]) =(4. 3 ± 0. 6) × 10 ^ 14 M_sun is about 30...|$|R
40|$|Rectangular porous wicks {{for use in}} {{flat plate}} heat pipes were {{fabricated}} using copper powder (63 mu m) sintered at 800 degrees C and 1000 degrees C. These wicks were characterized {{in terms of their}} porosity and pore size distribution using the techniques of mercury intrusion porosimetry and scanning electron microscopy (SEM). A <b>uni-modal</b> pore size <b>distribution</b> was obtained with most pores having sizes in the 30 - 40 mu m range. Comparison was also made with cylindrical wicks fabricated by injection molding technique with the same binder and sintered at the same temperatures. Calculated permeability values of the rectangular wicks are comparable with commercially produced cylindrical wicks. When compared with conventional heat pipe wicks such as those using wire mesh, the advantage of these sintered wicks appears to be the existence of smaller pores and the controllability of porosity and pore size to optimize heat pipe performance...|$|R
40|$|The present work {{discusses}} {{the role of}} orifice recess on the drop size characteristics of sprays discharging from gas centered swirl coaxial (GCSC) injectors used in liquid propellant rocket engines. Four GCSC injectors (one coplanar and three recessed) are considered. The experiments are conducted in a spray test facility with water and air as experimental fluids. The measurements of spray drop size are obtained using laser diffraction based Spraytec. The spray flow is characterized {{in terms of the}} gas-to-liquid momentum flux ratio, J. For a given GCSC injector, the measured SMD for sprays discharging from the injector decreases with increasing J. The sprays discharging from the coplanar CGCS injector exhibit typical <b>uni-modal</b> drop size <b>distribution.</b> However, the sprays discharging from the recessed GCSC injectors exhibit a bi-modal drop size distribution and the existence of bi-modality gets stronger with increasing J. Detailed analysis is made to shed lights on the mechanisms of spray formation in recessed GCSC injectors...|$|R
40|$|Particle size (30 to 10, 000 nm) {{distributions}} {{in number}} concentration were measured using an Electrical Low Pressure Impactor onboard a Mobile Real-time Air Monitoring Platform from June 2002 to August 2003 in Hong Kong {{to investigate the}} size distributions of on-road vehicular particles and their relationship with ambient temperature (T) and relative humidity (RH). In this article, {{we focus on the}} size distributions of particles > 30 nm in vehicle plumes where fresh vehicular particles dominated and the NOx concentration was > 400 ppb. A <b>uni-modal</b> size <b>distribution</b> with mode at either 60 - 108 nm or 108 - 170 nm was generally observed from April to October. This mode is conventionally believed to be soot particles in the literature and the different mode sizes probably depend on engine and vehicle operating conditions. From November to March, a bi-modal size distribution with a dominant mode at 30 - 60 nm and a minor mode at either 108 - 170 nm or 60 - 108 nm was generally observed. The existence of the 30 - 60 nm mode is explained in the literature by the growth of nucleated particles when vehicular exhaust cools in ambient air. Ratios of the number concentration of 30 - 60 nm particles to BC mass concentration correlated negatively with T, as well as with RH when RH was 60 %. The correlations suggested that T and RH exert significant influences on the formation of vehicular submicron particles, leading to varying size distributions of vehicular particles in Hong Kong...|$|R
40|$|Summary: The {{effects of}} reperfusion on the spatiotemporal {{dynamics}} of transient (60 minutes) focal ischemic brain injury in rats were evaluated on a pixel-by-pixel basis using quanti-tative {{cerebral blood flow}} (CBF) and apparent diffusion coef-ficient (ADC) measurements every 30 minutes for 3 hours and compared to post-mortem histology at 24 hours. Four biologi-cally relevant clusters were classified based on ADC (0. 53 ± 0. 02 × 10 − 3 mm 2 /s, SD) and CBF (0. 30 ± 0. 09 ml/g/min) viabil-ity thresholds, namely: (1) the “normal ” cluster with ADC and CBF> thresholds; (2) the “mismatch ” cluster with ADC> threshold but CBF threshold. The spa-tio-temporal progression of tissue volumes, ADC and CBF of each cluster were evaluated. Pixels of each cluster on the CBF-ADC space were mapped onto the image space. Following reperfusion, 28 % of the “core ” pixels and 90 % of the “mis-match ” (defined at 60 minutes) pixels were salvaged at 180 minutes, which correlated with histology. The ADC and CBF of subsequently salvaged tissues {{were significantly higher than}} those became infarcted. Salvaging “core ” pixels indicated that reduced ADC was not synonymous with irreversible injury; duration of exposure and severity of reduced ADC and CBF were likely critical. Projection profiles showed a bimodal ADC, but <b>uni-modal</b> CBF, <b>distributions.</b> The ADC bimodal minima, obtained without histological correlation, were similar to the histology-derived ADC and CBF viability thresholds, and could have potential clinical applications. This study demon-strated a simple but powerful approach to evaluate, on a pixel-by-pixel basis, the spatio-temporal evolution of ischemic brain injury, and a potential for statistical prediction of tissue fate...|$|R
