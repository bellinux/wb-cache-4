81|77|Public
2500|$|... the <b>unweighted</b> <b>mean</b> was [...] "691 ± 31 years", which {{corresponds}} to calibrated ages of [...] "1273 - 1288 CE" [...] with 68% confidence, and [...] "1262 - 1312, 1353 - 1384 CE cal" [...] with 95% confidence.|$|E
50|$|Contrast coding is {{used when}} {{one has a}} series of {{orthogonal}} contrasts or group comparisons {{that are to be}} investigated. In this case, the intercept is the <b>unweighted</b> <b>mean</b> of the individual group means. The unstandardized regression coefficient represents the difference between the <b>unweighted</b> <b>mean</b> of the means of one group (A) and the <b>unweighted</b> <b>mean</b> of another group (B), where A and B are two sets of groups in the contrast. This coding system is appropriate when researchers have an a priori hypothesis concerning the specific differences among the group means.|$|E
5000|$|If A is {{a finite}} {{non-empty}} set, one can replace the <b>unweighted</b> <b>mean</b> or average ...|$|E
50|$|The <b>unweighted</b> <b>means</b> {{correspond}} to setting all wi = 1/n.|$|R
50|$|Proof for <b>unweighted</b> power <b>means</b> {{is easily}} {{obtained}} by substituting wi = 1/n.|$|R
50|$|If all weights are the same, i.e. , {{then the}} {{weighted}} mean and covariance reduce to the <b>unweighted</b> sample <b>mean</b> and covariance above.|$|R
5000|$|The <b>un{{weighted}}</b> <b>mean</b> {{square of}} the weighted deviations (unweighted MSWD) can then be computed, as follows: ...|$|E
5000|$|... the <b>unweighted</b> <b>mean</b> was [...] "691 ± 31 years", which {{corresponds}} to calibrated ages of [...] "AD 1273 - 1288" [...] with 68% confidence, and [...] "AD 1262 - 1312, 1353 - 1384 cal" [...] with 95% confidence.|$|E
5000|$|... where [...] The {{variance}} attains {{its maximum}} value, , when all weights except one are zero. Its minimum value is found when all weights are equal (i.e., <b>unweighted</b> <b>mean),</b> {{in which case}} we have , i.e., it {{degenerates into the standard}} error of the mean, squared.|$|E
40|$|A {{graphical}} {{technique is}} introduced {{to assess the}} adequacy of the method of <b>unweighted</b> <b>means</b> in providing approximate F -tests for an unbalanced random model. These tests are similar to those obtained under a balanced ANOVA. The proposed technique is simple and can easily be used {{to determine the effects of}} imbalance and values of the variance components on {{the adequacy of the}} approximation. The one-way and two-way random models are used to illustrate the proposed methodology. Extensions to higher-order models are also mentioned. ...|$|R
40|$|A {{factorial}} design {{should be used}} when there are several factors of interest in experiment. The problem which arises when the factorial experiment does not contain equal sized samples in the cells is that the design is nonorthogonal. In other words, the total sums of squares in the ANOVA table cannot be decomposed {{into a series of}} additive components which permit the analysis of the separate effect. There are possible situations when the cell sample sized are unequal, allocated proportionately or disproportionately. On the allocated disproportionately, approximate F test using the method of <b>unweighted</b> <b>means.</b> ...|$|R
40|$|Many {{researchers}} {{assume that}} unequal cell frequencies in {{analysis of variance}} (ANOVA) designs result from poor planning. However, there are several valid reasons why one might have to analyze an unequal-n data matrix. The present'study reviewed four categories of methods for treating unequal-n matrices by ANOVA: (a) unaltered data (least-squares solution and <b>unweighted</b> <b>means</b> solution); (b) data substitution (grand mean method, cell mean Method, Winer method, Snedecor-Cochran method); (c) data deletion, and (d) data clustering (unreplicated cell mean method, unreplicated random data clustering method, replicated random data clustering method). The methods were compared empirically and theoretical problems with each were discussed. (Author) l...|$|R
50|$|According to 2012 {{paper the}} anomaly {{was due to}} the use of a {{weighted}} mean when there is a correlation between distances and distance errors for stars in clusters. It is resolved by using an <b>unweighted</b> <b>mean.</b> There is no systematic bias in the Hipparcos data when it comes to star clusters.|$|E
5000|$|In {{financial}} applications {{a simple}} moving average (SMA) is the <b>unweighted</b> <b>mean</b> {{of the previous}} n data. However, {{in science and engineering}} the mean is normally taken from an equal number of data on either side of a central value. This ensures that variations in the mean are aligned with the variations in the data rather than being shifted in time.An example of a simple equally weighted running mean for a n-day sample of closing price is the mean of the previous n days' closing prices. If those prices are [...] then the formula is ...|$|E
50|$|The Women’s Economic Opportunity Index uses a {{quantitative}} and qualitative scoring model, constructed from 29 indicators, measuring specific attributes of the environment for women employees and entrepreneurs in 128 economies. Five category scores are calculated from the <b>unweighted</b> <b>mean</b> of underlying indicators and scaled from 0-100, where 100=most favourable. These categories are: Labour policy and practice (which comprises two sub-categories: Labour policy and Labour practice); Access to finance; Education and training; Women’s legal and social status; and the General business environment. Each category or sub-category features several underlying indicators. The overall score (from 0-100) is calculated {{from an average of}} the unweighted category and indicator scores.|$|E
5000|$|If {{a set of}} weights , ..., [...] is {{associated}} to the dataset , ..., , the weighted harmonic mean is defined byThe <b>unweighted</b> harmonic <b>mean</b> {{can be regarded as}} the special case where all of the weights are equal.|$|R
40|$|Suitability Index (SI) curves {{developed}} by the U. S. Fish and Wildlife Service were used to evaluate habitat of adult spotted bass (Micropterus punctulatus) in riverine enviroments in northern Oklahoma. Reliability of suitability indices for individual variables appeared high. However, when the individual indices were aggregated into an overall habitat suitability index (HSI) by use of an <b>unweighted</b> geometric <b>mean,</b> correlations were low between HSI and species biomass. Accurate prediction of standing crop by aggregating individual suitability indices by an <b>unweighted</b> geometric <b>mean</b> appears to be unlikely. Rationale to explain failure of the geometric mean aggregation model is presented and an alternative procedure for predicting impacts is suggested...|$|R
30|$|The {{productivity}} weighted by {{employment share}} is called with structural change and without structural change <b>means</b> <b>unweighted</b> productivity.|$|R
50|$|The primary food of pygmy rabbits is big sagebrush, {{which may}} {{comprise}} up to 99% {{of the food}} eaten in the winter. Grasses and forbs are also eaten from mid- to late summer. In Idaho, Gates and Eng found that shrubs contributed 85.2% (<b>unweighted</b> <b>mean)</b> of pygmy rabbit diets from July to December. Shrub use was lowest in August (73.1%) and highest in December (97.9%). Big sagebrush {{was the most important}} shrub in the July to December diet (54.2%), followed byrubber rabbitbrush (Chrysothamnus nauseosus, 25.8%) and winterfat (Krascheninnikovia lananta, 4.6%). Grasses comprised 10% of the July to December diet and were consumed mostly during July and August. Indian ricegrass (Oryzopsis hymenoides) and needlegrass (Stipa spp.) were the most important grasses consumed. Forbs contributed 4.9% of the July to December diet.|$|E
50|$|This {{method of}} taking a simple mean average of a panel of {{independent}} forecasts, derived from different forecasting methods, is known as combining forecasts {{and the result is}} often referred to as a consensus forecast. Unless a particular forecast model which produces smaller forecast errors compared to other individual forecasts can be identified, adopting the consensus approach can be beneficial due to diversification gains. Combining economic forecasts is well established in many countries and can count central banks, government institutions and businesses among the users. In recent decades, consensus forecasts have attracted much interest, backed by the publication of a huge swathe of academic research on forecast accuracy. Empirical studies show that pooling forecasts increased forecast accuracy. One of the advantages of using consensus forecasts is that it can prove useful if there is a high degree of uncertainty or risk attached to the situation and the selection of the most accurate forecast in advance is difficult. Even if one method is identified as the best, combining is still worthwhile if other methods can make some positive contribution to the forecast accuracy. Moreover, many factors can affect the independent forecast and these, along with any additional useful information, might be captured by using the consensus approach. Another argument in favour of this method is that individual forecasts may be subject to numerous behavioural biases, but these can be minimised by combining independent forecasts together. Hence, combining is seen as helping to improve forecast accuracy by reducing the forecast errors of individual forecasts. Furthermore, averaging forecasts is likely to be more useful when the data and the forecasting techniques that the component forecasts are drawn from differ substantially. And even though it is only a simple approach (typically an <b>unweighted</b> <b>mean</b> average), this method is just as useful as other more sophisticated models. Indeed, more recent studies in the past decade have shown that, over time, the equal weights combined forecast is usually more accurate than the individual forecast which make up the consensus.|$|E
40|$|AbstractWe {{consider}} the mean squares of L-functions associated to modular forms {{with respect to}} Hecke congruence subgroups, expressing the mean value as an inner product. This avoids the discussion of generalized additive divisor problems. As applications, we obtain asymptotic formulas for both weighted and <b>unweighted</b> <b>mean</b> squares...|$|E
30|$|From {{estimates}} of the dissimilarities, the strains were grouped using hierarchical UPGMA method (<b>Unweighted</b> Pair-Group <b>Mean</b> Average) with the test of bootstrap (1000 times) to evaluate {{the consistency of the}} group (Efron & Tibshirani, 1993). A second analysis was performed using the pooling method of Tocher. All these tests were performed using the Genes program (Cruz, 2001).|$|R
40|$|The use {{of general}} linear {{regression}} methods {{for the analysis}} of categorical data is recommended. The general linear model analysis of a 0, 1 coded response variable produces estimates of the same response probabilities that might otherwise be estimated from frequencies in a multiway contingency table. When factors in the design are correlated, the regression analysis estimates the same response probabilities that would be estimated from the simple marginal frequencies in a balanced orthogonal design. The independent effects that are estimated by the regression analysis are the <b>unweighted</b> <b>means</b> of the response probabilities in various cells of a cross-classification design; however, it is not necessary that all cells in a complex design be filled in order for the estimates to have that interpretation. The advantages of the general linear model analysis include familiarity of most psychologists with the methods, availability of computer programs, and ease of application to problems that are too complex for development of complete multiway contingency tables...|$|R
40|$|Although a great methodological {{effort has}} been {{invested}} in proposing competitive solutions to the class-imbalance problem, little {{effort has been}} made in pursuing a theoretical understanding of this matter. In order to shed some light on this topic, we perform, through a novel framework, an exhaustive analysis of the adequateness of the most commonly used performance scores to assess this complex scenario. We conclude that using <b>unweighted</b> Hölder <b>means</b> with exponent p ≤ 1 to average the recalls of all the classes produces adequate scores which are capable of determining whether a classifier is competitive. Then, we review the major solutions presented in the class-imbalance literature. Since any learning task can be defined as an optimisation problem where a loss function, usually connected to a particular score, is minimised, our goal, here, is to find whether the learning tasks found in the literature are also oriented to maximise the previously detected adequate scores. We conclude that they usually maximise the <b>unweighted</b> Hölder <b>mean</b> with p = 1 (a-mean). Finally, we provide bounds on the values of the studied performance scores which guarantee a classifier with a higher recall than the random classifier in each and every class...|$|R
30|$|At the near-rotation stand, ΔCL K-MSN and K-MSN FPW were {{slightly}} higher than the arithmetic mean (less than 1 standard deviation). The estimates using KMSN and KMSN-FPW were identical. For ΔCD 2, the <b>unweighted</b> <b>mean</b> was higher than K-MSN and K-MSN FPW, but less than 1 standard deviation different. For ΔC 2 total, all estimates were within 1 standard deviation.|$|E
40|$|The {{field of}} {{statistics}} {{is becoming increasingly}} more important {{as the amount of}} data in the world grows. This thesis studies the Growth Curve model in multivariate statistics which is a model that is not widely used. One difference compared with the linear model is that the Maximum Likelihood Estimators are more complicated. That makes it more difficult to use and to interpret which may be a reason for its not so widespread use. From this perspective this thesis will compare the traditional mean estimator for the Growth Curve model with the <b>unweighted</b> <b>mean</b> estimator. The <b>unweighted</b> <b>mean</b> estimator is simpler than the regular MLE. It will be proven that the unweighted estimator is in fact the MLE under certain conditions and examples when this occurs will be discussed. In a more general setting this thesis will present conditions when the un-weighted estimator has a smaller covariance matrix than the MLEs and also present confidence intervals and hypothesis testing based on these inequalities...|$|E
30|$|At the {{juvenile}} stands, all estimates ∆C 2 were within 1 {{standard deviation of}} the estimates of ΣNEP. At HDF 90, the unweighted estimate of ∆C 2 matched ΣNEP CBM-CFS 3. At HDF 88, the <b>unweighted</b> <b>mean</b> of ground plots was the closest to the EC tower measurements of ΣNEP, while the ΔC 2 K-MSN had a different sign (indicating a small source), and the K-MSN ∆C 2 FPW had the same sign as ∆C 2 unweighted (Table  6).|$|E
40|$|Background: In the United Kingdom, sodium {{reduction}} targets {{have been}} set for {{a large number of}} processed food categories. Assessment and monitoring are essential to evaluate progress. Objectives: Our aim was to determine whether household con-sumer panel food-purchasing data could be used to assess the so-dium content of processed foods. Our further objectives were to estimate the mean sodium content of UK foods by category and undertake analyses weighted by food-purchasing volumes. Design: Data were obtained for 21, 108 British households between October 2008 and September 2009. Purchasing data (product de-scription, product weight, annual purchases) and sodium values (mg/ 100 g) were collated for all food categories known to be major contributors to sodium intake. <b>Unweighted</b> and weighted <b>mean</b> so-dium values were calculated. Results: Data were available for 44, 372 food products. The largest contributors to sodium purchases were table salt (23 %), processed meat (18 %), bread and bakery products (13 %), dairy products (12 %), and sauces and spreads (11 %). More than one-third of so-dium purchased (37 %) was accounted for by 5 food categories: bacon, bread, milk, cheese, and sauces. For some food groups (bread and bakery, cereals and cereal products, processed meat), purchase-weighted means were 18 – 35 % higher than <b>unweighted</b> <b>means,</b> suggesting that market leaders have higher sodium contents than the category mean. Conclusion: The targeting of sodium reduction in a small number of food categories and focusing on products sold in the highest volumes could lead to large decreases in sodium available for con-sumption and therefore to gains in public health. Am J Clin Nutr 2011; 93 : 594 – 600...|$|R
40|$|The second International Reference Preparation of Lymecycline was established. Nine {{laboratories}} in 8 countries collaborated in assaying its potency {{in terms}} of the first International Reference Preparation, of which stocks had become exhausted. The best estimate of potency was taken to be 948 IU/mg, which was the <b>unweighted</b> geometric <b>mean</b> of a total of 124 assays. On this basis, the International Unit of lymecycline was defined as the activity contained in 0. 0010548 mg of the second International Reference Preparation...|$|R
40|$|Nonresponse pervades survey {{samples of}} households, and devising methods to handle survey nonresponse {{continues}} to receive substantial attention among statisticians and econometricians. 1 Interest centers {{on whether the}} data are missing completely at random (MCAR), missing at random (MAR, alternatively known as ignorable nonresponse or selection on observables), or missing nonrandomly (MNR, also known as nonignorable nonresponse or selection on unobservables). The distinction is important because unadjusted estimates of model parameters (e. g., <b>unweighted</b> <b>means</b> or least squares coefficients) are consistent when the data are MCAR; however, if the data are MAR or MNR then some adjustment (e. g., bounds, weights, instruments, or assumptions about the missingness process) is needed for consistent estimation. The objective of this technical report is twofold. First, as background material we provide a survey of common methods used to address unit nonresponse, making sharp distinctions between data that are MCAR, MAR, and MNR. The methods described are useful {{in a variety of}} situations where social scientists confront contaminated data. Second, and more specific to the Child Support Demonstration Evaluation (CSDE), we describe briefly the Survey of Wisconsin Works Families (SWWF), a survey of resident parents (RP) and nonresident parents (NRP) associated with the CSDE, and then estimate model...|$|R
30|$|For the {{juvenile}} stands, K-MSN and K-MSN FPW ΔCL {{was less than}} 1 standard deviation higher than the <b>unweighted</b> <b>mean.</b> The K-MSN estimate was higher than the K-MSN FPW estimate. For ΔCD 2, K-MSN and K-MSN FPW estimates were slightly higher than the mean (less than 1 standard deviation). For the total ΔC 2, the estimates were less than 1 standard deviation different, and the standard deviations were very large compared to the means, indicating {{a large amount of}} variability at the site.|$|E
40|$|Graduation date: 1998 Measuring {{the source}} and {{magnitude}} of components of variation has important applications in industrial, environmental and biological studies. This thesis considers the problem of constructing confidence intervals for variance components in Gaussian mixed linear models. A number of methods based on the usual ANOVA mean squares have been proposed for constructing confidence intervals for variance components in balanced mixed models. Some authors have suggested extending balanced model procedures to unbalanced models by replacing the ANOVA mean squares with mean squares from an unweighted means ANOVA. However, the unweighted means ANOVA is only defined for a few specific mixed models. In Chapter 2 we define a generalization of the unweighted means ANOVA for the three variance component mixed linear model and illustrate how the mean squares from this ANOVA {{may be used to}} construct confidence intervals for variance components. Computer simulations indicate that the proposed procedure gives intervals that are generally consistent with the stated confidence level, except in the case of extremely unbalanced designs. A set of statistics that can be used {{as an alternative to the}} generalized <b>unweighted</b> <b>mean</b> squares is developed in Chapter 3. The intervals constructed with these statistics have better coverage probability and are often narrower than the intervals constructed with the generalized <b>unweighted</b> <b>mean</b> squares...|$|E
30|$|At the {{regenerating}} clearcut, unweighted ΔC 2 {{was within}} 1 {{standard deviation of}} the CBM-CFS 3 estimates of ΣNEP, and closest to unweighted CBM-CFS 3 ΣNEP. The <b>unweighted</b> <b>mean</b> of ΔC 2, ΔC 2 K-MSN, and ΔC 2 K-MSN FPW were greater than 1 standard deviation higher than the EC flux tower estimate of ΣNEP. ΔC 2 K-MSN was within 1 standard deviation of the CBM-CFS 3 unweighted ΣNEP. Both ΔC 2 K-MSN and ΔC 2 K-MSN FPW were greater than 1 standard deviation higher than ΣNEP CBM-CFS 3 FPW (Table  6).|$|E
40|$|This {{program for}} three-factor {{analysis}} of variance with repeated measures on two factors {{is based on an}} <b>unweighted</b> <b>means</b> analysis, permitting the use of unequal sample sizes. Each factor may be fixed or random since the program will select an appropriate error term or will calculate a quasi-F ratio. The number of possible levels of each factor is extended over those in other programs. Rounding errors are minimized. A special three-factor {{analysis of variance}} design in which there are repeated observations on two factors has been used frequently in educational and psychological research. This design has been dis-cussed and illustrated in experimental design text books (Lindquist, 1953, pp. 292 - 297; Winer, 1971, pp. 539 - 559). Computer programs are available for this design. However, existing programs suffer from the following limitations: (1) they require equal sample sizes for each level of the nonrepeated factor; (2) their use is restricted to conditions where all factors are fixed or where the user can instruct the computer to select an appropriate error term; (3) on small com-puters like the IBM 1130 the limited core memory severely restricts the number of levels of each factor; and (4) rounding errors cumu-late to produce only approximate results...|$|R
5000|$|... where [...] Therefore, {{the bias}} in our {{estimator}} is , {{analogous to the}} [...] bias in the <b>unweighted</b> estimator. This <b>means</b> that to unbias our estimator we need to pre-divide by , ensuring that the expected value of the estimated variance equals the actual variance of the sampling distribution.|$|R
40|$|We present {{estimates}} of heritability for carcass traits of cattle {{published in the}} scientific literature. Seventy-two papers published form 1962 to 2004, which reported {{estimates of}} heritability for carcass traits, were reviewed. The <b>unweighted</b> <b>means</b> of estimates of heritability for 14 carcass traits by slaughter end point (age, weight, and fat depth) were calculated. Among the three end points, carcass weight, backfat thickness, longissimus muscle area, and marbling score were the carcass traits with the most estimates of heritability (56 ≤n≤ 66). The averages for these traits indicate that they are similarly and moderately heritable (0. 40, 0. 36, 0. 40, and 0. 37, respectively). However, heritability estimates for most traits varied greatly, which {{could be due to}} differences in breed groups, methods of estimation, and effects in the model, number of records, measurement errors, sex, and management. Few studies have compared heritability estimates for carcass traits adjusted to different end points. Results from such studies have been inconsistent, although some studies revealed that heritability estimates for several carcass traits are sensitive to the covariate included in the model for the end point, implying that direct response to selection would be different for some traits depending on slaughter end point. The effect of different end points on estimates of heritability for many carcass traits has not been studied...|$|R
