3|9|Public
40|$|The {{notion of}} a fast <b>uplink</b> <b>grant</b> is {{emerging}} as a promising solution for enabling massive machine type communications (MTCs) in the Internet of Things over cellular networks. By using the fast <b>uplink</b> <b>grant,</b> machine type devices (MTD) will no longer require random access (RA) channels to send scheduling requests. Instead, uplink resources can be actively allocated to MTDs by the base station. In this paper, the challenges and opportunities for adopting the fast <b>uplink</b> <b>grant</b> to support MTCs are investigated. First, the fundamentals of fast <b>uplink</b> <b>grant</b> and its advantages over conventional access schemes: i) fully scheduled with RA process and ii) uncoordinated access, are presented. Then, the key challenges that include the prediction of set of MTDs with data to transmit, {{as well as the}} optimal scheduling of MTDs, are exposed. To overcome these challenges, a two-stage approach that includes traffic prediction and optimized scheduling is proposed. For this approach, various solutions for source traffic prediction for periodic MTD traffic are reviewed and novel methods for event-driven traffic prediction are proposed. For optimal allocation of uplink grants, new solutions based on advanced machine learning methods are presented. By using the proposed solutions, the fast <b>uplink</b> <b>grant</b> has the potential to enable cellular networks to support massive MTCs and effectively reduce the signaling overhead and overcome the delay and congestion challenges of conventional RA schemes...|$|E
30|$|Although NDMA and FF-NDMA were {{initially}} proposed a decade ago, the emerging MTC systems (with different requirements {{than those of}} conventional human-based cellular networks) suggest reviewing random access protocols with MPR and analyzing its applicability to the uplink communication in cellular networks [3], specially for scenarios characterized by {{a large number of}} devices, limited signaling load, low energy consumption, and high reliability. In particular, NDMA-based protocols are highly attractive for massive MTC. NDMA has been deeply analyzed in the recent literature with different protocols (e.g., H-NDMA [31]). However, FF-NDMA misses such wide analysis while it is suitable for massive MTC scenarios due to its low associated signaling load and reduced implementation complexity. Indeed, it is worth mentioning that NB-IoT [11] and the new radio (NR) access technology design for 3 GPP 5 G systems [34] already consider a contention-based transmission mode with a predefined number of packet repetitions (known as uplink grant-free access, in which devices contend for resources, and multiple predefined repetitions are allowed, as specified in [34]). Such <b>uplink</b> <b>grant</b> free access in NR targets at least for massive MTC and would allow the implementation of FF-NDMA.|$|E
40|$|For certain {{event based}} M 2 M applications, it is {{possible}} to predict when devices will or may need to send data on the LTE uplink. For example, in a wireless sensor network, the fact that one sensor has triggered may increase the probability that other sensors in the vicinity may also trigger in quick succession. The existing reactive LTE uplink access protocol, in which a device with pending data sends a scheduling request to the eNodeB at its next scheduled opportunity, and the eNodeB responds with an <b>uplink</b> <b>grant,</b> can lead to high latencies. This is particularly the case when the system utilizes a high scheduling request period (of up to 80 ms) to support a large number of devices in a cell, which is characteristic of M 2 M deployments. In this paper, we introduce, analyze and simulate a new predictive/proactive resource allocation scheme for the LTE uplink for use with event based M 2 M applications. In this scheme, when one device in a group sends a scheduling request, the eNodeB identifies neighbor devices in the same group which may benefit from a predictive resource allocation in lieu of waiting for those neighbors to send a scheduling request at their next scheduled opportunity. We demonstrate how the minimum uplink latency can be reduced from 6 ms to 5 ms and how the mean uplink latency can be reduced by greater than 50 % (in certain scenarios) using this method...|$|E
5000|$|The Physical Downlink Control Channel (PDCCH) carries between {{others the}} {{downlink}} allocation information, <b>uplink</b> allocation <b>grants</b> for the terminal.|$|R
3000|$|... (2) is {{dynamically}} {{given in}} the <b>uplink</b> scheduling <b>grant</b> and can take eight values, i.e., { 0, 2, 3, 4, 6, 8, 9, 10 }, and n [...]...|$|R
30|$|For the {{congestion}} {{in random}} access, Physical Downlink Shared Channel (PDSCH) resources of LTE are deemed sufficient in most communication scenarios. To ease the congestion {{on the air}} interface, those downlink assignments and <b>uplink</b> <b>grants</b> for MTC devices, which cannot be served by Physical Downlink Control Channel (PDCCH), can be aggregated into a transport block on PDSCH identified by a special radio network terminal identifier (RNTI) called MTC-RNTI [80]. MTC devices monitor PDCCH channel with their own cell RNTI and MTC-RNTI simultaneously. Game theory {{has been used for}} the context of cellular M 2 M to optimize preamble allocation [81]. In addition, a detailed random access related proposals are summarized in [15], which can be a complement of our categorization.|$|R
40|$|The control {{channels}} in LTE are provided to support efficient data transmission. Control information about resource allocation or <b>Uplink</b> <b>grants</b> {{has to be}} sent to every UE in the form of Downlink Control Information (DCI) through Physical Downlink Control Channel (PDCCH). PDCCH. If UE fails to decode its intended DCI resources allocated in shared channel will become futile. PDCCH allocated with limited resources and every scheduled UE has to be served and serviced. These resources become scarcer as the number of UEs increase within the network. As such, the PDCCH design becomes crucial to meet continuously increasing demand for ever increasing data transmission. This thesis explains design of PDCCH, its performance is simulated in different channel conditions and conclusion for resource allocation every UE based on its channel conditions are drawn for better performance and efficient utilization of resources...|$|R
40|$|We {{propose a}} {{predictive}} resource allocation scheme for the LTE uplink based upon Maximum Likelihood Estimation of event propagation characteristics for M 2 M/Smart Grid applications. The LTE eNodeB estimates the inter-sensor propagation {{time of a}} disturbance using the pattern and timing of received Scheduling Requests (SRs) from sensors and then proceeds to predict the time at which the disturbance will reach downstream sensors, facilitating predictive <b>uplink</b> <b>grants</b> for these sensors {{in order to reduce}} the mean latency of their uplink data packets by up to 50 % (according to a performance analysis) compared to the existing standard reactive LTE uplink resource allocation scheme. A further benefit is that when a predictive resource allocation is successful, the sensor does not need to send an SR, thereby freeing up uplink resources which can be critical with M 2 M communications. We consider various transition strategies from the estimation to prediction phases which reflect the compromise between estimation speed and accuracy, and also examine the concept of early and late prediction...|$|R
40|$|A {{canonical}} {{scenario in}} Machine-Type Communications (MTC) {{is the one}} featuring {{a large number of}} devices, each of them with sporadic traffic. Hence, the number of served devices in a single LTE cell is not determined by the available aggregate rate, but rather by the limitations of the LTE access reservation protocol. Specifically, the limited number of contention preambles and the limited amount of <b>uplink</b> <b>grants</b> per random access response are crucial to consider when dimensioning LTE networks for MTC. We propose a low-complexity model of LTE's access reservation protocol that encompasses these two limitations and allows us to evaluate the outage probability at click-speed. The model is based chiefly on closed-form expressions, except for the part with the feedback impact of retransmissions, which is determined by solving a fixed point equation. Our model overcomes the incompleteness of the existing models that are focusing solely on the preamble collisions. A comparison with the simulated LTE access reservation procedure that follows the 3 GPP specifications, confirms that our model provides an accurate estimation of the system outage event and the number of supported MTC devices. Comment: Submitted, Revised, to be presented in IEEE Globecom 2015; v 3 : fixed error in eq. (4...|$|R
30|$|In LTE networks, each UE {{performs}} {{random access}} (RA) procedures to transmit data during the access grant time interval (AGTI) or RA slots over a time-frequency radio resource called physical {{random access channel}} (PRACH). A UE initiates the RA mechanism in two cases [42]. Firstly, when a UE is turned on and the uplink timing synchronization is either lost or not yet achieved. Secondly, whenever a handover mechanism is performed from a serving eNB to a target eNB. In LTE, UEs perform the RA procedure for several reasons such as for establishing a communication link, re-initiating a radio link after a failure, for radio resources in case of no <b>uplink</b> resource <b>grant,</b> and scheduling requests {{in the absence of}} dedicated physical uplink control channels (PUCCHs).|$|R
30|$|PDCCH carries {{downlink}} scheduling {{assignments and}} <b>uplink</b> scheduling <b>grants.</b> The information {{fields in the}} scheduling assignments and scheduling grants include resource allocation information, transport format information, and HARQ information. Since there is no HARQ mechanism in PDCCH {{and the failure of}} PDCCH transmission will directly lead to failure of subsequent PDSCH transmission, the BLER target is set to 1 % for the purpose of reliable PDCCH transmission. The MCS for transmission of PDCCH payload is QPSK modulation with four different effective coding rates of 2 / 3, 1 / 3, 1 / 6, and 1 / 12, corresponding to aggregation level of 1, 2, 4, 8 CCEs, respectively. A user in favorable radio channel conditions may require just 1 CCE with QPSK 2 / 3. Adaptive coding can be used to aggregate 2, 4, or even 8 CCEs with lower effective coding rate, thus improving the PDCCH coverage for users in worse radio channel conditions.|$|R
40|$|A {{common theme}} in the {{publications}} included in this thesis {{is the quality of}} service and resource management in IP and wireless networks. This thesis presents novel algorithms and implementations for admission control in IP and IEEE 802. 16 e networks, active queue management in EGPRS, WCDMA, and IEEE 802. 16 e networks, and scheduling in IEEE 802. 16 e networks. The performance of different algorithms and mechanisms is compared with the prior art through extensive ns- 2 simulations. We show that similar active queue management mechanisms, such as TTLRED, can be successfully used to reduce the downlink delay (and in some cases even improve the TCP goodput) in different bottlenecks of IP, EGPRS, WCDMA, and IEEE 802. 16 e access networks. Moreover, almost identical connection admission control algorithms can be applied both in IP access networks and at IEEE 802. 16 e base stations. In the former case, one just has to first gather the link load information from the IP routers. We also note that DiffServ can be used to avoid costly overprovisioning of the backhaul in IEEE 802. 16 e networks. We present a simple mapping between IEEE 802. 16 e data delivery services and DiffServ traffic classes, and we propose that IEEE 802. 16 e base stations should take the backhaul traffic load into account in their admission control decisions. Moreover, different IEEE 802. 16 e base station scheduling algorithms and uplink channel access mechanisms are studied. In the former study, we show that proportional fair scheduling offers superior spectral efficiency when compared to deficit round-robin, though in some cases at the cost of increased delay. Additionally, we introduce a variant of deficit round-robin (WDRR), where the quantum value depends on the modulation and coding scheme. We also show that {{there are several ways to}} implement ertPS in an efficient manner, so that during the silence periods of a VoIP call no <b>uplink</b> slots are <b>granted.</b> The problem here, however, is how to implement the resumption after the silence period while introducing as little delay as possible...|$|R

