0|10000|Public
40|$|This study {{examines}} {{the extent of}} nonresponse bias in online advertising conversion studies. Two indicators (i. e., conversion rates and travel expenditure) assessing the tourism advertising effectiveness were compared <b>using</b> <b>unweighted</b> <b>and</b> weighted data sets. The {{results of this study}} using 24 locations throughout the U. S. confirm the conclusions of previous studies, showing consistent overestimates in advertising effectiveness. Several methodological and managerial implications of these findings are discussed...|$|R
40|$|We {{show that}} for every n-point metric space M there exists a {{spanning}} tree T with <b>unweighted</b> diameter O(n) <b>and</b> <b>weight</b> ω(T) = O(n) ·ω(MST(M)). Moreover, there is a designated point rt such {{that for every}} point v, dist_T(rt,v) 0. We extend this result, and provide a tradeoff between <b>unweighted</b> diameter <b>and</b> <b>weight,</b> <b>and</b> prove that this tradeoff is tight up to constant factors in {{the entire range of}} parameters. These results enable us to settle a long-standing open question in Computational Geometry. In STOC' 95 Arya et al. devised a construction of Euclidean Spanners with <b>unweighted</b> diameter O(n) <b>and</b> <b>weight</b> O(n) ·ω(MST(M)). Ten years later in SODA' 05 Agarwal et al. showed that this result is tight up to a factor of O(n). We close this gap and show that the result of Arya et al. is tight up to constant factors. Comment: 41 pages, 11 figure...|$|R
30|$|The CC {{standard}} data were studied <b>using</b> <b>unweighted</b> linear regression <b>and</b> weighted linear regression with a weighting factor of 1 /x, 1 /√x, and 1 /x 2. The data analysis {{was carried out}} using Microsoft ® Excel ® 2016 MSO (64 -bit).|$|R
40|$|Differential {{weighting}} {{promises to}} improve the validity of a measure. This study examines whether similar results would be found <b>using</b> weighted, <b>unweighted</b> <b>and</b> standardized z scores from the All Stars Core survey. It was concluded that the weighted systems were developed to equate the questions within the scales and to ease the process for customers without access to data analysis programs; however, the standardized scores were the more appropriate method for equating the test items...|$|R
30|$|All dense stereo {{matching}} algorithms use some method of measuring {{the similarity of}} pixels between the two image views. Typically, a matching function is computed at each pixel for all disparities under consideration. The simplest matching functions assume {{that there is little}} or no luminance difference between corresponding left/right pixels, but more robust methods may allow for (explicitly or implicitly) radiometric changes and/or noise. Common pixel-based matching functions include absolute differences, squared differences, or sampling-insensitive absolute differences [27]. Common window-based matching functions include the sum of absolute or squared differences (SAD, SSD), normalized cross-correlation (NCC), and rank and census transforms [28]. Some matching functions can be implemented efficiently <b>using</b> <b>unweighted</b> <b>and</b> weighted median filters [29, 30]. More complicated similarity measures are possible and have included mutual information or approximate segment-wise mutual information as used in the layered stereo approach of Zitnick [31]. Some methods not only try to employ new combined matching functions but also propose secondary disparity refinement to further remove the remaining outliers [32].|$|R
40|$|Significant {{differences}} were found between opioid takers and non-takers among referrals to Jervis Street Drug Advisory and Treatment Centre, Dublin, for the following variables: Sex, Age, Employment Status, Prior Court Appearance, Solitary drug taking. First drug taken abroad. Injection history. Physical complications associated with drug taking, and Maternal psychiatric status (for referrals aged under 21). Further analysis indicated 6 types of abuse associated with particular personal and social circumstances: (1) Minor tranquillisers, (2) Barbiturates only or with minor tranquillisers, (3) Opioids only or mainly, (4) Cannabis and/or L. S. D. only, (5) Poly-abuse excluding opioids, and (6) Poly-abuse including opioids. In broad social terms, these 6 groups may be seen as representing psychiatric or personal inadequacy-groups (1), (2) and (3), subcultural deviance-(5) and (6), and subcultural hedonism in the context of poor family relationships-(4). Groups most at risk were considered to be in the following order-(2), (3), (6),(1). Finally, cluster analyses, <b>using</b> <b>unweighted</b> <b>and</b> weighted variables, were employed to test the significance of distinctions based on types (3), (4), (5) and (6). In general, similar groups were obtained...|$|R
40|$|Abstract Background Multilevel models (MLM) offer complex {{survey data}} analysts a unique {{approach}} to understanding individual and contextual determinants of public health. However, little summarized guidance exists {{with regard to}} fitting MLM in complex survey data with design weights. Simulation work suggests that analysts should scale design weights using two methods and fit the MLM <b>using</b> <b>unweighted</b> <b>and</b> scaled-weighted data. This article examines the performance of scaled-weighted <b>and</b> <b>unweighted</b> analyses {{across a variety of}} MLM and software programs. Methods Using data from the 2005 – 2006 National Survey of Children with Special Health Care Needs (NS-CSHCN: n = 40, 723) that collected data from children clustered within states, I examine the performance of scaling methods across outcome type (categorical vs. continuous), model type (level- 1, level- 2, or combined), and software (Mplus, MLwiN, and GLLAMM). Results Scaled weighted estimates and standard errors differed slightly from unweighted analyses, agreeing more with each other than with unweighted analyses. However, observed differences were minimal and did not lead to different inferential conclusions. Likewise, results demonstrated minimal differences across software programs, increasing confidence in results and inferential conclusions independent of software choice. Conclusion If including design weights in MLM, analysts should scale the <b>weights</b> <b>and</b> use software that properly includes the scaled weights in the estimation. </p...|$|R
40|$|BACKGROUND: High-quality {{non-invasive}} imaging of {{the deep}} venous system in the thorax is challenging, but nevertheless required for diagnosis of vascular pathology {{as well as for}} patient selection and preoperative planning for endovascular procedures. PURPOSE: To compare the diagnostic quality of Gadofosveset-enhanced thoracic magnetic resonance venography, seven consecutive patients with suspected or known disease affecting the central thoracic veins were compared to seven consecutive magnetic resonance venography using conventional gadolinium-based contrast agents. MATERIALS AND METHODS: Diagnostic capability, defined as the ability to assess vessel patency and pathologic conditions, for the major thoracic deep venous segments was assessed by two-independent readers. Both reviewers rated the overall subjective image quality on a four-graded scale, and inter-rater variability was analyzed <b>using</b> <b>unweighted</b> <b>and</b> weighted Cohen's kappa values. RESULTS: Diagnostic capability was generally considerably higher in the Gadofosveset group for all examined vessel segments. The overall images quality rating was significantly higher for the Gadofosveset group with a mean rating of 2. 9 and 2. 7 for the two-independent readers, compared to 1. 2 and 1. 0 for the control croup. Inter-rater variability showed less variability for the Gadofosveset group with a quadratic-weighted Cohen's Kappa value of 0. 58 compared to 0. 36 for the control group. CONCLUSION: Our results show that Gadofosveset-enhanced magnetic resonance venography of the central thoracic veins is a reliable technique in clinical routine practice that results in diagnostic images, superior to conventional gadolinium-based contrast medium...|$|R
40|$|This study {{examines}} {{the relationship between}} the level of disclosure and its determinants, more specifically those relating to corporate governance mechanisms. The theoretical framework of the relationship between governance and the level of disclosure is proposed by the agency theory. For a sample of non-financial listed Tunisian companies for a period of 2004 - 2009. We built an index to approximate the extent of disclosure. We also <b>used</b> an <b>unweighted</b> <b>and</b> weighted index based on the views of financial information users (banker, Analyst, Financial Market Board, shareholders). The results show that the level of disclosure is explained by the size, leverage, profitability, duality, concentration of ownership and control quality as measured by the number of auditors and the presence of Big 4. Key words: Weighted disclosure index, corporate governance, board of directors, ownershi...|$|R
40|$|Females of Galodoxa torquata Nagy, 1974, {{from the}} Oriental region, are {{promptly}} {{recognized by the}} deeply incised and bifurcate posterior margin of the fourth metasomal sternite. Because of this unusual character Nagy (1974) established a subfamily to accommodate it, but a superficial examination indicates that this species might be better placed in the tribe Sclerodermini. In order to test the hypothesis, it is redescribed, illustrated, and cladistically compared with data in literature of representative species of almost all genera of Sclerodermini and three outgroup species. A total of 72 characters extracted from literature are evaluated. The analyses were executed with equally weighted parsimony <b>and</b> implied <b>weighting.</b> Both <b>unweighted</b> <b>and</b> implied <b>weighting</b> results support the placement of Galodoxa into the tribe Sclerodermini. The monotypic subfamily Galodoxinae is therefore treated as new synonym of the subfamily Epyrinae and the genus Galodoxa Nagy, 1974 is transferred to the tribe Sclerodermini...|$|R
40|$|Export {{diversification}} theory came to {{the fore}} {{in the second half of}} the twentieth century, in opposition to the classical and neoclassical theories of foreign trade. It defends the positive impact of trade diversification on the economic performance of a country. The question of how much big economies diversify their exports in the case of product groups and export destinations is answered in this paper. Three different indices are used, describing various features of export diversification in two dimensions <b>using</b> the <b>unweighted</b> <b>and</b> the study’s own weighted approach to values. It is shown by the analysis that the EU has achieved the greatest long-term export diversification for both product and territorial diversification. The BRICS countries have increased their export position in the world economy through the intensive and extensive margin, but from the perspective of the Herfindahl–Hirschman index of diversification, they have experienced very different developments of product and territorial diversification...|$|R
40|$|Estimating {{regional}} demand models by pooling different samples without correcting {{for such}} differences causes model misspecification as each sample {{belongs to a}} different population. Weighted regression using Pseudolikelihood to account for differences in sample population with adjustment for heteroskedasticity improves efficiency but the estimates are biased. We estimate regional demand for National Forest settings types in the southeastern states of U. S <b>using</b> weighted <b>and</b> <b>unweighted</b> regression. <b>Using</b> estimation of demand for National Forests as a case study, we resolve problems relating to inference about the data generating process when different samples are pooled together. We show that though efficiency of weighted estimates improves after correcting for heteroskedasticity, they still remain biased as the weights interact with covariates to explain part of model misspecification. In this paper, we show that {{it is best to}} <b>use</b> <b>unweighted</b> regression including interactions with weights as covariates. exogenous stratification, endogenous stratification, choice based data, outdoor recreation, Environmental Economics and Policy, Q 000, Q 500,...|$|R
40|$|OBJECTIVE: To {{assess whether}} {{ultrasonography}} (US) is reliable {{for the evaluation}} of inflammatory and structural abnormalities in patients with knee osteoarthritis (OA). METHODS: Thirteen patients with early knee OA were examined by 11 experienced sonographers during 2 days. Dichotomous and semiquantitative scoring was performed on synovitis characteristics in various aspects of the knee joint. Semiquantitative scoring was done of osteophytes at the medial and lateral femorotibial joint space or cartilage damage of the trochlea and on medial meniscal damage bilaterally. Intra- and interobserver reliability were computed by <b>use</b> of <b>unweighted</b> <b>and</b> weighted kappa coefficients. RESULTS: Intra- and interobserver reliability scores were moderate to good for synovitis (mean kappa 0. 67 and 0. 52, respectively) as well as moderate to good for the global synovitis (0. 70 and 0. 50, respectively). Mean intra- and interobserver reliability kappa for cartilage damage, medial meniscal damage and osteophytes ranged from fair to good (0. 55 and 0. 34, 0. 75 and 0. 56, 0. 73 and 0. 60, respectively). CONCLUSIONS: Using a standardised protocol, dichotomous and semiquantitative US scoring of pathological changes in knee OA can be reliable...|$|R
40|$|International {{audience}} 1. Many {{studies have}} identified relationships between plant reproductive behaviour and environmental conditions. However, {{they have all}} been based on cross-species analysis and take no account of the relative abundance of species with vegetation. 2. Using two reproductive traits - seed mass and dispersal vector - as examples, a range of previously identified relationships were tested <b>using</b> both <b>unweighted</b> <b>and</b> weighted-by-abundance data collected from land-use transitions at 12 sites across Europe. 3. Seed mass was correlated positively with most measures of temperature (stronger relationships for <b>unweighted</b> data) <b>and</b> declined against measures of disturbance (stronger relationships with weighted data). It was not related consistently to measures of water availability. 4. There was some evidence that endozoochory was associated with damper environments, hoarding with drier ones and exozoochory with more fertile habitats. 5. Weighting reduced the slope of relationships between seed mass and environmental variables, possibly indicating that dominance within vegetation is determined by land use after the operation of a climatic filter. Fewer significant relationships were detected for weighted dispersal mechanisms compared to unweighted ones, indicating less difference of the dominants from other species with regard to this trait. 6. Synthesis. This analysis shows that weighting by abundance in the vegetation (compared to unweighted analysis) has {{a significant impact on}} the relationships between key species traits and a range of environmental parameters related to climate and land use, and that this impact was not consistent in its effects...|$|R
40|$|Background: Hallux valgus (HV) is {{a common}} {{condition}} involving the progressive subluxation of the first metatarsophalangeal joint due to lateral deviation of the hallux and medial deviation of the first metatarsal. The objective {{of this study was}} to evaluate the re-test reliability and validity of self-assessment of HV using a simple clinical screening tool involving four standardised photographs (the Manchester scale), in order to determine whether this tool could be used for postal surveys of the condition. Methods: HV was assessed with the Manchester scale in 138 people aged 65 to 93 years of age (102 women and 36 men) as part of a larger randomised controlled trial. At the six month follow-up assessment, HV was reassessed to determine re-test reliability, and participants were asked to self-assess their degree of HV independent of the examiners. Associations between (i) baseline and follow-up assessments of the examiners and (ii) participant and examiner assessments were performed using weighted kappa statistics. Analyses were then repeated after HV was dichotomised as present or absent <b>using</b> <b>unweighted</b> kappa, <b>and</b> sensitivity and specificity of self-assessment of HV was determined. Results: Re-test reliability of the examiners was substantial to almost perfect (weighted kappa = 0. 78 to 0. 90), and there was a substantial level of agreement between observations of the participants and the examiners (weighte...|$|R
40|$|An {{important}} and difficult problem in computer vision {{is to determine}} 2 D image feature correspondences over a set of images. In this paper, two new affinity measures for image points and lines from different images are presented, and are <b>used</b> to construct <b>unweighted</b> <b>and</b> weighted bipartite graphs. It is shown that the image feature matching problem {{can be reduced to}} an unweighted matching problem in the bipartite graphs. It is further shown that the problem can be formulated as the general maximum-weight bipartite matching problem, thus generalizing the above unweighted bipartite matching technique. Keywords: image feature matching, bipartite matching, image sequence analysis, computer vision 1 INTRODUCTION A fundamental and important problem in computer vision is to acquire 3 D models of objects and scenes from a set of images. The basic principles involved in 3 D model acquisition are feature matching and triangulation, with the two commonly used types of image features being points an [...] ...|$|R
40|$|International {{audience}} A star is a graph {{in which}} some vertex is incident with every edge of the graph, i. e. a graph of diameter at most 2. A star forest is a graph in which each connected component is a star.  Given a connected graph G in which the edges may be weighted positively. A spanning star forest of G is a subgraph of G which is a star forest spanning the vertices of G. The size of a spanning star forest F of G is defined to be the number of edges of F if G is <b>unweighted</b> <b>and</b> the total <b>weight</b> of all edges of F if G is weighted. We {{are interested in the}} problem of finding a Maximum Weight spanning Star Forest (MWSFP) in G. In CTNguyen, the authors introduced the MWSFP and proved its NP-hardness. They also gave a polynomial time algorithm for the MWSF problem when G is a tree.|$|R
40|$|The genera Speiropsis and Xylomyces are anomorph fungi. The taxonomic {{address for}} the fungi has been unclear. In this study, {{observation}} of morphological traits indicates {{that they have}} a unique pattern of mycelia with dark-brown to black colour and thick-walled hyphae. The same culture patterns of certain fungi isolated from freshwater habitats in Thailand were selected from BIOTEC Culture Collection (BCC, Thailand), while more species were added from Centraalbureau voor Schimmelcultures (CBS, Netherlands). These fungi were composed of Jahnula spp. (2 -celled ascospores), Brachiosphaera tropicalis (hyaline and 4 - 5 armed conidia), S. pedatospora (hyaline and branches conidia) and Xylomyces sp. (dematiaceous and fusiform chlamydospores). This study was undertaken to confirm the taxonomic address for S. pedatospora and Xylomyces based on phylogenetics relationships as inferred from their ITS rDNA sequence data by <b>using</b> MP (<b>unweighted</b> <b>and</b> successive weighted MP), NJ, ML and Bayesian analysis. Phylogenic analysis revealed that isolates of S. pedatospora (2 strains) {{was a member of the}} Order Jahnulales and clustered with Jahnula spp. (5 strains) and B. tropicalis (4 strains) with > 82 % bootstrap support and 100 % posterior probabilities. Four isolates of X. chlamydosporus, X. elegans and X. aquaticus were shown to be polyphyletic within the Jahnulales and Pleoporales. The MP and NJ showed the same topology as in the Jahnulales clade obtained by ML analysis...|$|R
30|$|Sequences were {{rarefied}} {{prior to}} calculating alpha and beta diversity statistics. Alpha diversity indices were calculated in QIIME from rarefied samples using the Shannon and Simpson indexes for diversity, and the Chao 1 and ACE indexes for richness. Statistical {{analysis was performed}} with the Student’s t test using IBM SPSS Statistics 24 (IBM Corp., Armonk, NY, USA) {{and the results are}} presented as the mean[*]±[*]standard deviation. Beta diversity was calculated <b>using</b> weighted <b>and</b> <b>unweighted</b> UniFrac distances, <b>and</b> principal coordinate analysis (PCoA) was performed. An arithmetic mean phylogenetic tree was constructed from the beta diversity distance matrix with an unweighted pair group method. The Student’s t-test was employed for analysis of the relative abundance at the phylum and genus levels. A probability (p) value of<[*] 0.05 was considered statistically significant. Differences between the two groups were compared using STAMP (2.1. 3) analysis.|$|R
40|$|Consistent and {{reliable}} procedures for generating calibrations {{are essential to}} accurate laboratory results. Unfortunately the interpretation of acceptable practice is often based on misunderstanding or derived from practices commonly utilized in non-environmental methods, and therefore {{does not provide a}} reliable means for maintaining data quality. This paper presents a demonstration that some common practices used in the calculation and evaluation of calibration factors, including the <b>use</b> of <b>unweighted</b> regression <b>and</b> the associated correlation coefficient, are inappropriate for environmental analysis due to high relative errors which result {{at the low end of}} the curve. Alternate criteria for evaluation of calibration curves are proposed based on the Relative Standard Error (%RSE). Statistical derivations and examples are presented to demonstrate how this approach provides an improved measure for the evaluation of calibration data based on weighted regression. Other related considerations for assessing acceptability of calibration data are also presented...|$|R
40|$|The {{purpose of}} this {{research}} is to examine how environmental committees, institutional shareholdings, and board independence affect managerial carbon disclosure decisions, particularly those of firms belonging to highly polluting industries. We focus on Italian firms that operate in a code law environment but that have the option either to adopt the unitary corporate structure prevalent in common law countries or to retain the dual corporate structure used in code law countries. We <b>use</b> weighted <b>and</b> <b>unweighted</b> carbon disclosure indexes based on the Kyoto Protocol requirements. The findings show that all factors greatly affect voluntary carbon disclosure and that their impact is especially strong for firms in highly polluting industries. This study has important implications for managers and regulators...|$|R
40|$|In {{this paper}} we propose a method based on {{weighted}} regression for the estimation of risk in nested Monte Carlo simulation. The mean squared error (MSE) of a standard nested simulation converges at the rate k − 2 / 3, where k is the computational budget. Similar to the regression method proposed in Broadie, Du, and Moallemi (2011 b), the MSE of the proposed weighted regression method converges at the rate k − 1 until reaching an asymptotic bias level, which depends {{on the size of the}} regression error. However, the weighted approach further reduces MSE by emphasizing scenarios that are more important to the calculation of the risk measure. We find a globally optimal weighting strategy for general risk measures in an idealized setting. For applications, we propose and test a practically implementable two-pass method, where the first pass <b>uses</b> an <b>unweighted</b> regression <b>and</b> the second pass uses weights based on the first pass. ...|$|R
40|$|Certification of {{the phase}} {{compositions}} {{of the three}} NIST Reference Clinkers will be based upon more than one independent method. The current reference values were established using an optical microscope examination, with additional optical microscope data taken from an ASTM C 1356 round robin. The present X-ray powder diffraction (XRD) study provides the second, independent estimate of the phase abundance. Reitveld refinement of the powder diffraction data allowed calculation {{of a set of}} best-fit reference patterns and their scale factors. Because of significant contrast in the linear absorption coefficients of ferrite and periclase, relative to the estimated mean matrix linear absorption coefficient, the scale factors were adjusted for microabsorption effects. The XRD data agree with the optical data with the exception of aluminate. This disagreement may reflect the difficulty in resolving this fine-sized phase using the optical microscope. The XRD data did show greater precision than replicate measurements by microscopy. Measurements from different sources, laboratories, instruments, and from different methods can exhibit significant between-method variability, as well as distinct within-method variances. The data sets were treated <b>using</b> both <b>unweighted</b> <b>and</b> weighted schemes to establish the bestconsensus values and to provide meaningful uncertainties. While the mean values of individual phase abundance do not vary, the 95 % uncertainty level values do. The Mandel-Paule-Vangel-Rukhin method of combining the data sets is favored as this method produces a weighted mean whose weighting scheme does not necessarily skew the consensus value {{in the direction of the}} large number of XRD values, and that takes between- as well as within-method variation into account...|$|R
40|$|This paper {{describes}} the local polynomial method (LPM) for estimating the time- invariant bioimpedance {{frequency response function}} (FRF) considering both the output-error (OE) and the errors-in-variables (EIV) identi cation framework and compare it with the traditional cross 1 ̆ 00000 and autocorrelation spectral analysis techniques. The bioimpedance FRF is measured with the multisine electrical impedance spectroscopy (EIS) technique. To show the overwhelming accuracy of the LPM approach, both the LPM and the classical cross 1 ̆ 00000 and autocorrelation spectral analysis technique are evaluated through the same experimental data coming from a nonsteady-state measurement of time-varying in vivo myocardial tissue. The estimated error sources at the measurement frequencies due to noise, n Z, and the stochastic nonlinear distortions, NL Z, have been converted to and plotted over the bioimpedance spectrum for each framework. Ultimately, the impedance spectra have been tted to a Cole impedance model <b>using</b> both an <b>unweighted</b> <b>and</b> a weighted complex nonlinear least square (CNLS) algorithm. A table is provided with the relative standard errors on the estimated parameters to reveal the importance of which system identi cation frameworks should be used. Postprint (published version...|$|R
40|$|ABSTRACT. A {{widely held}} {{assumption}} is that postpyloric intubations occur more often with weighted than with un-weighted nasally inserted feeding tubes. This randomized, pro-spective study compared the frequency of duodenal intubations <b>using</b> weighted <b>and</b> <b>unweighted</b> nasoenteric feeding tubes. One hundred sixteen patients had either weighted (61 patients) or unweighted (55 patients) 10 F silicone elastomer feeding tubes inserted nasally 85 cm. Tubes were placed with wire stylets. Tube positions were verified radiographically within 4 hr after insertions. Radiographs were repeated daily for 3 days or until duodenal intubation occurred. Successful duodenal intubations were achieved in 35 patients (57 %) with weighted feeding tubes and in 37 patients (67 %) with unweighted feeding tubes. This difference was not significant. Weighted nasoenteric feeding tubes offer no advantage over unweighted tubes in achievin...|$|R
40|$|The aim of {{this study}} was to {{determine}} whether half-mouth examinations accurately reflect the dental and prosthetic status of the entire mouth. Samples of 1, 830 adults aged 55 - 79 years were examined. The rate of agreement between half- and full-mouth examinations was estimated <b>using</b> weighted <b>and</b> <b>unweighted</b> Kappa values comparing findings of each tooth bilaterally. A power analysis was performed to estimate the number of subjects representing complete dental recordings within a certain power. Subjects showed unweighted Kappa values from 0. 34 - 0. 96. Weighted Kappa values ranged from 0. 74 - 0. 99. A power analysis for unweighted Kappa scores computed that. findings from 122 - 335 individuals were necessary to equal the results obtained using complete dental recordings. Griffith Health, School of Dentistry and Oral HealthNo Full Tex...|$|R
40|$|International audienceA star is a graph {{in which}} some node is {{incident}} with every edge of the graph, i. e., a graph of diameter at most 2. A star forest is a graph in which each connected component is a star. Given a connected graph G in which the edges may be weighted positively. A spanning star forest of G is a subgraph of G which is a star forest spanning the nodes of G. The size of a spanning star forest F of G is defined to be the number of edges of F if G is <b>unweighted</b> <b>and</b> the total <b>weight</b> of all edges of F if G is weighted. We {{are interested in the}} problem of finding a Maximum Weight spanning Star Forest (MWSFP) in G. In [C. T. Nguyen, J. Shen, M. Hou, L. Sheng, W. Miller and L. Zhang, Approximating the spanning star forest problem and its applications to genomic sequence alignment, SIAM J. Comput. 38 (3) (2008) 946 – 962], the authors introduced the MWSFP and proved its NP-hardness. They also gave a polynomial time algorithm for the MWSF problem when G is a tree. In this paper, we present a linear time algorithm that solves the MSWF problem when G is a cactus...|$|R
40|$|The {{definitive}} {{version is}} available at www. blackwell-synergy. comAn important issue in quantitative trait loci (QTL) detection {{is the use of}} phenotypic measurement as a dependent variable. Daughter yield deviations (DYDs) as the unit of choice are not available for all traits of interest. The use of de-regressed proofs (DRPFs) of estimated breeding values (EBVs) is an alternative to using daughter yield deviations. The objective {{of this study was to}} examine possible differences between DYDs and DRPFs within the use of QTL detection. The pedigree used was part of the granddaughter design of the German QTL effort. Consisting marker maps for livestock species were derived from all available data of 16 German Holstein paternal half-sib families with a total of 872 sires. The number of progeny ranged from 19 to 127. A whole genome scan was performed <b>using</b> weighted <b>and</b> <b>unweighted</b> multimarker regression with DYDs, DRPFs and EBVs as dependent variables for the traits milk, fat and protein yields. Results were compared with respect to the number of QTL detected. A similar number of QTL was detected with DRPFs and DYDs. Also, when dependent variables were weighted according to the variance of the trait, a higher number of QTL was detected at the desired level of significance as compared to <b>using</b> <b>unweighted</b> variables. H Thomsen, N Reinsch, N Xu, C Looft, S Grupe, C Kühn, G. A Brockmann, M Schwerin, B Leyhe-Horn, S Hiendleder, G Erhardt, I Medjugorac, I Russ, M Förster, B Brenig, F Reinhardt, R Reents, J Blümel, G Averdunk, E Kal...|$|R
30|$|All {{analyses}} were conducted using SAS 9.4 (SAS Inst. Inc., Cary, NC, USA). The mean abundances (n =  8) of data metrics and each taxon were compared among the feed efficiency groups using a model of contemporary group and Cartesian quadrant [high ADG, high ADFI (ADGHigh–ADFIHigh); high ADG, low ADFI (ADGHigh–ADFILow); low ADG, low ADFI (ADGLow–ADFILow); low ADG, high ADFI (ADGLow–ADFIHigh)] as fixed effects. Significant differences were determined at P <  0.05 with the Benjamini–Hochberg method used for multiple-testing corrections (Benjamini and Hochberg 1995). Multiple-testing corrections were made {{for the number of}} phyla, the number of OTU groups, and other classified taxa groups. Linear contrasts were then applied to significant quadrants to separate whether microbial populations varied by low vs. high ADG, low vs. high ADFI, or their interaction (P <  0.05). Principal coordinates analysis (PCoA) was performed <b>using</b> weighted <b>and</b> <b>unweighted</b> UniFrac analyses (Lozupone and Knight 2005).|$|R
40|$|Data {{obtained}} from longitudinal surveys using complex multi-stage sampling designs contain cross-sectional dependencies among units caused by inherent hierarchies in the data, and within subject correlation arising due to repeated measurements. The statistical methods used for analyzing such data should account for stratification, clustering and unequal {{probability of selection}} as well as within-subject correlations due to repeated measurements. The complex multi-stage design approach {{has been used in}} the longitudinal National Population Health Survey (NPHS). This on-going survey collects information on health determinants and outcomes in a sample of the general Canadian population. This dissertation compares the model-based and design-based approaches used to determine the risk factors of asthma prevalence in the Canadian female population of the NPHS (marginal model). Weighted, <b>unweighted</b> <b>and</b> robust statistical methods were used to examine the risk factors of the incidence of asthma (event history analysis) and of recurrent asthma episodes (recurrent survival analysis). Missing data analysis was used to study the bias associated with incomplete data. To determine the risk factors of asthma prevalence, the Generalized Estimating Equations (GEE) approach was used for marginal modeling (model-based approach) followed by Taylor Linearization and bootstrap estimation of standard errors (design-based approach). The incidence of asthma (event history analysis) was estimated <b>using</b> weighted, <b>unweighted</b> <b>and</b> robust methods. Recurrent event history analysis was conducted using Anderson and Gill, Wei, Lin and Weissfeld (WLW) and Prentice, Williams and Peterson (PWP) approaches. To assess the presence of bias associated with missing data, the weighted GEE and pattern-mixture models were used. The prevalence of asthma in the Canadian female population was 6. 9 % (6. 1 - 7. 7) at the end of Cycle 5. When comparing model-based and design- based approaches for asthma prevalence, design-based method provided unbiased estimates of standard errors. The overall incidence of asthma in this population, excluding those with asthma at baseline, was 10. 5 / 1000 /year (9. 2 - 12. 1). For the event history analysis, the robust method provided the most stable estimates and standard errors. For recurrent event history, the WLW method provided stable standard error estimates. Finally, for the missing data approach, the pattern-mixture model produced the most stable standard errors To conclude, design-based approaches should be preferred over model-based approaches for analyzing complex survey data, as the former provides the most unbiased parameter estimates and standard errors...|$|R
40|$|An {{assessment}} of options {{to mitigate the}} effects of subsidence at low-level radioactive waste disposal sites on the Nevada Test Site was conducted using an informal method of expert judgment. Mitigation options for existing waste cells and future waste cells were identified by a committee composed of knowledgeable personnel from the DOE and DOE-contractors. Eight ranking factors were developed to assess the mitigation options and these factors were scored through elicitation of consensus views from the committee. Different subsets of the factors were applied respectively, to existing waste cells and future waste cells, and the resulting scores were ranked <b>using</b> weighted <b>and</b> <b>unweighted</b> scores. These scores {{show that there is}} a large number of viable mitigation options and considerable flexibility in assessing the subsidence issue with a greater range of options for future waste cells compared to existing waste cells. A highly ranked option for both existing and future waste cells is covering the waste cells with a thick closure cap of compacted native alluvium...|$|R
40|$|A {{large number}} of {{pedestrian}} fatalities were reported in China since the 1990 s, however the exposure of pedestrians in public traffic has never been measured quantitatively using in-depth accident data. This study aimed to investigate the association between the impact speed and risk of pedestrian casualties in passenger vehicle collisions based on real-world accident cases in China. The cases were selected from a database of in-depth investigation of vehicle accidents in Changsha-IVAC. The sampling criteria were defined as (1) the accident was a frontal impact that occurred between 2003 and 2009; (2) the pedestrian age was above 14; (3) the injury according to the Abbreviated Injury Scale (AIS) was 1 +; (4) the accident involved passenger cars, SUVs, or MPVs; and (5) the vehicle impact speed can be determined. The selected IVAC data set, which included 104 pedestrian accident cases, was weighted based on the national traffic accident data. The logistical regression models of the risks for pedestrian fatalities and AIS 3 + injuries were developed in terms of vehicle impact speed <b>using</b> the <b>unweighted</b> <b>and</b> weighted data sets. A multiple logistic regression model on the risk of pedestrian AIS 3 + injury was developed considering the age and impact speed as two variables. It {{was found that the}} risk of pedestrian fatality is 26 % at 50 km/h, 50 % at 58 km/h, and 82 % at 70 km/h. At an impact speed of 80 km/h, the pedestrian rarely survives. The weighted risk curves indicated that the risks of pedestrian fatality and injury in China were higher than that in other high-income countries, whereas the risks of pedestrian casualty was lower than in these countries 30 years ago. The findings could have a contribution to better understanding of the exposures of pedestrians in urban traffic in China, and provide background knowledge for the development of strategies for pedestrian protection. (C) 2010 Elsevier Ltd. All rights reserved...|$|R
40|$|Coordinated {{patterns}} of cortical morphology {{have been described}} as structural graphs and previous research has demonstrated that properties of such graphs are altered in Alzheimer’s disease (AD). However, it remains unknown how these alterations are related to cognitive deficits in individuals, as such graphs are restricted to group-level analysis. In the present study we investigated this question in single-subject grey matter networks. This new method extracts large-scale structural graphs where nodes represent small cortical regions that are connected by edges when they show statistical similarity. <b>Using</b> this method, <b>unweighted</b> <b>and</b> undirected networks were extracted from T 1 weighted structural magnetic resonance imaging scans of 38 AD patients (19 female, average age 7264 years) and 38 controls (19 females, average age 7264 years). Group comparisons of standard graph properties were performed after correcting for grey matter volumetric measurements and were correlated to scores of general cognitive functioning. AD networks were characterised by a more random topology as indicated by a decreased small world coefficient (p = 3. 5361025), decreased normalized clustering coefficient (p = 7. 2561026) and decreased normalized path length (p = 1. 9161027). Reduced normalized path length explained significantly (p = 0. 004) more variance in measurements of general cognitive decline (32 %) in comparison to volumetric measurements (9 %). Altered path length of the parahippocampal gyrus, hippocampus, fusiform gyrus and precuneus showed the strongest relationship with cognitive decline. The present results suggest that single-subject gre...|$|R
30|$|Raw reads were quality {{filtered}} {{to remove}} chimeric reads, reads[*]<[*] 150  bp, or with average phred scores[*]<[*] 20. The remaining high-quality reads were processed using the Quantitative Insights into Microbial Ecology (QIIME) package v 1.8 (Caporaso et al. 2010), merged and clustered into operational taxonomic units (OTUs) {{based on a}} 97 % sequence similarity threshold. Taxonomic assignment was performed against the Greengenes reference database [the Ribosomal Database Project (RDP) Gold database, 2.2]. Next, archaeal and eukaryotic reads were removed to minimize the effect of very low abundance OTUs (Bokulich et al. 2013). Alpha diversity was estimated using the Chao 1, ACE, Shannon and Simpson indices. Beta diversity was determined by principal coordinate analyses (PCoA) (Lozupone and Knight 2005) <b>using</b> weighted <b>and</b> <b>unweighted</b> UniFrac distance metrics. While both weighted <b>and</b> <b>unweighted</b> UniFrac take into account phylogenetic distances between OTUs, unweighted UniFrac distance is a qualitative measure and {{does not take into}} account OTU abundance, and only considers presence/absence (Lozupone and Knight 2005), while weighted UniFrac is a quantitative measure that takes into account OTU abundance (Lozupone et al. 2007). Raw sequence reads were deposited to the National Center for Biotechnology Information Short Read Archive (SRA) under the accession number SRP 1040138.|$|R
50|$|The {{keyboard}} is five octaves (61 notes, C to C), is <b>unweighted,</b> <b>and</b> is not velocity-sensitive.|$|R
40|$|Vietnam is a newly {{emerging}} {{nation that}} is transitioning from a planned economy to a market oriented economy. There are very few previous investigations into the Vietnamese economy found in the literature. This thesis intends {{to be among the}} pioneers by examining, first, the effect of board diversity on earnings quality; second, the effect of board diversity on corporate social disclosure (CSD); third, the relationship between CSD and earnings quality of Vietnamese listed firms. It will also examine whether the relationship between CSD and earnings quality is moderated by state ownership and foreign ownership. Board diversity is identified in two dimensions covering a wide range of attributes. One dimension covers structural attributes and the other dimension covers demographic attributes of the board of directors. Those attributes are then used to construct a diversity-of-boards index (structural dissimilarities among firm boards) and a diversity-in-boards index (demographic dissimilarities among directors within a board). These dimensions are considered as two scenarios. One scenario considers that attributes are equally important, (i. e. <b>unweighted</b> diversity-of-boards <b>and</b> diversity-in-boards indices), while the other scenario considers that attributes are not equally important (i. e. weighted diversity-of-boards and diversity-in-boards indices). The relative importance of attributes is measured using a survey questionnaire from the executives of listed firms that inquire into the relative importance of the attributes of the board of directors. This study then uses these two scenarios to examine the effect of board diversity on earnings quality and on CSD. In this study, earnings quality is a standardised aggregate measure compiled from four accounting-based measures of earnings quality: accruals quality, earnings persistence, earnings predictability, and earnings smoothness. CSD is measured as perceived by stakeholders. This study constructs a three dimensional CSD index where one dimension is the quantity of CSD, and other two relate to disclosure type quality and disclosure item quality. A content analysis of annual reports is used to measure the quantity of CSD. The two aspects of disclosure quality in this CSD index are measured by surveying four stakeholder groups (employees, lawyers and regulators, local communities, and customers) to obtain their perceptions on disclosure type preference (i. e., narrative; monetary quantification; numerical quantification; both monetary and numerical), and about disclosure reporting items (i. e., items in the social indicators of the Global Reporting Initiative 3. 1). Based on agency theory in hypothesis testing, this study finds a significant and positive linear relationship about the effect of diversity-of-boards (<b>using</b> weighted <b>and</b> <b>unweighted</b> indices) on earnings quality. Based on resource dependence theory in hypothesis testing, this study finds a non-linear U-shaped association about the effect of diversity-in-boards (<b>using</b> weighted <b>and</b> <b>unweighted</b> indices) on earnings quality. The results also show that the weighted <b>and</b> <b>unweighted</b> board diversity indices have a similar effect on earnings quality. According to agency theory in hypothesis testing, this study finds that diversity-ofboards (both <b>unweighted</b> <b>and</b> weighted indices) does not {{have a significant impact on}} CSD, thus these findings do not support agency theory. According to resource dependence theory in hypothesis testing, this study finds diversity-in-boards (both <b>unweighted</b> <b>and</b> weighted indices) has a positive effect on CSD. The weighted <b>and</b> <b>unweighted</b> board diversity indices also have a similar effect on CSD. In terms of stakeholder theory and agency theory in hypothesis testing, this thesis finds that earnings quality has a significant and positive effect on CSD, which suggests that stakeholder theory (long term perspective argument) explains better than agency theory (managers‟ opportunistic incentives argument) about the effect of earnings quality on CSD of Vietnamese listed firms. Furthermore, the effect of earnings quality on CSD is weakened when the percentage of shares held by government increases. The percentage of foreign ownership does not impact on the relationship between earnings quality and CSD. Overall, the empirical results of this thesis contribute on three fronts: theory, methodology, and practice. The theoretical front is advanced by testing theoretical propositions in the Vietnamese context; the methodological front is advanced by showing a design and measurement of board diversity indices as well as a design and measurement of CSD instrument. The findings benefit policymakers in better understanding firms‟ CSD practices and stakeholders‟ expectations to improve the current guidelines on the CSD as well as in reviewing the implications of the current corporate governance codes in the context of Vietnam to increase firms‟ reporting transparency and accountability to investors...|$|R
