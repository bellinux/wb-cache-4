21|3|Public
5|$|The {{episode was}} {{directed}} by Carlos Baeza. In {{the background of the}} classroom, there are several portraits of past United States presidents. These were added for the scene where Bart tries to think of a name for his fictional letter writer, and sees a portrait of Woodrow Wilson. Woodrow's voice was performed by Harry Shearer, who did an impression of Ricardo Montalbán. The picture Bart sends Edna is of NHL and WHA star Gordie Howe. The writers had originally wanted to use a picture of American football player Johnny Unitas, but were unable to get the rights to use his image for free. Howe, their second choice, was suggested by Al Jean, who had been a Detroit Red Wings fan growing up. At the end of the episode, Howe's NHL and WHA statistics are shown because the writers decided to try something different in filling a slight time <b>under-run.</b>|$|E
25|$|Earlier, {{household}} {{clothes dryers}} sometimes incorporated a germicidal lamp {{in series with}} an ordinary incandescent lamp; the incandescent lamp operated as the ballast for the germicidal lamp. A commonly used light in the home in the 1960s in 220–240V countries was a circleline tube ballasted by an <b>under-run</b> regular mains filament lamp. Self ballasted mercury-vapor lamps incorporate ordinary tungsten filaments within the overall envelope of the lamp to act as the ballast, and it supplements the otherwise lacking red area of the light spectrum produced.|$|E
6000|$|... "This is {{not being}} very clear, certainly," [...] whispered Sir Gervaise; [...] "but, perhaps by getting hold of {{the other end of}} the rope, we may <b>under-run</b> it, as we sailors say, and come at the meaning--we will let the poor man proceed, therefore. Quite plain, my dear sir, and what have you next to tell us. You left off without saying only half about Sir Reginald." ...|$|E
60|$|That, however, was a {{train of}} thought she did not care to indulge in, {{and in order to}} get rid of it she walked more briskly up a low rise where the grass was already turning white again, over the crest of it, and down the side of another hollow. The prairie rolled just there in wide {{undulations}} as the sea does when the swell of a distant gale <b>under-runs</b> a glassy calm. She had grown fond of the prairie, and its clear skies and fresh breezes had brought the colour to her cheeks and given her composure, though there were times when the knowledge that she was no nearer a decision in regard to Gregory weighed upon her like a chill depressing shadow. She had seen very little of him, and he had not been effusive then. What he felt she could not tell, but it had been a relief to her when he had ridden away again. Then for a while he faded to an unsubstantial, shadowy figure in the back of her mind.|$|R
40|$|Typical {{problems}} (from previous lectures) • Memory leaks aren’t {{just for}} (Objective) C • Tracking malloc() calls • Catching calls to zero length malloc() • Eradicating un-initialized memory • Bulletproofing • Catching leaks • Catching buffer over-runs and <b>under-runs</b> • Assumption for this lecture: {{we do not}} have access to the internals of the memory management routines: malloc(), free(), realloc(), etc. A memory leak in Java public class Stack { private int capacity, size; private Object[] array; / / constructor, size(), push(), &c public E pop() { assert size> 0; Object r = array[ [...] size]; return (E) r;} How does that leak Stack s = new Stack; s. push(a_large_document); s. pop(); / / Now you think the document has gone, and / / you certainly can’t get it back, but / / s. array[0] still points to it, so / / the Java garbage collector will not reclaim it. How do you stop that? public E pop() { assert size> 0; Object r = array[size [...] ]; array[size] = null; return (E) r; Vector. setSize, removeElementAt, removeAllElements, remove, clear; ArrayList. remove, clear; all take care to do this. Typical Problems in C • Allocate zero length blocks • Allocate a block and use its uninitialized contents • Free a block then use it • Call realloc() then use the old pointer • Allocate a block then lose the pointer to it • Read and write beyond the boundaries of a block • Fail to notice any of thesemalloc() Tracking • Put a wrapper around malloc() • aspt_malloc. h #ifdef MALLOC_DEBUG #define aspt_malloc(s) do_aspt_malloc(__LINE__, __FILE__, s) extern void *do_aspt_malloc(long, char const *, size_t); #else #define aspt_malloc(s) malloc(s...|$|R
40|$|Unexpected and {{apparently}} random crashes • In system heap routines • In previously stable places • These bugs {{are hard to}} find, but important to fix – Unpredictable and occur {{in a different place}} to the symptoms – But often remain unidentified and unfixed • There are many tools to help us find these errorsAnalogues • Failure to open file, window, DB connection, … • Failure to close file, window, DB connection, … • Closing one twice • Trying to use one that’s been closed • Correct closing on normal path but that code bypassed on exception — needs test cases that exercise exception raising • Using wrong resource • Misconfiguring device (camera &c) or driver • Memory is onlyone resource; this lecture is not just about memory! Style can help: s: = FileStream read: ‘foobar. txt’. n: = 0. [s atEnd] whileFalse: [s nextLine. n: = n+ 1]. s close. ⇑n “compare with” ⇑(FileStream read ‘foobar. txt’) bindOwn: [:s | n: = 0. [s atEnd] whileFalse: [s nextLine. n: = n+ 1]. n] “with second version, can’t forget to close, will be autoclosed on exception. Java: try (ResourceType resource = …) … cleans up anything that implements AutoCloseable. ” Ways to do monitoring • Macros+libraries • Source-to-source transformation • Object-to-object transformation • Object interpretation (emulation) • Object translation, load time or JIT • Trade off how much it can know about the program against what it can do; object level things can do stuff no ordinary compiler can generate. • How much does tool need? One file? All your files? All the files and all the shared objects? • MacOS Instruments can trace into OSLibraries • From last lecture – #define to replace malloc() and free() – Source code to track buffer over-run and <b>under-runs</b> – Source code to track memory leak...|$|R
6000|$|... "I {{beg your}} pardon, Captain Cuffe," [...] {{answered}} Griffin, who found himself compelled to appear a delinquent, whatever {{might be the}} injustice of the stiuation; [...] "it could not be helped. We got in in proper time; and I went {{to work with the}} deputy-governor and an old chap of a magistrate who was with him, as soon as I could get up to the house of the first. Yvard had been beforehand with me: and I had to <b>under-run</b> about a hundred of his lying yarns before I could even enter the end of an idea of my own--" ...|$|E
50|$|Additional session linking {{methods are}} more {{accurate}} with DVD+R(W) versus DVD-R(W), resulting in fewer damaged or unusable discs due to buffer <b>under-run</b> and multi-session discs with fewer PI/PO errors.|$|E
50|$|S - {{designed}} for daily operation and construction vehicles such as cement trucks. The daily cab has its front bumper lower {{to the ground}} to prevent <b>under-run,</b> whereas the construction version of the S cab has its front bumper higher to prevent hitting an obstacle when driving off-road on the site.|$|E
50|$|Tall {{structures}} {{in excess of}} certain legislated heights are often equipped with aircraft warning lamps, usually red, to warn pilots of the structure's existence. In the past, ruggedized and <b>under-run</b> filament lamps were used to maximize the bulb life. Alternatively, neon lamps were used. Nowadays such lamps tend to use LED arrays.|$|E
50|$|Earlier, {{household}} {{clothes dryers}} sometimes incorporated a germicidal lamp {{in series with}} an ordinary incandescent lamp; the incandescent lamp operated as the ballast for the germicidal lamp. A commonly used light in the home in the 1960s in 220-240 V countries was a circleline tube ballasted by an <b>under-run</b> regular mains filament lamp. Self ballasted mercury-vapor lamps incorporate ordinary tungsten filaments within the overall envelope of the lamp to act as the ballast, and it supplements the otherwise lacking red area of the light spectrum produced.|$|E
50|$|The {{episode was}} {{directed}} by Carlos Baeza. In {{the background of the}} classroom, there are several portraits of past United States presidents. These were added for the scene where Bart tries to think of a name for his fictional letter writer, and sees a portrait of Woodrow Wilson. Woodrow's voice was performed by Harry Shearer, who did an impression of Ricardo Montalbán. The picture Bart sends Edna is of NHL and WHA star Gordie Howe. The writers had originally wanted to use a picture of American football player Johnny Unitas, but were unable to get the rights to use his image for free. Howe, their second choice, was suggested by Al Jean, who had been a Detroit Red Wings fan growing up. At the end of the episode, Howe's NHL and WHA statistics are shown because the writers decided to try something different in filling a slight time <b>under-run.</b>|$|E
3000|$|... [...]. Furthermore, if the bound is exceeded, respectively, <b>under-run,</b> we decrease, respectively, {{increase}} [...]...|$|E
40|$|In future, new trucks shall {{most likely}} be {{equipped}} with a front <b>under-run</b> protection devices {{in order to prevent}} passenger cars from under-running. At the same time, the energy absorption by the car will be more adequate, because of the better geometrical compatibility with the truck front. As yet, this device shall not be designed with the objective to absorp energy in favour of the passenger car. From European accident analysis it is known that the average relative speed in a car-to-truck frontal collision is about 76 kph. Today, passenger cars are designed to provide protection to the occupants up to 56 kph in a frontal collision with a rigid wall. If a part of the impact energy could be absorbed by the truck, the injury severity to car occupants in a 75 kph collision would be reduced to survivable injuries observed in a 56 kph collision into a rigid wall. In order not to influence the payload of the truck, the energy absorbing front <b>under-run</b> protection system should be light and compact. Moreover, such a system should be cheap and easy to integrate into future truck design. Materials which could be considered are composites. It is known that composite crash cones have a very high specific energy absorption and are therefore exquisite for application in this field. In this paper, the design and development of an energy absorbing front <b>under-run</b> protection system with composite crash cones will be described and the performance will be demonstrated in a full-scale car-to-truck frontal collision. The results will be compared with the results of a test with identical vehicles, where the speed was 56 kph and the truck was provided with a rigid front <b>under-run</b> protection device...|$|E
40|$|In {{this work}} {{we deal with}} video streams over TCP {{networks}} and propose an alternative measurement to the widely used and accepted peak {{signal to noise ratio}} (PSNR) due to the limitations of this metric in the presence of temporal errors. A test-bed was created to simulate buffer <b>under-run</b> in scalable video streams and the pauses produced {{as a result of the}} buffer <b>under-run</b> were inserted into the video before being employed as the subject of subjective testing. The pause intensity metric proposed in [1] was compared with the subjective results and it was shown that in spite of reductions in frame rate and resolution, a correlation with pause intensity still exists. Due to these conclusions, the metric may be employed in layer selection in scalable video streams...|$|E
40|$|Abstract––Under-running of {{passenger}} vehicles {{is one of}} the important parameters to be considered during design and development of truck chassis. Rear <b>Under-run</b> Protection Device (RUPD) {{plays an important role in}} avoiding under-running of vehicles from rear side of a truck. In India, the legal requirements of a RUPD are fixed in regulation IS 14812 - 2005. To reduce number of iterations during the development process, the computational simulation method is used in RUPD analysis for impact loading. An explicit finite element code like Ls-Dyna is used for the simulation. The deformation of RUPD bar and plastic strains in RUPD components can be determined before the physical test for predicting failure of the system to meet the compliance requirements as per IS 14812 - 2005. Additionally, failure of the RUPD attachment points with chassis can be determined. Physical testing can be reduced significantly with this approach which ultimately reduces the total cycle time as well as the cost involved in product development. This paper explains the FE analysis of RUPD for impact loading. All the results obtained from the CAE analysis are evaluated against the requirements of IS 14812 - 2005 which could reduce the process development time and cost involved in the same. Keywords––Rear <b>Under-run</b> Protection Device (RUPD), IS 14812 - 2005, Chassis design, ECE R 58, Heavy Vehicle Systems I...|$|E
40|$|In {{this paper}} we {{consider}} the problem of adaptive video streaming over an LTE-A network that utilizes Licensed Assisted Access (LAA) which is an instance of LTE Unlicensed. With LTE Unlicensed users of the LTE-A network opportunisti- cally access radio resources from unlicensed and licensed carriers through Carrier Aggregation (CA). Our objective is to select the highest possible video quality for each LTE-A user while also try to deliver video data in time for playback, and thus avoid buffer <b>under-run</b> events that deteriorate viewing experience. However, the unpredictable nature of the wireless channel, {{as well as the}} unknown utilization of the unlicensed carrier by other unlicensed users, result in a challenging optimization problem. We first focus on developing an accurate system model of the adaptive streaming system, LTE-A, and the stochastic availability of unlicensed resources. Then, the formulated problem is solved in two stages: First, we calculate a proportionally fair video quality for each user, and second we execute resource allocation on a shorter time scale compatible with LTE-A. We compare our framework with the typical proportional fair scheduler as well as a state-of-the-art LTE-A adaptive video streaming framework in terms of average segment quality and number of buffer under- run events. Results show that the proposed quality selection and scheduling algorithms, not only achieve higher video segment quality in most cases, but also minimize the amount and duration of video freezes as a result of buffer <b>under-run</b> events...|$|E
40|$|Under-running of {{passenger}} vehicles {{is one of}} the important parameters to be considered during design and development of truck chassis. In India, the legal requirements of a RUPD (Rear <b>Under-Run</b> Protection Device) are fixed in regulation IS 14812 - 2005 which are derived from ECE R 58, which provides strict requirements in terms of device design and its behavior under loading that the device needs to fulfill for the approval of load carrying vehicles. The work focuses on optimization of RUPD Structure using Finite Element Analysis tool like LS-DYNA and HyperWorks Module and stress calculation for guard pipe has been performed. The regulation allows increasing the load bearing capacity of th...|$|E
40|$|YouTube {{traffic is}} bursty. These bursts trigger packet losses and stress router queues, causing TCP’s congestion-control {{algorithm}} to kick in. In this paper, we introduce Trickle, a server-side mechanism that uses TCP to rate limit YouTube video streaming. Trickle paces the video stream by placing an {{upper bound on}} TCP’s congestion window {{as a function of}} the streaming rate and the round-trip time. We evaluated Trickle on YouTube production data centers in Europe and India and analyzed its impact on losses, bandwidth, RTT, and video buffer <b>under-run</b> events. The results show that Trickle reduces the average TCP loss rate by up to 43 % and the average RTT by up to 28 % while maintaining the streaming rate requested by the application. ...|$|E
40|$|BACKGROUND AND OBJECTIVE: It is {{important}} that a surgical list is planned to utilise {{as much of the}} scheduled time as possible while not over-running, because this can lead to cancellation of operations. We wished to assess whether, theoretically, the known duration of individual operations could be used quantitatively to predict the likely duration of the operating list. METHODS: In a university hospital setting, we first assessed {{the extent to which the}} current ad-hoc method of operating list planning was able to match the scheduled operating list times for 153 consecutive historical lists. Using receiver operating curve analysis, we assessed the ability of an alternative method to predict operating list duration for the same operating lists. This method uses a simple formula: the sum of individual operation times and a pooled standard deviation of these times. We used the operating list duration estimated from this formula to generate a probability that the operating list would finish within its scheduled time. Finally, we applied the simple formula prospectively to 150 operating lists, 'shadowing' the current ad-hoc method, to confirm the predictive ability of the formula. RESULTS: The ad-hoc method was very poor at planning: 50 % of historical operating lists were under-booked and 37 % over-booked. In contrast, the simple formula predicted the correct outcome (<b>under-run</b> or over-run) for 76 % of these operating lists. The calculated probability that a planned series of operations will over-run or <b>under-run</b> was found useful in developing an algorithm to adjust the planned cases optimally. In the prospective series, 65 % of operating lists were over-booked and 10 % were under-booked. The formula predicted the correct outcome for 84 % of operating lists. CONCLUSION: A simple quantitative method of estimating operating list duration for a series of operations leads to an algorithm (readily created on an Excel spreadsheet, [URL] that can potentially improve operating list planning...|$|E
40|$|Compatibility is {{an issue}} that relates to the {{improvement}} of vehicle safety. After frontal and side impact self protection, partner protection, a key component of compatibility, represents the next step forward for passive safety improvement. Compatibility is complicated to achieve, because it requires world-wide industry to take steps in a similar direction. A harmonized approach is difficult to achieve because many differences in vehicle makes and models between the various fleets around the world exist. This leads to incompatibilities between vehicles in a global sense: Asian markets have a high market share of very small cars, the American market is characterized by a high proportion of LTVs and SUVs and the European market is somewhere between the American and the Asian markets. It is obvious that a lot of requirements need to be fulfilled by a compatibility regulation which is; beneficial to the customer, which is scientifically meaningful, refers to front and side-impact and which is applicable for all markets and, last but not least, is considered to be fair by all manufacturers. ACEA is not in the position to suggest a solution meeting all these requirements. However, some test results and observations which could contribute to a solution are presented in this paper. The focus of most proposed compatibility procedures is to improve structural interaction in collisions involving passenger cars. A couple of conditions exist that influence the definition of a geometric zone for structural interaction. A zone for structural interaction has to ensure maximal interaction between passenger vehicles with other passengers vehicles, SUVs/LTV’s and trucks (to be supported by <b>under-run</b> protection systems) can be achieved. This could represent a first step in increasing compatibility within vehicle fleets. Structural interaction is, in fact, the principle requirement for compatibility before the issue of stiffness can be solved. Keeping this in mind, ACEA drafted a road map chartering the path toward improved compatibility, which is presented in this paper...|$|E
40|$|On February 17, 1996, NASA {{solidified}} its 2 ̆ 2 faster, better, cheaper 2 ̆ 2 {{guidelines for}} low cost planetary missions with the successful {{launch of the}} Near Earth Asteroid Rendezvous (NEAR) spacecraft. A guide for future small spacecraft missions has now been established. NEAR, the first mission in NASA 2 ̆ 7 s Discovery Program for 2 ̆ 2 faster, better, cheaper 2 ̆ 2 planetary exploration and the first asteroid orbiter ever was designed and built at The Johns Hopkins University Applied Physics Laboratory (JHU/APL). The design emphasizes simplicity, reliability, and low cost. Discovery Program criteria include a cost ceiling of 150 million (FY 92 dollars) on spacecraft development to launch plus 30 days and a maximum 36 month development cycle. NEAR was developed and launched in 27 months for approximately 108 million (FY 92 dollars); 3. 6 million was actually returned to NASA following launch - the NEAR <b>under-run.</b> The cost criterion, with reference to NEAR, {{is the focus of}} this paper. This paper will discuss the NEAR program cost from the beginning of Phase C/D (December 1993) to launch plus 30 days (March 1996). The NEAR work breakdown structure (WBS) will be presented and each of its 29 cost centers will be discussed in detail with regard to their total cost, manpower required, engineering and fabrication shop hours required, and subcontract cost (with {{a brief description of the}} major subcontracts). In addition to the utilization of the WBS, showing the cost make up of each cost center, several other graphs and charts will be presented to show these same cost areas (total cost, manpower, shop hours, and subcontracts) in relation to the phases (design and fabrication, integration and test, launch support, etc.) in which they were expended. Also incorporated in this paper will be discussions on some key cost control techniques-some tried and proven in past programs, and others fairly new to JHU/ APL [...] regarding technical services and subcontract support. With NASA and its Discovery Program bringing the 2 ̆ 2 faster, better, cheaper 2 ̆ 2 mind-set to the forefront, more pressure is being placed on private and public organizations to find ways to reduce costs of future space systems and to actually achieve the originally estimated cost at the end of the project. The information in this paper will be presented in a way that will be useful as a template or starting point for future small spacecraft programs...|$|E
40|$|Fiscal Year (FY) 1995 {{challenged}} us {{to dramatically}} reduce costs at Hanford. We began {{the year with}} an 8 percent reduction in our Environmental Management budget {{but at the same}} time were tasked with accomplishing additional workscope. This resulted in a Productivity Challenge whereby we took on more work at the beginning of the year than we had funding to complete. During the year, the Productivity Challenge actually grew to 23 percent because of recissions, Congressional budget reductions, and DOE Headquarters actions. We successfully met our FY 1995 Productivity Challenge through an aggressive cost reduction program that identified and eliminated unnecessary workscope and found ways to be more efficient. We reduced the size of the workforce, cut overhead expenses, eliminated paperwork, cancelled construction of new facilities, and reengineered our processes. We are proving we can get the job done better and for less money at Hanford. DOE`s drive to do it ``better, faster, cheaper`` has led us to look for more and larger partnerships with the private sector. The biggest will be privatization of Hanford`s Tank Waste Remediation System, which will turn liquid tank waste into glass logs for eventual disposal. We will also save millions of dollars and avoid the cost of replacing aging steam plants by contracting Hanford`s energy needs to a private company. Other privatization successes include the Hanford Mail Service, a spinoff of advanced technical training, low level mixed waste thermal treatment, and transfer of the Hanford Museums of Science and history to a private non-profit organization. Despite the rough roads and uncertainty we faced in FY 1995, less than 3 percent of our work fell behind schedule, while the work that was performed was completed with an 8. 6 percent cost <b>under-run.</b> We not only met the FY 1995 productivity challenge, we also met our FY 1995 - 1998 savings commitments and accelerated some critical cleanup milestones. The challenges continue. Budgets remain on the decline, even while the expectations increase. Yet we are confident in our ability to keep our commitments and goals by identifying new efficiencies in the Hanford cleanup program. We will also pursue new contracting arrangements that will allow us to foster greater competition and use more commercial practices while maintaining our commitment to the safety and health of the public, our workers, and the environment...|$|E
40|$|The {{deregulation}} of energy markets around the world, including power markets {{has changed the}} way operating assets in these markets are managed. Independent power asset owners and even utilities operating in these markets no longer operate their assets based {{on the cost of}} service approach that prevailed under regulation. Just as in other competitive markets, the objectives of asset owners in power markets revolve around maximizing profit for their shareholders. To this end, financial valuation of physical assets in power markets should incorporate different strategies that are used by asset operators to maximize profit. A lot of observed strategies in power markets are driven by a number of factors, the key among which are: •	asset operators are no longer obligated to supply service or manage their assets in certain prescribed ways, rather they have rights to operate, within applicable market rules, using techniques that maximize their profits, •	revenues are driven by uncertain market factors, including power price, cost and/or availability of fuel stock and technical uncertainties, and •	power assets have physical operating and equipment constraints and limits. Having flexibilties (“options”) to optimize their assets (inline with shareholders’ objectives), rational asset managers react strategically to gradual arrival of information, given applicable equipment constraints, by revising previous decisions {{in such a way that}} only optimal (or near optimal) decisions are implemented. As a result, the appropriate approach to valuing power assets in competitive markets must account for managerial flexibilities or “real options” in the presence of uncertainties and technical constraints. The focus of this work is to develop a robust valuation framework for physical power assets operating in competitive markets such as peaking or mid-merit thermal power plants and baseload power plants. The goal is to develop a modeling framework that can be adapted to different energy assets with different types of operating flexibilities and technical constraints and which can be employed for various purposes such as capital budgeting, business planning, risk management and strategic bidding planning among others. The valuation framework must also be able to capture the reality of power market rules and opportunities, as well as technical constraints of different assets. The modeling framework developed conceptualizes operating flexibilities of power assets as “switching options’ whereby the asset operator decides at every decision point whether to switch from one operating mode to another mutually exclusive mode, within the limits of the equipment constraints of the asset. As a current decision to switch operating modes (in the face of current realization of relevant uncertainty factors) may affect future operating flexibilities of the asset and hence cash flows, a dynamic optimization framework is employed. The developed framework accounts for the uncertain nature of key value drivers by representing them with appropriate stochastic processes. Specifically, the framework developed conceptualizes the operation of a power asset as a multi-stage decision making problem where the operator has to make a decision at every stage to alter operating mode given currently available information about key value drivers. The problem is then solved dynamically by decomposing it into a series of two-stage sub-problems according to Bellman’s optimality principle. The solution algorithm employed is the Least Squares Monte Carlo (LSM) method. The developed valuation framework was adapted for a gas-fired thermal power plant, a peaking hydroelectric power plant and a baseload power plant. This work built on previously published real options valuation methodologies for gas-fired thermal power plants by factoring in uncertainty from gas supply/consumption imbalance which is usually faced by gas-fired power generators. This source of uncertainty which has yet to be addressed in the literature, in the context of real options valuation, arises because of mismatch between natural gas and electricity wholesale markets. Natural gas markets in North America operate on a day-ahead basis while power plants are dispatched in real time. Inability of a power generator to match its gas supply and consumption in real time, leading to unauthorized gas over-run or <b>under-run,</b> attracts penalty charges from the gas supplier to the extent that the generator can not manage the imbalance through other means. A savvy gas-fired power plant operator will factor in the potential costs of gas imbalance into its operating strategies resulting in optimal operating decisions that may be different from when gas-imbalance is not considered. By considering an illustrative power plant operating in Ontario, we show effects of gas-imbalance on dispatch strategies on a daily cycling operation basis and the resulting impact on net revenue. Results show that a gas-fired power plant is over-valued by ignoring the impacts of gas imbalance on valuation. Similarly, we employ the developed valuation framework to value a peaking hydroelectric power plant. This application also builds on previous real options valuation work for peaking hydroelectric power plants by considering their operations in a joint energy and ancillary services market. Specifically, the valuation model is developed to capture the value of a peaking power plant whose owner has the flexibility to participate in a joint operating reserve market and an energy market, which is currently the case in the Ontario wholesale power market. The model factors in water inflow uncertainty into the reservoir forebay of a hydroelectric facility and also considers uncertain energy and operating reserve prices. The switching options considered include (i) a joint energy and operating reserve bid (ii) an energy only bid and (iii) a do nothing (idle) strategy. Being an energy limited power plant, by doing nothing at a decision interval, the power asset operator is able to time-shift scarce water for use at a future period when market situations are expected to be better. An illustrative example considered shows the impact of the different value drivers on the plant’s value and dispatch strategies. Results show that by ignoring the flexibility of the asset owner to participate in an operating reserve market, a peaking hydroelectric power plant is undervalued. Finally, the developed valuation framework was employed to optimize life-cycle management decisions of a baseload power plant, such as a nuclear power plant. The applicability of real-options framework to the operations of baseload power plants has not attracted much attention in the literature given their inflexibility with respect to short-term operation. However, owners of baseload power plants, such as nuclear plants, have the right to optimize scheduling and spending of life cycle management projects such as preventative maintenance and equipment inspection. Given uncertainty of long-term value drivers, including power prices, equipment performance and the relationship between current life cycle spending and future equipment degradation, optimization is carried out with the objective of minimizing overall life-cycle related costs. These life-cycle costs include (i) lost revenue during planned and unplanned outages (ii) potential costs of future equipment degradation due to inadequate preventative maintenance and (iii) the direct costs of implementing the life-cycle projects. The switching options in this context include the option to shutdown the power plant in order to execute a given preventative maintenance and inspection project and the option to keep the option “alive” by choosing to delay a planned life-cycle activity. Results of an illustrative example analyzed show that the flexibility of the asset owner to delay spending or to suspend it entirely affects the asset’s value accordingly and should be factored into valuation. Applications can be found for the developed framework and models in different areas important to firms operating in competitive energy markets. These areas include capital budgeting, trading, risk management, business planning and strategic/tactitcal bidding among others...|$|E

