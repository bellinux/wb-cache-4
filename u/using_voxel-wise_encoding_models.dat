1|1097|Public
30|$|Analyzing {{functional}} {{magnetic resonance}} imaging (fMRI) data from the encoding perspective provides a powerful tool to explore human vision. <b>Using</b> <b>voxel-wise</b> <b>encoding</b> <b>models,</b> previous studies predicted the brain activity evoked by external stimuli successfully. However, these models constructed a regularized regression model for each single voxel separately, which overlooked the intrinsic spatial property of fMRI data. In this work, we proposed a multi-target regression model that predicts the activities of adjacent voxels simultaneously. Different from the previous models, the spatial constraint is considered in our model. The effectiveness of the proposed model is demonstrated by comparing it with two state-of-the-art voxel-wise models on a publicly available dataset. Results indicate that the proposed method can predict voxel responses more accurately than the competing methods.|$|E
40|$|AbstractRecent multi-voxel pattern {{classification}} (MVPC) {{studies have}} shown that in early visual cortex patterns of brain activity generated during mental imagery are similar to patterns of activity generated during perception. This finding implies that low-level visual features (e. g., space, spatial frequency, and orientation) are encoded during mental imagery. However, the specific hypothesis that low-level visual features are encoded during mental imagery is difficult to directly test using MVPC. The difficulty is especially acute when considering the representation of complex, multi-object scenes that can evoke multiple sources of variation that are distinct from low-level visual features. Therefore, we <b>used</b> a <b>voxel-wise</b> modeling and decoding approach to directly test the hypothesis that low-level visual features are encoded in activity generated during mental imagery of complex scenes. Using fMRI measurements of cortical activity evoked by viewing photographs, we constructed <b>voxel-wise</b> <b>encoding</b> <b>models</b> of tuning to low-level visual features. We also measured activity as subjects imagined previously memorized works of art. We then used the <b>encoding</b> <b>models</b> to determine if putative low-level visual features encoded in this activity could pick out the imagined artwork from among thousands of other randomly selected images. We show that mental images can be accurately identified in this way; moreover, mental image identification accuracy depends upon the degree of tuning to low-level visual features in the voxels selected for decoding. These results directly confirm the hypothesis that low-level visual features are encoded during mental imagery of complex scenes. Our work also points to novel forms of brain–machine interaction: we provide a proof-of-concept demonstration of an internet image search guided by mental imagery...|$|R
40|$|Abstract. Most fMRI studies <b>use</b> <b>voxel-wise</b> {{statistics}} {{to carry out}} intra-subject as well as inter-subject analysis. We show that statistics derived from voxel-wise comparisons {{are likely to be}} noisy and error prone, es-pecially for inter-subject comparisons. In this paper we propose a novel metric called weighted cluster coverage to compare two activation maps. This metric is based on the intersection of spatially contiguous clusters of activations. It is found to be more robust than voxel-wise comparisons and could potentially lead to more statistical power in fMRI-based group studies. ...|$|R
40|$|Functional MRI (fMRI) {{has become}} the most common method for {{investigating}} the human brain. However, fMRI data present some complications for statistical analysis and modeling. One recently developed approach to these data focuses on estimation of computational <b>encoding</b> <b>models</b> that describe how stimuli are transformed into brain activity measured in individual voxels. Here we aim at building <b>encoding</b> <b>models</b> for fMRI signals recorded in primary visual cortex of the human brain. We use residual analyses to reveal systematic nonlinearity across voxels not taken into account by previous models. We then show how a sparse nonparametric method (Ravikumar et al., 2009 b) can be used together with correlation screening to estimate nonlinear <b>encoding</b> <b>models</b> effectively. Our approach produces <b>encoding</b> <b>models</b> that predict about 25 % more accurately than models estimated using other methods (Kay et al., 2008 a). The estimated nonlinearity impacts the inferred properties of individual voxels, and it has a plausible biological interpretation. One benefit of quantitative <b>encoding</b> <b>models</b> is that estimated models can be used to decode brain activity, in order to identify which specific image was seen by an observer. <b>Encoding</b> <b>models</b> estimated by our approach also improve such image identification by about 12 % when the correct image is one of 11, 500 possible images. 1. Introduction. On...|$|R
30|$|Consequently, {{research}} efforts {{have attempted to}} improve the predictive nature of PET by taking into account all voxel values and <b>using</b> <b>voxel-wise</b> approaches for image analysis. For other imaging modalities, such as MR imaging, a so-called voxel-by-voxel analysis is well established. It has been {{proven to be a}} viable technique for measuring therapy response in breast cancer [12], while for high-grade glioma, it was predictive for the overall survival rate [13]. Voxel-based analysis has also been applied to response assessment with PET images in head and neck cancer patients and was shown to be a useful tool [14].|$|R
5000|$|The <b>encoded</b> <b>model</b> {{structure}} must {{reflect the}} (biological) process(es) detailed in the reference description.|$|R
40|$|A {{principal}} goal in sensory neuroscience is {{to understand}} how properties of our environment are reflected in neural activity patterns. Recent advances in computational modeling provide increasingly accurate predictions of how neural populations across the brain respond to complex naturalistic stimuli. The employed computational models, referred to as <b>encoding</b> <b>models,</b> explicitly transform complex stimuli into observed neural responses. This rapidly developing field is becoming increasingly important in sensory neuroscience as it provides detailed insights into the functional organization of neural representations. The present work starts by discussing the theoretical underpinnings of <b>encoding</b> <b>models.</b> Next, various applications of <b>encoding</b> <b>models</b> are reviewed. Finally, potential research directions that may shape future {{work in this area}} of research are described...|$|R
40|$|Deductive and {{inductive}} {{approaches to}} solving of pattern recognition problems are considered. Logical and precedent-related <b>encoding</b> <b>models</b> of prior information {{are used in}} these approaches correspondingly. Algebra of objects is built and its isomorphism to Boolean algebra is shown. Algorithms for mutual conversion of <b>encoding</b> <b>models</b> are developed. A modification of the resolution method for solution of pattern recognition problems is suggested. An algorithm combining the resolution method and a parametric family of recognition algorithms is developed...|$|R
50|$|More {{recent studies}} used voxels from early and {{anterior}} visual cortex areas forward of them (visual areas V3A, V3B, V4, and the lateral occipital) together with Bayesian inference techniques to reconstruct complex natural images. This brain reading approach uses three components: A structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas; a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas; and a Bayesian prior {{that describes the}} distribution of structural and semantic scene statistics.|$|R
40|$|Minor Physical Anomalies (MPAs) arise {{during the}} first {{trimester}} of prenatal life and occur more frequently in autism and related neurodevelopmental disorders. We measured intra-orbital distances from T 1 weighted images of children with autism aged 6 – 16 years and typically developing peers. We report {{a significant increase in}} intra-orbital distance in autism. <b>Using</b> <b>voxel-wise</b> linear regression analysis intra-orbital distances were found to positively correlate with the volume of inferio-temporal regions including the amygdala in the autism group only. We suggest that intra-orbital MPA may provide a ‘fossil’ record of much earlier childhood brain expansion in autism. published_or_final_versionThe 19 th Annual Meeting of the International Society for Magnetic Resonance in Medicine (ISMRM), Montreal, Canada, 7 - 13 May 2011. In Proceedings of the 19 th ISMRM, 2011, p. 252...|$|R
40|$|The {{growing trend}} of online image sharing and {{downloads}} today mandate {{the need for}} better encoding and decoding scheme. This paper looks into this issue of image coding. Multiple Description Coding is an encoding and decoding scheme that is specially designed in providing more error resilience for data transmission. The main issue of Multiple Description Coding is the lossy transmission channels. This work attempts {{to address the issue}} of re-constructing high quality image with the use of just one descriptor rather than the conventional descriptor. This work compare the use of Type I quantizer and Type II quantizer. We propose and compare 4 coders by examining the quality of re-constructed images. The 4 coders are namely JPEG HH (Horizontal Pixel Interleaving with Huffman Coding) model, JPEG HA (Horizontal Pixel Interleaving with Arithmetic <b>Encoding)</b> <b>model,</b> JPEG VH (Vertical Pixel Interleaving with Huffman <b>Encoding)</b> <b>model,</b> and JPEG VA (Vertical Pixel Interleaving with Arithmetic <b>Encoding)</b> <b>model.</b> The findings suggest that the use of horizontal and vertical pixel interleavings do not affect the results much. Whereas the choice of quantizer greatly affect its performance...|$|R
40|$|ABSTRACT: One of {{the many}} {{advantages}} of multivariate pattern rec-ognition approaches over conventional mass-univariate group analy-sis <b>using</b> <b>voxel-wise</b> statistical tests is their potential to provide highly sensitive and specific markers of diseases on an individual basis. However, {{a vast majority of}} imaging problems addressed by pattern recognition are viewed {{from the perspective of a}} two-class classifica-tion. In this article, we provide a summary of selected works that pro-pose solutions to biomedical problems where the widely-accepted classification paradigm is not appropriate. These pattern recognition approaches address common challenges in many imaging studies: high heterogeneity of populations and continuous progression of dis-eases. We focus on diseases associated with aging and propose that clustering-based approaches may be more suitable for disentangle-ment of the underlying heterogeneity, while high-dimensional pattern regression methodology is appropriate for prediction of continuous and gradual clinical progression from magnetic resonance brai...|$|R
40|$|Causal {{terminology}} {{is often}} {{introduced in the}} interpretation of <b>encoding</b> and decoding <b>models</b> trained on neuroimaging data. In this article, we investigate which causal statements are warranted and which ones are not supported by empirical evidence. We argue that the distinction between <b>encoding</b> and decoding <b>models</b> is not sufficient for this purpose: relevant features in <b>encoding</b> and decoding <b>models</b> carry a different meaning in stimulus- and in response-based experimental paradigms. We show that only <b>encoding</b> <b>models</b> in the stimulus-based setting support unambiguous causal interpretations. By combining <b>encoding</b> and decoding <b>models</b> trained on the same data, however, we obtain insights into causal relations beyond those that are implied by each individual model type. We illustrate the empirical relevance of our theoretical findings on EEG data recorded during a visuo-motor learning task. Comment: accepted manuscrip...|$|R
3000|$|... e 0, e 2 j}. In what follows, {{we split}} the stop codon into the three {{possibilities}} strictly observed {e 2 j_TAA,e 2 j_TAG,e 2 j_TGA}, {{for a total}} of 17 states in our forward <b>encoding</b> <b>model.</b>|$|R
40|$|While some first {{language}} (L 1) reading models suggest that inefficient word recognition and small working memory tend to inhibit higher-level comprehension processes; the Compensatory <b>Encoding</b> <b>Model</b> maintains that slow word recognition and small working memory do not normally hinder reading comprehension, as readers {{are able to}} operate metacognitive strategies to compensate for inefficient word recognition and working memory limitation as long as readers process a reading task without time constraint. Although empirical evidence is accumulated for support of the Compensatory <b>Encoding</b> <b>Model</b> in L 1 reading, there is lack of research for testing of the Compensatory <b>Encoding</b> <b>Model</b> in foreign language (FL) reading. This research empirically tested the Compensatory <b>Encoding</b> <b>Model</b> in English reading among Chinese college English language learners (ELLs). Two studies were conducted. Study one focused on testing whether reading condition varying time affects the relationship between word recognition, working memory, and reading comprehension. Students were tested on a computerized English word recognition test, a computerized Operation Span task, and reading comprehension in time constraint and non-time constraint reading. The correlation and regression analyses showed that the strength of association was much stronger between word recognition, working memory, and reading comprehension in time constraint than that in non-time constraint reading condition. Study two examined whether FL readers were able to operate metacognitive reading strategies as a compensatory way of reading comprehension for inefficient word recognition and working memory limitation in non-time constraint reading. The participants were tested on the same computerized English word recognition test and Operation Span test. They were required to think aloud while reading and to complete the comprehension questions. The think-aloud protocols were coded for concurrent use of reading strategies, classified into language-oriented strategies, content-oriented strategies, re-reading, pausing, and meta-comment. The correlation analyses showed that while word recognition and working memory were only significantly related to frequency of language-oriented strategies, re-reading, and pausing, but not with reading comprehension. Jointly viewed, {{the results of the}} two studies, complimenting each other, supported the applicability of the Compensatory <b>Encoding</b> <b>Model</b> in FL reading with Chinese college ELLs...|$|R
40|$|A celebrated result by Barak et al (JACM’ 12) {{shows the}} impos-sibility of {{general-purpose}} virtual black-box (VBB) obfuscation in the plain model. A recent work by Canetti, Kalai, and Paneth (TCC’ 15) extends this result {{also to the}} random oracle model (assuming trap-door permutations). In contrast, Brakerski-Rothblum (TCC’ 15) and Barak et al (Euro-Crypt’ 14) show that in idealized graded <b>encoding</b> <b>models,</b> general-purpose VBB obfuscation indeed is possible; these construction re-quire graded encoding schemes that enable evaluating high-degree (polynomial {{in the size of}} the circuit to be obfuscated) polynomials on encodings. We show a complementary impossibility of general-purpose VBB obfuscation in idealized graded <b>encoding</b> <b>models</b> that enable only evaluation of constant-degree polynomials (assuming trapdoor permu-tations) ...|$|R
30|$|In recent years, voxel-based <b>encoding</b> <b>models</b> were {{proposed}} and caught much attention (Kay et al. 2008). A typical <b>encoding</b> <b>model</b> {{can be divided}} into two parts. The first part tries to find a feature space to describe the external stimulus. The second part corresponds to the construction of regression models, which uses the stimulus features to predict corresponding brain activity. Lots of effort were taken to find ways to represent the stimulus images. Previous studies used Gabor wavelet pyramid model (Kay et al. 2008; Vu et al. 2011), two-layer sparse coding model (Güçlü and van Gerven 2014), and convolutional neural networks (Agrawal et al. 2014) to extract features that can represent natural images effectively. However, fewer studies focused on efficient regression model construction.|$|R
40|$|We {{propose a}} {{selective}} <b>encoding</b> <b>model</b> {{to extend the}} sequence-to-sequence framework for abstractive sentence summarization. It consists of a sentence encoder, a selective gate network, and an attention equipped decoder. The sentence encoder and decoder are built with recurrent neural networks. The selective gate network constructs a second level sentence representation by controlling the information flow from encoder to decoder. The second level representation is tailored for sentence summarization task, which leads to better performance. We evaluate our model on the English Gigaword, DUC 2004 and MSR abstractive sentence summarization datasets. The experimental {{results show that the}} proposed selective <b>encoding</b> <b>model</b> outperforms the state-of-the-art baseline models. Comment: 10 pages; To appear in ACL 201...|$|R
40|$|Purpose <b>Using</b> <b>voxel-wise</b> degree {{centrality}} (DC), {{as measured}} by resting-state fMRI, we aimed to study alterations in the brain functional networks in patients with primary angle-closure glau-coma (PACG) and to reveal the plastic trajectories of surgery. Methods A total of 23 preoperative PACG patients (49. 48 ± 14. 37 years old) were recruited to undergo a resting-state fMRI scan, and 9 of them were rescanned 3 months after surgery. All PACG patients underwent a complete ophthalmologic examination, including intraocular pressure (IOP), retinal nerve fiber layer (RNFL) thickness, vertical cup to disc ratio (V C/D), and average cup to disc ratio (A C/D). Another 23 gender- and age-matched healthy con-trols (48. 18 ± 9. 40 years old) underwent scanning once for comparison. The group differ-ence in DC was calculated in each voxel, and {{the correlations between the}} DC value and each of the clinical variables were analyzed in the PACG patients. Result...|$|R
40|$|Frontostriatal {{circuitry}} is {{implicated in}} the cognitive distortions associated with gambling behaviour. ‘Near-miss’ events, where unsuccessful outcomes are proximal to a jackpot win, recruit overlapping neural circuitry with actual monetary wins. Personal control over a gamble (e. g., via choice) is also known to increase confidence in one's chances of winning (the ‘illusion of control’). Using psychophysiological interaction (PPI) analyses, we examined changes in functional connectivity as regular gamblers and non-gambling participants played a slot-machine game that delivered wins, near-misses and full-misses, and manipulated personal control. We focussed on connectivity with striatal seed regions, and associations with gambling severity, <b>using</b> <b>voxel-wise</b> regression. For the interaction term of near-misses (versus full-misses) by personal choice (participant-chosen versus computer-chosen), ventral striatal connectivity with the insula, bilaterally, {{was positively correlated with}} gambling severity. In addition, some effects for the contrast of wins compared to all non-wins were observed at an uncorrected (...|$|R
30|$|This IP {{accelerated}} {{system model}} includes the memory, algorithm, and architecture optimization techniques {{to enable the}} reduction and elimination of the overhead resulted from the heterogeneous video encoding tasks. The video <b>encoding</b> <b>model</b> provided in this architecture is compliant with H. 264 standard specifications.|$|R
30|$|To {{reduce the}} {{complexity}} of the problem, the small cell network is initially divided into a number of subnetworks equal to the number of PoPs, classified based on the criteria of LOS condition as well as the distance to the closest PoP. The decomposed network will then be applicable to the proposed small cell backhaul model. A meta-heuristic method called simulated annealing (SA) [35] together with a Dandelion tree <b>encoding</b> <b>model</b> is exploited to solve the constrained minimum Steiner tree problem [36]. The Dandelion code has been recently proposed and proved to be an effective tree <b>encoding</b> <b>model,</b> which is more efficient and offers higher locality, i.e., small changes in code results in small changes in the tree, than the most popular Pruumlfer code [37].|$|R
40|$|Purpose The {{purpose of}} this work was {{to improve the quality}} of single-shot spiral MRI and {{demonstrate}} its application for diffusion-weighted imaging. Methods Image formation is based on an expanded <b>encoding</b> <b>model</b> that accounts for dynamic magnetic fields up to third order in space, nonuniform static B 0, and coil sensitivity <b>encoding.</b> The <b>encoding</b> <b>model</b> is determined by B 0 mapping, sensitivity mapping, and concurrent field monitoring. Reconstruction is performed by iterative inversion of the expanded signal equations. Diffusion-tensor imaging with single-shot spiral readouts is performed in a phantom and in vivo, using a clinical 3 T instrument. Image quality is assessed in terms of artefact levels, image congruence, and the influence of the different encoding factors. Results Using the full <b>encoding</b> <b>model,</b> diffusion-weighted single-shot spiral imaging of high quality is accomplished both in vitro and in vivo. Accounting for actual field dynamics, including higher orders, is found to be critical to suppress blurring, aliasing, and distortion. Enhanced image congruence permitted data fusion and diffusion tensor analysis without coregistration. Conclusion Use of an expanded signal model largely overcomes the traditional vulnerability of spiral imaging with long readouts. It renders single-shot spirals competitive with echo-planar readouts and thus deploys shorter echo times and superior readout efficiency for diffusion imaging and further prospective applications...|$|R
40|$|Placebo {{responses}} are highly variable across individuals. Explaining this variability {{is one of}} the keys to understanding endogenous regulatory processes, and is critical for measuring and controlling placebo effects in all kinds of studies. In this chapter, we review literature on the personality and brain correlates of individual differences in placebo analgesia. An emerging brain literature has used fMRI, opioid binding, dopamine binding, and structural brain imaging to predict the magnitude of individual placebo responses. Brain predictors in prefrontal cortices and ventral striatum/nucleus accumbens are relatively consistent across studies and methodologies, showing promise for understanding the neural bases of placebo analgesia. However, most studies <b>use</b> <b>voxel-wise</b> correlation maps to relate brain measures and placebo analgesia, which do not provide unbiased measures of predictive accuracy. Thus, the utility of these brain measures remains to be determined by larger-scale studies using appropriate analytic methods. Finally, we address an apparent paradox in the placebo literature...|$|R
30|$|The {{publicly}} available fMRI data (Kay et al. 2011) {{were used for}} model validation; this dataset is widely used in comparing models (Güçlü and van Gerven 2014; Naselaris et al. 2009; Agrawal et al. 2014), and detailed experiment information {{is available in the}} original papers (Kay et al. 2008; Naselaris et al. 2009). The fMRI responses were recorded when human subjects viewing grayscale natural images while fixating on a central white square. Two subjects took part in the experiments. They viewed 1750 training images (for <b>encoding</b> <b>model</b> training), each presented twice; and 120 validation images (for <b>encoding</b> <b>model</b> testing), each presented ten times. For each subject, the data were acquired in five scanner sessions on five different days. Each scan session consisted of five training runs, each lasted 11  min, and two validation runs, each lasted 12  min.|$|R
40|$|Bayesian neural {{decoding}} models aim at estimating an extrinsic stimulus, such as speech, from a neural popula-tion. They {{have been}} used to study several physiological systems such as the motor or auditory systems [1]. Such decoding models require the use of an <b>encoding</b> <b>model,</b> i. e. which aim at estimating the neural spikes from the stimulus [2]. One <b>encoding</b> <b>model</b> that has been used extensively in the past models the instantaneous spiking rate of a neuron using a generalized linear model (GLM). When applied to the auditory system, this GLM has three parameters that account respectively for 1) the spontaneous firing rate of the decoded neuron, 2) the spectro-temporal receptive field of the neuron and 3) the intrinsic dynamics of the neuron, such as refractory peri-ods, bursting and network dynamics [3]. In a decodin...|$|R
2500|$|SignWriting is {{the first}} writing system for sign {{languages}} {{to be included in}} the Unicode Standard. 672 characters were added in the Sutton SignWriting (Unicode block) of Unicode version 8.0 released in June 2015. [...] This set of characters is based on SignWriting's standardized symbol set and defined character <b>encoding</b> <b>model.</b>|$|R
40|$|It is {{well known}} that signals encoded by mechanoreceptors {{facilitate}} precise object manipulation in humans. It is therefore of interest to study signals encoded by the mechanoreceptors because this will contribute further towards the understanding of fundamental sensory mechanisms that are responsible for coordinating force components during object manipulation. From a practical point of view, this may suggest strategies for designing sensory-controlled biomedical devices and robotic manipulators. We use a two-stage nonlinear decoding paradigm to reconstruct the force stimulus given signals from slowly adapting type one (SA-I) tactile afferents. First, we describe a nonhomogeneous Poisson <b>encoding</b> <b>model</b> which {{is a function of the}} force stimulus and the force's rate of change. In the decoding phase, we use a recursive nonlinear Bayesian filter to reconstruct the force profile, given the SA-I spike patterns and parameters described by the <b>encoding</b> <b>model.</b> Under the current <b>encoding</b> <b>model,</b> the mode ratio of force to its derivative is: 1. 26 to 1. 02. This indicates that the force derivative contributes significantly to the rate of change to the SA-I afferent spike modulation. Furthermore, using recursive Bayesian decoding algorithms is advantageous because it can incorporate past and current information in order to make predictions [...] consistent with neural systems [...] with little computational resources. This makes it suitable for interfacing with prostheses...|$|R
40|$|Sensory {{processing}} is {{hard because}} {{the variables of}} interest are encoded in spike trains in a relatively complex way. A major goal in sensory processing is {{to understand how the}} brain extracts those variables. Here we revisit a common <b>encoding</b> <b>model</b> in which variables are encoded linearly. Although there are typically more variables than neurons, this problem is still solvable because {{only a small number of}} variables appear at any one time (sparse prior). However, previous solutions usually require all-to-all connectivity, inconsistent with the sparse connectivity seen in the brain. Here we propose a principled algorithm that provably reaches the MAP inference solution but using sparse connectivity. Our algorithm is inspired by the mouse olfactory bulb, but our approach is general enough to apply to other modalities; in addition, it should be possible to extend it to nonlinear <b>encoding</b> <b>models...</b>|$|R
40|$|In {{research}} on visual shape perception, various {{models have been}} designed for the encoding of visual patterns, in order to predict the human interpretation of such patterns. Each of these <b>encoding</b> <b>models</b> provides a few coding rules to obtain codes of a pattern, each code describing regularity and hierarchy in that pattern. Some of these models employ the minimum principle which states that the human interpretation of a pattern is reflected by the simplest code of that pattern. Despite empirical support, these <b>encoding</b> <b>models</b> suffer from three fundamental problems. First, although many coding rules can be proposed, no <b>encoding</b> <b>model</b> provides a psychological basis for those few coding rules that have been chosen (cf. Simon, 1972). Second, the minimum principle seems to require an unrealistic search for simplest pattern codes since, for any pattern, the number of possible codes is combinatorially explosive (cf. Hatfield & Epstein, 1985). Third, the quantification of simplicity is controversial and is suspected to depend too much on artifacts of the employed <b>encoding</b> <b>model</b> (cf. Hatfield & Epstein, 1985). The present study provides a coherent solution to these problems, based {{on the concept of}} accessibility. The concept of accessibility simply implies that regularity and hierarchy in the code of a pattern correspond directly to regularity and hierarchy in the pattern itself. This correspondence is specified by the notions of holographic regularity and transparent hierarchy. These two notions are based on a strictly formal analysis of regularity and hierarchy, and lead to just a few coding rules which, essentially, describe only three classes of regularities: Iterations, symmetries, and so-called alternations. Furthermore, the concept of accessibility enables an efficient and largely parallel encoding process, in which the simplest code of a pattern can be obtained without generating the explosive number of all possible codes (see also van der Helm & Leeuwenberg, 1986; van der Helm, 1988). Finally, the concept of accessibility gives rise to an improved and promising quantification of simplicity. status: publishe...|$|R
40|$|<b>Encoding</b> <b>models</b> {{are used}} for {{predicting}} brain activity in response to sensory stimuli {{with the objective of}} elucidating how sensory information is represented in the brain. <b>Encoding</b> <b>models</b> typically comprise a nonlinear transformation of stimuli to features (feature model) and a linear convolution of features to responses (response model). While there has been extensive work on developing better feature models, the work on developing better response models has been rather limited. Here, we investigate the extent to which recurrent neural network models can use their internal memories for nonlinear processing of arbitrary feature sequences to predict feature-evoked response sequences as measured by functional magnetic resonance imaging. We show that the proposed recurrent neural network models can significantly outperform established response models by accurately estimating long-term dependencies that drive haemodynamic responses. The results open a new window into modeling the dynamics of brain activity in response to sensory stimuli...|$|R
40|$|SummaryRecent {{studies have}} used fMRI signals from early visual areas to {{reconstruct}} simple geometric patterns. Here, we demonstrate a new Bayesian decoder that uses fMRI signals from early and anterior visual areas to reconstruct complex natural images. Our decoder combines three elements: a structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas, a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas, and prior {{information about the}} structure and semantic content of natural images. By combining all these elements, the decoder produces reconstructions that accurately reflect both the spatial structure and semantic category of the objects contained in the observed natural image. Our results show that prior information has a substantial effect {{on the quality of}} natural image reconstructions. We also demonstrate that much of the variance in the responses of anterior visual areas to complex natural images is explained by the semantic category of the image alone...|$|R
40|$|Recent {{studies have}} used fMRI signals from early visual areas to {{reconstruct}} simple geometric patterns. Here, we demonstrate a new Bayesian decoder that uses fMRI signals from early and anterior visual areas to reconstruct complex natural images. Our decoder combines three elements: a structural <b>encoding</b> <b>model</b> that characterizes responses in early visual areas, a semantic <b>encoding</b> <b>model</b> that characterizes responses in anterior visual areas, and prior {{information about the}} structure and semantic content of natural images. By combining all these elements, the decoder produces reconstructions that accurately reflect both the spatial structure and semantic category of the objects contained in the observed natural image. Our results show that prior information has a substantial effect {{on the quality of}} natural image reconstructions. We also demonstrate that much {{of the variance in the}} responses of anterior visual areas to complex natural images is explained by th...|$|R
40|$|Brain mapping using {{magnetic}} resonance imaging (MRI) is traditionally performed <b>using</b> <b>voxel-wise</b> statistical hypothe-sis testing. Such mass-univariate approach ignores subtle spa-tial interactions. The searchlight method, in contrast, uses a multivariate predictive model in each local neighborhood in brain space—named the searchlight. The classification per-formance is then reported {{at the center of}} the searchlight to build an information map. We extend the searchlight tech-nique to take into account additional voxels that can be con-sidered as a meaningful network; i. e., we define a criterion of multivariate connectivity to identify voxels that are statis-tically dependent on those in searchlight. We coin the term “connectivity searchlight ” for the extended searchlight. Using simulated data, we empirically show improved performance for brain regions with low signal-to-noise ratio and recovery of underlying network structures that would otherwise remain hidden. The proposed methodology is general and can be ap-plied to both functional and structural data. We also demon-strate promising results on a well-known fMRI dataset where images of different categories are presented. Index Terms — Magnetic resonance imaging, pattern recognition, multivariate analysis, functional connectivit...|$|R
40|$|Point process <b>encoding</b> <b>models</b> provide {{powerful}} {{statistical methods}} {{for understanding the}} responses of neurons to sensory stimuli. Although these models have been successfully applied to neurons in the early sensory pathway, they have fared less well capturing the response properties of neurons in deeper brain areas, owing {{in part to the}} fact that they do not take into account multiple stages of processing. Here we introduce a new twist on the point-process modeling approach: we include unobserved as well as observed spiking neurons in a joint <b>encoding</b> <b>model.</b> The resulting model exhibits richer dynamics and more highly nonlinear response properties, making it more powerful and more flexible for fitting neural data. More importantly, it allows us to estimate connectivity patterns among neurons (both observed and unobserved), and may provide insight into how networks process sensory input. We formulate the estimation procedure using variational EM and the wake-sleep algorithm, and illustrate the model’s performance using a simulated example network consisting of two coupled neurons. ...|$|R
40|$|Timbre, {{or sound}} quality, {{is a crucial}} but poorly {{understood}} dimension of auditory perception that is important in describing speech, music, and environmental sounds. The present study investigates the cortical representation of different timbral dimensions. <b>Encoding</b> <b>models</b> have typically incorporated the physical characteristics of sounds as features when attempting to understand their neural representation with functional MRI. Here we test an <b>encoding</b> <b>model</b> {{that is based on}} five subjectively derived dimensions of timbre to predict cortical responses to natural orchestral sounds. Results show that this timbre model can outperform other models based on spectral characteristics, and can perform as well as a complex joint spectrotemporal modulation model. In cortical regions at the medial border of Heschl's gyrus, bilaterally, and regions at its posterior adjacency in the right hemisphere, the timbre model outperforms even the complex joint spectrotemporal modulation model. These findings suggest that the responses of cortical neuronal populations in auditory cortex may reflect the encoding of perceptual timbre dimensions...|$|R
