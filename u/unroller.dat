3|2|Public
40|$|This thesis {{demonstrates}} that careful selection of compiler transformations {{can improve the}} output and reduce the compile-time cost of adaptive compilation. Compiler effectiveness depends {{on the order of}} code transformations applied. Adaptive compilation, then, uses empirical search to tune the transformation sequence for each program. This method achieves higher performance than traditional compilers, but often requires large compilation times. Previous research reduces compilation time by tuning the search process. This thesis, instead, tunes the search space by adding a loop <b>unroller,</b> addressing a deficiency in our compiler. Despite increasing the searchspace size, this change results in more effective and efficient searching. Averaged across nine benchmarks, the adaptive compiler produces code, more quickly, that is 10 % faster. Unfortunately, implementing a loop <b>unroller</b> is non-trivial for our low-level intermediate language. Therefore, this thesis also contributes an algorithm for identifying and unrolling loops in the absence of high-level loop structures...|$|E
40|$|The fast Fourier {{transform}} (FFT) is {{the cornerstone}} of many supercomputer applications and therefore needs careful performance tuning. Most often, however the real performance of the FFT implementations is far below the acceptable figures. In this paper we explore several strategies for performance optimisations of the FFT computation, such as enhancing instruction-level parallelism, loop merging, and reducing the memory loads and stores by using a special-purpose automatic loop <b>unroller.</b> Our approach is based on the principle of complete unrolling which we apply to modify the FT kernel of the NAS Parallel Benchmarks (NPB). In experiments on two different IBM SP 2 platforms, our automatically generated unrolled FFT subroutine is shown to improve the performance between 40 % and 53 % in comparison with the original code. Further the execution time of the entire 3 -D FFT mega-step of the benchmark is faster than when calls to a similar FFT subroutine from the vendor-optimised PESSL numerical library are used. Preliminary results suggest that the completely unrolled code also outperforms FFTW another high-performance FFT package. Finally, our approach for automatic generation of moderately optimised but specialised codes requires only a modest amount of programming effort...|$|E
40|$|Runtime compilation, {{due to its}} online nature, {{presents}} unique {{challenges and}} opportunities to compiler designers. Since compilation occurs during program execution, a just-in-time compiler (JIT) must be judicious in expending compilation time. The literature on traditional, offline compilers describes numerous program transformation techniques that strive to increase execution efficiency. However, while optimization passes for static compilers are well understood and have been thoroughly investigated, many such transformation algorithms cannot be implemented on a JIT environment due to compilation-time constraints. Further, offline algorithms are not designed to exploit information available to an online compiler at program execution time. The thesis of the research presented in this document is that program optimization techniques designed for traditional, offline compilers can be profitably adapted for a runtime compiler by effectively respecting the constraints imposed on compilation time and by exploiting the opportunities available in a runtime compilation environment. To that end, the dissertation explores the complexity of implementing program transformations for a runtime compiler and redesigns two optimization techniques for a JIT: register allocation and loop unrolling. The two transformations present contrasting challenges when they are included in a runtime compiler. While several offline, heuristic allocation algorithms achieve impressive results, they consume large amounts of compilation-time that are typically unacceptable for a JIT. We describe the design of two allocation algorithms that reduce allocation time while preserving the advantages of strong techniques authored for offline compilers. An experimental evaluation of the new algorithms demonstrates their effectiveness on a runtime compilation environment. While a runtime compiler {{is limited by the}} constraints imposed by its environment, compiling just prior to program invocation provides certain advantages over an offline compiler. In particular, it can examine information only available at program execution time. We describe the design of a lightweight runtime value-examining mechanism and a loop unrolling algorithm that work in tandem. Our experimental results indicate that the runtime <b>unroller</b> achieves significant improvements on floating point, scientific benchmarks. In summary, thus, the research described in this dissertation demonstrates how compiler optimization algorithms can be effectively tailored for runtime compilation...|$|E
2500|$|Callippus, a Greek {{astronomer}} of the 4th century, added seven spheres to Eudoxus' original 27 (in {{addition to}} the planetary spheres, Eudoxus included a sphere for the fixed stars). Aristotle described both systems, but insisted on adding [...] "unrolling" [...] spheres between each set of spheres to cancel the motions of the outer set. Aristotle {{was concerned about the}} physical nature of the system; without <b>unrollers,</b> the outer motions would be transferred to the inner planets.|$|R

