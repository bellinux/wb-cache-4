10|13|Public
5000|$|The Uniform {{distribution}} has the pdf:Thus {{the standard}} <b>uniform</b> <b>parameterization</b> is obtained if , , and [...]|$|E
40|$|This paper {{describes}} an algorithm the adaptively samples a parametric continuum {{so that a}} fidelity metric is satisfied. Using the divide-and-conquer strategy of adaptive sampling eliminates the guesswork of traditional <b>uniform</b> <b>parameterization</b> techniques. The space and time complexity of parameterization are increased in a controllable manner so that a desired fidelity is obtained...|$|E
40|$|Inverted soil {{moisture}} mv {{based on the}} linearized model for the interferometric phase at HH and VV polarization obtained using UAVSAR L-band data acquired during the CanEx-SM 10 campaign. The linearized model with the <b>uniform</b> <b>parameterization</b> is applied over the entire image, including to fields that decorrelate during the campaign (e. g. tilling) or to open water bodies. Note that the phase is not atmospherically corrected. linear_hh. mp 4 : HH polarization linear_vv. mp 4 : VV polarizatio...|$|E
40|$|Figure 1 : <b>Uniform</b> global {{conformal}} <b>parameterization</b> ((a) and (b)) {{and region}} emphasized conformal parameterization ((c) and (d)). (a). Least <b>uniform</b> conformal <b>parameterization</b> with energy: 21. 208 e − 5. (b). Most <b>uniform</b> conformal <b>parameterization</b> with energy: 3. 685 e − 5. (c). Maximizing the parameter {{area of the}} left half surface (with percentage: 83. 48 %). (d). Maximizing the parameter area of the right half surface (with percentage: 82. 58 %.) All orientable metric surfaces are Riemann surfaces and admit global conformal parameterizations. Riemann surface structure is a fundamental structure and governs many natural physical phenomena, such as heat diffusion and electro-magnetic fields on the surface. A good parameterization is crucial for simulation and visualization. This paper provides an explicit method for finding optimal global conformal parameterizations of arbitrary surfaces. It relies on certain holomorphic differential forms and conformal mappings from differential geometry and Riemann surface theories. Algorithms are developed to modify topology, locate zero points, and determine cohomology types of differential forms. The implementation {{is based on a}} finite dimensional optimization method. The optimal parameterization is intrinsic to the geometry, preserves angular structure, and can {{play an important role in}} various applications including texture mapping, remeshing, morphing and simulation. The method is demonstrated by visualizing the Riemann surface structure of real surfaces represented as triangle meshes. CR Categories: I. 3. 5 [Computational Geometry and Object Modeling]: Curve, surface, solid, and object representations—Surfac...|$|R
40|$|International audienceWe {{introduce}} {{the notion of}} angular speed uniformity as a quality measure for parameter-izations of plane curves and propose an algorithm to compute uniform reparameterizations for quadratic and cubic curves. We prove that only straight lines have <b>uniform</b> rational <b>parameterizations.</b> For any plane curve other than lines, we show {{how to find a}} rational reparameterization that has the maximum uniformity among all the rational parameterizations of the same degree. We also establish specific results for quadratic and certain cubic Bézier curves...|$|R
40|$|Multiple {{scattering}} contributes critically to {{the characteristic}} translucent appearance of food, liquids, skin, and crystals; but {{little is known}} about how it is perceived by human observers. This article explores the perception of translucency by studying the image effects of variations in one factor of multiple scattering: the phase function. We consider an expanded space of phase functions created by linear combinations of Henyey-Greenstein and von Mises-Fisher lobes, and we study this physical parameter space using computational data analysis and psychophysics. Our study identifies a two-dimensional embedding of the physical scattering parameters in a perceptually meaningful appearance space. Through our analysis of this space, we find <b>uniform</b> <b>parameterizations</b> of its two axes by analytical expressions of moments of the phase function, and provide an intuitive characterization of the visual effects that can be achieved at different parts of it. We show that our expansion of the space of phase functions enlarges the range of achievable translucent appearance compared to traditional single-parameter phase function models. Our findings highlight the important role phase function can have in controlling translucent appearance, and provide tools for manipulating its effect in material design applications. National Institutes of Health (U. S.) (Award R 01 -EY 019262 - 02) National Institutes of Health (U. S.) (Award R 21 -EY 019741 - 02...|$|R
40|$|An {{algebraic}} Z d-action of entropy rank one is one {{for which}} each element has finite entropy. Using the structure theory {{of these actions}} due to Einsiedler and Lind, this paper investigates dynamical zeta functions for elements of the action. An explicit periodic point formula is obtained leading to a <b>uniform</b> <b>parameterization</b> of the zeta functions that arise in expansive components of an expansive action, together with necessary and sufficient conditions for rationality in a more general setting...|$|E
40|$|RF cavity designs {{within the}} {{accelerator}} community have increased many {{fold in the}} last 20 years. Operating frequency now spans from a few megahertz to gigahertz, and quality factor varies from 1 to 1010. The requirements for stability and reliability have also become more stringent. During this period, technological revolutions in computers, telecommunication and networking {{have resulted in the}} production and wide spread availability of fast digital electronics components. These enable RF low-level control systems to rise to the challenges presented by the demands of new accelerators. By adapting more complex control algorithms in hybrid or fully digital feedback controls, a RF low-level control system with <b>uniform</b> <b>parameterization,</b> which was once impossible to implement in a fully analogue system, can now be achieved...|$|E
40|$|The {{improved}} quark mass density- dependent model, {{which has}} been successfully {{used to describe the}} properties of both finite nuclei and bulk nuclear matter, is extended to include the strange quark. The parameters of the model are determined by the saturation properties of bulk matter. Then the given parameter set is employed to investigate both the properties of strange hadronic matter and those of Λ hypernuclei. Bulk strange hadronic matter consisting of nucleons, Λ- hyperons and Ξ- hyperons is studied under mean-field approximation. Among others, density dependence of the effective baryon mass, saturation properties and stability of the physical system are discussed. For single-Λ hypernuclei, single particle energies of Λ hyperon is evaluated. In particular, it is found that the present model produces a small spin-orbit interaction, which is in agreement with the experimental observations. The above results show that the present model can consistently describe the properties of strange hadronic matter, {{as well as those of}} single Λ hypernuclei within an <b>uniform</b> <b>parameterization...</b>|$|E
40|$|The {{behavior}} of Catmull-Rom curves heavily {{depends on the}} choice of parameter values at the control points. We analyze a class of <b>parameterizations</b> ranging from <b>uniform</b> to chordal <b>parameterization</b> and show that, within this class, curves with centripetal parameterization contain properties that no other curves in this family possess. Researchers have previously indicated that centripetal parameterization produces visually favorable curves compared to <b>uniform</b> and chordal <b>parameterizations.</b> However, the mathematical reasons behind this behavior have been ambiguous. In this paper we prove that, for cubic Catmull-Rom curves, centripetal parameterization is the only parameterization in this family that guarantees that the curves do not form cusps or self-intersections within curve segments. Furthermore, we provide a formulation that bounds {{the distance of the}} curve to the control polygon and explain how globally intersection-free Catmull-Rom curves can be generated using these properties. Finally, we discuss two example applications of Catmull-Rom curves and show how the choice of parameterization makes a significant difference in each of these applications...|$|R
40|$|Description of purpose: The NA-MIC SPHARM-PDM Toolbox {{represents}} an automated {{set of tools}} for the computation of 3 D structural statistical shape analysis. SPHARM-PDM solves the correspondence problem by defining a first order ellipsoid aligned, <b>uniform</b> spherical <b>parameterization</b> for each object with correspondence es-tablished at equivalently parameterized points. However, SPHARM correspondence has shown to be inadequate for some biological shapes that are not well described by a <b>uniform</b> spherical <b>parameterization.</b> Entropy-based particle systems compute correspondence by representing surfaces as discrete point sets that does not rely on any inherent parameterization. However, they are sensitive to initialization and have little ability to recover from initial errors. By combining both methodologies we compute reliable correspondences in topologically challeng-ing biological shapes. Data: Diverse subcortical structures cohorts were used, obtained from MR brain images. Method(s) : The SPHARM-PDM shape analysis toolbox was used to compute point based correspondent models that were then used as initializing particles for the entropy-based particle systems. The combined framework was implemented as a stand-alone Slicer 3 module, which works as an end-to-end shape analysis module. Results: The combined SPHARM-PDM-Particle framework has demonstrated to improve correspondence in the example dataset over the conventional SPHARM-PDM toolbox. Conclusions: The work {{presented in this paper}} demon-strates a two-sided improvement for the scientific community, being able to 1) find good correspondences among spherically topological shapes, {{that can be used in}} many morphometry studies 2) offer an end-to-end solution that will facilitate the access to shape analysis framework to users without computer expertise...|$|R
40|$|AbstractIn {{this paper}} we derive an {{approximation}} property of four-point interpolatory curve subdivision, based on local cubic polynomial fitting. We show {{that when the}} scheme is used to generate a limit curve that interpolates given irregularly spaced points, sampled from a curve in any space dimension with a bounded fourth derivative, and the chosen parameterization is chordal, the accuracy is fourth order as the mesh size goes to zero. In contrast, <b>uniform</b> and centripetal <b>parameterizations</b> yield only second order...|$|R
40|$|The {{physical}} and chemical conditions under which Martian core formation took place are not well constrained. We modeled the pressure, temperature, and oxygen fugacity conditions under which {{it would be possible}} to match the inferred depletions of moderately siderophile elements Ni, Co, W, Mo, Ga, P, and Ge in the Martian mantle, using new constraints on their metal-silicate partitioning behavior. Using literature metal-silicate partitioning data, we characterize the dependence of the metal-silicate partition coefficients (D) on the temperature, pressure, oxygen fugacity, and composition of the silicate melt and the metal using a <b>uniform</b> <b>parameterization</b> approach for each element. Our results show that it is impossible to simultaneously account for the Martian mantle depletions of moderately siderophile elements if the Martian core sulfur content exceeds 10. 5 [*]wt[*]% at reducing conditions (1 log unit below the iron-wüstite (IW) buffer). At 10. 5 [*]wt[*]% core S, the conditions that best satisfy Martian mantle abundances of the seven siderophile elements are a mean pressure of 13 (± 1) [*]GPa at 2330 [*]K, corresponding to the presence of a magma ocean at least 1000 km deep during Martian core formation. More oxidizing conditions than the iron-wüstite buffer as suggested by iron meteorites are inconsistent with mantle siderophile element abundances. Extension of our approach to the highly siderophile elements Ru, Pd, Re, Ir, and Pt shows that their Martian mantle abundances are orders of magnitude too high to be accounted for by metal-silicate equilibration at high pressure and high temperature in a magma ocean, requiring a “late veneer” stage after core formation...|$|E
40|$|We study {{physical}} {{consequences of}} the Einstein equivalence principle (EEP) for a Hubble observer in FLRW universe. We introduce the local inertial coordinates {{with the help of}} a special conformal transformation. The local inertial metric is Minkowski-flat and materialized by a congruence of time-like geodesics of static observers. The static observers are equipped with the ideal clocks measuring the proper time that is synchronized with the clocks of the Hubble observer. The local inertial metric is used for physical measurements of spacetime intervals with the ideal clocks and rulers. The special conformal transformation preserves null geodesics but does not keep invariant time-like geodesics. Moreover, it makes the rate of the local time coordinate dependent on velocity of the particle which makes impossible to rich the <b>uniform</b> <b>parameterization</b> of the world lines of static observers and light geodesics with a single parameter - they differ by the conformal factor of FLRW metric. It tells us that the metric on the light cone is not Minkowski-flat but depends on the scale factor of FLRW universe and it can be interpreted as a weak violation of EEP for photons. The importance of this violation for gravitational physics is that some of local experiments conducted with freely-propagating electromagnetic waves may be sensitive to the Hubble expansion. We show that the Hubble constant H can be measured within the solar system by means of high-precision spacecraft Doppler tracking as a blue shift of frequency of radio waves circulating in the Earth-spacecraft radio link. We also analyze the behavior of the standing wave in a microwave resonator and show that the standing wave is insensitive to the Hubble expansion. Comment: 52 pages, no figures, references adde...|$|E
40|$|Boreal {{forest fires}} are a {{significant}} contributor to atmospheric composition in the high northern hemisphere, and are highly variable both spatially and temporally. This study uses a new emissions model [Kasischke et al., 2005] to generate input to the University of Maryland Chemical Transport Model [Allen et al., 1996], {{with the goal of}} examining and constraining the key uncertainties in current understanding of boreal forest fire behavior. Model outputs are compared with data from the MOPITT instrument as well as in situ measurements of CO. A case study of CO transport during the summer of 2000 is used to examine several key uncertainties in the emissions estimates, describing how current levels of uncertainty affect atmospheric composition and applying atmospheric measurements can be applied to constrain uncertainty. Source magnitudes determined by inverse methods were shown to be highly sensitive to the assumed injection properties. For the boreal forest in 2000, the best agreement with observations was obtained with a pressure-weighted profile of injection throughout the tropospheric column, but detailed examination of the results makes clear that any <b>uniform</b> <b>parameterization</b> of injection will be a significant source of error when applied globally. Comparison of simulated CO distributions from daily, weekly, and monthly aggregate emissions sources demonstrated that while model data sources produced a valid representation of emissions at weekly resolution, the atmospheric distribution outside the source region has very little sensitivity to temporal variability at scales finer than 30 days. Different estimates of burned area produced large differences in simulated patterns of atmospheric CO. The GBA- 2000 global product and the data sources used by Kasischke et al. [2005] gave better agreement with atmospheric observations compared to the GLOBSCAR product. Comparison of different estimates of fuel consumption indicated that atmospheric measurements of CO have limited sensitivity to spatial variability in fuels, but that current fuels maps can improve agreement with atmospheric measurements. These results provide a clear indication of how atmospheric measurements can be used to test hypotheses generated by emissions models...|$|E
40|$|Abstract. To {{solve the}} {{problems}} of more variety, more specifications and low efficiency during Cast & Roll process design, an expert database system for Cast & Roll process design of copper tubes has been developed. Knowledge reasoning, Artificial Neural Networks (ANN), Genetic Algorithm (GA), Numerical Simulation, <b>Uniform</b> Design, CAD <b>Parameterization</b> Design, database and Intranet have been integrated into the system for process design and parameter optimization, which can exert the advantages of each technology, which has been proved to be successful...|$|R
40|$|This paper {{describes}} {{a new technique}} for the triangulation of parametric surfaces. Most earlier methods sample the parameter domain, and the wrong choice of parameterization can spoil the triangulation or even cause the algorithm to fail. Conversely, we use a local tessellation primitive to sample and triangulate the surface. The sampling is almost <b>uniform</b> and the <b>parameterization</b> becomes irrelevant. If sampling density or triangle shape has to be adaptive, the resulting uniform mesh can be used either as an initial coarse mesh for a refinement process, or as a fine mesh to be reduced...|$|R
40|$|AbstractIn {{parametric}} curve interpolation there {{is given a}} sequence of data points and corresponding parameter values (nodes), {{and we want to}} find a {{parametric curve}} that passes through data points at the associated parameter values. We consider those interpolating curves that are described by the combination of control points and blending functions. We study paths of control points and points of the interpolating curve obtained by the alteration of one node. We show geometric properties of quadratic Bézier interpolating curves with <b>uniform</b> and centripetal <b>parameterizations.</b> Finally, we propose geometric methods for the interactive modification and specification of nodes for interpolating Bézier curves...|$|R
40|$|International audienceGlobal-scale tomographic models should aim at {{satisfying}} the full seismic spectrum. For this purpose, and to better constrain isotropic 3 [...] D variations of shear velocities in the mantle, we tackle a joint inversion of spheroidal normal-mode structure coefficients and multiple-frequency S-wave delay-times. In all previous studies for which normal modes were jointly inverted for, with body and/or surface waves, the mantle was laterally parameterized with uniform basis functions, such as spherical harmonics, equal-area blocks, evenly spaced spherical splines. In particular, spherical harmonics naturally appear {{when considering the}} Earth's free oscillations. However, progress towards higher resolution joint tomography requires a movement away from such <b>uniform</b> <b>parameterization,</b> to overcome its computational inefficiency to adapt to local variations in resolution. The main goal {{of this study is}} to include normal modes into a joint inversion based upon a non-uniform parameterization, that is adapted to the spatially varying smallest resolving-length of the data. Thus, we perform the first joint inversion of normal-mode and body-wave data using an irregular tomographic grid, optimized according to ray density. We show how to compute the projection of 3 [...] D sensitivity kernels for both data sets onto our parameterization made up of spherical layers spanned with irregular Delaunay triangulations. This approach, computationally efficient, allows us to map into the joint model multi-scale structural informations from data including periods in the 10 [...] 51 s range for body waves and 332 [...] 2134 s for normal modes. Tomographic results are focussed on the 400 [...] 2110 km depth range, where our data coverage is the most relevant. We discuss the potential of a better resolution where the grid is fine, compared to spherical harmonics up to degree 40, as the number of model parameters is similar. Our joint model seems to contain coherent structural components beyond degree 40, such as those related to the Farallon subduction. Assessing their robustness is postponed to a future work. A wider application of this tomographic workflow, holding promise to better understand mantle dynamics at various spatial scales, should primarily consist in adding surface-wave data and extending our sets of normal-mode and body-wave data...|$|E
40|$|Minimal l 1 Perturbation to Block Match Data (MILO) is a {{spatially}} accurate {{image registration}} algorithm developed for thoracic CT inhale/exhale images. The MILO algorithm {{consists of three}} components: (1) creating an initial estimate for voxel displacement via a Mutual Minimizing Block Matching Algorithm (MMBM), (2) a filtering step based on l 1 minimization and a <b>uniform</b> B-spline <b>parameterization,</b> and (3) recovering a full displacement field based on the filtered estimates. This thesis presents a variation of MILO for 4 DCT images. In practice, the use of uniform B-splines has led to rank deficient linear systems due to the spline's inability to conform to non-structured MMBM estimates. In order to adaptively conform to the data an octree is paired with radial functions. The l 1 minimization problem had previously been addressed by employing QR factorization, which required substantial storage. As an alternative a block coordinate descent algorithm is employed, relieving the need for QR factorization. Furthermore, by modeling voxel trajectories as quadratic functions in time, the proposed method is able to register multiple images...|$|R
40|$|We define b-compatibility for planar {{curves and}} propose three ball {{morphing}} techniques (b-morphs) between pairs of b-compatible curves. B-morphs use the automatic ball-map correspondence, proposed by Chazel et al. [11], {{from which they}} derive vertex trajectories (Linear, Circular, Parabolic). All are symmetric, meeting both curves with the same angle, which is a right angle for the Circular and Parabolic. We provide simple constructions for these b-morphs using the maximal disks in the finite region bounded by the two curves. We compare the b-morphs {{to each other and}} to other simple morphs (Linear Interpolation (LI), Closest Projection (CP), Curvature Interpolation (CI), Laplace Blending (LB), Heat Propagation (HP)) using seven measures of quality deficiency (travel distance, distortion, stretch, local acceleration, surface area, average curvature, maximal curvature). We conclude that the ratios of these measures depends heavily on the test case, especially for LI, CI, and LB which compute correspondence from a <b>uniform</b> geodesic <b>parameterization.</b> Nevertheless, we found that the Linear b-morph has consistently the shortest travel distance and that the Circular b-morph has the least amount of distortion. 36 37 Figure 1 : A morph between an apple and pear along Circular b-morph trajectories (top left). morphing solutions and (2) How do the b-morphs introduced here compare to other approaches...|$|R
30|$|In this subsection, we briefly {{discuss the}} {{procedure}} for finding the best parameter combination in the training period, which is a multi-step optimization procedure. The first step in this procedure {{is to determine the}} best specification of the pick matrix. As described in Sect.  3.3, a pick matrix that models the negative effect of sentiment should exploit the reversal effect of investor sentiment on returns. This means that if the sentiment index S_tm of market m at period t is positive (negative), the corresponding value in the pick matrix is negative (positive). The results in the training period identify this pick matrix as better than the positive pick matrix in terms of several performance measures. Having identified the general orientation, {{the next step is to}} determine if the weighted or unweighted version of the pick matrix should be applied. The comparison shows that both versions are very similar regarding their performance. Therefore, we chose the simpler, unweighted version of the pick matrix. As pointed out in Sect.  1, sentiment does not have an immediate effect on returns. Therefore, in the next step, the best lag τ has to be determined. We find that the sentiment strategy outperforms the benchmark strategies on medium-term lags, which we define as between 6 and 24  months. This implies that for the computation of the portfolio weights at period t, sentiment indexes with a medium-term lag should be used. As pointed out in Sect.  3.3, we want to impose as a few assumptions as possible regarding the prospective performance of the view in advance. Thus, the view distribution is selected to be <b>uniform</b> with <b>parameterization</b> U(- 0.005; 0.03). It should be noted that the mean of this distribution is positive. We chose a uniform view distribution with positive mean, since the outperformance that is generated by the view is expected to be positive. Therefore, this view distribution is not entirely uninformative, but uninformative regarding the probability of each value in the range [- 0.005; 0.03]. Nevertheless, alternative parameterizations of the view distribution are part of the robustness checks in Sect. 4.3. In addition, the initial market distribution is estimated using 10  years of historical data.|$|R

