18|283|Public
3000|$|In the following, we {{determine}} the sufficient conditions {{that will allow}} us to define an upper bound of an RT user's <b>utility</b> <b>parameter</b> [...]...|$|E
30|$|In {{an attempt}} to explore the policy {{implications}} of trying to increase teacher quality at disadvantaged schools, I run two simulations that change the number of vacancies and estimated <b>utility</b> <b>parameter</b> values to generate new counts of searching teachers and schools and new probabilities of searching and matching.|$|E
30|$|All the {{estimated}} coefficients are statistically different from zero, {{at a good}} level of significance (5 %), except the ModeI and PAType. The Likelihood Ratio test indicating the goodness-of-fit of the model is good. The ρ 2 and the %RIGHT tests are equal to 0.30 and 70.24 % respectively. The expected maximum <b>utility</b> <b>parameter</b> is equal to 1.402.|$|E
30|$|Teacher {{search and}} <b>utility</b> <b>parameters,</b> school <b>utility</b> <b>parameters,</b> {{as well as}} {{matching}} parameters are kept constant.|$|R
3000|$|..., one may, for example, {{emphasize}} sparsity in the <b>utility</b> <b>parameters.</b> In Section 3, we will {{evaluate a}} method for offline regression that uses a marginal prior that is more peaked than a Gaussian one, and hence it performs sound feature selection and fitting of <b>utility</b> <b>parameters</b> at the same time. Such an offline feature selection stage is not strictly necessary, but it can make the consecutive online learning stage in the field more (computationally) efficient.|$|R
3000|$|The new match probabilities {{are used}} in the multinomial logit {{framework}} for teachers and schools (along with <b>utility</b> <b>parameters)</b> to generate new search probabilities [...] (γ _j,k^o^k).|$|R
40|$|We generalise the {{standard}} joy-of-giving bequest motive by including inter-vivos gifts. Within a life-cycle framework, we analyse {{the implications of}} the choice of different discount factors for the utility of gifts and bequests. For a linear utility of giving, we characterise the gift and bequest pattern of a liquidity constrained individual over the life-cycle. We find that discounting at the interest rate is very convenient as the linear <b>utility</b> <b>parameter</b> can be interpreted as a summary measure for the strength of the motive of giving, net of all gift and bequest timing issues over the life-cycle. Peer reviewe...|$|E
40|$|The {{equilibrium}} analyses {{under the}} classical growth framework mainly concern production processes {{so far and}} the utility-maximization of consumers is not considered sufficiently. Treating a consumer as a producer of labor or land-use right etc. with a <b>utility</b> <b>parameter,</b> this paper presents equilibrium formulas taking account of the utility-maximization of consumers, which may facilitate the analysis of dynamic general equilibrium involving both profit-maximizing firms and utility-maximizing consumers under the classical growth framework. For concreteness, some numerical examples with Cobb-Douglas production and utility functions are utilized to illustrate the method of the equilibrium analysis involving utility-maximizing consumers. ...|$|E
40|$|A thought {{experiment}} {{is designed to}} investigate whether the structure of risk aversion (i. e., the changes in absolute or relative risk aversion associated with changes in wealth) can be estimated with reasonable precision from agricultural production data. Findings strongly suggest that typical production data are unlikely to allow identification {{of the structure of}} risk aversion. A flexible utility parameterization is found to slightly worsen technology parameter estimates. Results also indicate that even under a restricted utility specification, <b>utility</b> <b>parameter</b> estimates are biased. Further, their quality is much worse when shocks are not large or samples are small. expected utility, risk preferences, production analysis, risk attitudes, Production Economics, Risk and Uncertainty, C 13, D 24, D 81, Q 12,...|$|E
40|$|AbstractWe {{consider}} a model where a commuter's transportation mode choice is directly influenced by percentages of neighbors and socioeconomic peers making each choice. Discrete-choice estimation results controlling overall mechanisms related to individual heterogeneous preferences {{are embedded in}} a multi-agent based simulation in order to observe the evolution of choice behavior over time with sociodynamic feedback. We find that the estimated <b>utility</b> <b>parameters</b> for different plausible sociogeographic network scenarios can generate dramatically different dynamics. However, in a hypothetical experiment we find that swapping sociogeographic networks does not significantly change the long-run outcome of the simulation, when <b>utility</b> <b>parameters</b> are held fixed...|$|R
40|$|Currently, economists' {{models of}} the {{evolutionary}} selection of <b>utility</b> function <b>parameters</b> are generally based on two assumptions. First, {{it is assumed that}} <b>utility</b> <b>parameters</b> must serve Darwinian fitness, in the sense that individuals who maximize utility are also maximizing their biological survivability. Second, it is assumed that <b>utility</b> <b>parameters</b> accurately reflect well-being, in the sense that individuals who maximize utility also maximize their happiness. However, there is a large literature in anthropology, biology, and psychology suggesting that these two assumptions may not be warranted. Focusing on utility and happiness, the paper uses models of cultural selection to show that {{there is no guarantee that}} our evolved preference must be the preferences that maximize our happiness. Instead, there are plausible mechanisms of cultural selection that will allow immiserating preferences to persist in steady state equilibrium. These mechanisms are generally related to the concept of social achievement: those who achieve more in society will have a greater influence on the <b>utility</b> <b>parameters</b> of the next generation, and this influence is independent of the achievers' well-being. Thus, a preference is more likely to survive if it satisfies some mix of achievement goals and happiness goals, rather than just happiness goals alone. Copyright Kluwer Academic Publishers 2004 cultural theories of economic development, economics of happiness,...|$|R
30|$|In this section, {{we first}} detail and analyze a novel {{framework}} for reflecting users' short-term QoS requirements at their utility functions under a NUM problem formulation. This is achieved via the dynamic alteration of the utilities' properties {{in accordance to}} generic short-term time-varying QoS performance metrics—we refer to this framework as Dynamic Utility Adaptation (DUA). Emphasizing on multimedia services and their corresponding QoS prerequisites, a methodology for dynamically adapting RT users' <b>utility</b> <b>parameters</b> in accordance to their short-term throughput requirements is examined. Then, the overall utility-based optimization problem is formulated, considering both NRT and RT users' performance expectations, and its solution is derived. Finally, following a pure optimization theoretic analysis, the design properties of the proposed DUA framework are examined by determining the way users' <b>utilities</b> <b>parameters</b> deviations affect their priority of accessing system resources.|$|R
30|$|Results {{show that}} the {{probability}} of matching with a bad school is always greater than the probability of matching with a good school for teachers originating from bad schools. This is not very surprising. It is attributable to higher rates of transfer at bad schools, leading to more vacancies, and fewer teachers of all types searching for positions at bad schools, leading to less competition for these positions. Table 4 also shows that the probability of finding a match increases with experience level and with originating from a good school. For matching with a good school, originating from a good school dominates experience level. To match with a bad school, higher experience dominates school origin. These probabilities confirm the <b>utility</b> <b>parameter</b> results observed in Table 4, that good and bad schools have different priorities in recruiting teachers.|$|E
40|$|In this thesis, I {{estimate}} {{a structural}} demand model for prescription drug benefits by Medicare beneficiaries {{using data from}} the Medicare HMO program. I then use the <b>utility</b> <b>parameter</b> estimates to explore other questions of interest relating to the elderly's demand for prescription drug benefits. In Chapter 1, I study the question of how much Medicare beneficiaries value prescription drug benefits. Using data from the Medicare HMO program, I find that Medicare beneficiaries are willing to pay $ 33 to increase their brand-name coverage limit by $ 100. I also estimate marginal cost for each HMO and regress it on prescription drug benefits. I find that raising brand-name coverage by $ 100 costs $ 30. These estimates suggest that Medicare HMO enrollees are less than average prescription drug users and the results give a lower bound for the welfare derived by the elderly from prescription drug benefits. Chapter 2 addresses the question of how Medicare HMOs ' choices of premiums an...|$|E
40|$|This paper {{shows that}} a power utility speci 8 ̆ 5 cation of {{preferences}} over total expenditure (ie. CRRA preferences) implies that intratemporal demands are in the PIGL/PIGLOG class. This class generates (at most) rank two demand systems and we can test the validity of power utility on cross-section data. Further, if we maintain the assumption of power utility, and within period preferences are not homothetic, then the intertemporal preference parameter is identi ed by the curvature of Engel curves. Under the power utility assumption, neither Euler equation estimation nor structural consumption function estimation is necessary to identify the power parameter. In our empirical work, we use demand data to estimate the power <b>utility</b> <b>parameter</b> and to test the assumption of the power utility representation. We 8 ̆ 5 nd estimates of the power parameter larger than obtained from Euler equation estimation, but we reject the power speci 8 ̆ 5 cation of within period utility...|$|E
40|$|Multinomial logit choice models {{based on}} latent class (LC) or HB methods are {{utilized}} in marketing research today along with simulators which predict choices and market shares. However, a weakness in these models creates a potential interpretability and validity problem. The {{problem is that}} the part-worth preference (<b>utility)</b> <b>parameters</b> that are used to make suc...|$|R
40|$|The diploma thesis {{deals with}} the {{nutrition}} fattening cattle. The evaluation of the feed rations {{was based on the}} needs of nutrients for the recommended values in relation to <b>utility</b> <b>parameters</b> on the given farm. The work also evaluated feeding and stabling technique, the quality of feed composition and feed rations and evaluation of the basic economic indicators of fattening bulls...|$|R
3000|$|Following a pure {{functions}} theoretic analysis, {{the lower}} bound of an RT user's <b>utility</b> function <b>parameter</b> [...]...|$|R
40|$|This paper {{studies the}} ability of a general class of habit-based asset pricing models to match the {{conditional}} moment restrictions implied by asset pricing theory. We treat the functional form of the habit as unknown, and estimate it {{along with the rest of}} the model’s finite dimensional parameters. Using quarterly data on consumption growth, assets returns and instruments, our empirical results indicate that the estimated habit function is nonlinear, that habit formation is better described as internal rather than external, and the estimated time-preference parameter and the power <b>utility</b> <b>parameter</b> are sensible. In addition, the estimated habit function generates a positive stochastic discount factor (SDF) proxy and performs well in explaining crosssectional stock return data. We find that an internal habit SDF proxy can explain a cross-section of size and book-market sorted portfolio equity returns better than (i) the Fama and French (1993) three-factor model, (ii) the Lettau and Ludvigson (2001 b) scaled consumption CAPM model, (iii) an external habit SDF proxy...|$|E
40|$|In this thesis, I {{estimate}} {{a structural}} demand model for prescription drug benefits by Medicare beneficiaries {{using data from}} the Medicare HMO program. I then use the <b>utility</b> <b>parameter</b> estimates to explore other questions of interest relating to the elderly's demand for prescription drug benefits. In Chapter 1, I study the question of how much Medicare beneficiaries value prescription drug benefits. Using data from the Medicare HMO program, I find that Medicare beneficiaries are willing to pay $ 33 to increase their brand-name coverage limit by $ 100. I also estimate marginal cost for each HMO and regress it on prescription drug benefits. I find that raising brand-name coverage by $ 100 costs $ 30. These estimates suggest that Medicare HMO enrollees are less than average prescription drug users and the results give a lower bound for the welfare derived by the elderly from prescription drug benefits. Chapter 2 addresses the question of how Medicare HMOs' choices of premiums and benefits affect selection. Changes in demographic factors (a measure of risk based on beneficiaries' characteristics) and risk scores (a measure based on beneficiaries' inpatient diagnoses) in the fee-for-service sector are regressed on changes in premiums and benefits in the HMO sector. The results show that increasing premiums and lowering benefits raise the demographic factor but have no effect on the risk score, suggesting that beneficiaries in more expensive demographic categories switch out of HMOs when premiums rise and benefits fall but these beneficiaries are healthy for their demographic category. (cont.) Chapter 3 measures the welfare loss from the withdrawals from the HMO program following the Balanced Budget Act of 1997, using the <b>utility</b> <b>parameter</b> estimates from Chapter 1. The changes to the Medicare HMO program in the Balanced Budget Act triggered many plan withdrawals from the program. The welfare and costs are calculated under two counterfactual scenarios. The results show that the Medicare HMO program generates more welfare than costs and that the withdrawals resulted in a net loss for society. The estimates of the loss range from $ 4. 3 billion to $ 16. 6 billion. by Anne Elizabeth Hall. Thesis (Ph. D.) [...] Massachusetts Institute of Technology, Dept. of Economics, 2005. Includes bibliographical references...|$|E
40|$|This paper initiates a study toward {{developing}} and applying randomized algorithms for stability of high speed communication networks. The {{focus is on}} congestion and delay-based flow controllers for sources, which are "utility maximizers" for individual users. First, we introduce a nonlinear algorithm for such source flow controllers, which uses as feedback aggregate congestion and delay information from bottleneck nodes of the network, and depends {{on a number of}} parameters, among which are link capacities, user preference for utility, and pricing. We then linearize this nonlinear model around its unique equilibrium point and perform a robustness analysis for a special, symmetric, case, with a single bottleneck node. The "symmetry" here captures the scenario when certain utility and pricing parameters are the same across all active users, for which we derive closed-form necessary and sufficient conditions for stability and robustness under parameter variations. In addition, the ranges of values for the utility and pricing parameters for which stability is guaranteed are computed exactly. These results also admit counterparts for the case when the pricing parameters vary across users, but the <b>utility</b> <b>parameter</b> values are still the same...|$|E
40|$|We {{show how}} {{to include in}} the CAPM moments of any order, {{extending}} the mean-variance or mean-variance-skewness versions available until now. Then, we present a simple way to modify the formulae, {{in order to avoid the}} appearance of <b>utility</b> <b>parameters.</b> The results can be easily applied to practical portfolio design, with econometric inference and testing based on generalised method of moments procedures. An empirical application to the Brazilian stock market is discussed...|$|R
40|$|The {{bachelor}} thesis {{deals with}} the nutrition fattening cattle and evaluates standart of nutrition on the given farm. Information on the composition of feed rations, feeding and stabling technique {{were obtained from the}} dietary study of nutrition fattening cattle. The evaluation of the feed rations was based on the needs of nutrients for the recommended values in relation to <b>utility</b> <b>parameters.</b> The work also evaluated the quality of roughage in terms of nutritional value and selected fermentation characteristics...|$|R
40|$|We {{obtain the}} {{transitional}} {{dynamics of the}} decentralized economy described by P. M. Romer and characterize the dynamic behavior of the most relevant variables. We determine {{the existence of a}} stable one-dimensional manifold containing a steady state with innovation, unique in ratios, and also find a threshold in the accumulation of physical capital below which the economy is not innovating. Finally, using simulations, we assess the significance of this threshold and analyze the influence that technological and <b>utility</b> <b>parameters</b> have on it. ...|$|R
40|$|This paper initiates a study toward {{developing}} and applying randomized algorithms for stability of high speed communication networks. We consider the discrete-time {{version of the}} nonlinear algorithm introduced in [1], which uses as feedback variations in queueing delay information from bottleneck nodes of the network. We then linearize this nonlinear model around its unique equilibrium point at a single bottleneck node, and perform a robustness analysis for a special, symmetric case, where certain utility and pricing parameters are the same across all active users. We derive closed-form necessary and sufficient conditions for stability and robustness under parameter variations. In addition, the ranges of values for the utility and pricing parameters for which stability is guaranteed are computed exactly. These results also admit counterparts for the case when the pricing parameters vary across users, but the <b>utility</b> <b>parameter</b> values are still the same. In the general non-symmetric case, when closedform derivation is not possible, we construct specific randomized algorithms which provide a probabilistic estimate of the local stability of the network. In particular, we use Monte Carlo as well as Quasi-Monte Carlo techniques for the linearized model. The results obtained provide a complete analysis of congestion control algorithms for internet style networks with a single bottleneck node {{as well as for}} networks with general random topologies...|$|E
40|$|A popular {{explanation}} of aggregate stock market behavior suggests that assets are priced {{as if there}} were a representative investor whose utility is a power function of the difference between aggregate consumption and a “habit” level, where the habit is some function of lagged and (possibly) contemporaneous consumption. But theory does not provide precise guidelines about the parametric functional relationship between the habit and aggregate consumption. This makes for- mal estimation and testing challenging; at the same time, it raises an empirical question about the functional form of the habit that best explains asset pricing data. This paper studies the ability of a general class of habit-based asset pricing models to match the conditional moment restrictions implied by asset pricing theory. Our approach is to treat the functional form of the habit as unknown, and to estimate it {{along with the rest of}} the model’s finite dimensional parameters. This semiparametric approach allows us to empirically evaluate a number of interesting hypotheses about the specification of habit-based asset pricing models. Using stationary quarterly data on consumption growth, assets returns and instruments, our empirical results indicate that the estimated habit function is nonlinear, the habit formation is internal, and the estimated time-preference parameter and the power <b>utility</b> <b>parameter</b> are sensible. In addition, our estimated habit function generates a positive stochastic discount factor (SDF) proxy and performs well in explaining cross-sectional stock return data. We find that an internal habit SDF proxy can explain a cross-section of size and book-market sorted portfolio equity returns better than (i) the Fama and French (1993) three-factor model, (ii) the Lettau and Ludvigson (2001 b) scaled consumption CAPM model, (iii) an external habit SDF proxy, (iv) the classic CAPM, and (v) the classic consumption CAPM. ...|$|E
40|$|Doctor of PhilosophyDepartment of Agricultural EconomicsJason S. BergtoldIn recent years, great {{attention}} {{has been placed on}} conservation systems for agricultural production. Conservation practices offer economic and environmental benefits, yet conventional practices remain the prevailing system in some regions. As conservation efforts are launched by different local and federal agencies, understanding farmers’ motivations when adopting conservation practices is important to ensure the continuation of adoption through the development of programs that are tailored to meet farmers’ preferences and constraints. 	The purpose of the first essay was to identify the factors affecting farmers’ choice of tillage practice at the crop level. Farmer’s choice of No-till, Strip-till and Conventional tillage was modeled for dryland corn, wheat and soybean production in Kansas. The results show that tillage decisions are crop-specific and that factors such as risk aversion, baling and grazing of crop residue, crop acreage, and farmers’ approach to adopting new technologies are significant factors affecting farmers’ decisions. The second essay focused on the adoption of continuous no-till, conservation crop rotation, cover crops, and variable rate application of inputs and the effect that incentive payments, payment mechanism, and off-farm environmental benefits from conservation have on the decision to adopt. This essay also examined the risk associated with the variability of net returns and its effect on farmers’ willingness to adopt using a non-linear extended expected utility framework, allowing for the estimation of a <b>utility</b> <b>parameter</b> for net returns, farmer’s subjective judgment of probabilities, and farmers’ risk attitudes. Farmers were found to exhibit risk aversion, with an estimated risk premium of approximately 3 % of net returns. Results also suggested a preference for federally-run programs and for programs with higher off-farm environmental benefits. The third essay examined the timing of adoption of continuous no-till, cover crops, and variable rate application of inputs. This study found that risk aversion delays the timing of adoption of cover crops and variable rate application of inputs. However, the timing of adoption of continuous no-till was not affected by risk aversion. Findings also indicated that farmers who consider themselves innovators adopt at a faster rate than their counterparts...|$|E
40|$|This paper {{studies the}} {{identification}} of the costs of simultaneous search in portfolio problems (Chade and Smith, 2006). We show that market shares data from a single market do not provide sufficient information to identify the search cost distribution in any interval, even if utility distributions are known to the econometrician. We then show that by pooling data from markets where the alternatives that similar decision makers confront vary, the search cost distribution and the <b>utility</b> <b>parameters</b> of the logit demand model can be identified...|$|R
40|$|OBJECTIVE: To {{evaluate}} how {{the utility}} (reliability, validity, acceptability, feasibility, cost and educational impact) of a communication-OSCE {{was influenced by}} whether or not station-specific (StSp) checklists were used together with a generic instrument {{and whether or not}} narrative feedback was provided to students. METHODS: At ten stations, faculty members rated standardized patient-student interactions using the common ground (CG) instrument (at all stations) and StSp-checklists. Both raters and patients provided written feedback. The impact of changing the design on the various <b>utility</b> <b>parameters</b> was assessed: reliability by means of a generalizability study, cost using the Reznick model and the other <b>utility</b> <b>parameters</b> by means of a survey. RESULTS: Use of the generic instrument (CG) proved more reliable (G coefficient= 0. 67) than using the StSp-checklists (G= 0. 47) or both (G= 0. 65) while there was a high correlation between both scale scores (Pearsons'r= 0. 86). The cost was 6. 5 % higher when StSp-checklists were used and 5 % higher when narrative feedback was provided. CONCLUSION: The utility of a communication OSCE can be enhanced by omitting StSp-checklists and by providing narrative feedback to students. PRACTICE IMPLICATIONS: The same generic assessment scale can be used in all stations of a communication OSCE. Providing feedback to students is promising but it increases the costs...|$|R
40|$|Stated choice (SC) {{surveys are}} a key tool for {{studying}} travel behaviour and are used to inform policy decisions in many countries. Recently, the best-worst (BW) variant of SC has rapidly increased in popularity in fields as diverse as transport, marketing and health research. A key argument for its implementation has been that it {{is perceived to be}} easier for respondents to identify the best and the worst alternative in a choice set compared to identifying the second- or even third best. For elicitation formats asking respondents to consecutively identify the first, second and third best (etc.) alternative, labelled here as repeated best stages, {{it is well known that}} <b>utility</b> and scale <b>parameters</b> are generally not stable across the stages. Joint analysis of the responses to each stage may increase the efficiency of the <b>utility</b> and willingness-to-pay <b>parameters</b> (i. e. smaller standard errors), but incorrect inferences may be made if these parameters are not stable across the stages. This paper tests the stability of <b>utility</b> <b>parameters</b> for the repeated BW and one-off BW format. Using data from three different studies, we show that, regardless of the dataset and elicitation format used, the obtained <b>utility</b> <b>parameters</b> and willingness to pay estimates are not stable across stages. The results thereby question the use of BW data in applied work aimed at forecasting and understanding first (best) choices. Our findings thereby contradict recent discussions about potentially beneficial framing effects in BW surveys. The unique presence of corresponding data from a repeated best and repeated BW exercise in one survey highlights the observed rank-orders are highly consistent across the two elicitation formats and that any differences in marginal willingness to pay estimates can be attributed to the imposed econometric model rather than to differences in the behaviour of respondents...|$|R
40|$|The ever {{increasing}} demand for wireless data services {{has given a}} starring role to dense small cell (SC) deployments for mobile networks, as increasing frequency re-use by reducing cell size has historically been {{the most effective and}} simple way to increase capacity. Such densification entails challenges at the Transport Network Layer (TNL), which carries packets throughout the network, since hard-wired deployments of small cells prove to be cost-unfeasible and inflexible in some scenarios. The goal of this thesis is, precisely, to provide cost-effective and dynamic solutions for the TNL that drastically improve the performance of dense and semi-planned SC deployments. One approach to decrease costs and augment the dynamicity at the TNL is the creation of a wireless mesh backhaul amongst SCs to carry control and data plane traffic towards/from the core network. Unfortunately, these lowcost SC deployments preclude the use of current TNL routing approaches such as Multiprotocol Label Switching Traffic Profile (MPLS-TP), which was originally designed for hard-wired SC deployments. In particular, one of the main problems is that these schemes are unable to provide an even network resource consumption, which in wireless environments can lead to a substantial degradation of key network performance metrics for Mobile Network Operators. The equivalent of distributing load across resources in SC deployments is making better use of available paths, and so exploiting the capacity offered by the wireless mesh backhaul formed amongst SCs. To tackle such uneven consumption of network resources, this thesis presents the design, implementation, and extensive evaluation of a self-organized backpressure routing protocol explicitly designed for the wireless mesh backhaul formed amongst the wireless links of SCs. Whilst backpressure routing in theory promises throughput optimality, its implementation complexity introduces several concerns, such as scalability, large end-to-end latencies, and centralization of all the network state. To address these issues, we present a throughput suboptimal yet scalable, decentralized, low-overhead, and low-complexity backpressure routing scheme. More specifically, the contributions in this thesis can be summarized as follows: We formulate the routing problem for the wireless mesh backhaul from a stochastic network optimization perspective, and solve the network optimization problem using the Lyapunov-driftplus-penalty method. The Lyapunov drift refers to the difference of queue backlogs in the network between different time instants, whereas the penalty refers to the routing cost incurred by some network <b>utility</b> <b>parameter</b> to optimize. In our case, this parameter is based on minimizing the length of the path taken by packets to reach their intended destination. Rather than building routing tables, we leverage geolocation information as a key component to complement the minimization of the Lyapunov drift in a decentralized way. In fact, we observed that the combination of both components helps to mitigate backpressure limitations (e. g., scalability,centralization, and large end-to-end latencies). The drift-plus-penalty method uses a tunable optimization parameter that weight the relative importance of queue drift and routing cost. We find evidence that, in fact, this optimization parameter impacts the overall network performance. In light of this observation, we propose a self-organized controller based on locally available information and in the current packet being routed to tune such an optimization parameter under dynamic traffic demands. Thus, the goal of this heuristically built controller is to maintain the best trade-off between the Lyapunov drift and the penalty function {{to take into account the}} dynamic nature of semi-planned SC deployments. We propose low complexity heuristics to address problems that appear under different wireless mesh backhaul scenarios and conditions [...] . Postprint (published version...|$|E
40|$|The {{risks of}} HIV {{transmission}} {{associated with the}} opioid epidemic make cost-effective programs for people who inject drugs (PWID) a public health priority. Some of these programs have benefits beyond prevention of HIV-a critical consideration given that injection drug use is increasing across most United States demographic groups. To identify high-value HIV prevention program portfolios for US PWID, we consider combinations of four interventions with demonstrated efficacy: opioid agonist therapy (OAT), needle and syringe programs (NSPs), HIV testing and treatment (Test & Treat), and oral HIV pre-exposure prophylaxis (PrEP). We adapted an empirically calibrated dynamic compartmental model {{and used it to}} assess the discounted costs (in 2015 US dollars), health outcomes (HIV infections averted, change in HIV prevalence, and discounted quality-adjusted life years [QALYs]), and incremental cost-effectiveness ratios (ICERs) of the four prevention programs, considered singly and in combination over a 20 -y time horizon. We obtained epidemiologic, economic, and health <b>utility</b> <b>parameter</b> estimates from the literature, previously published models, and expert opinion. We estimate that expansions of OAT, NSPs, and Test & Treat implemented singly up to 50 % coverage levels can be cost-effective relative to the next highest coverage level (low, medium, and high at 40 %, 45 %, and 50 %, respectively) and that OAT, which we assume to have immediate and direct health benefits for the individual, {{has the potential to be}} the highest value investment, even under scenarios where it prevents fewer infections than other programs. Although a model-based analysis can provide only estimates of health outcomes, we project that, over 20 y, 50 % coverage with OAT could avert up to 22, 000 (95 % CI: 5, 200, 46, 000) infections and cost US$ 18, 000 (95 % CI: US$ 14, 000, US$ 24, 000) per QALY gained, 50 % NSP coverage could avert up to 35, 000 (95 % CI: 8, 900, 43, 000) infections and cost US$ 25, 000 (95 % CI: US$ 7, 000, US$ 76, 000) per QALY gained, 50 % Test & Treat coverage could avert up to 6, 700 (95 % CI: 1, 200, 16, 000) infections and cost US$ 27, 000 (95 % CI: US$ 15, 000, US$ 48, 000) per QALY gained, and 50 % PrEP coverage could avert up to 37, 000 (22, 000, 58, 000) infections and cost US$ 300, 000 (95 % CI: US$ 162, 000, US$ 667, 000) per QALY gained. When coverage expansions are allowed to include combined investment with other programs and are compared to the next best intervention, the model projects that scaling OAT coverage up to 50 %, then scaling NSP coverage to 50 %, then scaling Test & Treat coverage to 50 % can be cost-effective, with each coverage expansion having the potential to cost less than US$ 50, 000 per QALY gained relative to the next best portfolio. In probabilistic sensitivity analyses, 59 % of portfolios prioritized the addition of OAT and 41 % prioritized the addition of NSPs, while PrEP was not likely to be a priority nor a cost-effective addition. Our findings are intended to be illustrative, as data on achievable coverage are limited and, in practice, the expansion scenarios considered may exceed feasible levels. We assumed independence of interventions and constant returns to scale. Extensive sensitivity analyses allowed us to assess parameter sensitivity, but the use of a dynamic compartmental model limited the exploration of structural sensitivities. We estimate that OAT, NSPs, and Test & Treat, implemented singly or in combination, have the potential to effectively and cost-effectively prevent HIV in US PWID. PrEP is not likely to be cost-effective in this population, based on the scenarios we evaluated. While local budgets or policy may constrain feasible coverage levels for the various interventions, our findings suggest that investments in combined prevention programs can substantially reduce HIV transmission and improve health outcomes among PWID...|$|E
40|$|A preocupa????o com o planejamento das cidades e sua rela????o com as condi????es de vida das pessoas e das coletividades n??o ?? uma novidade na hist??ria da sa??de coletiva. Desde a d??cada de 1980, a proposta de promo????o da sa??de, intitulada Cidades Saud??veis, vem se apresentando como uma estrat??gia vi??vel e efetiva de planejamento sustent??vel local, tendo como eixo norteador a melhoria na qualidade de vida das pessoas e das coletividades. Ao longo dos anos de implanta????o dessa estrat??gia, diversos estudos foram desenvolvidos e um n??mero significativo de indicadores gerados, buscando avaliar os processos e os resultados relacionados a essa proposta de promo????o da sa??de. O objetivo desta pesquisa foi avaliar os estudos avaliativos relatados por autores, em artigos cient??ficos, no contexto do Movimento Internacional Cidades Saud??veis. Para tanto, realizou-se um estudo documental, com o cumprimento de etapas desde a sele????o das fontes e do {{material}} de consulta at?? a descri????o de alguns componentes das pr??ticas avaliativas, sendo, posteriormente, o material submetido ?? an??lise e avalia????o da qualidade, a partir dos par??metros e diretrizes atuais, elaborados pelo Joint Committee on Standards for Educational Evaluation (JCSEE). Visando uma maior comparabilidade entre os par??metros e diretrizes utilizados, empregou-se uma valora????o e classifica????o dos escores obtidos, bem como o tratamento estat??stico dos dados. Para completar a pesquisa metaavaliativa proposta, alguns aspectos ??ticos sobre o par??metro da Utilidade foram considerados e discutidos, ?? luz da Teoria da Ci??ncia do Comportamento. Os resultados evidenciaram que a maioria das avalia????es apresentou um bom desempenho, havendo uma predomin??ncia de 46 % de pr??ticas definidas como boas e que uma pequena parte dos estudos (8 %) avaliada como fraca. O par??metro viabilidade apresentou a melhor porcentagem de estudos avaliativos classificados como excelentes e nenhum registro na categoria fraco, sendo notada a maior ocorr??ncia dessa classifica????o no crit??rio propriedade. O par??metro responsabilidade s?? apresentou registro de informa????es sobre as pr??ticas avaliativas em quatro artigos selecionados. As diretrizes que apresentaram dados mais discrepantes e merecedores de aten????o foram U 3 ??? Prop??sitos negociados; U 5 ??? Informa????o Relevante; U 6 ??? Processos e Produtos Significativos; F 3 ??? Viabilidade contextual, P 1 ??? Orienta????o Responsiva e Inclusiva; P 2 ??? Acordos Formais; P 4 ??? Transpar??ncia e Justi??a e P 6 ??? Conflitos e interesses. No par??metro precis??o, foram encontrados os melhores resultados avaliativos e com menos varia????es. Com rela????es ?? an??lise dos valores prim??rios presentes nas pr??ticas avaliativas, a categoria comportamental bens dos outros foi identificada em todos os artigos, seja ocorrendo isoladamente (10 artigos) ou em combina????o com as outras categorias. Bens pessoais e bens das culturas n??o apareceram separadamente na amostra selecionada. Al??m desses valores prim??rios, vinte e nove categorias relativas aos valores instrumentais foram registradas, notando-se as presen??as marcantes dos valores participa????o e intersetorialidade. Por fim, considera-se importante e necess??rio o est??mulo ?? realiza????o de outras pesquisas meta-avaliativas no contexto do Movimento Internacional Cidades Saud??veis, bem como uma aten????o especial ao processo de explicita????o de valores, negocia????o e media????o de conflitos e interesses, em iniciativas envolvendo os temas promo????o da sa??de e processos urbanos. {{concern with}} cities??? planning {{and its relation}} to the living conditions of people and communities is not a novelty {{in the history of the}} public health. Since the 1980 ???s, the proposal for health promotion entitled Healthy Cities has been presenting itself as a feasible and effective strategy of local sustainable planning, and its guidelines are based on the improvement of people and communities??? life quality. Throughout the years deploying this strategy, several studies have been carried out and a significant number of indicators were produced, aiming at evaluating the processes and the findings related to this health promotion proposal. This research aims is to evaluate the evaluative studies reported by authors, in scientific articles, in the context of the International Healthy Cities Movenent. For that purpose, a documentary study was undertaken and completed in stages, from the selection of sources and consultation material up to the description of some compenents of the evaluating practices, with the subsequent forwarding of the material to analysis and evaluation of the quality, based on the current parameters and guidelines developed by the Joint Committee on Standards for Educational Evaluation (JCSEE). Aiming at an improved comparability between the parameters and guidelines used, it has been used the valuation and rating of scores found, as well as the statistical treatment of the data. To complete the evaluative target research proposed, some ethical aspects on the <b>Utility</b> <b>parameter</b> were considered and discussed in the light of the Behavioral Science Theory. The results evidenced that the majority of the evaluations had a good performance, with a prevalence of 46 % of the practices defined as good and a small portion of the studies (8 %) evaluated as weak. The Feasibility parameter presented the best percentage among the evaluative studies rated as excellent and there was no record under the weak category. It has been noticed the greatest occurrence of this rating under the Propriety criterion. The Evaluation Accountability parameter only presented records of information on the evaluative practices in four selected articles. The guidelines that presented the most discrepant data that deserve attention were the U 3 ??? Negotiated Purposes; U 5 ??? Relevant Information; U 6 ??? Meaningful Processes and Products; F 3 ??? Contextual Viability; P 1 ??? Responsive and Inclusive Orientation; P 2 ??? Formal Agreements; P 4 ??? Clarity and Fairness and P 6 ??? Conflicts and Interests. The Accuracy parameter was where the best evaluative results were found, with less variations. In relation to the analysis of the primary values present in the evaluative practices, the behavioral category third parties??? properties was identified in all articles, either separately (10 records) or combined with other categories. Personal properties and cultural properties did not appear separately in the selected sample. In addition to these primary values, twenty-nine categories related to instrumental values were registered, noticing the outstanding presence of the participation and intersectoriality values. Finally, the incentive of other evaluative target researches within the context of the International Health City Movement is both important and necessary, as well as the awareness of the process of value clarification, negotiation and mediation of conflicts and interests in initiatives that involve health promotion and urban processes themes...|$|E
30|$|Only {{two parties}} involved. The model assumes {{that there are}} only two parties so that the {{universe}} of outcomes is either unanimity or disagreement. This is a reasonable assumption in order to describe situations in which there are two majority parties whose agreement is needed to make an appointment. The many-party case involves a more complex model where the relative ideological proximity and the degree of risk aversion will {{play a role in the}} solution of the game. The resulting equilibria will typically depend on the ranges of <b>utility</b> <b>parameters</b> and ideological positions.|$|R
40|$|This {{bachelor}} thesis {{deals with}} the nutrition of dairy cows and feeding techniques and evaluation of level on that farm. Assessment {{of the level of}} nutrition was based on the assessment of needs nutrients and energy to recommended values in relation to <b>utility</b> <b>parameters.</b> Another part of work is focused on evaluating the quality of roughage from the view of selected fermentation characteristics and nutritious value. Corn and grass silage were evaluated as excellent. An average efficiency in the reporting enterprise was 7708 kg per cow in 2013...|$|R
40|$|We study hedonic {{games with}} {{heterogeneous}} player types that reflect her nationality, ethnic background, or skill type. Agents' preferences are dictated by status-seeking where status {{can be either}} local or global. The two dimensions of status define the two components of a generalized constant elasticity of substitution utility function. In this setting, we characterize the core {{as a function of}} the <b>utility's</b> <b>parameter</b> values and show that in all cases the corresponding cores are non-empty. We further discuss the core stable outcomes in terms of their segregating versus integrating properties. Coalitions, Core, Stability, Status-seeking...|$|R
