3|51|Public
60|$|This is {{a natural}} and almost <b>unavoidable</b> <b>imperfection</b> in almost all the names of substances, in all {{languages}} whatsoever, which men will easily find when, once passing from confused or loose notions, they come to more strict and close inquiries. For then they will be convinced how doubtful and obscure those words are in their signification, which in ordinary use appeared very clear and determined. I was once in a meeting of very learned and ingenious physicians, where by chance there arose a question, whether any liquor passed through the filaments of the nerves. The debate having been managed a good while, by variety of arguments on both sides, I (who {{had been used to}} suspect, that the greatest part of disputes were more about the signification of words than a real difference in the conception of things) desired, that, before they went any further on in this dispute, they would first examine and establish amongst them, what the word LIQUOR signified. They at first were a little surprised at the proposal; and had they been persons less ingenious, they might perhaps have taken it for a very frivolous or extravagant one: since {{there was no one there}} that thought not himself to understand very perfectly what the word liquor stood for; which I think, too, none of the most perplexed names of substances. However, they were pleased to comply with my motion; and upon examination found that the signification of that word was not so settled or certain as they had all imagined; but that each of them made it a sign of a different complex idea. This made them perceive that the main of their dispute was about the signification of that term; and that they differed very little in their opinions concerning SOME fluid and subtle matter, passing through the conduits of the nerves; though it was not so easy to agree whether it was to be called LIQUOR or no, a thing, which, when considered, they thought it not worth the contending about.|$|E
50|$|The biblical authors are, for Theodoret, {{merely the}} {{mouthpieces}} of the Holy Spirit, {{though they do}} not lose their individual peculiarities. By the <b>unavoidable</b> <b>imperfection</b> of the translations, he states, the understanding is encumbered. Not familiar with Hebrew, Theodoret uses the Syriac translation, the Greek versions, and the Septuagint.|$|E
40|$|International audienceThis {{monograph}} {{shows the}} reader {{how to avoid}} the burdens of sensor cost, reduced internal physical space, and system complexity in the control of AC motors. Many applications fields—electric vehicles, wind- and wave-energy converters and robotics, among them—will benefit. Sensorless AC Electric Motor Control describes the elimination of physical sensors and their replacement with observers, i. e., software sensors. Robustness is introduced to overcome {{problems associated with the}} <b>unavoidable</b> <b>imperfection</b> of knowledge of machine parameters—resistance, inertia, and so on—encountered in real systems. The details {{of a large number of}} speed- and/or position-sensorless ideas for different types of permanent-magnet synchronous motors and induction motors are presented along with several novel observer designs for electrical machines. Control strategies are developed using high-order, sliding-mode and quasi-continuous-sliding-mode techniques and two types of observer–controller schemes based on backstepping and sliding-mode techniques are described. Experimental results validate the performance of these observer and controller configurations with test trajectories of significance in difficult sensorless-AC-machine problems. Control engineers working with AC motors in a variety of industrial environments will find the space-and-cost-saving ideas detailed in Sensorless AC Electric Motor Control of much interest. Academic researchers and graduate students from electrical, mechanical and control-engineering backgrounds will be able to see how advanced theoretical control can be applied in meaningful real systems...|$|E
40|$|We {{present a}} {{feasibility}} {{study of a}} novel technique for continuously phase-matched second-harmonic generation in proton-exchanged lithium niobate waveguides. We demonstrate that a periodic variation of the nonlinear coefficient along the transverse direction {{with respect to the}} propagation one permits for efficient conversions. Comparison with the conventional first-order quasi-phase-matching interactions are then presented in front of <b>unavoidable</b> <b>imperfections</b> of real devices whenever Czochralski off-center technique is exploited in the fabrication process...|$|R
40|$|The natural {{notion of}} almost perfect state {{transfer}} (APST) is examined. It {{is applied to}} the modelling of efficient quantum wires with the help of $XX$ spin chains. It is shown that APST occurs in mirror-symmetric systems, when the 1 -excitation energies of the chains are linearly independent over rational numbers. This result is obtained as a corollary of the Kronecker theorem in Diophantine approximation. APST happens under much less restrictive conditions than perfect state transfer (PST) and moreover accommodates the <b>unavoidable</b> <b>imperfections.</b> Some examples are discussed. Comment: 11 page...|$|R
40|$|We {{show that}} tri-layer {{structures}} combining epsilon-negative and magneto-optical material layers can exhibit unidirectional resonant photon tunneling phenomena that can discriminate between circularly-polarized (CP) waves of given handedness impinging from opposite directions, or between CP waves with different handedness impinging {{from the same}} direction. This physical principle, which can also be interpreted {{in terms of a}} Fabry-Perot-type resonance, may be utilized to design compact optical isolators for CP waves. Within this framework, we derive simple analytical conditions and design formulae, and quantitatively assess the isolation performance, also taking into account the <b>unavoidable</b> <b>imperfections</b> and nonidealities. Comment: 9 pages, 9 figures (minor revisions in the text and figures...|$|R
40|$|The {{performance}} {{reach of}} the LHC depends on the magnitude of beam losses and the achievable cleaning efficiency of its collimation system. The ideal performance reach for the nominal Phase 1 collimation system is reviewed. However, <b>unavoidable</b> <b>imperfections</b> affect any accelerator and can further deteriorate the collimation performance. Multiple static machine and collimator imperfections {{were included in the}} LHC tracking simulations. Error models for collimator jaw flatness, collimator setup accuracy, the LHC orbit and the LHC aperture were set up, based to the maximum extent possible on measurements and results of experimental beam tests. It is shown that combined “realistic” imperfections can reduce the LHC cleaning efficiency by about a factor 11 on average...|$|R
40|$|The {{impact of}} future quantum {{networks}} hinges on high-quality quantum entanglement shared between network nodes. <b>Unavoidable</b> <b>imperfections</b> necessitate {{a means to}} improve remote entanglement by local quantum operations. We realize entanglement distillation on a quantum network primitive of distant electron-nuclear two-qubit nodes. The heralded generation of two copies of a remote entangled state is demonstrated through single-photon-mediated entangling of the electrons and robust storage in the nuclear spins. After applying local two-qubit gates, single-shot measurements herald the distillation of an entangled state with increased fidelity that is available for further use. The key combination of generating, storing, and processing entangled states should enable the exploration of multiparticle entanglement on an extended quantum network...|$|R
40|$|The main linacs for the {{proposed}} Next Linear Collider (NLC) provide acceleration of up to 500 GeV per beam. The linacs operate in a regime where <b>unavoidable</b> <b>imperfections</b> and even natural ground motion cause significant emittance dilutions. In order to achieve the NLC luminosity goals, small emittance beams must be transported with an emittance growth of less than about 175 % for the 1 TeV center-of-mass version of the NLC. In this paper the authors discuss the operation and the expected performance of the NLC main linacs. Under {{the assumption that the}} specified device tolerances are met, it is shown from detailed simulations that the linac emittance transport fulfills the NLC requirements...|$|R
60|$|Literally and mathematically invariable it is not, {{and could}} not be {{expected}} to be: because the period of a year is too short to include all the possible combinations of partial causes, while it is, at the same time, sufficiently long to make it probable that in some years at least, of every series, there will have been introduced new influences of a more or less general character; such as a more vigorous or a more relaxed police; some temporary excitement from political or religious causes; or some incident generally notorious, of a nature to act morbidly on the imagination. That in spite of these <b>unavoidable</b> <b>imperfections</b> in the data, there should be so very trifling a margin of variation in the annual results, is a brilliant continuation of the general theory.|$|R
40|$|We {{provide an}} {{analysis}} of basic quantum information processing protocols under the effect of intrinsic non-idealities in cluster states. These non-idealities {{are based on the}} introduction of randomness in the entangling steps that create the cluster state and are motivated by the <b>unavoidable</b> <b>imperfections</b> faced in creating entanglement using condensed-matter systems. Aided by the use of an alternative and very efficient method to construct cluster state configurations, which relies on the concatenation of fundamental cluster structures, we address quantum state transfer and various fundamental gate simulations through noisy cluster states. We find that a winning strategy to limit the effects of noise, is the management of small clusters processed via just a few measurements. Our study also reinforces recent ideas related to the optical implementation of a one-way quantum computer. Comment: 13 pages, 13 figures, RevTe...|$|R
40|$|Of {{interest}} {{here is the}} influence of imperfections on the stability of elastic systems, discrete or continuous, with nearly simultaneous modes. The majority of such structures show an extreme sensitivity of their first instability load {{to the shape of}} these small amplitude but <b>unavoidable</b> <b>imperfections.</b> The determination of the worst such possible shape is thus a very important issue from the design standpoint. Following a general analysis of the stability of arbitrary elastic systems with nearly simultaneous bifurcation eigenmodes in the presence of imperfections, conditions are given for the determination of the worst imperfection shape which minimizes the first local load maximum. For the case of coincident eigenmodes the answer to the worst shape problem is considerably simplified, for it is determined from the equilibrium branch of the perfect structure on which the load drops more rapidly...|$|R
40|$|The {{maximum beam}} {{particle}} intensity and minimum emittance {{that can be}} injected, accelerated and stored in high-brightness lepton as well as high-energy hadron accelerators is fundamentally limited by self-amplifying beam instabilities, intrinsic to <b>unavoidable</b> <b>imperfections</b> in accelerators. Traditionally, intra-bunch or head-tail particle motion has been measured using fast digitizers, with even using state-of-the-art technology being limited in their effective intra-bunch position resolution to few tens of um in the multi-GHz regime. To improve on the present signal processing, a multiband-instability-monitor (MIM) prototype system has been designed, constructed and tested at the CERN Super- Proton-Synchrotron (SPS) and Large Hadron Collider (LHC). The system splits the signal into multiple equallyspaced narrowfrequency bands that are processed and analysed in parallel. Working with narrow-band signals permits the use of much higher resolution analogue-to-digitalconverters {{that can be used}} to resolve nm-scale particlemotion already during the onset of instabilities...|$|R
30|$|Eccentrically loaded {{reinforced}} concrete columns are commonly exist in practice {{due to the}} existence of some bending moments. The eccentricity of the supported beams as well as the <b>unavoidable</b> <b>imperfections</b> of construction are the main sources of the developed bending moments in the columns under gravity loads. In addition, lateral loads due to wind or earthquake loading are another source of the developed bending moments on the columns. Therefore, the strength of the columns is controlled by the compressive strength of concrete, the tensile strength of the longitudinal reinforcements and the geometry of the column’ cross-section (Park and Paulay 1975; Nilson 2004; McCormac 1998; Yalcin and Saatcioglu 2000; MacGregor and Wight 2009). Contrasting to {{reinforced concrete}} beams, the compression failure cannot be avoided for eccentrically loaded columns since the type of failure is mainly dependent on the axial load level (Park and Paulay 1975).|$|R
40|$|Precision is {{a virtue}} {{throughout}} science in general and in optics in particular where carefully fabricated nanometer-scale devices hold great promise for both classical and quantum photonics [1 - 6]. In such nanostructures, <b>unavoidable</b> <b>imperfections</b> often impose severe performance limits but, in certain cases, disorder may enable new functionalities [7]. Here we demonstrate on-chip random nanolasers where the cavity feedback {{is provided by the}} intrinsic disorder in a semiconductor photonic-crystal waveguide, leading to Anderson localization of light [8]. This enables highly efficient and broadband tunable lasers with very small mode volumes. We observe an intriguing interplay between gain, dispersion-controlled slow light, and disorder, which determines the cross-over from ballistic transport to Anderson localization. Such a behavior is a unique feature of non-conservative random media that enables the demonstration of all-optical control of random lasing. Our statistical analysis shows a way towards ultimate thresholdless random nanolasers...|$|R
40|$|Quantum {{information}} degrades over distance {{due to the}} <b>unavoidable</b> <b>imperfections</b> of the trans- mission channels, {{with loss}} as the leading factor. This simple fact hampers quantum communication technologies, as they rely on propagating quantum systems. A solution to this issue is to introduce quantum repeaters at regular intervals along a lossy channel, to revive the quantum signal. In this work we study the concept of unitary one-way quantum repeaters that do not need measurements and do not require quantum memories, and are therefore considerably simpler than other schemes. We introduce and analyze two methods to construct hamiltonians that generate a repeater interaction that can beat the fundamental repeaterless key rate bound even {{in the presence of}} an additional coupling loss, with signals that contain only a handful of photons. The natural evolution of this work will be to approximate a repeater interaction by combining simple optical elements. Comment: 5 pages, 3 figure...|$|R
40|$|The {{application}} of a second-order plastic-zone formulation to study the minimum requirements needed {{to arrive at the}} so called advanced analysis concept, where an individual member’s check is simplified or even unnecessary, is presented in this paper. A companion paper provides the theoretical background for this formulation. These requirements appear in specifications and refer to the <b>unavoidable</b> <b>imperfections</b> of steel structure construction leading to premature collapse. The structure’s out-of-plumbness and members’ out-of-straightness form the initial geometric imperfections, affecting building stability and lateral drift, but are justifiable under manufacturing and erection tolerances. Unequal cooling of a steel section, after the rolling or welding process, creates residual stress that increases the plasticity path. As the plastic zone analysis accounts for these three imperfections in an explicit way, alone or combined, this study shows a brief review, computational implementation details and numerical examples. Finally, this work makes some recommendations to find the worst initial imperfect geometry for some loading cases...|$|R
6000|$|In this we {{hear the}} voice of the new time, as we do in his exclamation that the {{perfection}} of an Encyclopædia is the work of centuries; centuries had to elapse before the foundations could be laid; centuries would have to elapse before its completion: [...] "mais à la posérité, et À L'ÊTRE QUI NE MEURT POINT!"[127] These exalted ideas were not a substitute for arduous labour. In all that Diderot writes upon his magnificent undertaking, we are struck by his singular union of common sense with elevation, of simplicity with grasp, of suppleness with strength, of modesty with hopeful confidence. On occasions that would have tempted a man of less sincerity and less seriousness to bombast and inflation, his sense of the <b>unavoidable</b> <b>imperfections</b> of so vast a work always makes itself felt through his pride in its lofty aim and beneficent design. The weight of the burden steadied him, and the anxiety of the honest and laborious craftsman mastered the impulses of rhetoric.|$|R
40|$|The {{main results}} {{obtained}} by an extended test on the fatigue behaviour generated {{by changes in}} the relative distance of the plate elements of the lamella flanges of the Lochkov Bridge, which occur under the passages of heavy vehicles are presented. The plate elements exhibit <b>unavoidable</b> out-of-plane <b>imperfections,</b> which results in them not being in perfect contact. The lamellas are then subjected to many times repeated bending, which generates cumulative damage in the welds that connect the two lamellas...|$|R
40|$|In {{order to}} {{compensate}} for the scarcity of events at very high energy the LHC has to provide a luminosity of 1034 cm- 2 s- 1. This is obtained with a large beam current distributed over 2835 particle bunches, and a large transverse bunch density so as to operate close to the beam-beam limit. The beam-beam interaction has two components, the head-on interaction as in previous colliders with few bunches and the long range interaction due to multiple unwanted crossings. This last effect is controlled by letting the beams collide at a small angle. The single bunch and multibunch collective instabilities are kept under control by a proper design of the beam enclosure and by feedback systems. The <b>unavoidable</b> <b>imperfections</b> of the high field superconducting magnets create non-linear field errors which limit the useful range of particle betatron amplitudes where the motion is stable, the so-called Dynamic Aperture. An extended set of corrector magnets is foreseen {{to compensate for}} the effects of the strongest multipoles of low order. The machine lattice is designed with the aim of leaving sufficient freedom in the choice of the operating conditions to optimize performance...|$|R
30|$|Omnidirectional {{wheels are}} used in mobile robots doing {{material}} handling tasks and other industrial applications, though mobile robots with omnidirectional wheels are controllable with reduced number of actuators and are highly manoeuvrable in narrow or crowded spaces. Accuracy of motion is influenced by systematic errors caused by <b>unavoidable</b> <b>imperfections</b> in the control and mechanical subsystems and nonsystematic caused by unpredictable phenomena such as wheel slippage and surface irregularities. Calibration {{will be needed to}} compensate for those errors due to the use of omnidirectional wheels. Other odometry errors, while the robot movement, may also exist due to unequal wheels diameters, joints misalignment, backlash and slippage in encoder pulses [24]. Omnidirectional vehicles are widely used in mobile robots for materials handling vehicles for logistics and wheelchairs. However, they are generally designed for the case of motion on flat, smooth terrain and are not feasible for outdoor usage [17]. Slippage is there when omnidirectional wheels are in motion and manufacturing of those wheels is an expensive and needs high accuracy. Furthermore, there is a poor efficiency because not all the wheels are rotating in the direction of movement, which causes loss from friction, and are more computationally complex because of the angle calculations of movement [25].|$|R
40|$|Most {{emission}} spectra {{are characterized}} by lines of various intensities, a feature making them difficult to probe in their entirety - the limited dynamic range of the detector prohibits the simultaneous observation of both weak and intense spectral features. A further known complication in spectroscopy concerns the generation and detection of stray light, which is an undesired contribution of light, often associated with <b>unavoidable</b> <b>imperfections</b> in the spectrometer. Stray light leads to an offset that often exceeds the intensity of weak lines, especially those that were barely detectable {{in the absence of}} stray light. This problem is well-known in, for example, laser-induced Raman spectroscopic measurements. In this paper, we describe a methodology to solve both the stray light problem and that associated with the limited dynamic range of the detector. The method is based on combining the high dynamic range imaging concept commonly employed in digital photography with the periodic shadowing technique, where the former is used to boost the dynamics and the latter to suppress stray light. The capabilities of the approach, which is suitable for investigation of temporally stable sources, are demonstrated and the results are compared with measurements performed with both conventional equipment and the periodic shadowing technique...|$|R
40|$|Atom chips provide {{compact and}} robust {{platforms}} towards practical quantum technologies. A quick and faithful preparation of arbitrary input states for these systems is crucial but represents a very challenging experimental task. This is especially difficult when the dynamical evolution is noisy and <b>unavoidable</b> setup <b>imperfections</b> {{have to be}} considered. Here, we experimentally prepare with very high small errors different internal states of a Rubidium Bose-Einstein condensate realized on an atom chip. As a possible application of our scheme, we apply it to improve the sensitivity of an atomic interferometer. Comment: 6 pages, 6 figure...|$|R
40|$|Ensembles {{of quantum}} {{mechanical}} spins offer a promising platform for quantum memories, but proper functionality requires accurate control of <b>unavoidable</b> system <b>imperfections.</b> We present an efficient control scheme {{for a spin}} ensemble strongly coupled to a single-mode cavity based {{on a set of}} Volterra equations relying solely on weak classical control pulses. The viability of our approach is demonstrated in terms of explicit storage and readout sequences that will serve as a starting point towards the realization of more demanding full quantum mechanical optimal control schemes. Comment: 10 pagers, 5 figure...|$|R
40|$|M. Ing. This {{dissertation}} {{stresses the}} need and value of adding an Artificial Intelligence level between manufacturing units and First Principle Models that supply processing set points. The value is proven by evaluating the effect of designing and implementing a supervisory expert system for hot rolling process optimisation at Columbus Stainless Ltd. Pty. The hot rolling mill’s mainly fuzzy logic artificial intelligence “Expert System” functions as an extra diagnostic and control system that manages {{the performance of the}} processing set point models. The Expert System was developed in order to effectively imitate what the human experts used to do – which was to virtually continuously optimise the rolling process by making database data changes. The human experts had to make these process adjustments in order to compensate for the <b>unavoidable</b> <b>imperfections</b> and shortcomings of First Principle Models, which are unable to perfectly model nature. Even though the Expert System addresses a vast amount of hot rolling product quality and throughput control aspects, it still sufficiently automates human expert control to successfully manage production performance in all areas of control. This document was written in a format that would comply with Masters Degree Dissertation standards, while providing a document that can easily be used by Columbus Stainless personnel as a reference book of the philosophies, strategies and design of the Expert System...|$|R
40|$|Modeling the {{response}} of laminated composite structures to mechanical and environmental loadings is complicated, even in the elastic phase, by the multilayered material architecture {{and the presence of}} <b>unavoidable</b> <b>imperfections</b> and flaws at the layer interfaces; stress and displacement fields exhibit complex zig-zag through-thickness distributions and discontinuities. When damage begins, localized propagation of delamination cracks, which may lead to catastrophic failures, exacerbates the difficulties. The problem cannot be solved using equivalent single-layer theories or continuum damage models, and is typically tackled through discrete-layer cohesive-crack approaches and computationally expensive numerical solutions. A novel multiscale model is presented in this chapter for plates with arbitrary layups and numbers of layers and delaminations subjected to mechanical and environmental loadings. The model derives homogenized dynamic equilibrium equations which depend on a number of variables equal to that of equivalent single-layer theories, allows efficient and accurate closed form solution of problems that would otherwise necessitate a numerical treatment and sets up the bases for a more efficient numerical solution of complex problems. Explicit expressions are presented for stresses and displacements in thick and highly anisotropic wide plates with continuous imperfect interfaces and delaminations subjected to steady-state thermo-mechanical loading. Closed form solutions of the dynamic problem in simply supported wide plates highlight the important effects of the interfacial imperfections on natural frequencies and modes of vibration and frequency gaps...|$|R
40|$|This {{dissertation}} {{stresses the}} need and value of adding an Artificial Intelligence level between manufacturing units and First Principle Models that supply processing set points. The value is proven by evaluating the effect of designing and implementing a supervisory expert system for hot rolling process optimisation at Columbus Stainless Ltd. Pty. The hot rolling mill’s mainly fuzzy logic artificial intelligence “Expert System ” functions as an extra diagnostic and control system that manages {{the performance of the}} processing set point models. The Expert System was developed in order to effectively imitate what the human experts used to do – which was to virtually continuously optimise the rolling process by making database data changes. The human experts had to make these process adjustments in order to compensate for the <b>unavoidable</b> <b>imperfections</b> and shortcomings of First Principle Models, which are unable to perfectly model nature. Even though the Expert System addresses a vast amount of hot rolling product quality and throughput control aspects, it still sufficiently automates human expert control to successfully manage production performance in all areas of control. This document was written in a format that would comply with Masters Degree Dissertation standards, while providing a document that can easily be used by Columbus Stainless personnel as a reference book of the philosophies, strategies and design of the Expert System...|$|R
40|$|The FEL {{parameter}} optimization {{and performance}} characterizations that {{are described in}} Chapter 5 are based on three-dimensional theory and computer models. The investigation led to a selection of the best parameters and to {{a study of the}} sensitivity to changes in values of accelerator components and beam characteristics and to <b>unavoidable</b> <b>imperfections</b> in the settings of the beam characteristics, magnetic and mechanical components and electron beam monitoring. The focusing of the electron beam {{plays an important role in}} the production of the FEL radiation. The LCLS undulator optics has been optimized in terms of its focusing lattice and strength. The electron optics consists of FODO cells; with cell lengths between 7. 3 m and 7. 5 m. Focusing is obtained by placing permanent magnet quadrupoles in the breaks between the undulator sections. The correction of the electron orbit is obtained by a small lateral displacement of the quadrupoles. Simulations indicate that the FEL radiation saturates at a length of ~ 90 m. The proposed LCLS undulator has a magnetic length of 121 m, since it is a requirement that the FEL operate in the saturation regime. This fact not only gives the maximum output power, but also reduces the pulse-to-pulse fluctuations of the radiation. Complete simulations of the LCLS, starting from the photocathode, and continuing throug...|$|R
40|$|The {{threshold}} {{properties of}} photonic crystal quantum dot lasers {{operating in the}} slow-light regime are investigated experimentally and theoretically. Measurements show that, in contrast to conventional lasers, the threshold gain attains a minimum value for a specific cavity length. The experimental results are explained by an analytical theory for the laser threshold {{that takes into account}} the effects of slow-light and random disorder due to <b>unavoidable</b> fabrication <b>imperfections.</b> Longer lasers are found to operate deeper into the slow-light region, leading to a trade-off between slow-light induced reduction of the mirror loss and slow-light enhancement of disorder-induced losses. Comment: 5 pages, 7 figure...|$|R
40|$|Thesis (Ph. D.) [...] Wichita State University, College of Liberal Arts and Sciences, Dept. of ChemistryAn antiplasticizer is any {{chemical}} that when added, reduces the free volume of a polymer thereby restricting the polymeric chain motions. This type of additive usually increases the modulus and strength but can compromise other important properties such as {{glass transition temperature}} and thermal degradation profile. Oligomeric amide additives, which when mixed with TGDDM and DDS, react to form strong hydrogen bonds and reduce the free volume in the system, were synthesized. The nonaromatic additives, especially those that have shorter methylene sequences, had low solubility in the resin, while the mixed amide oligomer additive have better solubility. The effect of these additives to enhance mechanical properties was tested by tensile testing and fracture toughness measurement. Compact tension {{results indicated that the}} additives improved the resins’ resistance to crack propagation. In general, when the additive is shorter and additive loading is lower, the material performs better. No general conclusion can be arrived at from the tensile testing due to the variablility of results caused by <b>unavoidable</b> <b>imperfections</b> incurred during specimen preparation. The cure kinetics of the resin was studied using Differential Scanning Calorimetry. Dynamic temperature scanning DSC indicated that the cure reaction was not affected significantly by these additives. However, an increase in activation energy was observed. TMA experiments on resins with nonaromatic additives indicated that the additives slightly increased the softening temperature while DMA experiments on resins with mixed amide oligomers show that the additives slightly increase the glass transition temperature. TGA experiments on resins with mixed amide oligomers indicated that the additives did not introduce significant changes in thermal stability...|$|R
60|$|And even (it will be added) if the {{consequences}} of misconduct could be confined to the vicious or thoughtless individual, ought society to abandon to their own guidance those who are manifestly unfit for it? If protection against themselves is confessedly due to children and persons under age, is not society equally bound to afford it to persons of mature years who are equally incapable of self-government? If gambling, or drunkenness, or incontinence, or idleness, or uncleanliness, are as injurious to happiness, and as great a hindrance to improvement, as many {{or most of the}} acts prohibited by law, why (it may be asked) should not law, so far as is consistent with practicability and social convenience, endeavour to repress these also? And as a supplement to the <b>unavoidable</b> <b>imperfections</b> of law, ought not opinion at least to organise a powerful police against these vices, and visit rigidly with social penalties those who are known to practise them? There is no question here (it may be said) about restricting individuality, or impeding the trial of new and original experiments in living. The only things it is sought to prevent are things which have been tried and condemned {{from the beginning of the}} world until now; things which experience has shown not to be useful or suitable to any person's individuality. There must be some length of time and amount of experience, after which a moral or prudential truth may be regarded as established: and it is merely desired to prevent generation after generation from falling over the same precipice which has been fatal to their predecessors.|$|R
40|$|Nanophotonics {{focuses on}} the control of light and the {{interaction}} with matter by the aid of intricate nanostructures. Typically, a photonic nanostructure is carefully designed for a specific application and any imperfections may reduce its performance, i. e., a thorough investigation {{of the role of}} <b>unavoidable</b> fabrication <b>imperfections</b> is essential for any application. However, another approach to nanophotonic applications exists where fabrication disorder is used to induce functionalities by enhancing light-matter interaction. Disorder leads to multiple scattering of light, which is the realm of statistical optics where light propagation requires a statistical description. We review here the recent progress on disordered photonic nanostructures and the potential implications for quantum photonics devices. Comment: Review accepted for publication in Annalen der Physi...|$|R
40|$|Thesis (M. S.) [...] Wichita State University, College of Liberal Arts and Sciences, Dept. of ChemistryAdditives {{that enhance}} the {{mechanical}} properties of epoxy resins, {{by reducing the}} free volume and thereby restricting the molecular motions, are known as antiplasticizers. Antiplasticizers usually increase the modulus and strength but can decrease the glass transition temperature of the material. A series of oligomeric amide additives were synthesised, that would, when mixed with TGDDM and DDS, react to form strong hydrogen bonds and reduce the free volume in the system. The effect of end group functionality was tested by synthesising both amine terminated and acid terminated additives. The ability of these additives to enhance the mechanical properties of the cured resin was examined by conducting fracture toughness and tensile testing. Results obtained for compact tension specimens and tensile testing specimens were inconclusive due to <b>unavoidable</b> <b>imperfections</b> incurred during specimen preparation. The cure kinetics of the resin was studied using Differential Scanning Calorimetry or DSC. Dynamic temperature scanning DSC indicated that the cure reaction was not affected significantly by these additives. At higher heating rates, as expected, the degree of cure and rate of cure shifted to higher temperatures. Arrhenius type activation energy calculations showed that incorporating amine terminated additive did not significantly increase the activation energy of cure (Ea). However, {{a significant increase in}} Ea was observed when the resin was cured with acid terminated additive. DMA and TMA data indicated that the glass transition temperature of the matrix did not show a significant reduction upon addition of the additives to the resin. Thermal degradation of the resin was studied using Thermo Gravimetric Analysis or TGA. Results indicated that the presence of an additive does not affect the thermal stability of the resin...|$|R
40|$|The {{potential}} impact of future quantum networks hinges on high-quality quantum entanglement shared between network nodes. <b>Unavoidable</b> real-world <b>imperfections</b> necessitate means to improve remote entanglement by local quantum operations. Here we realize entanglement distillation on a quantum network primitive of distant electron-nuclear two-qubit nodes. We demonstrate the heralded generation of two copies of a remote entangled state through single-photon-mediated entangling of the electrons and robust storage in the nuclear spins. After applying local two-qubit gates, single-shot measurements herald the distillation of an entangled state with increased fidelity that is available for further use. In addition, this distillation protocol significantly speeds up entanglement generation compared to previous two-photon-mediated schemes. The key combination of generating, storing and processing entangled states demonstrated here {{opens the door to}} exploring and utilizing multi-particle entanglement on an extended quantum network...|$|R
40|$|The Rapid Cycling Synchrotron of the Beta-Beam {{facility}} {{has been designed}} to operatewith horizontal and vertical tunes between 6 and 7 in order to avoid systematicresonances up to the fourth order. Nevertheless, <b>unavoidable</b> magnet <b>imperfections</b> mayexcite non systematic second order resonances which may pertub particle motion. In this paper an Hamiltonian treatment based on a well established formalism [1 - 3] is used to analyze the resonance excitation and to suggest correction schemes minimizing their effects. [1] A. Schoch. Theory of linear and non linear perturbations of betatron oscillations inalternating gradient synchrotrons. CERN 52 - 21, 1958. [2] G. Guignard. A general treatment of resonances in accelerators. CERN 78 - 11, 1978. [3] J-L. Laclare, G. Leleux, and A. Tkatchenko. Resonnances quadrupolaires- aleatoiresquadrupolaires et corrections. DSS-GERS- 74 - 91 /TP- 06, 1974...|$|R
40|$|The {{development}} of nanoscale optical devices for classical and quantum photonics 1 – 5 {{is affected by}} <b>unavoidable</b> fabrication <b>imperfections</b> that often impose performance limitations. However, disorder may also enable new functionalities 6, for example in random lasers, where lasing relies on random multiple scattering 7 – 13. The applicability of random lasers has been limited due to multidirectional emission, lack of tunability, and strong mode competition 11 with chaotic fluctuations 14 due to a weak mode confinement. The regime of Anderson localization of light 15 has been proposed for obtaining stable multimode random lasing 16, and initial work concerned macro-scopic one-dimensional layered media 17. Here, we demonstrate on-chip random nanolasers where the cavity feedback is pro-vided by the intrinsic disorder. The strong confinement achieved by Anderson localization reduces the spatial overla...|$|R
