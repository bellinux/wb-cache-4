330|432|Public
25|$|The <b>unbiased</b> <b>sample</b> {{variance}} is a U-statistic for {{the function}} ƒ(y1,y2) =(y1−y2)2/2, {{meaning that it}} is obtained by averaging a 2-sample statistic over 2-element subsets of the population.|$|E
25|$|Consider now a {{function}} of the unknown parameter: an estimator is a statistic used to estimate such function. Commonly used estimators include sample mean, <b>unbiased</b> <b>sample</b> variance and sample covariance.|$|E
25|$|Firstly, if the omniscient mean {{is unknown}} (and is {{computed}} as the sample mean), then the sample variance is a biased estimator: it underestimates the variance {{by a factor}} of (n−1) / n; correcting by this factor (dividing by n−1 instead of n) is called Bessel's correction. The resulting estimator is unbiased, and is called the (corrected) sample variance or <b>unbiased</b> <b>sample</b> variance. For example, when n=1 the variance of a single observation about the sample mean (itself) is obviously zero regardless of the population variance. If the mean is determined in some other way than from the same samples used to estimate the variance then this bias does not arise and the variance can safely be estimated as that of the samples about the (independently known) mean.|$|E
40|$|Abstract — <b>Unbiased</b> <b>sampling</b> {{of online}} social {{networks}} (OSNs) {{makes it possible}} to get accurate statistical properties of large-scale OSNs. However, the most used sampling methods, Breadth-First-Search (BFS) and Greedy, are known to be biased towards high-degree nodes, yielding inaccurate statistical results. To give a general requirement for <b>unbiased</b> <b>sampling,</b> we model the crawling process as a Markov Chain and deduce a necessary and sufficient condition, which enables us to design various efficient <b>unbiased</b> <b>sampling</b> methods. To the best of our knowledge, we are among the first to give such a condition. Metropolis-Hastings Random Walk (MHRW) is an example which satisfies the condition. However, walkers in MHRW may stay at some low-degree nodes for a long time, resulting considerable self-loops on these nodes, which adversely affect the crawling efficiency. Based on the condition, a new <b>unbiased</b> <b>sampling</b> method, called USRS, is proposed to reduce the probabilities of self-loops. We use the dataset of Renren, the largest OSN in China, to evaluate the performance of USRS. The results have demonstrated that USRS generates <b>unbiased</b> <b>samples</b> with low self-loop probabilities, and achieves higher crawling efficiency. I...|$|R
40|$|In this paper, {{we present}} a new {{technique}} to generate <b>unbiased</b> <b>samples</b> on isosurfaces. An isosurface, F(x,y,z) = c, of a function, F, is implicitly defined by trilinear interpolation of background grid points. The key idea of our approach is that of treating the isosurface within a grid cell as a graph (height) function {{in one of the}} three coordinate axis directions, restricted to where the slope is not too high, and integrating / sampling from each of these three. We use this <b>unbiased</b> <b>sampling</b> algorithm for applications in Monte Carlo integration, Poisson-disk sampling, and isosurface meshing...|$|R
40|$|Ensemble of {{classifiers}} {{combines the}} more than one prediction models of classifiers into single model for classifying the new instances. <b>Unbiased</b> <b>samples</b> could help the ensemble classifiers to build the efficient prediction model. Existing sampling techniques fails to give the <b>unbiased</b> <b>samples.</b> To overcome this problem, the paper introduces a k-modes random sample technique which combines the k-modes cluster algorithm and simple random sampling technique to take the sample from the dataset. In this paper, the impact of random sampling technique in the Ensemble learning algorithm is shown. Random selection was done properly by using k-modes random sampling technique. Hence, sample will reflect the characteristics of entire dataset...|$|R
2500|$|An {{unbiased}} estimator for the variance {{is given by}} applying Bessel's correction, using N−1 instead of N to yield the <b>unbiased</b> <b>sample</b> variance, denoted s2: ...|$|E
2500|$|Hence [...] {{gives an}} {{estimate}} of the population variance that is biased by a factor of [...] For this reason, [...] {{is referred to as the}} biased sample variance. Correcting for this bias yields the <b>unbiased</b> <b>sample</b> variance: ...|$|E
5000|$|... s2 is the <b>unbiased</b> <b>sample</b> {{variance}} (i.e. with Bessel's correction) ...|$|E
5000|$|For initial {{states of}} {{physical}} interest, the coefficients [...] exhibit large fluctuations from eigenstate to eigenstate, {{in a fashion}} which is completely uncorrelated with the fluctuations of [...] from eigenstate to eigenstate. Because the coefficients and matrix elements are uncorrelated, the summation in the diagonal ensemble is effectively performing an <b>unbiased</b> <b>sampling</b> {{of the values of}} [...] over the appropriate energy window. For a sufficiently large system, this <b>unbiased</b> <b>sampling</b> should result in a value which is close to the true mean of the values of [...] over this window, and will effectively reproduce the prediction of the microcanonical ensemble. However, this mechanism may be disfavored for the following heuristic reason. Typically, one is interested in physical situations in which the initial expectation value of [...] is far from its equilibrium value. For this to be true, the initial state must contain some sort of specific information about , and so it becomes suspect whether or not the initial state truly represents an <b>unbiased</b> <b>sampling</b> of the values of [...] over the appropriate energy window. Furthermore, whether or not this were to be true, it still does not provide an {{answer to the question of}} when arbitrary initial states will come to equilibrium, if they ever do.|$|R
40|$|Recent work on <b>unbiased</b> <b>sampling</b> of OSNs {{has focused}} on {{estimation}} of degree distributions and clustering coefficients. In this work we shift the focus to node attributes. We show that existing sampling methods produce biased outputs and need modifications to alleviate the bias. Categories and Subject Descriptor...|$|R
5000|$|Observations of {{the faintest}} objects {{will provide a}} more {{complete}} view of the stellar luminosity function. Gaia will observe 1 billion stars and other bodies, representing 1% of such bodies in the Milky Way galaxy. All objects {{up to a certain}} magnitude must be measured in order to have <b>unbiased</b> <b>samples.</b>|$|R
5000|$|For the sequel, use {{the sample}} mean:and the (<b>unbiased)</b> <b>sample</b> variance: ...|$|E
50|$|The {{degrees of}} freedom of the weighted, <b>unbiased</b> <b>sample</b> {{variance}} vary accordingly from N &minus; 1 down to 0.|$|E
5000|$|This is {{unbiased}} (its {{expected value}} is [...] ), hence {{also called the}} <b>unbiased</b> <b>sample</b> variance, and its MSE is ...|$|E
40|$|<b>Unbiased</b> <b>samples</b> {{of ground}} states were {{generated}} for the short-range Ising spin glass with Jij=+/- 1, in three dimensions. Clustering {{the ground states}} revealed their hierarchical structure, which is explained by correlated spin domains, serving as cores for macroscopic zero energy "excitations". Comment: 4 pages, 5 figures, accepted to Phys. Rev. Let...|$|R
40|$|Lorenz {{curves and}} {{associated}} tools for ranking income distributions are commonly estimated {{on the assumption}} that full, <b>unbiased</b> <b>samples</b> are available. However it is common to ¯nd income and wealth distributions that are routinely censored or trimmed. We derive the sampling distribution for a key family of statistics in the case where data have been modified in this fashion...|$|R
30|$|In {{the second}} step, {{we will show}} that with a high probability, at least one {{infected}} node {{at the bottom of}} a one-time-slot infection subtree, which has not terminated, is observed under an <b>unbiased</b> <b>sampling</b> algorithm. In Figure 3, nodes d and f are two sampled nodes corresponding to the two one-time-slot infection subtrees starting from nodes b and c, respectively.|$|R
5000|$|The {{classifier}} {{created from}} the training set using a Gaussian distribution assumption would be (given variances are <b>unbiased</b> <b>sample</b> variances): ...|$|E
50|$|This {{effectively}} {{proves the}} use of the divisor n &minus; 1 in the calculation of an <b>unbiased</b> <b>sample</b> estimate of &sigma;2.|$|E
5000|$|For {{a normal}} {{distribution}} with unknown mean and variance, the sample mean and (<b>unbiased)</b> <b>sample</b> variance are the MVUEs {{for the population}} mean and population variance.|$|E
40|$|We {{present a}} Bayesian {{reconstruction}} algorithm to generate <b>unbiased</b> <b>samples</b> {{of the underlying}} dark matter field from halo catalogues. Our new contribution consists of implementing a non-Poisson likelihood including a deterministic non-linear and scale-dependent bias. In particular we present the Hamiltonian equations of motions for the negative binomial (NB) probability distribution function. This permits us to efficiently sample the posterior distribution function of density fields given a sample of galaxies using the Hamiltonian Monte Carlo technique implemented in the Argo code. We have tested our algorithm with the Bolshoi N-body simulation at redshift z = 0, inferring the underlying dark matter density field from sub-samples of the halo catalogue with biases smaller and larger than one. Our method shows that we can draw closely <b>unbiased</b> <b>samples</b> (compatible within 1 -σ) from the posterior distribution up to scales of about k 1 h/Mpc in terms of power-spectra and cell-to-cell correlations. We find that a Poisson likelihood yields reconstructions with power spectra deviating more than 10...|$|R
5000|$|How has {{the exact}} ESU been {{algorithm}} modified to RAND-ESU that estimates sub-graph concentrations? The procedure of implementing RAND-ESU is quite straightforward {{and is one}} of the main advantages of FANMOD. One can change the ESU algorithm to explore just a portion of the ESU-Tree leaves by applying a probability value [...] for each level of the ESU-Tree and oblige ESU to traverse each child node of a node in level [...] with probability [...] This new algorithm is called RAND-ESU. Evidently, when [...] for all levels, RAND-ESU acts like ESU. For [...] the algorithm finds nothing. Note that, this procedure ensures that the chances of visiting each leaf of the ESU-Tree are the same, resulting in <b>unbiased</b> <b>sampling</b> of sub-graphs through the network. The probability of visiting each leaf is [...] and this is identical for all of the ESU-Tree leaves; therefore, this method guarantees <b>unbiased</b> <b>sampling</b> of sub-graphs from the network. Nonetheless, determining the value of [...] for [...] is another issue that must be determined manually by an expert to get precise results of sub-graph concentrations. While there is no lucid prescript for this matter, the Wernicke provides some general observations that may help in determining p_d values. In summary, RAND-ESU is a very fast algorithm for NM discovery in the case of induced sub-graphs supporting <b>unbiased</b> <b>sampling</b> method. Although, the main ESU algorithm and so the FANMOD tool is known for discovering induced sub-graphs, there is trivial modification to ESU which makes it possible for finding non-induced sub-graphs, too. The pseudo code of ESU (FANMOD) is shown below: ...|$|R
3000|$|Consider an {{infinite}} tree. Let gmin be the lower bound {{on the number}} of children and qmin> 0 be the lower bound on q. Assume gmin> 1, gminqmin> 1, and the observed infection topology Y contains at least one infected node and is generated by an <b>unbiased</b> <b>sampling</b> algorithm. Then given ε> 0, the distance between the sample path estimator and the actual source is d [...]...|$|R
50|$|Consider now a {{function}} of the unknown parameter: an estimator is a statistic used to estimate such function. Commonly used estimators include sample mean, <b>unbiased</b> <b>sample</b> variance and sample covariance.|$|E
50|$|The <b>unbiased</b> <b>sample</b> {{variance}} is a U-statistic for {{the function}} ƒ(y1, y2) = (y1 − y2)2/2, {{meaning that it}} is obtained by averaging a 2-sample statistic over 2-element subsets of the population.|$|E
50|$|An {{unbiased}} (representative) {{sample is}} a set of objects chosen from a complete sample using a selection process that does not depend on the properties of the objects. For example, an <b>unbiased</b> <b>sample</b> of Australian men taller than 2m might consist of a randomly sampled subset of 1% of Australian males taller than 2m. But one chosen from the electoral register might not be unbiased since, for example, males aged under 18 will not be on the electoral register. In an astronomical context, an <b>unbiased</b> <b>sample</b> might consist of that fraction of a complete sample for which data are available, provided the data availability is not biased by individual source properties.|$|E
40|$|This paper {{presents}} a new approach, called perturb-max, for high-dimensional statistical inference {{that is based}} on applying random perturbations followed by optimization. This framework injects randomness to maximum a-posteriori (MAP) predictors by randomly perturbing the potential function for the input. A classic result from extreme value statistics asserts that perturb-max operations generate <b>unbiased</b> <b>samples</b> from the Gibbs distribution using high-dimensional perturbations. Unfortunately, the computational cost of generating so many high-dimensional random variables can be prohibitive. However, when the perturbations are of low dimension, sampling the perturb-max prediction is as efficient as MAP optimization. This paper shows that the expected value of perturb-max inference with low dimensional perturbations can be used sequentially to generate <b>unbiased</b> <b>samples</b> from the Gibbs distribution. Furthermore the expected value of the maximal perturbations is a natural bound on the entropy of such perturb-max models. A measure concentration result for perturb-max values shows that the deviation of their sampled average from its expectation decays exponentially in the number of samples, allowing effective approximation of the expectation. Comment: 47 pages, 10 figures, under revie...|$|R
30|$|We used three {{different}} clinically relevant murine models of focal injury, namely, controlled cortical impact brain injury (traumatic brain injury (TBI)) and transient and permanent occlusion of middle cerebral artery (tMCAo and pMCAo, respectively). Twenty-four hours after injury, M/M cells were labeled by CD 11 b, and × 40 photomicrographs were acquired by <b>unbiased</b> <b>sampling</b> of the lesion core using a motorized stage microscope. Images were processed with Fiji software to obtain shape descriptors.|$|R
50|$|On {{the other}} hand, people may {{consider}} that statistics are inherently unreliable because not everybody is called, {{or because they}} themselves are never polled. People may {{think that it is}} impossible to get data on the opinion of dozens of millions of people by just polling a few thousands. This is also inaccurate. A poll with perfect <b>unbiased</b> <b>sampling</b> and truthful answers has a mathematically determined margin of error, which only depends on the number of people polled.|$|R
5000|$|Hence [...] {{gives an}} {{estimate}} of the population variance that is biased by a factor of [...] For this reason, [...] {{is referred to as the}} biased sample variance. Correcting for this bias yields the <b>unbiased</b> <b>sample</b> variance: ...|$|E
50|$|An {{example of}} a degree-2 V-statistic is the second central moment m2.If h(x, y) = (x &minus; y)2/2, the {{corresponding}} V-statistic is:which is the maximum likelihood estimator of variance. With the same kernel, the corresponding U-statistic is the (<b>unbiased)</b> <b>sample</b> variance::.|$|E
5000|$|... where [...] is {{the sample}} mean and [...] is the <b>unbiased</b> <b>sample</b> variance. Since {{the right hand}} side of the second {{equality}} exactly matches the characterization of a noncentral t-distribution as described above, T has a noncentral t-distribution with n−1 degrees of freedom and noncentrality parameter [...]|$|E
40|$|Objectives To study health inequalities {{in persons}} with {{intellectual}} disabilities, representative and <b>unbiased</b> <b>samples</b> are needed. Little {{is known about}} sample recruitment in this vulnerable group. This study aimed to determine differences in ethical procedures and sample recruitment in a multicenter research on health of persons with intellectual disabilities. Study questions regarded the practical sampling procedure, how ethical consent was obtained in each country, and which person gave informed consent for each study participant. Study Design and Setting Exploratory, {{as part of a}} multicenter study, in 14 European countries. After developing identical guidelines for all countries, partners collected data on health indicators by orally interviewing 1, 269 persons with intellectual disabilities. Subsequently, semistructured interviews were carried out with partners and researchers. Results Identification of sufficient study participants proved feasible. Sampling frames differed from nationally estimated proportions of persons with intellectual disabilities living with families or in residential settings. Sometimes, people with intellectual disabilities were hard to trace. Consent procedures and legal representation varied broadly. Nonresponse data proved unavailable. Conclusion To build representative <b>unbiased</b> <b>samples</b> of vulnerable groups with limited academic capacities, international consensus on respectful consent procedures and tailored patient information is necessary...|$|R
40|$|I review some of {{the current}} efforts to create <b>unbiased</b> <b>samples</b> of galaxy clusters. Readers are {{referred}} elsewhere for general wide area sky surveys and redshift surveys, and for Sunyaev-Zeldovich, radio, infrared and submm surveys, {{some of which were}} not designed to search primarily for clusters. My focus will be on optical and X-ray samples and on high redshift clusters. Comment: Review talk presented at "Constructing The Universe With Clustersy Of Galaxies", Paris, July 3 - 9, 2000, 16 pages, 4 figure...|$|R
30|$|Crown biomass is {{difficult}} to predict because of the variability within and among species and various sites. A good allometric equation for predicting aboveground biomass {{should be based on}} data collected with an appropriate (precise and <b>unbiased)</b> <b>sampling</b> method. In this context, the objective {{of this study was to}} evaluate different sampling strategies to estimate crown biomass. We also evaluated how the performance of different methods was affected when different number of branches (3, 6, 9, and 12) per tree was sampled in estimating crown biomass.|$|R
