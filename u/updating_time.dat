28|2902|Public
40|$|Abstract | In this paper, we {{introduce}} a fast IP table lookup algorithm that improves table <b>updating</b> <b>time</b> {{as well as}} IP address searching time. Because routers with Patricia trie can't support giga-bit performance, many algorithms to support giga-bit routing performance by reducing serching time have been introduced. Most of them, however, did not considerably count the im-portance of <b>updating</b> <b>time.</b> As a network often falls into instable states, a router may generate and receive hundreds of update request messages per second. So the router {{should be able to}} update its routing table at least 1000 times per second to appropriately run in real networks. We consider <b>updating</b> <b>time</b> as much important factor as searching time in proposing a exible and fast IP lookup algorithm (FFILA) in this paper. Our scheme searches the table about 3 times faster than Patricia trie. It also shows improved performance in <b>updating</b> <b>time</b> by at least 30 % when compared with Patricia trie. Also as many backbone routers today have over 100, 000 routing table entries and its number is still increasing due to the growth in the network size, the memory requirement for the lookup algorithm becomes more important. An additional advantage of our algorithm is in its small memory requirement, which is good to overcome the scalability problem. I...|$|E
3000|$|... b, the <b>updating</b> <b>time</b> {{is pretty}} stable around 20 s when paring the {{addition}} of new policies. This is because the random policy generation makes the newly introduced causality among components close to a constant rate. At the same time, the concurrency capability introduced by Erlang also increases the system scalability.|$|E
40|$|This paper {{presents}} a self-tuning framework for knowledge-based diagnosis of routine alarms in steam turbine generators. The techniques provide a novel basis for initialising and <b>updating</b> <b>time</b> series feature extraction parameters {{used in the}} automated decision support of vibration events due to operational transients. The data-driven nature of the algorithms allows for machine specific characteristics of individual turbines to be learned and reasoned about. The paper provides a case study illustrating the routine alarm paradigm and the applicability of systems using such techniques...|$|E
40|$|For any fixed 1 > [epsilon] > 0 {{we present}} a fully dynamic {{algorithm}} for maintaining (2 + [epsilon]) -approximate all-pairs shortest paths in undirected graphs with positive edge weights. We use a randomized (Las Vegas) update algorithm (but a deterministic query procedure), so the time given is the expected amortized <b>update</b> <b>time.</b> Our query time O(log log log n). The <b>update</b> <b>time</b> is O[over ~](mnO(1 /[sqrt](log n)) log (nR)), where R is the ratio between the heaviest and the lightest edge weight in the graph (so R = 1 in unweighted graphs). Unfortunately, the <b>update</b> <b>time</b> does have the drawback of a super-polynomial dependence on e. it grows as (3 /[epsilon]) [sqrt]log n/log(3 /[epsilon]) = n [sqrt]log (3 /[epsilon]) /log n. Our algorithm has a significantly faster <b>update</b> <b>time</b> than any other algorithm with sub-polynomial query time. For exact distances, {{the state of the}} art algorithm has an <b>update</b> <b>time</b> of O[over ~](n[superscript 2]). For approximate distances, the best previous algorithm has a O(kmn[superscript 1 /k]) <b>update</b> <b>time</b> and returns (2 k - 1) stretch paths. Thus, it needs an <b>update</b> <b>time</b> of O(m[sqrt](n)) to get close to our approximation, and it has to return O([sqrt](log n)) approximate distances to match our <b>update</b> <b>time...</b>|$|R
40|$|We give a space-optimal {{algorithm}} with <b>update</b> <b>time</b> O(log^ 2 (1 /eps) loglog(1 /eps)) for (1 +eps) -approximating the pth frequency moment, 0 < p < 2, of a length-n vector updated in a data stream. This {{provides a}} nearly exponential {{improvement in the}} <b>update</b> <b>time</b> complexity over the previous space-optimal algorithm of [Kane-Nelson-Woodruff, SODA 2010], which had <b>update</b> <b>time</b> Omega(1 /eps^ 2) ...|$|R
40|$|We {{consider}} {{the problem of}} maintaining an approximately maximum (fractional) matching and an approximately minimum vertex cover in a dynamic graph. Starting with the seminal paper by Onak and Rubinfeld [STOC 2010], this problem has received significant attention in recent years. There remains, however, a polynomial gap between the best known worst case <b>update</b> <b>time</b> and the best known amortised <b>update</b> <b>time</b> for this problem, even after allowing for randomisation. Specifically, Bernstein and Stein [ICALP 2015, SODA 2016] have the best known worst case <b>update</b> <b>time.</b> They present a deterministic data structure with approximation ratio (3 / 2 +ϵ) and worst case <b>update</b> <b>time</b> O(m^ 1 / 4 /ϵ^ 2), where m {{is the number of}} edges in the graph. In recent past, Gupta and Peng [FOCS 2013] gave a deterministic data structure with approximation ratio (1 +ϵ) and worst case <b>update</b> <b>time</b> O(√(m) /ϵ^ 2). No known randomised data structure beats the worst case <b>update</b> <b>times</b> of these two results. In contrast, the paper by Onak and Rubinfeld [STOC 2010] gave a randomised data structure with approximation ratio O(1) and amortised <b>update</b> <b>time</b> O(^ 2 n), where n is the number of nodes in the graph. This was later improved by Baswana, Gupta and Sen [FOCS 2011] and Solomon [FOCS 2016], leading to a randomised date structure with approximation ratio 2 and amortised <b>update</b> <b>time</b> O(1). We bridge the polynomial gap between the worst case and amortised <b>update</b> <b>times</b> for this problem, without using any randomisation. We present a deterministic data structure with approximation ratio (2 +ϵ) and worst case <b>update</b> <b>time</b> O(^ 3 n), for all sufficiently small constants ϵ. Comment: An extended abstract of this paper appeared in SODA 201...|$|R
30|$|We {{evaluate}} {{the impact of}} the policy size on the incremental updating agility and the consumed system memory via another experiment. In this experiment, we use a typical university campus network topology with 57 routers to create an SDN testbed. Then we dynamically changing the number of policies from 10 up to 10, 000 to check (1) the required system memory for storing and constructing the belief network based on the policy input; and (2) the agility of MPI on its required <b>updating</b> <b>time</b> upon its previous belief network when receiving new policies.|$|E
40|$|A {{discrete}} {{collision detection}} algorithm to detect self-collisions between deformable objects is presented, this is built up using a bounding volume hierarchy (BVH) and a Feature-based method. The deformations {{are represented by}} {{the features of the}} mesh, which are within the bounding volumes and consequently the <b>updating</b> <b>time</b> for the BVH is reduced. The algorithm compares the minimum bounded geometry, the 1 -ring, with the other spheres of the hierarchy in order to cull away bounding volumes (BV) that are far apart. The 3 D objects utilised are surface-based and are deformed by warping, control points of splines, and a mass-spring model...|$|E
30|$|Furthermore, while {{a public}} {{transportation}} vehicle is moving, it can pass through several micro cells {{in a fairly}} short time. As discussed in [22, 23], the typical <b>updating</b> <b>time</b> of ABS configurations is {{in the order of}} minutes, and therefore {{it is reasonable to assume}} that the same ABS configuration will be used by several micro cells in a given area. In this way, not only the signaling overhead to communicate the ABS configurations between different nodes can be reduced,but also the measurement and feedback from the MNs to the network can be less frequent. Hence, in this study, we use the same ABSs pattern for all the micro cells in the area given in Figure 1.|$|E
40|$|We give a space-optimal {{algorithm}} with <b>update</b> <b>time</b> O(log 2 (1 /ε) log log(1 /ε)) for (1 ± ε) approximating the pth frequency moment, 0 < p < 2, of a length-n vector updated in a data stream. This {{provides a}} nearly exponential {{improvement in the}} <b>update</b> <b>time</b> complexity over the previous space-optimal algorithm of [Kane-Nelson-Woodruff, SODA 2010], which had <b>update</b> <b>time</b> Ω(1 /ε 2). ...|$|R
40|$|We present two {{deterministic}} dynamic algorithms for {{the maximum}} matching problem. (1) An algorithm that maintains a (2 +ϵ) -approximate maximum matching in general graphs with O(poly(n, 1 /ϵ)) <b>update</b> <b>time.</b> (2) An algorithm that maintains an α_K approximation {{of the value}} of the maximum matching with O(n^ 2 /K) <b>update</b> <b>time</b> in bipartite graphs, for every sufficiently large constant positive integer K. Here, 1 ≤α_K < 2 is a constant determined by the value of K. Result (1) is the first deterministic algorithm that can maintain an o(n) -approximate maximum matching with polylogarithmic <b>update</b> <b>time,</b> improving the seminal result of Onak et al. [STOC 2010]. Its approximation guarantee almost matches the guarantee of the best randomized polylogarithmic <b>update</b> <b>time</b> algorithm [Baswana et al. FOCS 2011]. Result (2) achieves a better-than-two approximation with arbitrarily small polynomial <b>update</b> <b>time</b> on bipartite graphs. Previously the best <b>update</b> <b>time</b> for this problem was O(m^ 1 / 4) [Bernstein et al. ICALP 2015], where m is the current number of edges in the graph. Comment: To appear in STOC 201...|$|R
40|$|This paper {{presents}} the first fully dynamic algorithms for maintaining all-pairs shortest paths in digraphs with positive integer weights less than b. For approximate shortest paths with an error factor of (2 + ffl), for any positive constant ffl, the amortized <b>update</b> <b>time</b> is O(n 2 log 2 n= log log n); for an error factor of (1 + ffl) the amortized <b>update</b> <b>time</b> is O(n 2 log 3 (bn) =ffl 2). For exact shortest paths the amortized <b>update</b> <b>time</b> is O(n 2 : 5 p b log n). Query time for exact and approximate shortest distances is O(1); exact and approximate paths {{can be generated}} in time proportional to their lengths. Also presented is a fully dynamic transitive closure algorithm with <b>update</b> <b>time</b> O(n 2 log n) and query time O(1). The previously known fully dynamic transitive closure algorithm with fast query time has one-sided error and <b>update</b> <b>time</b> O(n 2 : 28). The algorithms use simple data structures, and are deterministic...|$|R
40|$|In {{this paper}} we {{investigate}} several periodicity-related algorithms for partial words. First, {{we show that}} all periods of a partial word of length n are determined in O(nlogn), and provide algorithms and data structures that help us answer in constant time queries regarding the periodicity of their factors. For this we need a O(n 2) preprocessing time and a O(n) <b>updating</b> <b>time,</b> whenever the words are extended by adding a letter. In the second part we show that substituting letters of a word w with holes, with the property that no two holes are too close to each other, to make it periodic {{can be done in}} optimal time O(|w|). Moreover, we show that inserting the minimum number of holes such that the word keeps the property can be done as fast...|$|E
40|$|The {{purpose of}} this report is to {{optimize}} the Inside-Outside algorithm and realize fast EM learning of various extensions of PCFGs. The point of our optimization is {{the introduction of a}} new data structure called support graphs hierarchically representing a set of parse trees and a new EM learning algorithm called the graphical EM algorithm that runs on them. Learning experiments with PCFGs using Japanese corpora of moderate size with contrasting characters indicate that in terms of <b>updating</b> <b>time</b> per iteration, the graphical EM algorithm can learn parameters of PCFGs orders of magnitude faster than the Inside-Outside algorithm. We also experimentally show that the graphical EM algorithm requires at most about twice as much time as a pure PCFG to learn parameters of extended PCFGs (a Pseudo PCSG and and a lexicalized PCFG) ...|$|E
40|$|Efficient path {{computation}} {{is essential}} for applications such as intelligent transportation systems (ITS) and network routing. In ITS navigation systems, many path requests can be submitted over the same, typically huge, transportation network within a small time window. While path precomputation (path view) would provide an efficient path query response, it raises three problems which must be addressed: 1) precomputed paths exceed the current computer main memory capacity for large networks; 2) disk-based solutions are too inefficient to meet the stringent requirements of these target applications; and 3) path views become too costly to update for large graphs (resulting in out-of-date query results). We propose a hierarchical encoded path view (HEPV) model that addresses all three problems. By hierarchically encoding partial paths, HEPV reduces the view encoding time, <b>updating</b> <b>time</b> and storage requirements beyond previously known path precomputation techniques, while significantly mi [...] ...|$|E
40|$|We {{study the}} {{following}} dynamic graph problem: given an undirected graph G, we maintain a connectivity oracle between any two vertices in G under any on-line sequence of vertex deletions and insertions with incident edges. We propose two algorithms for this problem: an amortized <b>update</b> <b>time</b> deterministic {{one and a}} worst case <b>update</b> <b>time</b> Monte Carlo one. Both of them allow an arbitrary number of new vertices to insert. The <b>update</b> <b>time</b> complexity of the former algorithm is no worse than the existing algorithms, which allow only limited number of vertices to insert. Moreover, for relatively dense graphs, we can expect that the <b>update</b> <b>time</b> bound of the former algorithm meets a lower bound, {{and that of the}} latter algorithm {{can be seen as a}} substantial improvement of the existing result by introducing randomization...|$|R
40|$|For NAND flash memory-based systems, garbage {{collection}} remains a major performance bottleneck. To decrease the {{garbage collection}} overhead, data separation techniques based on update frequency are widely used. However, from our observations using the oracle predictor on data <b>update</b> <b>times,</b> separating data by their <b>update</b> <b>times</b> rather than data with high update frequencies {{is a more}} important factor in reducing garbage collection overhead. Based on the observations, we propose a novel update time-based data separation technique. The proposed technique predicts what data will be updated together based on program contexts hints which can record data update behaviors. Our technique finds program contexts which generate data with similar <b>update</b> <b>times,</b> and groups the program contexts by estimated <b>update</b> <b>times.</b> A flash translation layer (FTL) using the proposed technique can reduce garbage collection overhead by allocating data with similar <b>update</b> <b>times</b> to the same blocks. Our experimental results show that our technique can reduce the total execution time of garbage collection on average 58 % over a data update frequency-based approach. 1...|$|R
40|$|We present {{improved}} algorithms {{for maintaining}} transitive closure and all-pairs shortest paths/distances in a digraph under deletion of edges. (MATH) For {{the problem of}} transitive closure, the previous best known algorithms, for achieving O(1) query time, require O((m, n^ 3 /m)) amortized <b>update</b> <b>time,</b> implying an upper bound of O(n^ 3 / 2) on <b>update</b> <b>time</b> per edge-deletion. We present an algorithm that achieves O(1) query time and O(n ^ 2 n + n^ 2 /√(m) √(n)) <b>update</b> <b>time</b> per edge-deletion, thus improving the upper bound to O(n^ 4 / 3 √(n)). (MATH) For the problem of maintaining all-pairs shortest distances in unweighted digraph under deletion of edges, we present an algorithm that requires O(n^ 3 /m^ 2 n) amortized <b>update</b> <b>time</b> and answers a distance query in O(1) time. This improves the previous best known update bound {{by a factor of}} log n. For maintaining all-pairs shortest paths, we present an algorithm that achieves O((n^ 3 / 2 √(n), n^ 3 /m ^ 2 n)) amortized <b>update</b> <b>time</b> and reports a shortest path in optimal time (proportional to the length of the path). For the latter problem we improve the worst amortized <b>update</b> <b>time</b> bound by a factor of O(√(n/ n)). (MATH) We also present the first decremental algorithm for maintaining all-pairs (1 +&egr;) approximate shortest paths/distances, for any &egr; > 0, that achieves a sub-quadratic <b>update</b> <b>time</b> of O(n log 2 n + n^ 2 /√(ϵ m) √(n)) and optimal query time. Our algorithms are randomized and have one-sided error for query (with probability O(1 /nc) for any constant c) ...|$|R
40|$|Queuing models {{provide insight}} into the {{temporal}} inhomogeneity of human dynamics, characterized by the broad distribution of waiting times of individuals performing tasks. We study the queuing model of an agent trying to execute a task of interest, the priority of which may vary with time due to the agent's "state of mind. " However, its execution is disrupted by other tasks of random priorities. By considering the priority of the task of interest either decreasing or increasing algebraically in time, we analytically obtain and numerically confirm the bimodal and unimodal waiting time distributions with power-law decaying tails, respectively. These results are also compared to the <b>updating</b> <b>time</b> distribution of papers in the arXiv. org and the processing time distribution of papers in Physical Review journals. Our analysis helps to understand human task execution in a more realistic scenario. Comment: 8 pages, 6 figure...|$|E
40|$|Accurate {{knowledge}} of time-variation in meridional flow-speed and profile {{is crucial for}} estimating a solar cycle's features, which are ultimately responsible for causing space climate variations. However, no consensus has been reached yet about the Sun's meridional circulation pattern observations and theories. By implementing an Ensemble Kalman Filter (EnKF) data assimilation in a Babcock-Leighton solar dynamo model using Data Assimilation Research Testbed (DART) framework, {{we find that the}} best reconstruction of time-variation in meridional flow-speed can be obtained when ten or more observations are used with an <b>updating</b> <b>time</b> of 15 days and a < 10 % observational error. Increasing ensemble-size from 16 to 160 improves reconstruction. Comparison of reconstructed flow-speed with "true-state" reveals that EnKF data assimilation is very powerful for reconstructing meridional flow-speeds and suggests that it can be implemented for reconstructing spatio-temporal patterns of meridional circulation. Comment: 18 pages, 6 figures, published in GRL (August 2014...|$|E
40|$|AbstractDeep seated {{gravitational}} slope deformation {{and slow}} moving landslides on large areas {{were analyzed by}} spaceborne SAR interferometry: a test site in the Italian Alps of about 300 km 2 was selected for updating pre-existing landslide inventory maps based on the advanced interferometric processing technique (A-DInSAR). SAR images from ERS- 1 / 2 satellites (1995 – 2000) and from Envisat satellite (2002 – 2009) have been used, allowing the deferred-time analysis of past movements and the record of recent slope movements. In the multi-temporal updated landslide inventory database, {{the characteristics of the}} landslides were highlighted: geometry, state of activity, typology, monitoring systems, interventions, source of information and the <b>updating</b> <b>time</b> and actions. Furthermore, for each landslide area, the occurrence of persistent scatterers points and the statistical description of their velocities were reported. This methodology may allow the systematic updating of landslides inventory maps keeping all information on each landslide, becoming the basic tool for the realization and updating of thematic maps such as the landslide susceptibility map...|$|E
40|$|Abstract. In edge orientations, {{the goal}} is usually to orient (direct) the edges of an undirected network (modeled by a graph) such that all outdegrees are bounded. When the network is fully dynamic, i. e., admits edge insertions and deletions, we wish to {{maintain}} such an orientation while keeping a tab on the <b>update</b> <b>time.</b> Low out-degree orientations {{turned out to be}} a surprisingly useful tool for managing networks. Brodal and Fagerberg (1999) initiated the study of the edge orientation problem in terms of the graph’s arboricity, which is very natural in this context. Their solution achieves a constant out-degree and a logarithmic amortized <b>update</b> <b>time</b> for all graphs with constant arboricity, which include all planar and excluded-minor graphs. It remained an open question – first proposed by Brodal and Fagerberg, later by Erickson and others – to obtain similar bounds with worst-case <b>update</b> <b>time.</b> We address this 15 year old question by providing a simple algorithm with worst-case bounds that nearly match the previous amortized bounds. Our algorithm is based on a new approach of maintaining a combinatorial invariant, and achieves a logarithmic out-degree with logarithmic worst-case <b>update</b> <b>times.</b> This result has applications to various dynamic network problems such as maintaining a maximal matching, where we obtain logarithmic worst-case <b>update</b> <b>time</b> compared to a similar amortized <b>update</b> <b>time</b> of Neiman and Solomon (2013). ...|$|R
40|$|We present {{improved}} algorithms {{for maintaining}} transitive closure and all-pairs shortest paths in a digraph under deletion of edges. For {{the problem of}} transitive closure, the previous best known algorithms achieving O(1) query time require O(min(m; n =m)) amortized <b>update</b> <b>time,</b> thus establish an upper bound of O(n) on <b>update</b> <b>time</b> per edge-deletion where m and n denote the number of edges and vertices respectively in the given graph. We present an algorithm that achieves O(1) query time for answering a query and O(n log log n) <b>update</b> <b>time</b> per edge-deletion, thus improving the upper bound to O(n 3 log n) ...|$|R
40|$|In this paper, we {{consider}} the problem of finding ε{lunate}-approximate frequent items over a sliding window of size N. A recent work by Lee and Ting (2006) [7] solves the problem by giving an algorithm that supports O (frac(1, ε{lunate})) query and <b>update</b> <b>time,</b> and uses O (frac(1, ε{lunate})) space. Their query time and memory usage are essentially optimal, but the <b>update</b> <b>time</b> is not. We give a new algorithm that supports O (1) <b>update</b> <b>time</b> with high probability while maintaining the query time and memory usage as O (frac(1, ε{lunate})). © 2010 Elsevier B. V. All rights reserved. link_to_subscribed_fulltex...|$|R
40|$|Abstract: Satellite {{networks}} {{are becoming increasingly}} important because of the ex-citing global communication services they provide. Key management policies have been successfully deployed in terrestrial networks to guarantee the information se-curity. However, long propagation, storage and computation constraints bring new challenges in designing efficient and cost-effective key updating policies for satellite networks. Based on the structure and communication features of satellite networks, a dynamic key management model for satellite networks (DKM-SN) is presented, which includes certificates owned by each satellite, primary keys and session keys {{both of which are}} shared between two satellites. Furthermore, a protocol is designed for updating certificates for satellites; different policies for updating primary and ses-sion keys are studied and their efficiency and security are analyzed and compared. In addition, simulation environment for satellite networks is built and the key updat-ing processes are implemented in Walker constellation. From the simulation results, further contrasts on key <b>updating</b> <b>time</b> and storage costs between the applications of IBM hybrid key management model (HKMM) and DKM-SN in satellite {{networks are}} presented. Finally, important suggestions in designing key updating policies are given...|$|E
40|$|Nowadays, {{with the}} {{increasing}} variety of computer systems, resource discovery in the Grid environment has been very important due to their applications; thus, offering optimal and dynamic algorithms for discovering resources in which users need a short period is an important task in grid environments. One of the methods used in resource discovery in grid is to use routing tables RDV (resource distance vector) in which the resources are based on certain criteria clustering and the clusters form a graph. In this way, some information about the resources is stored in RDV tables. Due to the environmental cycle in the graph, there are some problems; for example there are multiple paths to resources, {{most of which are}} repeated. Also, in large environments, due to the existence of many neighbors, updating the graph is time-consuming. In this paper, the structure of RDV was presented as a binary tree and these two methods (RDV graph-algorithm and RDVBT) were compared. Simulation results showed that, as a result of converting the structure to a binary tree, much better results were obtained for routing time, table <b>updating</b> <b>time</b> and number of successful requests; also the number of unsuccessful requests was reduced.  </p...|$|E
40|$|An {{advantageous}} innovation for {{retail stores}} is the ESL system, {{which consists of}} many electronic units, called labels, showing product and price information to customers on small displays. Such a system offers, among other things, efficient price updates that implies lower costs by reducing man-hours and paper volumes. Data transfered to a label can be compressed {{in order to minimize}} the data size and thuslowering the <b>updating</b> <b>time</b> and the energy consumption of a label. In this study, twelve lossless compression prototypes were implemented and evaluated, using a corpus set of bi-level images, with respect to compressibility, encoding and decoding time. Six of those prototypes were subject to case studies of real ESL data and further studies of memory consumption. The results showed that the low-precision arithmetic coder LowPac, which uses a context-based probability model, {{was one of the best}} prototypes over all data sets in terms of compressibility and it was also the most memory-efficient prototype. Using the corpus set, LowPac obtained encoding and decoding times of 2 times longer than one of the fastest prototypes, but with 108 % improvement of compressibility, on average...|$|E
40|$|Abstract. In {{this paper}} we give a fully dynamic data {{structure}} {{to maintain the}} connectivity of the intersection graph of n axis-parallel rectangles. The amortized <b>update</b> <b>time</b> (insertion and deletion of rectangles) is O(n 10 = 11 polylog n) and the query time (deciding whether two given rectangles are connected) is O(1). It slightly improves the <b>update</b> <b>time</b> (O(...|$|R
5000|$|... the {{expected}} arrival or departure <b>time</b> and/or the <b>updated</b> <b>time</b> (reflecting any delays) ...|$|R
30|$|We set a {{threshold}} as a {{minimum number of}} <b>updating</b> <b>times,</b> and the <b>updating</b> <b>times</b> of each Gaussian model must exceed this threshold to ensure the stability of each model. Besides, {{in order to reduce}} the computation loading of updating procedure, we gave a limit that each Gaussian model could only be updated at most 200 times for one frame.|$|R
40|$|Engine power, brake-specific fuel consumption, and {{emissions}} relate closely to air ratio (i. e., lambda) {{among all the}} engine variables. An accurate and adaptive model for lambda prediction is essential to effective lambda control for long term. This paper utilizes an emerging technique, relevance vector machine (RVM), to build a reliable time-dependent lambda model which can be continually updated whenever a sample is added to, or removed from, the estimated lambda model. The paper also presents a new model predictive control (MPC) algorithm for air-ratio regulation based on RVM. This study shows that the accuracy, training, and <b>updating</b> <b>time</b> of the RVM model are superior to the latest modelling methods, such as diagonal recurrent neural network (DRNN) and decremental least-squares support vector machine (DLSSVM). Moreover, the control algorithm has been implemented on a real car to test. Experimental results reveal that the control performance of the proposed relevance vector machine model predictive controller (RVMMPC) is also superior to DRNNMPC, support vector machine-based MPC, and conventional proportional-integral (PI) controller in production cars. Therefore, the proposed RVMMPC is a promising scheme to replace conventional PI controller for engine air-ratio control...|$|E
40|$|Volunteered Geographic Information (VGI) is an {{approach}} to crowdsource information about geospatial objects around us, as implemented in Open Street Map, Google Map Maker and WikiMapia projects. The value of this content has been recognized by both researchers and organizations for acquiring free, timely and detailed spatial data versus standard spatial data warehouses where objects are created by professionals with variable <b>updating</b> <b>time.</b> However, evaluating its quality and handling its heterogeneity remain challenging concerns. For instance, VGI data sources have been compared to authoritative geospatial ones on specific regions/areas {{in order to determine}} an average overall quality level. In user-oriented VGI-based applications, it can be more relevant to assess the quality of particular contents, like specific Points of Interest. In this case, evaluation can be performed indirectly by reputation scores associated with the specific content. This paper focuses on this last aspect. Our contribution primarily provides a comprehensive model and architecture for reputation evaluation aimed to assess quality of VGI content. On the other hand, we also focus on applications by discussing two motivating scenarios for reputation-enhanced VGI data in the context of geospatial decision support systems and in recommending tourist itinerarie...|$|E
40|$|Openratio {{offers a}} mobile {{platform}} {{as a service}} (mPaaS) to build secure enterprise apps that use legacy systems from vendors such as Microsoft, IBM and SAP. The platform creates native mobile applications and mobile websites using a simple drag and drop interface without writing code. Openratio continuously develops their platform in short design cycles, and started a major system upgrade in 2014. The old mobile website was incompatible with the new specifications and upgrading it was time intensive, leading to a 6 months delay behind other system components’ progress. This thesis covers the process of analyzing the previous mobile website server and implementing a new mobile website rendering server. The server is developed from scratch using node. js, a javascript platform for developing web applications, and jQuery mobile, an HTML 5 based interface for responsive mobile websites. The designed server uses real-time configuration settings to dynamically render each page’s layout, navigation and content with enterprise-grade security. In addition, the server handles user authentication and session management, content fetching from external data sources and uses styling and website templating engines. The new implemented server shortened the <b>updating</b> <b>time</b> for each development cycle and decoupling the mobile website rendering server from the main server allowed team members to work on several platform components in parallel...|$|E
40|$|In this study, a new fast {{method for}} {{selecting}} the next <b>update</b> <b>time</b> in two maneuvering target tracking algorithms, namely the Interacting Multiple Models (IMM) algorithm and the Multi Rate Interacting Multiple Models (MRIMM), will be presented. Both IMM and MRIMM are used here to predict and estimate the target`s possible {{states and to}} select the correct next <b>update</b> <b>time.</b> The idea is to assign to each model in the IMM and MRIMM algorithms an appropriate rate and to weight these rates by the models` probabilities to obtain the rate to use. The resulting algorithms are named, respectively, the Fast Adaptive IMM (FAIMM) algorithm and the Adaptive MRIMM (AMRIMM) algorithm. Using Monte Carlo simulations, the performances of these algorithms are {{compared to that of}} the Adaptive IMM algorithm that uses Van Keuk criterion to select the next <b>update</b> <b>time</b> and to that of the IMM algorithm and MRIMM that use a constant <b>update</b> <b>time...</b>|$|R
40|$|We design fast dynamic {{algorithms}} {{for proper}} vertex and edge colorings in a graph undergoing edge insertions and deletions. In the static setting, there are simple linear time algorithms for (Δ+ 1) - vertex coloring and (2 Δ- 1) -edge coloring in a graph with maximum degree Δ. It is natural {{to ask if}} we can efficiently maintain such colorings in the dynamic setting as well. We get the following three results. (1) We present a randomized algorithm which maintains a (Δ+ 1) -vertex coloring with O(Δ) expected amortized <b>update</b> <b>time.</b> (2) We present a deterministic algorithm which maintains a (1 +o(1)) Δ-vertex coloring with O(polyΔ) amortized <b>update</b> <b>time.</b> (3) We present a simple, deterministic algorithm which maintains a (2 Δ- 1) -edge coloring with O(Δ) worst-case <b>update</b> <b>time.</b> This improves the recent O(Δ) -edge coloring algorithm with Õ(√(Δ)) worst-case <b>update</b> <b>time</b> by Barenboim and Maimon. Comment: To appear in SODA 201...|$|R
40|$|We {{present a}} {{parallel}} machine, based on programmable devices, dedicated to simulate spin glass models with Z 2 variables and short range interaction. A working prototype is described for two lattices containing 312 × 312 spins each with an <b>update</b> <b>time</b> of 50 ns per spin. The {{final version of}} the three dimensional parallel machine is discussed with spin <b>update</b> <b>time</b> up to 312 ps...|$|R
