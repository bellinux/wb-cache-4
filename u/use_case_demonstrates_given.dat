0|10000|Public
30|$|New <b>use</b> <b>cases</b> to <b>demonstrate</b> {{these two}} mechanisms.|$|R
50|$|The ONOS {{software}} {{has been}} used as a platform that applications have been written on top of or has been integrated into other projects. A number of <b>use</b> <b>cases</b> <b>demonstrate</b> how the software is being used today—including global research networking deployments, multilayer network control, and central office re-designed as a datacenter.|$|R
40|$|International audiencePharmML 1 is an XML-based {{exchange}} format 2 - 4 {{created with}} a focus on nonlinear mixed-effect (NLME) models used in pharmacometrics, 5, 6 but providing a very general framework that also allows describing mathematical and statistical models such as single-subject or nonlinear and multivariate regression models. This tutorial provides an overview of the structure of this language, brief suggestions on how to work with it, and <b>use</b> <b>cases</b> <b>demonstrating</b> its power and flexibility. © 2017 ASCPT All rights reserved...|$|R
40|$|Traceability and {{rationale}} {{management are}} highly important—especially in distributed collaborative software development projects {{due to a}} lack of mutual awareness and informal coordination among the participating stakeholders. Therefore this papers presents a tool for extracting, visualizing, and analyzing the relationships between requirements and other artifacts, activities as well as users within a distributed software project using a collaborative development environment. Underlying requirements and the conceptual design of this tool are based on several real-world <b>use</b> <b>cases</b> <b>demonstrating</b> the respective value contribution of the tool’s functionality...|$|R
50|$|The ODRL language, {{currently}} at Version 2.0, defines a comprehensive information policy framework through publication of two specifications: the ODRL Version 2.0 Core Model, and ODRL Version 2.0 Common Vocabulary. Included within the ODRL documentation {{are a number}} of basic <b>use</b> <b>cases</b> <b>demonstrating</b> how to implement policy expressions using the Core Model with terms from the Common Vocabulary. ODRL is fully extensible and provides a mechanism for new communities to extend and/or deprecate the ODRL Common Vocabulary used in conjunction with the Core Model.|$|R
30|$|Recontextualization {{can be used}} as {{a trigger}} for self-* {{operations}} that cannot misinterpret events. This is in contrast to a VM trying to analyse when an event had occurred via its own internal procedures, for example based on when its external IP address changes. A distributed file system <b>use</b> <b>case</b> <b>demonstrated</b> the feasibility of our approach. In the <b>use</b> <b>case</b> recontextualization is <b>used</b> to reconfigure the VM to recover from performance degradation experienced as a result of VM migration. Although the degradation is partly synthetic and correlated to the network settings used, we demonstrate that performance gains can be achieved by runtime optimization triggered by recontextualization.|$|R
40|$|Abstract. A virtual {{observatory}} {{will not}} only enhance many current scientific investigations, {{but it will also}} enable entirely new scientific explorations due to both the federation of vast amounts of multiwavelength data and the new archival services which will, as a necessity, be developed. The detailing of specific science <b>use</b> <b>cases</b> is important in order to properly facilitate the development of the necessary infrastructure of a virtual observatory. The understanding of high velocity clouds is presented as an example science <b>use</b> <b>case,</b> <b>demonstrating</b> the future synergy between the data (either catalog or images), and the desired analysis in the new paradigm of a virtual observatory. 1...|$|R
40|$|Summary: This {{deliverable}} describes Web-enabled public showcases {{for public}} dissemination and {{presentation of the}} project. The showcase is built around publicly available, Web-based CODE prototypes. The purpose of each prototype is briefly described followed by typical <b>use</b> <b>case</b> descriptions <b>demonstrated</b> along a typical <b>use</b> <b>case...</b>|$|R
30|$|Create <b>use</b> <b>cases</b> which <b>demonstrate</b> the {{triggering}} of a blockchain-based P 2 P energy trade {{based on}} measurements {{from a home}} smart meter in order {{to carry out a}} full end-to-end simulation with hardware in the loop.|$|R
40|$|This paper {{presents}} {{the current state}} of development of GlamMap, a visualisation tool that displays library metadata on an interactive, computer-generated geographic map. The focus in the paper is on the most crucial improvement achieved {{in the development of the}} tool: GlamMapping Trove. The visualisation of Trove’s sixty-million book records is possible thanks to an improved database structure, more efficient data retrieval, and more scalable visualisation algorithms. The paper analyses problems encountered in visualising massive datasets, describes remaining challenges for the tool, and presents a <b>use</b> <b>case</b> <b>demonstrating</b> GlamMap’s ability to serve researchers in the history of ideas...|$|R
40|$|Collective {{intelligence}} {{is currently a}} hot topic within the Web and Geoinformatics communities. Research into ways of producing advances with collective {{intelligence is}} becoming increasingly popular. This article introduces a novel approach to collective intelligence {{with the use of}} geographic knowledge discovery to determine spatially referenced patterns and models from the Geospatial Web which are used for supporting decisions. The article details the latest Web 2. 0 technologies which make geographic knowledge discovery from the Geospatial Web possible to produce advanced collective intelligence. The process is explored and illustrated in detail, and <b>use</b> <b>cases</b> <b>demonstrate</b> the potential usefulness. Finally, potential pitfalls are discussed...|$|R
40|$|We {{present the}} design and {{implementation}} of a real-time 3 D graphics library for image-based Constructive Solid Geometry (CSG). This major approach of 3 D modeling has not been supported by real-time computer graphics until recently. We explain two essential image-based CSG rendering algorithms, and we introduce an API that provides a compact access to their complex functionality and implementation. As an important feature, the CSG library seamlessly integrates application-defined 3 D shapes as primitives of CSG operations to ensure high adaptability and openness. We also outline optimization techniques to improve the performance {{in the case of}} complex CSG models. A number of <b>use</b> <b>cases</b> <b>demonstrate</b> potential applications of the library. ...|$|R
40|$|Abstract—Understanding {{information}} and gaining insights about information usually means {{interacting with the}} displayed information. Utilizing the new capabilities of smart meeting rooms, visual outputs of different information representation applications are presented according to the user’s needs. In this paper we present smart interaction management. This interaction approach enables the users to interact with all dis-played views, utilizing the novel capabilities of these environments and besides, to traditionally interact with applications using her local device. We further show two <b>use</b> <b>cases</b> <b>demonstrating</b> typical applications of our approach in such multi-display environments: (1) to modify the arrangement and layout of views and (2) {{to interact with the}} displayed information within a view. I...|$|R
40|$|The Chem 2 Bio 2 RDF portal is a Linked Open Data (LOD) portal for systems {{chemical}} biology aiming for facilitating drug discovery. It converts around 25 different datasets on genes, compounds, drugs, pathways, side effects, diseases, and MEDLINE/PubMed documents into RDF triples and links {{them to other}} LOD bubbles, such as Bio 2 RDF, LODD and DBPedia. The portal is based on D 2 R server and provides a SPARQL endpoint, but adds on few unique features like RDF faceted browser, user-friendly SPARQL query generator, MEDLINE/PubMed cross validation service, and Cytoscape visualization plugin. Three <b>use</b> <b>cases</b> <b>demonstrate</b> the functionality and usability of this portal. Comment: 8 pages, 10 figure...|$|R
40|$|A virtual {{observatory}} {{will not}} only enhance many current scientific investigations, {{but it will also}} enable entirely new scientific explorations due to both the federation of vast amounts of multiwavelength data and the new archival services which will, as a necessity, be developed. The detailing of specific science <b>use</b> <b>cases</b> is important in order to properly facilitate the development of the necessary infrastructure of a virtual observatory. The understanding of high velocity clouds is presented as an example science <b>use</b> <b>case,</b> <b>demonstrating</b> the future synergy between the data (either catalog or images), and the desired analysis in the new paradigm of a virtual observatory. Comment: 6 pages, 4 figures, uses newpasp. sty (included). To be published in the proceedings of the conference "Virtual Observatories of the Future," editors R. J. Brunner, S. G. Djorgovski, and Alex S. Szalay, ASP Conference Series, Volume 22...|$|R
40|$|We {{propose to}} {{demonstrate}} Direct Code Execution (DCE), {{a framework that}} enables to execute nearly unmodified ap-plications and Linux Kernel code jointly with the ns- 3 simu-lator. DCE allows therefore fully deterministic reproducibil-ity of network experiments. DCE also supports larger scale scenarios than real-time emulators by using simulation time dilatation. In this demonstration, we will showcase two main scenarios: (1) a basic example describing how to integrate in DCE the Data Center TCP (DCTCP) Linux kernel patch, and then how to customize this protocol and run it on differ-ent scenarios; (2) a more advanced <b>use</b> <b>case</b> <b>demonstrating</b> how to benefit from DCE to build a rich and realistic eval-uation environment for Software Defined Wireless Networks based on Open vSwitch and the NOX SDN controller...|$|R
40|$|Abstract. neXtProt {{provides}} a comprehensive knowledgebase on human proteins complemented by an extensive cross incorporation of annotations from many databases. With {{the diversity of}} published data, provenance information becomes critical to providing reliable and trustworthy services to scientists, thus the tracking of provenance in open, decentralized systems is especially important. Since the nanopublication system addresses many of these challenges, we have developed the neXtProt Linked Data by serializing in RDF/XML annotations specific to neXtProt and started employing the nanopublication model to give appropriate attribution to all data. Specifically, a <b>use</b> <b>case</b> <b>demonstrates</b> the handling of post-translational modification (PTM) data modeled as nanopublications to illustrate how the different levels of provenance and data quality thresholds can be captured in this model...|$|R
40|$|In {{this paper}} we {{argue for the}} use of Unstructured Supplementary Service Data (USSD) as a {{platform}} for universal cell phone applications. We examine over a decade of ICT 4 D research, analyzing how USSD can extend and complement current uses of IVR and SMS for data collection, messaging, information access, social networking and complex user initiated transactions. Based on these findings we identify situations when a mobile based project should consider using USSD with increasingly common third party gateways over other mediums. This analysis also motivates the design and implementation of an open source library for rapid development of USSD applications. Finally, we explore three USSD <b>use</b> <b>cases,</b> <b>demonstrating</b> how USSD opens up a design space not available with IVR or SMS...|$|R
40|$|Abstract. In this paper, {{we present}} a {{multilingual}} matching approach aiming at building matches between terms belonging to multilingual thesauri. The approach {{is presented as a}} variant of the schema matching problem and present its evalua-tion on domain-specific <b>use</b> <b>cases</b> by <b>demonstrating</b> the viability of the proposed technique for facing the multilingual thesaurus matching approach. ...|$|R
40|$|The present {{contribution}} describes {{approaches for}} visualizing building related data (temperature, energy use, etc.). A web based visualization framework is presented {{and a number}} of <b>use</b> <b>cases</b> are <b>demonstrated</b> (i. e. three-dimensional building browsing). Usability is optimized for diverse screen sizes, input methods (i. e. touch screen), and application logics. Finally, guidelines for further user interface development are presented...|$|R
40|$|We {{focus on}} visual {{analysis}} of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The {{analysis of these}} data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two <b>use</b> <b>cases</b> <b>demonstrating</b> its usefulness {{for a wide variety}} of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained...|$|R
40|$|While deliberating {{and making}} decisions, {{participants}} in urban development processes need {{easy access to}} the pertinent content scattered among different plans. A Planning Markup Language (PML) has been proposed to represent the underlying structure of plans in an XML-compliant way. However, PML currently covers only textual information and lacks specifications about graphic information used in plans. To fill in this gap, this dissertation develops a PML extension, termed PMLGraphics, with the capacity of marking up graphic content of plans in a ???plan usable??? way. The development of the PMLGraphics can significantly impact how plans are made and used in planning practice. The PMLGraphics is built on theoretical research on ontology of graphic representations in plan documents and relationships between different entities of plan content (i. e. text, single graphic and graphic group). The ontology of graphic representations includes typical graphic types in plans, representation methods used by graphics, and classification of intended plan information conveyed by graphics. The proposed PMLGraphics has three components: document metadata that summarizes general information of plan documents, document structure that outlines hierarchical structure of topics in plans, and document content that defines sets of elements to mark up plan content in text, single graphic, and graphic group, as well as relationships between these three content entities. To test the feasibility of the PMLGraphics, three plans are encoded and a prototype for using the PMLGraphics is designed and implemented. Three hypothetical <b>use</b> <b>cases,</b> which simulate scenarios in practical planning processes, are created to test the PMLGraphics capabilities. The <b>use</b> <b>cases</b> <b>demonstrate</b> the feasibility and applicability of the PMLGraphics in accessing graphic content scattered in different plans made by different agents. The significance of the PMLGraphics for planning participants is that, as <b>use</b> <b>cases</b> <b>demonstrate,</b> graphic plan content accessed through PMLGraphics would have been harder to find, if found at all, using hardcopy sources or using electronic files without graphic markup...|$|R
40|$|Let us {{consider}} a simplified emergency <b>use</b> <b>case</b> to <b>demonstrate</b> {{the potential of}} Geoinformation-services (GI services) in a cross-border region: A case of foot-and-mouth disease has occurred on a Dutch farm. A veterinary from the Dutch environmental authority needs to inform his German colleague of its occurrence. We shall assume that {{the locations of the}} barns or fields have bee...|$|R
40|$|We {{present a}} general visual {{analytics}} architecture that is constructed and implemented to effectively analyze un-structured social media {{data on a}} large scale. Pipelined based on a high-performance cluster configuration, MPI processing, and interactive visual analytics interfaces, our architecture, I-SI, closely integrates data-driven analyti-cal methods and user-centered visual analytics. It creates a coherent analysis environment for identifying event structures, geographical distributions, and key indicators of emerging events. This environment can support moni-toring, analyzing, and responding to latent information extracted from social media. We have applied the I-SI ar-chitecture to collect social media data, analyze the data {{on a large scale}} and uncover the latent social phenomena. To demonstrate the efficacy and applicability of I-SI, we describe several social media <b>use</b> <b>cases</b> in multiple do-mains that were evaluated by experts. The <b>use</b> <b>cases</b> <b>demonstrate</b> that I-SI can benefit a range of users by construct-ing meaningful event structures and identifying precursors to critical events within a rich, evolving set of topics...|$|R
40|$|Government {{contracting}} {{has experienced}} {{an explosion of}} available data in the last decade, marked {{by the rise of}} the global Open Contracting Data Standard. However, it remains largely under-utilized for Big Data analytics and embedding findings in policy making. In order to address this gap and promote the use of government administrative data for policy making, this paper provides a review on the availability, scope and quality of datasets in government contracting in 35 European countries and highlights prominent <b>use</b> <b>cases</b> to inspire policy makers and civil society. State of the art findings come from the ongoing Horizon 2020 -funded research project led by the University of Cambridge, called DIGIWHIST, which benchmarks, standardizes, and republishes public procurement data across Europe while also providing key performance indicators directly relevant for policy. <b>Use</b> <b>cases</b> <b>demonstrate</b> how civil society can use Big Data to hold governments accountable; and how governments can use advanced market analytics for detecting collusive competitors and safeguarding public spending...|$|R
40|$|Demo Abstract in Proceedings of ACM MSWiM, Montreal, Canada, September 21 - 26 2014 We {{propose to}} {{demonstrate}} Direct Code Execution (DCE), {{a framework that}} enables to execute nearly unmodified applications and Linux Kernel code jointly with the ns- 3 simu-lator. DCE allows therefore fully deterministic reproducibil-ity of network experiments. DCE also supports larger scale scenarios than real-time emulators by using simulation time dilatation. In this demonstration, we will showcase two main scenarios: (1) a basic example describing how to integrate in DCE the Data Center TCP (DCTCP) Linux kernel patch, and then how to customize this protocol and run it on differ-ent scenarios; (2) a more advanced <b>use</b> <b>case</b> <b>demonstrating</b> how to benefit from DCE to build a rich and realistic eval-uation environment for Software Defined Wireless Networks based on Open vSwitch and the NOX SDN controller...|$|R
40|$|We present MiningZinc, a novel {{system for}} con- straint-based pattern mining. It {{provides}} a declarative approach to data mining, where a user specifies {{a problem in}} terms of constraints and the system employs advanced techniques to efficiently find solutions. Declarative programming and modeling are common in artificial intelligence and in database systems, {{but not so much}} in data mining; by building on ideas from these communities, MiningZinc advances the state-of-the-art of declarative data mining significantly. Key components of the MiningZinc system are (1) a high-level and natural language for formalizing constraint-based itemset mining problems in models, and (2) an infrastructure for executing these models, which supports both specialised mining algorithms as well as generic constraint solving systems. A <b>use</b> <b>case</b> <b>demonstrates</b> the generality of the language, as well as its flexibility towards adding and modifying constraints and data, as well as the use of different solution methods. status: publishe...|$|R
40|$|Web {{services}} {{are supported by}} almost all major software vendors, but nevertheless {{there is still a}} certain barrier that prevents a broader user community to actually use them. The barrier is the lack of appropriate clients offered in conjunction with the services. This paper presents a Web Service Browser that automatically generates a dynamic user interface when the user browses to the location of the service description and additionally handles the invocation of the service. To ease the use of the service, the browser takes care of data management by using an implementation of the Flex-SwA architecture. Results are presented to the user in a human-readable manner. When the result contains multimedia data, an audio or video player is used to present the result. <b>Use</b> <b>cases</b> <b>demonstrate</b> the benefits of the browser. With the Web Service Browser, web services simply become a usable component offered in the WWW. ...|$|R
40|$|Cloud {{computing}} offers services which {{promise to}} meet continuously increasing computing demands {{by using a}} large number of networked resources. However, data heterogeneity remains a major hurdle for data interoperability and data integration. In this context, a Knowledge as a Service (KaaS) approach has been proposed with the aim of generating knowledge from heterogeneous data and making it available as a service. In this paper, a Collaborative Knowledge as a Service (CKaaS) architecture is proposed, with the objective of satisfying consumer knowledge needs by integrating disparate cloud knowledge through collaboration among distributed KaaS entities. The NIST cloud computing reference architecture is extended by adding a KaaS layer that integrates diverse sources of data stored in a cloud environment. CKaaS implementation is domain-specific; therefore, this paper presents its application to the disaster management domain. A <b>use</b> <b>case</b> <b>demonstrates</b> collaboration of knowledge providers and shows how CKaaS operates with simulation models...|$|R
40|$|Due to {{its wide}} use in personal, but most importantly, {{professional}} contexts, email represents a valuable {{source of information}} that can be harvested for understanding, reengineering and repurposing undocumented business processes of companies and institutions. Towards this aim, a few researchers investigated the problem of extracting process oriented information from email logs in order to take benefit of the many available process mining techniques and tools. In this paper we go further in this direction, by proposing a new method for mining process models from email logs that leverage unsupervised machine learning techniques with little human involvement. Moreover, our method allows to semi-automatically label emails with activity names, {{that can be used for}} activity recognition in new incoming emails. A <b>use</b> <b>case</b> <b>demonstrates</b> the usefulness of the proposed solution using a modest in size, yet real-world, dataset containing emails that belong to two different process models. Comment: 18 pages, 6 figure...|$|R
40|$|Hundreds of {{thousands}} of pedestrians are involved in severe traffic accidents every year world-wide. Reasons for these accidents include complex and highly dynamic traffic situations where views are obstructed or unexpected movement occurs. Driver assistance systems are a valid option for increasing pedestrian safety by enhancing the awareness of complex traffic situations and identifying potential dangers. In this work, we present a collision avoidance system based on smart video surveillance and car-to-infrastructure communication. We use a distributed system of monocular cameras to determine the position of both vehicles and pedestrians in realtime. In addition, we utilize standard car- 2 -x communication technology (ETSI ITS G 5) to provide all position detections to the vehicles, thus enabling complex <b>use</b> <b>cases</b> such as warning cascades to drivers in case of oncoming dangers. A detailed evaluation of the proposed system and collision warning <b>use</b> <b>case</b> <b>demonstrates</b> the suitability as assistance system for human drivers. We also show that automatic braking systems would lead to drastic performance improvements due to a significant reduction of reaction times...|$|R
40|$|GridLAB-D is a {{software}} simulation environment that was initially {{developed by the}} US Department of Energy (DOE) Office of Electricity (OE) {{for the purpose of}} enabling the effective analysis of emerging smart grid technologies. In order to achieve this goal GridLAB-D was developed using an open source approach with the intent that numerous people and organizations would contribute to the ongoing development. Because of the breadth and complexity of the emerging smart grid technologies the inclusion of multiple groups of developers is essential in order to address the many aspects of the smart grid. As part of the continuing Modern Grid Strategy (MGS) the Pacific Northwest National Laboratory (PNNL) has been tasked with developing an advanced set of GridLAB-D capabilities. These capabilities were developed to enable the analysis of complex <b>use</b> <b>case</b> studies which will allow for multi-disciplinary analysis of smart grid operations. The advanced capabilities which were developed include the implementation of an unbalanced networked power flow algorithm, the implementation of an integrated transmission and distribution system solver, and a set of <b>use</b> <b>cases</b> <b>demonstrating</b> the capabilities of the new solvers...|$|R
40|$|It is {{essential}} to understand the operation sequences of a production system when designing or changing it. This paper will demonstrate how the software tool Sequence Planner (SP) not only supports this understanding by sequence visualization, but also improves the solution using optimization and verification. SP is a tool for modeling and analyzing automation systems. The tool has been developed since 2007 with an initial focus on supporting engineers when developing control code for programmable logical controllers. Today, SP is a micro-service architecture, usable in various areas like runtime control, online monitoring, energy optimization, and even emergency department patient planning. This paper presents a <b>use</b> <b>case</b> at an automotive company, where the operation sequences in {{a large number of}} automated robot stations, need to be modified. SP, together with virtual commissioning tools, automates this modification by identifying, optimizing, verifying and simulating operation sequences, and then updates the robot and control programs. This <b>use</b> <b>case</b> <b>demonstrates</b> the strength of SP and its architecture and how it is used for integrated virtual preparation and commissioning...|$|R
40|$|This paper {{introduces}} the stack for service delivery models and interoperability in the Internet of Things. The main characteristics and functional {{layers of the}} IoT stack are described. The applicability of the IoT stack is described based on particular <b>use</b> <b>cases</b> and deployed pilots. The validation of the IoT stack in terms of functionality and adaptation at different IoT particular areas {{is based on the}} Virtual Development Kit (VDK) developed and implemented {{within the framework of the}} OpenIoT project - OpenIoT project is the awarded Internet of Things open-source rookie of the year by BlackDuck Software Co. (www. github. com/OpenIotOrg). The methods and standards that boosted OpenIoT-VDK implementation are described in this paper. An instance of the OpenIoT-VDK process is described as the practical <b>use</b> <b>case</b> <b>demonstrating</b> being an IoT platform with autonomic behavior. OpenIoT-VDK creates IoT instances, analyzes the IoT stack dependence, and resolves them following interoperability principles. The OpenIoT-VDK instance deploys IoT service delivery models facilitating the validation of <b>use</b> <b>cases</b> by <b>using</b> the OpenIoT platform. As proof of concept, a delivered IoT service using open data from OpenIoT local instantiation is described...|$|R
40|$|Abstract. Among the {{challenges}} of managing NASA’s information systems is the management (coordination, verification and validation, and enforcement) of many different role-based access control policies and mechanisms. This paper describes an actual data federation <b>use</b> <b>case</b> that <b>demonstrates</b> the inefficiencies created by this challenge and presents an approach to reducing these inefficiencies using OWL. The {{focus is on the}} representation of XACML policies in DL, but the approach generalizes to other policy languages. ...|$|R
40|$|The thesis {{examines}} how current mobile operating systems support context-aware applications and investigates {{the methods of}} mobile application debugging. The thesis points {{out what kind of}} problems need to be solved during debugging of context-aware applications. The primary goal of the thesis is to propose a debugging method which takes context information into account and to implement this method. The thesis contains a real world <b>use</b> <b>case</b> to <b>demonstrate</b> the proposed method...|$|R
