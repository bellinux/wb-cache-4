0|4293|Public
40|$|Training translators to <b>use</b> <b>corpora</b> hands-on: {{challenges}} and reactions {{by a group}} of 13 students at a UK university With the proliferation of online off-the-peg corpora over the past decade or so, the <b>use</b> of <b>corpora</b> is no longer restricted to a small community of researchers working on language description and natural language processing. Anyone with an internet connection is now able to access corpora to help them with everyday questions about language, including questions for which dictionaries, grammars and other language resources do not always have clear answers. Translators are among those who have much to gain from <b>using</b> <b>corpora,</b> as widely acknowledged in the literature (e. g. Zanettin 1998, Bowker and Pearson 2002, Zanettin et al 2003, Beeby et al 2009 and Gallego-Hernández 2015). Yet most of the research at the crossroads of translation and corpora seems to focus on the <b>use</b> of <b>corpora</b> in Translation Studies, and there {{does not seem to be}} enough information on the <b>use</b> of <b>corpora</b> in actual translation training and practice. This paper discusses some of the challenges of training translators to <b>use</b> <b>corpora</b> and then describes how a group of 13 students studying for an MA in Translation at the University of Surrey reacted to a hands-on module on learning to <b>use</b> <b>corpora</b> in everyday translation. The latter is based on the students' responses to a questionnaire given at the end of the teaching period and on a corpus of self-reports containing authentic examples of <b>using</b> <b>corpora</b> in translation practice...|$|R
40|$|In recent years, {{data-driven}} {{methods have}} become increasingly popular in natural language generation. Multimodal generation can also benefit from <b>using</b> <b>corpus</b> data directly; however, there are several issues that arise when <b>using</b> <b>corpora</b> for multimodal generation that do not occur in the unimodal case, and that mean that existing multimodal corpora are often not suitable for being directly used in a generation system. ...|$|R
5000|$|... "From central {{embedding}} to corpus linguistics" [...] in <b>Using</b> <b>Corpora</b> for Language Research (Longman, 1996) ...|$|R
40|$|We {{introduce}} {{the idea of}} <b>using</b> <b>corpora</b> – the linguist’s name for ‘big data’ – in language research, and sketch its history, first in linguistics in general, then in language learning and teaching. We then take a careful look at the hazards of <b>using</b> <b>corpora</b> in language learning, and arrive at some maxims for when and how they have a place: firstly, don’t scare the students; then, <b>use</b> the <b>corpus</b> when the dictionary does not tell you enough, and moreover, disguise the corpus as a dictionary. We then introduce Sketch Engine, and show how it implements these ideas through SKELL, its language-learner interface. We show how <b>corpora</b> can be <b>used,</b> both in the classroom, and in the background, for syllabus design, where we have <b>used</b> <b>corpora</b> of learner output to identify patterns of overuse and underuse, with implications for what needs teaching...|$|R
40|$|With the {{proliferation}} of online off-the-peg corpora {{over the past decade}} or so, the <b>use</b> of <b>corpora</b> is no longer restricted to a small community of researchers working on language description and natural language processing. Anyone with an internet connection is now able to access corpora to help them with everyday questions about language, including questions for which dictionaries, grammars and other language resources do not always have clear answers. Translators are among those who have much to gain from <b>using</b> <b>corpora,</b> as widely acknowledged in the literature (see, for example, Zanettin 1998, Maia 2002, Bowker and Pearson 2002, Zanettin et al 2003, and Beeby et al 2009). Yet in contrast to the pressure that exists to train translators in the use of computer-assisted translation tools, there seems to be little or no incentive to teach translators to <b>use</b> <b>corpora.</b> Moreover, most of the research at the crossroads of translation and corpora seems to focus on the <b>use</b> of <b>corpora</b> in Translation Studies, and there is not yet enough information about the <b>use</b> of <b>corpora</b> in actual translation training and practice. This paper discusses some of the challenges of training translators to <b>use</b> <b>corpora,</b> and then describes how a group of 13 students studying for an MA in Translation at the University of Surrey reacted to a hands-on module on learning to <b>use</b> <b>corpora</b> in everyday translation. The analysis of the students’ reactions draws on (1) their responses to an anonymous questionnaire and (2) a corpus of graded assignments, where the students were required to write a report on their <b>use</b> of <b>corpora</b> in translation (after having been asked from day one to keep a diary with examples of <b>using</b> <b>corpora</b> in their everyday translation practice). The corpus of student reports was submitted to both a quantitative and a qualitative analysis. The quantitative analysis focuses on verifying {{the extent to which the}} students made reference to terms such as concordance, lemma, collocation, part-of-speech tagging, normalized frequency and so on, and the extent to which the actual queries described in the reports involved the use of those concepts. The qualitative analysis details a selection of examples of how different students <b>used</b> <b>corpora</b> and also their views of the experience. The students’ opinions of corpora were generally very favourable, despite the steep learning curve entailed. The analysis also indicated that while some students remained underusers of corpora, others were quite capable of carrying out sophisticated queries that provided them with answers which they would not have been able to find in other more conventional tools and resources...|$|R
50|$|<b>Using</b> <b>corpora</b> and {{elaborate}} statistical methods, the team investigates {{topics such as}} syntactic alterations, linguistic categorization, preposition and verb-preposition constructions, the English noun phrase and others.|$|R
50|$|Machine {{translation}} from corpus linguistics {{is based}} {{in the analysis of}} real samples with its own translations. Among the different devices that <b>use</b> <b>corpus,</b> there are statistical methods and based on examples.|$|R
40|$|We {{investigate}} the automatic detection of sentences containing linguistic hedges <b>using</b> <b>corpus</b> statistics and syntactic patterns. We take Wikipedia as an already annotated <b>corpus</b> <b>using</b> its tagged weasel words which mark sentences and phrases as non-factual. We evaluate {{the quality of}} Wikipedia as training data for hedge detection, as well as shallow linguistic features. ...|$|R
40|$|This {{case study}} {{examines}} {{the influence of}} the <b>use</b> of <b>corpus</b> resources for second language (L 2) proofreading. An advanced English as a Second Language (ESL) student who was studying in an intensive academic English program in the summer of 2011 participated in this study. Specifically, the study focuses on the potential benefits of corpus linguistics with respect to lexical accuracy and aims to (1) describe the student???s proofreading strategies and <b>corpus</b> <b>use</b> when given an opportunity to <b>use</b> <b>corpus</b> technology for proofreading, (2) investigate how training in the use of corpus-based resources influenced the student???s approaches towards proofreading, and (3) describe the student???s perceptions about the corpus resources for L 2 proofreading purposes. A close analysis of patterns in the student???s <b>use</b> of <b>corpus</b> tools, along with interview data, demonstrated the positive impact of the corpus-based approach, such as increased awareness of and interest in lexis, but also revealed the participant???s mixed feelings towards future <b>use</b> of <b>corpus</b> resources...|$|R
40|$|In this paper, {{we present}} an {{experiment}} that {{was led to}} <b>use</b> finite <b>corpora</b> and WebCorp in the classroom with a peadagogic objective that was different from language teaching. WebCorp <b>use</b> and <b>corpus</b> <b>use</b> were embedded in the wider frame of teaching students how to use machine translation, by building a customised dictionary using available tools and resources. The issue of <b>using</b> finite <b>corpora</b> and the Web as a corpus was raised in that frame, and will be discussed. Although there is no simple and definite answer, this issue led students to put the Web into question, as a source or information, and {{to better understand the}} issues at stakes in corpus building and <b>corpus</b> <b>use...</b>|$|R
40|$|How can {{the effects}} of corpora on the {{language}} learning process be effectively assessed? This is an old question which is, however, just as important now as it was ten or twenty years ago. Does <b>corpus</b> <b>use</b> aid students in a measurable way? How does <b>corpus</b> <b>use</b> affect students’ subsequent language use? Is there a marked qualitative difference between the work of students who make <b>use</b> of <b>corpora</b> in their studies {{and those who do}} not? Does <b>corpus</b> <b>use</b> necessarily lead to an improvement in students’ language production? This research reports an ongoing study into phraseological production in advanced learner writing (Philip 2005 a; 2005 b; 2006 /forthcoming); in particular, it investigates <b>corpus</b> <b>use</b> and non-use in a semi-structured writing task. Unlike other studies in the EFL literature, this research examines multiple versions of a single base text, making it possible to observe what effect the <b>use</b> of <b>corpora</b> has on the production of phraseological units in text, rather than in gap-fill sentences or other, more traditional types of elicitation experiment, such as those found in Deignan et al. (1997 and Boers (2000). The rationale behind the present approach is influenced by the <b>use</b> of parallel <b>corpora</b> in translation studies in which multiple versions of single texts – in two or more languages – can be visualised and examined as KWIC concordances. The data presented here has been gathered from five groups of advanced learners between March 2005 and June 2006. The learners, following advanced (C 1) general English courses at the University of Bologna. Four of the groups have <b>used</b> <b>corpora</b> during the course of their studies; of these four groups of corpus users, two have <b>used</b> <b>corpora</b> extensively, and have been taught how to carry out advanced searches (multiple nodes, wildcards, and node plus tag). The fifth group, having had no exposure to language corpora, serves as a control...|$|R
2500|$|... {{corpus delicti}} – other Latin legal term <b>using</b> <b>corpus,</b> here meaning {{the fact of}} a crime having been committed, not {{the body of the}} person being {{detained}} nor (as sometimes inaccurately used) the body of the victim ...|$|R
50|$|Besides pure {{linguistic}} inquiry, corpus linguistics {{had begun}} {{to be applied to}} other academic and professional fields, such as the emerging sub-discipline of law and corpus linguistics, which seeks to understand the meaning of legal texts <b>using</b> <b>corpus</b> data and tools.|$|R
40|$|There is {{increasing}} interest in <b>using</b> <b>corpora</b> in NLG, {{perhaps because of}} the success of corpus-based techniques in other areas of speech and language processing. Many <b>uses</b> of <b>corpora</b> in NLG implicitly assume that the human-authored texts in a corpora are a 'gold standard', in other words that the NLG system should produce texts similar to the corpora texts. However, our experience with several corpora raises questions about this assumption, because human au- thors make mistakes and because different people write differently...|$|R
40|$|The {{purpose of}} the study is to develop and {{evaluate}} a bottom-up approach to extract the specific nursing terms from textual nursing records <b>using</b> <b>corpora</b> comparison. A nursing records corpus was developed as the target corpus, and a newspaper corpus and a medical literature abstracts corpus were developed as the reference corpora. Two filters were established to extract the technical terms and the relative frequency ratio was <b>used</b> for <b>corpora</b> comparison. The issues related to the improvement of both the algorithms and the evaluation methods were discussed...|$|R
40|$|Teaching and Language Corpora (TaLC) {{conferences}} are now {{a well-established}} biennial event. TaLC began at the University of Lancaster sixteen years ago and, after being held there twice, and then successively at the universities of Oxford, Graz, Bologna, Granada, and Paris 7, we are delighted that, for the present occasion, we {{have been asked to}} bring the 8 th Teaching and Language Corpora (TaLC 8) conference to the Instituto Superior de Línguas e Administração in Portugal. The <b>use</b> of <b>corpora</b> in teaching has been growing steadily {{in the past couple of}} decades. This increased interest is reflected in the 110 proposals from 28 different countries that we received for TaLC 8. The present volume is a compilation of the 3 invited talks, 48 papers, 22 posters, 4 software demonstrations and 4 workshops that were finally presented at TaLC 8, Lisbon, between 3 and 6 July 2008. Just by looking at their titles, it is easy to see how diversified and widespread the domain of teaching and language corpora has become. We have presentations about teaching advanced learners as well as beginners, and this includes university students, school children and even pre-schoolers. If in the beginning <b>corpora</b> was <b>used</b> mainly to teach English, on this occasion we also have presentations that draw on corpora of Portuguese, Mandarin, Cantonese, Spanish, Greek, Russian, Ukranian, Persian, Japanese, Czech, French, German, Italian, Lithuanian and Romanian. And it is not just different languages that are represented here, but also different types of languages: academic discourse, classroom discourse, youth language, learner language, translated language and even the discourse of diplomacy and of subtitles. Whereas <b>corpora</b> <b>used</b> to be mostly about the written medium, in TaLC 8 there is no shortage of presentations about corpora and speech. In addition to grammar and lexis, many of the papers in these proceedings are about phraseology, translation, literature and culture. Another point to be made is that this conference is not just about putting existing <b>corpora</b> to <b>use</b> in the classroom, but also about compiling different types of corpora for teaching, exploring novel types of pedagogical tagging, developing accessible corpus tools for education, <b>using</b> <b>corpora</b> for language assessment and training novice users how to <b>use</b> <b>corpora.</b> Of course, not everyone needs to learn how to <b>use</b> <b>corpora.</b> We have here both presentations that focus on the direct <b>use</b> of <b>corpora</b> by learners and presentations about developing data-driven materials which people who have never heard of corpora can benefit from. The content of this volume is also a measure of the direction in which we are heading. It is perfectly clear that language corpora are not being used as an end in itself, but as a means of achieving different educational goals in different educational settings. Our common interest in corpora and teaching has brought together researchers, practitioners and theorists in an unprecedented way. It is not just a question of establishing links with delegates from different countries. TaLC is an opportunity for corpus compilers to meet corpus users, for people developing corpus tools to exchange ideas with people developing corpus-based materials and people <b>using</b> <b>corpora</b> directly in the classroom. It is a chance for researchers working with written corpora to meet those working with spoken <b>corpora,</b> for teachers <b>using</b> <b>corpora</b> of one particular language to talk to teachers <b>using</b> <b>corpora</b> of other languages, for people interested in teaching literature to meet people interested in error analysis. These proceedings are a reflection of the fruitful exchange of ideas that will have taken place during TaLC 2008...|$|R
40|$|The {{article is}} aimed {{to resume the}} results of the {{analysis}} of western pedagogical experience of <b>using</b> <b>corpora</b> for language teaching. The main types and methods are picked out and the useful distinction is made between direct and indirect corpora applications while training languages for special purposes...|$|R
40|$|Several ESP (English for Specific Purposes) {{scholars}} <b>use</b> <b>corpus</b> {{data for}} practical purposes. The findings are diverse, and contribute empirical evidence to establish categories of word use and collocations (eg Luzón Marco 2000), {{and to offer}} detailed lexical profiles in specific subject areas (eg Nelson 2000). Th...|$|R
50|$|Shortly thereafter, Boston {{publisher}} Houghton-Mifflin approached Kučera {{to supply}} a million word, three-line citation base {{for its new}} American Heritage Dictionary. This ground-breaking new dictionary, which first appeared in 1969, was the first dictionary to be compiled <b>using</b> <b>corpus</b> linguistics for word frequency and other information.|$|R
50|$|The AHD broke ground among {{dictionaries}} by <b>using</b> <b>corpus</b> linguistics for compiling word {{frequencies and}} other information. It took the innovative step of combining prescriptive information (how language should be used) and descriptive information (how {{it actually is}} used). The descriptive information was derived from actual texts.|$|R
40|$|We {{performed}} corpus correction on an annotated corpus for {{machine translation}} using machine-learning {{methods such as}} the maximum-entropy method. We thus constructed a high-quality annotated corpus based on corpus correction. We compared several di#erent methods of corpus correction in our experiments and developed a suitable method for correction. Recently, corpus-based machine translation has been investigated. Since corpus-based machine translation <b>uses</b> <b>corpora,</b> the corpus correction we discuss in this paper should prove to be significant. ...|$|R
30|$|However, not {{all types}} of {{learners}} like this learning approach (Gilmore 2009), {{there are still some}} learners tired of <b>using</b> <b>corpora</b> for revision tasks by saying that “I like Baidu better since I can usually get a direct answer about how to correct errors by simply typing in an expression or a sentence.” Many Chinese EFL learners have already been accustomed to being directly told how to correct errors in writing in their prior school career, so the new exploratory approach may not appeal to them. Nevertheless, a majority of the interviewees responded that “we are more willing to <b>use</b> <b>corpora</b> in many cases and will continue to use it in the future writing”. When being asked about the problems they encountered while <b>using</b> <b>corpora</b> for revision tasks, almost all of them mentioned that they often feel frustrated when failing to get what they want after doing several queries in the corpora. They emphasized that “lack of concordance technique” and “lack of ability to induce language rules” brought trouble to them. Furthermore, they still expressed that they can hardly get the desirable results when trying to find out an English equivalent for an expression in Chinese. Just as stated by Sha (2010), DDL approach is not effective in helping learners paraphrase exactly what they try to express in a second language. This is really a limitation of merely <b>using</b> <b>corpora</b> in DDL, and maybe it can be solved by integrating other reference resources into corpora. Although time-consuming is another problem mentioned by them, most of them think it’s OK because they consulted corpora out of class which makes them make better use of their free time, or they may waste it in doing some other meaningless things.|$|R
40|$|Context: Software Engineering {{research}} {{makes use}} of collections of software artifacts (corpora) to derive empirical evidence from. Goal: To improve quality and reproducibility of research, {{we need to understand}} the characteristics of <b>used</b> <b>corpora.</b> Method: For that, we perform a literature survey using grounded theory. We analyze the latest proceedings of seven relevant conferences. Results: While almost all papers <b>use</b> <b>corpora</b> of some kind with the common case of collections of source code of open-source Java projects, there are no frequently <b>used</b> projects or <b>corpora</b> across all the papers. For some conferences we can detect recurrences. We discover several forms of requirements and applied tunings for corpora which indicate more specific needs of research efforts. Conclusion: Our survey feeds into a quantitative basis for discussing the current state of empirical research in software engineering, thereby enabling ultimately improvement of research quality specifically in terms of use (and reuse) of empirical evidence. Comment: 10 page...|$|R
40|$|The article {{shows some}} {{preliminary}} {{results of the}} study of the temporal adverb immediately <b>using</b> <b>corpus</b> methodology. The analysis of empirical data revealed the interdependency of some senses and syntactical patterns as well as a grammatical construction which has not been mentioned in English grammar books so far...|$|R
30|$|Compared to the {{advancement}} of English lexicography through <b>using</b> <b>corpora,</b> there are limited successful cases in Chinese lexicography (Huang et al. 黃居仁等 1997; Su 苏新春 2006; Yu et al. 俞士汶等 2003). Past survey on Chinese lexicography underlined the conservative nature and lack of adaptation of corpora and other technological innovations (Huang et al. 2016). Even some recent work on how to discriminate near synonyms is mainly based on introspection, referring to a corpus only, rather than making full <b>use</b> of <b>corpus</b> data, such as (Zhao et al. 赵新等 2014).|$|R
40|$|Referential {{coherence}} {{represents the}} smoothness of discourse resulting from topic continuity and pronominalization. Rational individuals prefer a referentially coherent structure of discourse when they select a language expression and its interpretation. This is {{a preference for}} cooperation in communication. By what principle do they share coherent expressions and interpretations? Centering theory is the standard theory of referential coherence [Grosz et al. 1995]. Although it is well designed on the bases of first-order inference rules [Joshi and Kuhn 1979], it does not embody a behavioral principle for the cooperation evident in communication. Hasida [1996] proposed a game-theoretic hypothesis in relation to this issue. We aim to empirically verify Hasida’s hypothesis by <b>using</b> <b>corpora</b> of multiple languages. We statistically design language-dependent parameters by <b>using</b> a <b>corpus</b> of the target language. This statistical design enables us to objectively absorb language-specific differences and to verify the universality of Hasida’s hypothesis by <b>using</b> <b>corpora.</b> We empirically verified our model by using large Japanese and English corpora. The result proves the language universality of the hypothesis...|$|R
40|$|The paper aims at {{exploring}} the linguistic resources through which historians project futurity in their disciplinary discourse. By <b>using</b> <b>corpus</b> evidence from {{a collection of}} specialised research articles, results reveal a complex network of rhetorical strategies behind the use ofphraseology embedding futurity: for instance, the construction of disciplinary authority and credibilit...|$|R
40|$|Second {{language}} acquisition (SLA) research has traditionally relied on elicited experimental data, {{and it has}} disfavoured natural language <b>use</b> data. Learner <b>corpus</b> research {{has the potential to}} change this but, to date, the research has contributed little to the interpretation of L 2 acquisition, and some of the corpora are flawed in design. We analyse the reasons why many SLA researchers are still reticent about <b>using</b> <b>corpora,</b> and how good corpus design and adequate tools to annotate and search corpora can help overcome some of the problems observed. We do so by describing how the ten standard principles <b>used</b> in <b>corpus</b> design (Sinclair 2005) were applied to the design of CEDEL 2, a large learner corpus of L 1 English ??? L 2 Spanish (Lozano 2009 a) ...|$|R
40|$|The goal of Sentiment Slot Filling is to <b>use</b> <b>corpora</b> {{to collect}} {{information}} regarding sentiment expressed towards or by an entity. Sentiment is defined here as a positive or negative emotion, evaluation, or judgement. Entities may be a person (PER), organization (ORG), or a geopolitical entity (GPE). This task explores the sentiment triple...|$|R
50|$|Shortly after {{publication}} of the first lexicostatistical analysis, Boston publisher Houghton-Mifflin approached Kučera to supply a million word, three-line citation base for its new American Heritage Dictionary. This ground-breaking new dictionary, which first appeared in 1969, was the first dictionary to be compiled <b>using</b> <b>corpus</b> linguistics for word frequency and other information.|$|R
50|$|Shortly thereafter, Boston {{publisher}} Houghton-Mifflin approached Kučera {{to supply}} a million-word, three-line citation base {{for its new}} American Heritage Dictionary, the first dictionary to be compiled <b>using</b> <b>corpus</b> linguistics. The AHD took the innovative step of combining prescriptive elements (how language should be used) with descriptive information (how it actually is used).|$|R
40|$|The <b>use</b> of <b>corpora</b> in {{language}} teaching {{is an important}} topic, since practice is aimed at ensuring that the teaching material {{is focused on the}} language in use. The process of creating activities for language teaching can be improved by <b>using</b> <b>corpus</b> data and computational tools in linguistic analysis. This study describes a system for text analysis and automatic creation of English reading activities. The results show that the system allows the development of teaching materials that focus on language in use and it also provides varied linguistic analysis, with less human effort, to the task of developing reading activities...|$|R
40|$|We {{describe}} a biographical multidocument summarizer that summarizes information about people {{described in the}} news. The summarizer <b>uses</b> <b>corpus</b> statistics along with linguistic knowledge to select and merge descriptions of people from a document collection, removing redundant descriptions. The summarization components have been extensively evaluated for coherence, accuracy, and non-redundancy of the descriptions produced...|$|R
50|$|A word sketch triple is {{a triple}} {{consisting}} of headword, grammatical relation, collocation (e.g. man, modifier, young).Considering an underlying text corpus, a word sketch quintuple is a quintuple consisting of headword, grammatical relation, collocation, position of headword in the corpus, position of collocation in the corpus (e.g. man, modifier, young, 104, 103).A word sketch database {{is a set}} of such triples or quintuples, which may be generated either by querying a <b>corpus</b> <b>using</b> <b>corpus</b> query language or by parsing the <b>corpus</b> <b>using</b> a natural language parser.|$|R
50|$|Elena Semino (born 9 September 1964) is an Italian-born British {{linguist}} whose research involves stylistics and metaphor theory. Focusing on {{figurative language}} {{in a range}} of poetic and prose works, most recently she has worked on topics from the domains of medical humanities and health communication. Her projects <b>use</b> <b>corpus</b> linguistic methods as well as qualitative analysis.|$|R
40|$|Domain {{specific}} texts {{often have}} implicit rules on content and organization. We introduce a novel method for synthesizing this topical structure. The system <b>uses</b> <b>corpus</b> examples and recursively merges their topics {{to build a}} hierarchical tree. A subjective cross domain evaluation showed that the system performed well in combining related topics and in highlighting important ones...|$|R
