8|33|Public
50|$|Recursive {{indexing}} with a 2-letter alphabet {{is called}} <b>unary</b> <b>code.</b>|$|E
40|$|Dynamic unary {{encoding}} takes unary encoding to {{the next}} level. Every n-bit binary string is an encoding of dynamic unary and every n-bit binary string is encodable by dynamic unary. By utilizing both forms of <b>unary</b> <b>code</b> and a single bit of parity information dynamic unary encoding partitions 2 ^n non-negative integers into n sets of disjoint cycles of n-bit elements. These cycles have been employed as virtual data sets, binary transforms and as a mathematical object. Characterization of both the cycles and of the cycle spectrum is given. Examples of encoding and decoding algorithms are given. Examples of other constructs utilizing the principles of dynamic unary encoding are presented. The cycle as a mathematical object is demonstrated. Comment: Seven pages of text, two pages of flow charts and two pages of data. Introduces an encoding scheme and a mathematical objec...|$|E
40|$|A field {{computer}} is a (spatial) continuum-limit neural net (MacLennan 1987). We investigate field computers whose temporal dynamics is also continuum-limit, being governed by an integro-differential equation. We prove {{that even when}} they are purely linear, such systems are computationally universal. The "trick" used to get such universal (and therefore in general nonlinear) behavior is quite similar to the way nonlinear macroscopic physics arises from the purely linear microscopic physics of Schrodinger's equation: one interprets the system in a non-linear way. In this paper, we show that simply using a <b>unary</b> <b>code</b> for the interpretation suffices. See Wolpert and MacLennan (1993) for full details and additional material. 1 A purely linear continuum-limit neural net The most natural way to extend conventional neural nets to the continuum limit in the set of neurons is to invoke the concept of a "field", that is a real-valued function on an n-dimensional Euclidean space (MacLennan 1987) [...] ...|$|E
40|$|<b>Unary</b> <b>coding</b> {{has found}} {{applications}} in data compression, neural network training, and {{in explaining the}} production mechanism of birdsong. <b>Unary</b> <b>coding</b> is redundant; therefore it should have inherent error correction capacity. An expression for the error correction capability of <b>unary</b> <b>coding</b> for the correction of single errors has been derived in this paper. Comment: 7 pages, 5 figure...|$|R
50|$|A {{generalized}} {{version of}} <b>unary</b> <b>coding</b> {{is able to}} represent numbers much more efficiently than standard <b>unary</b> <b>coding.</b> Here's an example of generalized <b>unary</b> <b>coding</b> for integers from 1 through 15 that requires only 7 bits (where three bits are arbitrarily chosen {{in place of a}} single one in standard unary to show the number). Note that the representation is cyclic where one uses markers to represent higher integers in higher cycles.Generalized <b>unary</b> <b>coding</b> requires that the range of numbers to be represented be pre-specified because this range determines the number of bits that are needed.|$|R
40|$|<b>Unary</b> <b>coding</b> {{is useful}} {{but it is}} {{redundant}} in its standard form. <b>Unary</b> <b>coding</b> {{can also be seen}} as spatial coding where the value of the number is determined by its place in an array. Motivated by biological finding that several neurons in the vicinity represent the same number, we propose a variant of unary numeration in its spatial form, where each number is represented by several 1 s. We call this spread <b>unary</b> <b>coding</b> where the number of 1 s used is the spread of the <b>code.</b> Spread <b>unary</b> <b>coding</b> is associated with saturation of the Hamming distance between code words. Comment: 5 pages, 2 figure...|$|R
40|$|An ideal Visible Light Communication (VLC) {{system should}} {{facilitate}} reliable data transmission at high throughputs, while also providing flicker-free illumination at the user-defined dimming level. In this spirit, we conceive a <b>unary</b> <b>code</b> aided dimming scheme for On-Off Keying (OOK) modulated VLC systems. The proposed unary-coded scheme facilitates joint dimming and throughput control, while relying on iterative decoding. It is {{demonstrated that the}} proposed unary-coded dimming scheme provides attractive throughput gains over its contemporaries {{and it is also}} capable of approaching the theoretical throughput limit. Furthermore, we design novel joint dimming-Forward Error Correction (FEC) coding schemes, which significantly outperform their compensation time dimming based counterparts in terms of the attainable Bit Error Rate (BER) performance as well as the throughput. Finally, in the quest for approaching the capacity, we also optimize our system using EXtrinsic Information Transfer (EXIT) charts and demonstrate an SNR-gain of up to 6 dB over the compensation time dimming based classic benchmarker...|$|E
40|$|HEVC {{implements}} {{a candidate}} vector list for merge and skip modes. When merge or skip modes are selected, a merge index {{is written in}} the bitstream. This index is first binarized using a <b>unary</b> <b>code,</b> then CABAC encoded. A CABAC context {{is dedicated to the}} first bin of the unary coded index while the remaining bins are considered as equiprobable. This strategy is efficient as long as the candidate list is constructed such as being ordered by decreasing index occurrence probability. In the context of 3 D video encoding, an inter-view motion vector predictor is added at the first position of the candidate list. It is reported in this document that the inter-view motion vector predictor is not always the most probable candidate. It actually depends on the video sequence characteristics. Therefore, a dynamic candidate vector list ordering is proposed. Coding gains of 0. 1 % on average are observed on side views and up to 0. 6 % is attained for the GTFly sequence view 2. ...|$|E
40|$|International audienceThis paper {{presents}} one of {{the first}} methods allowing the protection of the newly emerging video codec HEVC (High Efficiency Video Coding). Visual protection is achieved through selective encryption (SE) of HEVC-CABAC binstrings in a format compliant manner. The SE approach developed for HEVC is different from that of H. 264 /AVC in several aspects. Truncated rice code is introduced for binarization of quantized transform coefficients (QTCs) instead of truncated <b>unary</b> <b>code.</b> The encryption space (ES) of binstrings of truncated rice codes is not always dyadic and cannot be represented by an integer number of bits. Hence they cannot be concatenated together to create plaintext for the CFB (Cipher Feedback) mode of AES, which is a self-synchronizing stream cipher for so-called AES-CFB. Another challenge for SE in HEVC concerns the introduction of context, which is adaptive to QTC. This work presents a thorough investigation of HEVC-CABAC from an encryption standpoint. An algorithm is devised for conversion of non-dyadic ES to dyadic, which can be concatenated to form plaintext for AES-CFB. For selectively en-crypted binstrings, the context of truncated rice code for binarization of future syntax elements is guaranteed to remain unchanged. Hence the encrypted bitstream is format-compliant and has exactly the same bit-rate. The proposed technique requires very little processing power and is ideal for playback on hand held devices. The proposed scheme is acceptable for DRM {{of a wide range of}} applications, since it protects the contour and motion information, along with texture. Several benchmark video sequences of different resolutions and diverse contents were used for experimental evaluation of the proposed algorithm. A detailed security analysis of the proposed scheme verified the validity of the proposed encryption scheme for content protection in a wide range of applications...|$|E
50|$|Research {{has shown}} that <b>unary</b> <b>coding</b> {{is used in the}} neural {{circuits}} responsible for birdsong production. The use of unary in biological networks is presumably due to the inherent simplicity of the coding. Another contributing factor could be that <b>unary</b> <b>coding</b> provides a certain degree of error correction.|$|R
5000|$|Golomb coding uses a tunable {{parameter}} [...] {{to divide}} an input value [...] into two parts: , {{the result of}} a division by , and , the remainder. The quotient is sent in <b>unary</b> <b>coding,</b> followed by the remainder in truncated binary encoding. When [...] Golomb coding is equivalent to <b>unary</b> <b>coding.</b>|$|R
5000|$|Instantaneously trained neural {{networks}} use <b>unary</b> <b>coding</b> for efficient data representation.|$|R
40|$|It {{is known}} that the entire {{geometrical}} theory of a relativistic space-time {{can be summed up}} in two concepts, a space-time measure /J and a space-time causal or chronological order relation C; in brief, a causal measure space. On grounds of finiteness, unity and symmetry, we argue that the observed macroscopic space-time may be the classical-geometrical limit of a causal quantum space. The necessary conceptual framework is provided. Mathematical individuals that naturally form causal spaces are symbol sets ordered by inclusion. The natural extension of this purely logical concept to quantum symbols is formulated. The problem is posed to give finite quantum rules for the generation of quantum symbol sets such that the order of generation becomes, in the classical limit, the causal order of space-time; as it were, to break the space-time code. The causal quantum spaces of three simple codes are generated for comparison with reality. The <b>unary</b> <b>code</b> (repetitions of one digit) gives a linear] ordered external world of one time dimension and a circular internal space. The binary code gives the future null-cone of special relativity and a cii alar internal space. The causal quantum space of "words " (sets of characters) 2 2 2 1 / 2 in the binary code gives the solid light cone t> (x +y + z) ' of special relativity and an internal space U(2, C) suitable for the description of charge and isospin. There is full translational and proper Lorentz invariance except at the boundary of the light cone, where the classical-geometrical limit fails. Plausible consequences of this model for cosmology and elementary particles are discussed. There is a quantum of time T on the order of-n/m c, and the space-time complementarity relatio...|$|E
40|$|Shannon’s source-channel coding {{separation}} theorem {{states that}} near-capacity communication is theoretically possible, when employing Separate Source and Channel Codes (SSCCs), provided that an unlimited encoding/decoding delay and complexity can be afforded. However, it is typically impossible {{to remove all}} source redundancy {{with the aid of}} practical finite-delay and finite-complexity source encoding, which leads to capacity loss. As a potential remedy, Joint Source and Channel Codes (JSCCs) have been proposed for exploiting the residual redundancy and hence for avoiding any capacity loss. However, all previous JSCCs have been designed for representing symbols values that are selected from a set having a low cardinality and hence they suffer from an excessive decoding complexity, when the cardinality of the symbol value set is large, leading to an infinite complexity, when the cardinality is infinite. Motivated by this, we propose the family of Unary Error Correction (UEC), Elias Gamma Error Correction (EGEC) and Reordered Elias Gamma Error Correction (REGEC) codes in this thesis. Our family of codes belong to the JSCC class designed to have only a modest complexity that is independent of the cardinality of the symbol value set. We exemplify the application of each of the codes {{in the context of a}} serially concatenated iterative decoding scheme. In each coding scheme, the encoder generates a bit sequence by encoding and concatenating codewords, while the decoder performs iterative decoding using the classic Logarithmic Bahl, Cocke, Jelinek and Raviv (Log-BCJR) algorithm. Owing to this, our proposed codes are capable of mitigating any potential capacity loss, hence facilitating near-capacity operation. Our proposed UEC code is the first JSCC that maintains a low decoding complexity, when invoked for representing symbol values that are selected from a set having large or even infinite cardinality. The UEC trellis is designed to describe the unary codewords so that the transitions between its states are synchronous with the transitions between the consecutive codewords in the bit sequence. The <b>unary</b> <b>code</b> employed in the UEC code has a simple structure, which can be readily exploited for error correction without requiring an excessive number of trellis transitions and states. However, the UEC scheme has found limited applications, since the <b>unary</b> <b>code</b> is not a universal code. This motivates the design of our EGEC code, which is the first universal code in our code family. The EGEC code relies on trellis representation of the EG code, which is generated by decomposing each symbol into two sub-symbols, for the sake of simplifying the structure of the EG code. However, the reliance on these two parts requires us to carefully tailor the Unequal Protection (UEP) of the two parts for the specific source probability distribution encountered, whilst the actual source distribution may be unknown or non-stationary. Additionally, the complex structure of the EGEC code may impose further disadvantages associated with an increased decoding delay, loss of synchronisation, capacity loss and increased complexity due to puncturing. This motivates us to propose a universal JSCC REGEC code, which has a significantly simpler structure than the EGEC code. The proposed codes were benchmarked against SSCC benchmarkers throughout this thesis and they were found to offer significant gains in all cases. Finally, we demonstrate that our code family proposed in this thesis can be extended by several potential directions. The sophisticated techniques that have been subsequently proposed in the thesis for extending the UEC code, such as irregular trellis designs and the adaptive distribution-learning algorithm, can be readily applied to the REGEC codes which is an explicit benefit of its simple trellis structure. Furthermore, our proposed REGEC code can be extended using techniques that been subsequently proposed for extending the EGEC both to Rice Error Correction (RiceEC) codes and to Exponential Golomb Error Correction (ExpGEC) codes...|$|E
5000|$|Golomb coding, {{which has}} Rice <b>coding</b> and <b>unary</b> <b>coding</b> as special cases.|$|R
5000|$|<b>Unary</b> <b>coding</b> is an optimally {{efficient}} encoding for {{the following}} discrete probability distribution ...|$|R
40|$|Extended {{variants}} {{of the recently}} introduced spread <b>unary</b> <b>coding</b> are described. These schemes, in which {{the length of the}} code word is fixed, allow representation of approximately n^ 2 numbers for n bits, rather than the n numbers of the standard <b>unary</b> <b>coding.</b> In the first of two proposed schemes the spread increases, whereas in the second scheme the spread remains constant. Comment: 5 page...|$|R
5000|$|Rice coding, {{which is}} used in the FLAC audio codec and which has <b>unary</b> <b>coding</b> as a special case ...|$|R
50|$|<b>Unary</b> <b>coding,</b> {{sometimes}} called thermometer code, is an entropy encoding {{that represents a}} natural number, n, with n ones followed by a zero (if natural number is understood as non-negative integer) or with n &minus; 1 ones followed by a zero (if natural number is understood as strictly positive integer). For example 5 is represented as 111110 or 11110. Some representations use n or n &minus; 1 zeros followed by a one. The ones and zeros are interchangeable without loss of generality. <b>Unary</b> <b>coding</b> is both a prefix-free code and a self-synchronizing code.|$|R
5000|$|Their nonuniversality can be {{observed}} by noticing that, {{if any of these}} are used to code the Gauss-Kuzmin distribution or the Zeta distribution with parameter s=2, expected codeword length is infinite. For example, using <b>unary</b> <b>coding</b> on the Zeta distribution yields an expected length of ...|$|R
40|$|Often, the {{addition}} of metric operators to qualitative temporal logics leads to an increase {{of the complexity of}} satisfiability by at least one exponential. In this paper, we exhibit a number of metric extensions of qualitative temporal logics of the real line that do not lead to an increase in computational complexity. We show that the language obtained by extending since/until logic of the real line with the operators ‘sometime within n time units’, n coded in binary, is PSPACE-complete even without the finite variability assumption. Without qualitative temporal operators the complexity of this language turns out to depend on whether binary or <b>unary</b> <b>coding</b> of parameters is assumed: it is still PSPACE-hard under binary coding but in NP under <b>unary</b> <b>coding.</b> ...|$|R
50|$|Two of {{the most}} common entropy {{encoding}} techniques are Huffman coding and arithmetic coding.If the approximate entropy characteristics of a data stream are known in advance (especially for signal compression), a simpler static code may be useful.These static codes include universal codes (such as Elias gamma coding or Fibonacci coding) and Golomb <b>codes</b> (such as <b>unary</b> <b>coding</b> or Rice coding).|$|R
50|$|<b>Unary</b> <b>coding</b> {{is used in}} {{the neural}} {{circuits}} responsible for birdsong production. The nucleus in the brain of the songbirds that plays a part in both the learning and the production of bird song is the HVC (high vocal center). This coding works as space coding which is an efficient strategy for biological circuits due to its inherent simplicity and robustness.|$|R
40|$|This paper proposes an optimum {{version of}} the {{recently}} advanced scheme for generalized <b>unary</b> <b>coding.</b> In this method, the block of 1 s that identifies the number is allowed to be broken up, which extends the count. The result is established by a theorem. The number count is now n(n-k- 1) + 1 rather than the previously described (n-k) (n-k) - 1. Comment: 7 pages, 2 figure...|$|R
40|$|AbstractWe {{present a}} {{decision}} procedure for the description logic SHIQ {{based on the}} basic superposition calculus, and show that it runs in exponential time for <b>unary</b> <b>coding</b> of numbers. To derive our algorithm, we extend basic superposition with a decomposition inference rule, which transforms conclusions of certain inferences into equivalent, but simpler clauses. This rule {{can be used for}} general first-order theorem proving with any resolution-based calculus compatible with the standard notion of redundancy...|$|R
40|$|AbstractThe {{notion of}} an L code is {{introduced}} as a generalization of the customary notion of a code. Attention is focused on <b>unary</b> L <b>codes.</b> where the target alphabet consists of one letter only. <b>Unary</b> L <b>codes</b> can be identified with such number systems where the representation is unique. Surprisingly many unary morphisms are L codes. Furthermore, even for non-L-codes {{there is only one}} ‘exceptional length’ We also give a complete classification for the binary case...|$|R
40|$|The pattern {{recognition}} processor performs digital vector matrix multiplication using internally analog fine-grain parallel computing. The three-transistor CID/DRAM unit cell combines single-bit dynamic storage, binary multiplication, and zero-latency analog accumulation. Delta-sigma analogto-digital {{conversion of the}} analog array outputs is combined with oversampled <b>unary</b> <b>coding</b> of the digital inputs. The 256 ¢ 128 CID/DRAM processor with integrated 128 deltasigma ADCs measures 3 mm ¢ 3 mm in 0. 5 £ m CMOS and delivers 1. 1 GMACS/mW...|$|R
40|$|AbstractIn many cases, the {{addition}} of metric operators to qualitative temporal logics (TLs) increases the complexity of satisfiability {{by at least one}} exponential: while common qualitative TLs are complete for NP or PSpace, their metric extensions are often ExpSpace-complete or even undecidable. In this paper, we exhibit several metric extensions of qualitative TLs of the real line that are at most PSpace-complete, and analyze the transition from NP to PSpace for such logics. Our first result is that the logic obtained by extending since-until logic of the real line with the operators ‘sometime within n time units in the past/future’ is still PSpace-complete. In contrast to existing results, we also capture the case where n is coded in binary and the finite variability assumption is not made. To establish containment in PSpace, we use a novel reduction technique that {{can also be used to}} prove tight upper complexity bounds for many other metric TLs in which the numerical parameters to metric operators are coded in binary. We then consider metric TLs of the reals that do not offer any qualitative temporal operators. In such languages, the complexity turns out to depend on whether binary or <b>unary</b> <b>coding</b> of parameters is assumed: satisfiability is still PSpace-complete under binary coding, but only NP-complete under <b>unary</b> <b>coding...</b>|$|R
40|$|International audienceIn {{this paper}} we address the class of anti-uniform Huffman (AUH) <b>codes,</b> also named <b>unary</b> <b>codes,</b> for sources with finite and {{infinite}} alphabet, respectively. Geometric, quasi-geometric, Fibonacci and exponential distributions lead to anti-uniform sources for some ranges of their parameters. Huffman coding of these sources results in AUH codes. We prove that, in general, sources with memory are obtained as result of this encoding. For these sources we attach the graph and determine the transition matrix between states, the state probabilities and the entropy. We also compute the average cost for these AUH codes...|$|R
50|$|Instantaneously trained neural {{networks}} are feedforward artificial {{neural networks}} {{that create a}} new hidden neuron node for each novel training sample. The weights to this hidden neuron separate out not only this training sample but others that are near it, thus providing generalization. This training {{can be done in}} a variety of ways and the most popular network in this family is called the CC4 network where the separation is done using the nearest hyperplane that can be written down instantaneously. These networks use <b>unary</b> <b>coding</b> for an effective representation of the data sets.|$|R
50|$|In {{information}} retrieval, bit arrays {{are a good}} representation for the posting {{lists of}} very frequent terms. If we compute the gaps between adjacent values in a list of strictly increasing integers and encode them using <b>unary</b> <b>coding,</b> {{the result is a}} bit array with a 1 bit in the nth position if and only if n is in the list. The implied probability of a gap of n is 1/2n. This is also the special case of Golomb coding where the parameter M is 1; this parameter is only normally selected when -log(2-p)/log(1-p) ≤ 1, or roughly the term occurs in at least 38% of documents.|$|R
5000|$|In Golomb Rice <b>code,</b> <b>unary</b> {{encoding}} is used {{to encode}} the quotient part of the Golomb code word.|$|R
40|$|Abstract — The mixed-signal {{processor}} performs digital vectormatrix multiplication using internally analog fine-grain parallel computing. The three-transistor CID/DRAM {{unit cell}} combines single-bit dynamic storage, binary multiplication, and zerolatency analog accumulation. Matrix coefficients {{are stored in}} a bit-parallel form. Delta-sigma analog-to-digital conversion of the analog array outputs is combined with oversampled <b>unary</b> <b>coding</b> of the digital inputs. Sorting of unary inputs results in at most a single input line transition for arbitrary multi-bit inputs. This amounts to a linear gain in energy efficiency of the computational array {{in the number of}} bits of the input vector. The 256 × 128 CID/DRAM processor with integrated 128 deltasigma ADCs measures 3 mm × 3 mm in 0. 5 µm CMOS and delivers 6. 5 GMACS dissipating 5. 9 mW of power. CID/DRAM array dynamic power dissipation is reduced by a factor of four through sorting 8 -bit inputs. I...|$|R
40|$|As {{applications}} of description logics proliferate, efcient reasoning with large ABoxes (sets {{of individuals with}} de-scriptions) becomes ever more important. Motivated by the prospects of reusing optimization techniques from deduc-tive databases, in this paper, we present a novel approach to checking consistency of ABoxes, instance checking and query answering, w. r. t. ontologies formulated using a slight restriction of the description logic SHIQ. Our approach pro-ceeds in three steps: (i) the ontology is translated into rst-order clauses, (ii) TBox and RBox clauses are saturated using a resolution-based decision procedure, and (iii) the saturated set of clauses is translated into a disjunctive datalog program. Thus, query answering can be performed using the resulting program, while applying all existing optimization techniques, such as join-order optimizations or magic sets. Equally im-portant, the resolution-based decision procedure we present is for <b>unary</b> <b>coding</b> of numbers worst-case optimal, i. e. it runs in EXPTIME...|$|R
40|$|The {{advantages}} and disadvantages of classical rule-based and neural approaches to expert system design are complementary. We propose a strictly neural expert system architecture, that enables the creation of the knowledge base automatically, by learning from example inferences. For this purpose we employ a multi-layered neural network, trained with generalized back propagation for interval training patterns, that also makes the learning of patterns with irrelevant inputs and outputs possible. We eliminate the disadvantages of the neural approach by enriching the system with the heuristics to work with incomplete information, and to explain the conclusions. The structure of the expert attributes is optional, and a user of the system can define the types of inputs and outputs (real, integer, scalar type, and set), and the manner of their coding (floating point, binary, and <b>unary</b> <b>codes).</b> We have tested our neural expert system on several non-trivial real-world problems (e. g., the diagnost [...] ...|$|R
40|$|We {{investigate}} the computational complexity of optimal solutions, when the costs can be bounded by a polynomial, i. e. can be <b>unary</b> <b>coded.</b> Here, we revisit the computation problem OptP[log n], introduced by [K 88] {{and the search}} problem, called NP bOpt by [BKT 94]. In this paper we investigate corresponding classes uMaxP and NPuMax {{as well as more}} general formulations of optimization problems: uOptP and NP uOpt. These classes turn out to form the metric closure Γ 1 -T of the maximization classes. For this we introduce adapted reductions, where for instance we tighten the reduction model of search problems to the so-called strong reduction, where the solution space is completely covered by the mapping of the reduction, and show that completeness and closure results still hold. Many properties of nondeterministic Turing machines (NTM) like time or the number of guesses can be used to describe the class uMaxP. For this we refer to Krentel's proof of the correspondence of uMaxP to th [...] ...|$|R
