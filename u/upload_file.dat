13|906|Public
5000|$|Documents - Provides content {{management}} and storage capabilities, including content <b>upload,</b> <b>file</b> and folder creation and management, file check out, versioning, and so on. WebCenter Portal includes a restricted-use license of Oracle's enterprise content management product called WebCenter Content (formerly known as Universal Content Management) ...|$|E
50|$|Stage6 {{accepted}} DivX or Xvid encoded files up to 1080p60. Stage6 rejected encoded videos not {{mixed with}} MP2 or MP3 audio. <b>Upload</b> <b>file</b> size limit {{for an individual}} video was 2 Gigabytes. The download speeds from Stage6 ranged up to and above 16 MBit/s.|$|E
50|$|Google {{previously}} ran {{a project}} hosting service called Google Code that provided revision control offering Subversion, Mercurial and Git (transparently implemented using BigTable as storage), an issue tracker, and a wiki for documentation. The service was available and free for all OSI-approved Open Source projects (as of 2010, it was strongly recommended {{but no longer}} required {{to use one of}} the nine well-known open source licenses: Apache, Artistic, BSD, GPLv2, GPLv3, LGPL, MIT, MPL and EPL). The site limited the number of projects one person could have to 25. Additionally, there was a limit on the number of projects that could be created in one day, a 200 MB default <b>upload</b> <b>file</b> size limit, which could be raised, and a 5 GB per-project total size limit. The service provided a file download feature, but on May 2013 the creation of new downloads was disabled, with plans to disable it altogether on January 14, 2014. In March 2015, Google announced that it would be closing down Google Code on January 15, 2016. All projects on the site entered read-only mode on August 24, 2015, with the exception of certain Google-owned projects including Android and Chrome.|$|E
5000|$|MediaWiki stores <b>uploaded</b> <b>files</b> in {{directories}} {{with names}} {{derived from the}} base-36 representation of an <b>uploaded</b> <b>file's</b> checksum.|$|R
50|$|Since {{anyone can}} <b>upload</b> <b>files</b> to the website, all <b>uploaded</b> <b>files</b> {{have to go}} through a manual {{screening}} process where they are checked for integrity and quality by site staff.|$|R
50|$|Neembuu Uploader (also {{known as}} NU) {{is a highly}} {{portable}} free and open-source Java application that <b>uploads</b> <b>files</b> simultaneously to multiple filehosts. It is currently supporting 67 file hosting sites and lets you manage the download and delete URLs of the <b>uploaded</b> <b>files.</b>|$|R
3000|$|... that {{controls}} who can invoke the <b>upload</b> <b>file</b> operation. A consumer initially performs an unauthorized request for uploading a file (the file {{is not included}} in this request). The web application generates a token using the UUID Python function, it responds to the consumer by encoding the token in an HTTP header and updates the Token Table. The consumer software initiates the authentication and the authorization process described in Section 4.1. Then, it issues an authorized request, by encoding the request parameters in HTTP headers and the file as raw POST data. The web application executes the authorized request decision algorithm and if the consumer is allowed to upload the file, it stores it in the Google Drive. When uploading files, consumers are able to specify a U [...]...|$|E
40|$|Abstract — This {{project is}} for hybrid storage architecture, {{to make use}} of both {{shared-nothing}} and shared-disk architectures. The user can either <b>upload</b> <b>file</b> or can just synchronize the original copy from the master computer synchronized before. All the changes made on the original file will be reflected on the file stored on server. All files stored on the cloud server are broken into packets of some definite size and these packets will be distributed on various hard disks this data are replicated using the RAID- 1 concept, which are merged as a whole again whenever the user makes an access to the file on the on-line copy or makes changes to the original copy which is synchronized with the application. The packets are encrypted using a block of ECB encrypted cipher text; all the blocks are dependent on all the previous blocks...|$|E
40|$|The network {{scenario}} {{is that of}} an infrastructure IEEE 802. 11 WLAN with a single AP with which several stations (STAs) are associated. The AP has a finite size buffer for storing packets. In this scenario, we consider TCP controlled upload and download file transfers between the STAs and a server on the wireline LAN (e. g., 100 Mbps Ethernet) to which the AP is connected. In such a situation, it is known (see, for example, (3), [9]) that because of packet loss due to finite buffers at the Ap, <b>upload</b> <b>file</b> transfers obtain larger throughputs than download transfers. We provide an analytical model for estimating the upload and download throughputs {{as a function of}} the buffer size at the AP. We provide models for the undelayed and delayed ACK cases for a TCP that performs loss recovery only by timeout, and also for TCP Reno...|$|E
50|$|No {{optimization}} before <b>uploading</b> <b>files</b> is available.|$|R
50|$|Upload {{components}} can <b>upload</b> <b>files</b> to cloud storage.|$|R
40|$|What is the Wikimedia Commons? How do I [...] . Find files Use {{files in}} Wikipedia {{articles}} Use <b>files</b> outside Wikipedia <b>Upload</b> <b>files</b> Why should I <b>upload</b> <b>files</b> to the Commons? To view more videos from the session, please click here: Using Wikipedia as a Teaching Tool Information Literacy: Wikipedia-styl...|$|R
40|$|Abstract — As {{with the}} Internet, on-demand {{applications}} have grown so ubiquitous {{that almost every}} business user interacts with at least one, whether it's an email service, a Web conferencing application, or a file hosting system. This model is already quite common for consumer apps like email and photo sharing, and for certain business applications. In this paper we present a way to secure the data using different compression and encryption algorithms and to hide its location from the users that stores and retrieves it. The data is stored at multiple places over the information space (over the Internet). It sounds similar to file hosting websites which stores the data that is being uploaded by different users and can be retrieved using proper authentication. The {{only difference is that}} the system for which paper is presented is a application based system like which will run on the clients own system. This application will allow users to <b>upload</b> <b>file</b> of different formats with security features including Encryption and Compression. The uploaded files can be accessed from anywhere using the application which is provided. We believe this system serves as a foundation for future work in integrating and securing information sources across the WWW...|$|E
40|$|Omeka 1. 4 was {{released}} on June 22, 2011. General Batch editing for items Improved update and installation scripts Improved error handling and logging Improved <b>upload</b> <b>file</b> handling Allows configuration of tag delimiter Improvements to database date and time formatting Improvements to advanced search New "is exactly" advanced search type Fixed "is null" and "does not contain" search types Atom feed output Next, previous, last, and first links Improved user and access control handling Miscellaneous tweaks and bedazzlings Library Updates Updated Zend Framework to 1. 11. 6 Updated jQuery to 1. 6. 1 Updated jQuery UI to 1. 8. 13 Updated TinyMCE to 3. 4. 2 -jQuery Security Cross Site Scripting and AJAX vulnerabilities addressed CSRF protection for delete actions UI/UX Improvements to admin theme Many improvements and fixes to media helpers, esp. for display of AVI, WMV, WMA Improvements to theme configuration TinyMCE integration Image preview Improved item citation style Modal AJAX for delete/confirm For Developers Omeka_Job component for background jobs (e. g., importing) Omeka_Storage Layer Amazon S 3 storage New functions plugin_is_active link_to_items_atom clear_filters body_tag auto_discovery_link_tags _log random_featured_items plugin_body plugin_page_header plugin_page_content url_to_link New filters item_citation filter New global functions Deprecated functions auto_discovery_link_tag Tests Tests now require PHPUnit 3. 5 or newer Fakemail no longer required for testing Added test suites: Al...|$|E
40|$|Abstract: The {{paper is}} {{centered}} on the active initiatives from the ICT (information and communication technology) field using analysis and comparison of adopted solutions in ICT products {{for the support of}} competitive advantages. Confrontation of existing options is demonstrated on a security layer of selected products. This wider analysis brings an overview via operating and database systems, BI, and CRM products. A good starting point is an analysis of selected products by Petri Nets with simulation using a multidimensional and object approach. The realized analysis shows ways of security resolution in selected products and a mutual comparison of these solutions leads to an improved design of solutions in individual implementations. For example, Sugar CRM offers an optimal way of restricting access by date for access control to tabs and visible records for the user. Other positive options are advanced security (validation of IP address, maximum <b>upload</b> <b>file</b> size) or logging slow queries. Improvement requires restricted access for the system administrator (inspired by the Oracle database system) or transparent user identification (as in operating systems). Another benefit would be to simplify the overall concept of the accepted security layer from five components to four by merging the user account and system administrator area or audit and logging with an advanced security area...|$|E
5000|$|Resources (<b>uploading</b> <b>files</b> {{to share}} with other {{community}} members) ...|$|R
30|$|The user {{requests}} to perform analysis against the <b>uploaded</b> <b>files.</b>|$|R
50|$|A file select field (for <b>uploading</b> <b>files</b> to a server).|$|R
40|$|Writing {{this final}} project aims {{to know how}} to using {{software}} SIM-PUS to used and resistance into use software SIM-PUS on input collection library material 	Final project research we performed in UPT Library University Islam Batik Surakarta with three methods that is methods interview, methods observation, and methods literature study. 	Result observation showing software SIM-PUS in their use has been efficient and effective and saving time in a input data collection library material. But application software SIM-PUS in library UNIBA there still needs to be repaired as colimns of type on menu inventaritation which should be replaced with a thesis not final project. Application SIM-PUS also committed to improving software program to be more modern. 	Now the suggestion that writers convey to more developing software program in UPT Library University Islam Batik Surakarta, that is: 1) Application SIM-PUS in the input collection library material to make system cataloging in order become efficient and easily find data collection library material required as well using digital library to be used <b>upload</b> <b>file</b> thesis or final project each chapter. 2) Proccesing service collection library material was conducted the librarian in the input this collection in application software SIM-PUS must be manage material collection with good, true, and more carefully. 3) Menu inventaritation in colums of type collection library material should be replaced and repaired its kind to accord with collection library material which included input. 4) Barcode can’t scanning because device scanner in UPT Library UNIBA didn’t function properly so it should be upgrade so barcode can be using. 5) Performance application software SIM-PUS to make better again in processing collection library material it was easier to using. Keyword : Application Software SIM-PUS, digital library, program performanc...|$|E
40|$|New value {{constraints}} for database {{tables and}} validations for corresponding models; new RSpec tests; several bug fixes. Many new values constraints {{have been added}} to ensure database-integrity. Consistency checks {{have been added to}} the dbfiles table to ensure the referred-to containers exist. Restrictions on editing variables associated with traits or covariates that violate the range restriction for the variable value have been relaxed. Many bug fixes have been implemented. Changes Pertinent to PEcAn Users Administrators need to do a database migration. See "Database Changes" below. Summary of Changes Implemented values constraints, both at the database level and and the Web user-interface (Rails app) level The addition of value constraints is a major step toward helping to ensure data-integrity. It should no longer be possible, for example, to enter a site with a longitude value of 2000 (which has happened!) or genuses that aren't capitalized. Not only will these constraints help prevent gross errors, they will also help standardize the set of allowable values. When used to constrain values in columns comprising a candiate key, this will make it less likely that duplicate rows for the same entity will occur. To give one example, a uniqueness constraint on species. scientificname will not by itself prevent the occurrence of two species rows that are identical except that the first has scientificname "Abies alba" and the second has scientificname "Abies alba ". Requiring values in this column to be "whitespace-normalized" (no leading or trailing space, no double-spaces) will prevent this sort of duplicate from occurring. Implemented integrity constraints on references to inputs, models, and posteriors in dbfiles table A row having container_type = 'Input' must have a value for container_id that matches the id column value of some row in the inputs table. Similarly for container types "Model" and "Posterior". Allowing "lazier" approach to fixing variable range violations It used to be a variable could not be edited if any trait or covariate row that referred to the variable had a variable value that violated the range restriction for the variable. One first had to fix all the range violations in the traits and/or covariates rows before the variable could be edited, even if the update only involved, say, changing the notes. Now the trigger that checks for range violations is only run when an attempt is made to change the value of the min or max attribute. Thus all other attributes are now freely editable, regardless of any range violations in associated rows. Bug Fixes Some of the fixes include: Corrected text of mis-labelled buttons Fix for issue # 282 : Can't create two new managements in a row for a given treatment. Eliminated duplicate fields from New Species form Fixed layout of Species and Covariate "Edit" pages (GH # 280) Fixed trait-search action used on Covariate "Edit" page Eliminated vestigial obsolete code and routes Restored the change-password checkbox to the edit-user page to make this page clearer and more user-friendly Re-aligned and rearranged fields in species/show page (GH # 135) Restored some routes that were eliminated when wildcard routes were eliminated. Corrected title for Machine "Show" page (GH # 294) Allow Managers to delete Yield records; also allow Creators to delete Yield records they themselves created (part of Redmine issue # 2334) Made treatments on Listing Treatments page sortable Restyled Listing Treatments page to make it more readable, and added delete buttons to rows that user is allowed to delete (part of Redmine issue # 2334) Better error message when treatment is missing in bulk <b>upload</b> <b>file</b> (GH # 287) Better error message for violation of foreign key constraint (GH # 306) Fixed "CF Guidelines" link on Variables "Edit" page (GH # 308) Fixed Variable update form so that variable type can be updated (GH # 309) Fixed Management "Edit" page so that citation is not inadvertently changed (GH # 313) Fixed "map" links on Site listing page that were broken in certain deployment configurations and removed "map" link from "Show" pages (GH # 305) On "Edit" pages for traits and yields, preselect the current access level so that it isn't inadvertently changed (GH # 302) Fixed display of incorrect QA/QC values on yields listing page (part of GH # 303) Fixed bug in data access filter so that Views and Creators can once again see all records that they themselves created Changed criteria for displaying the edit control for QA/QC values on the yields list page (part of GH # 303) Re-styled "New File" page (GH # 304) Removed "Show" button from "New Site" page (GH # 321) Changed "Back" buttons on all "New" pages to say "All Records" like all the edit pages do (GH # 322) Steps Needed for Upgrade Database Changes Administrators need to do database migrations! There are three database migrations included in this release. The first and most extensive of these involves the addition of several new value constraints. The following set of SQL commands may prove helpful in applying this migration, especially if a data synchronization has not been done recently: update ensembles set notes = '', updated_at = now() at time zone 'utc' where notes is null; update runs set outprefix = '', updated_at = now() at time zone 'utc' where outprefix is null; update runs set setting = '', updated_at = now() at time zone 'utc' where setting is null; update users set state_prov = '', updated_at = now() at time zone 'utc' where state_prov is null; update users set postal_code = '', updated_at = now() at time zone 'utc' where postal_code is null; update workflows set params = '', updated_at = now() at time zone 'utc' where params is null; If further trouble-shooting of migrations is required, the following may be helpful in finding the source of migration problems: bundle exec rake db:migrate 2 >& 1 | grep ERROR (If you run BETYdb in the production environment, and your production database differs from you development database, prefix this command with RAILS_ENV=production.) The database version for this release is 20150521211114. Gem Installation No new Gems need be installed for this release. Status of RSpec Tests All tests continue to pass when run in the default environment and can be run using the command bundle exec rspec Complete details for running the rspec tests are on the updated Wiki page at [URL]...|$|E
5000|$|<b>Upload</b> <b>files</b> such as videos to YouTube or {{pictures}} to Photobucket ...|$|R
5000|$|Enough {{access to}} your server to <b>upload</b> <b>files</b> and change some permissions ...|$|R
5000|$|Able to <b>upload</b> <b>files</b> {{and retain}} {{associated}} original date/timestamps, unlike FTP clients ...|$|R
50|$|Bulletin boards {{commonly}} accept <b>uploaded</b> <b>files</b> {{from their}} users. The BBS software would prompt {{the user to}} supply a description for the <b>uploaded</b> <b>file,</b> but these descriptions were often less than useful. BBS system operators spent many hours going over the upload descriptions correcting and editing the descriptions. The FILE_ID.DIZ inclusion in archives was designed to address this problem.|$|R
5000|$|... Executes code from {{an already}} <b>uploaded</b> <b>file</b> called exploit.php (local file {{inclusion}} vulnerability) ...|$|R
50|$|File Sharing: Team member can <b>upload</b> <b>files</b> {{from their}} {{multi-platform}} devices and cloud storage.|$|R
5000|$|... jSite: jSite {{is a tool}} {{to upload}} websites. It handles keys and manages <b>uploading</b> <b>files.</b>|$|R
50|$|RapidShare {{started to}} check newly <b>uploaded</b> <b>files</b> against a {{database}} of files already reported as illegal. By comparing the files' MD5-hash the site would now prevent illegal files from being reuploaded. While this would be sufficient under United States law, it was later established in court that under German law it is not. That decision forced RapidShare to check all the <b>uploaded</b> <b>files</b> before publishing them.|$|R
5000|$|A Corporate intranet, {{that users}} can configure, <b>upload</b> <b>files</b> and {{documents}} to and write content for themselves ...|$|R
5000|$|GM-Upload.cgi is {{the script}} that enables users to <b>upload</b> <b>files</b> to their site through Greymatter to their {{archives}} directory.|$|R
5000|$|Clean interface. Through its simple sidebar, you {{can access}} all {{information}} about the network, searching, downloading and <b>uploading</b> <b>files.</b>|$|R
50|$|Go Daddy, Clarion University of Pennsylvania and National Capital FreeNet {{recommend}} FileZilla for <b>uploading</b> <b>files</b> {{to their}} web hosting services.|$|R
50|$|All Tools had an admin {{view for}} the {{instructor}} to edit the page: enter information, <b>upload</b> <b>files,</b> create quizzes, etc.|$|R
5000|$|File - an API {{intended}} to handle <b>file</b> <b>uploads</b> and <b>file</b> manipulation; ...|$|R
50|$|<b>Uploaded</b> <b>files</b> may be {{associated}} with their basic attributes, such as time stamps. This is an advantage over the common FTP protocol.|$|R
5000|$|... 5.4: This {{is a minor}} release, {{following}} up on v. 5.3, introducing support for bulk <b>uploading</b> <b>files</b> to the website file system, a small improvement to the hierarchical selector and a new command for Nightwatch.js API to test <b>file</b> <b>uploads.</b>|$|R
