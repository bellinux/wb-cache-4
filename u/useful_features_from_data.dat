2|10000|Public
40|$|Feature {{engineering}} {{is one of}} the most important and time consuming tasks in predictive analytics projects. It involves understanding domain knowledge and data exploration to discover relevant hand-crafted features from raw data. In this paper, we introduce a system called One Button Machine, or OneBM for short, which automates feature discovery in relational databases. OneBM automatically performs a key activity of data scientists, namely, joining of database tables and applying advanced data transformations to extract <b>useful</b> <b>features</b> <b>from</b> <b>data.</b> We validated OneBM in Kaggle competitions in which OneBM achieved performance as good as top 16 % to 24 % data scientists in three Kaggle competitions. More importantly, OneBM outperformed the state-of-the-art system in a Kaggle competition in terms of prediction accuracy and ranking on Kaggle leaderboard. The results show that OneBM can be useful for both data scientists and non-experts. It helps data scientists reduce data exploration time allowing them to try and error many ideas in short time. On the other hand, it enables non-experts, who are not familiar with data science, to quickly extract value from their data with a little effort, time and cost...|$|E
40|$|In this paper, {{the results}} of an {{investigation}} of the possibility of extending "color constancy" to obtain illuminant-invariant reflectance features from data in the near-ultraviolet (UV) and near-infrared (IR) wavelength regions are reported. These features are obtained by extending a blackbody-model-based color constancy algorithm proposed by Ratnasingam and Collins [J. Opt. Soc. Am. A 27, 286 (2010) ] to these additional wavelengths. Ratnasingam and Collins applied the model-based algorithm in the visible region to extract two illuminant-invariant features related to the wavelength-dependent reflectance of a surface from the responses of four sensors. In this paper, this model-based algorithm is extended to extract two illuminant-invariant reflectance features from the responses of sensors that cover the visible and either the near-UV or near-IR wavelength. In this investigation, test reflectance data sets are generated using the goodness-fitness coefficient (GFC). The appropriateness of the GFC for generating the test data sets is demonstrated by comparing the results obtained with these data with those obtained from data sets generated using the CIELab distance. Results based upon the GFC are then presented that suggest that the model-based algorithm can extract <b>useful</b> <b>features</b> <b>from</b> <b>data</b> from the visible and near-IR wavelengths. Finally, results are presented that show that, although the spectrum of daylight in the near UV is very different from a blackbody spectrum, the algorithm can be modified to extract useful features from visible and near-UV wavelengths...|$|E
40|$|Feature {{selection}} {{has been}} a productive field {{of research and development}} in data mining, machine learning and statistical pattern recognition, and is widely applied to many fields such as, image retrieval, genomic analysis and text categorization. Feature selection includes selecting the most <b>useful</b> <b>features</b> <b>from</b> the given <b>data</b> set. The feature selection involves removing irrelevant and redundant features form the data set. The feature selection can be efficient and effective using clustering approach. Based on the criteria of efficiency in terms of time complexity and effectiveness in terms of quality of <b>data,</b> <b>useful</b> <b>features</b> <b>from</b> the big <b>data</b> can be selected. Feature selection reduces the computational complexity of learning and prediction algorithms and saves on the cost of measuring non selected features. The feature selection can be done using the graph clustering approach based on theoretic graph. The most relevant <b>features</b> are selected <b>from</b> the cluster for the relevant target class. The features in every cluster are different and independent of the other...|$|R
40|$|We {{propose a}} Multimodal Stacked Denoising Autoen-coder for {{learning}} a joint model {{of data that}} consists of mul-tiple modalities. The model is used to extract a joint repre-sentation that fuses modalities together. We have found that this representation is useful for classification tasks. Our model {{is made up of}} layers of denoising autoencoders which are trained locally to denoise corrupted versions of their in-puts. This allows the model to learn <b>useful</b> <b>features</b> <b>from</b> unlabeled <b>data</b> in an unsupervised fashion. Our results on multimodal data consisting of images and text show that our model significantly outperforms SVMs and LDA on discrim-inative tasks. We also present our work towards generating tags from a image. 1...|$|R
40|$|We {{present an}} {{automatic}} method, {{based on a}} neural network ensemble, for extracting multiple, diverse and complementary sets of <b>useful</b> classification <b>features</b> <b>from</b> highdimensional <b>data.</b> We demonstrate the utility of these diverse representations for an image dataset, showing good classification accuracy and {{a high degree of}} dimensionality reduction. We then outline a number of possible extensions to the project in an evolutionary computation context. 1. 1. Ensemble Learning 1...|$|R
40|$|Temporal {{information}} can provide <b>useful</b> <b>features</b> for recognizing facial expressions. However, to manually design <b>useful</b> <b>features</b> {{requires a lot}} of effort. In this paper, to reduce this effort, a deep learning technique which is regarded as a tool to automatically extract <b>useful</b> <b>features</b> <b>from</b> raw <b>data,</b> is adopted. Our deep network is based on two different models. The first deep network extracts temporal geometry <b>features</b> <b>from</b> temporal facial landmark points, while the other deep network extracts temporal appearance <b>features</b> <b>from</b> image sequences. These two models are combined in order to boost the performance of the facial expression recognition. Through several experiments, we showed that the two models cooperate with each other. As a result, we achieved superior performance to other state-of-the-art methods in CK+ and Oulu-CASIA databases. Furthermore, one of the main contributions of this paper is that our deep network catches the facial action points automatically. Comment: 9 page...|$|R
40|$|Feature {{engineering}} {{is one of}} the most important but tedious tasks in data science projects. This work studies automation of feature learning for relational data. We first theoretically proved that learning relevant <b>features</b> <b>from</b> relational <b>data</b> for a given predictive analytics problem is NP-hard. However, it is possible to empirically show that an efficient rule based approach predefining transformations as a priori based on heuristics can extract very <b>useful</b> <b>features</b> <b>from</b> relational <b>data.</b> Indeed, the proposed approach outperformed the state of the art solutions with a significant margin. We further introduce a deep neural network which automatically learns appropriate transformations of relational data into a representation that predicts the target variable well instead of being predefined as a priori by users. In an extensive experiment with Kaggle competitions, the proposed methods could win late medals. To the best of our knowledge, this is the first time an automation system could win medals in Kaggle competitions with complex relational data...|$|R
30|$|Unsupervised {{learning}} {{has been successfully}} used for feature extraction in many scientific and industrial applications such as pattern recognition and computer vision [1]. It is adopted to extract generally <b>useful</b> <b>features</b> <b>from</b> unlabelled <b>data.</b> Thus redundant inputs can be removed, and only essential aspects of the data are preserved [2]. As an unsupervised learning algorithm, an autoencoder is a neural network which can discover useful structures of the input data. It is trained {{in a way that}} sets the target values to be equal to the inputs [3]. However, it is impossible to learn features on entire images when the size of images becomes large because of computational expense. Then, we can take advantage of convolutional neural networks (CNNs) [4] to exploit local connectivity without training the network on full images [5]. CNNs are a special kind of multi-layer neural networks that have been successfully applied to computer vision.|$|R
40|$|In this study, we {{designed}} {{a system that}} recognizes a person’s physical activity by analyzing <b>data</b> read <b>from</b> a device {{that he or she}} wears. In order to reduce the system’s demands on the device’s computational capacity and memory space, {{we designed}} a series of strategies such as making accurate analysis based on only a small amount of data in the memory, extracting only the most <b>useful</b> <b>features</b> <b>from</b> the <b>data,</b> cutting unnecessary branches of the classification system, etc. We also implemented a strategy to correct certain types of misclassifications, in order to improve the performance of the system. We categorized a person’s daily activities into three activity states, including stationary, walking, and running. Based on <b>data</b> collected <b>from</b> five subjects, we trained a classification system that provides an activity state feedback every second and yields a classification accuracy of 94. 82 %. Our experiments also demonstrated that the strategies applied to reduce system size and improve system performance worked well...|$|R
40|$|We {{introduce}} Harmonic Motion, a free {{open source}} toolkit for artists, musicians and designers working with gestural <b>data.</b> Extracting musically <b>useful</b> <b>features</b> <b>from</b> captured gesture <b>data</b> can be challenging, with projects often requiring bespoke processing techniques developed through iterations of tweaking equations involving {{a number of}} constant values – {{sometimes referred to as}} ‘magic numbers’. Harmonic Motion provides a robust interface for rapid prototyping of patches to process gestural data and a framework through which approaches may be encapsulated, reused and shared with others. In addition, we describe our design process in which both personal experience and a survey of potential users informed a set of specific goals for the software...|$|R
40|$|Abstract: The {{need for}} an {{efficient}} and standard technique for optimal spectral sampling of hyperspectral data during the inversion of canopy reflectance models {{has been the subject}} of many studies. The objective of this study was to investigate the utility of the discrete wavelet transform (DWT) for extracting <b>useful</b> <b>features</b> <b>from</b> hyperspectral <b>data</b> with which forest LAI can be estimated through inversion of a three dimensional radiative transfer model, the Discrete Anisotropy Radiative Transfer (DART) model. DART, coupled with the leaf optical properties model PROSPECT, was inverted with AVIRIS data using a look-up-table (LUT) -based inversion approach. We used AVIRIS data and in situ LAI measurements from two different hardwood forested sites in Wisconsin, USA. Prior to inversion, model-simulated and AVIRIS hyperspectral data were transformed into discrete wavelet coefficients using Haar wavelets. The LUT inversion was performed with three different datasets, the original reflectance bands, the full set of wavelet extracted features, and two wavelet subsets containing 99. 99 % and 99. 0 % of the cumulative energyRemote Sens. 2013, 5 264...|$|R
40|$|In {{smart home}} {{environment}} research, {{little attention has}} been given to monitoring, analyzing, and predicting energy usage, despite the fact that electricity consumption in homes has grown dramatically in the last few decades. We envision that a potential application of this smart environment technology is predicting the energy would be used to support specific daily activities. The {{purpose of this paper is}} thus to validate our hypothesis that energy usage can be predicted based on sensor data that can be collected and generated by the residents in a smart home environment, including recognized activities, resident movement in the space, and frequency of classes of sensor. In this paper, we extract <b>useful</b> <b>features</b> <b>from</b> sensor <b>data</b> collected in a smart home environment and utilize several machine learning algorithms to predict energy usage given these features. To validate these algorithms, we use real sensor data collected in our CASAS smart apartment testbed. We also compare the performance between different learning algorithms and analyze the prediction results for two different experiments performed in the smart home...|$|R
40|$|Abstract. Fault {{diagnosis}} {{is a kind}} of pattern recognition problem and how to extract diagnosis features and improve recognition performance is a difficult problem. Local Linear Embedding (LLE) is an unsupervised non-linear technique that extracts <b>useful</b> <b>features</b> <b>from</b> the high-dimensional <b>data</b> sets with preserved local topology. But the original LLE method is not taking the known class label information of input data into account. A new characteristics similarity-based supervised locally linear embedding (CSSLLE) method for fault {{diagnosis is}} proposed in this paper. The CSSLLE method attempts to extract the intrinsic manifold <b>features</b> <b>from</b> high-dimensional fault <b>data</b> by computing Euclidean distance based on characteristics similarity and translate complex mode space into a low-dimensional feature space in which fault classification and diagnosis are carried out easily. The experiments on benchmark data and real fault dataset demonstrate that the proposed approach obtains better performance compared to SLLE, and it is an accurate technique for fault diagnosis...|$|R
40|$|A Nonlinear Gaussian Belief Network (NLGBN) based fault {{diagnosis}} technique is proposed for industrial processes. In this study, a three-layer NLGBN is constructed and trained to extract <b>useful</b> <b>features</b> <b>from</b> noisy process <b>data.</b> The nonlinear {{relationships between the}} process variables and the latent variables are modelled {{by a set of}} sigmoidal functions. To take into account the noisy nature of the data, model variances are also introduced to both the process variables and the latent variables. The three-layer NLGBN is first trained with normal process data using a variational Expectation and Maximization algorithm. During real-time monitoring, the online process data samples are used to update the posterior mean of the top-layer latent variable. The absolute gradient denoted as G-index to update the posterior mean is monitored for fault detection. A multivariate contribution plot is also generated based on the G-index for {{fault diagnosis}}. The NLGBN-based technique is verified using two case studies. The results demonstrate that the proposed technique outperforms the conventional nonlinear techniques such as KPCA, KICA, SPA, and Moving Window KPCA...|$|R
40|$|The {{need for}} an {{efficient}} and standard technique for optimal spectral sampling of hyperspectral data during the inversion of canopy reflectance models {{has been the subject}} of many studies. The objective of this study was to investigate the utility of the discrete wavelet transform (DWT) for extracting <b>useful</b> <b>features</b> <b>from</b> hyperspectral <b>data</b> with which forest LAI can be estimated through inversion of a three dimensional radiative transfer model, the Discrete Anisotropy Radiative Transfer (DART) model. DART, coupled with the leaf optical properties model PROSPECT, was inverted with AVIRIS data using a look-up-table (LUT) -based inversion approach. We used AVIRIS data and in situ LAI measurements from two different hardwood forested sites in Wisconsin, USA. Prior to inversion, model-simulated and AVIRIS hyperspectral data were transformed into discrete wavelet coefficients using Haar wavelets. The LUT inversion was performed with three different datasets, the original reflectance bands, the full set of wavelet extracted features, and two wavelet subsets containing 99. 99 % and 99. 0 % of the cumulative energy of the original signal. The energy subset containing 99. 99 % of the cumulative signal energy provided better estimates of LAI (RMSE = 0. 46, R 2 = 0. 77) than the original spectral bands (RMSE = 0. 60, R 2 = 0. 47). The results indicate that the discrete wavelet transform can increase the accuracy of LAI estimates by improving the LUT-based inversion of DART (and, potentially, by implication, other terrestrial radiative transfer models) using hyperspectral data. The improvement in accuracy of LAI estimates is potentially due to different properties of wavelet analysis such as multi-scale representation, dimensionality reduction, and noise removal...|$|R
40|$|Abstract. Sparse coding {{of sensory}} data has {{recently}} attracted notable attention in research of learning <b>useful</b> <b>features</b> <b>from</b> the unlabeled <b>data.</b> Empirical {{studies show that}} mapping the data into a significantly higherdimensional space with sparse coding can lead to superior classification performance. However, computationally {{it is challenging to}} learn a set of highly over-complete dictionary bases and to encode the test data with the learned bases. In this paper, we describe a mixture sparse coding model that can produce high-dimensional sparse representations very efficiently. Besides the computational advantage, the model effectively encourages data that are similar to each other to enjoy similar sparse representations. What’s more, the proposed model can be regarded as an approximation to the recently proposed local coordinate coding (LCC), which states that sparse coding can approximately learn the nonlinear manifold of the sensory data in a locally linear manner. Therefore, the feature learned by the mixture sparse coding model works pretty well with linear classifiers. We apply the proposed model to PASCAL VOC 2007 and 2009 datasets for the classification task, both achieving stateof-the-art performances. Key words: Sparse coding, highly over-complete dictionary training, mixture model, mixture sparse coding, image classification, PASCAL VOC challenge...|$|R
40|$|Active Learning Method (ALM) {{is one of}} the {{powerful}} tools in soft computing that is inspired by human brain capabilities in processing complicated information. ALM, which is in essence an adaptive fuzzy learning method, models a Multi-Input Single-Output (MISO) system with several Single-Input Single-Output (SISO) subsystems. Ink Drop Spread (IDS) operator, which is the main processing engine of this method, extracts <b>useful</b> <b>features</b> <b>from</b> the <b>data</b> without complicated computations and provides stability and convergence as well. Despite great performance of ALM in applications such as classification, clustering, and modelling, an efficient hardware implementation has remained a challenging problem. Large amount of memory required to store the information of IDS planes as well as the high computational cost of the IDS computing system are two main barriers to ALM becoming more popular. In this paper, a novel learning method is proposed based on the idea of IDS, but with a novel approach that eliminates the computational cost of IDS operator. Unlike traditional approaches, our proposed method finds functions to describe the IDS plane that eliminates the need for large amount of memory to a great extent. Narrow Path and Spread, which are two main features used in the inference engine of ALM, are then extracted from IDS planes with minimum amount of memory usage and power consumption. Our proposed algorithm is fully compatible with memristor-crossbar implementation that leads to a significant {{decrease in the number of}} required memristors (from O(n^ 2) to O(3 n)). Simpler algorithm and higher speed make our algorithm suitable for applications where real-time process, low-cost and small implementation are paramount. Applications in clustering and function approximation are provided, which reveals the effective performance of our proposed algorithm...|$|R
40|$|Handwritten digit {{recognition}} {{is an open}} problem in computer vision and pattern recognition, and solving this problem has elicited increasing interest. The main challenge of this problem is the design of an efficient method that can recognize the handwritten digits that are submitted by the user via digital devices. Numerous studies have been proposed {{in the past and}} in recent years to improve handwritten digit recognition in various languages. Research on handwritten digit recognition in Arabic is limited. At present, deep learning algorithms are extremely popular in computer vision and are used to solve and address important problems, such as image classification, natural language processing, and speech recognition, to provide computers with sensory capabilities that reach the ability of humans. In this study, we propose a new approach for Arabic handwritten digit recognition by use of restricted Boltzmann machine (RBM) and convolutional neural network (CNN) deep learning algorithms. In particular, we propose an Arabic handwritten digit recognition approach that works in two phases. First, we use the RBM, which is a deep learning technique that can extract highly <b>useful</b> <b>features</b> <b>from</b> raw <b>data,</b> and which has been utilized in several classification problems as a feature extraction technique in the feature extraction phase. Then, the extracted features are fed to an efficient CNN architecture with a deep supervised learning architecture for the training and testing process. In the experiment, we used the CMATERDB 3. 3. 1 Arabic handwritten digit dataset for training and testing the proposed method. Experimental results show that the proposed method significantly improves the accuracy rate, with accuracy reaching 98. 59 %. Finally, comparison of our results with those of other studies on the CMATERDB 3. 3. 1 Arabic handwritten digit dataset shows that our approach achieves the highest accuracy rate...|$|R
40|$|Many {{forms of}} {{biometrics}} {{have been proposed}} and studied for biometrics authentication. Recently researchers are looking into longitudinal pattern matching that based on {{more than just a}} singular biometrics; <b>data</b> <b>from</b> user’s activities are used to characterise the identity of a user. In this paper we advocate a novel type of authentication by using a user’s medical history which can be electronically stored in a biometric security card. This is a sequel paper from our previous work about defining abstract format of medical data to be queried and tested upon authentication. The challenge to overcome is preserving the user’s privacy by choosing only the <b>useful</b> <b>features</b> <b>from</b> the medical <b>data</b> for use in authentication. The features should contain less sensitive elements and they are implicitly related to the target illness. Therefore exchanging questions and answers about a few carefully chosen features in an open channel would not easily or directly expose the illness, but yet it can verify by inference whether the user has a record of it stored in his smart card. The design of a privacy preserving model by backward inference is introduced in this paper. Some live medical data are used in experiments for validation and demonstration...|$|R
40|$|License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. Many forms of biometrics {{have been proposed}} and studied for biometrics authentication. Recently researchers are looking into longitudinal pattern matching that based on {{more than just a}} singular biometrics; <b>data</b> <b>from</b> user’s activities are used to characterise the identity of a user. In this paper we advocate a novel type of authentication by using a user’s medical history which can be electronically stored in a biometric security card. This is a sequel paper from our previous work about defining abstract format of medical data to be queried and tested upon authentication. The challenge to overcome is preserving the user’s privacy by choosing only the <b>useful</b> <b>features</b> <b>from</b> the medical <b>data</b> for use in authentication. The features should contain less sensitive elements and they are implicitly related to the target illness. Therefore exchanging questions and answers about a few carefully chosen features in an open channel would not easily or directly expose the illness, but yet it can verify by inference whether the user has a record of it stored in his smart card. The design of a privacy preserving model by backward inference is introduced in this paper. Some live medical data are used in experiments for validation and demonstration. 1...|$|R
40|$|Graphs (networks) are {{ubiquitous}} {{and allow}} us to model entities (nodes) and the dependencies (edges) between them. Learning a <b>useful</b> <b>feature</b> representation <b>from</b> graph <b>data</b> {{lies at the heart}} and success of many machine learning tasks such as classification, anomaly detection, link prediction, among many others. Many existing techniques use random walks as a basis for learning features or estimating the parameters of a graph model for a downstream prediction task. Examples include recent node embedding methods such as DeepWalk, node 2 vec, as well as graph-based deep learning algorithms. However, the simple random walk used by these methods is fundamentally tied to the identity of the node. This has three main disadvantages. First, these approaches are inherently transductive and do not generalize to unseen nodes and other graphs. Second, they are not space-efficient as a feature vector is learned for each node which is impractical for large graphs. Third, most of these approaches lack support for attributed graphs. To make these methods more generally applicable, we propose a framework for inductive network representation learning based on the notion of attributed random walk that is not tied to node identity and is instead based on learning a function Φ : x→ w that maps a node attribute vector x to a type w. This framework serves as a basis for generalizing existing methods such as DeepWalk, node 2 vec, and many other previous methods that leverage traditional random walks. Comment: NIPS WiM...|$|R
5000|$|LMA {{is used in}} Human-Computer Interaction as a {{means of}} extracting <b>useful</b> <b>features</b> <b>from</b> a human's {{movement}} to be understood by a computer, as well as generating realistic movement animation for virtual agents [...] and robots.|$|R
40|$|XML {{documents}} are inherently extremely verbose since the "schema" is repeated for every "record" in the document. While {{a variety of}} compressors are available to address this problem, they are not designed to support direct querying of the compressed document, a <b>useful</b> <b>feature</b> <b>from</b> a database perspective...|$|R
40|$|In {{this paper}} {{we present a}} review of {{stochastic}} trees, a convenient modeling approach for medical treatment decision analyses. Stochastic trees are a generalization of decision trees that incorporate <b>useful</b> <b>features</b> <b>from</b> continuous-time Markov chains. We also discuss StoTree, a freely available software tool for the formulation and solution of stochastic trees, implemented in the Excel spreadsheet environment...|$|R
30|$|It {{is known}} {{that the goal of}} {{learning}} theory is to approximate a function (or some function <b>features)</b> <b>from</b> <b>data</b> samples.|$|R
40|$|Capturing user’s {{emotional}} state is an emerging way for implicit relevance feedback in information retrieval (IR). Recently, EEG-based emotion recognition has drawn increasing attention. However, a key challenge is effective learning of <b>useful</b> <b>features</b> <b>from</b> EEG signals. In this paper, we present our on-going work on using Deep Belief Network (DBN) to automatically extract high-level <b>features</b> <b>from</b> raw EEG signals. Our preliminary experiment on the DEAP dataset {{shows that the}} learned features perform comparably {{to the use of}} manually generated features for emotion recognition...|$|R
30|$|In this study, three {{different}} methods which are eigenfeatures, local binary pattern (LBP) features, and gray-level co-occurrence matrix (GLCM) features {{were used to}} extract the <b>features</b> <b>from</b> <b>data.</b>|$|R
40|$|Nickle is {{a vaguely}} C-like {{programming}} language for numerical applications, useful {{both as a}} desk calculator and as a prototyping and implementation language for numerical and semi-numerical algorithms. Nickle abstracts a number of <b>useful</b> <b>features</b> <b>from</b> {{a wide variety of}} other programming languages, particularly functional languages. Nickle’s design principles and implementation pragmatics mesh nicely to form a language filling a useful niche in the UNIX software environment. The history of Nickle is also an instructive example of the migration of an application from an idea to a freely-available piece of software. ...|$|R
40|$|The Runge-Kutta {{discontinuous}} Galerkin (RKDG) {{method for}} solving hyperbolic conservation laws {{is a high}} order finite element method, which utilizes the <b>useful</b> <b>features</b> <b>from</b> high resolution finite volume schemes, such as the exact or approximate Riemann solvers, TVD Runge-Kutta time discretizations, and limiters. In this paper, we investigate using the RKDG finite element method for compressible two-medium flow simulation with conservative treatment of the moving material interfaces. Numerical results for both gas-gas and gas-water flows in one-dimension are provided to demonstrate the characteristic behavior of this approach. (c) 2006 Elsevier Inc. All rights reserved...|$|R
40|$|Abstract — A major {{challenge}} {{in the path of}} widespread use of mobile robots is the ability to function autonomously, learning <b>useful</b> <b>features</b> <b>from</b> the environment and using them to adapt to environmental changes. We propose an algorithm for mobile robots equipped with color cameras that allows for smooth operation under illumination changes. The robot uses image statistics and the environmental structure to autonomously detect and adapt to both major and minor illumination changes. Furthermore, the robot autonomously plans an action sequence that maximizes color learning opportunities while minimizing localization errors. Our approach is fully implemented and tested on the Sony AIBO robots...|$|R
50|$|Grundtvig had amalgamated what he {{considered}} <b>useful</b> <b>features</b> <b>from</b> various versions of a folksong or ballad to produce a long, complex whole; Olrik, in contrast, sought to trace {{the history of the}} oral texts back to simple originals. He published several sample studies in Danske Studier, the journal he co-founded with Marius Kristensen in 1904, and in 1899 - 1909, with Ida Falbe-Hansen, he published a collection of reconstructed texts, Danske Folkeviser i Udvalg; in 1899 - 1904, an edition with melodic arrangements by Thomas Laub was published. These were very popular and were translated into German and English.|$|R
40|$|Abstract—Image Fusion is the {{procedure}} of combining <b>useful</b> <b>features</b> <b>from</b> multiple sensor image inputs {{to form a}} sin-gle composite image. In this work, the authors extend the previously proposed Image Fusion framework, based on self-trained Independent Component Analysis (ICA) bases, to a more sophisticated region-based Image Fusion system. The input images are segmented into three areas of different activity: edges, texture and constant background. A hierarchical set of fusion rules employing textural information from the spatial-domain {{in the form of}} local variance, entropy and fourier energy is introduced. The proposed system improves the performance of our previous system...|$|R
5000|$|A set of Gabor filters with {{different}} frequencies and orientations {{may be helpful}} for extracting <b>useful</b> <b>features</b> <b>from</b> an image. In the discrete domain, two-dimensional Gabor filters are given by,where B and C are normalizing factors to be determined.2-D Gabor filters have rich applications in image processing, especially in feature extraction for texture analysis and segmentation. [...] defines the frequency being looked for in the texture. By varying , we can look for texture oriented in a particular direction. By varying , we change {{the support of the}} basis or the size of the image region being analyzed.|$|R
50|$|Supervised feature {{learning}} is learning <b>features</b> <b>from</b> labeled <b>data.</b> Approaches include.|$|R
40|$|Data mining {{methods are}} used to handle the {{problems}} of dynamic huge data set. To build a classification model, time complexity of calculated result can be scale back by selecting only <b>useful</b> <b>features.</b> A feature selection technique is used to select only <b>useful</b> <b>features</b> <b>from</b> available <b>features.</b> An intersection principle based feature selection approach is Used. Genetic algorithm {{is used as a}} search method and it select only the features which are appears frequently in datasets. Then results were tested for different datasets having different type of data using Naive Bayes & J 48 classifiers. The result analysis shows that Naive Bayes classifier gives better result than J 48 classifier, with the substantial growth in accuracy, minimum time and minimum number of features. In this paper correlation feature selection is used with Genetic Algorithm for feature selection...|$|R
30|$|Besides those hand-crafted feature methods, {{data-driven}} RATR {{approaches have}} attracted increasing attention {{in past years}} due {{to their ability to}} learn <b>useful</b> <b>features</b> <b>from</b> the dataset automatically. In [10], the principal components analysis (PCA)-based feature subspace is constructed to minimize reconstruction error for RATR. In [11 – 15], the researchers employ factor analysis (FA) model to project and recognize HRRPs in a low-dimensional latent feature space. Considering the sparsity within the HRRP signals, Feng et al. [16] and Zhou [17] apply sparse constraint on the feature vectors and solve the problems via l 0 -minimization. However, all those methods build linear and shallow architectures that limit their capability to represent the complicated HRRP data.|$|R
