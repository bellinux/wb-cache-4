64|174|Public
5000|$|Up-sampling: {{the color}} bands are <b>up-sampled</b> {{to the same}} {{resolution}} as the panchromatic band; ...|$|E
5000|$|In {{the above}} diagram, filters in each level are <b>up-sampled</b> {{versions}} of the previous (see figure below).|$|E
5000|$|Forward transform: the <b>up-sampled</b> color {{bands are}} {{transformed}} to an alternate color space (where intensity is orthogonal {{to the color}} information); ...|$|E
40|$|In a {{scalable}} video coding (SVC), spatial <b>up-sampling</b> {{of video}} sequences is an important process for spatial scalability. We propose an <b>up-sampling</b> method based on the type- 1 DCT. For further improvement of the upsampling method, we introduce an adaptive filtering method, which applies different weighting parameters to DCT coefficients. The proposed adaptive <b>up-sampling</b> method shows much improved PSNR {{in comparison with the}} recent H. 264 SVC <b>up-sampling</b> method. Index Terms — Adaptive filters, DCT, video codecs. 1...|$|R
3000|$|... {{and then}} <b>up-sample</b> it using bi-cubic {{interpolation}} {{by the same}} factor of s to obtain the low-frequency band image Y_l∈R^K. Then, we <b>up-sample</b> X [...]...|$|R
30|$|R {{to obtain}} the {{disparity}} map. Considering the tradeoff of the <b>up-sampling</b> quality and the computational complexity, we select the bicubic interpolation as the <b>up-sampling</b> method. The disparity estimation in this method utilizes normalized mutual information (NMI) algorithm based on adaptive support weighting (ASW).|$|R
5000|$|Output {{sampling}} frequency of 44.1 kHz (it can also accept 22.05-kHz samples - they are <b>up-sampled</b> to 44.1 kHz before output) ...|$|E
50|$|Clocking {{flexibility}} {{allows the}} McASP to receive and transmit at different rates. For example, the McASP can receive data at 48 kHz but output <b>up-sampled</b> data at 96 kHz or 192 kHz.|$|E
5000|$|Alignment: the <b>up-sampled</b> color {{bands and}} the {{panchromatic}} band are aligned to reduce artifacts due to mis-registration (generally, when the data {{comes from the}} same sensor, this step is usually not necessary); ...|$|E
40|$|Image <b>up-sampling</b> {{is found}} to be a very {{effective}} technique useful in today’s digital image processing applications or rendering devices. In image upsampling, an image is enhanced from a lower resolution to a higher resolution with the degree of enhancement depending upon application requirements. It is known that the traditional interpolation based approaches for <b>up-sampling,</b> such as Bilinear or Bicubic interpolation, blur the resultant images [1, 2]. Furthermore; in color imagery, these interpolation based <b>up-sampling</b> methods may have color infringing artifacts in the areas where the images contain sharp edges and fine textures. In this paper, we present an interesting <b>up-sampling</b> algorithm using 9 / 7 bi-orthogonal Spline filters based Discrete Wavelet Transform (DWT). The proposed method preserves much of the sharp edge features in the image, and lessens the amount of color artifacts. Effectiveness of the proposed algorithm has been demonstrated based on evaluation of PSNR and � Eab quality metrics of the original image and the reconstructed image...|$|R
40|$|Abstract — Unorganized point clouds {{obtained}} from 3 D shape acquisition devices usually present noises, outliers, and non-uniformities. In this article, we propose a framework to consoli-date unorganized points by an iterative procedure of interlaced down-sampling and <b>up-sampling</b> steps. After down-sampling and <b>up-sampling,</b> selection operations are conducted to remove outliers while preserving geometric details. The uniformity of points is improved {{by moving the}} down-sampled particles and the following refinement of point samples, and the missed regions are filled through surface extrapolation. Moreover, an adaptive sampling strategy is employed {{to speed up the}} iterations. Ex-perimental results demonstrate the effectiveness of the proposed point processing framework. Index Terms — Unorganized point clouds, repulsion operator, outlier removal, down-sampling, <b>up-sampling.</b> I...|$|R
40|$|<b>Up-sampling</b> and down-sampling are the {{two most}} used methods in {{balancing}} the data when dealing with two class imbalance problem. However, none of the existing approaches to class rebalance take into account class information (e. g. distribution, within and between class distances, imbalance factor). This study presents initial results of <b>up-sampling</b> methods based on various approaches to aggregation of class information such as spread, imbalance factor and the distance between the classes. Artificially generated data are used for experiments. The performance of each <b>up-sampling</b> method is evaluated with respect to how well the resulting data set reflects the underlying original class distribution, in terms of mean, standard deviation and (empirical) distribution function...|$|R
50|$|On the Apple TV (2nd generation), {{digital output}} audio is <b>up-sampled</b> to 48 kHz, {{including}} lossless CD rips at 44.1 kHz. Although {{this is a}} higher frequency and the difference is not audible in most cases, it means the audio is not 'bit perfect' which is often a goal for digital transmission of data.|$|E
5000|$|The {{resolution}} {{independence of}} a fractal-encoded image {{can be used}} to increase the display resolution of an image. This process is also known as [...] "fractal interpolation". In fractal interpolation, an image is encoded into fractal codes via fractal compression, and subsequently decompressed at a higher resolution. The result is an <b>up-sampled</b> image in which iterated function systems have been used as the interpolant.Fractal interpolation maintains geometric detail very well compared to traditional interpolation methods like bilinear interpolation and bicubic interpolation. Since the interpolation cannot reverse Shannon entropy however, it ends up sharpening the image by adding random instead of meaningful detail. One cannot, for example, enlarge an image of a crowd where each person's face is one or two pixels and hope to identify them.|$|E
3000|$|R is {{the full}} {{resolution}} frames {{in the right}} view. Disparity estimation is employed between the <b>up-sampled</b> I [...]...|$|E
30|$|Step 6 : The reconstructed {{residual}} signal errrec {{is produced}} by applying the inverse WT and <b>up-sampling</b> process {{by a factor of}} two, respectively.|$|R
40|$|Abstract — In many video {{compression}} systems, the frames are down-sampled before transmission. Also, in many scalable systems, the residual after down- and <b>up-sampling</b> is encoded and transmitted. Sometimes, a few frames are encoded at normal resolution (key frames) {{while the other}} frames are encoded at reduced resolution. Super resolution {{can be used to}} enhance the <b>up-sampling</b> process, using motion information to improve traditional interpolation. In this paper, we propose to use a super resolution method to <b>up-sample</b> the non-key frames using the key frames as reference. We build dictionaries on-the-fly using the key frames instead of the traditional off-line training images. The high-frequency data of matching blocks are added to the low-resolution blocks. Since the key frames are very similar to the non-key frames, the method is robust enough to allow successful super resolution of highly compressed (severely degraded) sequences. Results are presented for many predefined block sizes, key frames frequencies, and compression parameters. I...|$|R
30|$|Fourier {{transforming}} (FT) the de-rotated {{signals in}} the azimuth direction. It {{should be noted}} that <b>up-sampling</b> in azimuth may be required in the spotlight mode to avoid the Doppler spectrum aliasing.|$|R
30|$|Before {{starting}} with sub-pixel prediction, the frames must be <b>up-sampled</b> to half-pixel accuracy {{by means of}} a 6 -tap filter, and then they are <b>up-sampled</b> to quarter-pixel accuracy {{by means of a}} bilinear filter. The up-sampling is carried out on the GPU because the frames are transferred to the GPU memory with full-pixel accuracy. It is faster to generate the frames with quarter-pixel accuracy than to transfer them. Three GPU kernels are needed since there are dependencies in the up-sampling process.|$|E
30|$|In {{order to}} carry out the {{bi-directional}} sub-pixel prediction {{it is not necessary to}} up-sample the reference frames, because they have been previously <b>up-sampled</b> before applying the forward and backward predictions.|$|E
40|$|Abstract—Generation of upsampled tomographic images via {{combination}} of rotated lattices has been explored in [1]. In this paper, we evaluate the existing method using real phantom data. <b>Up-sampled</b> tomographic images are generated via {{combination of}} rotated hexagonal lattices. Sinogram data is filtered and back-projected on two hexagonal lattices which are rotated versions of each other. Samples from these lattices are interpolated to generate an <b>up-sampled</b> image defined on a square lattice. These results are compared with direct up-sampling method and image ISR- 2 algorithm described in [10]. Two PET phantoms- NEMA and Hoffman brain phantom {{are used for}} purpose of evaluation. The results of the proposed method show considerable improvement over direct <b>up-sampled</b> image in terms of contrast, sharpness and imaging artifact; but when compared with ISR- 2 generated image, the difference in image quality is not significant. A key advantage of the proposed method is that only two images are required for generating a high resolution image whereas ISR- 2 requires k low resolution images for an up-sampling factor of k...|$|E
50|$|Lanczos {{resampling}} {{is based}} on a windowed sinc function as a practical upsampling filter approximating the ideal sinc function. Lanczos resampling is widely used in video <b>up-sampling</b> for digital zoom applications.|$|R
40|$|Image <b>up-sampling</b> in the {{discrete}} cosine transform (DCT) domain is {{a challenging}} problem because DCT coefficients are de-correlated, {{such that it}} is nontrivial to estimate directly high-frequency DCT coefficients from observed low-frequency DCT coefficients. In the literature, DCT-based <b>up-sampling</b> algorithms usually pad zeros as high-frequency DCT coefficients or estimate such coefficients with limited success mainly due to the nonadaptive estimator and restricted information from a single observed image. In this paper, we tackle the problem of estimating high-frequency DCT coefficients in the spatial domain by proposing a learning-based scheme using an adaptive k-nearest neighbor weighted minimum mean squares error (MMSE) estimation framework. Our proposed scheme makes use of the information from precomputed dictionaries to formulate an adaptive linear MMSE estimator for each DCT block. The scheme is able to estimate high-frequency DCT coefficients with very successful results. Experimental {{results show that the}} proposed <b>up-sampling</b> scheme produces the minimal ringing and blocking effects, and significantly better results compared with the state-of-the-art algorithms in terms of peak signal-to-noise ratio (more than 1 dB), structural similarity, and subjective quality measurements. Department of Electronic and Information Engineerin...|$|R
40|$|Hybrid opto-digital joint {{transform}} correlator (HODJTC) {{is effective}} for image motion measurement, {{but it is}} different from the traditional joint transform correlator because it only has one optical transform and the joint power spectrum is directly input into a digital processing unit to compute the image shift. The local cross-correlation image can be directly obtained by adopting a local Fourier transform operator. After the pixel-level location of cross-correlation peak is initially obtained, the <b>up-sampling</b> technique is introduced to relocate the peak in even higher accuracy. With signal-to-noise ratio >= 20 dB, <b>up-sampling</b> factor k >= 10 and the maximum image shift <= 60 pixels, the root-mean-square error of motion measurement accuracy can be controlled below 0. 05 pixels...|$|R
3000|$|..., one {{for each}} <b>up-sampled</b> {{reference}} frame (backward and forward). The two warpings, W, obtained for each transform, correspond to two sets of perspective transform vectors, one set of vectors pointing from the WZ frame to X [...]...|$|E
40|$|Abstract — We {{consider}} the warping problem which appears in well-known image registration algorithms that use higher-order motion models. An implementation inspired by recent {{work and a}} new image registration algorithm are used for the analysis. Both approaches rely on frame-to-frame estimation. The key technique is the well-established gradient descent approach for the estimation of higher-order motion parameters. We show that using <b>up-sampled</b> input images in the last step of the algorithms improves {{the accuracy of the}} estimated motion parameters. It {{can be seen in the}} experimental results that the performance of the image registration algorithms increases significantly only by applying the gradient descent on <b>up-sampled</b> images in comparison to recent algorithms developed. I...|$|E
30|$|Quarter-pel {{up-sampling}} - To {{provide a}} more accurate estimation for the possible perspective deformations, the backward and forward reference frames are first <b>up-sampled</b> with the H. 264 /AVC quarter-pel up-sampling filter [1]; this is performed so that the next steps can benefit from increased precision reference frames.|$|E
30|$|The {{problem of}} class skewness, {{imbalance}} {{in the class}} distribution, give rise to poor performance of a supervised learning algorithm [18]. To cope with this issue, existing research suggests several different approaches, such as altering the training sample by <b>up-sampling</b> or down-sampling, i.e., balancing.|$|R
40|$|Edge-preserving {{smoothing}} and super-resolution are {{classic and}} important prob-lems in computational photography and related fields. The first addresses {{the problem of}} noise removal from images while preserving its sharp features such as strong edges. Image <b>up-sampling,</b> on the other hand, addresses the problem o...|$|R
40|$|We {{propose a}} novel edge {{detection}} algorithm with sub-pixel accuracy based on annihilation of signals with finite rate of innovation [1, 2]. We {{show that the}} Fourier domain annihila-tion equations {{can be interpreted as}} spatial domain multipli-cations. From this new perspective, we obtain an accurate es-timation of the edge model by assuming a simple parametric form within each localised block. Further, we build a locally adaptive global mask function (i. e, our edge model) for the whole image. The mask function is then used as an edge-preserving constraint in further processing. Numerical ex-periments on both edge localisations and image <b>up-sampling</b> show the effectiveness of the proposed approach, which out-performs state-of-the-art method. Index Terms—Annihilation equations, sub-piexel edge detection, image <b>up-sampling</b> 1...|$|R
40|$|Abstract. Depth {{estimation}} for dynamic scenes is {{a challenging}} and relevant problem in computer vision. Although this {{problem can be}} tackled by means of ToF cameras or stereo vision systems, {{each of the two}} systems alone has its own limitations. In this paper a framework for the fusion of 3 D data produced by a ToF camera and a stereo vision system is proposed. Initially, depth data acquired by the ToF camera are <b>up-sampled</b> to the spatial resolution of the stereo vision images by a novel up-sampling algorithm based on image segmentation and bilateral filtering. In parallel a dense disparity field is obtained by a stereo vision algorithm. Finally, the <b>up-sampled</b> ToF depth data and the disparity field provided by stereo vision are synergically fused by enforcing the local consistency of depth data. The depth information obtained with the proposed framework is characterized by the high resolution of the stereo vision system and by an improved accuracy with respect to the one produced by both subsystems. Experimental results clearly show how the proposed method is able to outperform the compared fusion algorithms. ...|$|E
40|$|High-refresh-rate {{displays}} (e. g., 120 Hz) {{have recently}} become {{available on the}} consumer market and quickly gain on popularity. One of their aims {{is to reduce the}} perceived blur created by moving objects that are tracked by the human eye. However, an improvement is only achieved if the video stream is produced at the same high refresh rate (i. e. 120 Hz). Some devices, such as LCD TVs, solve this problem by converting low-refresh-rate content (i. e. 50 Hz PAL) into a higher temporal resolution (i. e. 200 Hz) based on two-dimensional optical flow. In our approach, we will show how rendered three-dimensional images produced by recent graphics hardware can be <b>up-sampled</b> more efficiently resulting in higher quality at the same time. Our algorithm relies on several perceptual findings and preserves the naturalness of the original sequence. A psychophysical study validates our approach and illustrates that temporally <b>up-sampled</b> video streams are preferred over the standard low-rate input by the majority of users. We show that our solution improves task performance on high-refresh-rate displays...|$|E
40|$|Depth {{estimation}} for dynamic scenes is {{a challenging}} and relevant problem in computer vision. Although this {{problem can be}} tackled by means of ToF cameras or stereo vision systems, {{each of the two}} systems alone has its own limitations. In this paper a framework for the fusion of 3 D data produced by a ToF camera and a stereo vision system is proposed. Initially, depth data acquired by the ToF camera are <b>up-sampled</b> to the spatial resolution of the stereo vision images by a novel up-sampling algorithm based on image segmentation and bilateral filtering. In parallel a dense disparity field is obtained by a stereo vision algorithm. Finally, the <b>up-sampled</b> ToF depth data and the disparity field provided by stereo vision are synergically fused by enforcing the local consistency of depth data. The depth information obtained with the proposed framework is characterized by the high resolution of the stereo vision system and by an improved accuracy with respect to the one produced by both subsystems. Experimental results clearly show how the proposed method is able to outperform the compared fusion algorithms...|$|E
40|$|This paper {{presents}} a novel algorithm of a scalable and efficient Pseudo-Quadrature Mirror Filters (PQMF), which is employed for partial decoding a single-layer audio bitstream such as MP 3, typically coded in joint/MS mode. The proposed algorithm {{is a new}} extension to our previous work on scalable audio decoding and is designed for asymmetric partial spectrum reconstruction (APSR), where perceptually irrelevant computations are removed. Furthermore, an efficient <b>up-sampling</b> operation is introduced for right channel output. The slight distortions introduced by our simple <b>up-sampling</b> method are inaudible according {{to a set of}} perceptual evaluations. Simulation results show that 64. 6 % energy savings can be achieved for a typical configuration in comparison to the standard PQMF algorithm employed by MPEG- 1 audio. 1...|$|R
30|$|Except for {{the input}} {{dimensions}} of the first layer and an <b>up-sampling</b> factor, the ANN topologies used for this task are {{essentially the same as}} those for pattern B. First experiments have shown that the performance of the RNN benefits from processing the control vector twice.|$|R
40|$|Abstract. This paper {{proposes a}} multirate control {{algorithm}} {{to guarantee the}} stability of haptic dental training system. In terms of a high-frequency force in-terpolating model, a multirate system with two levels <b>up-sampling</b> is intro-duced. The first level <b>up-sampling</b> achieves the haptic rendering with 1 K Hz and the second level achieves the interpolating algorithm with 10 K Hz or higher. Due to the slow velocity of dental training system, the complex virtual tooth surface {{can be regarded as}} a series of consecutive virtual tangent planes, in which the interpolating algorithm is designed with virtual wall model. Theo-retical analysis proves that the multirate control algorithm can enlarge the range of virtual stiffness and improve the stability. Numerical and experimental re-sults of a three degree-of-freedom haptic device demonstrate the effectiveness of the proposed method...|$|R
