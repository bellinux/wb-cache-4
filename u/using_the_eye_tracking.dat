13|10000|Public
50|$|In 2014 Red Bull started <b>using</b> <b>the</b> <b>Eye</b> <b>Tracking</b> Glasses as part {{of their}} Red Bull Surf Science project. At the Game Developers Conference 2014, Sony {{unveiled}} the prototype of PlayStation 4 game Infamous: Second Son with the RED-oem eye tracking system integrated into it.|$|E
50|$|Before <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> device, a {{calibration}} {{is needed}} {{in order for the}} device to find a user's pupils and identify unique eye characteristics needed to help enhance the accuracy of tracking one's gaze. The tracker has an average accuracy of about 0.5 degree of visual angle and can identify and follow the movement of an eye with sub millimeter precision, which is around the size of a fingertip.|$|E
40|$|The paper {{deals with}} author’s pilot {{experiments}} <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> method {{for the primary}} school children examination. This method enables to gain {{a large amount of}} research data based on the tested people’s eye movements monitoring. In the paper, there are processed chosen research data of four gifted students’ examination {{in the context of their}} mathematical and logical intelligence...|$|E
30|$|This {{research}} <b>used</b> <b>the</b> <b>Eye</b> <b>Tracking</b> Tobii X 1 L equipment {{with data}} capture at 30  HZ. This is high-precision equipment with dual-camera system for <b>the</b> <b>tracking</b> of both <b>eyes</b> and automatic {{light and dark}} selection for tracking pupil. The tracking recovery time after {{the blink of an}} eye is 10  ms (Tobii 2014).|$|R
50|$|In 2013 TechViz {{integrated}} SMI’s 3D <b>Eye</b> <b>Tracking</b> Glasses with TechViz 3D visualization {{software to}} enable <b>eye</b> <b>tracking</b> {{in a virtual}} reality CAVE. <b>The</b> 3D <b>Eye</b> <b>Tracking</b> Glasses were developed in partnership with Volfoni. In the same year WorldViz started cooperating with SMI to enable calculation intersects of gaze vectors with 3D objects and saving the data in one common database for deeper analysis. German Research Center for Artificial Intelligence (DFKI) <b>used</b> <b>the</b> <b>Eye</b> <b>Tracking</b> Glasses to create Talking Places - the prototype of an interactive city guide.|$|R
40|$|In this paper, we <b>use</b> <b>the</b> optical-type <b>eye</b> <b>tracking</b> {{system to}} control powered wheelchair. <b>The</b> userís <b>eye</b> {{movements}} are translated to screen position <b>using</b> <b>the</b> optical-type <b>eye</b> <b>tracking</b> system. <b>The</b> pupil-tracking goggles {{with a video}} CCD camera and a frame grabber analyzes a series of human pupil images when the user is gazing at the screen. A new calibration algorithm is then <b>used</b> to determine <b>the</b> direction of <b>the</b> <b>eye</b> gaze in real time. We design an interface with nine command zones to control powered wheelchair. The command at the calculated position of the gazed screen is then sent to move the powered wheelchair...|$|R
40|$|ABSTRACT The {{e-commerce}} {{sites have}} many dimensions {{from the final}} user’s point of view. Making websites more usable and improving the users’ experience represents an important step when desiring {{to keep them from}} moving away. This study is examining the effects of the interactivity dimensions on users’ content comprehension and their attitudes towards e-commerce websites. By <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> technology, we investigate the websites interactivity dimensions, identified in the interactivity index, exploring the visual process and drawing the time spent on the site or on various regions of it, the heatmaps, the scanpaths, the percentage fixated, the fixations before, the time to first fixation or the total fixation duration...|$|E
40|$|Bachelor {{thesis is}} focused on testing user {{experience}} of official tourism webpage for Brno - GOtoBRNO. cz. The thesis includes introduction to user experience, web design and web optimization and eye tracking a destination marketing. Significant part of the thesis is a research <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> technology. Scenario of the conducted research was assembled {{on the basis of}} consultations with the team members of the eye tracking lab of Mendel University in Brno, creators and administrators of the web (employees of TIC Brno), personal consideration and knowledge obtained from the relevant literature. All acquired data and conclusions {{made on the basis of}} the results should be understood as recommendations and its possible use I leave to the reader...|$|E
40|$|Research team headResearch team memberResearch team memberResearch team memberResearch team memberPublisher研究種目 : 若手研究(B) 研究期間 : 2015 ～ 2016 課題番号 : 15 K 19157 研究分野 : 婦人科手術近年外科手術では機能温存や低侵襲性が求められ, 低侵襲手術である腹腔鏡手術の比率が多くなっている。開腹手術の教育に役立てることを目的とし, 婦人科開腹手術画像の解析を, アイトラッキングという技術を活用して行う研究を開始した。動画に対する注視点の解析が困難であり, 手術動画以外に婦人科診療に関連する画像へ対象を広げて研究を継続した。子宮頸部病変の観察に行うコルポスコピー検査の画像も対象とした。コルポスコピー検査は, 施行者の技量によって診断は左右される。結果, 明らかな有意差は認められないものの, 熟練者においてはマイナーな所見も捉えられたのに対して, 修練者では, 「病変の境界」などの観察が不足していた。 In recent years, {{the ratio}} of laparoscopic surgery is increasing, and the {{opportunities}} for residents to experience open surgery is decreasing. In {{order to make it}} useful for the education of open surgery, we plan to perform image analysis in gynecologic open surgery <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> technique in this study. We analyzed the movements of the viewpoints of the experts and expected to be able to extract problems characteristic of the practitioner, but analysis of gaze points for moving images was more difficult than expected. And this study expanded the scope of research to images related to gynecology. Specifically, images obtained by colposcopy examination for observation of cervical lesions in gynecology were examined. The diagnosis of colposcopy is influenced by the skill of the enforcer. Although no obvious significant difference was observed, even minor abnormal lesions were distinguished by experts. Observation such as "boundary of lesion" was insufficient in practitioners...|$|E
30|$|Despite the {{importance}} of this issue to public health, there are no studies on the effectiveness of warning communications and if the target audience was really appropriately exposed to warning messages. That is, it is not known whether the proposed goals of reading warning messages are met. The reading would be the first step for the law to reach the proposed goals. One {{of the best ways to}} answer this question is to <b>use</b> <b>the</b> <b>Eye</b> <b>Tracking</b> technology. Eye-trackers are systems that estimate the gaze direction of an individual, that is, this technology enables checking where the individual is looking at. This enables identified which parts of the stimulus attracted the consumer’s attention. Therefore, the eye-tracking is one of the most suitable techniques to understand how advertising incentives and warning messages are affecting consumer behavior, especially regarding the visual attention of these stimuli (Weigle and Banks 2008).|$|R
40|$|The paper reports {{two studies}} {{concerning}} attention to and comprehension of Multimedia presentations. <b>The</b> MM sequence <b>used</b> {{was taken from}} a commercially produced CD-ROM, ‘The Etiology of Cancer’. First, an <b>eye</b> <b>tracking</b> study of <b>the</b> presentation is reported. A second study was then cortductekl ml the memorisation of <b>the</b> materials <b>used</b> in <b>the</b> <b>eye</b> <b>tracking</b> study. <b>The</b> results of <b>the</b> studies are <b>used</b> to propose guidelines to improve design of MM presentations...|$|R
25|$|Djimon Hounsou as Mose Jakande, a Somali {{mercenary}} {{and terrorist}} who leads a private military company that allies with Shaw and <b>uses</b> <b>the</b> God's <b>Eye</b> to <b>track</b> its creator and use her {{to track down}} his enemies.|$|R
40|$|The {{usage of}} eye {{trackers}} {{is becoming more}} and more popular in the field of information visualization. In this project two eye trackers, The Eye Tribe nd Mirametrix S 2, are used to obtain eye tracking data for visualizations. It is planned to use the eye trackers with OnGraX, a network visualization system, where they will provide data for the implementation of visualizations, specifically, heatmaps. OnGraX already uses heatmaps to show regions in a network that have been in the viewport of the user. One aim of this thesis will be the comparison between the two eye trackers, and if the use of eye tracking data gives better results thatn the already existing viewport-based approach. At the same time, we provide the foundation for adaptive visualizations with OnGraX. Our research problem is also of interest for visualization in general, because it will help to improve and develop eye tracking technology in this context. To support the outcome of our implementation, we carried out a user study. As a result, we concluded that one of the two eye trackers appears to have more capabilities than the other, and that <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> data is a more preferred way of depicting the heatmaps on OnGraX. ...|$|E
40|$|Objective: Children with attention-deficit / {{hyperactivity}} disorder (ADHD) react explosively and inappropriately to emotional stimuli. It could be hypothesized {{that these children}} have some impairment in attending to emotional cues. Based on this hypothesis, we conducted this study to evaluate visual directions of children with ADHD towards paired emotional scenes. Method: thirty boys {{between the ages of}} 6 and 11 years diagnosed with ADHD were compared with 30 age-matched normal boys. All participants were presented paired emotional and neutral scenes in the four following categories: pleasant-neutral; pleasant-unpleasant; unpleasant-neutral; and neutral – neutral. Meanwhile, their visual orientations towards these pictures were evaluated <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> system. The number and duration of first fixation and duration of first gaze were compared between the two groups using the MANOVA analysis. The performance of each group in different categories was also analyzed using the Friedman test. Results: With regards to duration of first gaze, which is the time taken to fixate on a picture before moving to another picture, ADHD children spent less time on pleasant pictures compared to normal group,while they were looking at pleasant – neutral and unpleasant – pleasant pairs. The duration of first gaze on unpleasant pictures was higher while children with ADHD were looking at unpleasant – neutral pairs (P< 0. 01). Conclusion: based on {{the findings of this study}} it could be concluded that children with ADHD attend to unpleasant conditions more than normal children which leads to their emotional reactivity...|$|E
40|$|Context. Gaze based {{interaction}} in video games {{is still a}} developing field, and is mostly used as an off-line evaluation tool or a replacement for traditional input methods. This thesis will look closer {{at the prospect of}} using eye tracking as an additional input to be used alongside the traditional methods of input to improve the immersion and performance of the player. Objectives. To implement a gaze based interaction method into arst person adventure in a way to improve player performance and immersion. Method. Using the Tobii REX eye tracker, 18 volunteers participated in an experiment. They played two versions of a game in an controlled environment. The versions had the same mechanics and game elements but only one of them had eye tracking implemented. After the experiment the participants answered nine questions about which prototype they preferred. Results. All participants' scores were in all cases but one, lower when <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> input method, compared to the traditional one. The time it took for the participants to complete the game was longer for everybody. 16 out of 18 players also felt more immersed in the game while using eye tracking compared to playing with the traditional input method. Conclusions. The results from the experiments provided evidence that the interaction method designed for this thesis did not improve player performance. The results also showed that the interaction method did improve immersion for most players...|$|E
40|$|Within the {{mechanical}} engineering discipline, product representational {{studies have been}} used to inform engineers on the suitability of their product designs for prospective customers. Mainly based in customers 2 ̆ 7 oral responses, engineers would modify the product design accordingly. <b>The</b> incorporation of <b>eye</b> <b>tracking</b> data, in addition to the oral responses, in these product representational studies is a recent addition. This case study performs data analysis of a product representational study conducted by Reid, MacDonald and Du (2012), which considers the impact of 2 D and 3 D product representation on customer judgments with associated <b>eye</b> gaze patterns. <b>The</b> aim of this thesis is to act as a set of guidelines for analyzing other <b>eye</b> <b>tracking</b> studies that deal with product evaluations by discussing some of the possible analysis techniques to <b>use</b> <b>the</b> <b>eye</b> <b>tracking</b> data to obtain interesting facts and patterns. The thesis presents these five guideline characteristics: (1) question-based analysis, (2) question and category dependencies, (3) product and category dependencies, (4) gender impact and (5) experiment repeatability situations. In addition, a brief comparison of the 2 D and 3 D product representation experiments is described for each guideline characteristic. ...|$|R
40|$|Objective: The aims of this {{quasi-experimental}} before-and-after study were to first determine whether <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> technology combined with video debriefing techniques {{has the potential}} {{to improve the quality of}} feedback and enhance situation awareness (SA) in simulated settings and second to determine students 2 ̆ 7 satisfaction towards simulated learning...|$|R
40|$|Abstract. Video-oculography (VOG) is a {{non-invasive}} method <b>used</b> for <b>the</b> <b>eye</b> <b>tracking</b> detecting. A most important work of VOG is to accurately estimate the pupil center. However, VOG cannot acquire <b>eye</b> movement when <b>the</b> <b>eye</b> blinks. A Grey forecasting model was proposed {{to predict the}} pupil center for the blinking frame of VOG video. The Grey forecasting model used GM(1, 1) model {{to carry on the}} modeling. Then an experiment is provided. The experiment results show that the predicted data of the Grey forecasting meet the characteristics of the patients with nystagmus. The Grey forecasting model is a viable means of accurately predict the pupil center for blinking in VOG...|$|R
40|$|Purpose Automated scanpath {{comparison}} metrics should {{deliver an}} objective method {{to evaluate the}} similarity of scanpaths. The aim of this thesis is an evaluation of seven existing scanpath comparison metrics in static and dynamic tasks {{in order to provide}} a guidline that helps to decide which algorithm has to be chosen for a special kind of task. Methods The applicability of the algorithms for a static, visual search task and a dynamic, interactive video game task as well as their constraints and limitations were tested. Therefore, binocular gaze data were recorded by <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> system The Eye Tribe (The Eye Tribe ApS, Copenhagen/ Denmark). Objective task performance measures from 21 subjects were used in order to create scanpath groupings for which a relevant effect of dissimilarity was to be expected. Objective task performance measures such as task performance time were statistically evaluated and compared to the results gained by the comparison metrics. Results Four of the algorithms being used successfully identified differences for static and dynamic tasks: MultiMatch, iComp, SubsMatch and the Hidden Markov Model. ScanMatch was very sensitive for the static task but not applicable to the dynamic task whereas FuncSim was suitable for dynamic but not for static tasks. Eyenalysis failed to detect any effect. Conclusion The applicability of scanpath comparison metrics depends {{on the state of the}} task, respectively on the kind of experimental set up. In future, the application area for eye tracking will expand and an improvement of automated scanpath comparison metrics is therefore required...|$|E
40|$|To {{compare the}} {{reproducibility}} of SD-OCT (spectral-domain optical coherence tomography) measurements of RNFL (retinal nerve fiber layer) and macular thickness between children and adults. Seventy-one eyes of 71 children and 71 eyes of 71 adults were prospectively enrolled. RNFL and macular thicknesses were measured by one operator, {{with a brief}} rest between measurements. The two measurements were obtained <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> and retest function of Spectralis SD-OCT. Reproducibility was evaluated with reference to COVs (coefficients of variation) and ICCs (intraclass correlation coefficients). The ICC values of the RNFL and macular thicknesses were compared, respectively between the two groups, by Fisher's z-test. The RNFL and macular thicknesses did not differ between the two groups. The COVs of the RNFL measurements ranged from 0. 945 to 4. 531 % in the children group and from 0. 496 to 1. 391 % in the adults group. In most of the RNFL sectors, the ICCs of the children group (range: 0. 731 - 0. 987) were significantly {{lower than those of}} the adults group (range: 0. 986 - 0. 993). The COVs of the macular measurements ranged from 0. 496 to 1. 157 % in the children group and from 0. 275 to 0. 656 % in the adults group. The ICCs (range: 0. 860 - 0. 974) in the children group, significantly lower than for the adults (range: 0. 989 - 0. 995), in all of the macular sectors. The reproducibility of SD-OCT RNFL and macular measurements for children was excellent, albeit statistically lower than that for adults...|$|E
40|$|Background Children {{growing up}} in low-income {{countries}} are at an increased risk for exposure to adverse contextual factors that may affect their cognitive development early in life. Yet, the prevalence and specific nature of cognitive problems are still poorly understood given a lack of objective, non-invasive, and field-friendly techniques for assessing early cognitive functioning in low-resource settings. In {{an effort to help}} address this gap, we carried out a study to evaluate the feasibility of using eye tracking to assess infants’ cognitive functioning in a low-income setting. Methods A battery of eye tracking tests were used to assess basic cognitive functions, such as anticipatory looking, sequence learning, and perception of facial expressions, of 39 Finnish and 37 Malawian infants 9 months of age. To evaluate the feasibility of <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> method in Malawi, we measured and compared the acceptability of the eye tracking method (the participants’ mothers’ appreciation of the method) and quality of the eye tracking data collected from the Malawian site to that of data collected from the Finnish site. The following conditions needed to be met in order for the method to be defined as feasible: (1) a proportion of Malawian participants similar to that of Finnish participants {{had to be able to}} complete the whole assessment, (2) a proportion of participating Malawian mothers similar to that of Finnish mothers had to report acceptance of the method, and (3) the eye tracking data quality in terms of attrition rate and proportion of valid trials had to be similar at the two sites (Malawi and Finland) and in parity with previous infancy eye tracking studies (i. e., attrition rate around 20 – 35 % or lower, based on Ambrosini et al. 2013, Oakes and Ellis 2013, and Watanabe et al. 2012, and proportion of valid trials in each eye tracking task at greater than 70 %, based on Forssman, Wass, and Leppänen 2014 and Leppänen et al. 2014). Results The majority of Finnish (95 %) and Malawian (92 %) infants were able to complete the whole assessment. At both sites, 95 % or more of the participating mothers reported acceptability of the method. Examination of eye tracking data quality between the Finnish and Malawian testing sites showed similar patterns, although the overall completion rate (Finland: 94. 9 %; Malawi: 91. 9 %) and the overall proportion of valid trials (Finland: 79. 5 %; Malawi: 71 %) were slightly in favor of the Finnish sample. There were however no significant differences in task-specific data attrition rates between the two samples (p =. 141 –. 946) and the attrition rates at both sites was equivalent to or better than the attrition rates reported in previous eye tracking studies with infants of similar age. Conclusions The consistency of data retention and test acceptance rate between the Finnish and Malawian samples demonstrates the feasibility of eye tracking-based assessments of infants’ cognition in low-resource settings. Based on the results from this pilot test, we believe that eye tracking is a promising tool for assessing early cognitive functions in Malawi and other low-income countries. However, further research is still needed to establish the validity of early-emerging cognitive markers as predictors of long-term health outcomes in childhood. ...|$|E
40|$|Against the {{backdrop}} of the rapid growth of <b>the</b> <b>use</b> <b>eye</b> <b>tracking</b> and facial recognition methodology, this chapter discusses <b>the</b> measurement of <b>eye</b> movements, facial expression of emotions, pupil dilation, eye blinks and head movements. After discussing some of the main research findings in the marketing literature to date, we reflect on future research and marketing applications of these technologies...|$|R
40|$|Van Mierlo, C. M. (2010, 15 November and 2 December). Eye tracking: Applications within {{cognitive}} science. Workshop {{given at}} the Open University of the Netherlands, Heerlen, The Netherlands. Detailed examples of <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> within <b>the</b> area of Visual Search in Cognitive Psychology. Discussion of <b>the</b> methods <b>used,</b> <b>the</b> {{advantages and disadvantages of}} using <b>eye</b> <b>tracking</b> in your studies and possible pitfalls you might encounter...|$|R
40|$|This work {{deals with}} <b>eye</b> <b>tracking</b> systems and {{possibility}} of using them {{for control of}} many software or hardware devices. Project explains eye anatomy and electrophysiology, types of eye trackers and methods of <b>eye</b> <b>tracking.</b> We studied methods of image processing and image analyzing in LabVIEW development system and IMAQ Vision subsystem. On the base of these studies, we created whole <b>eye</b> <b>tracking</b> system. This system can be <b>used</b> for both <b>the</b> <b>eye</b> <b>tracking</b> from video recording and real time <b>eye</b> <b>tracking.</b> This system can monitor position or trajectory of look...|$|R
40|$|Eye {{tracking}} {{research and}} research methodologies are becomingly increasingly common in many disciplines from psychology and marketing {{to education and}} learning. This is because eye tracking research and research methodologies offer new ways of collecting data, framing research questions, and thinking about how we view, see, and experience the world. Researchers are also making new findings about {{the way that the}} visual system works and the way it interacts with attention, cognition, and behaviour. As a result, research based on eye tracking research methods is increasing in every discipline. New studies using eye tracking technologies are continually being published and new applications of this innovative way of conducting research are being shared by researchers from every continent and country. Analysis of researchusing eye tracking methods is growing exponentially. Current Trends in Eye Tracking Research presents a range of new research studies using eye tracking research and research methods {{from a wide variety of}} disciplines. The research studies have been chosen to chronicle the wide applications and uses of eye tracking research. Current Trends in Eye Tracking Research is comprised of new and innovative studies using eye tracking research and research methods and showcases innovative ways of applying eye tracking technologies to interesting research problems. The book collects the research of over 55 researchers and academics currently <b>using</b> <b>the</b> <b>eye</b> <b>tracking</b> research and introduces the work of a number of eye tracking research laboratories and their key staff and research interests. Current Trends in Eye Tracking Research is designed to explore a broad range of applications of this emerging and evolving research technology and to open the research space for wider sharing of new research methods and research questions. The book incorporates a number of new studies and introduces a number of new researchers to the practitioners of eye tracking research. Current Trends in Eye Tracking Research also focuses on lessons learned in conducting eye movement research across multiple institutions, settings, and disciplines and innovative uses of existing technology as well as pioneering implementation of new technology in a range of research contexts and disciplines, key challenges, and important discoveries in moving from raw data to findings and challenges and opportunities related to situating individual research efforts in a larger research context. Current Trends in Eye Tracking Research is divided into four key sections. Each section provides a central theme that integrates the many chapters in that section. Part I is titled Eye Tracking and the Visual System and is concerned with research on the operation of the human visual system. The chapters in this section overview eye tracking and the human visual system research, and provide a series of chapters that examine how to explain the operation of the human visual system and fundamentalresearch on the use of eye tracking to deepen and strengthen our understanding of the complexity of visual processes. Part II is titled Aligning Eye Tracking and EEG Data and is concerned with research that reports on the alignment of EGG and eye tracking data. The chapters in this section overview fundamental research finding on how to link eye tracking and EEG data. The chapters in this section also address some critical research questions in integrating eye tracking data with other forms of data. The four chapters also overview current approaches to research on this alignment process. Part III is titled Eye Tracking and Marketing and Social Applications and is concerned with eye tracking based research in a range of social science and marketing disciplines. Each chapter provides a different application from a different discipline — from marketing to aging, from mental illness to evaluating forgeries to understanding what people see when they read financial reports. Each chapter provides a novel application of eye tracking research methodology in the social sciences. Part IV is titled Eye Tracking and Education and is concerned with research on learning using eye tracking methodologies. The five chapters focus on fundamental research problems in learning such as reading comprehension and the visual mechanics of comprehension, learning to read complex visual displays, and the development of student self-regulation skills. The section also explores the use of think aloud research protocols for multilingual learners...|$|E
40|$|This article surveys <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> in investiga-tions {{of online}} search. Three <b>eye</b> <b>tracking</b> {{experiments}} that we undertook are discussed and compared to additional {{work in this}} area, revealing recurring behaviors and trends. The first two studies are described in greater detail in Granka, Joachims, & Gay (2004), Lorigo et al. (2006), and Pan et al. (2007), and the third study is de-scribed {{for the first time}} in this article. These studies reveal how users view the ranked results on a search engine results page (SERP), the relationship between the search result abstracts viewed and those clicked on, and whether gender, search task, or search engine influence these behaviors. In addition, we discuss a key challenge that arose in all three studies that applies to <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> in studying online behaviors which is due to the limited support for analyzing scanpaths, or sequences of eye fixations. To meet this challenge, we present a preliminary approach that involves a graphical visualization to compare a path with a group of paths. We conclude by summarizing our findings and discussing future work in further understanding online search be-havior with <b>the</b> help of <b>eye</b> <b>tracking...</b>|$|R
50|$|First {{revealed}} on June 2, 2009, PlayStation Move is {{a motion}} control {{system for the}} PlayStation 3 based on video tracking and inertial sensors. Based on a wand controller, PlayStation Move <b>uses</b> <b>the</b> PlayStation <b>Eye</b> to <b>track</b> <b>the</b> wand's position in three dimensions through a special illuminated orb at the end. The controller was released in the EU, UK and USA in September 2010, with an Asian release date listed as October 21, 2010.|$|R
30|$|Eye tracker {{data were}} {{recorded}} across all first viewings {{for each participant}} <b>using</b> <b>the</b> Remote <b>Eye</b> <b>Tracking</b> Device (RED) system developed by SensoMotoric Instruments (SMI). This system is contact-free with automatic eye-tracking and head movement compensation solutions. The RED system provides reliable binocular and pupil gaze data and allows subjects to wear glasses or contacts. The RED system was interfaced with a laptop and stimuli were presented on a stand-alone 22 ″ monitor. Stimuli presentation and <b>eye</b> <b>tracking</b> data acquisition were controlled by Experiment Centre 3.0 and iView X, respectively. Fixations were defined temporally and spatially using a pre-set minimum fixation duration of 80 milliseconds (ms) and a maximum dispersion value of 100 pixels. Prior to commencement of the videos, a 9 -point calibration procedure was performed by the SMI Experiment Centre software.|$|R
40|$|In {{everyday}} {{and learning}} tasks, <b>the</b> <b>eyes</b> have, firstly, <b>the</b> roles of locating and recognizing objects and then, secondly, directing the actions {{to make use}} of them (Land & Tatler 2009). <b>The</b> <b>use</b> of <b>eye</b> <b>tracking</b> can reveal important aspects about students’ learning processes. Because <b>eye</b> <b>tracking</b> provides insights into the allocation of visual attention, it is very suited to study differences in learners’ attentional processes. In this section of the book, the contributions focus on the visual processes that occur when participants are performing a task...|$|R
40|$|The {{possibility}} to <b>track</b> human <b>eye</b> gaze is not new. Different <b>eye</b> <b>tracking</b> devices {{have been available}} for several years. The technology has for instance been used in psychological research, usability evaluation and in equipment for disabled people. The devices have often required the user to utilize a chinrest, a bite board or other cumbersome equipment. Hence, <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> has been limited to restricted environments. In recent years, new non-intrusive <b>eye</b> <b>tracking</b> technology has become available. This {{has made it possible}} to use <b>eye</b> <b>tracking</b> in new, natural environments. The aim {{of this study was to}} evaluate <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> in computer games. A literature study was made to gather information about eye tracker systems, existing eye gaze interfaces and computer games. The analysis phase included interviews with people working with human-computer interaction and game development, a focus group session and an evaluation of computer games. The result from the analysis constituted of a summary of interaction sequences, presumable suitable to control with <b>the</b> <b>eyes.</b> Three different prototypes of eye controlled computer games were developed. The first was a shoot’em up game where the player aimed with his eyes to shoot monsters that appeared in random places. The two other prototypes were developed with the Half Life Softwar...|$|R
40|$|The {{theoretical}} {{part of this}} thesis deals with the description of sensory processes, human eye and visual perception. The following are traffic participant and get data <b>using</b> <b>the</b> method of <b>eye</b> <b>tracking.</b> <b>The</b> practical part consisted {{in the evaluation of}} driving video recordings describing the driver's observation. The frequency and length of the pedestrian observation was evaluated, and the graphical processing was performed depending on whether the pedestrian actually crossed the road or simulated walking {{on the side of the}} roadway...|$|R
30|$|We have {{categorised}} related studies {{under three}} categories: <b>eye</b> <b>tracking</b> for user classification, <b>eye</b> <b>tracking</b> and attention/affective state and <b>eye</b> <b>tracking</b> and graphics/visualisations. In <b>the</b> first category, <b>eye</b> <b>tracking</b> {{is used to}} directly augment the student model or understand different groups of students. We then outline the research work involving <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> to understand or predict the students’ affective state, in particular to determine when students are struggling. A review of <b>the</b> research into <b>using</b> <b>eye</b> <b>tracking</b> {{to learn more about}} students’ behaviour when viewing visualisations and graphics follows, and a summary of the findings of the related work concludes this section.|$|R
40|$|Abstract: A {{powered wheel}} chair is a mobility-aided device for persons with moderate/severe {{physical}} disabilities or chronic diseases {{as well as the}} elderly. In order to take care for different disabilities, various kinds of interfaces have been developed for powered wheelchair control; such as joystick control, head control and sip-puff control. Many people with disabilities do not have the ability to control {{powered wheel chair}} <b>using</b> <b>the</b> above mentioned interfaces. The proposed model is a possible alternative. In this paper, we <b>use</b> <b>the</b> optical-type <b>eye</b> <b>tracking</b> system to control powered wheel chair. User‘s eye movement are translated to screen position <b>using</b> <b>the</b> optical type <b>eye</b> <b>tracking</b> system. When user looks at appropriate angle, then computer input system will send command to the software based on the angle of rotation of pupil i. e., when user moves his eyes balls up (move forward), left (move left), right (move right) in all other cases wheel chair will stop. Once the image has been processed it moves onto the second part, our microprocessor. The microprocessor will take a USB output from the laptop and convert the signal into signals that will be sent to the wheelchair wheels for movement. Also, the pressure and object detection sensors will be connected to our microprocessor to provide necessary feedback for proper operation of the wheelchair system. The final part of the project is the wheelchair itself. The rear wheels will provide forward. The front two wheels will be used for steering left and right. All four wheels will be connected to our microprocessor that will send signals to control the wheels and thus the overall movement...|$|R
30|$|<b>Eye</b> <b>tracking</b> {{is used in}} {{interface}} usability studies, advertising as well as developmental psychology. As {{regards to}} ITSs, <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> to increase student model bandwidth for educational purposes was first discussed in Gluck et al. (2000). <b>Eye</b> <b>tracking</b> was also used {{as a form of}} input (Wang et al. 2006), by allowing students to select a topic to study by simply looking at a portion of the screen for a pre-specified time or answer questions using eye movements. Other researchers used eye-tracking data to analyse how students interpret open learner models (Bull et al. 2007; Mathews et al. 2012).|$|R
40|$|Interactive {{evolution}} {{has shown the}} potential to create amazing and complex forms in both 2 -D and 3 -D settings. However, the algorithm is slow and users quickly become fatigued. We propose that <b>the</b> <b>use</b> of <b>eye</b> <b>tracking</b> for interactive evolution systems will both reduce user fatigue and improve evolutionary success. We describe a systematic method for testing <b>the</b> hypothesis that <b>eye</b> <b>tracking</b> driven interactive evolution will be a more successful and easierto-use design method than traditional interactive evolution methods driven by mouse clicks. We provide preliminary results that support the possibility of this proposal, and lay out future work to investigate these advantages in extensive clinical trials. 1...|$|R
40|$|<b>The</b> <b>use</b> of <b>eye</b> <b>tracking</b> in {{usability}} {{research has}} increased in the past years. The work {{presented in this paper}} reports on an empirical study that took place at the University of Aveiro. 58 participants were asked to read news on the SAPO homepage while their eye movements and mouse interaction were recorded. An analysis of their visual and interactive behavior on the news areas of interest was made as well as other areas of the homepage. Acquired results were considered, and reinforced interaction design criteria <b>used</b> in <b>the</b> reconceptualization of the actual SAPO homepage. SAPO/UA R&D Lab...|$|R
