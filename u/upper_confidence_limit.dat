86|5431|Public
5000|$|A {{tolerance}} interval is a statistical interval within which, with some confidence level, a specified proportion of a sampled population falls. [...] "More speciﬁcally, a 100×p%/100×(1−α) {{tolerance interval}} provides limits within {{which at least}} a certain proportion (p) of the population falls with a given level of conﬁdence (1−α)." [...] "A (p, 1−α) tolerance interval (TI) based on a sample is constructed {{so that it would}} include at least a proportion p of the sampled population with conﬁdence 1−α; such a TI is usually referred to as p-content − (1−α) coverage TI." [...] "A (p, 1−α) upper tolerance limit (TL) is simply an 1−α <b>upper</b> <b>confidence</b> <b>limit</b> for the 100 p percentile of the population." ...|$|E
50|$|The {{basis for}} the profile {{probability}} estimation for Y-STR analysis is the counting method. The application of a confidence interval accounts for database size and sampling variation. The Y haplotype frequency (p) is calculated using the p = x/N formula, where x {{is equal to the}} number of times the haplotype is observed in a database containing N number of haplotypes. For example, if a haplotype has been observed twice in a database of N = 2000, the frequency of that haplotype will be: 2/2000 = 0.001. Reporting a Y haplotype frequency, without a confidence interval, is acceptable but only provides a factual statement regarding observations of a Y haplotype in the database. An <b>upper</b> <b>confidence</b> <b>limit</b> for the probability of the Y haplotype in the population should be calculated using the method described by Clopper and Pearson (1934). This uses the binomial distribution for the probabilities of counts, including zero or other small numbers that are found for Y haplotypes.|$|E
40|$|On {{the basis}} of a {{negative}} binomial sampling scheme, we consider a uniformly most accurate <b>upper</b> <b>confidence</b> <b>limit</b> for a small but unknown proportion, such as the proportion of defectives in a manufacturing process. The optimal stopping rule, with reference to the twin criteria of the expected length of the confidence interval and the expected sample size, is investigated. The proposed confidence interval has also been compared with several others that have received attention in the recent literature. expected length, posterior quantile, negative binomial, sample size, score interval, uniformly most accurate, <b>upper</b> <b>confidence</b> <b>limit,...</b>|$|E
40|$|This report {{provides}} a general method of determining <b>upper</b> <b>confidence</b> <b>limits</b> {{for the failure}} probability of any combination of components when the failure history of the individual components is known. The assumptions made are that failures are independent and follow a binomial distribution. The relation between systems of <b>upper</b> <b>confidence</b> <b>limits</b> and operating characteristic curves for acceptance testing by attributes is also described. "Sandia Corporation contractors for U. S. Atomic Energy Commission" [...] Cover. "Systems Analysis. ""December 1957. "Includes bibliographical references (p. 36). This report {{provides a}} general method of determining <b>upper</b> <b>confidence</b> <b>limits</b> for the failure probability of any combination of components when the failure history of the individual components is known. The assumptions made are that failures are independent and follow a binomial distribution. The relation between systems of <b>upper</b> <b>confidence</b> <b>limits</b> and operating characteristic curves for acceptance testing by attributes is also described. Mode of access: Internet. This bibliographic record is available under the Creative Commons CC 0 public domain dedication. The University of Florida Libraries, as creator of this bibliographic record, has waived all rights to it worldwide under copyright law, including all related and neighboring rights, to the extent allowed by law...|$|R
40|$|We {{consider}} the following question: "Is there a <b>confidence</b> <b>upper</b> <b>limit</b> with given minimum coverage properties which is better than all other <b>confidence</b> <b>upper</b> <b>limits</b> with the given minimum coverage properties?". We prove that for discrete data this question is answered in the negative when certain readily checked and commonly satisfied assumptions hold true. Reliability <b>Confidence</b> <b>upper</b> <b>limit</b> Discrete data...|$|R
40|$|We present {{improved}} {{lower and}} upper bounds {{for the time}} constant of first-passage percolation on the square lattice. For the case of lower bounds, a new method, using {{the idea of a}} transition matrix, has been used. Numerical results for the exponential and uniform distributions are presented. A simulation study is included, which results in new estimates and improved <b>upper</b> <b>confidence</b> <b>limits</b> of the time constants. ...|$|R
30|$|The percent {{mortality}} was observed, and {{the average}} mortality data were subjected to Probit analysis for calculating LC 50 and, lower and <b>upper</b> <b>confidence</b> <b>limit</b> values at 95  % using the SPSS software package 9.0 ver. Results with p value of < 0.05 {{were considered to be}} statistically significant.|$|E
40|$|The Buehler 1 -[alpha] <b>upper</b> <b>confidence</b> <b>limit</b> is {{as small}} as possible, subject to the {{constraints}} that (a) its coverage probability never falls below 1 -[alpha] and (b) it is a non-decreasing function of a designated statistic T. We provide two new results concerning the influence of T on the efficiency of this confidence limit. Firstly, we extend the result of Kabaila (Statist. Probab. Lett. 52 (2001) 145) to prove that, for a wide class of Ts, the T which maximizes the large-sample efficiency of this confidence limit is itself an approximate 1 -[alpha] <b>upper</b> <b>confidence</b> <b>limit.</b> Secondly, there may be ties among the possible values of T. We provide the result that breaking these ties by a sufficiently small modification cannot decrease the finite-sample efficiency of the Buehler confidence limit. Confidence upper limit Reliability Biostatistics Discrete data Nuisance parameter...|$|E
30|$|The average larval {{mortality}} {{data were}} subjected to probit analysis for calculating LC 50, LC 90, and other statistics at 95 % confidence limits of <b>upper</b> <b>confidence</b> <b>limit</b> and lower confidence limit and Chi-square values were calculated using the SPSS 11.5 (Statistical Package of Social Sciences) software. Results with P[*]<[*] 0.05 {{were considered to be}} statistically significant.|$|E
40|$|Optimization {{methods have}} been widely applied in statistics. Among them, {{capability}} measuring techniques are widely applied in industries. Process Capability Indices (PCIs) have been proposed for measuring process production capability. This paper concentrates, the lower and <b>upper</b> <b>confidence</b> <b>limits</b> for the PCIs are obtained from generalized pivotal quantity of random model and also, use this confidence interval, the decision variables would seem to monitor the capability of production process of linear programming models and find {{the solution of the}} accepted models...|$|R
40|$|Abstract We {{present a}} {{procedure}} for estimating Q 95 low flows in both gauged and ungauged catchments where Q 95 is the flow that is exceeded 95 % of the time. For {{each step of}} the estimation procedure, a number of alternative methods was tested on the Austrian data set by leave-one-out cross-validation, and the method that performed best was used in the final procedure. To maximise the accuracy of the estimates, we combined relevant sources of information including long streamflow records, short streamflow records, and catchment characteristics, according to data availability. Rather than deriving a single low flow estimate for each catchment, we estimated lower and <b>upper</b> <b>confidence</b> <b>limits</b> to allow local information to be incorporated in a practical application of the procedure. The components of the procedure consist of temporal (climate) adjustments for short records; grouping catchments into eight seasonality-based regions; regional regressions of low flows with catchment characteristics; spatial adjustments for exploiting local streamflow data; and uncertainty assessment. The results are maps of lower and <b>upper</b> <b>confidence</b> <b>limits</b> of low flow discharges for 21 000 sub-catchments in Austria. Key words low flows; droughts; regionalisation; prediction of ungauged catchments (PUB); seasonality index; catchment grouping; regional regression; climate variability adjustment; predictive uncertaint...|$|R
30|$|For {{the four}} core years, the results {{both for the}} {{analyses}} of averages over all three periods and for the analyses of data from individual Periods were a mix {{of positive and negative}} estimates (Fig.  3). Two of the negative ones (for egg area averaged across periods and for larval area in the After period) were significantly different from zero though only marginally (Fig.  3). For the other 22 cases, the confidence intervals were not as wide as for the fifth-year estimates. While <b>confidence</b> <b>limits</b> are specific to the estimated mean, we point out that 18 of the lower <b>confidence</b> <b>limits</b> were more negative than − 20 % and almost half of the <b>upper</b> <b>confidence</b> <b>limits</b> were greater than + 20 %.|$|R
40|$|We {{present a}} new and simple method for {{constructing}} a 1 -[alpha] <b>upper</b> <b>confidence</b> <b>limit</b> for [theta] {{in the presence of}} a nuisance parameter vector [psi], when the data is discrete. Our method is based on computing a P-value P{T[less-than-or-equals, slant]t} from an estimator T of [theta], replacing the nuisance parameter by the profile maximum likelihood estimate for [theta] known, and equating to [alpha]. We provide a theoretical result which suggests that, from the point of view of coverage accuracy, this is close to the optimal replacement for the nuisance parameter. We also consider in detail limits for the (i) slope parameter of a simple linear logistic regression, (ii) odds ratio in two-way tables, (iii) ratio of means for two Poisson variables. In all these examples the coverage performance of our upper limit is a dramatic improvement on the coverage performance of the standard approximate upper limits considered. <b>Upper</b> <b>confidence</b> <b>limit</b> Profile maximum likelihood estimator Coverage error Nuisance parameter...|$|E
40|$|Competitive {{limits on}} the weakly {{interacting}} massive particle (WIMP) spin-independent scattering cross section are currently being produced by 76 Ge detectors originally designed to search for neutrinoless double beta decay, such as the Heidelberg-Moscow and IGEX experiments. In the absence of background subtraction, {{limits on the}} WIMP interaction cross section are set by calculating the <b>upper</b> <b>confidence</b> <b>limit</b> on the theoretical event rate, given the observed event rate. The standard analysis technique involves calculating the 90 % <b>upper</b> <b>confidence</b> <b>limit</b> {{on the number of}} events in each bin, and excluding any set of parameters (WIMP mass and cross-section) which produces a theoretical event rate for any bin which exceeds the 90 % <b>upper</b> <b>confidence</b> <b>limit</b> on the event rate for that bin. We show that, if {{there is more than one}} energy bin, this produces exclusion limits that are actually at a lower degree of confidence than 90 %, and are hence erroneously tight. We formulate criteria which produce true 90 % confidence exclusion limits in these circumstances, including calculating the individual bin confidence limit for which the overall probability that no bins exceeds this confidence limit is 90 % and calculating the 90 % minimum confidence limit on the number of bins which exceed their individual bin 90 % confidence limits. We then compare the limits on the WIMP cross-section produced by these criteria with those found using the standard technique, using data from the Heidelberg-Moscow and IGEX experiments. Comment: 6 pages, 3 figures, 3 tables, shortened version to appear in Phys. Rev. D, contents otherwise unchange...|$|E
40|$|We {{discuss the}} problem of {{incorporating}} the uncertainty in the experimental sensitivity into the calculation of an <b>upper</b> <b>confidence</b> <b>limit</b> on a branching ratio or similar quantity. If the number of events is small or zero but without background, the correction to the usual result is given by a simple, easily applied formula. The case of an accurately known background also has a simple solution. ...|$|E
30|$|The {{results for}} rape during years 1 – 4 (both for the {{analyses}} of averages over all three periods {{and for the}} analyses of data from individual Periods or the four core years) had a preponderance of positive estimates, i.e. {{cases in which the}} hives exposed to the treated crop were estimated to have performed better than the controls (19 / 24) (Fig.  4). None of the estimates was significantly different from zero and the <b>confidence</b> <b>limits</b> were very wide: 23 of the 24 lower <b>confidence</b> <b>limits</b> were more negative than − 20 %, with 15 more than − 50 %; 23 of the 24 <b>upper</b> <b>confidence</b> <b>limits</b> were greater than + 20 %, with 20 greater than + 50 %.|$|R
40|$|A common {{statistical}} {{issue in}} seed-quality control is {{to prove that}} the proportion of individuals showing an unwanted trait is less than a small threshold. Group testing can be used to reduce costs of assay and <b>upper</b> <b>confidence</b> <b>limits</b> for the proportion of detrimental individuals can be used for either estimation or hypothesis testing. A crucial problem of group testing is the appropriate choice of group size in dependence of the number of groups, an assumed true proportion, and the threshold. This paper reports on experimental design to achieve high power for tests or low confidence interval width. Two agricultural applications are presented for which experimental design is discussed...|$|R
40|$|A {{generalized}} {{least squares}} regression model {{was developed to}} estimate local harvest of the Western Arctic caribou (Rangifer tarandus granti) herd. This model provides herd and community level harvest based on community size, proximity of the herd to the village. The model utilizes community harvest survey information from the Alaska Department of Fish and Game, Subsistence Division and cooperation from the nonprofit organizations Maniliq and Kawerak. The model will assist in an annual selection of communities to survey. The predicted local resident harvest of the Western Arctic caribou herd is 14 700 with 95 % lower and <b>upper</b> <b>confidence</b> <b>limits</b> of 10 100 and 19 700 respectively...|$|R
40|$|This report {{presents}} background {{concentrations of}} 17 trace elements in groundwater in the Netherlands. The {{three types of}} background concentrations distinguished are natural, semi-natural and regional. Natural background concentration is the concentration at locations without any human influence. Because these types of locations are {{not found in the}} Netherlands natural background concentrations for groundwater are, as a first approach, estimated by deriving the <b>upper</b> <b>confidence</b> <b>limit</b> of the median trace metal concentration at the above-mentioned locations with only diffuse pollution. Semi-natural background concentration is the concentration at locations not influenced by point sources of pollution. The locations may be influenced by diffuse pollution occurring on a national scale. This is determined by calculating the <b>upper</b> <b>confidence</b> <b>limit</b> of the 90 -percentile of the concentration at this type of locations. Regional background concentrations are concentrations occurring at locations with an elevated regional atmospheric deposition but without local point sources of pollution. Regional background concentrations have been derived for trace metals in groundwater found in the sands {{in the southern part of}} the Netherlands. The southern part of the Netherlands, with mainly sandy soil, has a well-known history of relatively high atmospheric trace metal deposition due to the presence of a zinc industry. In addition, this region has suffered from a high atmospheric acid deposition, mainly due to the presence of high intensive animal farming in this region (ammonia emission and deposition). The combination of a high deposition and vulnerable soils is probably the cause of the high trace-metal concentrations in groundwater. Regional background concentrations are determined by calculating the <b>upper</b> <b>confidence</b> <b>limit</b> of 90 -percentile of the concentration at these type of locations. Data from this region have not been used to derive natural and semi-natural background concentrations in groundwater in sandy soils for beryllium, cadmium, cobalt, nickel and zinc. Natural and semi-natural background concentrations are given for each of the soil types, with different background concentrations specified for different depths in the groundwater. The three soil types distinguished are sand, clay and peat. The three levels distinguished: are upper groundwater (> 5 m), shallow groundwater (ca. 10 m) and deep groundwater (ca. 25 m) ...|$|E
40|$|Consider the {{reliability}} problem {{of finding a}} 1 -[alpha] upper (lower) confidence limit for [theta] the probability of system failure (non-failure), based on binomial data on the probability of failure of each component of the system. The Buehler 1 -[alpha] confidence limit is usually based on an estimator of [theta]. This confidence limit has the desired coverage properties. We prove that in large samples the Buehler 1 -[alpha] <b>upper</b> <b>confidence</b> <b>limit</b> based on an approximate 1 -[alpha] upper limit for [theta] is less conservative, whilst also possessing the desired coverage properties. Reliability Confidence limit Discrete data...|$|E
40|$|In this paper, {{we develop}} an {{approach}} for optimizing the explicit binomial confidence interval recently derived by Chen et al. The optimization reduces conservativeness while guaranteeing prescribed coverage probability. 1 Explicit Formula of Chen et al. Let X be a Bernoulli random variable defined in probability space (Ω,F,Pr) with distribution Pr{X = 1 } = 1 − Pr{X = 0 } = p ∈ (0, 1). It {{is a frequent}} problem to construct a confidence interval for p based on n i. i. d. random samples of X. limit Recently, Chen et al. have proposed an explicit confidence interval in [1] with lower confidence and <b>upper</b> <b>confidence</b> <b>limit</b> Ln,δ = K...|$|E
40|$|The acute static renewal {{test of a}} botanical {{pesticide}} - azadirachtin for the freshwater catfish, Heteropneustes fossilis {{has been}} performed to determine the LC 50 values at different exposure period. The LC 50 values at various exposure periods are 173. 06 mg L - 1 for 24 h; 80. 69 mg L - 1 for 48 h; 58. 57 mg L - 1 for 72 h and 52. 35 mg L - 1 for 96 h. The <b>upper</b> <b>confidence</b> <b>limits</b> were 196. 87, 86. 91, 79. 20 and 70. 04 mg L - 1 for 24, 48, 72 and 96 h and lower <b>confidence</b> <b>limits</b> were 154. 01, 74. 24, 37. 33 and 33. 83 mg L - 1, respectively. These results indicate that azadirachtin exposure to the fish caused toxic effects. </p...|$|R
5000|$|The {{determination}} of the confidence interval of Pc makes use of Student's t-test (t). The value of t depends {{on the number of}} data and the confidence level of the estimate of the confidence interval. Then, the lower (L) and <b>upper</b> (U) <b>confidence</b> <b>limits</b> of Pc in a symmetrical distribution are found from: ...|$|R
40|$|The paper {{develops}} {{and studies}} simultaneous confidence bounds that {{are useful for}} making low dose inferences in quantitative risk analysis. Application is intended for risk assessment studies where human, animal or ecological data are used to set safe low dose levels of a toxic agent, but where study information is limited to high dose levels of the agent. Methods are derived for estimating simultaneous, one-sided, <b>upper</b> <b>confidence</b> <b>limits</b> on risk for end points measured on a continuous scale. From the simultaneous confidence bounds, lower <b>confidence</b> <b>limits</b> on the dose {{that is associated with}} a particular risk (often referred to as a "bench-mark dose") are calculated. An important feature of the simultaneous construction is that any inferences that are based on inverting the simultaneous confidence bounds apply automatically to inverse bounds on the bench-mark dose. Copyright 2005 Royal Statistical Society. ...|$|R
40|$|The US Environmental Protection Agency (EPA) {{recommends}} {{the use of}} an <b>upper</b> <b>confidence</b> <b>limit</b> in making a decision of whether a possibly polluted environment needs clean-up. This decision rule, however, is frequently too conservative and {{does not take into account}} the costs and/or benefits from making a correct or a wrong decision. In this paper we propose an asymmetric loss function and a Bayesian decision rule for remediation actions. The new loss function accounts for both false-positive and false-negative errors possibly involved in a decision, and accommodates the needs of both the EPA and other parties involved. Asymmetric loss Costs and risks Action-level-concentration Superfund program...|$|E
40|$|The topical {{carcinogenicity}} to mouse skin {{of smoke}} condensates {{obtained from a}} tobacco substitute (NSM), alone or in combination with tobacco, has been compared with condensate from tobacco and with acetone, the solvent used. Sixteen different types of cigarette were {{used to make the}} condensates, and the age-standardized results have been analysed according to the Weibull distribution model. The results show that NSM condensate has less than 25 % of the potency of tobacco condensate (37 % at 95 % <b>upper</b> <b>confidence</b> <b>limit),</b> and that condensates from blends of NSM and tobacco are similarly reduced in activity. General pathology analysis failed to reveal abnormalities due to NSM...|$|E
40|$|Background: Switching off air {{handling}} systems in operating theaters {{during periods of}} prolonged inactivity (eg, nights, weekends) can produce a substantial reduction of energy expenditure. However, little evidence is available regarding the effect of switching off the {{air handling}} system during periods of prolonged inactivity on the air quality in operating theaters during operational periods. The {{aim of this study}} is to determine the amount of time needed after restarting the ventilation system to return to a stable situation, with air quality at least equal to the situation before switching off the system. Methods: Measurements were performed in 3 operating theaters, all of them equipped with a unidirectional downflow(UDF) system. Measurements (particle counts of emitted particles with a particle size ≥ 0. 5 μm) were taken during the start-up of the ventilation system to determine when prespecified degrees of protectionwere achieved. Temperature readingswere taken to determine when a stable temperature difference between the periphery and the protected area was reached, signifying achievement of a stable condition. Results: After starting up the system, the protected area achieved the required degrees of protection within 20 minutes (95 % <b>upper</b> <b>confidence</b> <b>limit).</b> A stable temperature difference was achieved within 23 minutes (95 % <b>upper</b> <b>confidence</b> <b>limit).</b> Both findings lie well within the period of 25 minutes normally required for preparations before the start of surgical procedures. Conclusions: Switching off the ventilation systemduring prolonged inactivity (during the night andweekend) has no negative effect on the air quality in UDF operating theaters during normal operational hour...|$|E
40|$|The three-parameter {{lognormal}} distribution is {{the extension of}} the two-parameter {{lognormal distribution}} to meet the need of the biological, sociological, and other fields. Numerous research papers have been published for the parameter estimation problems for the lognormal distributions. The inclusion of the location parameter brings in some technical difficulties for the parameter estimation problems, especially for the interval estimation. This paper proposes a method for constructing exact confidence intervals and exact <b>upper</b> <b>confidence</b> <b>limits</b> for the location parameter of the three-parameter lognormal distribution. The point estimation problem is discussed as well. The performance of the point estimator is compared with the maximum likelihood estimator, which is widely used in practice. Simulation result shows that the proposed method is less biased in estimating the location parameter. The large sample size case is discussed in the paper...|$|R
40|$|The {{interval}} {{estimation of the}} survival function of the two-parameter exponential distribution {{on the basis of}} the progressively Type-II censored samples is investigated. Toward this end, the concept of the generalized confidence intervals (GCIs) is used and the lower and <b>upper</b> generalized <b>confidence</b> <b>limits</b> (GCLs) are obtained. It will be shown that the coverage probabilities of the GCLs are satisfactory using a simulation study. Finally, some concluding remarks are presented...|$|R
40|$|Static renewal {{evaluation}} of the acute toxicity of an organophosphate pesticide, dimethoate against the freshwater fish H. fossilis was conducted in the laboratory. H. fossilis showed behavioural changes against dimethoate intoxication. There were increased opercular movement, sluggish, lethargic and abnormal swimming, loss of buoyancy and muscular tetany. The treated fishes also showed fading of their body colour. The LC 50 values of dimethoate to the freshwater catfish, Heteropneustes fossilis at various exposure periods are 15. 92 mg/l for 24 h; 13. 42 mg/l for 48 h; 12. 39 mg/l for 72 h and 11. 34 mg/l for 96 h. The <b>upper</b> <b>confidence</b> <b>limits</b> were 16. 59, 14. 72, 13. 54 and 12. 86 mg/l for 24, 48, 72 and 96 h and lower <b>confidence</b> <b>limits</b> were 15. 32, 12. 18, 11. 23 and 9. 79 mg/l, respectively. From the present study {{it seems that the}} freshwater catfish, H. fossilis is more susceptible to dimethoate toxicity as the LC 50 value for this organophosphate is less than other reported fish species. These results indicate that dimethoate exposure to the fish caused toxic effects...|$|R
40|$|Abstract. The brittle is {{crippling}} {{the application}} of bioceramic. The compound bioceramic is a new biomaterial being widely applied in medical treatments and its fracture toughness is an important mechanical behaviors. In this paper, we introduce the manufacturing method of the compound bioceramic and experiment facilities for its fracture toughness, investigate its probability distribution for the experimental data and conduct the test for fit. We conclude that the experimental data for the toughness fracture of the compound bioceramic obey the two-parameter Weibull distribution, introduce the analyzing method for the <b>upper</b> <b>confidence</b> <b>limit</b> curve and lower confidence limit curve and study the reliability and confidence level of the fracture toughness of the compound bioceramic...|$|E
40|$|The {{objective}} {{of this study is}} to compare interval estimation methods for population means of positively skewed distributions. The estimation methods are the interval estimation method with student-t statistics, the interval estimation method with Johnson’s statistics, the interval estimation method with Hall’s statistics and the interval estimation method with Chen’s statistics. Log-normal distribution and Weibull distribution are considered. The measures of skewness under the consideration are 1. 0, 3. 0, 5. 0, respectively. The sample sizes are 10, 30, 50 and the confidence levels are 0. 95. The consideration has two steps. First, the confidence level of interval estimation methods are not lower than the determined confidence level value. The second is the comparision of mean of lower confidence limit, mean of <b>upper</b> <b>confidence</b> <b>limit</b> and mean of confidence interval length. The experimental data are generated by the Monte Carlo Simulation technique. The confidence level of interval estimation method with Bootstrap is higher than the non-boot-strap. The interval estimation method with Johnson’s statistics is the optimum estimation method for the upper confidence interval and two-tailed confidence interval. The interval estimation method with Chen’s statistics is the optimum estimation method for the lower confidence interval. Commonly, the confidence level of interval estimation methods for upper confidence interval are varied by the measure of skewness butthe confidence level of interval estimation methods for lower confidence interval and two-tailed confidence interval are converted by the measure of skewness. The mean of lower confidence limit is varied by the sample size, on the other hand, the mean of <b>upper</b> <b>confidence</b> <b>limit</b> and mean of confidence interval length are converted by the sample size...|$|E
40|$|Shock is {{accompanied}} by generalised splanchnic hypoperfusion, and splanchnic organs like the pancreas can be damaged, as shown in animal experimental models and in humans, {{by the presence of}} high plasma concentrations of trypsin and other pancreatic enzymes. In order to design a radioimmunoassay technique (RIA) for the measurement of equine trypsin-like immunoreactivity (TLI) in biological fluids, trypsin was purified (with purity {{greater than or equal to}} 96 %) from the equine pancreas by extraction in an acid medium, ammonium sulfate precipitations, gel filtration chromatography and, after activation of trypsinogen into trypsin, affinity chromatography. Gel polyacrylamide electrophoresis showed a monomeric enzyme with a molecular weight of 27 kDa. The purified equine trypsin served for the immunisation of rabbits in order to obtain a specific antiserum, and the labelled antigen was prepared by iodination of equine trypsin with I- 125. The RIA was based on the binding of the antigen to the antibody followed by the separation of the antigen-antibody complex by immunoprecipitation in the presence of sheep anti-rabbit gammaglobulins and the assay of the radioactivity in the precipitate. The RIA showed good sensitivity, specificity, precision, accuracy and reproducibility. The reference mean value of TLI in the plasma of healthy horses (n = 20) was 30. 01 +/- 6. 84 ng/mL (<b>upper</b> <b>confidence</b> <b>limit</b> 50. 52 ng/mL; p < 0. 01). Three horses with non strangulating intestinal obstruction without shock showed TLI values within normal limits whereas 5 of 7 horses with strangulation obstruction showed TLI levels above the <b>upper</b> <b>confidence</b> <b>limit.</b> Further studies using the RIA and the enzymatic assay should be performed in order to confirm the role of the pancreas in equine intestinal obstruction. Peer reviewe...|$|E
40|$|Southern Guangxi, China {{has one of}} {{the highest}} incidences of {{hepatocellular}} carcinoma (HCC) in the world. Serum samples collected from subjects of an earlier case-control study (39 cases, 41 controls) and from a random sampling of a residential male cohort (n = 100) were tested for antibodies for the hepatitis C virus (anti-HCV) using ELISA version 2. 0 with confirmation by RIBA version 2. 0. Only one of 141 (0. 7 %, <b>upper</b> 95 % <b>confidence</b> <b>limit,</b> 3. 2 %) control subjects and none of 39 (<b>upper</b> 95 % <b>confidence</b> <b>limit,</b> 6. 07 %) HCC cases tested positive for anti-HCV. Our results indicate that hepatitis C infection is not an important environmental determinant of HCC risk in this hyperendemic region...|$|R
40|$|The lesion {{location}} (cochlear vs. retrocochlear) of {{sensorineural hearing}} loss may be differentiated with a diagnostic index (delta V), which is calculated from the wave V latency of the monaurally evoked auditory brainstem response (ABR), and from the pure-tone hearing threshold at 2 and 4 kHz. The delta V values obtained from 80 recruiting ears have proven to correlate linearly {{to the amount of}} the hearing loss, hence allowing to define appropriate confidence boundaries for cochlear hearing losses. In contrast, the delta V values obtained from 32 ears of patients with retrocochlear lesions [...] cerebellopontine angle (CPA) tumors [...] were all found to exceed the 95 % <b>upper</b> <b>confidence</b> <b>limits</b> projected for cochlear lesions, thus giving a 100 % rate of true results in the detection of retrocochlear pathology. These results, providing an ABR parametric model for the cochlear hearing loss, suggest a diagnostic strategy for the early detection of CPA tumors based on the exclusion of a cochlear hearing loss...|$|R
5000|$|An {{analogous}} problem {{arises in}} the construction of confidence intervals. For instance, the Clopper-Pearson interval is always conservative because of the discrete nature of the binomial distribution. An alternative is to find the <b>upper</b> and lower <b>confidence</b> <b>limits</b> [...] and [...] by solving the following equations: ...|$|R
