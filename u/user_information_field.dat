0|10000|Public
40|$|Iterative {{design of}} a high infomation-bandwidth, mobile {{augmented}} reality interface. The Mobile Infosphere test bed at Michigan State University is designed to explore mobile interface issues, implementations, and design options. This paper discusses about the human-factors research on how a mobile <b>user</b> structures an <b>information</b> <b>field</b> of data and tools around the user and the environment. Because {{a great deal of}} human cognitive capacity is allocated to perceiving, using, and remembering the spatial relation of objects in the environment relative to the individual, our current approach is to find ways to make optimal use of human spatial cognition for information manipulation and storage in a mobile augmented reality environment...|$|R
40|$|Letters and memos at Los Alamos National Laboratory (LANL) are {{formatted}} {{in accordance}} with rules established in the Laboratory's Ofice Procedures Manual. UTEX style files were written to let people produce letters and memos without worrying about a complicated set of rules. Macro and template files are distributed through the Laboratory's Change Control system. A testbed of several hundred test files is used to minimize bugs in the distributed versions. There is a choice of Computer Modern fonts or Postscript fonts. Memos and letters can be printed in Roman or typewriter typefaces. When called for, classification labels will be printed on every page. Headers on pages following the first page are compiled from information found on the first page. Letters can handle multiple addresses. Default options are provided where applicable, and error messages warn <b>users</b> about missing <b>information</b> <b>fields...</b>|$|R
40|$|Various {{strategies}} {{have been proposed}} to enhance web search through utilizing individual <b>user</b> <b>information.</b> However, considering the well acknowledged recurring queries and repetitive clicks among users, it is still an open issue whether using individual <b>user</b> <b>information</b> is a proper direction of efforts in improving the web search. In this paper, we first quantitatively demonstrate that individual <b>user</b> <b>information</b> is more beneficial than common <b>user</b> <b>information.</b> Then we statistically compare the benefit of individual and common <b>user</b> <b>information</b> through Kappa statistic. Finally, we calculate potential for personalization to present an overview of what queries can benefit more from individual <b>user</b> <b>information.</b> All these analyses are conducted on both English AOL log and Chinese Sogou log, and a bilingual perspective statistics consistently confirms our findings. ...|$|R
5000|$|Data {{terminal}} equipment, an end {{instrument that}} converts <b>user</b> <b>information</b> into signals for transmission or reconverts the received signals into <b>user</b> <b>information</b> ...|$|R
50|$|In {{telecommunications}} systems, <b>user</b> <b>information</b> includes <b>user</b> overhead <b>information.</b>|$|R
50|$|In {{computer}} networking, the Name/Finger {{protocol and}} the Finger <b>user</b> <b>information</b> protocol are simple network protocols for {{the exchange of}} human-oriented status and <b>user</b> <b>information.</b>|$|R
50|$|The {{property}} {{that allows a}} transmission system or channel to accept, at its input, unmodified <b>user</b> <b>information,</b> and deliver corresponding <b>user</b> <b>information</b> at its output, unchanged in form or <b>information</b> content. The <b>user</b> <b>information</b> may be changed internally within the transmission system, but it is restored to its original form prior to the output without {{the involvement of the}} user.|$|R
40|$|Machine-learning {{techniques}} {{play the}} important roles for information filtering. The main objective of machine-learning is to obtain users' profiles. To decrease {{the burden of}} on-line learning, {{it is important to}} seek suitable structures to represent <b>user</b> <b>information</b> needs. This paper proposes a model for information filtering on the Web. The <b>user</b> <b>information</b> need is described into two levels in this model: profiles on category level, and Boolean queries on document level. To efficiently estimate the relevance between the <b>user</b> <b>information</b> need and documents, the <b>user</b> <b>information</b> need is treated as a rough set on the space of documents. The rough set decision theory is used to classify the new documents according to the <b>user</b> <b>information</b> need. In return for this, the new documents are divided into three parts: positive region, boundary region, and negative region. An experimental system JobAgent is also presented to verify this model, and it shows that the rough set based model can provide an efficient approach to solve the information overload problem...|$|R
30|$|Thirdly, the JHPeer {{framework}} supports push recommendations. A <b>user</b> <b>information</b> needs module {{is desirable}} to detect <b>user</b> <b>information</b> needs and request recommendation services in application layer to push just-in-time recommendations to users. Bringing this module may simplify applications development using the JHPeer framework.|$|R
5000|$|... #Subtitle level 3: <b>User</b> <b>information</b> {{initiating}} fraudulent transfers ...|$|R
40|$|This {{enlarged}} {{and expanded}} edition {{is designed to}} be a valuable resource for librarians and <b>users</b> of <b>information</b> sources, clarifying the bewidering number of new acronyms that appear every year in the <b>information</b> science <b>field.</b> Nearly 30, 000 acronyms in 35 languages are listed. As libraries are to a large extent interdisciplinary, the dictionary covers language forms used in computers, publishing, printing, archive management, journalism and reprography, {{as well as in the}} library and <b>information</b> science <b>fields</b> Acronyms reproduced here represent institutions, library and information systems, p...|$|R
50|$|<b>User</b> <b>information</b> bits are encoded to form channel bits.|$|R
40|$|In {{the task}} of {{adaptive}} information filtering, a system receives a stream of documents but delivers only those that match a person's information need. As the system filters it also refines its knowledge about the <b>user's</b> <b>information</b> needs based on relevance feedback from the user. Delivering a document thus has two e#ects: i) it satisfies the <b>user's</b> <b>information</b> need immediately, and ii) it helps the system better satisfy the user in the future by improving its model of the <b>user's</b> <b>information</b> need. The traditional approach to adaptive information filtering fails to recognize and model this second e#ect...|$|R
40|$|PREFACE [...] …iv Scope [...] …. iv <b>User</b> <b>Information</b> [...] i...|$|R
50|$|The BBC began {{providing}} real-time global <b>user</b> <b>information</b> in June 2006.|$|R
50|$|There {{are several}} ways for third parties to access <b>user</b> <b>information.</b>|$|R
500|$|... scheme [...] <b>user</b> <b>information</b> [...] host [...] port [...] query [...] {{fragment}} ...|$|R
5000|$|Present {{a unified}} virtual view of <b>user</b> <b>information</b> stored across {{multiple}} systems.|$|R
30|$|In {{order to}} collect <b>user</b> <b>information</b> and analyze <b>user</b> {{behavior}} in some electronics markets, they will implement third party plug-ins {{to their own}} market in popular software in which may reveal <b>user</b> privacy <b>information.</b>|$|R
50|$|Because Lynx {{does not}} support graphics, web bugs that track <b>user</b> <b>information</b> are not fetched; therefore, web pages can be read without the privacy {{concerns}} of graphic web browsers. However, Lynx does support HTTP cookies, which {{can also be used}} to track <b>user</b> <b>information.</b> Lynx therefore supports cookie whitelisting and blacklisting, or alternatively cookie support can be disabled permanently.|$|R
40|$|In this paper, {{we propose}} an {{interactive}} segmentation method to apply <b>user</b> <b>information</b> during the segmentation {{of a specific}} anatomic structure. This method is formulated to use belief propagation to minimize a global cost function according to local level sets. The propagation starts with one user labeled point, and iteratively extends the <b>user</b> <b>information</b> from the labeled pixel to its neighborhood by calculating the beliefs of the pixels in {{the same level as}} the labeled pixel. Since the segmentation relies on both local <b>user</b> <b>information</b> and global image features, it is less interrupted by noise, and works well even the target is not obvious to its neighbor. The promising segmentation results also show that our method is robust to the objects with high shape variation and inhomogeneous intensity value appearance. Index Terms — Interactive segmentation, level set method, belief propagation, <b>user</b> <b>information,</b> medical imag-ing I...|$|R
5000|$|Internal context - <b>user</b> <b>information,</b> {{to include}} {{personal}} preferences, location, speed, and orientation ...|$|R
50|$|The {{following}} method {{shows how}} to use the Cache object to retrieve data from the cache. In this example, a user identifier (userid) is the key for the associated <b>user</b> <b>information</b> object. The code first attempts to get this <b>user</b> <b>information</b> from the cache using the userid key. If that does not succeed, the code retrieves the information with a database query and then stores the returned user data in the cache. The next time the same code is run, the <b>user</b> <b>information</b> will be returned from the cache rather than the database. This assumes that the cached data has not been expired or evicted.|$|R
3000|$|Then, the {{following}} question arises. From the discussion to {{this point in the}} paper, we can define user-centric system as a system that [...] "understands" [...] (is able to capture) the <b>user's</b> <b>information</b> need in order to satisfy it effectively. But how can the system be user-centric and satisfy sufficiently the <b>user's</b> <b>information</b> need without being able to capture it? [...]...|$|R
50|$|The {{company that}} owned Ghostery, Ghostery, Inc. (previously Evidon), plays a dual {{role in the}} online {{advertising}} industry. Ghostery blocks marketing companies from gathering website <b>user</b> <b>information,</b> but it makes money from selling page visit, blocking and advertising statistics to corporations globally, including corporations that are actively engaged in collecting <b>user</b> <b>information</b> to target ads and other marketing messages to consumers.|$|R
40|$|Nowadays, {{the rapid}} {{development}} of the Internet {{has given rise to}} a global murky underground business, which is called the hacker economy industry. Numerous individuals and companies have become victims of the industry. In essence, the leakage of <b>user</b> <b>information</b> which facilitates the operation of the industry is the chief culprit. Hackers all over the world have invented hundreds and thousands of sophisticated schemes to obtain <b>user</b> <b>information.</b> Once <b>user</b> <b>information</b> is obtained, a full utilization of it will be performed by hackers until ultimately, the value of it is drained out. In order to present a general picture of the hacker economy industry, we in this paper perform a detailed analysis of websites, malware, hackers, and users. In addition, we elaborate the operations and the structure of the hacker economy industry. Lastly, we point out the direction of possible countermeasures for guarding <b>user</b> <b>information</b> which facilitates a further in-depth study and present a case study to illustrate our work...|$|R
40|$|One-Class Collaborative Filtering (OCCF) is an {{emerging}} setup in collaborative filtering {{in which only}} positive examples or implicit feedback can be observed. Compared with the traditional collaborative filtering setting where the data has ratings, OCCF is more realistic in many scenarios when no ratings are available. In this paper, we propose to improve OCCF accuracy by exploiting the rich <b>user</b> <b>information</b> that is often naturally available in community-based interactive information systems, including a user’s search query history, purchasing and browsing activities. We propose two ways to incorporate such <b>user</b> <b>information</b> into the OCCF models: one is to linearly combine scores from different sources {{and the other is}} to embed <b>user</b> <b>information</b> into collaborative filtering. Experimental results on a largescale retail data set from a major e-commerce company show that the proposed methods are effective and can improve the performance of the One-Class Collaborative Filtering over baseline methods through leveraging rich <b>user</b> <b>information...</b>|$|R
40|$|Combining the {{language}} model and inference network, as {{implemented in the}} Indri search engine, is efficient and verified approach. In this retrieval model, the <b>user’s</b> <b>information</b> need is exhibited as Indri’s Structural Query Language. Although the SQL allows expert users to richly represent its information needs but unfortunately, the complicacy of SQLs make them unpopular in the WEB for ordinary ones. Au-tomatically detecting the concepts in a <b>user’s</b> <b>information</b> need and generate a richly structured equivalent query is a good solution. It needs a concept repository {{and a way to}} extracting appropriate concepts from the <b>user’s</b> <b>information</b> need. We utilize Wikipedia as a great, multilingual, free-content encyclopedia for our knowledge base and also some state of the art algorithms for extracting Wikipedia’s concepts from the <b>user’s</b> <b>information</b> need. This process is called “Query Wikification”. Mining Wikipedia concept repository help us to propose a solution that supports usability in multilingual environments, cross-language retrievals, scalability and covering erra-tum, various equivalents and synonyms of a concept. Experimental results verify tha...|$|R
50|$|In 2007 {{there was}} a Facebook revolt over the selling of <b>user</b> <b>information</b> to advertisers.|$|R
5000|$|... {{updating}} <b>user's</b> <b>information</b> such {{as first}} and last names, address, etc. associated with the account; ...|$|R
50|$|Precision is the {{fraction}} of the documents retrieved {{that are relevant to}} the <b>user's</b> <b>information</b> need.|$|R
30|$|Such an {{approach}} requires the RP {{to know the}} <b>user</b> <b>information</b> in advance (as {{is the case for}} the solution discussed in Section 4). We exploit this knowledge by modifying the form of the request provided by the RP. That is, instead of asking for <b>user</b> personal <b>information,</b> the RP asks for the IdP to confirm that specific statements about the <b>user's</b> personal <b>information</b> are correct.|$|R
40|$|The Digital Technical Documentation Handbook {{describes}} {{the process of}} developing and producing technical <b>user</b> <b>information</b> at Digital Equipment Corporation. * Discusses techniques for making <b>user</b> <b>information</b> _more effective * Covers the draft and reviewprocess, the production and distribution of printed and electronic media, archiving, indexing, testing for usability, and many other topics * Provides quality assurance checklists, contains a glossary and a bibliography of resources for technicalcommunicator...|$|R
50|$|Once {{the network}} has {{established}} a connection, the edge node of the Frame Relay network must monitor the connection's traffic flow {{to ensure that the}} actual usage of network resources does not exceed this specification. Frame Relay defines some restrictions on the <b>user's</b> <b>information</b> rate. It allows the network to enforce the end <b>user's</b> <b>information</b> rate and discard information when the subscribed access rate is exceeded.|$|R
40|$|International audienceThe {{information}} resource sharing {{system as a}} information movement, will guide users to access and use knowledge or information as the information commons. Many barriers existed in information sharing systems due to the less consideration of the users’ behavior in information utilization by designers of the information sharing systems. Therefore, the design of information sharing systems should be fully aware of and respect for <b>user</b> <b>information</b> behaviors, and on this basis, {{to adhere to the}} design concept of the <b>user</b> <b>information</b> behavior laws in order to truly complete the mission of the information sharing systems. Otherwise, the principle of <b>user</b> <b>information</b> behaviors will most likely constitute the information sharing “regularity disorder”...|$|R
40|$|Understanding or {{acquiring}} a <b>user's</b> <b>information</b> needs from their local information repository (e. g. {{a set of}} example-documents {{that are relevant to}} <b>user</b> <b>information</b> needs) is important in many applications. However, acquiring the <b>user's</b> <b>information</b> needs from the local information repository is very challenging. Personalised ontology is emerging as a powerful tool to acquire the <b>information</b> needs of <b>users.</b> However, its manual or semi-automatic construction is expensive and time-consuming. To address this problem, this paper proposes a model to automatically learn personalised ontology by labelling topic models with concepts, where the topic models are discovered from a <b>user's</b> local <b>information</b> repository. The proposed model is evaluated by comparing against ten baseline models on the standard dataset RCV 1 and a large ontology LCSH. The results show that the model is effective and its performance is significantly improved...|$|R
