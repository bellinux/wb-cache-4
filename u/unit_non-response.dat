46|14|Public
50|$|Firstly, item {{non-response}} {{needs to}} be addressed. Non-response can either be 'unit'- where a person gave no response {{for any of the}} n items, or 'item'- i.e., individual question. <b>Unit</b> <b>non-response</b> is generally dealt with exclusion. Item non-response should be handled by imputation- the method used can vary between test and questionnaire items. Literature about the most appropriate method to use and when can be found here.|$|E
40|$|This paper {{estimates}} {{associations between}} individual and neighborhood characteristics and <b>unit</b> <b>non-response</b> {{in a survey}} of the population aged 50 and over in the Netherlands in 2004. The statistical model includes interviewer fixed effects to control for the non-random distribution of addresses over interviewers. The empirical analysis shows that, relative to individuals living in apartments, there is a lower <b>unit</b> <b>non-response</b> among individuals living in houses and a higher <b>unit</b> <b>non-response</b> among individuals living in old age institutions. <b>Unit</b> <b>non-response</b> is positively associated with the size of a city. No age and gender effects are found. <b>Unit</b> <b>non-response</b> is about 25 percent lower among individuals in the top than among individuals {{in the bottom of the}} distribution of neighborhood average income. This latter result implies that the response sample is biased toward individuals living in the more wealthy neighborhoods. 1...|$|E
40|$|Sampling {{surveys are}} more than often {{affected}} by non-response. More so, the process of data collection is practically never free of non-response. Because of the damage that it has on survey estimates, taking measures of prevention and the treating for non-response it is clearly necessary. Considering the fact that non-response is a two-level phenomenon, i. e. item and <b>unit</b> <b>non-response,</b> the measures differ on {{the two types of}} non-response. The paper presents an overview of the methods used for prevention and control for item non-response and <b>unit</b> <b>non-response.</b> Key words: survey non-response, item non-response, <b>unit</b> <b>non-response,</b> prevention methods...|$|E
5000|$|... 32 <b>Non-Response</b> <b>Units</b> - Used for patrol, however not {{emergency}} response.|$|R
40|$|Process-generated and {{administrative}} datasets {{have become increasingly}} important for labour market research {{over the past ten}} years. Major advantages of this data are large sample sizes, absence of retrospective gaps and <b>unit</b> <b>non-responses.</b> Nevertheless, the quality and validity of the information remain unclear. This paper contributes to this subject, focusing on the variation of research results due to alternative data cleansing procedures. In particular, the paper uses the general set up for data cleaning proposed by Wunsch/Lechner (2008) in evaluating the outcome of training programmes in Germany. First results are limited to the sensitivity of the construction of the sample populations used for the counterfactual analysis. The results emphasize that sample construction seems to be robust to the scenario used for the data cleansing. " (Author's abstract, IAB-Doku) ((en)) Arbeitsmarktforschung, Wirkungsforschung, Forschungsmethode, prozessproduzierte Daten, Datenqualität, Validität, Datenaufbereitung, Stichprobenverfahren, Non Response...|$|R
3000|$|... differ {{somewhat}} {{from those}} estimated {{on the survey}} data in the analyses above, probably due to different measurements of household <b>units</b> and to <b>non-response</b> in the survey data.|$|R
40|$|Statistical {{surveys are}} always {{affected}} by non-response. There is item non-response, {{in which only}} the answers to some questions are missing, {{and there is also}} <b>unit</b> <b>non-response,</b> in which the answers to all questions are missing. For many years now Statistics Netherlands has been confronted with severe non-response problems. This is mainly <b>unit</b> <b>non-response.</b> Consequently, research has concentrated o...|$|E
40|$|When {{weighting}} {{adjustment is}} applied {{in a situation}} of <b>unit</b> <b>non-response</b> with linked register data, extra variance due to non-response is not taken into account. Since weighted respondents represent non-respondents, extra variance due to non-response should be taken into account. Multiple imputation, now commonly used to solve item non-response, does take this extra variance into account. Therefore weighting and multiple imputation are compared {{in a situation of}} <b>unit</b> <b>non-response</b> with linked register data in terms of bias of the mean and coverage of the 95 % confidence interval. The performance of multiple imputation appears to be dependent on the correlation between the auxiliary variables and the target variables...|$|E
40|$|We {{study the}} effects of {{attrition}} and other <b>unit</b> <b>non-response</b> in the HRS on inferences about the distribution of socio-economic variables. A feature of the HRS is that efforts are made to bring non-respondents in a particular wave back in the next wave. We find that bringing back these temporary non-respondents substantially reduces the selection effects due to <b>unit</b> <b>non-response.</b> This applies to cross-section analyses but the same conclusion is obtained from our analysis of examples of panel data models, explaining changes in wealth, health, or labour force participation. This conclusion has important implications for users and designers of the HRS and other longitudinal socio-economic surveys with a similar design...|$|E
40|$|Process-generated and {{administrative}} datasets {{have become increasingly}} important for labor market research {{over the past ten}} years. Major advantages of these data are large sample sizes as well as absence of retrospective gaps and <b>unit</b> <b>non-responses.</b> Nevertheless, the quality and validity of the information remains unclear and a lot of preparation and data cleansing is necessary before the data are analyzable. Unfortunately, only few researchers provide access to their cleansing procedures and therefore, also the impact of them on the results of the analyses is unidentified. This paper contributes to this subject and focuses on the variation of research results due to alternative data cleansing procedures. In particular, the paper uses the framework for data preparation suggested in an evaluation study by Wunsch and Lechner (2008) as a benchmark and then induces variation by developing different cleansing procedures for overlapping and parallel observations. The descriptive results show that the differences between the data sets (based on the different procedures) show various magnitudes on some attributes concerning time and personal characteristics. Similar results appear for the subsequent analysis of the treatment effects, which do not vary in the overall shape but in the magnitude especially during the lock-in effect. In sum the results of the analysis indicate that the empirical findings of the evaluation method are fairly robust to variations in the underlying cleansing procedure. " (Author's abstract, IAB-Doku) ((en)) Datenqualität, prozessproduzierte Daten, Datenaufbereitung, Integrierte Erwerbsbiografien...|$|R
30|$|In {{the context}} of PISA and TALIS, we can {{consider}} two types of missing data; <b>unit</b> and item <b>non‐response.</b> However, when considering the fusion of the two data sets, a very large amount of unit missing data obtains because the surveys contain different items and units of analysis. What is required {{to move forward with}} data fusion is a general theoretical framework for the problem of missing data.|$|R
40|$|This report summarises the methodologies used in {{the first}} wave of the Eurosystem Household Finance and Consumption Survey, which {{provides}} household-level data collected in a harmonised way in 15 euro area countries for a sample of more than 62, 000 households. The report presents the methodologies applied in areas such as data collection, sample design, weighting, imputation, and variance estimation. It also analyses issues like differential <b>unit</b> and item <b>non-response</b> and other issues that may {{have an effect on the}} comparability of the survey data across countrie...|$|R
40|$|The Medical Expenditure Panel Survey – Insurance Component (MEPS-IC) is a {{stratified}} one-stage {{sample design}} that employs an iterative multi-stage weighting procedure that accounts first for <b>unit</b> <b>non-response</b> before post-stratifying to outside control totals. This weighting procedure is both time-consuming an...|$|E
40|$|The Household Finance and Consumption Survey (HFCS) is {{a recent}} {{initiative}} from the Eurosystem to collect comparable micro-data on household wealth and indebtedness in the euro area countries. The Household Finance and Consumption Network (HFCN), which comprises the European Central Bank (ECB), national central banks (NCBs), and national statistical institutes (NSIs), {{is in charge of}} the development and implementation of the HFCS. The first round of the survey was successfully conducted between 2008 and 2011, and the results were published in April 2013. The second round is now under way and will cover all the euro area countries. This paper is a joint effort by several members of the HFCN to further investigate the issue of <b>unit</b> <b>non-response</b> in the HFCS, better describe and understand its patterns, measure its effects on the overall quality of the survey and, ultimately, propose strategies to mitigate them. The paper is divided into sections, the first section being the introduction. The second section draws up a list of the main possible sources of auxiliary information that can be relied on in order to analyse non-response patterns in the HFCS. It also presents summary indicators that can be used to quantify <b>unit</b> <b>non-response.</b> In the third section, based on the experience from the first wave of the HFCS, the report elaborates on good survey practices (e. g. interviewer training and compensation, use of incentives, persuasive contact strategies, etc.) to prevent <b>unit</b> <b>non-response</b> from occurring. The fourth section compares several reweighting strategies for coping with <b>unit</b> <b>non-response</b> a posteriori, in particular simple and generalised calibration methods. These methods are assessed with respect to their impact on the main HFCS-based estimates. Finally, based on the outcome of this empirical analysis, recommendations are made with regard to post-survey weighting adjustment in the HFCS...|$|E
40|$|Panel {{surveys are}} {{frequently}} {{used to measure}} the evolution of parameters over time. Panel samples may suffer from different types of <b>unit</b> <b>non-response,</b> which is currently handled by estimating the response probabilites and by reweighting respondents. In this work, we consider estimation and variance estimation under <b>unit</b> <b>non-response</b> for panel surveys. Extending the work by Kim and Kim (2007), we consider an expansion estimator accounting for initial non-response and attrition, and propose a suitable variance estimator. It is then extended to cover most estimators encountered in surveys, including calibrated estima-tors, complex parameters and longitudinal estimators. The properties of the proposed variance estimator and of a simplified variance estima-tor are estimated through a simulation study. An illustration of the proposed methods on data from the ELFE survey is also presented...|$|E
3000|$|... (n<N) {{by simple}} random {{sampling}} without replacement (SRSWOR) to collect information on Y. Assuming at first phase, Y can be observed only for n_ 1 units out of n and, the remaining n_ 2 =n-n_ 1 units are taken as non-response. A sub-sample of size r=n_ 2 /k, k> 1 is selected from <b>non-response</b> <b>units</b> where r would be an integer or must be rounded. Assuming that all r selected units give full response on second call. In this fashion, the population {{is said to be}} divided into two groups U_ 1 and U_ 2 of sizes N_ 1 and N_ 2, where U_ 1 is a group of respondents that would give response on the first call at second phase and U_ 2 is non-respondents group which would respond on the second call. Obviously N_ 1 and N_ 2 are unknown quantities.|$|R
40|$|In large–scale {{sampling}} opeartions (e. g. nation-wide health surveys) {{we always}} face {{the problem of}} non-response item(s) and/or <b>non-response</b> <b>unit(s).</b> In fitting a model to the data we have two groups of variables, namely dependent and independent variables. Non-response may occur {{for any of these}} groups of variables. In this paper we assume Y as a categorical dependent variable with three levels, Z and X as independent variables from any kind: scale, categorical, ordinal, etc. We have complete data on the first two variables and we assume that the missing items follow a random pattern (MAR). Then a model is devised based on the likelihood function for the whole data set (including missing values) and estimates of parameters are compared with those obtained by statistical programs such as SPSS, which are only based on completely observed data and ignore units with missing data. Our results show that the likelihood-based model is superior to the standard approach utilized by the software packages. The comparison is made using data on thyriod disease (goiter) obtained by a health survey in Gazvin province...|$|R
40|$|The Household Finance and Consumption Survey (HFCS) {{provides}} information about household wealth (real and financial assets {{as well as}} liabilities) from 15 Euro-countries after the financial crisis of 2007 / 8. The survey will be the central dataset in this topic in the future. However, several aspects point to potential methodological constraints regarding crosscountry comparability. Therefore {{the aim of this}} paper is to get a better insight in the data quality of this important data source. We will first present a synopsis of cross-country differences, which is the core of the paper. We will compare the sampling processes, the interview modes, the oversampling techniques, the <b>unit</b> and item <b>non-response</b> rates and how itis dealt with them via weighing and imputation as well as further points which might restrict country comparability. In addition we give a first insight in the selectivity of item nonresponse in a cross-national setting. We make use of logit models as well as apply a decomposition method suggested by Fairlie (1999, 2005) to identify differences in characteristics as well as structural (cultural) differences in the item non-response missing process...|$|R
3000|$|... 1 Participation was {{compulsory}} {{in a very}} heterogeneous {{group of}} countries, consisting of Belgium, Spain, France, Italy, Cyprus, Malta, Portugal, and Slovakia. Generally, response rates were also very high in the remaining countries, with a <b>unit</b> <b>non-response</b> rate of 13 % in Austria, by far the highest non-response rate (Eurostat 2008). Owing to high response rates, we do not expect that differences in response patterns lead to biased cross-country comparisons.|$|E
40|$|Business Tendency Surveys (BTS) {{continue}} {{to be an important}} source of timely information on business cycles in many countries. We address quality of economic survey data by uncovering the relation between <b>unit</b> <b>non-response</b> and participant characteristics on company respectively respondent level. We use a unique, matched dataset that merges rich business tendency survey panel data with data from an exclusively conducted meta survey. Our meta information enhances the set of firm characteristics by information such as valuation of business tendency surveys or perceived response burden. We use different count data models to explain non-response count. Our models include weighted count data regressions as well as a two part hurdle model. We find that response burden, a company's survey track record, timeliness and participation mode are the strongest and most robust predictors of <b>unit</b> <b>non-response.</b> We also find a weaker negative effect of the business situation on unit response. Remarkably we do not find a significant influence of neither company size nor valuation of BTS on the propensity to respond to periodical qualitative BTS...|$|E
40|$|In {{order to}} correct the bias due to <b>unit</b> <b>non-response</b> for the KOF ETH Zurich's {{business}} (mail) surveys, we usually use {{the results of a}} second (phone) survey by the non-respondents. Taking the case of the survey 2000 on Organization and Information Technologies in the Swiss economy, we describe how to build the sample of this second survey and how to use the collected data. Actually, we show how to generate new correcting weights {{to correct the}} non-response bias...|$|E
30|$|Most {{empirical}} evidence on state dependence in welfare receipt relies on survey data (e.g., Cappellari and Jenkins 2008; Königs 2014; Wunder and Riphahn 2014). However, {{the quality of}} data from household surveys suffers from several problems (Meyer et al. 2015 a). The problem of unit nonresponse occurs when households from the sampling frame do not answer the survey at all. The problem of item non-response arises when households participate in the survey but do not answer single questions. Both problems lead to a potential bias of survey estimates if <b>unit</b> and item <b>non-response</b> on income and wealth questions could not be considered as randomly across the population (Groves 2006; Meyer et al. 2015 a; Riphahn and Serfling 2005). Last, a potential bias to survey based estimates accrues, if respondents do not answer accurately or even give false answers. Concerning welfare benefits, a substantial fraction of individuals do not report that they receive benefits (e.g., because of the stigma of benefit receipt, see, e.g., Meyer et al. 2015 a). Not only this so-called underreporting can bias the estimates of state dependence when using survey data but also non-recipients who report to receive welfare benefits (overreporting). In our paper, {{we focus on the}} effects of this specific form of measurement error, under- and overreporting of welfare benefits, on the estimates of state dependence in welfare receipt. Over- and underreporting of benefits seem to be especially relevant for the analysis of state dependence if misreporting changes over time, which can lead to observed transitions between welfare receipt and non-receipt that, in reality, did not happen.|$|R
40|$|The Food Nutrition Environment Survey (FNES) is {{a survey}} of New Zealand early {{childhood}} centres and schools and the food and nutritional services that they provide for their pupils. The 2007 and 2009 FNES surveys were managed by the Ministry of Health. Like all the other social surveys, the FNES has the common problem of <b>unit</b> and item <b>non-responses.</b> In other words, the FNES has missing data. In this thesis, we have surveyed {{a wide variety of}} missing data handling techniques and applied most of them to the FNES datasets. This thesis can be roughly divided into two parts. In the first part, we have studied and investigated the different nature of missing data (i. e. missing data mechanisms), and all the common and popular imputation methods, using the Synthetic Unit Record File (SURF) which has been developed by the Statistics New Zealand for educational purposes. By comparing all those different imputation methods, Bayesian Multiple Imputation (MI) method is the preferred option to impute missing data in terms of reducing non-response bias and properly propagating imputation uncertainty. Due to the overlaps in the samples selected for the 2007 and 2009 FNES surveys, we have discovered that the Bayesian MI can be improved by incorporating the matched dataset. Hence, we have proposed a couple of new approaches to utilize the extra information from the matched dataset. We believe that adapting the Bayesian MI to use the extra information from the matched dataset is a preferable imputation strategy for imputing the FNES missing data. This is because the use of the matched dataset provides more prediction power to the imputation model...|$|R
40|$|This article {{examines}} the relation between well-being and fertility intentions in Europe and addresses three main research questions: Does overall well-being infl uence fertility intentions? What kind of well-being factors are {{more important in the}} determination of fertility intentions (individual-level subjective ones vs. individual-level objective ones vs. country-level ones) ? Does the role of specifi c well-being variables change {{over the course of the}} life course, i. e. as age and parity increase? In accordance with the theory of planned behaviour (Ajzen, 1991), fertility intentions are studied as important predictors of actual fertility behaviour. And in line with established studies, a broad approach is taken towards the concept of well-being. The analysis is theoretically grounded in the framework of methodological individualism (i. e. micro-macro linkages). Use is made of data on women aged 20 - 39 in 27 countries, which were taken from the ‘Family, work and well-being’ module in the 5 th round (2010) of the European Social Survey. The analysis of a comparable European population sample is made possible by taking account of both <b>unit</b> and item <b>non-responses,</b> and correcting for them. Our analysis shows overall positive but small correlations between well-being and fertility intentions in all countries: the higher the level of well-being, the higher the intended fertility, although the strength of the correlation differs between countries. Also, overall, individual-level objective well-being factors, such as level of education and employment status, have a larger impact on fertility intentions than individual-level subjective well-being factors and country-level well-being factors regarding human development, gender inequality and region. Changes in the effects of these well-being factors are found depending on the stage of the life course: as parity and age increase, the importance of country-level well-being effects increases. This shows that family-friendly country policies targeted to these groups can have positive effects on fertility. status: publishe...|$|R
40|$|Missing {{survey data}} occur because of unit and item non-response. This is {{practically}} {{independent of the}} method of data collection. As {{a result of the}} bias that non-response sometimes introduces in survey estimates, identifying factors that promote it, and taking measures of prevention and correction methods are clearly necessary. The standard method to compensate for <b>unit</b> <b>non-response</b> is by weighting adjustment, while item non-responses are handled by some form of imputation. This paper reviews factors that give rise to nonresponse and the corresponding methods used for its prevention and control. It also discusses their properties...|$|E
40|$|We link {{information}} on graduates from many cohorts to their high-school and college records and demographics to infer {{the impact of}} college major on earnings. We develop an estimator to handle potential non-response bias and identify non-response using an affinity measure [...] the potential respondent's link to the survey organization. This technique is generally applicable for adjusting for <b>unit</b> <b>non-response.</b> In the earnings model estimated using the identified (for non-response bias) selectivity adjustments, adjusted earnings differentials across college majors are below half as large as unadjusted differentials and ten percent smaller than {{those that do not}} account for selective non-response. ...|$|E
40|$|We analyse {{household}} <b>unit</b> <b>non-response</b> in {{six major}} UK Government surveys {{by using a}} multilevel multinomial modelling approach. The models are guided by current conceptual frameworks and theories of survey participation. One key feature of the analysis is {{the investigation of the}} extent to which effects of household characteristics are survey specific. The analysis is based on the 2001 UK Census Link Study, which is a unique source of data containing an unusually rich set of auxiliary variables. The study contains the response outcome of six surveys, linked to census data and interviewer observations for both respondents and non-respondent...|$|E
40|$|In {{large-scale}} surveys, non-response is {{a common}} phenomenon. This non-response can be of two types; <b>unit</b> and item <b>non-response.</b> In this thesis we deal with item non-response as other responses from the survey unit {{can be used for}} adjustment. Usually non-response adjustment is carried out in one of three ways; weighting, imputation and no adjustments. Imputation is the most commonly used adjustment method, either as single imputation or multiple imputations. In this thesis we study single imputation, in particular nearest neighbour methods, and we have developed a new method. Our method is based on dissimilarity measures and is nonparametric and handles categorical and continuous covariates without requiring any transformations. One drawback with this method was that it is relatively computer intensive, so we investigated data reduction methods. For data reduction we developed a new method that uses propensity scores. Propensity score is used as it has properties that suggest that it would make a good method for matching the respondents and non-respondents. We also looked at subset selection of the covariates using graphical modelling and principal component analysis. We found that the data reduction methods gave as good a result as when using all variables and there was considerable reduction in computation time especially with the propensity score method. As the imputed values are not true values, estimating the variance of the parameter of interest using standard methods would underestimate the variance if no allowance is made for the extra uncertainty due to imputed data being used. We examined various existing methods of variance estimation, particularly the bootstrap method, because both nearest neighbour imputation and bootstrap are non parametric. Also bootstrap is a unified method for estimating smooth as well as non-smooth parameters. Shao and Sitter (1996) proposed a bootstrap method, but for some extreme situations this method has problems. We have modified the bootstrap method of Shao and Sitter to overcome this problem and simulations indicate that both methods give good results. The conclusions from the study are that our new method of multivariate nearest neighbour is at least as good as regression based nearest neighbour and is often better. For large data sets, data reduction may be desirable and we recommend our propensity score method as it was observed to be the fastest among the subset selection methods as well as have some other advantages over the others. Imputing using any of the subsets methods we looked at appear to have similar results to imputing using all covariates. To compute the variance of the imputed data, we recommend the method proposed by Shao and Sitter or our modification of Shao and Sitter's method...|$|R
40|$|This {{thesis is}} {{concerned}} with methods for dealing with missing data in nonrandom samples and recurrent events data. The {{first part of this}} thesis is motivated by scores arising from questionnaires which often follow asymmetric distributions, on a fixed range. This can be due to scores clustering {{at one end of the}} scale or selective reporting. Sometimes, the scores are further subjected to sample selection resulting in partial observability. Thus, methods based on complete cases for skew data are inadequate for the analysis of such data and a general sample selection model is required. Heckman proposed a full maximum likelihood estimation method under the normality assumption for sample selection problems, and parametric and non-parametric extensions have been proposed. A general selection distribution for a vector Y 2 Rp has a PDF fY given by fY(y) = fY?(y) P(S? 2 CjY? = y) P(S? 2 C); where S? 2 Rq and Y? 2 Rp are two random vectors, and C is a measurable subset of Rq. We use this generalization to develop a sample selection model with underlying skew-normal distribution. A link is established between the continuous component of our model log-likelihood function and an extended version of a generalized skewnormal distribution. This link is used to derive the expected value of the model, which extends Heckman's two-step method. The general selection distribution is also used to establish the closed skew-normal distribution as the continuous component of the usual multilevel sample selection models. Finite sample performances of the maximum likelihood estimator of the models are studied via Monte Carlo simulation. The model parameters are more precisely estimated under the new models, even in the presence of moderate to extreme skewness, than the Heckman selection models. Application to data from a study of neck injuries where the responses are substantially skew successfully discriminates between selection and inherent skewness, and the multilevel model is used to analyze jointly <b>unit</b> and item <b>non-response.</b> We also discuss computational and identification issues, and provide an extension of the model using copula-based sample selection models with truncated marginals. The second part of this thesis is motivated by studies that seek to analyze processes that generate events repeatedly over time. We consider the number of events per subject within a specified study period as the primary outcome of interest. One considerable challenge in the analysis of this type of data is the large proportion of patients that might discontinue before the end of the study, leading to partially observed data. Sophisticated sensitivity analyses tools are therefore necessary for the analysis of such data. We propose the use of two frequentist based imputation methods for dealing with missing data in recurrent event data framework. The recurrent events are modeled as over-dispersed Poisson data, with constant rate function. Different assumptions about future behavior of dropouts depending on reasons for dropout and treatment received are made and evaluated in a simulation study. We illustrate our approach with a clinical trial in patients who suffer from bladder cancer...|$|R
40|$|By all accounts, income {{inequality}} in Egypt {{is low and}} had been declining during the decade that preceded the 2011 revolution. As the Egyptian revolution was partly motivated by claims of social injustice and inequalities, this seems at odds with {{a low level of}} {{income inequality}}. Moreover, while income inequality shows a decline between 2000 and 2009, the World Values Surveys indicate that the aversion to inequality has significantly increased during the same period and for all social groups. This paper utilizes a range of recently developed statistical techniques to assess the true value of income inequality {{in the presence of a}} range of possible measurement issues related to top incomes, including item and <b>unit</b> <b>non-response,</b> outliers and extreme observations, and atypical top income distributions. The analysis finds that correcting for <b>unit</b> <b>non-response</b> significantly increases the estimate of inequality by just over 1 percentage point, that the Egyptian distribution of top incomes follows rather closely the Pareto distribution, and that the inverted Pareto coefficient is located around median values when compared with 418 household surveys worldwide. Hence, income inequality in Egypt is confirmed to be low while the distribution of top incomes is not atypical compared with what Pareto had predicted and compared with other countries in the world. This would suggest that the increased frustration with income inequality voiced by Egyptians and measured by the World Values Surveys is driven by factors other than income inequality. This paper is a product of the Poverty Reduction and Economic Management Department, Middle East and North Afric...|$|E
40|$|With the IAB Establishment Panel the Institute for Employment Research (Institut für Arbeitsmarkt- und Berufsforschung - IAB) has {{conducted}} a large-scale annual establishment survey in western Germany since 1993 {{and also in}} eastern Germany since 1996, covering some 15, 500 establishments in the meantime. In this panel survey the establishments are asked in face-to-face interviews 1 to provide information on key determinants of employment. The IAB Establishment Panel is a survey in which the same establishments are contacted each year. New establishments {{are added to the}} sample each year in order to depict structural change. Furthermore additional establishments have {{to be included in the}} sample to replace those which have dropped out of the sample in the course of time. For despite all efforts, one problem arises in every survey: individual establishments' unwillingness to participate, which leads to so-called non-response. Two forms of non-response can be distinguished. First, an establishment may refuse to participate in the survey at all (<b>unit</b> <b>non-response).</b> Second, participating establishments may fail to answer individual questions in the questionnaire (item non-response). Both types of non-response can lead to biased results if the cases of non-response are not random. <b>Unit</b> <b>non-response</b> leads to greater problems, however, as no interview is available for these establishments and it is not just the case that individual questions are not answered. Experience made with the IAB Establishment Panel shows that the willingness of establishments surveyed for the first time to participate in the survey is clearly lower, at 36 percent, than that of establishments which have already been included in the survey at least once. Furthermore the <b>unit</b> <b>non-response</b> of establishments surveyed for the first time has increased in the past few years. The willingness of the panel establishments, in other words the repeat respondents from previous years, to complete the questionnaire is considerably higher at about 80 percent. There is no indication that the willingness to participate is declining over the years. The advantage of panel surveys is also that a wealth of establishment information is available from previous years for the establishments which have been surveyed repeatedly but which no longer respond and this can be used to model the non-response process. On the other hand little information is available about the establishments which are included in the survey for the first time. It is important to analyse the non-response processes in order to gain the most precise insight possible into the survey process. The findings obtained in this way make it possible to optimise the fieldwork management, thus contributing to quality improvements and possibly to cost reductions. In addition to this, the analyses can reveal any selectivities that may lead to biased estimates. The representativeness of the projection of all variables can also be jeopardised by possible selectivities. Furthermore, in panel surveys selectivities may intensify over time. The aim of this paper is to examine the <b>unit</b> <b>non-response</b> of establishments which have already taken part in the survey at least once and are approached again. On the basis of an extended conceptual framework for establishment surveys, determinants that influence the non-response process are to be brought out. For the first time for establishment surveys the interviewer's influence on the success of the interview is taken into account both in the conceptual framework and in the analyses. " (Author's abstract, IAB-Doku) ((en)) Datengewinnung, Antwortverhalten, IAB-Betriebspanel, Befragung, Non Response...|$|E
40|$|Population surveys {{around the}} world face the problem of declining {{cooperation}} and participation rates of respondents. Not only can item nonresponse and unit nonresponse impair important outcome measures for inequality research such as total household disposable income; {{there is also a}} further case of missingness confronting household panel surveys that potentially biases results. The approach commonly used in such surveys of interviewing all adult household members and aggregating their individual incomes to yield a final outcome measure for welfare analyses often suffers from partial <b>unit</b> <b>non-response</b> (PUNR), i. e., the non-response of at least one unit, or member, of an otherwise participating household. In these cases, the aggregate income of all household members lacks at least one individual's income. These processes are typically not random and require appropriate correction. Using data from more than twenty waves of the German Socio-Economic Panel (SOEP) we evaluate four different strategies to deal with this phenomenon: (a) Ignorance, i. e., assuming the missing individual's income to be zero. (b) Adjustment of the equivalence scale to account for differences in household size and composition. (c) Elimination of all households observed to suffer PUNR, and re-weighting of households observed to be at risk of but not affected by PUNR. (d) Longitudinal imputation of the missing income components. The aim {{of this paper is to}} show how the choice of technique affects substantive results in the inequality research. We find indications of substantial bias on income inequality and poverty as well as on income mobility. These findings are obviously even more important in cross-national comparative analyses if the data providers in the individual countries deal differently with PUNR in the underlying data. Household Panel Surveys, Partial <b>Unit</b> <b>Non-Response,</b> Inequality, Mobility, Imputation, SOEP...|$|E
40|$|Reweighting {{of survey}} {{data of the}} {{respondents}} is required for several reasons, especially due to problems in frame coverage and frame data quality on one hand, and due to selective <b>unit</b> <b>non-response,</b> on the other. Over years, a number of methods have been proposed and used. An appropriate methodology requires necessarily auxiliary data. The more and predicatbe auxiliary data are available more options to reweight initial sampling weights exist. Basically, two types of such variables can be tried, either aggregate or micro. Typically, aggregate variables are margins of the target population frame. Consequently, such information gives opportunity to use calibration methods. On the other hand, if micro variables are available, response propensity methodology is possible, as well. This paper compares these two approaches, both theoretically and using simulated data...|$|E
40|$|A {{framework}} is outlined for testing empirically whether utilization of {{and access to}} public-sector GPs in Spain in 1993 {{was consistent with the}} twin criteria of horizontal and vertical equity, where these are defined with respect to need. Vertical (horizontal) inequities in access are assessed by including interactions between determinants of access and need (non-need) variables in a utilization equation. Findings are consistent with the principle of vertical equity in the utilization of GP services, but are not consistent with horizontal equity. Travel time for individuals who did not visit their GP are imputed {{but it is not a}} significant determinant of utilization or access. However, caution is expressed when interpreting these findings, as they may be contaminated by biases arising from <b>unit</b> <b>non-response,</b> measurement error and simultaneity. The paper concludes with a set of recommendations for future studies. ...|$|E
40|$|Three {{separate}} estimators, for {{the estimation}} of the population total, based on two-stage sampling design on two successive occasions with partial replacement of secondary stage units only have been presented. For these estimators {{it is assumed that}} there is <b>unit</b> <b>non-response.</b> Hence, Hansen and Hurwitz (1946) technique has been used to adjust for the non-response. Empirically, it has been found that the estimator that uses individual weights within first stage units perform better than the other estimators that use common weights in estimating the population total. Theoretically, it has also been shown that the larger the ratio of the within first stage unit variability of the non-respondents to the between first stage unit variability the higher the gain in efficiency of the proposed estimators over the estimator obtained when there is no partial matching of units...|$|E
40|$|The {{effects of}} <b>unit</b> <b>non-response</b> on survey errors are {{of great concern}} to researchers. However, direct {{assessment}} of non-response bias in survey estimates is rarely possible. Attempts are often made to adjust {{for the effects of}} non-response by weighting, but this usually relies on the use of frame data or external population data, which are at best modestly correlated with the survey variables. This paper reports the development of a method to collect limited survey data from non-respondents to personal interview surveys and a large-scale field test of the method on the British Crime Survey (BCS). The method is shown to be acceptable and low cost, to provide valid data, and to have no detrimental effect on the main survey. The use of the resultant data to estimate non-response bias is illustrated and some substantive conclusions are drawn for the BCS...|$|E
