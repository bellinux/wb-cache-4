6|31|Public
40|$|We {{demonstrate}} that undetectable single stuck-at faults in full-scan bench mark circuits tend to cluster in certain areas. This implies that certain areas may remain uncovered by a test set for single stuck-at faults. We describe an extension {{to the set}} of target faults aimed at providing a better coverage of the circuit {{in the presence of}} undetectable single stuck-at faults. The extended set of target faults consists of double stuck-at faults that include an <b>undetectable</b> <b>fault</b> as one of their components. The other component is a detectable fault adjacent to the <b>undetectable</b> <b>fault.</b> We present experimental results of fault simulation and test generation for the extended set of target faults...|$|E
40|$|Abstract: Redundant faults {{in digital}} {{circuits}} not only result in extra hardware but also mask other faults {{and may also}} make <b>undetectable</b> <b>fault</b> detectable. Redundancies increase the chip area, the power consumption, and often propagation delays in the circuit and might even reduce the yield [5]. This paper {{is a result of}} literary search for detection and removal of such faults. This paper addresses procedures described in literature to detect and remove redundant faults. 1...|$|E
40|$|Abstract — Considering {{the full}} scan {{benchmark}} circuit, {{in which the}} undetectable single stuck-at faults, tends to cluster in certain areas. This indicates that certain areas may remain uncovered by a test set for single stuck-at faults. The extension to the set of target faults aimed at providing a better coverage of the circuit {{in the presence of}} undetectable single stuck-at fault. The extended set of target faults consists of double stuck-at faults that include an <b>undetectable</b> <b>fault</b> as one of their components. The other component is a detectable fault adjacent to the <b>undetectable</b> <b>fault.</b> Test sets that contain several different tests for each fault (n-detection test sets) are expected to increase the likelihood of detecting defects associated with the sites of target faults. This phenomenon is discerned from the gate level description of the circuit, and it is independent of layout parameters. In addition, the clustering is based on the gate level, and remains valid for any layout of the circuit. The fault simulation and test generation for the extended set of target faults is simulated using modelsim along with that the test set compaction is achieved by reseeding method. Index Terms — Benchmark circuits, fault simulation, stuck-at faults, test quality, unresolved faults. ...|$|E
40|$|Several theorems {{exist that}} allow the {{identification}} of <b>undetectable</b> <b>faults</b> in synchronous sequential circuits by applying combinational ATPG to an iterative logic array of limited length. In this paper, we consider the theorem that resulted {{in one of the}} most effective procedures for identifying <b>undetectable</b> <b>faults.</b> We show conditions on fault free sequential circuits under which the only <b>undetectable</b> <b>faults</b> that can be identified by this theorem using an iterative logic array of any length are combinationally redundant faults. Such faults can be identified using an iterative logic array of length one, or techniques specifically developed for combinationally redundant faults. Whereas for a general circuit, increasing the length of the iterative logic array may help identify additional <b>undetectable</b> <b>faults,</b> this is not the case for circuits with the properties identified here. We demonstrate the existence of benchmark circuits that satisfy these conditions. ...|$|R
40|$|We {{provide a}} {{definition}} of <b>undetectable</b> <b>faults</b> in partial scan cir-cuits under a test application scheme where a test consists of pri-mary input vectors applied at-speed between scan operations. We also provide sufficient conditions for a fault to be undetect-able under this test application scheme. We present experimen-tal results on finite-state machine benchmarks to demonstrate {{the effectiveness of these}} conditions in identifying <b>undetectable</b> <b>faults.</b> 1...|$|R
40|$|A {{computer}} aided {{method for}} analyzing the testability of Programmable Logic Arrays (PLAs) is described. The method, {{which is based}} on a functional verification approach, estimates the complexity of testing a PLA according to the amount of single <b>undetectable</b> <b>faults</b> in the array structure. An analytic program (FACTPLA) is developed to predict the above complexity without analyzing the topology of the array as such. Thus, the method is technology invariant and depends only on the functionality of the PLA. The program quantitatively evaluates the effects of <b>undetectable</b> <b>faults</b> and produces some testability measures to manifest these effects. A testability profile for different PLA examples is provided and a number of suggestions for further research to establish definitely the usefulness of some functional properties for testing were made. TO MY PARENTS...|$|R
40|$|We {{define a}} robust fault model {{as a model}} where the {{existence}} of an <b>undetectable</b> <b>fault</b> implies the existence of logic redundancy, or more generally, a suboptimality in the synthesis of the circuit. The stuck-at fault model is robust, but other fault models such as certain bridging fault models are not. A robust fault model provides a mechanism to synthesize circuits in which all the target faults are detectable and 100 % fault coverage is achievable. The ability to achieve 100 % fault coverage, or understand why it is not achievable, is important since the requirement to achieve high test quality translates into a requirement to achieve complete fault coverage for target faults, regardless of the metrics used to measure test quality. We discuss a robust bridging fault model and its use as part of a test generation process for a non-robust bridging fault model (a non-robust bridging fault model may have to be used in order to capture the behavior of bridging defects). We also present experimental results related to the robust bridging fault model...|$|E
40|$|We {{consider}} two topics {{related to}} testing of synchronous sequential circuits. The first topic deals with synchronizable circuits and their synchronizing sequences. Synchronizing sequences {{are important in}} facilitating the test generation process for detectable faults, and in identifying undetectable faults. They are also important in determining whether an <b>undetectable</b> <b>fault</b> can be removed from a circuit without affecting its normal operation. We show a class of faults for which a synchronizing sequence for the faulty circuit can be easily determined from the synchronizing sequence of the fault free circuit. We also consider circuits that have a reset mechanism, and show how reset can ensure that no single fault would cause the circuit to become unsynchronizable. The second topic we consider deals with test sequence partitioning to speed up static test compaction. We propose a procedure for partitioning a given test sequence into subsequences such that the cumulative fault coverage of all the subsequences, when applied as independent test sequences, {{is equal to the}} fault coverage of the original sequence. Each subsequence can then be compacted independently. 1...|$|E
40|$|Due to {{shrinking}} feature sizes, {{the number}} of defects in electronic chips has risen. These defects can be modeled as logic faults. Tests are applied to check {{whether or not a}} fault is present. Faults are not always present, but always need to be tested for. If a test for a fault does not exist, the fault is called undetectable. Undetectable faults leave uncovered defect sites in the circuit. It has been observed that undetectable faults cluster in sub-circuits of benchmark circuits. This implies that certain sub-circuits are uncovered or less covered than others by a test set for all the modeled faults. Design-For-Manufacturability (DFM) guidelines were created which if followed during manufacturing, can help avoid potential defects. DFM guidelines are not followed if they conflict with other constraints such as area or performance. This implies that defects are not avoided even if the possibility of their occurrence can be predicted. This research involves resynthesizing sub-circuits by using an algorithm in order to reduce {{the number of}} undetectable internal faults in them and break the fault clusters. It was observed that by replacing one instance in one cell type in every iteration, the number of undetectable internal faults were successfully reduced. It was also observed that in slightly larger circuits, the number of faults increased at the beginning of every new cycle due to an optimization step in the tool. It can thus be concluded that it is possible to break down the <b>undetectable</b> <b>fault</b> clusters using resynthesis...|$|E
40|$|In this paper, we {{show how}} {{fault-tolerance}} can be effectively added to {{several types of}} faults in program computations that use barrier synchronization. We divide the faults that occur in practice into two classes, detectable and undetectable, and design a fully distributed program that tolerates the faults in both classes. Our program guarantees that every barrier is executed correctly even if detectable faults occur, and that eventually every barrier is executed correctly even if <b>undetectable</b> <b>faults</b> occur. Via analytical as well as simulation results we show {{that the cost of}} adding fault-tolerance is low, in part by comparing the times required by our program with that required by the corresponding fault-intolerant counterpart. Keywords: fault-tolerance, multitolerance, detectable and <b>undetectable</b> <b>faults,</b> synchronization, concurrency. 1 Email: fkulkarni,anishg@cis. ohio-state. edu; Web: [URL] kulkarni,~anish g. Research supported in part by NSF Grant CCR- 93 [...] ...|$|R
40|$|This thesis was {{submitted}} for {{the degree of}} Doctor of Philosophy and awarded by Brunel University. A computer aided method for analyzing the testability of Programmable Logic Arrays (PLAs) is described. The method, {{which is based on}} a functional verification approach, estimates the complexity of testing a PLA according to the amount of single <b>undetectable</b> <b>faults</b> in the array structure. An analytic program (FACTPLA) is developed to predict the above complexity without analyzing the topology of the array as such. Thus, the method is technology invariant and depends only on the functionality of the PLA. The program quantitatively evaluates the effects of <b>undetectable</b> <b>faults</b> and produces some testability measures to manifest these effects. A testability profile for different PLA examples is provided and a number of suggestions for further research to establish definitely the usefulness of some functional properties for testing were made...|$|R
40|$|The paper proposes an {{approach}} for designing TSC networks {{by means of}} error detecting code application, based on {{the analysis of the}} desired fault-error relation. The network structure is analyzed by taking into account each possible fault, belonging to the adopted fault set, and by verifying if the produced error is detectable with respect to the adopted encoding. If <b>undetectable</b> <b>faults</b> are located the network is locally modified, so that area overheads for TSC designs are limited...|$|R
40|$|Newer FPGA {{devices are}} more {{susceptible}} to faults, especially transient faults. Some kind of concurrent error detection approach has to be used to avoid system failure due to these aults. To obtain the totally self checking property is the goal in most cases, but it's often impossible. It's useful to evaluate numbers of detectable and <b>undetectable</b> <b>faults.</b> An FPGA-based fault injector capable to get these values is presented in this paper. It's implemented in Atmel FPSLIC and uses dynamic reconfiguration...|$|R
40|$|Conventional fault {{simulation}} techniques for FPGAs are very complicated and time consuming. The other alternative, FPGA fault emulation technique, is incomplete, {{and can be}} used only after the FPGA chip is manufactured. In this paper, we present efficient algorithms for computing the fault coverage of a given FPGA test configuration. The faults considered are opens and shorts in FPGA interconnects. Compared to conventional methods, our technique is orders of magnitude faster, while is able to report all detectable and <b>undetectable</b> <b>faults.</b> 1...|$|R
40|$|The {{problem of}} {{determining}} a minimal number of control inputs for converting a {{programmable logic array}} (PLA) with <b>undetectable</b> <b>faults</b> to crosspoint-irredundant PLA for testing has been formulated as a nonstandard set covering problem. By representing subsets of sets as cubes, this problem has been reformulated as familiar problems. It is noted that this result has significance because a crosspoint-irredundant PLA {{can be converted to}} a completely testable PLA in a straightforward fashion, thus achieving very good fault coverage and easy testability...|$|R
40|$|The {{full text}} {{of this article is}} not {{available}} on SOAR. WSU users can access the article via IEEE Xplore database licensed by University Libraries: [URL] study of bridging faults (or short circuits that occur between conducting paths) has become increasingly important with the advent of LSI technology. To date, only a very few papers have been published on this topic. Specifically, little is known regarding <b>undetectable</b> bridging <b>faults.</b> More importantly, what has yet to be explored are the effects of <b>undetectable</b> bridging <b>faults</b> on the tests designed to detect stuck-at faults. Peer reviewed articl...|$|R
40|$|ISBN: 0080375359 Presents briefly {{the theory}} of {{generalized}} fail-safe systems which includes new, more general definitions, construction conditions and basic properties for fail-safe systems. Then, {{in order to take}} into account the problem of <b>undetectable</b> <b>faults,</b> we define strongly fail-safe circuits who achieve the totally fail-safe goal. As an application the authors propose a fail-safe integrated interface which transforms the outputs of self-checking systems into signal adequate to drive electromechanical actuators and such that the whole system, self checking processing part and interface, implemented in VLSI is strongly fail-safe. Therefore this system can be used for safe drive of complex critical processes...|$|R
40|$|In {{this paper}} we present the {{specification}} backpropagation technique which enables one to derive the constraint {{of an internal}} functional block {{with respect to a}} given DC specification for an analog/mixed-signal system. Based on this technique, we implement an efficient fault simulator which reduces the required efforts by (1) removing <b>undetectable</b> <b>faults</b> from the fault list, and (2) performing fault simulation only locally for the faulty block. Simulation results on an industrial design show a speedup factor of 7. 2 with 98 % correct classification of detected and undetected faults as compared with full-chip DC fault simulation. 1...|$|R
40|$|The layout level {{design for}} {{testability}} (LLDFT) rules used here allow to avoid some hard to detect <b>faults</b> or even <b>undetectable</b> <b>faults</b> on a cell library by modifying the cell layout without changing their behavior and achieving a good level of reliability. These rules avoid some open faults or reduce their appearance probability. The main purpose has been to apply that set of LLDFT rules on {{the cells of the}} library designed at the Centre Nacional de Microelectronica (CNM) in order to obtain a highly testable cell library. The authors summarize the main results (area overhead and performance degradation) of the application of the LLDFT rules on the cell...|$|R
40|$|Many {{state-of-the-art}} approaches on fault-tolerant {{system design}} make the simplifying assumption that all faults are detected {{within a certain}} time interval. However, based on a detailed experimental analysis, we observe that perfect fault detection {{is not only an}} impractical assumption but even if implementable also a suboptimal design decision. This paper presents an approach that takes imperfect fault detection into account. Novel analysis and optimization techniques are developed, which distinguish detectable and <b>undetectable</b> <b>faults</b> in the overall workflow. Besides synthesizing the task schedules, our approach also decides which of the available fault detectors is selected for each task instance. Experimental results show that our approach finds solutions with several orders of magnitude higher reliability than current approaches. Categories and Subject Descriptors B. 8. 1 [Performance and Reliability]: Reliability, Test-ing, and Fault-Tolerance; C. 3 [special-purpose and ap-plication-based systems]: Real-time and embedded sys-tem...|$|R
40|$|We {{design a}} multitolerant program for {{synchronizing}} the phases of concurrent processes. The tolerances {{of the program}} enable processes to (i) compute all phases correctly {{in the presence of}} faults that corrupt process state in a detectable manner, and (ii) compute only a minimum possible number of phases incorrectly before resuming correct computation in the presence of faults that corrupt process state in an undetectable manner. The program is fine-grain in the sense that each process action either updates the state of that process or involves communication with one of two neighboring processes. Keywords: fault-tolerance, detectable and <b>undetectable</b> <b>faults,</b> synchronization, concurrency. 1 Motivation Barrier synchronization in its general form requires that a set of processes execute a cyclic sequence of phases so that a phase is executed by each process only after all processes have completed the previous phase. This form of synchronization generalizes a variety of others, su [...] ...|$|R
40|$|Abstract. Identifying {{legal and}} illegal states {{significantly}} reduces computational complexity of ATPG. A unified framework for identification of the {{legal and illegal}} states is presented. Most known methods for identification of the legal and illegal states are interpretable within this framework. New theorems and the resulting procedures for identifying exact collection of legal or illegal states of a circuit are presented. Experimental results demonstrate that exact collection of legal states for some circuits is significantly smaller than collections obtained by backward state search algorithm and by algorithm based on combinational ATPG theorems. The use of the exact collection of legal states allows identifying more <b>undetectable</b> <b>faults.</b> The proposed procedure for identifying of the exact collection of legal states starts from any state of the circuit, builds initially an enlarged collection of legal states and converges rapidly to the exact solution. Key words: sequential circuits, legal and illegal states, detectability of faults. 1...|$|R
40|$|We {{design in}} a {{stepwise}} manner a multitolerant computation for synchronizing the phases of concurrent processes. The tolerances of the computation enable processes to (i) compute all phases correctly {{in the presence}} of faults that corrupt process state in a detectable manner, and (ii) compute only a minimum possible number of phases incorrectly before resuming correct computation {{in the presence of}} faults that corrupt process state in an undetectable manner. Keywords: fault-tolerance, detectable and <b>undetectable</b> <b>faults,</b> stepwise design, concurrency. 1 The Problem Given is an undirected, connected network of processes. Each process consists of a cyclic sequence of n+ 1 terminating phases, [phase: 0; phase: 1; : : :; phase:n], and is initially ready to execute phase: 0. A computation of the network of processes is correct iff each phase:i, 0 i n, is executed correctly with respect to the following barrier synchronization specification: ffl Safety: No process executes phase:i unti [...] ...|$|R
40|$|The final checker of a {{self-checking}} system is an embedded double-rail checker (the partial checkers have in general two outputs). The self-testing or the strongly code disjoint property of this embedded checker can be lost {{if it is}} not exercised by an appropriate set of inputs. If some partial checkers are strongly code disjoint, then some <b>undetectable</b> <b>faults</b> can modify the input/output mapping of these checkers. This can compromise the exercising of the final double-rail checker especially if this modification leads to the reduction of the partial checker's output code space. In that case it will be required that the partial strongly code disjoint checkers must also be strongly fault secure. In this work we show that the (two-output) strongly code disjoint checkers do not allow such reduction of their output code space and on this basis we show that the strongly fault secure property is not necessary. We also give some techniques that ensure exercising the final checker...|$|R
40|$|AbstractThis paper {{examines}} {{a hypothetical}} CO 2 seepage by numerical simulations for assessment of potential environmental impacts at geological storage sites. A reasonable {{but the worst}} seepage case for geological CO 2 storage site in Japan was considered. In order to select the model parameters, papers which reported faults/fractures in mainly Tertiary formations in Japan were reviewed. From this review we considered that <b>undetectable</b> <b>faults</b> could have 1 km length and 5 m width, and the permeability in faults/fractures {{would be in the}} range of 1 - 1000 mD. The migration along a hypothetical fault with 200 mD permeability was studied using TOUGH 2 simulator. CO 2 seepage rate became the maximum at around 5 years, and then decrease gradually. The total amounts of escaped CO 2 and maximum seepage rate were about 1 % and 0. 3 %/year of injected CO 2, respectively. The sensitivity analysis of the model parameters was carried out. It suggests that the seepage rate is controlled not only the permeability of the fault but also that of the reservoir...|$|R
40|$|ABSTRACT: A high {{impedance}} fault (HIF) {{results when}} an energized primary conductor {{comes in contact}} with a quasi-insulating object such as a tree, structure or equipment, or falls to the ground. The significance of these previously <b>undetectable</b> <b>faults</b> is that they represent a serious public safety hazard {{as well as a}} risk of arcing ignition of fires. A high impedance fault [1] is characterized by having impedance sufficiently high that it is not detected by conventional over current protection, such as fuses and over current relays. Unlike low impedance short circuits, which involve relatively large fault currents and are readily detectable by conventional over current protection, these HIFs represent little threat of damage to power system equipment. High impedance faults produce current levels in the 0 to 50 ampere range. Typically, an HIF exhibits arcing and flashing at the point of contact. Throughout the utility industry, there have been differences of opinion on how often HIFs occur. Normally, utilities do not keep good records on the number of down conductor instances...|$|R
40|$|ISBN: 0080334385 Concerns {{the design}} of a {{microprocessor}} dedicated to safety applications and more particularly to automatic train control. This microprocessor is self-checking i. e. able to detect its own errors. Its name is COBRA (controller with built-in selfchecking for real-time applications). In {{the design of}} this circuit, low-level fault hypotheses for the N-MOS technology are considered. In this case redundant <b>faults,</b> i. e. <b>undetectable</b> <b>faults,</b> generally exist in any design and thus fault detecting capabilities must be provided for sequences of faults. The functional circuits will process with coded data and will be checked by strongly code-disjoint checkers. COBRA's data path processes independently 19 different signals, and supervises 14 level inputs (binary values). 7 independent outputs could be binary values, and 3 could be clocks. The data path communicates with an external PROM, used as program storage for COBRA. This PROM is addressed with 14 bits, multiplexed over the 8 -bit address/data internal bus of the data path. It also contains one serial I/O, a 64 byte RAM, and 3 independent 14 bits counters. An 8 bit ALU could be used for arithmetical or logical operations. A set of 42 instructions processes all these operations...|$|R
40|$|Abstract — A {{powerful}} combinational path sensitization {{engine is}} required for the efficient implementation of tools for test pattern generation, timing analysis, and delay fault testing. Path sensitization can be posed as a search, in the n-dimensional Boolean space, for a consistent assignment of logic values to the circuit nodes which also satisfies a given condition. In this paper we propose and demonstrate the effectiveness of several new techniques for search-space pruning for test pattern generation. In particular, we present linear-time algorithms for dynamically identifying unique sensitization points and for dynamically maintaining reduced head line sets. In addition, we present two powerful mechanisms that drastically reduce the number of backtracks: failure-driven assertions and dependency-directed backtracking. Both mechanisms {{can be viewed as a}} form of learning while searching and have analogs in other application domains. These search pruning methods have been implemented in a generic path sensitization engine called LEAP. A test pattern generator, TG-LEAP, that uses this engine was also developed. We present experimental results that compare the effectiveness of our proposed search pruning strategies to those of PODEM, FAN, and SOCRATES. In particular, we show that LEAP is very efficient in identifying <b>undetectable</b> <b>faults</b> and in generating tests for difficult faults. I...|$|R
40|$|In this paper, the {{validity}} of'single fault assumption in deriving diagnostic test sets is examined {{with respect to}} crosspoint faults in programmable logic arrays (PLA's). The control input procedure developed here {{can be used to}} convert PLA's having <b>undetectable</b> crosspoint <b>faults</b> to crosspoint-irredundant PLA's for testing purposes. All crosspoints will be testable in crosspoint-irredundant PLA's. The control inputs are used as extra variables during testing. They are maintained at logic I during normal operation. A useful heuristic for obtaining a near-minimal number of control inputs is suggested. Expressions for calculating bounds on the number of control inputs have also been obtained...|$|R
40|$|<b>Undetectable</b> stuck-at <b>faults</b> in combinational {{circuits}} {{are related}} to the existence of logic redundancy (s-redundancy). Similarly, logically equivalent nodes may cause some bridging <b>faults</b> to become <b>undetectable</b> by IDDQ testing. An efficient method for the identification and removal of such functionally equivalent nodes (f-redundant nodes) in combinational circuits is presented. OBDD graphs are used to identify the functional equivalence of candidate to f-redundancy nodes. An f-redundancy removal algorithm based on circuit transformations to improve bridging fault testability, is also proposed. The efficiency of the identification and removal of f-redundancy has been evaluated on a set of benchmark circuits...|$|R
40|$|Defects {{occurring}} at knitting, dyeing, linking, boarding, cutting and sewing individually or collectively give rice to faults in hosiery which are detected by {{the naked eye}} apart from the <b>undetectable</b> winding <b>faults</b> and yarn faults. In this study these faults have been considered in eight different classes and given in tabulated form. Due to practical difficulties such as interruption to production flow and difficulties in introducing new methods, this study has been limited to a few suggestions only. This work {{could be used for}} a more detailed study in faults in hosiery including shrinkage after dyeing of stretched nylon and acrylic for hosiery knitted fabric...|$|R
40|$|This work investigates {{testability}} of asynchronous circuits and {{its relation}} with signal transition graphs (STGs), using a state based approach on non-scan asynchronous circuits. In addition to the testability characteristics studied, this work suggests some test generation techniques for asynchronous circuits designed from STGS. An event fault, interpreted as either a stimulating fault or an inhibiting fault of a transition, is used to cover the stuck-at-fault (SAF) behavior of an asynchronous circuit. An advantage of such analysis is that test vectors for an inhibiting fault {{can be obtained from}} operations on a signal transition graph (STG) or a state graph (SG) rather than simulation at the circuit level. A test vector for a test state is represented in an STG by a test marking for each event fault. The lock relation of signals is a property proposed for hazard-free asynchronous circuit's synthesis. However, it is found that there is a special case of the lock relation that can prohibit the testing of some faults, the introduction of which cannot be avoided by the circuit level mapping. Some independent <b>undetectable</b> <b>faults</b> due to uncontrollable test states however can be detected if the reset state is the test state. Using a minimized two-level sum-of-products representation, each literal in a cube of the sum-of-products form is found to have its own function corresponding to the STG. Consequently, four types of literals are defined and their relations with the SAF behavior over the stimulating/inhibiting fault are analyzed. Although factorization of a logic equation binded to a C-element or a set-reset (SR) flip-flop is not always possible, a correct implementation on a set-dominant SR flip-flop is guaranteed. (Abstract shortened by UMI. ...|$|R
40|$|Semiconductor {{industry}} {{goals for}} the quality of shipped products continue to get higher to satisfy customer requirements. Higher quality of shipped electronic devices can only be obtained by thorough tests of the manufactured components. Scan chains are universally used in large industrial designs in order to cost effectively test manufactured electronic devices. They contain nearly half of the logic transistors in large industrial designs. Yet, faults in the scan cells are not directly targeted by the existing tests. The main objective of this thesis is to investigate the detectability of the faults internal to scan cells. In this thesis, we analyze the detection of line stuck-at, transistor stuck-on, resistive opens and bridging faults in scan cells. Both synchronous and asynchronous scan cells are considered. We define the notion of half-speed flush test and demonstrate that such new tests increase coverage of internal faults in scan cells. A new set of flush tests is proposed and such tests are applied at higher temperatures to detect scan cell internal opens with a wider range of resistances. We also propose new scan based tests to further increase the coverage of those opens. The proposed tests are shown to achieve the maximum possible coverage of opens in transistors internal to scan cells. For an asynchronous scan cell considered, two new flush tests are added to cover the faults that are not detected by the tests for synchronous scan cells. An analysis of detection of a set of scan cell internal bridging faults is described. Both zero-resistance and nonzero-resistance bridging fault models are considered. We show that the detection of some zero-resistance non-feedback bridging faults requires two-pattern tests. We classify the <b>undetectable</b> <b>faults</b> based on the reasons for their undetectability. We also propose an enhanced logic BIST architecture that accomplishes the new flush tests we propose to detect scan cell internal opens. The effectiveness of these new methods to detect scan cell internal faults is demonstrated by experimental results using some standard scan cells from a large industrial design...|$|R
40|$|Debugging errors during {{real-world}} {{testing of}} remote platforms can be time consuming and expensive when the remote environment is inaccessible and hazardous such as deep-sea. Pre-real world testing facilities, such as Hardware-In-the-Loop (HIL), {{are often not}} available due to the time and expense necessary to create them. Testing facilities tend to be monolithic in structure and thus inflexible making complete redesign necessary for slightly different uses. Redesign is simpler {{in the short term}} than creating the required architecture for a generic facility. This leads to expensive facilities, due to reinvention of the wheel, or worse, no testing facilities. Without adequate pre-real world testing, integration errors can go undetected until real world testing where they are more costly to diagnose and rectify, e. g. especially when developing Unmanned Underwater Vehicles (UUVs). This thesis introduces a novel framework, the Augmented Reality Framework (ARF), for rapid construction of virtual environments for Augmented Reality tasks such as Pure Simulation, HIL, Hybrid Simulation and real world testing. ARF’s architecture is based on JavaBeans and is therefore inherently generic, flexible and extendable. The aim is to increase the performance of constructing, reconfiguring and extending virtual environments, and consequently enable more mature and stable systems to be developed in less time due to previously <b>undetectable</b> <b>faults</b> being diagnosed earlier in the pre-real-world testing phase. This is only achievable if test harnesses can be created quickly and easily, which in turn allows the developer to visualise more system feedback making faults easier to spot. Early fault detection and less wasted real world testing leads to a more mature, stable and less expensive system. ARF provides guidance on how to connect and configure user made components, allowing for rapid prototyping and complex virtual environments to be created quickly and easily. In essence, ARF tries to provide intuitive construction guidance which is similar in nature to LEGOR pieces which can be so easily connected to form useful configurations. ARF is demonstrated through case studies which show the flexibility and applicability of ARF to testing techniques such as HIL for UUVs. In addition, an informal study was carried out to asses the performance increases attributable to ARF’s core concepts. In comparison to classical programming methods ARF’s average performance increase was close to 200 %. The study showed that ARF was incredibly intuitive since the test subjects were novices in ARF but experts in programming. ARF provides key contributions in the field of HIL testing of remote systems by providing more accessible facilities that allow new or modified testing scenarios to be created where it might not have been feasible to do so before. In turn this leads to early detection of faults which in some cases would not have ever been detected before. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|International audienceSeveral {{studies have}} focused on the role of damage zone (DZ) on the {{hydromechanical}} behaviour of faults by assuming a fractured DZ (i. e. low stiffness/high permeability). Yet, this vision may not be valid in all geological settings, in particular, in high-porosity reservoirs as targeted by several underground exploitations. We investigate the impact of a high-stiff/low-permeable DZ on the shear reactivation of a blind, <b>undetectable</b> normal <b>fault</b> (1 km long, ≤ 10 [*]m offset), with a 0. 5 m thick low-porosity/permeability fault core during fluid injection into a high-porosity reservoir. The spatial distribution of effective properties (elastic moduli, Biot's coefficients and permeability) of DZ including deformation bands (DB; elliptic inclusions) and intact rock were derived using upscaling analytical expressions. The influence of DZ on the hydromechanical behaviour of the fault zone was numerically explored using 2 -D plane-strain finite-element simulations within the framework of fully saturated isothermal porous media by accounting for an orthotropic elastic rheology. The numerical results showed that the presence of DB plays a protective role by reducing the potential for shear reactivation inside the fault core. On the other hand, they favour shear failure {{in the vicinity of the}} fault core (off-fault damage) by accelerating the decrease of the minimum principal effective stress while limiting the decrease of the maximum one. This behaviour is strongly enhanced by the fault-parallel DZ effective stiffness, but limited by the combined effect of fault-normal DZ effective permeability and of the Biot's coefficients. This can have implications for the location and size of aftershocks during fault reactivation...|$|R
40|$|As {{the clock}} {{frequency}} {{and complexity of}} digital integrated circuits increase rapidly, delay testing is indispensable to guarantee the correct timing behavior of the circuits. In this dissertation, we describe methods developed for three aspects of delay testing in scan-based circuits: test generation, path selection and built-in test generation. ^ We first describe a deterministic broadside test generation procedure for a path delay fault model named the transition path delay fault model, which captures {{both large and small}} delay defects. Under this fault model, a path delay fault is detected only if all the individual transition faults along the path are detected by the same test. To reduce the complexity of test generation, sub-procedures with low complexity are applied before a complete branch-and-bound procedure. Next, we describe a method based on static timing analysis to select critical paths for test generation. Logic conditions that are necessary for detecting a path delay fault are considered to refine the accuracy of static timing analysis, using input necessary assignments. Input necessary assignments are input values that must be assigned to detect a fault. The method calculates more accurate path delays, selects paths that are critical during test application, and identifies <b>undetectable</b> path delay <b>faults.</b> These two methods are applicable to off-line test generation. For large circuits with high complexity and frequency, built-in test generation is a cost-effective method for delay testing. For a circuit that is embedded in a larger design, we developed a method for built-in generation of functional broadside tests to avoid excessive power dissipation during test application and the overtesting of delay faults, taking the functional constraints on the primary input sequences of the circuit into consideration. Functional broadside tests are scan-based two-pattern tests for delay faults that create functional operation conditions during test application. To avoid the potential fault coverage loss due to the exclusive use of functional broadside tests, we also developed an optional DFT method based on state holding to improve fault coverage. High delay fault coverage can be achieved by the developed method for benchmark circuits using simple hardware. ...|$|R
