11|0|Public
5000|$|The {{inverse matrix}} {{converts}} from the <b>YCoCg</b> color model {{back to the}} RGB color model: ...|$|E
5000|$|The three {{values of}} the <b>YCoCg</b> color model are {{calculated}} as follows from the three color {{values of the}} RGB color model: ...|$|E
50|$|Advantages the <b>YCoCg</b> color {{model has}} over the YCbCr color model are simpler and faster computation, better decorrelation {{of the color}} planes to improve {{compression}} performance, and exactly lossless invertibility.|$|E
50|$|The HEVC {{standard}} supports color spaces such as generic film, NTSC, PAL, Rec. 601, Rec. 709, Rec. 2020, SMPTE 170M, SMPTE 240M, sRGB, sYCC, xvYCC, XYZ, and externally specified color spaces. HEVC supports color encoding representations such as RGB, YCbCr, and <b>YCoCg.</b>|$|E
50|$|The <b>YCoCg</b> color {{model is}} the color space formed from a simple {{transformation}} of an associated RGB color space into a luma value (denoted as Y) and two chroma values called chrominance green (Cg) and chrominance orange (Co). It is supported in video and image compression designs such as H.264/MPEG-4 AVC, HEVC, JPEG XR, and Dirac, since it is simple to compute, has good transform coding gain, and can be losslessly converted to and from RGB with fewer bits than are needed with other color models.|$|E
5000|$|A scaled {{version of}} the transformation, {{sometimes}} called YCoCg-R (where the [...] "-R" [...] refers to reversibility), can be implemented efficiently with a reduced bit depth. The scaled version uses a lifting scheme to make it exactly invertible while minimizing the bit depth of the three color components. For RGB signals with bit depth n, the bit depth of the Y signal when using YCoCg-R will be n and the bit depth of Co and Cg will be n+1, as contrasted with ordinary <b>YCoCg</b> which would need n+2 bits for Y and Cg and n+1 bits for Co.|$|E
5000|$|FLIF {{uses the}} {{reversible}} <b>YCoCg</b> color space (unlike [...] that loses {{a bit of}} color information, independently of its use in otherwise lossy JPEG). Not yet implemented are some features, e.g. other [...] "color spaces (CMYK, YCbCr, ...)". The color space conversion is faster, but the overall decoding (and encoding) is still slower than it needs to be, {{or some of the}} competition, even with the better color space as that is {{only a small fraction of}} the overall process. The format supports an optional alpha channel (RGBA) like PNG (but unlike JPEG); and progressive coding, similar to PNG (unlike it, progressive compression doesn't increase file-size), but as FLIF's algorithm is more complex (and partly, may not have had as much tuning of the implementation yet), it has a higher computational cost; at least lower bandwidth requirements can offset some of that extra time. Without the progressive coding, FLIF is faster, than otherwise.|$|E
40|$|Abstract: Edges are {{prominent}} features in images and their analysis and detection are an essential goal in computer vision and image processing. Indeed, identifying and localizing edges are {{a low level}} task {{in a variety of}} applications such as 3 -D reconstruction, shape recognition, image compression, enhancement, and restoration. This paper presents a comparative study on different approaches to edge detection of colour images. The approaches are based on transforming the RGB image to YUV and <b>YCoCg</b> and back to RGB colour model. Edges are detected by Laplacian operator and Gradient Operator. The results show that the colour models can be adopted based on the industry that colours are to be used. I...|$|E
40|$|When {{considering}} color {{images and}} more generally multi component images, {{state of the}} art image codecs usually achieve component decorrelation through static color transforms such as YUV or <b>YCoCg.</b> This approach leads to suboptimal results as statistics of the image are not taken into account. The new approach proposed here offers to remove the correlation of one component according to another adaptively during the prediction process of an image codec. Through two jointly used processes, one aiming at choosing the best predictor of a component and another aiming at improving the predictorâ€™s effectiveness, this new approach improves both image quality and compression ratio. This new technique has been applied to the LAR codec and shows an improvement over previous studies up to 20 % in rate and 0. 5 db in PSNR at low bit rates. 1...|$|E
40|$|Figure 1. Our method can {{rasterize}} a {{color image}} using only two frame-buffer chan-nels by interleaving the chrominance components in a checkerboard pattern. The final image is reconstructed using an edge-directed demosaicing filter. The compression error, visualized in the inset, is negligible, and the filtering is temporally stable. In {{this article we}} present a lossy frame-buffer compression format, suitable for exist-ing commodity GPUs and APIs. Our compression scheme allows a full-color image to be directly rasterized using only two color channels at each pixel, instead of three, thus reducing both the consumed storage space and bandwidth during the rendering process. Exploiting {{the fact that the}} human visual system is more sensitive to fine spatial variations of luminance than of chrominance, the rasterizer generates frag-ments in the <b>YCoCg</b> color space and directly stores the chrominance channels at a lower resolution using a mosaic pattern. When reading from the buffer, a simple and efficient edge-directed reconstruction filter provides a very precise estimation of the original uncompressed values. We demonstrate that the quality loss from our method is negligible, while the bandwidth reduction results in a sizable increase in the fill rate of the GPU rasterizer...|$|E

