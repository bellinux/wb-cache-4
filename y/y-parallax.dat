16|8|Public
5000|$|Generalization of <b>y-parallax</b> {{differential}} formula. Photogrammetria Elsevier Publishing Company, Amsterdam, 23,(1968) 95-102.|$|E
30|$|Because zero <b>y-parallax</b> {{is one of}} {{the most}} {{important}} features of epipolar constraints in stereo image processing applications, zero <b>y-parallax</b> should be used as an evaluation criterion. Therefore, the experimental results were presented to show whether the proposed algorithms satisfied this criterion and could be considered valid for use in applications.|$|E
3000|$|... <b>y-parallax</b> {{between the}} {{resampled}} epipolar image pair {{can be measured}} by a stereo matching algorithm. All of the reliable matched image points from epipolar image pair are used to compute <b>y-parallax.</b> The points, which are used in stereo matching, are extracted using the Harris corner detector and the bi-directional area-based stereo matching algorithm with sub-pixel accuracy is used to get more reliable result.|$|E
40|$|A {{practical}} example of digital rectification of tilted photographs using a drum scanning micro densitometer and general purpose computers is depicted. The present research covers rectification of projective distorsions, occuring {{when the camera}} axis is not truly vertical, and affine distorsions due to curvature of a drum of a scanner. For this purpose, fundamental mathematical expressions were derived. And some pixel interpolation methods necessary for image reconstruction were compared experimentally. The examples revealed, however, that the film was deformed so complexly {{that they could not}} be corrected sufficiently only by affine transformation. Accuracy of rectification was checked by use of stereo aerial photographs in terms of residual <b>y-parallaxes.</b> The result showed residual <b>y-parallaxes</b> of ± 1 pixel (± 50 μm) and sometimes ± 2 pixels were observed. They seem to be caused mainly by film deformations which have not been eliminated, and their amount seems to exceed the photogrammetric tolerance...|$|R
40|$|For {{operational}} use, {{the photo}} orientations of a block {{with more than}} 1000 images have been determined with an LCR 88 inertial measurement unit (IMU) and GPS. The relation of the IMU to the camera and corrections for the GPS-data of the projection centers have been determined and improved {{by means of a}} small reference block with 5 – 8 photos. For checking purposes the photo coordinates of 252 photos have been measured and the orientations are determined by a combined bundle block adjustment with the GPS-data of the projection centers based on 9 control points. The achieved accuracy of the photo orientations based on IMU and GPS are sufficient for the creation of orthophotos but problems are still existing with <b>y-parallaxes</b> in the models. The <b>y-parallaxes</b> can be reduced by a combined bundle block adjustment without control points or a more expensive inertial measurement system. 1...|$|R
40|$|During {{recent years}} direct sensor {{orientation}} with GPS and IMU has gained popularity. The system can directly get exterior orientation elements without using ground control points. To achieve the full accuracy potential of direct sensor orientation, the compensation of systematic errors {{with the correct}} mathematical model and an optimum number of parameters for sensor calibration is required. However, experiments showed {{that there would be}} some problems with <b>y-parallaxes</b> of stereo models based on direct sensor orientation. In this paper we put up one method to resolve this problem. The method was the integration of GPS/IMU and (automatic) aerial triangulation (AAT) into bundle block adjustment, which was also called integrated sensor orientation. From experimental results, we could get some conclusions that direct sensor orientation currently allows the generation of orthoimages of the small image scale. But it is not always suitable for stereo plotting because of the large <b>y-parallaxes</b> in some models. To resolve this problem, the combination of GPS/IMU observations with ground control points (integrated sensor orientation) should be preferred in some cases. 1...|$|R
30|$|Besides the {{classical}} 1 D matching (along an image ray, an image row or the Z-coordinate) for reconstruction of object geometry, MicMac also implements a 2 D matching strategy. This strategy {{is useful in}} 2 D deformation studies between rectified images (cf. Fig. 5; also MM 2 DPosSism), as an orientation quality estimation tool to asses the remaining <b>y-parallax</b> (MMTestOrient; cf. Fig. 6), or in cases when orientation parameters are unknown or known with poor precision (executed with XML file). Because the expected disparities pertinent to geometry are of higher frequencies than those along the <b>y-parallax,</b> the regularization of the energy function in the two direction is managed separately; cf. Eq. (2).|$|E
30|$|The {{proposed}} method will {{be practical}} and useful in generating stereo image pairs {{for the many}} applications that employ dense matching algorithms [13], because the proposed method efficiently yields constraints on the search space, with near zero <b>y-parallax</b> and the x-parallax bounded by the minimum and maximum heights using any type of sensor models.|$|E
30|$|As {{stated in}} the introduction, we suggest four {{performance}} evaluation criteria for piecewise epipolar resampling algorithms: geo-positioning accuracy, pixel scale and perpendicularity of axis in object space, near zero <b>y-parallax</b> in epipolar image space, and proportionality between x-parallax disparity and ground height. The third and the fourth criteria have already been mentioned in several previous studies [3, 4, 7, 8].|$|E
40|$|The usual {{satellite}} image orientation {{is based on}} bias corrected rational polynomial coefficients (RPC). The RPC are describing the direct sensor orientation of the {{satellite image}}s. The locations of the projection centres today are without problems, but an accuracy limit {{is caused by the}} attitudes. Very high resolution satellites today are very agile, able to change the pointed area over 200 km within 10 to 11 seconds. The corresponding fast attitude acceleration of the satellite may cause a jitter which cannot be expressed by the third order RPC, even if it is recorded by the gyros. Only a correction of the image geometry may help, but usually this will not be done. The first indication of jitter problems is shown by systematic errors of the <b>y-parallaxes</b> (py) for the intersection of corresponding points during the computation of ground coordinates. These <b>y-parallaxes</b> have a limited influence to the ground coordinates, but similar problems can be expected for the x-parallaxes, determining directly the object height. Systematic <b>y-parallaxes</b> are shown for Ziyuan- 3 (ZY 3), WorldView- 2 (WV 2), Pleiades, Cartosat- 1, IKONOS and GeoEye. Some of them have clear jitter effects. In addition linear trends of py can be seen. Linear trends in py and tilts in of computed height models may be caused by limited accuracy of the attitude registration, but also by bias correction with affinity transformation. The bias correction is based on ground control points (GCPs). The accuracy of the GCPs usually does not cause some limitations but the identification of the GCPs in the images may be difficult. With 2 -dimensional bias corrected RPC-orientation by affinity transformation tilts of the generated height models may be caused, but due to large affine image deformations some satellites, as Cartosat- 1, have to be handled with bias correction by affinity transformation. Instead of a 2 -dimensional RPC-orientation also a 3 -dimensional orientation is possible, respecting the object height more as by 2 -dimensional orientation. The 3 -dimensional orientation showed advantages for orientation based on a limited number of GCPs, but in case of poor GCP distribution it may cause also negative effects. For some of the used satellites the bias correction by affinity transformation showed advantages, but for some other the bias correction by shift was leading to a better levelling of the generated height models, even if the root mean square (RMS) differences at the GCPs were larger as for bias correction by affinity transformation. The generated height models can be analyzed and corrected with reference height models. For the used data sets accurate reference height models are available, but an analysis and correction with the free of charge available SRTM digital surface model (DSM) or ALOS World 3 D (AW 3 D 30) is also possible and leads to similar results. The comparison of the generated height models with the reference DSM shows some height undulations, but the major accuracy influence is caused by tilts of the height models. Some height model undulations reach up to 50 % of the ground sampling distance (GSD), this is not negligible but it cannot be seen not so much at the standard deviations of the height. In any case an improvement of the generated height models is possible with reference height models. If such corrections are applied it compensates possible negative effects of the type of bias correction or 2 -dimensional orientations against 3 -dimensional handling...|$|R
40|$|The direct {{geo-referencing}} {{of sensors}} {{based on a}} combination of relative kinematic GPS-positioning and inertial measurement units (IMU) has reached a high accuracy level and growing application. It includes the advantage of a very flexible use, independent upon control points which are only required for the system calibration and independent upon block or strip configurations. It is in use in areas with difficult access, as well as for standard applications. The direct georeferencing is a prerequisite for the economic use of small format digital images instead of standard aerial photos. Projects with standard accuracy requirements can be handled without problems. Only some limitations may appear for the model setup; disturbing <b>y-parallaxes</b> cannot be avoided with the today dominating application of standard photographic aerial cameras. But an improvement of individual models or a whole block by a combined adjustment together with image coordinates of tie points can solve this problem. For large scale projects with higher accuracy requirements an integrated sensor orientation by a bundle block adjustment with the orientations as observations and a minimal number of control points is proposed. An overview of the status of direct and integrated sensor orientation will be given. 1...|$|R
40|$|The {{determination}} of the exterior orientation {{by a combination of}} an inertial measurement system (IMU) with relative kinematic GPS-positioning – the direct georeferencing- has a growing number of applications for standard photogrammetric projects. One mayor problem is the {{determination of}} the relation between the camera and the IMU- the boresight misalignment. The rigorous mathematical model requires the computation and use of it in an orthogonal coordinate system like a tangential system in relation to the earth ellipsoid. But the final data acquisition usually shall be made directly in the national coordinate system. The procedure to use the boresight misalignment without loss of accuracy in the national coordinate system in any location will be explained. Results of the stability of the misalignment over the time will be shown. If the results of the boresight calibration shall be used for different image scales, also the inner orientation has to be determined together with the boresight misalignment. This has to be done with 2 different flying heights over a calibration site. Another problem is the limited accuracy of the model set up, today the direct sensor orientation is often not accurate enough to guarantee a model set up without a disturbing size of the <b>y-parallaxes.</b> This can be solved with a combined adjustment of the direct sensor orientation together with image coordinates of tie points, but without control points. 1...|$|R
30|$|Furthermore, {{we suggest}} four {{performance}} evaluation criteria for epipolar resampling algorithms: (1) geo-positioning {{accuracy of the}} resampled epipolar images relative to the original sensor model, (2) square pixel scale and perpendicularity of axis in object space, (3) near zero <b>y-parallax</b> in epipolar image space, and (4) proportionality between the disparity in the x-parallax and the ground height. Using these criteria, performance evaluations of the previously suggested algorithms and the algorithm proposed in this paper are presented based on experimental data from satellite images, including optical images such as those from IKONOS, Pleiades, and WorldView, as well as synthetic aperture radar (SAR) images as those from KOMPSAT- 5 and TerraSAR-X.|$|E
30|$|Several {{studies have}} been {{conducted}} to establish the epipolar geometry of the pushbroom camera to achieve effective epipolar image resampling. For example, Oh et al. [3] proposed a piecewise approach to this problem with rational polynomial coefficient (RPC); this is an image space-based approach and was shown to achieve almost zero <b>y-parallax,</b> as well as a linear relationship between the x-parallax and the ground height. Alternatively, Wang et al. [4] suggest a method that implements a new epipolarity model based on the projection reference plane (PRP); this is an object space-based approach, and experimental results showed that the vertical parallaxes all attained sub-pixel levels in along-track and cross-track stereo images from actual equipment, including Earth observation satellites SPOT- 5, IKONOS, IRS-P 5, and QuickBird.|$|E
30|$|This section {{describes}} a modified algorithm to perform piecewise epipolar resampling that ensures (1) {{preservation of the}} geo-positioning accuracy of the original sensor model in the resampled epipolar images, (2) scales with equidistant pixels and perpendicularity of the axis, (3) near zero <b>y-parallax,</b> and (4) proportionality between the disparity in the x-parallax and the ground height. The proposed algorithm is a unified one {{because it can be}} applied to both along-track and cross-track stereo images and can also be applied to SAR stereo images for radargrammetry, as shown by experimental results reported in Section 5. The prevailing methods can also be applied to all of these types of stereo images, but the proposed one uses only the CSM [10] interface, stated in Section 3.2, {{so that it can be}} applied to all of stereo image pairs regardless of the sensor types, and furthermore, it shows better performance in terms of the four performance evaluation criteria.|$|E
40|$|During {{recent years}} the direct sensor {{orientation}} with GPS and IMU has gained popularity. These systems allow the determination of all exterior orientation elements without using ground control points. This technology opens several new applications for photogrammetry and remote sensing. One precondition for direct sensor orientation with GPS and IMU is the correct sensor calibration. The related parameters {{as well as the}} relation between the IMU and the aerial camera (boresight misalignment) have to be determined by conventional bundle block adjustment. During this process a camera self calibration (focal length, principal point, additional parameters etc.) may be performed under operational conditions. To achieve the full accuracy potential of direct sensor orientation, the compensation of systematic errors with the correct mathematical model and an optimum number of parameters for sensor calibration is required. A series of tests was conducted and showed the good accuracy potential of direct GPS/IMU sensor orientation. First investigations showed also problems with <b>y-parallaxes</b> of stereo models based on direct sensor orientation. Future developments in GPS and IMU sensors and data processing may reduce this problem. Just now we do need another save solution. A promising one is the integration of GPS/IMU and (automatic) aerial triangulation (AAT) into bundle block adjustment, also called integrated sensor orientation. This paper presents the sensor calibration based on data from test flights in large image scales. Furthermore it demonstrates the accuracy potential at independent check points in object and in image space for direct and integrated sensor orientation. ...|$|R
40|$|The European Organisation for Experimental Photogrammetric Research (OEEPE) has {{embarked}} on a test investigating integrated sensor orientation using GPS and IMU in comparison and in combination with aerial triangulation. The test consists of two phases. The first phase comprises the system calibration and the determination of the exterior orientation parameters. The second phase deals with the integration of the GPS/IMU data into the bundle block adjustment, i. e. the integrated sensor orientation itself. 13 test participants processed the distributed data and returned their results. In this paper we shortly describe the test setup and report about the results of phase I. The accuracy potential of direct georeferencing for 1 : 5000 imagery was found to lie at approximately 5 - 10 cm in planimetry and 10 – 15 cm in height in object space and at 15 - 20 µm in image space. The most important finding is the fact that direct georeferencing {{has proven to be a}} serious alternative to conventional bundle adjustment and currently allows for the generation of orthophotos and other applications with less stringent accuracy requirements. However, stereo plotting is not yet possible due to the relatively large remaining <b>y-parallaxes.</b> Future developments in the areas of GPS and IMU sensors and data processing will probably also reduce this problem. The best results in terms of accuracy and in particular in terms of reliability are expected from an intergration of GPS/IMU data into the bundle adjustment 1...|$|R
30|$|Computational stereo is in {{the fields}} of {{computer}} vision and photogrammetry. In the computational stereo and surface reconstruction paradigms, {{it is very important to}} achieve appropriate epipolar constraints during the camera-modeling step of the stereo image processing. It has been shown that the epipolar geometry of linear pushbroom imagery has a hyperbola-like shape because of the non-coplanarity of the line of sight vectors. Several studies have been conducted to generate resampled epipolar image pairs from linear pushbroom satellites images; however, the currently prevailing methods are limited by their pixel scales, skewed axis angles, or disproportionality between x-parallax disparities and height. In this paper, a practical and unified piecewise epipolar resampling method is proposed to generate stereo image pairs with zero <b>y-parallax,</b> a square pixel scale, and proportionality between x-parallax disparity and height. Furthermore, four criteria are suggested for performance evaluations of the prevailing methods, and experimental results of the method are presented based on the suggested criteria. The proposed method is shown to be equal to or an improvement upon the prevailing methods.|$|E
40|$|The {{idea and}} concept of Measurable Virtual Reality (MVR) based on {{seamless}} stereo-orthoimage database is firstly put forward. The meanings and basic principle of MVR {{is discussed in}} this paper. Based on stereovision of human’s eyes, the main idea of MVR is to generate a seamless Digital Orthophoto Quadrangles (DOQ) database from DEM and odd photos and generate additionally a digital stereo-orthophoto partner (DSP) from DEM and even photos, then a large area 3 D virtual landscape environment can be formed without <b>y-parallax.</b> In such environment, the 3 D measurement and analysis can be done under the interface of normal GIS or CAD systems without complex DPW. The 3 D objects, such as houses, trees, cloverleaf junctions, geologic ruptures, and so on, which are not acquired during data acquisition at DPW, can be measured by end user himself. The project design in such 3 D virtual landscape environment will be more intuitionistic and more realistic. The application fields and the prospects of MVR are also presented in this paper. At last, some experiment results of MVR are discussed. 1...|$|E
40|$|Image {{registration}} {{is a broad}} topic which is not only applied to photogrammetry and remote sensing problems, but also to medical imaging, pattern recognition, and computer vision activities. Image registration can be categorized into non-photogrammetric (or non sensor model-based) and photogrammetric (or sensor model-based). Registration problems can also be classified into 2 D-to- 2 D, 3 D-to- 2 D, and 3 D-to- 3 D. In this thesis, we mainly focus on 2 D-to- 2 D and 3 D-to- 2 D image registration. ^ The primary thrust of this thesis is in three main areas: replacement sensor model, epipolar image rectification, and image registration. Several types of image acquisition datasets, from aerial frame, airborne whiskbroom, and satellite pushbroom (linear array scanners) passive sensors, are used. Knowledge of sensor model {{can be used to}} relate three-dimensional object data to corresponding two-dimensional image data (i. e. 3 D-to- 2 D registration). These can be categorized into the original physical/geometrical models, or their replacement models. A novel approach, termed “generalized True Replacement Model (TRM) ”, is developed to satisfy the following characteristics: highly accurate ground-to-image function, rigorous error propagation, and an ability for model parameter refinement. More importantly, the generalized TRM can perform relative triangulation without any use of ground control points (GCPs) {{in a manner similar to}} the original model. The generalized TRM was successfully implemented with no significant difference in triangulation results with the physical model. ^ Epipolar rectification of scan imageries is a challenging problem since unique epipolar geometry might not exist, unlike frame images. A new approach for epipolar rectification of scan imageries is proposed to minimize <b>y-parallax</b> in the rectified images. Several experiments are conducted to assess the effect of different stereo geometries, on epipolar rectification, from along-track and across-track stereo pairs. The results show that a reduction of <b>y-parallax</b> to the sub-pixel level for OrbView, QuickBird, and HyMap (whiskbroom) pairs. This allows stereo anaglyph images to be generated. It is concluded that very acceptable results can be produced for stereo images either from satellite or airborne scan sensors. ^ For 2 D-to- 2 D registration, transformations such as affine, projective, or polynomials were investigated since they are commonly used in non-photogrammetric registration. Decrease in registration accuracy is found when terrain variation is increased. Several experiments on sensitivity analysis and error propagation are performed to evaluate this approach. Relative triangulation is the technique used in the 2 D-to- 2 D photogrammetric registration. Similar experiments on sensitivity analysis and error propagation are performed and the two approaches compared. Photogrammetric registration requires object surface information. Therefore, a reconstruction technique, based on dynamic programming, for digital surface model (DSM) is developed. The DSM results show promise in that the results are comparable to those generated from NGATE in the Socetset commercial software. Finally, comparison of photogrammetric registration to non-photogrammetric registration clearly indicated that in urban areas the photogrammetric approach is superior. In general, caution should be exercised, when using non-photogrammetric registration, particularly when significant elevation variation, especially from man-made object, exists. ...|$|E
40|$|Linear array {{scanners}} {{are used}} as a substitute of two-dimensional/frame digital cameras since they can produce high-resolution digital images comparable to scanned aerial photographs. On the other hand, digital frame cameras have inadequate size that is dictated by technical considerations/limitations. In general, rigorous sensor modelling involves {{the description of the}} physical process of data capture using such a sensor. For imaging systems, rigorous modelling incorporates the system’s interior and exterior orientation parameters. Such parameters might not be always available for linear array scanners (e. g., commercially available IKONOS scenes). Deriving these parameters requires numerous ground control points. Moreover, the estimation process is geometrically ill posed due to the narrow angular field of view of the imaging system. Recently, parallel projection has emerged as an approximate model (for high altitude scanners with narrow angular field of view) {{that can be used to}} represent the mathematical relationship between scene and object space coordinates using few parameters. This paper outlines the derivation of resampling approach of linear array scanner scenes according to epipolar geometry. Conjugate points should have no <b>y-parallax</b> in the resampled scenes. Moreover, they should have an x-parallax that is linearly proportional to the corresponding object height. Such requirements can only be met by projecting the original scenes into a common horizontal plane. The paper explains the selection of such plane to meet these specifications. Experimental results using IKONOS data demonstrate the feasibility of the approach. 1...|$|E
40|$|The geo-referenced {{image with}} one-meter {{resolution}} (GRIOMR) {{is one of}} the most basic information in the digital earth. The remote sensing image with high resolution (RSIHR) is the best resource for acquiring the GRIOMR in low costing and sort period. The key technique producing GRIOMR from RSIHR is introduced in this paper, including parameter computation of RSIHR, image matching to creating DTM and fast orthogonal rectification of RSIHR. After the Rational Polynomial Coefficient (RPC) used by IKONOS and QUICKBIRD images and the block adjustment based on RPC parameters are presented, the new, simple and strict geometric model based on affine transformation is described. When there are control points less than 5 in each image, the block adjustment based on RPC parameters could be used. If there are control points more than 4 in each image, the new, simple and strict geometric model based on affine transformation should be applied. For some of RSIHR, the approximate epipolar image pair, after relative registration, remains quite large <b>y-parallax.</b> Therefore, the 2 D relaxation matching should be used in the DTM modelling from RSIHR. Based on DTM and image parameters acquired by block adjustment based on RPC parameters or the model based on affine transformation, the RSIHR can be rectified by fast algorithm. The experimental results with real RSIHR show the strategy introduced in this paper is feasible. Corresponding conclusion and future work are summarized in the final. 1...|$|E
40|$|As {{the initial}} {{investigation}} on disaster occurrence, {{it is very}} important for reducing economical losses to obtain timely observation of damages especially in metropolis. In such situation, information on changed area obtained from aerial photo analysis is promising. In this study, we propose a change detection approach objected for metropolis right after the disaster with automatic image processing of aerial photos. We introduce two different types of approaches. The first method is for the case of no available orientation information. In this case change detection is performed by registration of images, which are taken before and after the disaster. We define this approach as 2 D image matching method. The second approach aims at acquiring not only 2 D changes’ distribution but also quantitative 3 D shifts by matching between digital terrain data and images before and after the disaster. We call this approach 3 D image matching method. In the first step of 2 D image matching method, initial registration is executed for minimizing the matching process between images before and after disaster. This process is performed automatically by detecting appropriate conjugate points which candidates are derived from images independently with the improved relaxation method and a mathematical model, which is constrained by a photogrammetric principle (relative orientation). In the next step, image rectification is executed. Owing to these processes <b>y-parallax</b> in images is eliminated and matching process is restricted in x-axis. In the case of relative orientation failure, formation of imaginary stereo model by perspective projection is executed as a substitutive means. For detecting changed area, the adaptive nonlinear mapping is applied. This method is based on model of self-organization in neural network. The one of the image pair i...|$|E
40|$|Large scale {{maps and}} image mosaics are {{representative}} geospatial data {{that can be}} extracted from UAV images. Map drawing using UAV images can be performed either by creating orthoimages and digitizing them, or by stereo plotting. While maps generated by digitization may serve the need for geospatial data, many institutions and organizations require map drawing using stereoscopic vision on stereo plotting systems. However, there are several aspects to be checked for UAV images to be utilized for stereo plotting. The first aspect is the accuracy of exterior orientation parameters (EOPs) generated through automated bundle adjustment processes. It {{is well known that}} GPS and IMU sensors mounted on a UAV are not very accurate. It is necessary to adjust initial EOPs accurately using tie points. For this purpose, we have developed a photogrammetric incremental bundle adjustment procedure. The second aspect is unstable shooting conditions compared to aerial photographing. Unstable image acquisition may bring uneven stereo coverage, which will result in accuracy loss eventually. Oblique stereo pairs will create eye fatigue. The third aspect is small coverage of UAV images. This aspect will raise efficiency issue for stereo plotting of UAV images. More importantly, this aspect will make contour generation from UAV images very difficult. This paper will discuss effects relate to these three aspects. In this study, we tried to generate 1  :  1, 000 scale map from the dataset using EOPs generated from software developed in-house. We evaluated Y-disparity of the tie points extracted automatically through the photogrammetric incremental bundle adjustment process. We could confirm that stereoscopic viewing is possible. Stereoscopic plotting work was carried out by a professional photogrammetrist. In order to analyse the accuracy of the map drawing using stereoscopic vision, we compared the horizontal and vertical position difference between adjacent models after drawing a specific model. The results of analysis showed that the errors were within the specification of 1  :  1, 000 map. Although the <b>Y-parallax</b> can be eliminated, it is still necessary to improve the accuracy of absolute ground position error in order to apply this technique to the actual work. There are a few models in which the difference in height between adjacent models is about 40  cm. We analysed the stability of UAV images by checking angle differences between adjacent images. We also analysed the average area covered by one stereo model and discussed the possible difficulty associated with this narrow coverage. In the future we consider how to reduce position errors and improve map drawing performances from UAVs...|$|E

