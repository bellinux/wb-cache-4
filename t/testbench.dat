380|76|Public
5000|$|Simulation {{acceleration}} {{can address}} the performance shortcomings of simulation to an extent. Here {{the design is}} mapped into a hardware accelerator to run much faster and the <b>testbench</b> (and any behavioral design code) continues to run on the simulator on the workstation. A high-bandwidth, low latency channel connects the workstation to the accelerator to exchange signal data between <b>testbench</b> and design. By Amdahl's law, the slowest device in the chain will determine the speed achievable. Normally, this is the <b>testbench</b> in the simulator. With a very efficient <b>testbench</b> (written in C or transaction-based), the channel may become the bottleneck. In some cases, a transaction-level <b>testbench</b> is able to feed as much data to the design being emulated as [...] "live" [...] stimulus.|$|E
50|$|To {{simulate}} an HDL model, {{an engineer}} writes a top-level simulation environment (called a test bench). At minimum, a <b>testbench</b> contains an instantiation {{of the model}} (called the device under test or DUT), pin/signal declarations for the model's I/O, and a clock waveform. The <b>testbench</b> code is event driven: the engineer writes HDL statements to implement the (testbench-generated) reset-signal, to model interface transactions (such as a host-bus read/write), and to monitor the DUT's output. An HDL simulator — the program that executes the <b>testbench</b> — maintains the simulator clock, which is the master reference for all events in the <b>testbench</b> simulation. Events occur only at the instants dictated by the <b>testbench</b> HDL (such as a reset-toggle coded into the <b>testbench),</b> or in reaction (by the model) to stimulus and triggering events. Modern HDL simulators have full-featured graphical user interfaces, complete with a suite of debug tools. These allow the user to stop and restart the simulation at any time, insert simulator breakpoints (independent of the HDL code), and monitor or modify any element in the HDL model hierarchy. Modern simulators can also link the HDL environment to user-compiled libraries, through a defined PLI/VHPI interface. Linking is system-dependent (Win32/Linux/SPARC), as the HDL simulator and user libraries are compiled and linked outside the HDL environment.|$|E
5000|$|Specman is an EDA {{tool that}} {{provides}} advanced automated functional verification of hardware designs. It provides an environment for working with, compiling, and debugging <b>testbench</b> environments {{written in the}} e Hardware Verification Language. Specman also offers automated <b>testbench</b> generation to boost productivity {{in the context of}} block, chip, and system verification.|$|E
40|$|Code {{generation}} or model driven software development {{has always had}} his place {{within the field of}} ASIC verification due to the obvious advantages with respect to time savings, complexity reduction, less bugs/errors etc. Typically, model driven software development has been used for generating RTL implementation for registers, register documentation, self-contained register tests from abstract specifications such as IP-XACT. Over {{the last couple of years}} generation of <b>testbenches</b> implemented in UVM have been widely introduced within the field by several contributors. This paper tries to leverage all of this previous work and introduce a layered abstraction for UVM <b>testbenches</b> which makes it possible to generate UVM-SystemVerilog (UVM-SV) and UVM-SystemC (UVM-SC) based <b>testbenches</b> from the same abstract specification. Especially UVM-SystemC enables the reuse of <b>testbenches,</b> e. g. from concept level down to Hardware-in-the-loop (HiL) approaches...|$|R
5000|$|... e is a {{hardware}} verification language (HVL) which is tailored to implementing highly flexible and reusable verification <b>testbenches.</b>|$|R
5000|$|... "Intelligent Verification" [...] uses {{existing}} logic simulation <b>testbenches,</b> {{and automatically}} targets and maximizes the following types of design coverage: ...|$|R
50|$|In 2013 TsAGI {{developed}} a <b>testbench</b> for high-speed compound helicopters with propellers.|$|E
5000|$|Applicability to {{all levels}} of {{simulation}} to decrease reliance on <b>testbench</b> programs ...|$|E
50|$|Newer {{intelligent}} verification {{tools are}} able to derive the essential functions one would expect of a <b>testbench</b> (stimulus, coverage, and checking) from a single, compact, high-level model. Using a single model that represents and resembles the original specification greatly reduces the chance of human error in the <b>testbench</b> development process {{that can lead to}} both missed bugs and false failures.|$|E
40|$|This paper {{provides}} some guidelines {{on how to}} approach System On a Chip (SOC) verification, and how to create effective SOC <b>testbenches.</b> It surveys the challenges in SOC verification {{and some of the}} traditional verification techniques, and then focuses on showing preferred practical approaches to the problem. 1...|$|R
40|$|One of {{the most}} {{difficult}} challenges in SoC verification today is determining how to make sure the hardware and software work together at the SoC level. Hardware verification has advanced {{to the point where the}} verification of individual functional blocks in a design can be achieved with reasonable confidence using constrained random <b>testbenches,</b> code coverage, assertio...|$|R
40|$|Abstract—Recent {{advances}} {{in both the}} capabilities and ac-cessibility of embedded systems {{have resulted in the}} potential to build increasingly complex systems that consequently are difficult to develop, test and deploy. Model-driven approaches raise the level of abstraction at which developers work, promising improved quality (reliability, safety, real-time properties) and increased productivity through automation. However, despite the increasing application of model-driven technologies to the development of embedded systems, little {{attention has been paid to}} the corresponding increase in complexity of verification environments for embedded systems. As system complexity has increased in recent years so has the complexity of hardware verification <b>testbenches</b> resulting in them becoming difficult to understand, maintain, extend and reuse across projects. This paper presents a new UML profile for the e verification language that enables the use of an aspect-oriented, model-driven approach for the design of verification <b>testbenches.</b> Index Terms—simplicity, beauty, elegance I...|$|R
50|$|Intelligent {{verification}} uses automation {{to adapt}} the <b>testbench</b> {{to changes in the}} register transfer level code.|$|E
5000|$|Can create highly {{reusable}} code, {{especially when}} the <b>testbench</b> is written following the Universal Verification Methodology (UVM) ...|$|E
5000|$|Static {{classes are}} labeled with the keyword 'unit'. Units {{are used for}} {{creating}} the permanent <b>testbench</b> structure.|$|E
40|$|Assertions (SVA), a {{synchronous}} assertion package {{based on}} the temporal-logic semantics of PSL. Traditionally assertions are checked in software simulation. We introduce a method for synthesizing SVA directly into hardware modules in Bluespec SystemVerilog. This opens up new possibilities for FPGA-accelerated <b>testbenches,</b> hardware/software co-emulation, dynamic verification and fault-tolerance. We describe adding synthesizable assertions to a cache controller, and investigate their hardware cost. ...|$|R
40|$|Part 3 : VerificationInternational audienceNowadays highly {{competitive}} market of consumer electronics is {{very sensitive to}} {{the time it takes}} to introduce a new product. However, the ever-growing complexity of application specific instruction-set processors (ASIPs) which are inseparable parts of nowadays complex embedded systems makes this task even more challenging. In ASIPs, it is necessary to test and verify significantly bigger portion of logic, tricky timing behaviour or specific corner cases in a defined time schedule. As a consequence, the gap between the proposed verification plan and the quality of verification tasks is widening due to this time restriction. One way how to solve this issue is using faster, efficient and cost-effective methods of verification. The aim of this paper is to introduce an automated generation of SystemVerilog verification environments (<b>testbenches)</b> for verification of ASIPs. Results show that our approach reduces the time and effort needed for implementation of <b>testbenches</b> significantly and is robust enough to detect also well-hidden bugs...|$|R
40|$|SystemVerilog [1] UVM [2] {{class-based}} <b>testbenches</b> {{have become}} {{as complex as}} the hardware under test, and are evolving into large object-oriented software designs. The usual RTL debugging techniques must be updated to match this new complexity. Debugging tools are addressing these complexities, but this article will describe techniques and approaches {{that can be used}} to help debug these complex environments without advanced debug tools...|$|R
5000|$|Providing {{verification}} {{results on}} or above par with a <b>testbench</b> program but {{driven by a}} compact high-level model ...|$|E
50|$|Intelligent Verification, which {{includes}} intelligent <b>testbench</b> automation, {{is a form}} of functional verification used to verify that an electronic hardware design conforms to specification before device fabrication. Intelligent verification uses information derived from the design and specification(s) to expose bugs in and between hardware IP's. Intelligent verification tools require considerably less engineering effort and user guidance to achieve verification results that meet or exceed the standard approach of writing a <b>testbench</b> program.|$|E
5000|$|The {{ability to}} {{generate}} a <b>testbench</b> (Conversion of test benches) with test vectors in VHDL or Verilog, based on complex computations in Python.|$|E
40|$|Abstract: This paper {{describes}} {{a method to}} perform error simulation to estimate {{the quality of the}} <b>testbenches</b> used to validate VHDL designs. The method is based in the mutation of VHDL descriptions by an error model. The proposed method allows an automatic execution of the error simulation using a commercial VHDL simulator. The resulting tool will be integrated in an environment devoted to quality checking of VHDL designs. 1...|$|R
40|$|This chapter {{addresses}} {{the problem of}} functional verification of IP cores to be integrated in complex embedded systems. After analyzing the limits of methods based on HDL <b>testbenches</b> or formal verification, a pseudorandom coverage-driven approach is presented (verification environment design guidelines together with a final coverage report summary) and applied to a novel Router IP core design, {{a key component of}} Networkon- Chip communication infrastructure in embedded system...|$|R
5000|$|Altera, Cambridge Silicon Radio and Xilinx on - IP-based Design and Verification Reuse. At Design Automation Conference 2013, three IC Manage {{customers}} discussed {{design and}} verification approaches utilizing IC Manage: Using one data repository for all designs, reusing simulation <b>testbenches,</b> linking the bug tracking system and data management system, making verification information {{part of the}} IP, designing by high-level block function rather than chips, minimizing IP modifications, and restricting IP access.|$|R
5000|$|SOPC Builder, a tool in Quartus II {{software}} that eliminates manual system integration tasks by automatically generating interconnect logic {{and creating a}} <b>testbench</b> to verify functionality ...|$|E
50|$|One {{can design}} {{hardware}} in a VHDL IDE (for FPGA implementation such as Xilinx ISE, Altera Quartus, Synopsys Synplify or Mentor Graphics HDL Designer) {{to produce the}} RTL schematic of the desired circuit. After that, the generated schematic can be verified using simulation software which shows the waveforms of inputs and outputs of the circuit after generating the appropriate <b>testbench.</b> To generate an appropriate <b>testbench</b> for a particular circuit or VHDL code, the inputs have to be defined correctly. For example, for clock input, a loop process or an iterative statement is required.|$|E
50|$|VHDL has file {{input and}} output capabilities, {{and can be used}} as a {{general-purpose}} language for text processing, but files are more commonly used by a simulation <b>testbench</b> for stimulus or verification data. There are some VHDL compilers which build executable binaries. In this case, it might be possible to use VHDL to write a <b>testbench</b> to verify the functionality of the design using files on the host computer to define stimuli, to interact with the user, and to compare results with those expected. However, most designers leave this job to the simulator.|$|E
2500|$|To {{reduce the}} number of {{functionality}} bugs, a separate hardware verification group will take the RTL and design <b>testbenches</b> and systems to check that the RTL actually is performing the same steps under many different conditions, classified as the domain of functional verification. Many techniques are used, none of them perfect but all of them useful [...] extensive logic simulation, formal methods, hardware emulation, lint-like code checking, code coverage, and so on.|$|R
40|$|Abstract. Multi-million gate {{designs of}} {{circuits}} and systems {{can only be}} handled by means of computer aided design tools. <b>Testbenches</b> or formal verification are used to ensure correctness of these large designs. But most tools only return a single simulation trace to expose a failure. Then, usually simulation has {{to be used for}} manual debugging. Here, a tool that automatically diagnoses an error and intuitively visualizes diagnosis results for equivalence checking is presented. The diagnosis engine facilitates a fast algorithm to calculate candidate error sites from counter-examples. The visualization engine was developed under the objective to handle large industrial designs. 1 Introduction Design and verification of todays integrated circuits with several million gates heavily depend on computer aided design (CAD). Tools are employed for synthesis of the initial HDL-description, optimization of the first gate-level description and during verification. While synthesis and logic optimization benefit from very efficient fully automatic tools, ensuring correctness has become the major bottleneck in the design process. Already up to 80 % of the design costs are caused by verification. During verification either <b>testbenches</b> or formal methods [1] are used to check the behavior of a design. When using <b>testbenches</b> debugging is only aided by simulators. Also in the context of property checking recent techniques for debugging essentially rely on simulation to navigate through the erroneous design [2, 3]. The methods based on property checking additionally offer some hints, which stimuli are essential to produce an erroneous output. But the designer can only use the simulated values to find the error. No automatic identification of candidate error sites is done, i. e. the tools do not show areas in the design that are capable of error correction...|$|R
40|$|A highly {{reliable}} safety class controller for NPPs (Nuclear Power Plants) is mandatory as even a minor malfunction {{can lead to}} disastrous consequences for people, the environment or the facility. In order to enhance the reliability of a safety class digital controller for NPPs, we employed a diversity approach, in which a PLC-type controller and a PLD-type controller are to be operated in parallel. We built and used structured <b>testbenches</b> based on the classes supported by UVM for functional verification of the PLD-type controller designed for NPPs. We incorporated a UVM register model into the <b>testbenches</b> {{in order to increase}} the controllability and the observability of the DUT(Device Under Test). With the increased testability, we could easily verify the datapaths between I/O ports and the register sets of the DUT, otherwise we had to perform black box tests for the datapaths, which is very cumbersome and time consuming. We were also able to perform constrained random verification very easily and systematically. From the study, we confirmed the various advantages of using the UVM register model in verification such as scalability, reusability and interoperability, and set some design guidelines for verification of the NPP controllers...|$|R
50|$|Catapult C {{supports}} SystemC model generation {{intended for}} virtual platforms, and a SystemC test environment {{to verify the}} generated RTL against the original C++ using the original C++ <b>testbench.</b>|$|E
50|$|An e <b>testbench</b> {{is likely}} to be run with RTL or higher-level models. Bearing this in mind, e is capable of {{interfacing}} with VHDL, Verilog, C, C++ and SystemVerilog.|$|E
50|$|Analog {{verification}} {{is built}} {{on the idea that}} transistor level simulation will always be too slow to provide adequate functional verification. Instead, it is necessary to build simple and efficient models of the blocks that make up the analog portion of the design and use those to verify the design. Those models are typically written in Verilog or Verilog-AMS, but could also be written in VHDL or VHDL-AMS. However, simply using a simple functional model is not sufficient. It is also necessary to build a comprehensive self-checking <b>testbench,</b> that thoroughly exercises the design and compare its response against a previously written specification for the design. Furthermore, this <b>testbench</b> should be applied in turn to both the model and the design. In this case, the design is represented with a transistor-level schematic. If both the model and the design pass all tests, and if the <b>testbench</b> is comprehensive, then this confirms that the model is consistent with the design and that the design is consistent with the specification.|$|E
40|$|This paper {{presents}} Pyramid code, {{an optimal}} code for transmitting sequential addresses over a DRAM bus. Constructed by finding an Eulerian cycle on a complete graph, this code is optimal for conventional DRAM {{in the sense}} that it minimizes the switching activity on the time-multiplexed address bus from CPU to DRAM. Experimental results on a large number of <b>testbenches</b> with different characteristics (i. e. sequential vs. random memory access behaviors) are reported and demonstrate a reduction of bus activity by as much as 50 %. 1...|$|R
40|$|Verification {{of complex}} {{hardware}} designs remains a very labor-intensive process often involving multiple designer and verification teams. Unfortunately, often the designs under verification are poorly documented and invariants of circuit operations are ill-defined increasing {{the burden on}} testers and verification engineers, who must understand internal aspects of the design written by other people. Since forcing the design team to write complete and exact specifications for each submodule is extremely costly and counterproductive, {{it is much more}} effective to help engineers to deduce internal design invariants from interface level behavior. This paper presents Vesper (VErilog Signal ProfilER) -a tool that identifies internal design signals causing interface level behavior through signal value profiling. Vesper engine automatically extracts internal design signal from registertransition level Verilog and creates monitoring environment based on user-described interface events. After running several <b>testbenches</b> the analytical engine of Vesper reasons on which signals could have caused the events to happen based on the frequency of the observed signal values. Vesper is very flexible and can be parameterized through several preand post-simulation filters to effectively limit the number of signals reported and thus help verification engineers in understanding the internal structure of the design. Our tests show that Vesper is impervious to false-negatives and is quite precise even with a small number of <b>testbenches.</b> We also postulate how Vesper can be used in verification {{as a part of a}} directed random simulation engine, making much of this work automatic and increasing productivity of the verification process. 1...|$|R
40|$|Before any IC is {{fabricated}} it {{is desired}} to check whether the required functionalities are preserved or not. Otherwise this {{may lead to}} a huge loss to the company in case of any failure in during the design/coding stage. Verification engineers {{have to make sure that}} before fabrication all the properties of the IC can be successfully implicated. So functional verification provides a lot of benefits to the IC designers. Today, testing and verification are alternatively used for the same thing. Testing of a large design using FPGA consumes longer compilation time in case of debugging and committing small mistakes. Simulation based testing is faster and also provides capability to check all the signals buried under the design. But due to the increasing complexity in design and the concurrency behavior of the design it has become very difficult to verify the functionality using traditional <b>testbenches.</b> So new languages called Hardware Verification Languages (HVL) are introduced. System Verilog is an IEEE standard Verification language. The library and package oriented feature provide an efficient way of writing <b>testbenches.</b> The Open Verification Methodology (OVM) Class Library provides the building blocks needed to quickly develop reusable and well-constructed verification components and test environments using SystemVerilog. In this paper we have developed testing environment using system Verilog implementation of OVM for I 2 C controller core. Our work introduces an automated stimulus generating testing environment for the design and checks the functionality of the I 2 C bus controller...|$|R
