0|161|Public
5000|$|... #Caption: Channel <b>S</b> <b>cameras</b> {{broadcasting}} the Baishakhi Mela in 2009 at Weavers Field, East London ...|$|R
40|$|Participation as chorister {{and actor}} in stage {{performance}} of "The Events" at Silo Theatre with Handel Consort and Quire and N. <b>S.</b> <b>Camera</b> Sept 3 2015 Study {{of the scores}} and rehearsal with the choir provided invaluable information towards the continued development of my own choral writing and my lecturing to composition students...|$|R
5000|$|Rollei 35 <b>S</b> compact <b>camera</b> (Singapore) with 40 mm f/2.8 Zeiss Sonnar made by Rollei.|$|R
50|$|Baraniuk is {{a co-founder}} of InView Technology Corporation, which is commercializing Baraniuk’ <b>s</b> single-pixel <b>camera</b> research.|$|R
5000|$|... #Caption: Samsung Galaxy <b>S</b> (i9000) <b>camera</b> with 1/3.6" [...] type sensor (4 mm × 3 mm).|$|R
40|$|In July 2012, as {{the four}} {{ground-based}} gamma-ray telescopes of the H. E. S. S. (High Energy Stereoscopic System) array reached their tenth {{year of operation}} in Khomas Highlands, Namibia, a fifth telescope took its first data {{as part of the}} system. This new Cherenkov detector, comprising a 614. 5 m 2 reflector with a highly pixelized camera in its focal plane, improves the sensitivity of the current array by a factor two and extends its energy domain down to a few tens of GeV. The present part I of the paper gives {{a detailed description of the}} fifth H. E. <b>S.</b> <b>S.</b> telescope’s <b>camera,</b> presenting the details of both the hardware and the software, emphasizing the main improvements as compared to previous H. E. <b>S.</b> <b>S.</b> <b>camera</b> technology...|$|R
40|$|Abstract: The H. E. <b>S.</b> <b>S.</b> <b>cameras</b> {{require a}} precise and regular {{calibration}} over time, {{to reconstruct the}} gamma-ray characteristics. The different sub-systems {{used to determine the}} gain and the uniformity of the PMTs and their evolution with time are presented. Then, we focus on the absolute energy scale calibration, by using a full reconstruction of isolated muons recorded during normal observation. The method and the evolution of the absolute overall light collection efficiency are shown...|$|R
40|$|MOBILE phones keep adding whiz-bang features, but {{research}} {{released this week}} suggests fewer people than makers would like are bothering to use them. Of people with handsets capable of doing things other than making phone calls, 59 per cent had sent an MMS; 55 per cent recorded video; 45 per cent went online; 40 per cent used GPS navigation and 27 per cent had made a video call. However, one {{thing we can do}} is take photos, with 84 per cent of people using their mobile 2 ̆ 7 <b>s</b> <b>camera</b> function...|$|R
40|$|H. E. S. S. —the {{high energy}} {{stereoscopic}} system—is {{a new system}} of large atmospheric Cherenkov telescopes for GeV/TeV astronomy. Each of the four telescopes of 107 m 2 mirror area is equipped with a 960 -pixel photomultiplier-tube camera. This paper describes the methods used to convert the photomultiplier signals into the quantities needed for Cherenkov image analysis. Two independent calibration techniques have been applied in parallel to provide an estimation of uncertainties. Results on the long-term stability of the H. E. <b>S.</b> <b>S.</b> <b>cameras</b> are also presented...|$|R
40|$|The artist 2 ̆ 7 <b>s</b> <b>camera</b> {{is pointed}} outward, {{through the windows}} of a {{revolving}} restaurant, toward the cityscape of Vancouver’s West End. With the restaurant acting as moving tripod, the video begins by panning clockwise, slowly passing cargo ships, skyscrapers, Stanley Park, and mountains on Vancouver’s North Shore. Maintaining its slowly creeping pace, the video progresses, subsequently recording the movement of cruise liners and smaller vessels in Coal Harbour. Midway through the video, the action reverses—allowing boats and cars to travel backwards—gradually replaying the previous views...|$|R
5000|$|The {{submission}} {{phase of}} the third edition of Red Bull Illume was open from December 1, 2012 until April 30, 2013. The 50 finalists were unveiled on August 29, 2013 at a ceremony at the Avenue of Stars in Hong Kong. The overall winner was Lorenz Holder (GER) whose image of snowboarder Xaver Hoffmann performing a jump at a satellite dish in Raisting, Germany was selected by an international panel of 50 photo experts, winning him a Leica <b>S</b> <b>camera,</b> a broncolor Move Outdoor kit as well as Sun-Sniper gear worth over €2,000.|$|R
40|$|H. E. S. S. - the High Energy Stereoscopic System- is a {{new system}} of large {{atmospheric}} Cherenkov telescopes for GeV/TeV astronomy. Each of the four telescopes of 107 m^ 2 mirror area is equipped with a 960 -pixel photomulitiplier-tube camera. This paper describes the methods used to convert the photomultiplier signals into the quantities needed for Cherenkov image analysis. Two independent calibration techniques have been applied in parallel to provide an estimation of uncertainties. Results on the long-term stability of the H. E. <b>S.</b> <b>S.</b> <b>cameras</b> are also presented. Comment: 29 pages, 13 figures, accepted by Astroparticle Physic...|$|R
40|$|The H. E. <b>S.</b> <b>S.</b> <b>cameras</b> {{require a}} precise and regular {{calibration}} over time, {{to reconstruct the}} gamma-ray characteristics. The different sub-systems {{used to determine the}} gain and the uniformity of the PMTs and their evolution with time are presented. Then, we focus on the absolute energy scale calibration, by using a full reconstruction of isolated muons recorded during normal observation. The method and the evolution of the absolute overall light collection efficiency are shown. Comment: 4 pages. Proceedings of the Atmospheric Monitoring for High-Energy Astroparticle Detectors (AtmoHEAD) Conference, Saclay (France), June 10 - 12, 201...|$|R
50|$|While {{studying}} {{sociology at}} Penn State, Gilden saw Michelangelo Antonioni's film Blowup in 1968. Influenced by the film, he purchased his first camera and began taking night classes in photography at the School of Visual Arts of New York. Fascinated with {{people on the}} street and the idea of visual spontaneity, Gilden turned to a career in photography. His work is characterized by his use of flash photography. He has worked in black and white most of his life, but he began shooting in color and digital when he was introduced to the Leica <b>S</b> <b>camera</b> as part of Magnum’s Postcards From America project. Gilden {{has been a member of}} Magnum Photos since 1998.|$|R
40|$|The imaging of {{electric}} fields on the nanometer scale {{is of great}} interest for modern materials research. Techniques providing a fast, direct and precise measurement of local fields are thus useful for materials science applications. We present microscopic measurements {{of electric}} fields with the 4 D-STEM technique using the pnCCD (<b>S)</b> TEM <b>camera.</b> In 4 D-STEM, a 2 D camera image is recorded for each probe position of a 2 D scan area, yielding a 4 D dataset. With this technique, small shifts of the bright field disc (BFD) due to a deflection of the electron beam through electric and magnetic fields in the sample region can be detected. Hence, the magnitude {{and direction of the}} local field at each probe position can be determined. Given the large number of necessary probe positions, this technique requires a fast camera system providing short enough readout times so that instabilities in the microscope and sample drift or radiation damage do not deteriorate the final STEM image. Furthermore, a pixelated detector is required to record and account for the intensity distribution variations caused by interaction of the electron beam with the sample. The pnCCD (<b>S)</b> TEM <b>camera</b> allows fast acquisition of 2 D camera images with a direct detecting, radiation hard pnCCD with 264 × 264 pixels [1]. Routinely, the readout speed is 1000 frames per second (fps) and can be further increased through binning and windowing. For example, with the pnCCD (<b>S)</b> TEM <b>camera</b> a 256 x 256 STEM image – where a camera image is recorded at each probe position – can be recorded in less than 70 s. The 264 x 264 pixel camera image allows precise determination of the BFD position, yielding information about electric and magnetic fields in the sample. For data analysis, image subsets can be selected freely to obtain virtual diffraction images or perform differential phase contrast (DPC) analysis. A major advantage over conventional segmented DPC detectors is that, with the pnCCD (<b>S)</b> TEM <b>camera,</b> movements of the BFD can be discriminated from intensity variations inside the BFD which is of particular importance for analysis of electromagnetic fields inside specimens. Further 4 D-STEM applications benefitting from the pnCCD (<b>S)</b> TEM <b>camera</b> include imaging on the micro- and millisecond timescale [2], strain analysis [3], magnetic domain mapping [1], and electron ptychography [4]. A demonstration of electric field mapping in vacuum with the pnCCD (<b>S)</b> TEM <b>camera</b> is shown in Figure 1. A voltage of 50 V was applied to a tungsten needle mounted in an FEI Titan G 2 80 - 200 ChemiSTEM microscope, operated at 80 keV. For each of the 256 x 256 probe positions, a 2 D camera image was recorded (Fig. 1 a). From these camera images an incoherent bright field STEM image (Fig. 1 b, background) as well as the position in the x- and y-directions of the BFD at each probe position was calculated. A comparison of the position of the BFD with and without an applied voltage yields information about the magnitude and direction of the local gradient of the projected electrostatic potential (Fig. 1 b, indicated by coloring and arrows). In addition to this direct mapping of the electric field around a needle with rather well-shaped BFDs, the large number of pixels of the pnCCD (<b>S)</b> TEM <b>camera</b> allows the precise determination of the BFD position, even in cases when the BFD is weak and deformed through the interaction of the electron beam with the sample (Fig. 1 c). In conclusion, 4 D-STEM techniques like electromagnetic field mapping benefit significantly from the capabilities of the pnCCD (<b>S)</b> TEM <b>camera.</b> The readout speeds of 1000 fps and above allow the fast acquisition of 4 D datasets with 2 D camera images at each probe position. Through the large number of pixels, position and intensity variations of BFDs can be precisely determined...|$|R
40|$|Reflected {{ultraviolet}} {{imaging techniques}} {{allow for the}} visualization of evidence normally outside the human visible spectrum. Specialized digital cameras possessing extended sensitivity {{can be used for}} recording reflected ultraviolet radiation. Currently, {{there is a lack of}} standardized methods for ultraviolet image recording and processing using digital cameras, potentially limiting the implementation and interpretation. A methodology is presented for processing ultraviolet images based on linear responses and the sensitivity of the respective color channels. The methodology is applied to a FujiS 3 UVIR camera, and a modified Nikon D 70 <b>s</b> <b>camera,</b> to reconstruct their respective spectral sensitivity curves between 320 and 400 nm. This method results in images with low noise and high contrast, suitable for qualitative and/or quantitative analysis. The application of this methodology is demonstrated in the recording of latent fingerprints...|$|R
50|$|This was the Nikon S, {{long overdue}} when made {{available}} early in 1951; it is a Nikon M with flash sync contacts, two sockets {{at the upper}} left-hand edge of the body. All cameras sold with this feature are considered a Nikon S by the factory, even if marked M. Despite its shortcomings, the Nikon S sold well, {{and became the first}} Nikon on the US market. By chance, a number of Nikon <b>S</b> <b>cameras</b> have one more serial number digit, known as the 8-digit Nikon S. When reaching 6099999 the engraver continued at 60910000, but it was soon realized that the long serial number was impractical, and after some 1200 cameras, the numbering reverted to 6100000. The 609 prefix in the serial number refers to the date the design was approved in September 1946.|$|R
40|$|In {{this paper}} we present an {{interface}} {{system for the}} control of mobile devices based on motion and using existing camera technology. In this system the user can control the phone 2 ̆ 7 s functions by performing a series of motions with the camera and each command is defined by a unique series of these motions. A sequence of motion features is produced using the phone 2 ̆ 7 <b>s</b> <b>camera</b> and these characterise the translation motion of the phone. These sequences of motion features are classified using _Hidden Markov Models_ (HMMs). In order to improve the robustness of the system {{the results of this}} classification are then filtered using a likelihood ratio and the entropy of the sequence to reject possibly incorrect sequences. When tested on 570 previously unseen motion sequences the system incorrectly classified only 5 sequences...|$|R
40|$|Monitoring an individual’s daily {{dietary intake}} can provide various {{insights}} regarding {{the health of}} the individual. Applications such as My Fitness Pal exists, which allows individuals to monitor all items that the individual consumed. However, manual monitoring can be labour intensive. To overcome this limitation, wrist worn sensor based eating habit monitoring has been studied by various researchers. These systems can detect eating gesture, but they cannot determine what is being eaten. We have built a system which can (i) detect eating gesture using the smartwatch 2 ̆ 7 s inertial sensors (ii) use the smartwatch 2 ̆ 7 <b>s</b> <b>camera</b> to capture images of food consumed at opportune moment and (iii) present the images to the user at the end of day. Key challenges in building the system are : (i) limited battery (ii) diversity in eating style and (iii) latency in camera triggering...|$|R
40|$|Presented at the 2 nd Web Audio Conference (WAC), April 4 - 6, 2016, Atlanta, Georgia. This {{presentation}} {{was presented as}} part of a lightning talks session on April 4, 2016. Timestamp: 00 : 37 - 02 : 36. In moving towards the development of a technical standard for streaming 360 degree audio-visual media and using the Ricoh Theta SDK as a development platform, the author will present a demonstration of a browser-based iOS application using a live, streaming monaural audio signal paired with 360 degree video, with both signals being generated by the Ricoh Theta <b>S</b> <b>camera.</b> The audio signal is intended to be spatialized in 3 dimensions using the BinauralFIR node developed for the Web Audio API by Arnau Juliá Collados in his degree’s thesis Design of a binaural synthesis processor in the browser using Web Audio API (with supervision by T. Carpentier, S. Goldszmidt and F. Vallverdu) ...|$|R
40|$|As recent {{technology}} {{has become more}} heavily integrated into research opportunities, researchers {{have taken advantage of}} computer processing to produce results for modern, innovative methods that were previously unfeasible. One research project, led by Research Officer Dr. Robert Gagnon of the National Research Council 2 ̆ 019 s Institute for Ocean Technology (NRC-IOT), makes use of image analysis to automatically produce results from the novel remote foggy icing sensor that his team has created. Images acquired by the sensor 2 ̆ 019 <b>s</b> <b>camera</b> system are given directly to a program which can analyze how much ice is present on the structure in the captured images. The program created for the purpose of extracting this raw data is written in Python, an efficient programming language which enables rapid development and robust techniques for dealing with potential errors that may occur. Peer reviewed: NoNRC publication: Ye...|$|R
40|$|We {{explore the}} use of gesture {{recognition}} on a wrist-worn smartwatch as an enabler of an automated eating activity (and diet monitoring) system. We show, using small-scale user studies, {{how it is possible}} to use the accelerometer and gyroscope data from a smartwatch to accurately separate eating episodes from similar non-eating activities, and to additionally identify the mode of eating (i. e., using a spoon, bare hands or chopsticks). Additionally, we investigate the likelihood of automatically triggering the smartwatch 2 ̆ 7 <b>s</b> <b>camera</b> to capture clear images of the food being consumed, for possible offline analysis to identify what (and how much) the user is eating. Our results show both the promise and challenges of this vision: while opportune moments for capturing such useful images almost always exist in an eating episode, significant further work is needed to both (a) correctly identify the appropriate instant when the camera should be triggered and (b) reliably identify the type of food via automated analyses of such images...|$|R
40|$|The {{potential}} of the night pictures taken from the International Space Station (ISS) with a Nikon D 3 <b>s</b> digital <b>camera</b> to fight against light pollution is shown. A scientific analysis of ISS 026 -E- 26493 RAW image of Madrid at night with techniques used by astronomers and cartographers is performed. We suggest an observational setup to obtain useful scientific information from the pictures including series of exposures and calibration frames...|$|R
40|$|The {{potential}} of {{the pictures of the}} Earth taken at night from the International Space Station (ISS) with a Nikon D 3 <b>s</b> digital <b>camera</b> to fight against light pollution is shown. We show that RAW pictures should be used to obtain fluxes. We have developed a method to perform absolute photometric calibration measuring fluxes of the stars recorded in the pictures and also calibrated sources at earth...|$|R
30|$|The gold {{surfaces}} {{with thin}} mica flakes on it were then characterized by optical reflection microscopy using an AxioImager A 1 m (Zeiss, Oberkochen, Germany) mounted with an AxioCam ERc 5 <b>s</b> <b>camera.</b> Moreover, conductive {{atomic force microscopy}} (C-AFM) images were taken with a commercial AFM (Nanotec Electronica, S.L., Madrid, Spain) with a custom-made current amplifier[9]. C-AFM measurements simultaneously provide conductivity and topography of the mica flakes. This enabled us first to distinguish mica flakes from gold by measuring the insulating behavior of the mica as opposed to conductive gold and then to precisely measure {{the thickness of the}} flakes from topography. We used doped diamond AFM tips (CDT-FMR, Nanosensors, Neuchatel, Switzerland; spring constant of 2.1  N/m). All C-AFM measurements were done in contact mode with 100  mV applied at room temperature with approximately 0 % relative humidity controlled by dry N 2 (g) flow. A resistance of approximately 100 MΩ was connected in series with the substrate to limit the current. Image processing was performed with WSxM software (Nanotec Electronica)[10].|$|R
50|$|Richard {{has worked}} closely with Leica since 2012 as a Leica brand Ambassador for the Leica <b>S</b> System of <b>cameras</b> and lenses, and his work using this {{equipment}} has featured as a backdrop at their Burlington Arcade store in London.|$|R
40|$|Coastal vegetation, land use, current circulation, water turbidity, {{and ocean}} waste {{dispersion}} were studied by interpreting ERTS- 1 and Skylab imagery {{with the help}} of ground truth collected during overpasses. Based on high-contrast targets such as piers and roads, the ERTS- 1 multispectral scanner was found to have a resolution of 70 - 100 m, Skylab's <b>S</b> 190 A <b>cameras</b> about 20 - 40 m, and its <b>S</b> 190 B <b>camera</b> about 10 - 20 m. Important coastal land-use details can be more readily mapped using Skylab's imagery. On the other hand, the regular 18 -day cycle of ERTS- 1 allows observation of important man-made and natural changes, and facilitates collection of ground truth...|$|R
40|$|The {{author has}} {{identified}} the following significant results. Attempts to correlate optical aircraft remote sensing of water quality with the optical {{data from the}} ERTS- 1 satellite using calibrated imagery of Charlotte Amalie harbor, St. Thomas, Virgin Islands are reported. The harbor at Charlotte Amalie has a concentration {{of a number of}} factors affecting water quality: untreated sewage, land runoff, and sediment from navigation and dredging operations. Calibration procedures have been originated and applied to ERTS- 1 and I 2 <b>S</b> <b>camera</b> imagery. The results indicate that the ERTS- 1 and I 2 S imagery are correlated with optical in situ measurements of the harbor water. The aircraft green photographic and ERTS- 1 MSS- 4 bands have been found most suitable for monitoring the scattered light levels under the conditions of the investigation. The chemical parameters of the harbor water were found to be correlated to the optical properties for two stations investigated in detail. The biological properties of the harbor water (chlorophyll and carotenoids), correlate inversely with the optical data near the pollution sources compared to further away. Calibration procedures developed in this investigation were essential to the interpretation of the photographic and ERTS- 1 photometric responses...|$|R
30|$|The {{collection}} was visually examined and digitally documented before sampling. For digitization and morphological measurements, a light table, rulers, digital calliper and a Nikon-D 300 <b>s</b> DSLR <b>camera</b> were used. All measurements, observations and images were recorded per catalogue number (Arabic paper—AP) thus building a reference database. All samples {{were given a}} unique ID, consisting of “AP” followed by an incremental number. Sheets from the same bound volume were considered as sub-samples e.g. AP 1 - 1 and AP 1 - 2.|$|R
40|$|Scanning {{electron}} diffraction (SED), {{performed in}} a (S) TEM, is a powerful technique combining information in reciprocal space and real space to achieve nanoscale crystal cartography of materials structure. SED involves scanning a focused electron beam across a specimen and recording an electron diffraction pattern at each position to yield a 4 D dataset comprising a 2 D diffraction pattern at every position in the 2 D scan region. Obtaining high quality data depends on fast acquisition, large dynamic range, and accurate recording of the location and intensity of diffraction spots. Here, we present SED measurements using the pnCCD (<b>S)</b> TEM <b>camera</b> taking a Ti-Fe-Mo alloy for demonstration. The large number of pixels and high readout speed of this camera enables the recording of high quality diffraction patterns in a short acquisition time. Further, using the various camera operation modes, position and intensity of diffraction spots can be determined precisely. The pnCCD (<b>S)</b> TEM <b>camera</b> provides fast acquisition of 2 D camera images using a direct detecting, radiation hard pnCCD with 264 x 264 pixels [1]. Routinely, the readout speed is 1000 frames per second (fps) and can be further increased by binning and windowing. For example, with the pnCCD (<b>S)</b> TEM <b>camera,</b> a 256 x 256 STEM dataset [...] where a camera image is recorded {{at each of the}} 65 536 probe positions [...] can be recorded in less than 70 <b>s.</b> The <b>camera</b> properties can be changed by modifying the voltages applied to the pnCCD and thus adjusted to the experimental needs [2]. Considering scanning electron diffraction experiments, which are performed at high electron beam intensities, the combination of data recorded in two different camera operation modes allows a comprehensive diffraction pattern analysis with quantitative and spatial information. In the high-charge-handling-capacity (HCHC) mode, up to 16 000 incident electrons per pixel per second can be processed for a primary electron energy of 80 keV and a readout speed of 1000 fps. In the case of higher electron rates where the amount of signal exceeds the charge handling capacity of the affected detector pixels, signal spills over into neighboring pixels. Although diffraction spots broaden, the quantitative information is preserved. In the anti-blooming (AB) mode, the amount of signal exceeding the charge handling capacity is drained from the detector preventing an overflowing of pixels. Thus, the spatial information is preserved. The data can be analysed {{in a number of ways}} [3], most simply by plotting the intensity of a subset of pixels as a function of probe position in flexible post-experiment schemes to obtain ‘virtual diffraction images’ or to perform differential phase contrast analysis. Results are shown (Figure 1) from a Ti(40 at. %) -Fe(20 at. %) -Mo(40 at. %) alloy from which SED data was acquired in an FEI Titan G 2 80 - 200 ChemiSTEM microscope, operated at 200 keV. A diffraction pattern was recorded for each of the 512 x 512 probe positions using both HCHC and AB modes of the pnCCD (<b>S)</b> TEM <b>camera</b> at a readout speed of 1000 fps. Each dataset was thus acquired with a total acquisition time of less than 5 minutes per STEM dataset. Virtual diffraction images using the AB-mode data were then formed to discriminate the two phases existing in an ultra-fine lamellar microstructure [4] in this Ti-Fe-Mo alloy...|$|R
40|$|International audienceThe High Energy Stereoscopic System (H. E. S. S.) is {{an array}} of five imaging {{atmospheric}} Cherenkov telescopes (IACT) located in Namibia. In order to assure the continuous operation of H. E. S. S. at its full sensitivity until and possibly beyond the advent of CTA, the older cameras, installed in 2003, are currently undergoing an extensive upgrade. Its goals are reducing the system failure rate, reducing the dead time and improving the overall performance of the array. All camera components have been upgraded, except the mechanical structure and the photo-multiplier tubes (PMTs). Novel technical solutions have been introduced: the upgraded readout electronics {{is based on the}} NECTAr analog memory chip; the control of the hardware is carried out by an FPGA coupled to an embedded ARM computer; the control software was re-written from scratch and it is based on modern C++ open source libraries. These hardware and software solutions offer very good performance, robustness and flexibility. The first camera was fielded in July 2015 and has been successfully commissioned; the rest is scheduled to be upgraded in September 2016. The present contribution describes the design, the testing and the performance of the new H. E. <b>S.</b> <b>S.</b> <b>camera</b> and its components...|$|R
40|$|Abstract This paper {{discusses}} a super-resolution (SR) system implemented on {{a mobile}} device. We utilized an Android device 2 ̆ 019 <b>s</b> <b>camera</b> to take successive shots and applied a classical multiple-image super-resolution (SR) technique that utilized {{a set of}} low-resolution (LR) images. Images taken from the mobile device are subjected to our proposed filtering scheme wherein images that have noticeable presence of blur are discarded to avoid outliers from affecting the produced high-resolution (HR) image. The remaining subset of images are subjected to non-local means denoising, then feature-matched against the first reference LR image. Successive images are then aligned {{with respect to the}} first image via affine and perspective warping transformations. The LR images are then upsampled using bicubic interpolation. An L 2 -norm minimization approach, which is essentially taking the pixel-wise mean of the aligned images, is performed to produce the final HR image. Our study shows that our proposed method performs better than the bicubic interpolation, which makes its implementation in a mobile device quite feasible. We have also proven in our experiments that there are substantial differences from images captured using burst mode that can be utilized by an SR algorithm to create an HR image...|$|R
40|$|The {{most common}} {{navigation}} aid visually-impaired people employ {{is a white}} cane, but, recently, technology {{has given rise to}} a varied set of sophisticated navigation aids. While these new aids can provide more assistance to a visually-impaired person than a white cane, they tend to be expensive due to a small market segment, which in turn can reduce their accessibility. In an effort to produce a technologically-advanced yet accessible navigation aid, an Android application is proposed that detects and notifies users about obstacles within their path {{through the use of a}} smartphone 2 ̆ 7 <b>s</b> <b>camera.</b> While the smartphone is mounted on a harness worn by the user, the Walking Assistant application operates by capturing images as the user walks, finding features of objects within each frame, and determining how the features have moved from image to image. If it is discovered that an object is moving towards the user, the Walking Assistant will activate the smartphone 2 ̆ 7 s vibration mode to alert the user to the object 2 ̆ 7 s presence. Additionally, the user can control the Walking Assistant through the use of either touch or voice commands. By conducting real-world tests, it was determined that the Walking Assistant can correctly identify obstacles 42. 1...|$|R
30|$|For TRPL measurements, {{the sample}} is excited by a frequency-doubled Ti/sapphire laser at the {{wavelength}} of 405 nm. The repetition rate is 80 MHz. The PL signal is analyzed by an <b>S</b> 20 streak <b>camera,</b> and measurements are performed at 10 K to overcome non-radiative recombinations channels.|$|R
50|$|A Swiss filmmaker (<b>S.)</b> and his <b>camera</b> {{team are}} working on a {{documentary}} film project in New York. They research the theme of loneliness. 12 million people live in New York City, 7,5 million of them are singles, living alone. An impressive background for the project.|$|R
40|$|Today 2 ̆ 7 <b>s</b> digital <b>cameras</b> {{and camera}} phones allow users to capture bar codes, {{which are used}} to uniquely {{identify}} consumer product. In this paper a fast algorithm is proposed that locates a 1 -D bar code in the DCT-domain of a bar code image taken by a digital camera. The algorithm uses the DCT-transform properties to distinguish bar code from other texture, morphological operations to smooth the detected bar code area and {{the features of the}} extracted area lo detect position and orientation of a bar code in the imag...|$|R
