0|724|Public
40|$|As nations {{engage in}} the {{long-term}} process of negotiating a protocol on controlling greenhouse gas emissions, the danger of costly mistakes looms large, both from doing too little or too much. Researchers try to provide insight and guidance on this difficult problem, many relying on the tools of mathematical simulation models, but <b>two</b> important <b>shortcomings</b> <b>remain</b> {{in much of the}} current analysis. One is the treatment of the uncertainty inherent in projections of economic activity over the next century or more; and the other is the way economic activity is modeled to impact the poorly understood physical and biological systems of the earth. This paper presents several simple illustrations of the performance of current policy proposals {{in the face of a}} long-term climate-based goal when uncertainties in economic growth and technology development are made explicit. Several conclusions emerge. Analyses that rely on deterministic emissions paths through time obscure the underlying uncertaint [...] ...|$|R
40|$|Empirical thesis. Bibliography: pages 65 - 68. 1. Introduction [...] 2. Background to {{survival}} analysis [...] 3. Literature review [...] 4. Maximum likelihood estimation for Cox model with time-varying covariates [...] 5. Results [...] 6. Conclusion and discussion [...] 7. Appendix [...] Supplementary material [...] References. Credit granting institutions need {{to estimate the}} probability of default, the chance a customer fails to make repayments as promised (BIS (2006) and IASB (2014)). The Cox model with time-varying covariates (Cox (1972), Crowley and Hu (1977)) is a technique often applied due to its substantial benefits beyond classification approaches (such as logistic regression) whilst achieving similar accuracy (Lessmann et al. (2015), Bellotti and Crook(2009)). However partial likelihood estimation of this model has <b>two</b> <b>shortcomings</b> that <b>remain</b> unaddressed in the literature: (1) the baseline hazard is not estimated, so calculating probabilities requires a further estimation step; and (2) a covariance matrix for both regression parameters and the baseline hazard is not produced. We address these by developing a maximum likelihood method that jointly estimates regression coefficients and the baseline hazard using constrained optimisation that ensures the baseline hazard’s non-negativity. We show in a simulation our technique is more accurate in moderate sized samples and when applied to real home loan data it produces a smoother estimate of the baseline hazard than the Breslow (1972) estimator. Our model {{could be used to}} predict life-time probability of default, required under the International Financial Reporting Standard (IFRS) 9 accounting standard. Mode of access: World wide web 1 online resource ([vii], 68 pages...|$|R
5000|$|The SMF 120.9 was {{provided}} to address <b>two</b> <b>shortcomings</b> in the previous SMF design for WAS z/OS: ...|$|R
50|$|The Crown Prince has talent {{given by}} Heaven, and is {{complete}} in his eight virtues. However, he has <b>two</b> <b>shortcomings</b> {{that he needs}} to self-examine: his overindulgence in hunting and music. Both of these have harm for the state.|$|R
40|$|On September 29, 2010, the European Commission {{announced}} {{a set of}} legislative proposals to improve economic governance in the European Union. The package is wide-ranging and consists of six proposals, four of which deal with fiscal questions and two with broader macroeconomic balance issues. While <b>shortcomings</b> <b>remain,</b> the proposed measures, if implemented, will improve the management of economic policy in the European Union. In turn, better economic policy will promote the smooth functioning of the European economy...|$|R
40|$|Traditional {{consensus}} surveys among economists seem {{to suffer}} from <b>two</b> <b>shortcomings.</b> First, they target the consensus issue {{in a way that}} tends to underestimate the agreement among economists, and second, they fail to offer information about how much economists'transfer of knowledge, economic policy, consensus survey...|$|R
30|$|This work {{explored}} {{a concept}} still little studied and, thus, some <b>shortcomings</b> <b>remain</b> to be addressed. The {{dynamics of the}} social network is one of them. We worked with a fixed time window to the social network modeling. However, slicing the time interval probably would improve the prediction models by capturing the transient characteristics over time in the social structures. Another improvement could be achieved by grouping the extracted terms by topics, which can be more relevant than analyzing each term alone.|$|R
40|$|The work {{reported}} in this paper {{is part of a}} project financed by the Centre for Planning and Economic Research (KEPE), Athens. We should like to thank KEPE's Scientific Director, Louka Katseli, for her help and encouragement and the staff of KEPE for their help with the data. We should like to thank D. Karantinos for the insights he provided on the Greek labour market. Finally we should like to thank Neils Westergaard-Nielsen for his comments. All errors and <b>shortcomings</b> <b>remain</b> our responsibility...|$|R
50|$|Finished Dufaycolor films {{suffer from}} the <b>two</b> <b>shortcomings</b> {{inherent}} in all mosaic colour screen processes: the réseau absorbs most of the viewing or projection light, requiring {{the use of an}} unusually bright light for normal image brightness, and if too greatly magnified, the individual colour filter elements become disruptively visible.|$|R
40|$|Virtual environments (VE) {{are gaining}} in {{popularity}} and are increasingly used for teamwork training purposes, e. g., for medical teams. We have identified <b>two</b> <b>shortcomings</b> of modern VEs: First, nonverbal communication channels {{are essential for}} teamwork but are not supported well. Second, view control in VEs is usually done manually, requiring the user to learn the controls before being able to effectively use them. We address those <b>two</b> <b>shortcomings</b> by using an inexpensive webcam to track the user’s head. The rotational movement is used to control the head movement of the user’s avatar, thereby conveying head gestures and adding a nonverbal communication channel. The translational movement is used to control {{the view of the}} VE in an intuitive way. Our paper presents the results of a user study designed to investigate how well users were able to use our system’s advantages...|$|R
500|$|In the {{build-up}} to the , Alonso {{noted that}} although addressing the power unit's <b>shortcomings</b> <b>remained</b> the team's biggest challenge, he {{was unhappy with}} some of their trackside operations, citing a lack of running in Friday practice sessions, under-preparedness in starting procedures and pit stops, and unreliability of other parts—such as the gearbox—as compounding {{the problems with the}} engine. After being powerless to defend against repeated overtakes during the race, Alonso was overheard condemning the RA615H as [...] "embarrassing" [...] and a [...] "GP2 engine" [...] over the radio.|$|R
30|$|However, certain <b>shortcomings</b> <b>remain</b> in our work. If the {{correlation}} relationship among wind power sequences is weak, the prediction results obtained using this method are usually poor. In the prediction, we only consider {{the correlation}} {{relationship between the}} wind power in the adjacent time periods but ignore the correlation relationship between the wind power sequence and influencing factors such as meteorology and unit maintenance. Therefore, in future work, we will further study the copula function wind power interval prediction based on the combination of meteorological factors and wind power.|$|R
40|$|This thesis {{conducts a}} {{comparative}} {{analysis of the}} labour market policies of the Czech Republic and Kyrgyzstan. Through the comparative analysis advantages and shortcomings of labour market polices are revealed. It further examines the role and effectiveness of various instruments or institutional patterns used by the government, such as employment services, action plans and finance of employment policies over the years. The research findings show that in most regards, the Czech Republic has more effective labour policies. However, <b>shortcomings</b> <b>remain</b> in both Czech Republic and Kyrgyzstan. Powered by TCPDF (www. tcpdf. org...|$|R
5000|$|In the {{build-up}} to the , Alonso {{noted that}} although addressing the power unit's <b>shortcomings</b> <b>remained</b> the team's biggest challenge, he {{was unhappy with}} some of their trackside operations, citing a lack of running in Friday practice sessions, under-preparedness in starting procedures and pit stops, and unreliability of other parts—such as the gearbox—as compounding {{the problems with the}} engine. After being powerless to defend against repeated overtakes during the race, Alonso was overheard condemning the RA615H as [...] "embarrassing" [...] and a [...] "GP2 engine" [...] over the radio.|$|R
30|$|Except for IIA {{property}} restrictions, MNL {{model has}} <b>two</b> <b>shortcomings</b> in application. One is its incapability of handling with random preference discrepancies, {{the other is}} its incapability of finding out the correlative factors with panel data. Two merits of MNL are {{that it has a}} close-formed structure, and its parameters can be easily estimated.|$|R
5000|$|Besides, <b>two</b> <b>shortcomings</b> are (1) {{complexity}} of the FMEA worksheet (2) intricacy of its use. Entries in a FMEA worksheet are voluminous. The FMEA worksheet is hard to produce, hard to understand and read, as well as hard to maintain. The use of neural network techniques to cluster and visualise failure modes were suggested, recently.|$|R
30|$|The 7 -element feature {{descriptor}} is invariant to rotation, translation, and scale, {{making it}} a good candidate to overcome the <b>two</b> <b>shortcomings</b> of Harris detector, that is, corner point displacement and variant to rotation. It {{is calculated based on}} the texture-based statistical descriptor moment. For a detailed definition and calculation of the invariant moments, please refer to [19].|$|R
5000|$|All {{subsequent}} works {{dealing with}} Boccherini have merely reproduced, borrowed or translated this fundamental work, which, despite certain <b>shortcomings,</b> must <b>remain</b> {{the starting point}} of any study by the Italian composer.|$|R
30|$|We {{identify}} <b>two</b> <b>shortcomings</b> {{in service}} selection approaches in the literature. They {{reduce the number}} of comparisons by either using heuristic algorithms or indexing the search space. However, they do not accommodate the customers’ preferences in the decision making. Furthermore, all approaches handle every application deployment as a new case without taking into account the results of similar previous deployments.|$|R
30|$|Muler, Peña and Yohai (2009, p. 817) note <b>two</b> <b>shortcomings</b> of the {{estimates}} obtained in this way. They write: ‘First, these estimates are asymptotically biased. Second, {{there is not}} an asymptotic theory for these estimators, and therefore inference procedures like tests or confidence regions are not available.’ They then suggest a different approach and show that it allows an asymptotic theory to be developed.|$|R
40|$|ArticleHas {{immigration}} been securitised at the EU level? The {{question has}} been hotly discussed, but no consensus has been reached. This article claims that <b>two</b> <b>shortcomings</b> – one methodological, one theoretical – in the empirical conduct of securitisation theory (ST) have provoked this lack of consensus. Taking this situation as an opportunity, a quantitative method is introduced that addresses these <b>two</b> <b>shortcomings,</b> thereby helping to reach a stronger claim on the securitisation of immigration at the EU level. By measuring {{the intensity of the}} security framing in EU legislation on immigration, the method helps avoid simplistic binary statements of (non-) securitisation and encourages the scholar to acknowledge the complex, multifaceted reality of vast political fields. The results contribute to accrediting the thesis according to which immigration has been securitised at the EU level, but nuances it by demonstrating a significant variation between the various subfields of the policy (e. g. asylum, legal immigration) ...|$|R
40|$|A rules-based fiscal framework, {{such as the}} EU’s Stability and Growth Pact (SGP), can be an {{important}} bulwark against short-sighted policies. Although policies have improved following the SGP’s adoption, <b>shortcomings</b> <b>remain.</b> These, however, are rooted in the policies rather than the rules, where few changes seem necessary. Specifically, the Excessive Deficit Procedure needs a stronger focus on policies rather than outcomes, while staying operationally simple and transparent. Furthermore, reforms are needed to foster time-consistent national policies, budgetary transparency, and ownership of the Pact. Accordingly, parliaments should debate national Stability Programs and national fiscal councils should review these programs for parliaments. ...|$|R
40|$|This article {{examines}} how the Republic of Cyprus has confronted {{the threat of}} international terrorism. Although {{the threat of terrorism}} in Cyprus remains relatively low, the Cypriot authorities have nevertheless sought to minimize the risk and maximize the level of preparedness. This has involved taking an uncompromising attitude toward those suspected of involvement with terrorist groups. At the same time, there has been a marked increase in the amount of international co-operation, especially since EU accession, in 2004. Nevertheless, <b>shortcomings</b> <b>remain,</b> particularly in terms of the legislative framework and the development of an analytical counterterrorism capability...|$|R
30|$|To tackle this {{drawback}} {{some research}} studies are being carried out. However, as {{mentioned in the}} introduction, the first one [15] significantly increases the RX complexity, while the second one [16] fails to reach the objective of theoretical maximum spectral efficiency, that is, does not satisfy condition (ii). The one we propose hereafter {{is based on a}} combination of CDMA with OFDM/OQAM and avoids these <b>two</b> <b>shortcomings.</b>|$|R
40|$|Abstract — The {{design and}} {{optimization}} of rateless codes for Slepian-Wolf encoding are considered. Rateless codes are proposed to address <b>two</b> <b>shortcomings</b> of currently available Slepian-Wolf schemes: their fragility to changing source statistics, and {{their inability to}} guarantee successful decoding for practical block length. We propose a novel type of optimized rateless code, called a Matrioshka code, {{to deal with the}} particular conditions of Slepian-Wolf encoding. I...|$|R
50|$|Critics {{point out}} <b>two</b> <b>shortcomings</b> of Steinberg and Kincheloe's work: the (mostly) {{homogenous}} make-up of the collection's contributors and its bias toward {{an audience of}} teachers and parents of middle-class children. While many of the essays address the role race, class and gender play {{in the construction of}} kinderculture, they do not focus on how children of color/less-privileged children fit into this scheme of corporation consumption.|$|R
40|$|Abstract—The {{design and}} {{optimization}} of rateless codes for Slepian-Wolf encoding are considered. Rateless codes are pro-posed to address <b>two</b> <b>shortcomings</b> of currently available Slepian-Wolf schemes: their fragility to changing source statistics, and {{their inability to}} guarantee successful decoding for practical block length. We propose a novel type of optimized rateless code, called a Matrioshka code, {{to deal with the}} particular conditions of Slepian-Wolf encoding. I...|$|R
40|$|In {{simulation}} studies Latent Factor Prediction Pursuit outperformed classical reduced rank regression methods. The algorithm described so far for Latent Factor Prediction Pursuit had <b>two</b> <b>shortcomings.</b> It {{was only}} implemented for {{situations where the}} explanatory variables were of full colum rank. Also instead of the projection matrix only the regression matrix was calculated. These problems are addressed by a new algorithm which finds the prediction optimal projection...|$|R
40|$|Acute {{otitis media}} and otitis media with {{effusion}} are common childhood disorders, {{a source of}} significant morbidity, and {{a leading cause of}} antibiotic prescription in primary health care. Although effective treatments are available, some <b>shortcomings</b> <b>remain,</b> and thus better treatments would be welcome. Recent discoveries within the field of otitis media research relating to its etiology and pathogenesis have led to further investigation aimed at developing novel treatments. This article provides a review of the latest evidence relating to the understanding of acute otitis media and otitis media with effusion, current treatment strategies, their limitations, new areas of research, and novel strategies for treatment...|$|R
40|$|Venereal disease {{research}} laboratory (VDRL) test is a nontreponemal test, used for screening of syphilis {{due to its}} simplicity, sensitivity and low cost. Prozone phenomenon and biological false positive (BFP) reaction are <b>two</b> <b>shortcomings</b> of this test. Quantitative estimation of VDRL is essential in treatment evaluation. CSF VDRL test is very specific for neurosyphilis though its sensitivity is low. Interpretation of VDRL in HIV infection is incompletely understood...|$|R
40|$|The study {{proposed}} a stochastic method of container logistic transport {{in order to}} solve the unreasonable transportation’s problem and overcome the traditional models’ <b>two</b> <b>shortcomings.</b> Container transport has rapidly developed into a modern means of transportation because of their significant advantages. With the development, it also exacerbated the flaws of transport in the original. One {{of the most important}} problems was that the invalid transport had not still reduced due to the congenital imbalances of transportation. Container transport exacerbated the invalid transport for the empty containers. To solve the problem, people made many efforts, but they did not make much progress. There had two theoretical flaws by analyzing the previous management methods in container transport. The first one was the default empty containers inevitability. The second one was that they did not overall consider how {{to solve the problem of}} empty containers allocation. In order to solve the unreasonable transportation’s problem and overcome the traditional models’ <b>two</b> <b>shortcomings,</b> the study re-built the container transport planning model-gravity model. It gave the general algorithm and has analyzed the final result of model...|$|R
30|$|However, the {{dimension}} of instances is low {{and the number of}} slave computers in the numerical experiment is only three. The potential ability of this method has not been fully expressed. In the next step, these <b>two</b> <b>shortcomings</b> will be settled. With large number of slave computers, one can be confident to believe that the numerical results will be more better. Additionally, the distributed method is easy to be extended to solving other problems.|$|R
50|$|Blade element {{momentum}} (BEM) theory alone {{fails to}} represent accurately the true physics of real wind turbines. <b>Two</b> major <b>shortcomings</b> are {{the effects of}} a discrete number of blades and far field effects when the turbine is heavily loaded. Secondary shortcomings originate from having to deal with transient effects like dynamic stall, rotational effects like the Coriolis force and centrifugal pumping, and geometric effects that arise from coned and yawed rotors. The current state of the art in BEM uses corrections to deal with these major shortcomings. These corrections are discussed below. There is as yet no accepted treatment for the secondary <b>shortcomings.</b> These areas <b>remain</b> a highly active area of research in wind turbine aerodynamics.|$|R
40|$|Micro-level {{analyses}} of the farm sector may be conducted at intra-household, household or village levels. Most economists have preferred {{to work at the}} household level because of the existence of a well-developed farm-household theory. Empirical studies at the micro level have mostly used econometric or mathematical programming approaches. For both, but especially the former, the strong assumption of separability of production and consumption decisions is usually crucial. While the number and sophistication of empirical studies continue to grow, operational <b>shortcomings</b> <b>remain</b> severe. The limited use in policy making of many analyses is noted and the merits of combining comprehensive formal models with less formal and relatively simple approaches are canvassed. Community/Rural/Urban Development,...|$|R
5000|$|In {{order to}} address the problem of {{nutrient}} supplementation on a community-wide level, the INP helped establish the short-term program [...] "Nutrition Supplementation Program" [...] (previously known as the PEM Scheme). This program has been fairly effective because of the well-trained nutritionists that assist it. However, various <b>shortcomings</b> <b>remain.</b> The program has struggled with community based interventions and with properly reaching out to and enrolling all malnourished children without misusing resources on children that are not truly malnourished. If the Child Support Grant was extended to apply to all families of malnourished children, all at risk children could be reached and enrolled at hospitals, clinics, and other places that participate in growth monitoring.|$|R
40|$|Ultimately, {{scientific}} numerical models need quantified output uncertainties so that modeling can evolve {{to better}} match reality. Documenting model input uncertainties and verifying that numerical models are translated into code correctly, however, are necessary first steps toward that goal. Without known input parameter uncertainties, model sensitivities are all one can determine, and without code verification, output uncertainties {{are simply not}} reliable. To address these <b>two</b> <b>shortcomings,</b> <b>two</b> proposals are offered: (1) an unobtrusive mechanism to document input parameter uncertainties in situ and (2) an adaptation of the Scientific Method to numerical model development and deployment. Because these two steps require changes in the computational simulation community to bear fruit, they are presented {{in terms of the}} Beckhard-Harris-Gleicher change model...|$|R
