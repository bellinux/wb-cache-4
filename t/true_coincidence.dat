33|44|Public
5000|$|The primary {{difficulty}} {{inherent in}} {{this approach is that}} high-frequency localisation and clarity relies on the diaphragms approaching <b>true</b> <b>coincidence.</b> By stacking the capsules vertically, perfect coincidence for horizontal sources is obtained. However, sound from above or below will theoretically suffer from subtle comb filtering effects in the highest frequencies. In most instances this is not a limitation as sound sources far from the horizontal plane are typically from room reverberation. In addition, stacked figure-8 microphone elements have a deep null in the direction of their stacking axis such that the primary transducer in those directions is the central omnidirectional microphone. In practice this can produce less localisation error than either of the alternatives (tetrahedral arrays with processing, or a fourth microphone for the Z axis.) ...|$|E
40|$|An {{analysis}} algorithm {{to correct}} for the g-ray <b>true</b> <b>coincidence</b> summing effects for radionuclides decay by cascading photons {{was developed and}} implemented in Canberra¿s Genie 2000 software in 2001. It has been extended to correct for <b>true</b> <b>coincidence</b> summing effects from low energy g-rays, KX-rays from electron capturing and internal conversion, and the 511 keV positron annihilation photons. Validation of these extensions shows significant improvement in Genie 2000 ¿s <b>true</b> <b>coincidence</b> summing correction capability and the accuracy of nuclide activity measurement. JRC. E. 8 -Nuclear safeguards and Securit...|$|E
40|$|Aim of {{this work}} is the {{numerical}} calculation of the <b>true</b> <b>coincidence</b> correction factors by means of Monte-Carlo simulation techniques. For this purpose, the Monte Carlo computer code PENELOPE was used and the main program PENMAIN was properly modified in order to include {{the effect of the}} <b>true</b> <b>coincidence</b> phenomenon. The modified main program that takes into consideration the <b>true</b> <b>coincidence</b> phenomenon was used for the full energy peak efficiency determination of an XtRa Ge detector with relative efficiency 104 % and the results obtained for the 1173 keV and 1332 keV photons of 60 Co were found consistent with respective experimental ones. The <b>true</b> <b>coincidence</b> correction factors were calculated as the ratio of the full energy peak efficiencies was determined from the original main program PENMAIN and the modified main program PENMAIN. The developed technique was applied for 57 Co, 88 Y, and 134 Cs and for two source-to-detector geometries. The results obtained were compared with <b>true</b> <b>coincidence</b> correction factors calculated from the "TrueCoinc" program and the relative bias was found to be less than 2 %, 4 %, and 8 % for 57 Co, 88 Y, and 134 Cs, respectively...|$|E
30|$|The {{acquisition}} of a weak signal may be masked by natural radioactivity of 176 Lu in LSO crystals (about 2.59 % of the lutetium element). The background signal generated by 176 Lu {{can contribute to the}} amount of random and <b>true</b> <b>coincidences</b> [26, 30]. For each acquisition, prompt and random coincidence rates were measured. A long acquisition (approximately 900, 000 registered <b>true</b> <b>coincidences)</b> with no activity present in the field of view was performed to determine the 176 Lu background count rate.|$|R
40|$|A {{new type}} of angular {{correlation}} apparatus is described, and a mathematical model of its statistics is given. The angular correlation of coincident nuclear radiations can be measured by detecting intensity correlations in the output of two counters. For prompt coincidences, the detector currents are mixed in a broadband circuit whose output {{is the product of}} the two inputs. The time-average output of the mixer is shown to be proportional to the rate of <b>true</b> <b>coincidences,</b> and therefore to the angular correlation function. Furthermore, the fluctuation of this output has the same ratio to the average current as the rate of random to <b>true</b> <b>coincidences</b> both for weak and strong sources. For delayed coincidences, other circuits give the time spectrum and the frequency spectrum of the perturbed correlation function. Possible applications are mentioned, and the relation to the Brown-Twiss interferometer is clarified...|$|R
30|$|Despite {{promising}} advances, attenuation {{correction of}} PET data remains challenging in PET/MRI. Known approaches to estimating attenuation maps from PET emission data {{take into account}} only <b>true</b> <b>coincidences</b> and fail to completely determine the attenuation map without prior information. Even TOF PET emission data determines the attenuation sinogram up to an unknown constant only. We propose to extract information from scattered PET coincidences to fully determine the attenuation map.|$|R
40|$|The {{choice of}} {{injected}} dose of 18 F-FDG and acquisition time {{is important in}} obtaining consistently high-quality PET images. The {{aim of this study}} was to determine the optimal acquisition protocols based on patient weight for 3 -dimensional lutetium oxyorthosilicate PET/CT. Methods: This study was a retrospective analysis of 76 patients ranging from 29 to 101 kg who were injected with 228 - 395. 2 MBq of 18 F-FDG for PET imaging. The study population was divided into 4 weightbased groups: less than 45 kg (group 1), 45 - 59 kg (group 2), 60 - 74 kg (group 3), and 75 kg or more (group 4). We measured the <b>true</b> <b>coincidence</b> rate, random coincidence rate, noise-equivalent counting rate (NECR), and random fraction and evaluated image quality by the coefficient of variance (COV) in the largest liver slices. Results: The <b>true</b> <b>coincidence</b> rate, random coincidence rate, and NECR significantly increased with increasing injected dose per kilogram (r 5 0. 91, 0. 83, and 0. 90; all P < 0. 01). NECR maximized at 10. 11 MB/kg in underweight patients. The <b>true</b> <b>coincidence</b> rate differed significantly among the 4 groups, except for group 3 versus group 4 (P < 0. 01). The ratio of the <b>true</b> <b>coincidence</b> rate for group 2 to groups 3 and 4 was 1. 4 and 1. 6, respectively. The average random fraction for all 4 groups was approximately 35 %. The COV of the 4 groups differed for all pairs (P < 0. 01). The COVs in overweight patients were larger than those in underweight patients, and image quality in overweight patients was poor. Conclusion: We modified acquisition protocols for 18 F-FDG PET/CT according to the characteristics of a 3 -dimensional lutetium orthosilicate PET scanner and PET image quality based on patient weight. The optimal acquisition time was approximately 1. 4 - 1. 6 times longer in overweight patients than in normal-weight patients. Estimation of optimal acquisition times using the <b>true</b> <b>coincidence</b> rate is more important than other variables in improving PET image quality. © 2011 by the Society of Nuclear Medicine, Inc. Thesis of Nagaki, Akio / 長木 昭男 博士学位論文(金沢大学 / 大学院医薬保健学総合研究科...|$|E
40|$|International audienceA well-type {{detector}} {{installed in}} the Modane underground Laboratory (LSM) can combine both low background and high detection efficiency and it is well suited {{for the analysis of}} small amounts of environmental samples. Reference materials such as IAEA- 447 (moss-soil), IAEA-RG-Th 1 and IAEA-RG-U 1 were used for the detector calibration, owing to a chemical composition close to those of the environmental samples. Nevertheless, the matrix effects and the <b>true</b> <b>coincidence</b> summing effects must be corrected from the full energy peak efficiency (FEPE). The FEPE was performed {{for a wide range of}} energy by a semi-empirical method using Monte Carlo simulation (MCNP 6), intended for environmental measurements such as lake sediments dating. In the well geometry, the <b>true</b> <b>coincidence</b> summing effects could be very important and correction factors have been computed in three different ways...|$|E
40|$|A {{laboratory}} {{exercise for}} calculation of <b>true</b> <b>coincidence</b> summing correction factors {{as well as}} calculating the effect of deviations between sample and standard source (filling height) was developed. This laboratory exercise was held in a masters course in nuclear chemistry the first time during fall 2013. The aim of the exercise was to high-light the importance of correcting for biases due to different systematic effects in gamma spectrometric measurements...|$|E
3000|$|... − pair {{production}} [52, 53]. Nevertheless, {{even with a}} background of singles, randoms, and net trues, LSO and LYSO scanners have been proven to function better than BGO-based scanners because of the time-of-flight capability associated with fast LSO/LYSO scintillators [53]. In general, the extremely small background of net <b>true</b> <b>coincidences</b> is neglected, and no additional correction, apart from standard scatter and random corrections, is performed for 90 Y imaging in the commercial PET scanners.|$|R
30|$|Patient-specific {{dosimetry}} {{is possible}} {{even in a}} scenario with low <b>true</b> <b>coincidences</b> and high random fraction, as in 90 Y–PET imaging, granted that accurate absolute PET calibration is performed and acquisition times are sufficiently long. Despite Monte Carlo calculations seeming to outperform all dose estimation algorithms, our data provide a strong argument for encouraging {{the use of the}} local deposition algorithm for routine 90 Y dosimetry based on PET/CT imaging, due to its simplicity of implementation.|$|R
40|$|In {{this paper}} a method is developed, using higher order statistics, to {{identify}} the type and degree of neutron and gamma ray cross talk between detectors that are placed in proximity to one another. A set of measurements was performed using the Nuclear Materials Identification System (NMIS) to acquire the time-dependent bicovariance of the pulses in fast plastic scintillating detectors. These signatures were analyzed to infer the degree and type of false coincidences (cross talk) in relation to <b>true</b> <b>coincidences...</b>|$|R
40|$|We {{report on}} a new {{measurement}} of ^ 14 N(p,γ) ^ 15 O for the ground state capture transition at E_p = 360, 380 and 400 keV, using the 400 kV LUNA accelerator. The <b>true</b> <b>coincidence</b> summing effect [...] {{the major source of}} error in the ground state capture determination [...] has been significantly reduced by using a Clover [...] type gamma detector. Comment: 6 pages, 5 figures, Accepted for publication in Journal of Physics...|$|E
30|$|Patient-specific {{dosimetry}} in SIRT {{suffers from}} a number of image-degrading effects. Besides PVE, that is likely {{to play a major role}} in small lesions, low <b>true</b> <b>coincidence</b> statistic due to the combined interplay of low beta plus branching ratio and low achievable acquisition time are likely to impact the image quality. Furthermore, the high scatter component intrinsic of 90 Y PET imaging may negatively affect image quantification. Ultimately, patient respiratory motion is the primary cause of image blurring possibly leading to systematic dose underestimations [43].|$|E
40|$|The aim of {{this study}} was to check for {{equivalence}} of computer codes that are capable of performing calculations of <b>true</b> <b>coincidence</b> summing (TCS) correction factors. All calculations were performed for a set of well-defined detector parameters, sample parameters and decay scheme data. The studied geometry was a point source of 133 Ba positioned directly on the detector window of a low-energy (n-type) detector. Good agreement was established between the TCS correction factors computed by the different codes. JRC. G. 2 -Standards for Nuclear Safety, Security and Safeguard...|$|E
40|$|The major accomplishments this year, so far, are (1) {{validation}} of Monte Carlo simulation code with scattered, {{as well as}} <b>true</b> <b>coincidences,</b> {{for a variety of}} scanner geometries, (2) {{validation of}} 3 -D reprojection-reconstruction algorithm and comparisons to 2 -D reconstruction, {{as a function of the}} scanner axial extent, using simulated data, (3) initial development of energy window scatter correction technique for use in volume imaging PET, (4) evaluation of high-countrate calibrations and imaging of {sup 15 }O brain studies with the UGM PENN-PET...|$|R
30|$|NEMA {{sensitivity}} of the GE discovery MI is 13.6 cps/kBq, matching information provided by GE. This sensitivity increases to 246.7 cps/kBq and 171.2 cps/kBq for a TB-PET with pixelated and monolithic crystals respectively. Per voxel inside the lesion, the TB-PET with monolithic crystal truly detected 1895.6 ± 45.3 decays. The conventional system only detects 97.2 ± 9.9 decays. The total number of <b>true</b> <b>coincidences</b> originating from the prostate lesion (indicated in Fig. 3) are 1, 218, 887 and 62, 531 respectively. The TB-PET thus detected almost 20 times more decays originating from the lesion.|$|R
30|$|The {{results of}} this {{research}} are sufficient to conclude, with some caveats, that patient-specific dosimetry is possible even in a scenario with low <b>true</b> <b>coincidences</b> and high random fraction, as in 90 Y PET imaging, granted that accurate absolute PET calibration is performed and acquisition times are sufficiently long. In the final analysis, despite Monte Carlo calculations outperforming all dose estimation algorithms, we believe to have gathered ample evidence to recommend {{the use of the}} LD algorithm for routine 90 Y dosimetry based on PET/CT imaging, due to its simplicity of implementation.|$|R
40|$|The aim of {{the study}} was to check for {{equivalence}} of computer codes that can perform calculations of <b>true</b> <b>coincidence</b> summing correction factors. All calculations were performed for a set of well-defined detector and sample parameters, without any reference to empirical data. For a p-type detector model the application of different codes resulted in satisfactory agreement in the calculated correction factors. For high-efficiency geometries in combination with an n-type detector and a radionuclide emitting abundant X-rays the results were scattered. JRC. D. 4 -Standards for Nuclear Safety, Security and Safeguard...|$|E
40|$|The {{feasibility}} of using certified reference {{materials for the}} full energy efficiency calibration of p-type coaxial high-purity germanium detectors for the determination of radioactivity in environmental samples is discussed. The main sources of uncertainty are studied and the contributions to the total uncertainty budget for the most intense gamma lines are presented. The correction factors due to self-absorption and <b>true</b> <b>coincidence</b> summing effects are discussed in detail. The calibration procedure is validated for natural and artificial radionuclide determination in different matrices through an internal cross-validation and through the participation in a world-wide open proficiency test...|$|E
40|$|The program ROMOS and the {{assisting}} program RECAL are presented. These {{programs were}} designed to facilitate nuclide identification and concentration calculation in NAA using the k 0 -concept. For nuclide identification classical tests (energy match, decay factor) are complemented with {{a test of the}} saturation factor including the sensitivity of neutron acctivation analysis for the candidate nuclide. For nuclides emitting more than one gamma-energy the intensity of the observed peaks in the spectrum are compared. Thereby full account is taken of relative detection efficiency and <b>true</b> <b>coincidence</b> effects. Practical experience in using the interactive code shows that it is a convenient and time-saving working aid for an experienced experimenter...|$|E
30|$|As the SNR is {{proportional}} to the square root of the number of detected counts, there will be an improvement in SNR equal to the square root of the gain factor. Both relationships describe the gain of noise reduction by TOF on <b>true</b> <b>coincidences</b> only. Both scatter and randoms [85] have also the same factor, due to the reduced noise propagation caused by the localized nature of the TOF kernel. The effect of TOF is however more complex. First of all, the good timing resolution reduces significantly the negative effect of randoms on the NEC performance.|$|R
30|$|Of note, average absorbed doses {{determined}} {{with the}} LD method are in excellent agreement with those obtained using the MIRD and the kernel convolution dose calculation approach. This result provides a strong argument for encouraging LD algorithm {{for the evaluation}} of absorbed doses in the clinical practice, where resource–intensive software packages are not always available. Similar conclusions have been drawn in recent research on the matter [26]. However, the large dose variability at the voxel level—most likely due to a scenario with low <b>true</b> <b>coincidences</b> and high random fraction—raises questions about the possibility of using dDVH for radiobiological modeling if acquisitions are performed with a non-TOF scanner.|$|R
40|$|In {{the third}} {{sentence}} under the subheading “Sensitivity and calibration measurements ” of Results, Fig. 1, and the legend for Fig. 1, the abbreviation for kilocounts is incorrect. Please view the corrected Fig. 1 below. The corrected third sentence under the subheading “Sensitivity and calibration measurements” of Results is: “The net <b>true</b> <b>coincidences</b> fall along {{a straight line}} with a slope of (189. 4 ± 1. 5) kcts/GBq, y-intercept of (6. 8 ± 2. 5) kcts and R 2 = 0. 9998. ” The complete, corrected Fig. 1 legend is: “Counting statistics (kcts) for the 30 min acquisition with 2 bed positions for Day 0, 3, 5 and 7 measurement time points during 1 week and an empty phantommeasurement. ...|$|R
30|$|About 14 % of 82 Rb β + decays {{also produce}} a 776.5  keV γ-ray with no angular correlation. This {{results in a}} {{significant}} pollution of the <b>true</b> <b>coincidence</b> emission data, distinct in shape from the scatter component, and must be corrected in view of quantitative cardiac perfusion imaging [27, 30, 31]. Quantitative PET reconstructions were corrected for prompt gamma pollution using a specific correction method provided by the vendor (not yet reported in the literature). Image quality control (QC) was used to obtain a precise alignment of the heart in PET and CT images in the short axis, vertical, and horizontal long-axis views. Rest and stress dynamic studies were reconstructed from list mode.|$|E
40|$|In {{previous}} work, {{the main}} interfering {{background for the}} in vivo lead in bone measurement {{was found to be}} from back-scattered Compton and Rayleigh source photons, which is, therefore, also the main problem for the improvement of sensitivity. Based on the physics of atomic transition, certain fractions of the characteristic K-series X-rays and L-series X-rays are in <b>true</b> <b>coincidence.</b> With an advanced CAMAC data acquisition system, experimental results are presented and preliminary quantitative methods for analyzing coincidence spectra are treated. A prototype coincidence spectrometer was proposed in previous work and is studied by benchmarked Monte Carlo simulation in this work. Additional information is provided by this method (CXRF) and measurement sensitivity is improved...|$|E
40|$|The isotopic {{composition}} of uranium {{was measured using}} high resolution gamma spectrometry. Two acid solutions and two samples {{in the form of}} UO 2 pellets were measured. The measurements were done in close geometries, i. e. directly on the endcap of the high purity germanium detector (HPGe). Applying no corrections for count losses due to <b>true</b> <b>coincidence</b> summing (TCS) resulted in up to about 40 % deviation in the abundance of U- 235 from the results obtained with mass spectrometry. However, after correction for TCS, excellent agreement was achieved between the results obtained using two different measurement methods, or a certified value. Moreover, after corrections, the fitted relative response curves correlated excellently with simulated responses, for the different geometries, of the HPGe detector...|$|E
30|$|As per the {{arguments}} exposed above, a primary issue concerns the opportunity, {{if not the}} necessity, to have a <b>truer</b> <b>coincidence</b> between citizens and places, area and administration. On one hand, we have de-territorialized human relations since technology allows interacting intensely with other people wherever you are physically located. On the other hand, because of the same telecommunication development, {{we have the opportunity}} to stay longer in the same place and so we need to make that place enjoyable, to make it home. But that place has no name yet, hence it is invisible! Civic institutions should follow and encourage this possible trend that reduces pollution, energy demand and environmental impact of infrastructures needed to move. A new list of place names and typologies of urban spaces would help in promoting environmental and social consciousness.|$|R
30|$|Regarding the {{estimation}} of scattered radiation, {{it should be noted}} that it relies on a prior quick analytical reconstruction uncorrected for scattering events [35]. As these preliminary reconstructions are based on very noisy sinograms, we expect as well the scattering simulation may fail to calculate a reliable estimate. Similarly, van Elmbt et al. [19] suggested an additional component of <b>true</b> <b>coincidences</b> affecting the ends of the profile tails of the rebinned sinograms. They assumed that this signal may come from pair production in the LSO crystals by the X-ray bremsstrahlung above 1.022  MeV. This component may have an impact on the scaling of the scattered sinogram to the emission sinogram. This uniform background may also affect the random correction process, but no specific correction was applied to account for.|$|R
40|$|This paper {{critically}} examines coincidence {{arguments and}} evolutionary debunking arguments against non-naturalist realism in metaethics. It advances {{a version of}} these arguments that goes roughly like this: Given a non-naturalist, realist metaethic, it would be cosmically coincidental if our first order normative beliefs were <b>true.</b> This <b>coincidence</b> undermines any prima facie justification enjoyed by those beliefs...|$|R
40|$|A {{mathematical}} model of <b>True</b> <b>Coincidence</b> Summing (TCS) correction factors of gamma photons from simple decay schemes of °Co and 88 Y was developed. The model developed {{made use of}} the total detection efficiency of the detector and the yields for the photons concerned. The total detection efficiency was determined based on the fraction of the simulated gamma photons being absorbed by the detector. Self-absorption by the sample was also taken into account. The simulation code was written in FORTRAN 90. The simulated total detection efficiencies obtained {{were used in the}} {{mathematical model}} to yield the needed TCS correction factors. The model-simulated TCS correction factors were compared with experimental results. Application of the model and simulation to samples used by other researchers shows an average agreement of within 5...|$|E
40|$|The alpha-particle {{emission}} probabilities {{associated with}} the three main alpha transitions of 238 U were measured by high-resolution alpha-particle spectrometry. Highly enriched 238 U material was used and its isotopic composition characterised by mass spectrometry. Source production through electrodeposition was optimised to reconcile conflicting demands for good spectral resolution and statistical precision. Measurements were performed at IRMM and CIEMATfor 1 - 2 years in three different set-ups. A new magnet system was put into use to largely eliminate <b>true</b> <b>coincidence</b> effects with low-energy conversion electrons. Finally the accuracy and precision of the relative emission probabilities for the three transitions – 77. 01 (10) %, 22. 92 (10) % and 0. 068 (10) %, respectively – have been improved significantly. JRC. D. 4 -Standards for Nuclear Safety, Security and Safeguard...|$|E
40|$|One of {{the outputs}} of the European Metrology Research Programme project “Ionising {{radiation}} metrology for the metallurgical industry” (MetroMetal) was a recommendation {{on a novel}} radionuclide specific detector system optimized for the measurement of radioactivity in metallurgical samples. The detection efficiency of the recommended system for the standards of cast steel, slag and fume dust developed within the project was characterized by Monte Carlo (MC) simulations performed using different MC codes. Capabilities of MC codes were also tested for simulation of <b>true</b> <b>coincidence</b> summing (TCS) effects for several radionuclides {{of interest in the}} metallurgical industry. The TCS correction factors reached up to 32 % showing that the TCS effects are of high importance in close measurement geometries met in routine analyses of metallurgical samples. JRC. D. 4 -Standards for Nuclear Safety, Security and Safeguard...|$|E
40|$|The co-existence of de novo myelodysplastic {{syndrome}} (MDS) and non-Hodgkin lymphoma (NHL) {{prior to}} therapy {{is an extremely}} unusual finding. We report here a case of co-existent de novo MDS-refractory cytopenia with multilineage dysplasia and T-cell NHL, including clinical features, histo-pathological findings, molecular assessment, treatment course and outcomes. Other cases from the literature showing co-existence of both disorders are also reviewed; to date 19 similar cases have been reported. Among all cases (including the present patient), eight cases were diagnosed with de novo MDS and NHL simultaneously, which {{were considered to be}} <b>true</b> <b>coincidences.</b> The mechanisms responsible for the appearance of co-existence have not yet been ascertained, however in the present case a common chromosomal abnormality (20 q deletion) was found in bone marrow and lymph node preparations. We conclude, therefore, that the co-existent de novo MDS and T-cell NHL seen in the present case may have a common origin...|$|R
30|$|Standard scatter {{correction}} {{and random}} correction alone {{are not sufficient}} to obtain quantitative images {{in the presence of}} abundant spurious coincidences from prompt gammas. In the absence of proper correction, this results in high artifact background levels and consequent loss of contrast, or overestimation of the conventional scatter, with over subtraction in {{the central part of the}} body. In order to mitigate the effect of the prompt gamma, it has been shown that a narrower energy window can effectively reduce the prompt gamma contamination in the data [33]. This alone does not eliminate the problem, particularly in situations where the prompt gammas have energy very close to the conventional PET energy (511  keV) or the prompt gamma coincidences are the majority component. Moreover, it does reduce the sensitivity of the PET scanner to <b>true</b> <b>coincidences.</b> A new correction is needed, the prompt gamma correction (PGC). In the past years, several methods have been proposed to estimate and subtract the prompt gamma component.|$|R
40|$|Performance {{tests on}} {{lutetium}} oxyorthosilicate (LSO) –based PET scanners cannot be conducted strictly {{according to the}} National Electrical Manufacturers Association (NEMA) NU 2 standards {{because of the presence}} of intrinsic radioactivity within the LSO crystal scintillator material. This background radiation gives rise mainly to random coincidence events but also to a small number of <b>true</b> <b>coincidences,</b> which cannot be eliminated from measurements on such scanners and must therefore be corrected for in the data analysis. The current NU 2 standards do not take account of these backgrounds and hence can lead to erroneous results on LSO-based machines. Nevertheless, the intent of the standards can be met with ap-propriate modifications to the acquisition and processing pro-cedures. In this paper, we propose certain changes to the NEMA specifications to accommodate this class of scanners. These changes affect mainly the estimation of sensitivity, scat-ter, randoms, and count losses. Using these modified proce-dures, the NU 2 performance of LSO-based systems can accu-rately be measured. Key Words: background; intrinsic radioactivity; lutetium oxy...|$|R
