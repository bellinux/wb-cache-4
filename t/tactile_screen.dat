25|19|Public
25|$|Two dice {{are usually}} used {{to decide what}} part of the wall to start dealing from. They are {{standard}} six sided dice. The dealer marker is a round or square object that the dealer places to the side to remind players who the dealer is. The wind marker may be used which indicates the current prevailing wind. In some cases the dealer marker and the wind marker are represented by one large marker, usually a small wheel where one can swivel the outer circle to indicate the prevailing wind (which the dealer holds onto) or a dice with the four winds placed onto four of the sides which can be placed in a hollow square (the dealer holds onto it. There are a variety of counting pieces used in different countries. They range from Chinese counting sticks (thin sticks with various dots on them to represent various points), poker like chips, paper money, paper and pencil or various apps on <b>tactile</b> <b>screen</b> devices used to calculate and keep scores.|$|E
50|$|Along the {{itinerary}} of the exhibition, {{it is possible}} to consult a <b>tactile</b> <b>screen</b> with images of the works and entries about the artists edited by Paola Bonani for the Quadriennale Foundation.|$|E
50|$|Based {{on these}} calculations, {{an array of}} bimorphs was {{constructed}} for reading rate tests with the computer simulation at SRI. The computer simulation presented tactile images of perfectly formed and aligned letters in a stream that moved across the bimorph array. Candy Linvill and other blind subjects learned to read text presented in this fashion with encouraging results. However, this simulation differed from the conditions that the user would encounter with an Optacon in the real world. There would be {{a wide range of}} type fonts and print qualities, plus the user would have to move the camera across the text rather than the computer moving the text across the <b>tactile</b> <b>screen</b> at a fixed rate. It wasn’t known how much the mental load of controlling the camera would reduce the reading rate.|$|E
40|$|International audienceThis paper {{presents}} SpiraList, a focus+context visualization {{technique for}} interacting with large lists on handheld devices. SpiraList has been {{specifically designed to}} fit the constraints of small <b>tactile</b> <b>screens.</b> It provides a global view of large lists {{by way of a}} compact layout based on a spiral representation. Its design also allows for direct interaction with fingers. The combination of this compact layout and one-handed interaction makes SpiraList particularly suitable for mobility...|$|R
50|$|Xperia E3 {{possesses}} an IPS <b>tactile</b> capacitive <b>screen</b> of 4.5 inches with multi tactile points. Its {{resolution is}} 854x480 pixels, with 16 million colours.|$|R
40|$|This paper {{presents}} SpiraList, a focus+context visualization {{technique for}} interacting with large lists on handheld devices. SpiraList has been {{specifically designed to}} fit the constraints of small <b>tactile</b> <b>screens.</b> It provides a global view of large lists {{by way of a}} compact layout based on a spiral representation. Its design also allows for direct interaction with fingers. The combination of this compact layout and one-handed interaction makes SpiraList particularly suitable for mobility. Author Keywords: Mobile interfaces, spiral layout, focus+context visualization, finger interaction. ACM Classification: H 5. 2 [Information interfaces and presentation]: User Interfaces- Graphical user interfaces...|$|R
50|$|When {{a single}} column of 24 pixels is scanned across {{a line of}} text, all of the {{information}} is acquired. However, with the sense of touch, people are capable of perceiving two dimensional images. Bliss wondered if the reading rate would be higher if more than one column of 24 pixels were used, and if so, how many columns would be appropriate? Experiments with the computer simulation determined that reading rate increased dramatically up to 6 columns, which was a window width of about one letter space and this was about the maximum number of columns that could be placed on one finger. Jon Taenzer, one of Bliss’ Stanford graduate students, ran visual reading experiments on the same computer simulation and determined that for visual reading, reading rates continued to increase up to a window width of up to about 6 letter spaces. This led to a number of experiments toward trying to increase the tactile reading rate by increasing the number of columns in the <b>tactile</b> <b>screen</b> so more than one letter would be in view at a time. Instead of moving the text across only the index fingertip, tests were run with a screen wide enough for both the index finger and the middle finger to be used so two letters could be simultaneously tactually sensed. In another experiment the moving belt of text was run {{down the length of the}} fingers, rather than across them. The only approach that showed any promise of increasing the reading rate was when both index fingers were used, rather than the index finger and the adjacent middle finger. However, the use of both index fingers was incompatible with the design concept of using one hand to control the camera while the other hand sensed the <b>tactile</b> <b>screen.</b> The Optacon design was therefore based on an array of 24-by-6 pixels in both the camera retina and bimorph array.|$|E
5000|$|Two dice {{are usually}} used {{to decide what}} part of the wall to start dealing from. They are {{standard}} six sided dice. The dealer marker is a round or square object that the dealer places to the side to remind players who the dealer is. The wind marker may be used which indicates the current prevailing wind. In some cases the dealer marker and the wind marker are represented by one large marker, usually a small wheel where one can swivel the outer circle to indicate the prevailing wind (which the dealer holds onto) or a dice with the four winds placed onto four of the sides which can be placed in a hollow square (the dealer holds onto it. There are a variety of counting pieces used in different countries. They range from Chinese counting sticks (thin sticks with various dots on them to represent various points), poker like chips, paper money, paper and pencil or various apps on <b>tactile</b> <b>screen</b> devices used to calculate and keep scores.|$|E
40|$|In {{this paper}} {{we present a}} joint use of <b>tactile</b> <b>screen</b> and animation. We first recall why this two {{techniques}} are valuable for air traffic controller computer interaction and then describe the current trends for these techniques. We then describe the methodology we used, based on paper and video fast prototyping. It allowed us to quickly design the first computer-based prototypes. These prototypes demonstrated that tightly coupling <b>tactile</b> <b>screen</b> and animation make the computer human interaction more natural. These results can easily be applied in future air traffic controller computer interfaces studied at the CENA...|$|E
40|$|This work {{describes}} several infrastructure contributions {{targeted to}} enhance the interaction with Ambient Assisted Living-AAL [1] environments, so that elderly people can maximize the time they live independently, through the help of Information and Communication Technologies-ICT at their homes. Traditional interaction mechanisms, such as the keyboard, mouse or the usage of <b>tactile</b> <b>screens</b> {{to interact with the}} environment are only suitable for elderly people with ICT familiarity, but they are not friendly enough for most of the elderly that have never interacted with this kind of interfaces. That is the reason why this work proposes a set of multimodal interaction alternatives with the environment combining more natural communication channels like voice, images, videos and non-intrusive sensors and devices which interact by themselves, in an implicit manner, with the environment...|$|R
40|$|International audienceThis paper {{presents}} a focus+context visualization and interaction technique for displaying large lists on handheld devices. This technique has been {{specifically designed to}} fit the constraints of small <b>tactile</b> <b>screens.</b> Thanks to its spiral layout, it provides a global view of large lists on {{a limited amount of}} screen real-estate. It has also been designed to allow direct interaction with fingers. This technique proposes an alternative to multi-focus visualization, called "augmented context", where several objects of interest can be pointed up simultaneously. We propose two implementations of this approach that either use spatial or temporal composition. We conducted a controlled experiment that compares our approach to standard scrollable lists for a search task on a PDA phone. Results show that our technique significantly reduces the error rate (about 3. 7 times lower) without loss of performance...|$|R
40|$|This paper {{describes}} an approach {{for assessing the}} level of stress of users of mobile devices with <b>tactile</b> <b>screens</b> by analysing their touch patterns. Two features are extracted from touches: duration and intensity. These features allow to analyse the intensity curve of each touch. We use decision trees (J 48) and support vector machines (SMO) to train a stress detection classifier using additional data collected in previous experiments. This data includes the amount of movement, acceleration on the device, cognitive performance, among others. In previous work we have shown the co-relation between these parameters and stress. Both algorithms show around 80 % of correctly classified instances. The decision tree {{can be used to}} classify, in real time, the touches of the users, serving as an input to the assessment of the stress level. This work is funded by National Funds through the FCT Fundacao para a Ciencia e a Tecnologia (Portuguese Foundation for Science and Technology) within project PEst-OE/EEI/UI 0752 / 2011. The work of Davide Carneiro is also supported by a doctoral grant by FCT (SFRH/BD/ 64890 / 2009) ...|$|R
40|$|National audienceThis article {{introduces}} the Swiss Army Menu (SAM), a radial menu that enables {{a very large}} number of functions on a single small <b>tactile</b> <b>screen.</b> The design of SAM relies on four different kinds of items, support for navigating in hierarchies of items and a control based on small thumb movements. SAM can thus offer a set of functions so large that it would typically have required a number of widgets that could not have been displayed in a single viewport at the same time...|$|E
40|$|EVWUDFWIn {{this paper}} is {{presented}} an educational application for teaching ideas related to partitioning, placement and routing (PPR) of digital circuit in a generic FPGA (Field-Programmable Gate Arrays) architecture. Tapping in the <b>tactile</b> <b>screen,</b> the student can construct different blocks. They can fill the contents of LUTs (Look-up Tables) and wire them activating segments of a programmable interconnection network. The program works on Android telephones and tablets. The application includes a tutorial, a set of exercises, and auxiliary tools for checking the results or sends them by e-mail [...] HQGURLG) 3 * 'LJLWDO 'HVLJQ /RRNXS 7 DEOHV 7 HFKQRORJDSSLQJ 6 KDQQRQ&RIDFWRULQ...|$|E
40|$|Abstract. We present TimeTilt, a sensor-based {{technique}} that allows multiple windows switching on mobile devices, and which overcomes {{the limitations of}} mobile devices, i. e. their impoverished input bandwidth (often no keyboard, a small <b>tactile</b> <b>screen</b> and the drawbacks of one-handed interaction). TimeTilt, {{which is based on}} a lenticular metaphor, aims at both reducing the activation time when switching between views, and supporting a natural mapping between the gestures and the navigation. We draw a brief classification of sensor-based gestures {{that could be used in}} mobile conditions, and we present an experiment. Keywords: Mobile devices, One-handed interaction, Multiple windows, Sensors, Gestures, Lenticular, Undo, Redo...|$|E
50|$|In May 2017, Amazon {{introduced}} the Echo Show, {{which features a}} <b>tactile</b> 7-inch LCD <b>screen</b> {{that can be used}} for playing media, making video calls (5 MP front camera), and other features. The Echo Show was offered for purchase at a price of $229.99 on June 28, 2017 and is initially only available in the U.S.|$|R
40|$|We {{present the}} design and {{evaluation}} of TapTap and MagStick, two thumb interaction techniques for target acquisition on mobile devices with small touch-screens. These two techniques address all {{the issues raised by}} the selection of targets with the thumb on small <b>tactile</b> screens: <b>screen</b> accessibility, visual occlusion and accuracy. A controlled experiment shows that TapTap and MagStick allow the selection of targets in all areas of the screen in a fast and accurate way. They were found to be faster than four previous techniques except Direct Touch which, although faster, is too error prone. They also provided the best error rate of all tested techniques. Finally the paper also provides a comprehensive study of various techniques for thumb based touch-screen target selection. Categories and Subject Descriptor...|$|R
40|$|Abstract — This paper {{presents}} the early {{results of the}} multidisciplinary project Tivipol aiming to propose ICT devices to enhance the daily life of older people in a retirement home. A prototype combining a <b>tactile</b> color <b>screen,</b> a RFID reader and a ticket printer has been designed. It allows the older people to manage their usual activities in the retirement home (e. g. reserving their menu for the next days at the cafeteria). A first formative evaluation carried out with five residents of the home has shown {{the high level of}} usability and possible acceptance of the new system. This ongoing research is intended to find out which elements {{play a key role in}} the acceptation and diffusion of a ICT-based technology among elderly people in good physical and mental conditions...|$|R
40|$|Abstract — This paper {{presents}} the preliminary {{results of a}} multi-disciplinary project aiming at studying technology supported life in a retirement home. The results of semistructured interviews conducted {{with a group of}} 40 (semi-) autonomously living elderly persons are presented. In general they point {{in the direction of a}} “differential indication” of technologies in the sense of identifying personal solution for individual needs. Second, results show that the crucial dimension underlying the acceptance of technologies is the notion of personal control. The paper also identifies ten key design factors to build successful applications for elderly people. Finally an initial version of a new system mixing RFID, <b>tactile</b> <b>screen</b> and large display is described...|$|E
40|$|Abstract — The current {{development}} of educational applications for language learning {{has experienced a}} qualitative change in the criteria of interaction between users and devices due to the technological advances of input and output data through keyboard, mouse, stylus, <b>tactile</b> <b>screen,</b> etc. The multiple interactions generated in a natural way by humans during ordinary communication can be transferred in a sequential way to devices like PDAs, PC Tablet, etc. depending on the users' needs to carry out specific tasks that allow humans to adapt to their nearest learning context. This paper shows the possibility of establishing multimodal architectures within the applications for specific language learning areas with ubiquitous devices, evidencing the technical and formal aspects necessary for their accomplishment that are currently being developed at the Universidad Politécnica de Valencia (Spain) ...|$|E
40|$|International audienceCurrently, {{everybody}} wish {{to access}} to applications {{from a wide}} variety of devices (PC, Tablet, Smartphone, Set-top-box, etc.) in situations including various interactions and modalities (mouse, <b>tactile</b> <b>screen,</b> voice, gesture detection, etc). At home, users interact with many devices and get access to many multimedia oriented documents (hosted on local drives, on cloud storage, on line streaming, etc.) in various situations and with multiple (and sometimes at the same time) devices. This paper presents an efficient approach to context aware content delivery. We particularly focus on cloud ontology model, as a way to inference users’ preferences according to different sensitive situations. Thus, we can determine the necessary adaptations that the user has full exploitation of multimedia documents and their use with interactive services in order to help in achieving user’s preferences under multiples devices constraints with multiple interacting modalities. Our simulation study shows the efficiency and effectiveness of our approach...|$|E
5000|$|The {{passage of}} the Help America Vote Act in 2002 {{required}} new voting systems to be accessible. This led Eugene Cummings to file for a patent in 2003 on a machine that became the AutoMARK. [...] This machine has a touch <b>screen,</b> <b>tactile</b> keyboard, and headphone jack, as well as support for several other assistive devices, and it records votes on ballots used by several widely used optical scan voting systems. [...] By 2016, the AutoMARK was used statewide in 10 states in the United States, and widely used in 19 additional states.|$|R
50|$|The first Optacon {{prototype}} {{using this}} retina was completed on September 1, 1969. It was portable and completely self-contained {{in that it}} combined the stimulator array, electronics, batteries, and camera in a single package measuring 13.5″ by 8″ by 2.25″. The total weight was 9 pounds. The low power electronics design in this unit was a joint effort by J. S. Brugler and W. T. Young which made possible about 12 hours of sustained operation from the rechargeable batteries. This unit included an improved optical system and camera plus a <b>tactile</b> bimorph driven <b>screen,</b> both developed by James Baer and John Gill at SRI.|$|R
40|$|Liquid {{crystal display}} panels {{subjected}} to tactile force will show ripple propagation on <b>screens.</b> <b>Tactile</b> forces change tilt angles of liquid crystal molecules and alter optical transmission {{so as to}} generate ripple on screens. Based on the Ericksen-Leslie theory, this study investigates ripple propagation by dealing with tilt angles of liquid crystal molecules. Tactile force effects {{are taken into account}} to derive the molecule equation of motion for liquid crystals. Analytical results show that viscosity, tactile force, the thickness of cell gap, and Leslie viscosity coefficient lead to tilt angle variation. Tilt angle variations of PAA liquid crystal molecules are sensitive to tactile force magnitudes, while those of 5 CB and MBBA with larger viscosity are not. Analytical derivation is validated by numerical results...|$|R
40|$|Multi-agent {{systems are}} now wide spread in {{scientific}} works and in industrial applications. Few applications {{deal with the}} Human/Multi-agent system interaction. Multi-agent systems are characterized by individual entities, called agents, in interaction {{with each other and}} with their environment. Multi-agent systems are generally classified into complex systems categories since the global emerging phenomenon cannot be predicted even if every component is well known. The systems developed in this paper are named reactive because they behave using simple interaction models. In the reactive approach, the issue of Human/system interaction is hard to cope with and is scarcely exposed in literature. This paper presents Sphericall, an application aimed at studying Human/Complex System interactions and based on two physics inspired multi-agent systems interacting together. The Sphericall device is composed of a <b>tactile</b> <b>screen</b> and a spherical world where agents evolve. This paper presents both the technical background of Sphericall project and a feedback taken from the demonstration performed during OFFF Festival in La Villette (Paris) ...|$|E
40|$|International audienceTactile {{displays}} have predominantly {{been used}} for information transfer using patterns or as assistive feedback for interactions. With recent advances in hardware for conveying increasingly rich tactile information that mirrors visual information, and the increasing viability of wearables that remain in constant contact with the skin, there is a compelling argument for exploring tactile interactions as rich as visual displays. Direct Manipulation underlies much of the advances in visual interactions. In this work, we introduce {{the concept of a}} Direct Manipulation-enabled Tactile display (DMT). We define the concepts of a <b>tactile</b> <b>screen,</b> tactile pixel, tactile pointer, and tactile target which enable tactile pointing, selection and drag & drop. We build a proof of concept tactile display and study its precision limits. We further develop a performance model for DMTs based on a tactile target acquisition study. Finally, we study user performance in a real-world DMT menu application. The results show that users are able to use the application with relative ease and speed...|$|E
40|$|International audienceFor the 2006 VRIC conference, we {{presented}} a scientific article {{dealing with a}} new way of thinking our technical heritage. We propose to preserve it as a digital object. However it does not mean beautiful 3 D animation with nice static rendering; indeed, we create virtual mock-up which are dynamically operating. We use CAD software and engineering simulation tools. Nowadays the global methodology has been improved: it is named Advanced Industrial Archaeology. In this communication, we will detail a new experimentation done in partnership with a French museum: the Château des Ducs de Bretagne in France. This project deals with a physical mock-up of Nantes city built in 1899 and exposed in 1900 for the World Fair that took place in Paris, France. The heritage object is nowadays in the museum but exposed as “a fish inside an aquarium”. Thanks to a virtual system coupling a <b>tactile</b> <b>screen</b> with semantic research modules, a 3 D active screen and a light pointer, it will allow the visitor to better understand the mock-up and emphasize important places of Nantes city life...|$|E
500|$|The {{majority}} of the machines were designed by Martin Laing, a crew member on Cameron's Titanic and Ghosts of the Abyss. McG described many of the machines as having an H. R. Giger influence. McG's intent {{was to create a}} gritty, <b>tactile</b> 2018 on <b>screen,</b> and Laing concurred the robots would have to be black and degraded as none of them are new. Laing devised Aerostats, which are smaller versions of the Aerial Hunter Killers from the previous films. The Aerostats send a signal to the [...] humanoid Harvesters. They are very big and slow, so they use Mototerminators to capture humans, and the Harvesters place them in Transporters. Laing was unsure of how to design the Transporters until he saw a cattle transport while driving through Albuquerque.|$|R
40|$|A {{method for}} the {{conversion}} of crystallographic information framework (CIF) files to stereo lithographic data files suitable for printing on three-dimensional printers is presented. Crystallographic information framework or CIF files are capable of being manipulated in virtual space {{by a variety of}} computer programs, but their visual representations are limited to the two-dimensional surface of the computer <b>screen.</b> <b>Tactile</b> molecular models that demonstrate critical ideas, such as symmetry elements, {{play a critical role in}} enabling new students to fully visualize crystallographic concepts. In the past five years, major developments in three-dimensional printing has lowered the cost and complexity of these systems to a level where three-dimensional molecular models may be easily created provided that the data exists in a suitable format. Herein a method is described for {{the conversion of}} CIF file data using existing free software that allows for the rapid creation of inexpensive molecular models. This approach has numerous potential applications in basic research, education, visualization, and crystallography...|$|R
40|$|Different tactile {{interfaces}} {{have been}} proposed to represent either text (braille) or, in a few cases, <b>tactile</b> large-area <b>screens</b> as replacements for visual displays. None of the implementations so far can be customized to match users preferences, perceptual differences and skills. Optimal choices in these respects are still debated; we approach a solution by designing a flexible device allowing the user to choose key parameters of tactile transduction. We present here a new dynamic tactile display, a 8 × 8 matrix of plastic pins based on well-established and reliable piezoelectric technology to offer high resolution (pin gap 0. 7 mm) as well as tunable strength of the pins displacement, and refresh rate up to 50 s- 1. It can reproduce arbitrary patterns, allowing it to serve the dual purpose of providing, depending on contingent user needs, tactile rendering of non-character information, and reconfigurable braille rendering. Given {{the relevance of the}} latter functionality for the expected average user, we considered testing braille encoding by volunteers a benchmark of primary importance. Tests were performed to assess the acceptance and usability with minimal training, and to check whether the offered flexibility was indeed perceived by the subject as an added value compared to conventional braille devices. Different mappings between braille dots and actual tactile pins were implemented to match user needs. Performances of eight experienced braille readers were defined as the fraction of correct identifications of rendered content. Different information contents were tested (median performance on random strings, words, sentences identification was about 75 %, 85 %, 98 %, respectively, with a significant increase, p< 0. 01), obtaining statistically significant improvements in performance during the tests (p< 0. 05). Experimental results, together with qualitative ratings provided by the subjects, show a good acceptance and the effectiveness of the proposed solution...|$|R
40|$|Abstract—This paper {{presents}} a new tactile display based on thermopneumatic actuators. Since the main drawback {{of these devices}} in the market is their cost, this proposal is intended to reduce the price because of the simplicity of the actuator and the potential low cost assembling. A small display with 4 x 4 taxels and 2. 54 mm of distance between centers has been built and results from a single actuator with proposed activation circuitry illustrate its performance in this first prototype. Specifically, rise and fall times of 2 and 11 seconds respectively are measured as well as maximum stroke and force above 1 mm and 0. 1 N respectively. This results are good to implement a large <b>tactile</b> <b>screen.</b> Power consumption is high, but it could be lower if latching mechanisms are used to keep the taxel active without power supply. Finally, thermopneumatic actuators have been used in micropumps and microvalves in technologies for MEMS, thus very small and smart tactile devices could be fabricated to improve the resolution and performance. Index Terms—Blind people aids, Tactile graphic displays, Thermopneumatic actuator...|$|E
40|$|Abstract — This paper {{describes}} and evaluates {{an intelligent}} wheelchair, adapted for cognitively disabled subjects with mobility impairement. The {{study focused on}} cerebral palsy patients, {{one of the most}} common congenital disorders that affect muscle control and coordination, thereby impairing movement. The wheelchair concept is an assistive device that allows the subject to select arbitrary local destinations through a <b>tactile</b> <b>screen</b> interface. The device incorporates an automatic navigation system that drives the vehicle, avoiding obstacles even in unknown and dynamic scenarios, providing the subject with a high degree of autonomy, independent from a particular environment, i. e., not restricted to predefined conditions. To evaluate the rehabilitation device, a study was carried out with four cognitively impaired subjects, between 11 and 16 years of age. They were first trained so as to get acquainted with the tactile interface and then were recruited to drive the wheelchair. Based on the experience with the subjects, an extensive evaluation of the intelligent wheelchair was provided from two perspectives: (i) based on the technical performance of the entire system and its components and, (ii) based on the behavior of the user (execution analysis, activity analysis and competence analysis). The results indicated that this device effectively provided mobility and autonomy to the target population. I...|$|E
40|$|International audienceCurrently, {{everybody}} wish {{to access}} to applications {{from a wide}} variety of devices (PC, Tablet, Smartphone, Set-top-box, etc.) in situations including various interactions and modalities (mouse, <b>tactile</b> <b>screen,</b> voice, gesture detection, etc.). At home, users interact with many devices and get access to many multimedia oriented documents (hosted on local drives, on cloud storage, online streaming, etc.) in various situations with multiple (and sometimes at the same time) devices. The diversity and heterogeneity of users profiles and service sources can be a barrier to discover the available services sources that can come from anywhere from the home or the city. The objective of this paper is to suggest a meta-level architecture for increasing the high level of context concepts abstracting for heterogeneous profiles and service sources via a top-level ontology. We particularly focus on context-aware mHealth applications and propose an ontologies-based architecture, OntoSmart (a top-ONTOlogy SMART), which provides adapted services that help users to broadcast of multimedia documents and their use with interactive services in order to help in maintaining old people at home and achieving their preferences. In order to validate our proposal, we have used Semantic Web, Cloud and Middlewares by specifying and matching OWL profiles and experiment their usage on several platforms...|$|E
40|$|Abstract: An Interactive Whiteboard (IWB) is {{a device}} that is a giant <b>tactile</b> and {{projection}} <b>screen.</b> It {{can be considered as}} one of the main elements for pedagogical innovation with information technol-ogy. IWB allows to transform the classical classroom environment into a working and learning interactive environment. This pedagogical tool is particularly pertinent in higher school especially in scientific teaching where it allows to better illustrate scientific approach thanks to the ability to record annotations in association with a time line. If the use of IWB seems to be natural in lecture, it can also be used in tutorial and practical class where collaborative work is particularly important. The collaborative ability is closely tied to the softwares used. Few software have func-tionalities aimed at facilitate collaborative work. This feature is the main issue of this article. To develop this ability, a multi-agent approach has been chosen. Multi-agent systems approach {{is one of the most}} interesting thanks to its intrinsic properties and features such as simplicity, flexibility, reliability, self-organization/emergent phenomena, low cost agent design and adaptation skills, [...] . This paper presents the solution developed in order to make IWB able to communicate with each other. ...|$|R
40|$|ABSTRACT: New {{smartphones}} generation {{provided with}} webcams, <b>tactile</b> <b>screen</b> and internet connection allow adaptation {{of new technologies}} and computer applications {{to this kind of}} devices. Augmented reality technology becomes widespread and more used each time by everyone. Augmented reality (AR) seeks creating virtual objects in user interface which superimpose over the physical environment. Equipment maintenance as well as training tasks are both excellent fields for developing augmented reality applications, in fact, several apps of Augmented Reality have been performed in very specific systems and complex (aircrafts, military equipment [...] .). In this paper our aim is making this technology approachable for applications and tasks quite common to everybody, so two prototypes have been developed: one smartphones-based mobile AR system and another video see-through based AR system which will guide the user step by step through installation of the V-brakes system, change of cartridge shoes and adjustment of tension cable. An easy interface based of several cards containing markers with codified sequences based in 3 D models for performing maintenance, is fitted to the bike handlebars. Usability study results illustrate the feasibility of the prototype in both versions considering use of the smartphone for domestic and user tasks meanwhile virtual glasses are advised for more complex maintenance which may require use of both hands...|$|E
40|$|This paper {{describes}} and evaluates {{an intelligent}} wheelchair, adapted for users with cognitive disabilities and mobility impairment. The study focuses on patients with cerebral palsy, {{one of the}} most common disorders affecting muscle control and coordination, thereby impairing movement. The wheelchair concept is an assistive device that allows the user to select arbitrary local destinations through a <b>tactile</b> <b>screen</b> interface. The device incorporates an automatic navigation system that drives the vehicle, avoiding obstacles even in unknown and dynamic scenarios. It provides the user with a high degree of autonomy, independent from a particular environment, i. e., not restricted to predefined conditions. To evaluate the rehabilitation device, a study was carried out with four subjects with cognitive impairments, between 11 and 16 years of age. They were first trained so as to get acquainted with the tactile interface and then were recruited to drive the wheelchair. Based on the experience with the subjects, an extensive evaluation of the intelligent wheelchair was provided from two perspectives: 1) based on the technical performance of the entire system and its components and 2) based on the behavior of the user (execution analysis, activity analysis, and competence analysis). The results indicated that the intelligent wheelchair effectively provided mobility and autonomy to the target population. Peer ReviewedPostprint (published version...|$|E
