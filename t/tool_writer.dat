5|116|Public
40|$|A {{performance}} counter is {{that part}} of a microprocessor that measures and gathers performance-relevant events on the microprocessor. The number and type of available events differ significantly between existing microprocessors, because there is no commonly accepted specification, and because each manufacturer has different priorities on analyzing the performance of architectures and programs. Looking at the supported events on the different microprocessors, it can be observed that the functionality of these events differs from the requirements of an expert application programmer or a performance <b>tool</b> <b>writer.</b> PCL, the Performance Counter Library, establishes a common platform for performance measurements {{on a wide range of}} computer systems. With a common interface on all systems and a set of application-oriented events defined, the application programmer is able to do program optimization in a portable way and the performance <b>tool</b> <b>writer</b> is able to rely on a common interface on different systems. PCL has functions to query the functionality, to start and to stop counters, and to read the values of counters. PCL supports nested calls to PCL functions thus allowing hierarchical performance measurements. Counting may be done either in system or in user mode. All interface functions are callable in C, C++, and Fortran...|$|E
40|$|The {{proliferation}} of dynamic program analysis tools has {{done much to}} ease the burden of developing complex software. However, creating such tools remains a challenge. Dynamic binary instrumentation frameworks such as DyanamoRIO and Pin provide support for such tools by taking responsibility for application transparency and machine code manipulation. However, tool writers must still make a tough choice when writing instrumentation: should they inject custom inline assembly into the application code, or should they use the framework facilities for inserting callbacks into regular C code? Custom assembly can be more performant and more flexible, but it forces the tool to take some responsibility for maintaining application transparency. Callbacks into C, or “clean calls, ” allow the <b>tool</b> <b>writer</b> to ignore the details of maintaining transparency. Generally speaking, a clean call entails switching to a safe stack...|$|E
40|$|Binary {{instrumentation}} {{has been}} widely used to observe dynamic program behavior, but current binary instrumentation systems do not allow the <b>tool</b> <b>writer</b> to alter the program execution path. This paper introduces some simple and general mechanisms for a binary instrumentation infrastructure to provide control over the application’s execution path, allowing tools to replay or skip parts of the application, and to start or switch between threads. Specifically, the technique provides the following three functionalities for both single-threaded and multi-threaded applications: (1) checkpointing the execution state, (2) resuming execution at a checkpoint, and (3) starting execution at an arbitrary point in the program with a specified architectural state. We describe our implementation of these functionalities in Pin, a dynamic binary instrumentation infrastructure from Intel [5]. We demonstrate the usefulness of our mechanism by describing several binary instrumentation tools that have been built using this interface, including a transactional memory model and a thread scheduler. ...|$|E
5000|$|Scrivener (software) - A {{powerful}} content-generation <b>tool</b> for <b>writers</b> {{that allows}} you to concentrate on composing and structuring long and difficult documents for Mac OS X and Microsoft Windows.|$|R
50|$|Grothaus {{has also}} spoken {{frequently}} about his dissatisfaction with things being {{the reasons he}} writes about what he does. He also maintains that dissatisfaction {{is the most important}} <b>tool</b> a <b>writer</b> has.|$|R
50|$|Raphael Arthur Salaman (24 April 1906 - 31 December 1993) was a British engineer, {{collector}} of hand <b>tools</b> and <b>writer.</b> His work recorded the tools {{used during the}} 18th, 19th and early 20th centuries in Britain.|$|R
40|$|Robust and {{powerful}} software instrumentation tools {{are essential for}} program analysis tasks such as profiling, performance evaluation, and bug detection. To meet this need, we have developed a new instrumentation system called Pin. Our goals are to provide easy-to-use, portable, transparent, and efficient instrumentation. Instrumentation tools (called Pintools) are written in C/C++ using Pin’s rich API. Pin follows the model of ATOM, allowing the <b>tool</b> <b>writer</b> to analyze an application at the instruction level {{without the need for}} detailed knowledge of the underlying instruction set. The API is designed to be architecture independent whenever possible, making Pintools source compatible across different architectures. However, a Pintool can access architecture-specific details when necessary. Instrumentation with Pin is mostly transparent as the application and Pintool observe the application’s original, uninstrumented behavior. Pin uses dynamic compilation to instrument executables while they are running. For efficiency, Pin uses several techniques, including inlining, register re-allocation, liveness analysis, and instruction scheduling to optimize instrumentation. This fully automated approach delivers significantly better instrumentation performance than similar tools. For example, Pin is 3. 3 x faster than Valgrind and 2 x faster than DynamoRIO for basic-block counting. To illustrate Pin’s versatility, we describe two Pintools in daily use to analyze production software. Pin is publicly available for Linux platforms on four architectures: IA 32 (32 -bit x 86), EM 64 T (64 -bit x 86), Itanium R ○, and ARM. In the ten months since Pin 2 was released in July 2004, there have been over 3000 downloads from its website. Categories and Subject Descriptors D. 2. 5 [Software Engineering]: Testing and Debugging-code inspections and walk-throughs...|$|E
40|$|The {{proliferation}} of dynamic program analysis tools has {{done much to}} ease the burden of developing complex software. However, creating such tools remains a challenge. Dynamic binary instrumentation frameworks such as DyanamoRIO and Pin provide support for such tools by taking responsibility for application transparency and machine code manipulation. However, tool writers must still make a tough choice when writing instrumentation: should they inject custom inline assembly into the application code, or should they use the framework facilities for inserting callbacks into regular C code? Custom assembly can be more performant and more flexible, but it forces the tool to take some responsibility for maintaining application transparency. Callbacks into C, or "clean calls," allow the <b>tool</b> <b>writer</b> to ignore the details of maintaining transparency. Generally speaking, a clean call entails switching to a safe stack, saving all registers, materializing the arguments, and jumping to the callback. This thesis presents a suite of optimizations for DynamoRIO that improves the performance of "naive tools," or tools which rely primarily on clean calls for instrumentation. Most importantly, we present a novel partial inlining optimization for instrumentation routines with conditional analysis. For simpler instrumentation routines, we present a novel call coalescing optimization that batches calls into fewer context switches. In addition to these two novel techniques, we provide a suite of machine code optimizations designed to leverage the opportunities created by the aforementioned techniques. With this additional functionality built on DynamoRIO, we have shown improvements of up to 54. 8 x for a naive instruction counting tool {{as well as a}} 3. 7 x performance improvement for a memory alignment checking tool on average for many of the benchmarks from the SPEC 2006 CPU benchmark suite. by Reid Kleckner. Thesis (M. Eng.) [...] Massachusetts Institute of Technology, Dept. of Electrical Engineering and Computer Science, 2011. Cataloged from PDF version of thesis. Includes bibliographical references (p. 59 - 60) ...|$|E
40|$|The {{process of}} writing—andteaching writing—is in themidst of a tectonic change(Yancey, in press). The changeis {{in the new}} technoiogical <b>tools</b> <b>writers</b> use, and in how these tools affect {{composition}} {{and the relationship between}} writer and audience. As they have for hundreds of years, student writers still compose with pencil and paper. But in addition, writers now compose through new media like e-mail, listservers, and creative software pack-ages. Writers use digital technologies to write many new kinds of texts, such as Web logs, hypertexts, and electronic portfolios. Helping writers develop fluency and competence in a variety of technologies is a key part of teaching writing in this century...|$|R
50|$|It {{can also}} be an {{extremely}} useful <b>tool</b> for a <b>writer</b> working on a spec script.|$|R
40|$|Web servers such as Apache and web proxies like Squid support {{event logging}} using a common log format. The logs {{produced}} using these de-facto standard formats are invaluable to system administrators for trouble-shooting a server and <b>tool</b> <b>writers</b> to craft <b>tools</b> that mine the log files and produce reports and trends. The Session Initiation Protocol (SIP) {{does not have}} a common log format, and as a result, each server supports a distinct log format. This plethora of formats discourages the creation of common tools. Whilst SIP is similar to HTTP, {{there are a number of}} fundamental differences between a sessionmode protocol and a stateless request-response protocol. We propose a common log file format for SIP servers that can be used uniformly by proxies, registrars, redirec...|$|R
40|$|Program {{instrumentation}} has a {{wide variety}} of useful applications, but <b>tool</b> <b>writers</b> must overcome the challenge of substantial overheads caused by introducing additional code and data into a program. This paper observes that instrumentation usually operates on many discrete, independent data structures, which we call metadata parallelism. We proposes to exploit this phenomenon to reduce the overhead of instrumented programs by executing instrumentation function invocations that manipulate different pieces of metadata simultaneously in different threads. The key challenge to spreading instrumentation function execution across many threads is ensuring that metadata updates occur in the correct order, and do not suffer from data races. Metadata-based parallelization solves this problem by using a user-specified mapping of instrumentation function invocations to serialization sets...|$|R
50|$|Xtranormal was {{launched}} {{after four years}} of software development. It was established as a storyboarding <b>tool</b> for <b>writers</b> and film directors. The original intent was to allow users to create videos by choosing from a menu of predesigned characters and sets, and scripting their own dialogue.|$|R
40|$|The {{decommissioning}} of Alpha AXP-based systems {{carrying the}} ATOM toolkit {{has left the}} need for an efficient, flexible binary instrumentation tool-building framework for another platform. PMaCinst is a binary instrumentation toolkit that operates on XCOFF binaries on AIX for PowerPC processors. PMaCinst has a C++ API that provides the means to inject code and data into a binary file In this paper, we first present the mechanisms for performing these modifications along with the key parts of the API. We then present three example rewriting tools that have been built using PMaCinst, which help to highlight some of the correctness and efficiency issues that can be encountered by <b>tool</b> <b>writers.</b> Finally, we show that programs instrumented with PMaCinst slow down at rates that are comparable to equivalently instrumented programs created with ATOM. 1...|$|R
40|$|DraftWell-known {{web servers}} such as Apache and web proxies like Squid support event logging using a common log format. The logs {{produced}} using these de-facto standard formats are invaluable to system administrators for trouble-shooting a server and <b>tool</b> <b>writers</b> to craft <b>tools</b> that mine the log files and produce reports and trends. Furthermore, these log files {{can also be}} used to train anomaly detection systems and feed events into a security event management system. The Session Initiation Protocol does not have a common log format, and as a result, each server supports a distinct log format that makes it unnecessarily complex to produce tools to do trend analysis and security detection. We propose a common log file format for SIP servers that can be used uniformly by proxies, registrars, redirect servers as well as back-to-back user agents...|$|R
40|$|This paper {{deals with}} the {{construction}} of distributed software development environments (SDE). Distributed SDEs must often run on heterogeneous hardware and software platforms. A promising approach to solve this heterogeneity problem is to implement tools, at least their front-ends, in Java. We propose a repository-centered SDE architecture in which an active repository offers services such as views, transactions, and access controls and, in addition, provides an integrated, distributed notification mechanism. The notification mechanism allows <b>tool</b> <b>writers</b> to implement, with very low effort, a network-wide, view-independent change propagation which covers both interactive and batch applications. The architecture allows tools, or the whole environment, to have multiple windows. Each window basically corresponds to an independent process, and processes can run truly in parallel (not just pseudo-parallel). The paper describes the details of the architecture, issues concerning the reposi [...] ...|$|R
40|$|Processor {{and memory}} {{technology}} trends portend a continual {{increase in the}} relative cost of accessing main memory. Machine designers have tried {{to mitigate the effect}} of this trend through a hierarchy of caches {{and a variety of other}} hardware and software techniques. These techniques, unfortunately, have only been partially successful for pointer-manipulating programs. This paper explores a complementary approach of enlisting programmers and <b>tool</b> <b>writers</b> in the task of improving the cache locality of accesses to pointer-based data structures. Throughout, we exploit the location transparency of pointer-based data structures that allow changes to the memory (and cache) layout of nodes, records, fields, etc. We discuss how programmers can manually improve cache performance with techniques, such as clustering, compression, and coloring. We then explore how to lessen a programmer's burden with the help of semi-automatic and automatic tools for changing structure layout to improve cache per [...] ...|$|R
40|$|This chapter {{traces the}} {{development}} of cosmopolitan and transnational sensibilities later emphasized by twentieth-century writers such as Joseph Conrad and E. M. Forster. Ranging from Anglo-American aesthetes including Oscar Wilde, Henry James, Walter Pater, and Michael Field to French Decadents like Charles Baudelaire and Joris-Karl Huysmans, the chapter demonstrates the Zeitgeist’s dependence on what Conrad called ‘the latent feeling of fellowship with all creation’. Style, synaesthesia, and ekphrasis were among the <b>tools</b> <b>writers</b> employed to emphasize the multivalent nature of their politics and aesthetics. In doing so, however, they hearkened back to the politicized aesthetics underscored earlier {{in the nineteenth century}} in the works of John Ruskin, Karl Marx, and Friedrich Engels. Current critical practice shares many of the concerns of these writers: it is therefore necessary to preserve modes of reading that attend to stifled, marginalized voices because of the salutary socio-political lessons they can teach our discipline...|$|R
40|$|Robust and {{powerful}} software instrumentation tools are es-sential for dynamic program analysis {{tasks such as}} profiling, performance evaluation, and bug detection. Dynamic binary instrumentation (DBI) is a general purpose technique that eases the development of program analysis tools by facili-tating automatic low-level instrumentation. DBI-based pro-gram analysis can introduce high overhead and it is crucial for <b>tool</b> <b>writers</b> to minimize the cost. Analyzing the per-formance of instrumentation tools is challenging because most systems use a just-in-time compiler (JIT) to dynami-cally generate code. In this paper, we describe our method for analyzing the performance of instrumentation tools. The instrumented code is itself instrumented with basic block counters. We implement the profiler in Pin {{and use it to}} an-alyze the behavior of simple and complex instrumentation tools. The analysis yields several unexpected results about the dynamic behavior of instrumented programs. By exam-ining these results, we often find effective solutions to im-prove performance. 1...|$|R
40|$|The C {{programming}} language is intimately connected to its macro preprocessor. This relationship affects, indeed generally hinders, both the tools (compilers, debuggers, call graph extractors, etc.) built to engineer C programs {{and also the}} ease of translating to other languages such as C++. This paper analyzes 27 packages comprising 1. 2 million lines of publicly available C code, determining how the preprocessor is used in practice. We developed a framework for analyzing preprocessor usage {{and used it to}} extract information about the incidence of preprocessor directives, the frequency of macro use and redefinition, the purposes of macros (in terms of both definitions and uses), and expressibility of macros in terms of other C or C++ language features. We particularly note data that are material to the development of tools for C or C++, including translating from C to C++ to reduce preprocessor usage. The results are of interest to language designers, <b>tool</b> <b>writers,</b> programmers, and soft [...] ...|$|R
50|$|In recent years, the {{prominence}} of computers in society has led to many advances {{in the field of}} digital communications, leading to many changes in the <b>tools</b> technical <b>writers</b> use. Hypertext, word processors, graphics editing programs, and page layout software have made the creation of technical documents faster and easier than ever before, and technical writers of today must be proficient in these programs.|$|R
5000|$|Scrivener allows photos, URLs, and {{multiple}} other file formats, {{to be dragged}} into its interface as well. Because of its breadth of interfaces and features, it has positioned itself {{not only as a}} word processor, but as a project management <b>tool</b> for <b>writers,</b> and includes many user-interface features that resemble Xcode, Apple's integrated development environment (IDE). One computer programmer has called Scrivener [...] "an IDE for writing".|$|R
40|$|Thesis supervisor: Jennifer Rowe. [ACCESS RESTRICTED TO THE UNIVERSITY OF MISSOURI AT AUTHOR'S REQUEST. ] The {{purpose of}} this {{research}} is to discover the <b>tools</b> <b>writers</b> use to construct realistic profiles of celebrities whom have not consented to an interview. The research analyzes seven magazine articles and includes interviews with three prominent writers. By means of textual analysis and semi-structured, in-depth interviews, the researcher examines how reporting and literary techniques allow writers to craft realistic portraits of celebrities. The Social Construction of Reality Theory shows how the studied articles employ the basic understandings of how humans understand "reality" so that what has not been actually lived can still be conveyed through the written word. The result of this research shows that writers rely on common reporting techniques, such as immersion, secondary sourcing, and seeking out interviews with nonsubject primary sources, as well as literary devices such as scene construction, dialogue, and character development, to craft profiles that are realistic despite lacking in main subject participation. Includes bibliographical references (pages 132 - 135) ...|$|R
50|$|Lupton {{primarily}} bases her {{designs on}} typography and implements type on a communicative level. Not only is lettering {{used to describe}} everyday things to us, or to help us communicate, {{but it is also}} there to be a creative <b>tool</b> for <b>writers,</b> artists, illustrators, and graphic designers. Regardless of the type of design some texts may have, text is everywhere. It is a medium and a message to the senders and receivers.|$|R
50|$|Screen capture <b>tools</b> Technical <b>writers</b> {{commonly}} use Screen Capture Tools like Camtasia and Snagit {{to capture}} their desktops. When creating instructions for computer software, it's {{much easier for}} a technical writer to simply record themselves completing a task {{than it is to}} write a lengthy series of instructions that describe how the task must be performed. Screen capture tools are also used to take screenshots of programs and software running on user's computers and then to create accompanying diagrams.|$|R
40|$|Due to {{the wide}} range of compilers and the lack of astandardized {{performance}} <b>tool</b> interface, <b>writers</b> of performance toolsface many challenges when incorporating support for global address space(GAS) programming models such as Unified Parallel C (UPC), Titanium, andCo-Array Fortran (CAF). This document presents a Global Address SpacePerformance tool interface (GASP) that is flexible enough to be adaptedinto current global address space compiler and runtime infrastructureswith little effort, while allowing performance analysis tools to gathermuch information about the performance of global address spaceprograms...|$|R
40|$|In {{this paper}} the authors briefly outline editing {{functions}} which use methods from computational linguistics {{and take the}} structures of natural languages into consideration. Such functions could reduce errors and better support writers in realizing their communicative goals. However, linguistic methods have limits, and there are various aspects software developers {{have to take into}} account to avoid creating a solution looking for a problem: Language-aware functions could be powerful <b>tools</b> for <b>writers,</b> but writers must not be forced to adapt to their tools...|$|R
40|$|In this work, we {{demonstrate}} {{the power of}} providing {{a common set of}} operating system services to Grid Architectures, including high-performance I/O, communication, resource management and process management. A Grid[1] enables the sharing, selection, and aggregation {{of a wide variety of}} geographically distributed resources including supercomputers, storage systems, data sources, and specialized devices owned by different organizations administered with different policies. In the last few years, a number of exciting projects like Globus[2], Legion[3], and UNICORE[4] developed the software infrastructure needed for grid computing. However, operating system support for grid computing is minimal or non-existent. <b>Tool</b> <b>writers</b> are forced to re-invent the wheel by implementing from scratch. This is error prone and often results in sub-optimal solutions. To address these problems, we are developing GridOS, a set of operating system services that facilitate grid computing. The services are designed to make writing middleware easier and make a normal commodity operating system like Linux highly suitable for grid computing. The modules are designed to be policy neutral, exploit commonality in various grid infrastructures and provide high-performance. Experiments with GridOS verify that there is dramatic improvement in performance when compared to the existing grid file transfer protocols like GridFTP[5]. Our proof-of-concept middleware shows that writing middleware is easy using GridOS...|$|R
40|$|The {{process of}} writing—and {{teaching}} writing—is {{in the midst}} of a tectonic change (Yancey, in press). The change is in the new technological <b>tools</b> <b>writers</b> use, and in how these tools affect composition and the relationship between writer and audience. As they have for hundreds of years, student writers still compose with pencil and paper. But in addition, writers now compose through new media like e-mail, listservers, and creative software packages. Writers use digital technologies to write many new kinds of texts, such as Web logs, hypertexts, and electronic portfolios. Helping writers develop fluency and competence in a variety of technologies is a key part of teaching writing in this century. Acquiring Textured Literacy Examining specific ways in which teachers are bringing new technologies and related practices into the classroom reveals how the writing curriculum of the early 21 st century is both an extension of what has come before and an expansion of it. One new element in this expanded writing curriculum is helping students acquire what I call textured literacy—the ability to comfortably use and combine print, spoken, visual, and digital processes in composing a piece of writing. Teachers often begin acclimating young students to new writing technologies in...|$|R
40|$|Due to {{the wide}} range of compilers and the lack of a {{standardized}} performance <b>tool</b> interface, <b>writers</b> of performance <b>tools</b> face many challenges when incorporating support for global address space (GAS) programming models such as Unified Parallel C (UPC), Titanium, and Co-Array Fortran (CAF). This document presents a Global Address Space Performance tool interface (GASP) that is flexible enough to be adapted into current global address space compiler and runtime infrastructures with little effort, while allowing performance analysis tools to gather much information about the performance of global address space programs...|$|R
40|$|Java {{annotations}} are meta-data about Java program elements, as in “@Deprecated class Date { [...] . }”. Ordinarily, Java annotations {{are written}} in the source code of a. java Java source file. When javac compiles the source code, it inserts the annotations in the resulting. class file (as “attributes”). Sometimes, it is convenient to specify the annotations outside the source code or the. class file. • When source code is not available, a textual file provides a format for writing and storing annotations that {{is much easier to}} read and modify than a. class file. Even if the eventual purpose is to insert the annotations in the. class file, the annotations must be specified in some textual format first. • Even when source code is available, sometimes it should not be changed, yet annotations must be stored somewhere for use by tools. • A textual file for annotations can eliminate code clutter. A developer performing some specialized task (such as code verification, parallelization, etc.) can store annotations in an annotation file without changing the main version of the source code. (The developer’s private version of the code could contain the annotations, but the developer could copy them to the separate file before committing changes.) • <b>Tool</b> <b>writers</b> may find it more convenient to use a textual file, rather than writing a Java or. class file parser...|$|R
5000|$|Sir William Empson {{spoke of}} the ideal of Pastoral as being {{embedded}} in varying degrees of ambivalence, and yet, for all the apparent dichotomies, and contradicting elements found within it, he felt there was a unified harmony within it. He refers to the pastoral process as 'putting the complex into the simple.' Empson argues that [...] "[...] [...] good proletarian art is usually Covert Pastoral", and uses Soviet Russia's propaganda about the working class as evidence. Empson also {{emphasizes the importance of}} the double plot as a <b>tool</b> for <b>writers</b> to discuss a controversial topic without repercussions.|$|R
50|$|A word {{processing}} application {{available in a}} bank-selected cartridge and a double-sided disk (master disk on one side, dictionary disk on the other side). It was developed by Madison Micro and published by OSS in 1984. According to Bill Wilkinson, OSS was already building a word processor, but stopped when The <b>Writer's</b> <b>Tool</b> was submitted.|$|R
50|$|The System Builder/SB+ server {{environment}} is based around {{a set of}} key tools and utilities. These leverage out to provide a powerful and comprehensive development environment which is, itself, built mainly from these tools. SB+ includes an application menuing system, screen generator, a 3GL programming language, an expression language, the GUI components and report <b>writer</b> <b>tool.</b>|$|R
40|$|The {{technology}} and tools used by technical writers are constantly changing and evolving. One tool specifically {{has taken the}} spotlight {{in recent years to}} become one of the most adopted technical writing tools—the Darwin Information Typing Architecture (DITA). To gauge the usefulness and potential lifespan of DITA as a <b>tool</b> technical <b>writers</b> rely on, a survey of technical writing professionals who utilize DITA in their work was conducted asking for their opinions and thoughts regarding DITA and its lifespan as a tool. This paper explores how DITA has become an integral tool to the technical writing world and discusses what professionals and educators alike can expect of its future...|$|R
5000|$|When tool {{historians and}} <b>tool</b> book <b>writers</b> began {{to pay him}} visits to see his {{collection}} and publish items from it, he came to realise that what he had amassed was worthy of a book in its own right. He struggled to pull together a team to bring the book to fruition, but after much toil spanning several years the book was published to critical acclaim in October 2010. The dust-jacket text summarizes the book's aim as one of [...] "providing a broad survey of hand tool-making from prehistory to today."As David Linley wrote in the foreword: [...] "Russell is to be congratulated on amassing with unerring eye such a fascinating array of tools." ...|$|R
