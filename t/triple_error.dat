7|30|Public
40|$|Preferred {{embodiments}} of {{the invention}} provide WOM cod ing methods and electronic devices With error correcting codes that provide single, double and <b>triple</b> <b>error</b> correction. Preferred codes of the invention also the following property: if the code corrects tWo/three errors it has tWo/three parts of redundancy bits. For double error correction, {{if only one}} part of the redundancy bit has no errors then it is possible to correct one error. For <b>triple</b> <b>error</b> correction, if only one/tWo parts of the redundancy bits have no errors then it is possible to correct one/tWo errors. Preferred methods of the invention use codes that correct / detect a single, tWo and three cell-erasures. A preferred method of the invention applies a code that has three roots, ah a 2, a 3, each of Which is a primitive element and Where every pair of roots generates a double error correcting code. Methods of the invention further provide and utilize codes utilitiZing a <b>triple</b> <b>error</b> correcting WOM code that can correct an arbitrary number of errors. US 2013 / 0091402 A...|$|E
40|$|In {{a recent}} paper, Bracken and Helleseth [2009]showed {{that one can}} {{construct}} triple-error-correcting codes usingzero set consisting different zero set than the BCH codes. In thiscorrespondence we present some new <b>triple</b> <b>error</b> correcting codehaving zeros, +, + and, +, + where gcd (2 k, n) = 1 and n be odd...|$|E
40|$|Abstract- In {{a recent}} paper, Bracken and Helleseth [2009] showed {{that one can}} {{construct}} triple-error-correcting codes using zero set consisting different zero set than the BCH codes. In this correspondence we present some new <b>triple</b> <b>error</b> correcting code having zeros, +, + 	 and, +, where gcd (2 k, n) = 1 and n be odd...|$|E
40|$|In this paper, we provise an {{implementation}} of five, seven and nine-qubits error correcting codes on a classical computer using the quantum simulator Feynman program. We also compare the three codes by computing the fidelity when double errors {{occurs in a}} depolarizing channel. As <b>triple</b> <b>errors</b> and more are considered very unlikely, it has negligible effect on the next resultsComment: 24 page...|$|R
40|$|Abstract-In {{this paper}} we first present a {{systematic}} (16, 8) code that can correct double errors and detect all triple-adjacent errors. The re-striction of detecting triple-adjacent errors in 8 -bit bytes has been re-moved. We also present a systematic (16, 8) code that can correct all 16 single errors, correct 113 of the 120 doubIe errors, detect seven daw ble errors, correct seven of 14 <b>triple</b> adjacent <b>errors,</b> detect seven <b>triple</b> adjacent <b>errors,</b> and correct all quadruple adjacent errors. Index Terms-Adjacent error detection, error correction, systematic codes. I...|$|R
40|$|Spare columns {{are often}} {{included}} in memories {{for the purpose}} of allowing for repair in the presence of defective cells or bit lines. In many cases, the repair process will not use all spare columns. This paper proposes an extremely low cost method to exploit these unused spare columns to improve the reliability of the memory by enhancing its existing error correcting code (ECC). Memories are generally protected with single-errorcorrecting, double-error-detecting (SEC-DED) codes using the minimum number of check bits. In the proposed method, unused spare columns are exploited to store additional check bits which can be used to reduce the miscorrection probability for <b>triple</b> <b>errors</b> in SEC-DED codes or non-adjacent double errors in single adjacent error correcting codes (SEC-DAEC) codes...|$|R
40|$|Abstract — Nowadays, {{memories}} we use are cheap, {{easily available}} in market, compact, have high programmability and available on various ranges of size and type. But the dis-advantage with these memories is that whenever {{there is a}} radiation strike on sensitive part of memory circuit, the data stored in the memory will be corrupted. These types of errors are common in radiation-prone environment like space, aircrafts, radiation research laboratories, power plants, mines etc. One of the remedies for this is to use error correction codes. Different error correction codes are available, from simple to complex. As the complexity increases efficiency also increases. Radiation will effect closer memory locations mainly as they are adjacent to each other. SEC-DAED code provides single error correction and double adjacent error detection, but cannot do anything about <b>triple</b> <b>error</b> detection. Codes like SEC-DED-TAED will also provide <b>triple</b> <b>error</b> detection {{but there is no}} provision for double error correction. This project compare different error correction codes and develop a new method which will provide single and double adjacent error correction which is occurring most time and also provide double non adjacent and triple adjacent error detection. The coding is done using VHDL in Xilinx 14. 5 and simulations were obtained using ISim simulator. The project was implemented on Spartan 3 XC 3 s 200 FPGA platform. Keywords—- single event effect(SEE), multiple cell upset(MCU), single error correction –double adjacent error detection (SEC-DAED),single error correction –double error –detection (SEC-DED-TAED),), Orthogonal Latin Square Codes(OLS) ...|$|E
40|$|In high-reliability aerospace, avionics, and {{military}} applications, single error correction (SEC) and double error detection (DED) may not provide adequate protection against SDRAM memory faults. This makes multiple-error correction (MEC) highly desirable. Although many powerful error control methods including Reed-Solomon {{are capable of}} correcting multiple bytes of error, the general drawback with these methods is latency and speed. Most of these codes require at least several dozen cycles to complete the first correction. Additional latency is not appealing to most memory interface applications. Fortunately, Reed-Muller error control codes possess multiple bit error correction capability with relatively low latency and high performance. In this application note, the <b>triple</b> <b>error</b> correcting Reed-Muller (RM) is implemented in both the Virtex-II Pro ™ and Virtex- 4 ™ Platform FPGA families...|$|E
40|$|HARRIS, under {{contract}} with NASA Lewis, {{has developed a}} hard decision BCH (Bose-Chaudhuri-Hocquenghem) <b>triple</b> <b>error</b> correcting block CODEC ASIC, {{that can be used}} in either a bursted or continuous mode. the ASIC contains both encoder and decoder functions, programmable lock thresholds, and PSK related functions. The CODEC provides up to 4 dB of coding gain for data rates up to 300 Mbps. The overhead is selectable from 7 / 8 to 15 / 16 resulting in minimal band spreading, for a given BER. Many of the internal calculations are brought out enabling the CODEC to be incorporated in more complex designs. The ASIC has been tested in BPSK, QPSK and 16 -ary PSK link simulators and found to perform to within 0. 1 dB of theory for BER's of 10 (exp - 2) to 10 (exp - 9). The ASIC itself, being a hard decision CODEC, is not limited to PSK modulation formats. Unlike most hard decision CODEC's, the HARRIS CODEC doesn't upgrade BER performance significantly at high BER's but rather becomes transparent...|$|E
40|$|The {{problem of}} {{constructing}} systematic error correcting codes has been stated as follows, “Construct a group code such that each word representing an error pattern {{to be corrected}} lies in a separate coset. ” A computational method is described which will generate such codes of any given word length correcting any arbitrarily chosen set of error patterns. The method suggested by Sacks (1958) {{turns out to be}} a special case of the method here described, where the set of error patterns are the set of all n-tuple errors. Codes having up to 10 check bits have been constructed using this method for correcting double and <b>triple</b> <b>errors</b> as well as burst-type errors of 3 digit width. The computation for each code took an LGP- 30 computer 3 to 4 hr. The resulting codes have been compared to other known codes...|$|R
40|$|Modern storage systems orchestrate a {{group of}} disks to achieve their {{performance}} and reliability goals. Even though such systems are designed to withstand the fail-ure of individual disks, failure of multiple disks poses {{a unique set of}} challenges. We empirically investigate disk failure data from a large number of production systems, specifically focusing on the impact of disk failures on RAID storage systems. Our data covers about one million SATA disks from 6 disk models for periods up to 5 years. We show how observed disk failures weaken the protection provided by RAID. The count of reallocated sectors correlates strongly with impending failures. With these findings we designed RAIDSHIELD, which consists of two components. First, we have built and evaluated an active defense mechanism that moni-tors the health of each disk and replaces those that are predicted to fail imminently. This proactive protection has been incorporated into our product and is observed to eliminate 88 % of <b>triple</b> disk <b>errors,</b> which are 80 % of all RAID failures. Second, we have designed and simulated a method of using the joint failure probability to quantify and predict how likely a RAID group is to face multi-ple simultaneous disk failures, which can identify disks that collectively represent a risk of failure even when no individual disk is flagged in isolation. We find in sim-ulation that RAID-level analysis can effectively identify most vulnerable RAID- 6 systems, improving the cover-age to 98 % of <b>triple</b> <b>errors.</b> ...|$|R
5000|$|Hearst spared {{no expense}} {{with the new}} {{headquarters}} {{in an attempt to}} capture the attention of Syracusans. By October 1, 1922, {{just in time for the}} 1922 World Series, the company installed an [...] "automatic board" [...] that showed every play, in detail, [...] "within a few seconds after it is made, every strike, every ball, every base hit, two-base hit, three-base hit, home run, double or <b>triple</b> play, <b>error</b> and run is illustrated just as you would see it on the home grounds." [...] The New York Giants beat the New York Yankees in five games that year. Hearst spared no expense with the new headquarters in an attempt to capture the attention of Syracusans. By October 1, 1922, just in time for the 1922 World Series, the company installed an [...] "automatic board" [...] that showed every play, in detail, [...] "within a few seconds after it is made, every strike, every ball, every base hit, two-base hit, three-base hit, home run, double or <b>triple</b> play, <b>error</b> and run is illustrated just as you would see it on the home grounds." [...] The New York Giants beat the New York Yankees in five games that year.|$|R
40|$|This report {{covers the}} {{investigation}} of problems relating to the telemetry of pacemakers in a noisy environment. An {{attempt was made to}} suggest schemes that improve system performance. We define system performance to be improved noise immunity with high reliability and increased message throughput. Three aspects were considered, with implementation schemes that incur minimal protocol changes over systems in existence. 1. The present scheme is writing to the pacemaker and echoing each bit back within a 2 ms frame. If any echoed bit is not in agreement with that sent, the message is re-transmitted {{from the start of the}} block. Because the return link is poor in terms of signal to noise ratio, echoing bits up this link degrades system performance, particularly as the noise power increases. An ARQ (autamatic repeat request) scheme is suggested as a solution to this problem. 2. When data is to be read from the pacemaker, reply is via two 4 ms frames each of 6 bits. A CRC (cyclic redundancy check) is performed on the returned data (8 bits) which checks for three or less errors, and the redundancy bits are appended to the end of the 9 bits. If any errors are detected, a retransmission is required. Using a FEC (forward error correction) scheme to correct errors, together with a CRC to check the integrity of data, throughput can be significantly improved especially in a noisy environment. The scheme we suggest is to encode data bits plus CRC with a 23, 12 Golay code, and send the data using four by 4 ms frames. The Golay code suggested is a perfect code, <b>triple</b> <b>error</b> correcting. 3. The final aspect we considered is the possible system performance improvement using soft decision quantization at the programmer of received data. This system gives gains of the order of 1. 75 dB over current practice...|$|E
40|$|The {{redundancy}} n - k of an (n, k) binary linear {{block code}} capable of single error correction, double adjacent <b>error</b> correction and <b>triple</b> adjacent <b>error</b> correction (SEC-DAEC-TAEC) is lower bounded by log(2) (3 n - 2). Recently, researchers {{have tried to}} find minimum redundancy codes which achieve equality in this lower bound using computer search and failed. In this letter, we prove that such codes do not exist for any n and k. This results in the tighter lower bound of n - k >= log(2) (3 n - 1) on the redundancy of SEC-DAEC-TAEC codes...|$|R
5000|$|Managed by Carlos Subero, Venezuela outscored {{their opponents}} 45-15 while the defense {{committed}} only three <b>errors.</b> <b>Triple</b> Crown winner Ramón Hernández {{was named the}} Series Most Valuable Player after leading all players with a [...]542 batting average (13-for-24) and eight RBIs, while tying with Edgar González with three home runs. Hernández also hit for the cycle in Game Two, {{to become the first}} player {{to do it in the}} Series history.|$|R
40|$|In {{the last}} few years, {{research}} made significant progress towards operational soil moisture remote sensing which lead to the availability of several global data sets. For an optimal use of these data, an accurate estimation of the error structure is an important condition. To solve for the validation problem we introduce the <b>triple</b> collocation <b>error</b> estimation technique. The triple collocation technique is a powerful tool to estimate the {{root mean square error}} while simultaneously solving for systematic differences in the climatologies of a set of three independent data sources. We evaluate the method by applying it to a passive microwave (TRMM radiometer) derived, an active microwave (ERS- 2 scatterometer) derived and a modeled (ERA-Interim reanalysis) soil moisture data sets. The results suggest that the method provides realistic error estimates. Copyright 2008 by the American Geophysical Union...|$|R
40|$|A {{method is}} {{developed}} for generating pseudopotentials {{for use in}} correlated-electron calculations. The paradigms of shape and energy consistency are combined and {{defined in terms of}} correlated-electron wave-functions. The resulting energy consistent correlated electron pseudopotentials (eCEPPs) are constructed for H, Li [...] F, Sc [...] Fe, and Cu. Their accuracy is quantified by comparing the relaxed molecular geometries and dissociation energies they provide with all electron results, with all quantities evaluated using coupled cluster singles doubles and <b>triples</b> calculations. <b>Errors</b> inherent in the pseudopotentials are also compared with those arising from a number of approximations commonly used with pseudopotentials. The eCEPPs provide a significant improvement in optimised geometries and dissociation energies for small molecules, with errors for the latter being an order-of-magnitude smaller than for Hartree-Fock-based pseudopotentials available in the literature. Gaussian basis sets are optimised for use with these pseudopotentials. Comment: 18 pages, 5 figures. Includes supplemental informatio...|$|R
5|$|One {{exception}} in this rule {{occurs when the}} defense makes at least one out and attempts to complete a double play or <b>triple</b> play. An <b>error</b> is not charged in that situation if a wild throw allows the runner to reach safely. If a wild throw allows the runner to advance an additional base, an error may then be charged for the additional advance. However, if an accurate throw is made in time to complete a double play or triple play, but the fielder on the base fails to make the catch, an error may be charged.|$|R
40|$|Abstract — In {{order to}} reduce overall system costs, the {{aerospace}} industry has been increasingly using commercial off the shelf components in their products. The sensitivity of these products to radiation induced soft errors becomes a major concern. In this paper, we propose a method to increase the reliability of a given off the shelf component by manipulating the software-based error correction algorithm of its already existing 4 -D parity codes. The paper shows that using this approach, {{it is possible to}} correct <b>triple</b> bit adjacent <b>errors,</b> without adversely affecting the performance or memory usage. Furthermore, we discuss the results of implementing and validating the proposed approach in practice on PIC microcontrollers. I...|$|R
40|$|Based on an {{asymmetric}} Lanczos-chain subspace algorithm, damped coupled cluster {{linear response}} functions {{have been implemented}} for the hierarchy of coupled cluster (CC) models including CC with single excitations (CCS), CC 2, CC with single and double excitations (CCSD), and CCSD with noniterative triple corrected excitation energies CCSDR(3). This work {{is a first step}} toward the extension of these theoretical electronic structure methods of well-established high accuracy in UV-vis absorption spectroscopies to applications concerned with x-ray radiation. From the imaginary part of the linear response function, the near K-edge x-ray absorption spectra of neon, water, and carbon monoxide are determined and compared with experiment. Results at the CCSD level show relative peak intensities in good agreement with experiment with discrepancies in transition energies due to incomplete treatment of electronic relaxation and correlation that amount to 1 - 2 eV. With inclusion of <b>triple</b> excitations, <b>errors</b> in energetics are less than 0. 9 eV and thereby capturing 90 %, 95 %, and 98 % of the relaxation-correlation energies for C, O, and Ne, respectively. Funding Agencies|EU| 254326 |Swedish Research Council| 621 - 2010 - 5014 |National Supercomputer Centre (NSC), Sweden|...|$|R
40|$|We {{studied the}} case of {{transparent}} word labels (e. g., "push") placed on glass doors, when viewed {{from the other side}} as mirror-reversed script, hence requiring an action opposite to word meaning. As compared with a regular view, labels seen "from the other side" in the glass door situation caused strong delays of actions and a <b>tripling</b> of <b>error</b> rates. This problem is unrelated to mirror reading but is at least partially due to the need to act opposite to word meaning. The glass door effect was not related to practice and age and showed no adaptation effect after incompatible trials. Distribution analyses showed an increased correct reaction time (RT) effect for slower responses, whereas accuracy effects were specific for fast responses. In the literature, problems with such mixed mappings have often been interpreted in the sense of competing action tendencies. Experiments 1 to 4, however, demonstrated that this might merely be a task difficulty effect due to the necessity for a mental transformation in case of mirror-reversed labels. Moreover, our results strongly advocate against using transparent labels because they may pose a considerable risk...|$|R
40|$|International audienceGlobal {{surface soil}} {{moisture}} (SSM) datasets are being produced based on active and passive microwave satellite observations and simulations from land surface models (LSM). This study investigates {{the consistency of}} two global satellite-based SSM datasets based on microwave remote sensing observations from the passive Soil Moisture and Ocean Salinity (SMOS; SMOSL 3 version 2. 5) and the active Advanced Scatterometer (ASCAT; version TU-Wien-WARP 5. 5) with respect to LSM SSM from the MERRA-Land data product. The relationship between the global-scale SSM products was studied during the 2010 - 2012 period using (1) a time series statistics (considering both original SSM data and anomalies), (2) a space-time analysis using Hovmöller diagrams, and (3) a <b>triple</b> collocation <b>error</b> model. The SMOSL 3 and ASCAT retrievals {{are consistent with the}} temporal dynamics of modeled SSM (correlation R > 0. 70 for original SSM) in the transition zones between wet and dry climates, including the Sahel, the Indian subcontinent, the Great Plains of North America, eastern Australia, and south-eastern Brazil. Over relatively dense vegetation covers, a better consistency with MERRA-Land was obtained with ASCAT than with SMOSL 3. However, it was found that ASCAT retrievals exhibit negative correlation versus MERRA-Land in some arid regions (e. g., the Sahara and the Arabian Peninsula). In terms of anomalies, SMOSL 3 better captures the short term SSM variability of the reference dataset (MERRA-Land) than ASCAT over regions with limited radio frequency interference (RFI) effects (e. g., North America, South America, and Australia). The seasonal and latitudinal variations of SSM are relatively similar for the three products, although the MERRA-Land SSM values are generally higher and their seasonal amplitude is much lower than for SMOSL 3 and ASCAT. Both SMOSL 3 and ASCAT have relatively comparable <b>triple</b> collocation <b>errors</b> with similar spatial error patterns: (i) lowest errors in arid regions (e. g., Sahara and Arabian Peninsula), due to the very low natural variability of soil moisture in these areas, and Central America, and (ii) highest errors over most of the vegetated regions (e. g., northern Australia, India, central Asia, and South America). However, the ASCAT SSM product is prone to larger random errors in some regions (e. g., north-western Africa, Iran, and southern South Africa). Vegetation density was found to be a key factor to interpret the consistency with MERRA-Land between the two remotely sensed products (SMOSL 3 and ASCAT) which provides complementary information on SSM. This study shows that both SMOS and ASCAT have thus a potential for data fusion into long-term data records...|$|R
40|$|Nowadays, {{spaceborne}} Synthetic Aperture Radar (SAR) {{has become}} {{a powerful tool for}} providing significant wave height (SWH). Traditionally, validation of SAR derived SWH has been carried out against buoy measurements or model outputs, which only yield an inter-comparison, but not an "absolute" validation. In this study, the <b>triple</b> collocation <b>error</b> model has been introduced in the validation of Envisat ASAR derived SWH products. SWH retrievals from ASAR wave mode using ESA's algorithm are validated against in situ buoy data, and wave model hindcast results from WaveWatch III wave model, covering a period of six years. From the triple collocation validation analysis, the impacts of the collocation distance and water depth on the error of ASAR SWH are discussed. It is found that the error of Envisat ASAR SWH product is linear to the collocation distance, and decrease with the decreasing collocation distance. Using the linear regression fit method, the absolute error of Envisat ASAR SWH was obtained with zero collocation distance. The absolute Envisat ASAR wave height error of 0. 49 m is presented in deep and open ocean from this triple collocation validation work, in contrast to a larger error of 0. 56 m in coastal and shallow waters. One {{of the reasons for the}} larger Envisat ASAR SWH errors in the coastal waters may be the inaccurate Modulation Transfer Function (MTF) adopted in the Envisat ASAR wave retrieval algorithm...|$|R
40|$|Uncertainty {{information}} for global {{leaf area index}} (LAI) products is important for global modeling studies but usually difficult to systematically obtain at a global scale. Here, we present a new method that cross-validates existing global LAI products and produces consistent uncertainty information. The method {{is based on a}} <b>triple</b> collocation <b>error</b> model (TCEM) that assumes errors among LAI products are not correlated. Global monthly absolute and relative uncertainties, in 0. 05 ° spatial resolutions, were generated for MODIS, CYCLOPES, and GLOBCARBON LAI products, with reasonable agreement in terms of spatial patterns and biome types. CYCLOPES shows the lowest absolute and relative uncertainties, followed by GLOBCARBON and MODIS. Grasses, crops, shrubs, and savannas usually have lower uncertainties than forests in association with the relatively larger forest LAI. With their densely vegetated canopies, tropical regions exhibit the highest absolute uncertainties but the lowest relative uncertainties, the latter of which tend to increase with higher latitudes. The estimated uncertainties of CYCLOPES generally meet the quality requirements (± 0. 5) proposed by the Global Climate Observing System (GCOS), whereas for MODIS and GLOBCARBON only non-forest biome types have met the requirement. Nevertheless, none of the products seems to be within a relative uncertainty requirements of 20 %. Further independent validation and comparative studies are expected to provide a fair assessment of uncertainties derived from TCEM. Overall, the proposed TCEM is straightforward and could be automated for the systematic processing of real time remote sensing observations to provide theoretical uncertainty {{information for}} a wider range of land products...|$|R
40|$|Potential {{techniques}} to identify small quantities of fissionable materials (FM) (0. 001 % wt.) in conditions {{of a high}} gamma background level have been reviewed and compared, and the optimal possibility for the nuclear material (NM) control in spent fuel assemblies (SFA) has been selected. It was found through numerical simulation that a system based on a passive neutron control method {{could be used to}} detect FMs indirectly when the spent nuclear fuel (SNF) burn-up and cooling time are known. Two types of detectors have been compared: 3 He counters and 235 U-based fission chambers. Better application prospects of 3 He counters, based on the SNM- 18 neutron counter, have been shown and drawbacks of passive control technique have been pointed out. An active neutron control {{has been found to be}} the best way to address the problem considered. The system's computational model shows that the signal exceeds the <b>triple</b> background <b>error</b> (both for ambient and intrinsic background from Cm isotopes) more than twelvefold. To improve the signal recording efficiency, the system has been modified to allow for irregularities in the geometrical position of structural materials (SM) in the measuring chamber. The proposed procedure makes it possible to determine in a short time the content of 239 Pu, 242 Cm, and 244 Cm in an SFA. After the quantity of 239 Pu is determined, it is possible to estimate the content of other isotopes (Am, U, Np) due to the constancy of the 239 Pu mass ratio to the mass of the actinide identified...|$|R
40|$|Includes bibliographical {{references}} (page 62) Although continuing {{cost and}} performance improvements {{of the new}} bipolar and MOS RAM devices are providing strong incentives for their greatly expanded use in mainframe memory and other storage applications, these components have not yet reached the degree of reliability for large memory system. Memory error frequency will increase due {{to the use of}} larger memory system and higher density memory RAMs, which are more susceptible to soft errors because of their smaller memory cell geometry. The Error Detection and Correction AM 2960 allows correction of any single bit error and detection of all double and some <b>triple</b> bit <b>errors.</b> In this paper, the design of highly memory subsystem based on the use of AM 2960 is presented. Since the AM 2960 EDC unit improves the reliability of the overall system, diagnostic software is developed to check the operation of the EDC itself. Together with the AM 2960, a 4 -bit Error Correction Multiple Bus Buffers AM 2962 is used to facilitate the complete data path interface between the AM 2960, RAM memory and system data bus. In all the present EDC system, the processor will stop upon detection of double bit errors. In this system, the design of Error Logging and Selective Memory Scrubbing to reduce the chance of having double bit errors is discussed. Additionally, to keep system running upon detection of double bit errors, techniques of memory spare block redundancy and memory block power switching is also presented with minimum increase in cost and power...|$|R
40|$|Hundred Talent Program of the Chinese Academy of Sciences Uncertainty {{information}} for global {{leaf area index}} (LAI) products is important for global modeling studies but usually difficult to systematically obtain at a global scale. Here, we present a new method that cross-validates existing global LAI products and produces consistent uncertainty information. The method {{is based on a}} <b>triple</b> collocation <b>error</b> model (TCEM) that assumes errors among LAI products are not correlated. Global monthly absolute and relative uncertainties, in 0. 05 degrees spatial resolutions, were generated for MODIS, CYCLOPES, and GLOBCARBON LAI products, with reasonable agreement in terms of spatial patterns and biome types. CYCLOPES shows the lowest absolute and relative uncertainties, followed by GLOBCARBON and MODIS. Grasses, crops, shrubs, and savannas usually have lower uncertainties than forests in association with the relatively larger forest LAI. With their densely vegetated canopies, tropical regions exhibit the highest absolute uncertainties but the lowest relative uncertainties, the latter of which tend to increase with higher latitudes. The estimated uncertainties of CYCLOPES generally meet the quality requirements (+/- 0. 5) proposed by the Global Climate Observing System (GCOS), whereas for MODIS and GLOBCARBON only non-forest biome types have met the requirement. Nevertheless, none of the products seems to be within a relative uncertainty requirements of 20 %. Further independent validation and comparative studies are expected to provide a fair assessment of uncertainties derived from TCEM. Overall, the proposed TCEM is straightforward and could be automated for the systematic processing of real time remote sensing observations to provide theoretical uncertainty {{information for}} a wider range of land products. (C) 2012 Elsevier Inc. All rights reserve...|$|R
40|$|In {{this study}} we {{evaluate}} the skill of a new, merged soil moisture product (ECV_SM) that has been developed {{in the framework of}} the European Space Agency's Water Cycle Multi-mission Observation Strategy and Climate Change Initiative projects. The product combines in a synergistic way the soil moisture retrievals from four passive (SMMR, SSM/I, TMI, and AMSR-E) and two active (ERS AMI and ASCAT) coarse resolution microwave sensors into a global data set spanning the period 1979 - 2010. The evaluation uses ground-based soil moisture observations of 596 sites from 28 historical and active monitoring networks worldwide. Besides providing conventional measures of agreement, we use the triple collocation technique to assess random errors in the data set. The average Spearman correlation coefficient between ECV_SM and all in-situ observations is 0. 46 for the absolute values and 0. 36 for the soil moisture anomalies, but differences between networks and time periods are very large. Unbiased root-mean-square differences and <b>triple</b> collocation <b>errors</b> show less variation between networks, with average values around 0. 05 and 0. 04 m 3 m- 3, respectively. The ECV_SM quality shows an upward trend over time, but a consistent decrease of all performance metrics is observed for the period 2007 - 2010. Comparing the skill of the merged product with the skill of the individual input products shows that the merged product has a similar or better performance than the individual input products, except with regard to the ASCAT product, compared to which the performance of ECV_SM is inferior. The cause of the latter is most likely a combination of the mismatch in sampling time between the satellite observations and in-situ measurements, and the resampling and scaling strategy used to integrate the ASCAT product into ECV_SM on the other. The results of this study will be used to further improve the scaling and merging algorithms for future product updates...|$|R
40|$|The Fraction of Absorbed Photosynthetically Active Radiation (FAPAR) is {{recognized}} as an essential climate variable (ECVs), playing {{a critical role in}} the estimation of the global energy and carbon balance. With multiple space-borne remote sensing FAPAR global products available from several sources the need for continual comparison and validation has become imperative. In this study, the performance of three global FAPAR algorithms (JRC-TIP, ESA/JRC MGVI and Boston University FAPAR) was evaluated over Europe for the year 2011. Results show an overall agreement among FAPAR products on sites having high and low FAPAR values, except for the north-eastern region of Europe characterized by boreal forest and the transition region with tundra biomes, where the Boston product exceeds values in other products by up to 0. 5. Differences in FAPAR estimates over forest biomes suggest that assumptions on structure and optical properties of land surfaces in the different radiative transfer models {{play an important role in}} remote-sensing-derived FAPAR products. Uncertainty assessments were carried out using both quality indicators as proposed by the individual product teams as well as independent theoretical uncertainty estimates obtained with the <b>triple</b> collocation <b>error</b> model. The former revealed consistent spatial patterns but large differences in magnitudes (up to 0. 1) with systematically lower uncertainties for the Boston product. The latter instead suggests similar uncertainty ranges among the three products. Finally, a comparison with ground estimates for the 2009 – 2011 period over four European flux tower sites showed consistent, plausible seasonal variations of remote-sensing-derived FAPAR products. Findings suggest that differences in absolute values and inconsistency in uncertainty representation among FAPAR products are still considerable. Standardization frameworks quantifying the impact of different radiative transfer formulations on the estimation of biophysical variables, independent uncertainty estimation methods and well-defined ground measurement protocols need to be put in place before FAPAR products can be reliably fed into existing biogeochemical process models...|$|R
40|$|Understanding {{the error}} {{structures}} of remotely sensed soil moisture observations {{is essential for}} correctly interpreting observed variations and trends in the data or assimilating them in hydrological or numerical weather prediction models. Nevertheless, a spatially coherent assessment {{of the quality of}} the various globally available datasets is often hampered by the limited availability over space and time of reliable in-situ measurements. As an alternative, this study explores the <b>triple</b> collocation <b>error</b> estimation technique for assessing the relative quality of several globally available soil moisture products from active (ASCAT) and passive (AMSR-E and SSM/I) microwave sensors. The triple collocation is a powerful statistical tool to estimate the root mean square error while simultaneously solving for systematic differences in the climatologies of a set of three linearly related data sources with independent error structures. Prerequisite for this technique is the availability of a sufficiently large number of timely corresponding observations. In addition to the active and passive satellite-based datasets, we used the ERA-Interim and GLDAS-NOAH reanalysis soil moisture datasets as a third, independent reference. The prime objective is to reveal trends in uncertainty related to different observation principles (passive versus active), the use of different frequencies (C-, X-, and Ku-band) for passive microwave observations, and the choice of the independent reference dataset (ERA-Interim versus GLDAS-NOAH). The results suggest that the triple collocation method provides realistic error estimates. Observed spatial trends agree well with the existing theory and studies on the performance of different observation principles and frequencies with respect to land cover and vegetation density. In addition, if all theoretical prerequisites are fulfilled (e. g. a sufficiently large number of common observations is available and errors of the different datasets are uncorrelated) the errors estimated for the remote sensing products are hardly influenced by the choice of the third independent dataset. The results obtained in this study can help us in developing adequate strategies for the combined use of various scatterometer and radiometer-based soil moisture datasets, e. g. for improved flood forecast modelling or the generation of superior multi-mission long-term soil moisture datasets. ...|$|R
40|$|The vast {{majority}} of trisomies in spontaneous abortions (SAB) are single and of maternal origin, most frequently due to meiosis I <b>errors.</b> <b>Triple</b> trisomies are exceedingly rare (∼ 0. 05 % of spontaneous abortions), most often of maternal origin, and associated with increased maternal age. Some trisomic SAB specimens can exhibit abnormal villous morphology simulating a partial hydatidiform mole, a distinct form of hydatidiform mole characterized by diandric triploidy. A SAB specimen from a 27 -year-old woman, G 1 P 0 at 8 weeks gestational age, was reviewed in consultation to address the finding of morphological features suggestive of a partial hydatidiform mole but DNA ploidy analysis yielding a diploid result. The villi were irregularly shaped and hydropic but lacked trophoblastic hyperplasia; p 57 expression was retained. Since fully developed features of a partial hydatidiform mole were lacking, additional analysis was performed. Molecular genotyping and single nucleotide polymorphism array analysis demonstrated biparental diploidy with trisomy of chromosomes 7, 13, and 20, all of paternal origin. The three trisomies may have originated from paternal meiosis II errors, or from mitotic nondisjunction. We believe {{this to be the}} first report of triple trisomy in a SAB confirmed to be of paternal origin...|$|R
40|$|Soil {{moisture}} products {{acquired from}} passive satellite missions {{have been widely}} applied in environmental processes. A primary challenge {{for the use of}} soil moisture products from passive sensors is their reliability. It is crucial to evaluate the reliability of those products before they can be routinely used at a global scale. In this paper, we evaluated the Soil Moisture Active/Passive (SMAP) and the Advanced Microwave Scanning Radiometer (AMSR 2) radiometer soil moisture products against in situ measurements collected from American networks with four statistics, including the mean difference (MD), the root mean squared difference (RMSD), the unbiased root mean square error (ubRMSE) and the correlation coefficient (R). The evaluation results of SMAP and AMSR 2 soil moisture products were compared. Moreover, the <b>triple</b> collocation (TC) <b>error</b> model was used to assess the error among AMSR 2, SMAP and in situ data. The monthly average and daily AMSR 2 and SMAP soil moisture data were analyzed. Different spatial series, temporal series and combined spatial-temporal analysis were carried out. The results reveal that SMAP soil moisture retrievals are generally better than AMSR 2 soil moisture data. The remotely sensed retrievals show the best agreement with in situ measurements over the central Great Plains and cultivated crops throughout the year. In particular, SMAP soil moisture data shows a stable pattern for capturing the spatial distribution of surface soil moisture. Further studies are required for better understanding the SMAP soil moisture product...|$|R
40|$|We {{present a}} global water cycle reanalysis that merges water balance {{estimates}} {{derived from the}} Gravity Recovery And Climate Experiment (GRACE) satellite mission, satellite water level altimetry and off-line estimates from several hydrological models. Error estimates for the sequential data assimilation scheme were derived from available uncertainty information and the <b>triple</b> collocation technique. <b>Errors</b> in four GRACE storage products were estimated to be 11 – 12 mm over land areas, while errors in monthly storage changes derived from five global hydrological models were estimated to be 17 – 28 mm. Prior and posterior water storage estimates were evaluated against independent observations of river water level and discharge, snow water storage and glacier mass loss. Data assimilation improved or maintained agreement overall, although results varied regionally. Uncertainties were greatest in regions where glacier mass loss and subsurface storage decline are both plausible but poorly constrained. We calculated a global water budget for 2003 – 2012. The main changes were {{a net loss of}} polar ice caps (− 342 Gt yr − 1) and mountain glaciers (− 230 Gt yr − 1), with an additional decrease in seasonal snowpack (− 18 Gt yr − 1). Storage increased due to new impoundments (+ 16 Gt yr − 1), but this was compensated by decreases in other surface water bodies (− 10 Gt yr − 1). If the effect of groundwater depletion (− 92 Gt yr − 1) is considered separately, subsurface water storage increased by + 202 Gt yr − 1 due particularly to increased wetness in northern temperate regions and in the seasonally wet tropics of South America and southern Africa. The reanalysis results are publicly available via www. wenfo. org/wald/...|$|R
40|$|Global {{time series}} of the Essential Climate Variable (ECV) soil mositure (SM) is being {{developed}} from passive and active satellite microwave sensors at a coarse spatial resolution with Climate Change Initiative program funded by European Space Agency. This study aims to validate the reliability of ECV SM dataset, and attempts are made to analyze SM trends in cropland. Firstly, in-situ SM measurements during crop growing seasons from 1992 to 2010 for 228 stations across China and 21 stations over cropland of North China Plain (NCP) were employed to validate ECV SM product. Then, the spatiotemporal variations of ECV SM were analyzed during growing period of winter wheat (April-June) and summer maize (July-September) from 1981 to 2010 in NCP. Finally, the possible relationship between SM, precipitation, evapotranspiration and NOVI were explored. Results showed that ECV SM could generally capture the seasonal SM dynamics. The average <b>triple</b> collocation random <b>error</b> of ECV SM in China was 0. 052 m(3) m(- 3) while the error in cropland ranged from 0. 003 to 0. 156 m(3) m(- 3). The averaged Spearman correlation coefficient between ECV SM and all in-situ observations was 0. 42 (p< 0. 01) in China and 0. 43 (p< 0. 01) for cropland over NCP. Spatially, ECV SM was decreasing in most areas during wheat season, whereas the trends of ECV SM were positive in south and negative in north during maize season in NCP, being consistent with the precipitation fluctuation. Overall, ECV SM is potentially suitable for trend analysis in NCP and its validations and analysis will be helpful for further enhancement of the ECV SM product. (C) 2015 Elsevier B. V. All rights reserved...|$|R
40|$|Increasing static {{random access}} memory (SRAM) bitcell density is a major driving force for {{semiconductor}} technology scaling. The industry standard 2 x reduction in SRAM bitcell area per technology node has lead to a proliferation in memory intensive applications as greater memory system capacity can be realized per unit area. Coupled with this increasing capacity is an increasing SRAM system-level soft error rate (SER). Soft errors, caused by galactic radiation and radioactive chip packaging material corrupt a bitcell’s data-state and are a potential cause of catastrophic system failures. Further, reductions in device geometries, design rules, and sensitive node capacitances increase the probability of multiple adjacent bitcells being upset per particle strike to over 30 % of the total SER below the 45 nm process node. Traditionally, these upsets have been addressed using a simple error correction code (ECC) combined with word interleaving. With continued scaling however, errors beyond this setup begin to emerge. Although more powerful ECCs exist, they come at an increased overhead in terms of area and latency. Additionally, interleaving adds complexity to the system and may not always be feasible for the given architecture. In this thesis, a new class of ECC targeted toward adjacent multi-bit upsets (MBU) is proposed and analyzed. These codes present a tradeoff between the currently popular single error correcting-double error detecting (SEC-DED) ECCs used in SRAMs (that are unable to correct MBUs), and the more robust multi-bit ECC schemes used for MBU reliability. The proposed codes are evaluated and compared against other ECCs using a custom test suite and multi-bit error channel model developed in Matlab as well as Verilog hardware description language (HDL) implementations synthesized using Synopsys Design Compiler and a commercial 65 nm bulk CMOS standard cell library. Simulation results show that for the same check-bit overhead as a conventional 64 data-bit SEC-DED code, the proposed scheme provides a corrected-SER approximately equal to the Bose-Chaudhuri- Hocquenghem (BCH) double error correcting (DEC) code, and a 4. 38 x improvement over the SEC-DED code in the same error channel. While, for 3 additional check-bits (still 3 less than the BCH DEC code), a <b>triple</b> adjacent <b>error</b> correcting version of the proposed code provides a 2. 35 x improvement in corrected-SER over the BCH DEC code for 90. 9 % less ECC circuit area and 17. 4 % less error correction delay. For further verification, a 0. 4 - 1. 0 V 75 kb single-cycle SRAM macro protected with a programmable, up-to- 3 -adjacent-bit-correcting version of the proposed ECC has been fab- ricated in a commercial 28 nm bulk CMOS process. The SRAM macro has undergone neu- tron irradiation testing at the TRIUMF Neutron Irradiation Facility in Vancouver, Canada. Measurements results show a 189 x improvement in SER over an unprotected memory with no ECC enabled and a 5 x improvement over a traditional single-error-correction (SEC) code at 0. 5 V using 1 -way interleaving for the same number of check-bits. This is compa- rable with the 4. 38 x improvement observed in simulation. Measurement results confirm an average active energy of 0. 015 fJ/bit at 0. 4 V, and average 80 mV reduction in VDDMIN across eight packaged chips by enabling the ECC. Both the SRAM macro and ECC circuit were designed for dynamic voltage and frequency scaling for both nominal and low voltage applications using a full-custom circuit design flow...|$|R

