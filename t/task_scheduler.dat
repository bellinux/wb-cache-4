281|156|Public
5|$|Furthermore, scans are {{no longer}} {{scheduled}} through the Windows <b>Task</b> <b>Scheduler,</b> but through the Symantec's proprietary one, which performs tasks while the computer is idle (i.e., when the user is away from the computer).|$|E
25|$|Windows Vista {{includes}} an overhauled <b>Task</b> <b>Scheduler</b> that uses hierarchical folders of tasks. The <b>Task</b> <b>Scheduler</b> can run programs, send email, or display a message. The <b>Task</b> <b>Scheduler</b> can also now {{be triggered by}} an XPath expression for filtering events from the Windows Event Log, and can respond to a workstation's lock or unlock, and {{as well as the}} connection or disconnection to the machine from a Remote Desktop. The <b>Task</b> <b>Scheduler</b> tasks can be scripted in VBScript, JScript, or PowerShell.|$|E
25|$|Windows Vista {{contains}} {{a range of}} new technologies and features that are intended to help network administrators and power users better manage their systems. Notable changes include a complete replacement for NTLDR based on the Windows Preinstallation Environment, completely rewritten image-based deployment mechanisms, a significantly improved <b>Task</b> <b>Scheduler,</b> a revamped event logging infrastructure, Windows Recovery Environment, support for per-application Remote Desktop sessions, new diagnostic, health monitoring and system administration tools, {{and a range of}} new Group Policy settings covering many of the new features.|$|E
30|$|For instance, {{suppose there}} are two cloud <b>task</b> <b>schedulers</b> (schedA and schedB) for cloud users. The cloud <b>task</b> <b>schedulers</b> deploy the <b>tasks</b> of the users {{according}} to the specification of their algorithm. If the expected makespan of schedA is 151  s and that of schedB is 130  s, then the user will choose schedB for the tasks deployment since the user will pay more as much as schedA takes longer than schedB (for 21  s) if the user chooses schedB.|$|R
30|$|There {{are three}} {{categories}} for task scheduling strategies in cloud computing environments: focusing on performance by improving of cloud <b>task</b> <b>schedulers</b> (Category 1), considering multi-objective (e.g., QoS, energy consumption, financial cost, and SLA) for finding optimal solutions (Category 2), and using nature-inspired optimization algorithms to solve cloud task scheduling problems (Category 3).|$|R
40|$|This {{thesis is}} {{concerned}} with the design and implementation of single-processor embedded real-time systems with highly predictable behaviour and strict constraints on resource usage. The main aim of this research is to identify the sources of unpredictable behaviour in such systems – exhibited as timing jitter- when a time-triggered pre-emptive task scheduling approach is adopted, and then provide software based techniques to enhance their temporal predictability. The thesis provides a review of related previous work on predictable real-time task scheduling, as well as resource-access control methods for maintaining predictable real-time system behaviour through the prevention of priority inversion and other related problems. The design and implementation of the time-triggered hybrid (TTH), time-triggered rate-monotonic (TTRM), and time-triggered deadline-monotonic (TTDM) <b>task</b> <b>schedulers</b> is discussed in detail as they provide the most predictable behaviour within the category of pre-emptive <b>task</b> <b>schedulers.</b> For that reason, they will be use...|$|R
50|$|<b>Task</b> <b>Scheduler</b> 2.0 exposes an API {{to allow}} {{computer}} programs and scripts create tasks. It consists of 42 COM interfaces. The Windows API does not, however, include a managed wrapper for <b>Task</b> <b>Scheduler</b> though an open source implementation exists. The job files for <b>Task</b> <b>Scheduler</b> 2.0 are XML-based, and are human-readable, conforming to the <b>Task</b> <b>Scheduler</b> Schema. Although possible, Microsoft advises {{not to create}} the job files by hand, and instead, use the <b>Task</b> <b>Scheduler</b> API.|$|E
5000|$|<b>Task</b> <b>Scheduler</b> schema: <b>Task</b> <b>Scheduler</b> allows {{creating}} and managing tasks through XML-formatted documents.|$|E
5000|$|Windows Vista {{includes}} an overhauled <b>Task</b> <b>Scheduler</b> that uses hierarchical folders of tasks. The <b>Task</b> <b>Scheduler</b> can run programs, send email, or display a message. The <b>Task</b> <b>Scheduler</b> can also now {{be triggered by}} an XPath expression for filtering events from the Windows Event Log, and can respond to a workstation's lock or unlock, and {{as well as the}} connection or disconnection to the machine from a Remote Desktop. The <b>Task</b> <b>Scheduler</b> tasks can be scripted in VBScript, JScript, or PowerShell.|$|E
40|$|In {{order to}} harness the {{additional}} compute resources of future Multi-core Architectures (MCAs) with many cores, applications must expose their thread-level parallelism to the hardware. One common approach to doing this is to decompose a program into parallel “tasks ” and allow an underlying software layer to schedule these tasks on different threads. Software task scheduling can provide good parallel performance as long as tasks are large compared to the software overhead. We examine a set of Recognition, Mining, and Synthesis (RMS) applications and find {{that a significant number}} have small tasks for which software <b>task</b> <b>schedulers</b> achieve only limited parallel speedups. We propose a hardware technique to accelerate dynamic task scheduling on MCAs with many cores. We compare this hardware to highly tuned software <b>task</b> <b>schedulers</b> for a set of RMS benchmarks with small tasks. The proposed hardware delivers significant performance improvements over the best software scheduler: for 64 cores, it is 88 % faster on a set of loop-parallel benchmarks and 98 % faster on a set of task-parallel benchmarks...|$|R
40|$|From {{the humble}} {{infinite}} loop to the priority-based preemptive RTOS and beyond, scheduling options are everywhere to be found. This article offers a survey and comparison. Many {{different kinds of}} <b>task</b> <b>schedulers</b> are available to software developers of embedded and real-time systems. They range from a simple cyclic executive that you can build “at home, ” to the many prioritybased preemptive schedulers that are available commercially and beyond. Table 1 shows a number of <b>task</b> <b>schedulers,</b> including the sorts of software tasks and hardware device interfaces they support. Depending {{on the nature of}} your application and your I/O requirements, you can choose the appropriate one from a wide spectrum of schedulers that will be described here. The endless loop For very simple embedded systems, the most basic way to write application software is as an endless loop. The activities programmed within the loop are executed in sequence. Branches and nested loops are okay, as long as when the code is done executing, it loops back to the beginning for another go-round...|$|R
40|$|In {{reconfigurable}} platform, before convert {{and download}} program into real hardware, reliable estimation of speedup factor {{is of great}} importance for <b>task</b> <b>schedulers.</b> In this paper, a novel technique for speedup factor estimation is proposed. From the event patterns collected by hardware counters built in modern processors, a formula is given to estimate speedup factor of target process. Experiments on programs from SPEC 2006 show that the speedup feature is able to be estimated at an acceptable cost...|$|R
50|$|<b>Task</b> <b>Scheduler</b> is a {{component}} of Microsoft Windows that provides the ability to schedule the launch of programs or scripts at pre-defined times or after specified time intervals: job scheduling (task scheduling). It was first introduced in the Microsoft Plus! for Windows 95 as System Agent but was renamed to <b>Task</b> <b>Scheduler</b> in Internet Explorer 4.0 and Windows 98. The Windows Event Log service must be running before the <b>Task</b> <b>Scheduler</b> starts up.|$|E
50|$|Note {{that the}} <b>Task</b> <b>Scheduler</b> {{is the process}} {{responsible}} for parsing the trace data collected by the prefetcher and writing files to the prefetcher directory. As a result, the prefetcher will not operate correctly if the <b>Task</b> <b>Scheduler</b> service is not started.|$|E
50|$|<b>Task</b> <b>Scheduler</b> 2.0 was {{introduced}} with Windows Vista and included in Windows Server 2008 as well. The redesigned <b>Task</b> <b>Scheduler</b> user interface is now based on Management Console. In addition to running tasks on scheduled times or specified intervals, <b>Task</b> <b>Scheduler</b> 2.0 also supports calendar and event-based triggers, such as starting a task when a particular event is logged {{to the event}} log, or when a combination of events has occurred. Also, several tasks that are triggered by the same event can be configured to run either simultaneously or in a pre-determined chained sequence {{of a series of}} actions, instead of having to create multiple scheduled tasks. Tasks can also be configured to run based on system status such as being idle for a pre-configured amount of time, on startup, logoff, or only during or for a specified time. XPath expressions can be used to filter events from the Windows Event Log. Tasks can also be delayed for a specified time after the triggering event has occurred, or repeat until some other event occurs. Actions that need to be done if a task fails can also be configured. The actions that can be taken in response to triggers, both event-based as well as time-based, not only include launching applications but also take a number of custom actions. <b>Task</b> <b>Scheduler</b> includes a number of actions built-in, spanning a number of applications; including send an e-mail, show a message box, or fire a COM handler when it is triggered. Custom actions can also be specified using the <b>Task</b> <b>Scheduler</b> API. <b>Task</b> <b>Scheduler</b> keeps a history log of all execution details of all the tasks.. Windows Vista uses <b>Task</b> <b>Scheduler</b> 2.0 to run various system-level tasks; consequently, the <b>Task</b> <b>Scheduler</b> service can no longer be disabled (except with a simple registry tweak).|$|E
40|$|The {{problem of}} {{accurately}} estimating the processor power consumption has generated significant interest among computer architects {{in the last}} decade. With the focus on green computing intensifying, increasing number of task management applications have become power aware in last few years. Hence, {{the need for a}} fast and accurate power model is greater than ever. In addition, today’s multi-core processors demand <b>task</b> <b>schedulers</b> to balance the performance requirements, power budget and thermal constraints. This thesis addresses this requirement by presenting a percore power model based upon performance monitoring counters and temperature data. PMC based power models provide a straightforward and fast way of analyzing the activity of processor’s underlying microarchitecture. The advantage of our model is that it is general enough to be ported and scaled across different platforms with ease, fast enough to be used online by <b>task</b> <b>schedulers,</b> and it requires no knowledge of individual applications. During this thesis work, we validated the model on three different (two- to eight-core) platforms. The model accurately estimates core power consumption, exhibiting 1. 8 %- 4. 8 % per-suite median error on the NAS, SPEC OMP, and SPEC 2006 benchmarks (and 1. 6 %- 4. 4 % overall) ...|$|R
5000|$|Synchronize & Schedule: User {{can create}} a sync session to make his file {{up-to-date}} or a <b>task</b> for <b>scheduler</b> to perform routine work ...|$|R
30|$|In MapReduce, {{there are}} some general <b>task</b> <b>{{scheduler}}s,</b> such as FIFO scheduler [15], capacity-based scheduler [16], and fairness-based scheduler [17]. Concerning the specific applications, Sandholm and Lai [18] proposed a scheduling algorithm, which allows users to adjust the required computing resources dynamically according {{to the importance of}} MapReduce tasks, Zaharia et al. [19] proposed a scheduling algorithm for heterogeneous cluster environments, and Kwon et al. [20] proposed the Skewtune algorithm for dealing with skewness in the processes of MapReduce tasks.|$|R
5000|$|... 0x80041311: Corruption was {{detected}} in the <b>Task</b> <b>Scheduler</b> security database ...|$|E
5000|$|... a <b>task</b> <b>scheduler,</b> for {{scheduling}} daily maintenance, etc. (ver. 13.00); ...|$|E
5000|$|... 0x00041325: The <b>Task</b> <b>Scheduler</b> {{service has}} asked the task to run.|$|E
40|$|The {{problem of}} {{execution}} management of client’s tasks and optimal management of cluster’s computing resources {{is one of}} the key problems in grid. In this paper the detailed investigation and comparison of <b>task</b> <b>schedulers</b> and <b>task</b> scheduling techniques has been performed with respect to the result quality and throughput. The results of conducted computing experiments have found out the critical scheduler’s components and preferable scheduling approaches which are promising and indicate the ways of further development of grid optimization methods. </p...|$|R
40|$|Abstract. The {{management}} {{of personal and}} shared schedules {{is limited by the}} lack of flexibility of time management services. Online calendar managers fail to support reasoning about time and multi-user activities. <b>Task</b> <b>schedulers</b> fully control the temporal allocation of events without involving their users in decision making. As an attempt to address such issues, this paper presents a mixedinitiative scheduling model supporting interactive calendar management. Our model is applied in MARA (Mixed-initiAtive calendaR mAnager), which enables users to solve scheduling problems by incrementally exploring the solution space...|$|R
40|$|Chip multiprocessors (CMPs) are now commonplace, and {{the number}} of cores on a CMP is likely to grow steadily. However, in order to harness the {{additional}} compute resources of a CMP, applications must expose their thread-level parallelism to the hardware. One common approach to doing this is to decompose a program into parallel “tasks ” and allow an underlying software layer to schedule these tasks to different threads. Software task scheduling can provide good parallel performance as long as tasks are large compared to the software overheads. We examine a set of applications from an important emerging domain: Recognition, Mining, and Synthesis (RMS). Many RMS applications are compute-intensive and have abundant thread-level parallelism, and are therefore good targets for running on a CMP. However, a significant number have small tasks for which software <b>task</b> <b>schedulers</b> achieve only limited parallel speedups. We propose Carbon, a hardware technique to accelerate dynamic task scheduling on scalable CMPs. Carbon has relatively simple hardware, most of which can be placed far from the cores. We compare Carbon to some highly tuned software <b>task</b> <b>schedulers</b> for a set of RMS benchmarks with small tasks. Carbon delivers significant performance improvements over the best software scheduler: on average for 64 cores, 68 % faster on a set of loop-parallel benchmarks, and 109 % faster on a set of task-parallel benchmarks...|$|R
5000|$|... 0x8004130C: The <b>Task</b> <b>Scheduler</b> {{service is}} not {{installed}} on this computer.|$|E
5000|$|... 0x80041312: <b>Task</b> <b>Scheduler</b> {{security}} services are available only on Windows NT.|$|E
5000|$|Service Control Manager in {{conjunction}} with the Windows <b>Task</b> <b>Scheduler</b> supports trigger-start services.|$|E
40|$|Large-scale data {{analytics}} frameworks are shifting towards shorter task durations and larger degrees of parallelism to provide low latency. Scheduling highly parallel jobs that complete {{in hundreds of}} milliseconds poses a major challenge for <b>task</b> <b>schedulers,</b> which will need to schedule millions of tasks per second on appropriate machines while offering millisecond-level latency and high availability. We demonstrate that a decentralized, randomized sampling approach provides near-optimal performance while avoiding the throughput and availability limitations of a centralized design. We implement and deploy our scheduler, Sparrow, on a 110 -machine cluster and demonstrate that Sparrow performs within 12 % of an ideal scheduler. ...|$|R
40|$|This {{thesis is}} {{concerned}} with the design and implementation of single-processor embedded real-time systems with highly predictable behaviour and strict constraints on resource usage. The main aim of this research is to identify the sources of unpredictable behaviour in such systems – exhibited as timing jitter - when a time-triggered pre-emptive task scheduling approach is adopted, and then provide software based techniques to enhance their temporal predictability. The thesis provides a review of related previous work on predictable real-time task scheduling, as well as resource-access control methods for maintaining predictable real-time system behaviour through the prevention of priority inversion and other related problems. The design and implementation of the time-triggered hybrid (TTH), time-triggered rate-monotonic (TTRM), and time-triggered deadline-monotonic (TTDM) <b>task</b> <b>schedulers</b> is discussed in detail as they provide the most predictable behaviour within the category of pre-emptive <b>task</b> <b>schedulers.</b> For that reason, they will be used as the software platforms in the experimental part of this research. Two novel software techniques for enhancing the temporal predictability in systems utilising time-triggered schedulers are introduced. The first software technique presented is a resource-access control protocol named Timed Resource-Access Protocol (TRAP). This protocol is designed to avoid the problems of priority inversion, chained blocking and deadlocks while coercing system tasks to exhibit timing predictability that is proportional to their significance in the system. This appears in the decreasing levels of task finishing jitter as the significance of tasks in the system increases. The second technique is named Planned Pre-emption (PP). This technique is aimed at eliminating the scheduling unpredictability due to variable timer interrupt service time in time-triggered scheduling systems. The impact of this technique appears in the considerable reduction in <b>scheduler</b> <b>task</b> release jitter. Finally, the thesis is concluded by a discussion and a summary of the work presented. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|Managing {{criticality}} in task-based programming models opens a {{wide range}} of performance and power optimization opportunities in future manycore systems. Criticality aware <b>task</b> <b>schedulers</b> can benefit from these opportunities by scheduling tasks to the most appropriate cores. However, these schedulers may suffer from priority inversion and static binding problems that limit their expected improvements. Based on the observation that task criticality information can be exploited to drive hardware reconfigurations, we propose a Criticality Aware Task Acceleration (CATA) mechanism that dynamically adapts the computational power of a task depending on its criticality. As a result, CATA achieves significant improvements over a baseline static scheduler, reaching average improvements up to 18. 4...|$|R
50|$|<b>Task</b> <b>Scheduler</b> - Allows {{scheduling}} of {{the flow}} execution in a specific date or pattern.|$|E
5000|$|... 0x80041323: The <b>Task</b> <b>Scheduler</b> {{service is}} {{too busy to}} handle your request. Please try again later.|$|E
5000|$|... 0x8004130F: No account {{information}} {{could be found}} in the <b>Task</b> <b>Scheduler</b> security database for the task indicated.|$|E
40|$|Through {{the past}} years, several {{scheduling}} heuristics {{were introduced to}} improve the performance of task-based ap-plications, with schedulers increasingly becoming aware of memory-related bottlenecks such as data locality and cachesharing. However, {{there are not many}} useful tools that pro-vide insights to developers about why and where dierentschedulers do better scheduling, and how this is related tothe applications' performance. In this work we present atechnique to characterize dierent <b>task</b> <b>schedulers</b> based onthe analysis of data reuse, providing high-level, quantitativeinformation that can be directly correlated with tasks per-formance variation. This exible insight is key for optimiza-tion in many contexts, including data locality, throughput, memory footprint or even energy eciency. Resource Sharing ModelingUPMAR...|$|R
5000|$|Scheduler, {{introduced}} in Laravel 5.0, is {{an addition to}} the Artisan that allows programmatic scheduling of periodically executed <b>tasks.</b> Internally, <b>Scheduler</b> relies on the cron daemon to run a single Artisan job that, in turn, executes the configured tasks.|$|R
40|$|In {{this paper}} we revisit the {{admission}} of applications upon a processor share modeled by the explicit-deadline periodic (EDP) resource-supply model. In particular, we consider applications that represent a fixed-priority sporadic task system. Existing works heavily build on the analysis of a hierarchy of preemptive <b>task</b> <b>schedulers.</b> We instead consider the feasibility of such tasks and applications for a hierarchy of deferredpreemptive schedulers, {{so that we can}} efficiently deal with the scenario where tasks and applications execute their work in nonpreemptive chunks. Our model therefore gives better control over preemptions of tasks of different applications. We present exact analysis for deferred-preemptive scheduling of tasks on EDP resources. In addition, we propose algorithms for dimensioning an application’s budget tightly...|$|R
