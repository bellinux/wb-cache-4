2|27|Public
50|$|Pin was {{designed}} for <b>tool</b> <b>portability,</b> and despite JIT compiling from one ISA to the same ISA (and not using a single intermediate representation for all code), most of its APIs are architecture and operating system independent. It was also designed to be portable itself, carefully isolating platform-specific code from generic code, allowing the fast adaptation of Pin to new platforms. Approximately half of the code is generic {{and the rest is}} either architecture or OS dependent.|$|E
40|$|A five-year effort {{under the}} Ada Joint Program Office has {{developed}} a proposed standard for a host system interface as seen by tools running in an Ada Programming Support Environment (APSE). Standardization of this interface as DOD-STD- 1838 A will {{have a number of}} desirable effects for the Department of Defense, including <b>tool</b> <b>portability,</b> tool integration, data transportability, encouragement of a market in portable tools, and better programmer productivity. As the capability of tools {{to communicate with each other}} is a central requirement in APSEs, the Common APSE Interface Set (CAIS) has paid particular attention to facilitate such communication in a host-independent fashion. CAIS incorporates a well-integrated set of concepts tuned to the needs of writers and users of integrated tool sets. This paper covers several of these concepts: the entity management system used in place of a traditional filing system, object typing with inheritance, process control including atomic transactions, access control and security, input/output methods, support for distributed resource control, and facilities for inter-system data transport...|$|E
5000|$|Survival kit <b>tools</b> {{emphasize}} <b>portability</b> and versatility. <b>Tools</b> {{recommended for}} {{many types of}} survival kit include: ...|$|R
40|$|Abstract — Web-based {{learning}} {{is becoming an}} important tool in education. However, the cost of producing an on-line course is high. This paper discuses the design and implementation of WebLS system which is aiming to assist traditional instructors to archive their learning materials on the web. WebLS features web-based authoring <b>tools,</b> <b>portability</b> on various platforms, and flexibility of XML-based storage allowing the learning materials to be delivered in many different ways...|$|R
40|$|URL] {{applications}} {{have become}} popular work <b>tools.</b> <b>Portability</b> {{and ease of}} Internet connectivity are characteristics that favor this adoption. However, mobile applications sometimes incorrectly process events associated with the user-interaction features. These features include content presentation or navigation. Rotating the devices, and gestures such as scroll or zoom into screens are some examples. There {{is a need to}} assess the quality with which mobile applications are processing these user-interaction features in order to improve their performance. In this paper, we present a top-down design approach for an automated testing framework for mobile applications. Our framework integrates digital image processing, GUI information, and historical bug information to identify new bugs based on user-interaction features. Our framework captures images before and after applying the user-interaction features and uses the SURF algorithm to identify interest points in each image. We compared interest points to note differences on the screens before and after applying the user-interaction features. This differences helps to find bugs in mobile applications. The first results show that it is feasible to identify bugs with user-interaction features using the proposed technique...|$|R
40|$|This article aims {{to develop}} a fuzzy Multicriteria Decision Making (MCDM) tool that equips with Analytic Hierarchy Process (AHP) {{framework}} to help users in semi-structured and unstructured decision making tasks. The <b>tool</b> provides <b>portability</b> and adaptability features by deploying the software on web platform. In addition, this system provides an integrated domain reference channel via a database connection to assist the user obtains relevant information regarding the problem domain before constructing the AHP hierarchy attributes. Our decision making tool combines the characteristics of real time information retrieval through Internet and MCDM problem analytical processing logic...|$|R
40|$|This article {{deals with}} the {{implementation}} of <b>tool</b> allowing the <b>portability</b> of the digital mock-up for architectural projects on the building renovation place and the use of representation layers giving functions adapted to the different workers open to work in this place. Our test case is applied to renovation works on old windows in an ancient abbey where it is necessary to improve the thermal efficiency. International audienceThis article {{deals with the}} implementation of <b>tool</b> allowing the <b>portability</b> of the digital mock-up for architectural projects on the building renovation place and the use of representation layers giving functions adapted to the different workers open to work in this place. Our test case is applied to renovation works on old windows in an ancient abbey where it is necessary to improve the thermal efficiency...|$|R
30|$|An {{interesting}} {{study could}} {{be performed by}} porting backprojection to several other HPRC systems, some {{of which can be}} targeted by high-level design languages. This would be the first step toward developing a benchmark suite for testing HPRC systems; however, without significant <b>tool</b> support-to-support application <b>portability</b> between HPRC platforms, this process would be daunting.|$|R
40|$|Abstract: This article aims {{to develop}} a fuzzy Multicriteria Decision Making (MCDM) tool that equips with Analytic Hierarchy Process (AHP) {{framework}} to help users in semi-structured and unstructured decision making tasks. The <b>tool</b> provides <b>portability</b> and adaptability features by deploying the software on web platform. In addition, this system provides an integrated domain reference channel via a database connection to assist the user obtains relevant information regarding the problem domain before constructing the AHP hierarchy attributes. Our decision making tool combines the characteristics of real time information retrieval through Internet and MCDM problem analytical processing logic. Key words: Multicriteria decision making, analytic hierarchy process (AHP), fuzzy set theor...|$|R
30|$|Finally, each HPRC {{system has}} its own {{programming}} method that is generally incompatible with other systems. The standardization of programming interfaces would make the development of design tools easier, and would also increase application developer productivity when moving from one machine to the next. Alternately, <b>tools</b> to support <b>portability</b> of HPRC applications such as the VForce project [18] would also help HPRC developers.|$|R
40|$|This paper proposes an open objectoriented {{architecture}} called FIRST (Framework for Interoperable Resources, Services and Tools). This {{distributed software}} tool development framework addresses the key objectives of <b>tool</b> interoperability, <b>portability</b> and extensibility. A conforming tool {{can thus be}} used {{on a variety of}} platforms, presenting a consistent high-level view of its interactions with parallel (or distributed) programs and machines. Applications are dynamically instrumented with instructions at run-time and can therefore benefit from a variety of conforming software tools without need for recompilation. The major components and their principal interactions are described along with some examples of the different types of tool that can easily be produced with the framework. Keywords: CORBA, portability, dynamic instrumentation, software tools, interoperability, framework. 1 Introduction Despite the existence of many powerful tools supporting practical application engineering [...] ...|$|R
40|$|This paper {{discusses}} {{an architecture}} for real-time, distributed (parallel) knowledge-based systems called the Parallel Real-time Artificial Intelligence System (PRAIS). PRAIS strives for transparently parallelizing production (rule-based) systems, even when under real-time constraints. PRAIS accomplishes these goals by incorporating a dynamic task scheduler, operating system extensions for fact handling, and message-passing among multiple copies of CLIPS executing on a virtual blackboard. This distributed knowledge-based system <b>tool</b> uses the <b>portability</b> of CLIPS and common message-passing protocols to operate over a heterogeneous network of processors...|$|R
40|$|Software {{applications}} for computer-based patient records require substantial development investments. Portable, open software architectures are {{one way to}} delay or avoid software application obsolescence. The Clinical Management System at Temple University School of Dentistry uses a portable, GUI-based, object-oriented client-server architecture. Two main criteria determined this approach: preservation of investment in software development and a smooth migration path to a Computer-based Patient Record. The application is separated into three layers: graphical user interface, database interface, and application functionality Implementation with generic cross-platform development <b>tools</b> ensures maximum <b>portability...</b>|$|R
40|$|While a {{large number}} of tools have been {{developed}} to support application portability, high performance application developers often prefer to use vendor-provided, non-portable programming interfaces. This phenomena indicates the mismatch between user priorities and tool capabilities. This paper summarizes the results of a user survey and a developer survey. The user survey has revealed the user priorities and resulted in three criteria for evaluating <b>tool</b> support for <b>portability.</b> The developer survey has resulted in the evaluation of portability support and indicated the possibilities and difficulties of improvements...|$|R
40|$|Typewritten ms. This {{thesis is}} {{concerned}} with the design and construction of a high voltage generator capable of producing steady Potentials of approximately 100, 000 volts. The generator is designed to be used principally for acceleration of ions or protons for use in nuclear reactions. Voltages of this nature may be used quite efficiently for producing low energy neutrons in a deuteron-deuterium reaction. Other reactions which are of interest in this ränge are the proton-lithium, protonboron and proton-fluorine reactions. (10). In addition to the above uses, the generator may be used in any apparatus which requires high DC potentials but does not draw more than a few hundred microamperes. The apparatus is of a semi-portable nature capable of being transported from one room to another like a laboratory <b>tool.</b> This <b>portability</b> is a radical departure from previous apparatus of this type. The circuit used is a form of the Cockcroft- Walton (6) or Greinacher (7) voltage multiplier...|$|R
40|$|Empirical {{performance}} evaluation of parallel systems and applications can generate {{significant amounts of}} per-formance data and analysis results from multiple ex-periments as performance is investigated and problems diagnosed. Hence, the management of performance in-formation is a core component of performance analy-sis tools. To better support <b>tool</b> integration, <b>portability,</b> and reuse, {{there is a strong}} motivation to develop per-formance data management technology that can provide a common foundation for performance data storage, ac-cess, merging, and analysis. This paper presents the de-sign and implementation of the Performance Data Man-agement Framework (PerfDMF). PerfDMF addresses objectives of performance tool integration, interopera-tion, and reuse by providing common data storage, ac-cess, and analysis infrastructure for parallel performance profiles. PerfDMF includes an extensible parallel profile data schema and relational database schema, a profile query and analysis programming interface, and an ex-tendible toolkit for profile import/export and standard analysis. We describe the PerfDMF objectives and ar-chitecture, give detailed explanation of the major compo-nents, and show examples of PerfDMF application. 1...|$|R
40|$|FPGA {{overlays}} {{have shown}} the potential to improve designers’ productivity through balancing flexibility and ease of configuration of the underlying fabric while maintaining considerable overall performance promised by FPGAs. To truly facilitate full application acceleration, it is often necessary to also include a highly efficient processor that integrates and collaborates with the accelerators while maintaining the benefits of being implemented within the same overlay framework. This thesis presents an open-source soft processor that is tightly-coupled with FPGA accelerator {{as part of an}} overlay framework. RISC-V is chosen as the instruction set for its openness and simplicity, and the soft processor is designed as a 4 -stage pipeline to balance resource consumption and performance when implemented on FPGAs. The processor is generically implemented so as to promote design portability and compatibility across different FPGA platforms. Experiment shows that the integrated software-hardware applications using the proposed tightly-coupled architecture achieve comparable performance as hardware-only accelerators while the proposed architecture provides additional run-time flexibility. The processor can be synthesized to both low-end and high-performance FPGA families from different vendors, achieving the highest frequency of 268 : 67 MHz on Virtex- 7 device. Synthesized results of the soft processor also display improvement on FPGA resource consumption and efficiency when compared to existing RISC-V design. In addition, this thesis also presents an FPGA-centric approach that allows gateware to directly access the virtual memory space as part of the executing process without involving the CPU. It allows efficient access to memory in heterogeneous systems and complements traditional software-centric approach by providing a simplified memory access model to improve designers’ productivity and high-level compilation <b>tools</b> <b>portability.</b> In this approach, a caching address translation buffer was implemented alongside the user FPGA gateware to provide runtime mapping between virtual and physical memory addresses. It coordinates with the OS running on the CPU to update address translations and to maintain memory consistency. The system was implemented on a commercial off-the-shelf FPGA add-on card to demonstrate the viability of such approach in low-cost systems. Experiment with a 2 D stencil computing application implemented with this FPGA-centric approach results in reasonable performance improvement when compared to a typical software-centric implementation; while the number of context switches between FPGA and CPU in both kernel and user mode was significantly reduced, freeing the CPU for other concurrent user tasks. published_or_final_versionElectrical and Electronic EngineeringMasterMaster of Philosoph...|$|R
40|$|Our main {{motivation}} {{is to build}} general and adaptable linguistic tools and we have faced the problem of their portability. We first make a quick de- scription of the linguistic tools we have at hand and we explain why linguistic tools, unlike other software <b>tools,</b> present particular <b>portability</b> problems. We then discuss code portability and also data portability and we describe the method we have used for a French lexicon, showing that portability leads to a more "natural" computational lexicon. We then propose {{the use of a}} command language to intcrfitcc the tools with tnom complex applications and we show that this technique l'acilitates integnttion of tools from various sources, entails a better exploitation of linguistic resources and makes easier the distribution of tools on several machines...|$|R
40|$|The {{scientific}} computing landscape {{has evolved}} {{dramatically in the}} past few years, with new schemes for organizing and storing data that reflect the growth in size and complexity of astronomical data sets. In response to this changing landscape, we are, over the next two years, deploying the next generation of the Montage toolkit ([ascl: 1010. 036]). The first release (October 2015) supports multi-dimensional data sets ("data cubes"), and insertion of XMP/AVM tags that allows images to "drop-in" to the WWT. The same release offers a beta-version of web-based interactive visualization of images; this includes wrappers for visualization in Python. Subsequent releases will support HEALPix (now standard in cosmic background experiments); incorporation of Montage into package managers (which enable automated management of software builds), and support for a library that will enable Montage to be called directly from Python. This next generation toolkit will inherit the architectural benefits of the current engine - component based <b>tools,</b> ANSI-C <b>portability</b> across Unix platforms and scalability for distributed processing. With the expanded functionality under development, Montage can be viewed not simply as a mosaic engine, but as a scalable, portable toolkit for managing, organizing and processing images. Comment: 4 pages, ADASS XXV, Sydney, Australi...|$|R
40|$|Extensions to an {{architecture}} for real-time, distributed (parallel) knowledge-based systems called the Parallel Real-time Artificial Intelligence System (PRAIS) are discussed. PRAIS strives for transparently parallelizing production (rule-based) systems, even under real-time constraints. PRAIS accomplished these goals (presented {{at the first}} annual C Language Integrated Production System (CLIPS) conference) by incorporating a dynamic task scheduler, operating system extensions for fact handling, and message-passing among multiple copies of CLIPS executing on a virtual blackboard. This distributed knowledge-based system <b>tool</b> uses the <b>portability</b> of CLIPS and common message-passing protocols to operate over a heterogeneous network of processors. Results using the original PRAIS architecture over a network of Sun 3 's, Sun 4 's and VAX's are presented. Mechanisms using the producer-consumer model to extend the architecture for fault-tolerance and distributed truth maintenance initiation are also discussed...|$|R
40|$|The RAPID tool {{facilitates}} {{the analysis and}} the visualization of data residing in arbitrary text files. It differs from other analysis applications {{in the way it}} selects and operates on data. In RAPID, data elements are directly retrieved from the unstructured text files using pattern-matching. For this purpose, we use the Perl language. This language was especially designed for efficient text scanning and thus provides powerful support for pattern-matching. Moreover, the fact that Perl is an interpreted script language enhances our <b>tool's</b> extensibility and <b>portability</b> significantly. In this paper, we describe the RAPID tool and discuss some of its design and implementation issues. 1 Introduction Computer experiments, such as simulations, typically generate a vast amount of output. Since manual interpretation of the data is generally not feasible, {{it is important to have}} the disposal of good analysis tools. Using all kinds of statistical methods and visualization techniques, these too [...] ...|$|R
40|$|Learning Management Systems (i. e. LMS) {{is one of}} {{the most}} popular {{solutions}} towards the e-Learning objective in different universities all around the world, where this environments are used to not only deliver contents but to perform assessments, tests and other tasks related to learning. Although, there are popular LMS such as Moodle, and more developed, such as Chamilo, there is no assessment/test portability among their LMS. Each assessment export formats make difficult to transfer well done Moodle-based online courses into young platforms such as Chamilo. The purpose of this paper is to address this portability issue and to show possibility of exporting Moodle assessment data (i. e. Moodle XML), into a more standardized format, which is IMS Question & Test Interoperability (IMS QTI). That can be used not only in Chamilo, but also other LMSs globally. The present paper shows the first approach towards a more global <b>portability</b> <b>tool</b> in which not only assessments but the whole structure of the course could be easily exported to other platforms. Contribution of this work is providing data exchange between LMSs...|$|R
40|$|Developing {{and testing}} a new {{debugging}} tool on {{a collection of}} n parallel machines would require developing n implementations of that tool, one for each machine. Re-implementation is also required to run existing distributed programs (programs developed for a specific target machine) on some other system. <b>Portability</b> <b>tools</b> do exist which allow users to develop programs using communication primitives that have been implemented on a collection of distributed machines. However, they {{do not apply to}} existing programs which use the primitive operations of a particular machine. This paper describes the design of Earl, a system for program portability and the portable implementing and testing of debugging techniques for message-passing machines. A message-passing program (written for some parallel machine) is linked with a speciallibrary that maps the machine's native message-passing primitives to our generic set. Another group of libraries maps the generic set back to the native primitives of some- but not necessarily the same, parallel machine. To test a debugging tool using Earl, only a single instance of the tool need be implemented, and only for our generic set of message-passing routines (instead of the peculiarities of any particular machine). Since the primitive operations of all machines ar...|$|R
40|$|AbstractObjectivesInhalation {{therapy is}} the main {{treatment}} for asthma and its adequate use has been a factor responsible for disease control; therefore, {{the aim of the}} study was to determine whether a digital media <b>tool,</b> which features <b>portability</b> on mobile phones, modifies the assimilation of the inhalation technique. MethodsA total of 66 professionals working in the health care area with the pediatric population were selected. They were submitted to a pre-test on their knowledge of inhalation therapy. The professionals were randomized into two groups (A and B). Group A received a media application on their mobile phones showing the steps of inhalation therapy, while group B received the same information in written form only. A post-test was applied after 15 days. The results (pre- and post-) were analyzed by two pediatric pulmonologists. ResultsOf the 66 professionals, 87. 9 % were females. Of a total possible score of ten, the mean score obtained in the pre-test was 5. 3 ± 3, and in the second test, 7. 5 ± 2 (p< 0. 000). There were no significant differences when comparing the two groups (p= 0. 726). The nurses had the lowest mean scores in the initial test (2. 3 ± 2); however, they were the group that learned the most with the intervention, showing similar means to those of other groups in the second test (6. 1 ± 3). ConclusionThere was significant improvement in knowledge about inhalation therapy in all professional categories using both methods, demonstrating that education, when available to professionals, positively modifies medical practice...|$|R
40|$|OBJECTIVES: Inhalation {{therapy is}} the main {{treatment}} for asthma and its adequate use has been a factor responsible for disease control; therefore, {{the aim of the}} study was to determine whether a digital media <b>tool,</b> which features <b>portability</b> on mobile phones, modifies the assimilation of the inhalation technique. METHODS: A total of 66 professionals working in the health care area with the pediatric population were selected. They were submitted to a pre-test on their knowledge of inhalation therapy. The professionals were randomized into two groups (A and B). Group A received a media application on their mobile phones showing the steps of inhalation therapy, while group B received the same information in written form only. A post-test was applied after 15 days. The results (pre- and post-) were analyzed by two pediatric pulmonologists. RESULTS: Of the 66 professionals, 87. 9 % were females. Of a total possible score of ten, the mean score obtained in the pre-test was 5. 3 &# 177; 3, and in the second test, 7. 5 &# 177; 2 (p < 0. 000). There were no significant differences when comparing the two groups (p = 0. 726). The nurses had the lowest mean scores in the initial test (2. 3 &# 177; 2); however, they were the group that learned the most with the intervention, showing similar means to those of other groups in the second test (6. 1 &# 177; 3). CONCLUSION: There was significant improvement in knowledge about inhalation therapy in all professional categories using both methods, demonstrating that education, when available to professionals, positively modifies medical practice...|$|R
40|$|The {{problem of}} {{portability}} and reproducibility {{of the software}} used to conduct computational experiments has recently come to the fore. Container virtualisation {{has proved to be}} a powerful <b>tool</b> to achieve <b>portability</b> of a code and it's execution environment, through runtimes such as Docker, LXC, Singularity and others - without the performance cost of traditional Virtual Machines (Chamberlain, Invenshure, and Schommer 2014; Felter et al. 2014). However, scientific software often depends on a system foundation that provides middleware, libraries, and other supporting software in order for the code to execute as intended. Typically, container virtualisation addresses only the portability of the code itself, which does not make it inherently reproducible. For example, a containerized MPI application may offer binary compatibility between different systems, but for execution as intended, it must be run on an existing cluster that provides the correct interfaces for parallel MPI execution. As a greater demand to accomodate a diverse range of disciplines is placed on high performance and cluster resources, the ability to quickly create and teardown reproducible, transitory virtual environments that are tailored for an individual task or experiment will be essential. The Virtual Container Cluster (VCC) is a framework for building containers that achieve this goal, by encapsulating a parallel application along with an execution model, through a set of dependency linked services and built-in process orchestration. This promotes a high degree of portability, and offers easier reproducibility by shipping the application along with the foundation required to execute it - whether that be an MPI cluster, big data processing framework, bioinformatics pipeline, or any other execution model (Higgins, Holmes, and Venters 2017) ...|$|R
40|$|As {{the human}} {{population}} grows, there is an increasing demand for early detection {{of a variety of}} analytes in different fields. This demand mainly includes early and sensitive detection of pathogens, disease biomarkers, pesticides, food contaminants, and explosives. To address this, lab-on-a-chip (LOC) technology has emerged as a <b>tool</b> to improve <b>portability,</b> automation and sensitivity of sensors by taking advantage of integrated laboratory functions on a miniaturized chip. It is agreed that LOC has the potential to make various sensing modules practical for real- world applications. In this work, we have developed a highly sensitive, portable, and automated optofluidic surface enhanced Raman spectroscopy (SERS) microsystem for chemical and biological detection. SERS is a powerful molecular identification technique that combines laser spectroscopy with optical properties of metal nanoparticles. Optofluidic SERS is defined as the synergistic use of microfluidic functions to improve the performance of SERS. By leveraging microfluidic functions, the optofluidic SERS microsystem mixes and concentrates the sample and nanoparticles resulting in an improved performance as compared to conventional open microfluidic SERS systems. The device requires low sample volume and has multiplexed detection capabilities. Moreover, it is suitable for on-site detection of analytes in the field because of its improved automation and portability due to the integrated fiber optics. The final device consists of two regions of packed silica beads inside microchannels for biomolecular interaction as well as sample concentration for SERS measurements. Additionally, an on-chip micromixer and fiber optics are integrated into the device. Optical fibers aligned to the detection zone make the biosensor alignment-free, which greatly improves automation. Practical applications for the detection of real-world analytes (e. g., pesticides, fungicides, food contaminants, and DNA sequences) are demonstrated utilizing our optofluidic SERS microsystem. Detection of biological samples could be extended to proteins and proteolytic enzymes through displacement assays. Consequently, the integration of microfluidic functions, including a microporous reaction zone, a nanoparticle concentration zone, and a micromixer, combined with the use of integrated fiber optics and portable spectrometers, make our microsystem suitable for on-site detection of analytes at trace levels...|$|R
40|$|Digital {{fabrication}} tools, specifically {{additive manufacturing}} systems, have consistently advanced in efficiencies such as print speed, gantry size, material cost {{and ease of}} use. However most of these systems remain limited {{in their ability to}} enable automated mixing and extrusion of multiple materials with variable properties on large scales. This thesis focuses on the first steps of realizing this enabling technology by operating across two distinct trajectories. The first aims at digitally controlling precision path placement of material with high levels of tunability through analog mixing, while the second explores do-it-yourself <b>tool</b> customization, compactness, <b>portability</b> and the possibility of fabrication node-to-node communication. Inspired by the silkworm's ability to spin highly sophisticated and tunable material architectures, the aim of this thesis is to develop an enabling technology for digital fabrication requiring high levels of material tunability in product and architectural scales. Specifically, I designed, developed, built and evaluated an array of six unique customizable and compact deposition heads for tunable material properties. Amongst those tools is a freeform extrusion head for tunable geometry without the need for auxiliary support structure; a fast thread deposition head and a fiber winding head for tunable compressive and tensile strength respectively; a portable cable-suspended paste droplet extrusion head for tunable drop size of paste material; and a chitosan gel extrusion head for tunable plasticity using biomaterials. Operating across the two trajectories of tunability and portability, this thesis argues that highly tunable, compact and portable extrusion heads developed within a Fab Lab environment can support variable property printing of one or more materials outside of commercial based systems. This capability will in the future enable the digital fabrication of larger-scale prototypes, sustainable products and architectural structures inspired by nature in Fab Lab settings. by Jared Smith Laucks. Thesis: S. M., Massachusetts Institute of Technology, School of Architecture and Planning, Program in Media Arts and Sciences, 2014. Cataloged from PDF version of thesis. Includes bibliographical references (pages 94 - 97) ...|$|R
40|$|Validation and {{verification}} are {{key points}} within a space project {{to check for}} reliability of the designed product. Of course, those phases are fundamental within the development of projects focused on planetary exploration too, such as those involving mobile elements on the surface; on board software, operations, and operational modes must be checked in a specific simulation environment, possibly including some software representation of the on board hardware too. A space mission simulator allows checking for the design robustness too, as different and complex faulty scenarios may be analysed either to revise the hardware solutions or to correctly define the reconfiguration procedures. Although spacecraft simulators are routine at control centers, rover virtual simulator is a young area for Europe as no space rover has been deployed yet. While the ExoMars program offers a great field for Martian applications, the Lunar Google XPrize challenge represents a perfect lunar scenario to start working on that topic: according to the challenge statement, a rover must be sent on the Moon within 2012, built exploiting only private sponsorships. Italy is running the race with the so called Team Italia: a mainly academic consortium supported by three important space involved national companies. To support the project, the Aerospace Engineering Department of Politecnico di Milano tailored an under development virtual simulator on the lunar mission scenario: at this early phase of the project the robustness of the sensorsarclhteeturc can be checked; to visualize the rover behaviour on the surface greatly helps the designers revising and refining the preliminary choices. Moreover, activity planning, operation sequences and operational modes can be easier defined and cross checked. The effects {{of a lot of}} faulty conditions may be analyzed to better understand how to cope with either through the design or during operational phases. The simulator here presented supplies: the representation of our satellite environment; orbital mechanics features to let the user identify the visibility windows between the rover antenna and a selected ground station on Earth; representation of the rover - user defined - according to the current design; a navigation module, to define the safe path according to the current map of the environment surrounding the rover; the multi-body model of the rover integrated in the simulation environment, including the traction control of the wheels. The drivers for designing the simulator architecture and selecting the implementation environment for the <b>tool</b> were the <b>portability</b> and the flexibility. The simulator, in fact, must provide a software framework for testing different levels of autonomy - plug-in of external modules and tools must be easy - simulated hardware must be simply redefineable to support the system design process; validation of different granularity of the mission plan shall be feasible The proposed tool merges a physic and a graphic (Irrlicht) engine. Irrlicht is a cross-platform high performance real-time 3 D engine; it is a high level API for creating complete 3 D and 2 D applications like games or scientific visualizations. It comes with a wide documentation and integrates all the state-of-the-art features for visual representation like dynamic shadows, particle systems, character animation, indoor and outdoor technology. The engine is open source. The virtual environment contains all physical properties of the planetary surface, rock distribution and terrain properties, exploited to evaluate the interaction with the rover. The map of the soil properties is an output of the tool, the user can select the soil type, introducing the soil parameters or a predefined soil class; currently the data of Lunar and Martian surface are available, but the tool is highly flexible and configurable. The tool exploits those inputs to build the soil map. The navigation module solves the pathplanning problem by applying a potential field method, the target position attracts the rover while obstacles repulse it; therefore, the global effects on the rover, evaluated at each step, determines the future travelling direction. The rover simulator is going to be exploited by the Team Italia to check for rover operations feasibility and robustness both in nominal and possibly faulty scenarios and to validate the design before starting integrating the whole system. The paper will deeply describe the features of the proposed tool and will discuss open points and future refinements...|$|R

