164|1468|Public
5000|$|Fixed {{priority}} pre-emptive scheduling, an {{implementation of}} preemptive <b>time</b> <b>slicing</b> ...|$|E
50|$|<b>Time</b> <b>slicing</b> is a {{technique}} used by ATSC-M/H to provide power savings on receivers. It {{is based on the}} time-multiplexed transmission of different services.|$|E
5000|$|The POWER Hypervisor {{controls}} <b>time</b> <b>slicing,</b> {{management of}} all hardware interrupts, dynamic movement of resources across multiple operating systems, and dispatching of logical partition workloads.|$|E
50|$|In this example, the <b>time</b> <b>slice</b> 1 always {{contains}} {{high priority}} data (e.g. for motion control), while <b>time</b> <b>slice</b> 2 always contains best effort data.Therefore, a guard band {{needs to be}} placed at every transition point into <b>time</b> <b>slice</b> 1 to protect the <b>time</b> <b>slice</b> of the critical data stream(s).|$|R
50|$|The {{period of}} time for which a process is allowed to run in a {{preemptive}} multitasking system is generally called the <b>time</b> <b>slice</b> or quantum. The scheduler is run once every <b>time</b> <b>slice</b> to choose the next process to run. The length of each <b>time</b> <b>slice</b> can be critical to balancing system performance vs process responsiveness - if the <b>time</b> <b>slice</b> is too short then the scheduler will consume too much processing time, but if the <b>time</b> <b>slice</b> is too long, processes will take longer to respond to input.|$|R
3000|$|... (j)], {{and finish}} later than j.[*]deadline. Obviously, {{there is no}} any idle <b>time</b> <b>slice</b> in <b>time</b> <b>slice</b> [COT [...]...|$|R
50|$|<b>Time</b> <b>slicing</b> is a {{technique}} used by the DVB-H and ATSC-M/H technologies for achieving power-savings on mobile terminal devices. It {{is based on the}} time-multiplexed transmission of different services.|$|E
50|$|Programs {{designed}} to require concurrency {{are more difficult}} to debug. Programs {{designed to}} require concurrency will have performance issues when the number of required threads exceeds the number of hardware threads because <b>time</b> <b>slicing</b> artifacts can hit hard.|$|E
50|$|<b>Time</b> <b>slicing</b> {{requires}} a sufficiently {{high number of}} multiplexed services and a certain minimum burst data-rate to guarantee effective power saving. Basically, the power consumption of the front end correlates with the service data-rate of the service currently selected.|$|E
5000|$|This {{scheduler}} divides processor {{time into}} epochs. Within each epoch, every task can execute {{up to its}} <b>time</b> <b>slice.</b> If a task does not use all of its <b>time</b> <b>slice,</b> then the scheduler adds half of the remaining <b>time</b> <b>slice</b> {{to allow it to}} execute longer in the next epoch.|$|R
50|$|At <b>time</b> <b>slice</b> 5, both P2 and P3 {{have the}} same deadline, needing to {{complete}} before <b>time</b> <b>slice</b> 10, so EDF may schedule either one.|$|R
50|$|In this example, each cycle {{consists}} of two <b>time</b> <b>slices.</b> <b>Time</b> <b>slice</b> 1 only allows the transmission of traffic tagged with VLAN priority 3, and <b>time</b> <b>slice</b> 2 in each cycle allows {{for the rest of}} the priorities to be sent. Since the IEEE 802.1Qbv scheduler requires all clocks on all network devices (Ethernet switches and end devices) to be synchronized and the identical schedule to be configured, all devices understand which priority can be sent to the network at any given point in <b>time.</b> Since <b>time</b> <b>slice</b> 2 has more than one priority assigned to it, within this <b>time</b> <b>slice,</b> the priorities are handled according to standard IEEE 802.1Q strict priority scheduling.|$|R
50|$|Vice versa, the OFF {{time that}} is to be used can be {{calculated}} from the actual constant bitrate of the video stream. This is more intuitive, since the constant (or average) video bitrate is known before applying <b>time</b> <b>slicing.</b>|$|E
5000|$|The {{length of}} a burst [...] can be {{calculated}} through {{the size of the}} burst [...] and the bitrate of the burst [...] An additional factor of 0.96 is introduced to compensate for the headers of the underlying MPEG transport stream, because they are created after applying <b>Time</b> <b>Slicing.</b>|$|E
5000|$|When {{two or more}} tasks {{have the}} same priority, the kernel allows one task to run for a {{predetermined}} amount of time, named a quantum, and then selects another task. This process is termed round robin scheduling or <b>time</b> <b>slicing.</b> The kernel gives control to the next task in line if: ...|$|E
3000|$|..., {{we first}} {{computed}} [...] COT_m(j_i^') [...] {{and then find}} a series of unoccupied <b>time</b> <b>slices,</b> whose sum to be [...] TC_r(j_i^'), beginning with the moment [...] COT_m(j_i^'), and tag these <b>time</b> <b>slices</b> as occupied. Then, the finished time of the Reduce step of j_i^', i.e., [...] COT_r(j_i^'), is the finished time of the latest <b>time</b> <b>slices.</b>|$|R
30|$|The <b>time</b> <b>slices</b> {{obtained}} shows delineated subsurface structural features at 2.35 and 2.62  s, respectively. This {{shows the}} {{spatial distribution of}} seismic amplitude over the study area. At 2.10  s, the faults became more visible and gave a better resolution of distribution of the fault patterns across the field location. The compared seismic amplitude shows (Fig.  6) as the normal seismic amplitude <b>time</b> <b>slice</b> with a smeared lineament, (Fig.  7), the variance <b>time</b> <b>slice</b> with defined faults and (Fig.  8) the coherence <b>time</b> <b>slice</b> with the faults mapped better than the normal seismic amplitude time.|$|R
40|$|International audienceIn this paper, {{we propose}} a right {{transmission}} {{condition for the}} time decomposition that consists to transform the initial boundary value problem into a time boundary values problem. This allows us to use the classical multiplicative Schwarz algorithm using non-overlapping <b>time</b> <b>slices.</b> It also avoids the symmetrizing of the time interval needed to set the unknown value of the solution at the end time boundary of the last <b>time</b> <b>slice.</b> We show that, for nonlinear scalar problems, we must imposed some invariant of the problem as transmission conditions between <b>time</b> <b>slices.</b> We derive a Robin transmission condition in order to break the sequentiality of the propagating of the exact solution from the first <b>time</b> <b>slice</b> to the <b>time</b> <b>slices</b> that follow. We show the purely linear behaviour of this multiplicative Schwarz and its extrapolation to the right transmission conditions using Aitken's technique to accelerate convergence. Then a dual Schur complement technique is used on the nonlinear problem. We derive a method where the nonlinear transmission conditions are used to solve on each <b>time</b> <b>slice</b> while imposing the constraint of the solution continuity between <b>time</b> <b>slices...</b>|$|R
50|$|In May 2006, Markopoulou {{published}} a paper with Lee Smolin that further popularized this Causal Dynamical Triangulation (CDT) Theory by explaining <b>time</b> <b>slicing</b> of the Ambjorn-Loll CDT model as result of gauge fixing. Their approach relaxed {{the definition of}} the Ambjorn-Loll CDT model in 1 + 1 dimensions to allow for a varying lapse.|$|E
50|$|For a {{particle}} in curved space the kinetic term {{depends on the}} position, and the above <b>time</b> <b>slicing</b> cannot be applied, this being {{a manifestation of the}} notorious operator ordering problem in Schrödinger quantum mechanics. One may, however, solve this problem by transforming the time-sliced flat-space path integral to curved space using a multivalued coordinate transformation (nonholonomic mapping explained here).|$|E
50|$|<b>Time</b> <b>slicing</b> {{offers another}} {{benefit for the}} {{terminal}} architecture. The rather long power-save periods {{may be used to}} search for channels in neighboring radio cells offering the selected service. This way a channel handover can be performed at the border between two cells which remains imperceptible for the user. Both the monitoring of the services in adjacent cells and the reception of the selected service data can be done with the same front end.|$|E
30|$|I. Given {{the network}} {{partition}} P in the reference <b>time</b> <b>slice</b> t, identify a community C (C ∈P). C {{is the target}} community of interest to be mapped to in the following <b>time</b> <b>slices.</b>|$|R
5000|$|Time-Slicing. If the vendor’s PCS allows time-slicing (like Digital UNIX, unlike Solaris), then T1 {{might simply}} have its <b>time</b> <b>slice</b> {{run out and}} T2 (at the same {{priority}} level) would then receive a <b>time</b> <b>slice.</b>|$|R
50|$|Just {{before the}} end of <b>time</b> <b>slice</b> 2 in cycle n, a new frame {{transmission}} is started. Unfortunately, this frame is too large to fit into its <b>time</b> <b>slice.</b> Since the transmission of this frame cannot be interrupted, the frame infringes the following <b>time</b> <b>slice</b> 1 of the next cycle n+1. By partially or completely blocking a time-critical <b>time</b> <b>slice,</b> real-time frames can be delayed up {{to the point where they}} cannot meet the application requirements any longer. This is very similar to the actual buffering effects that happen in non-TSN Ethernet switches, so TSN has to specify a mechanism to prevent this from happening.|$|R
5000|$|For oscillatory path integrals, {{ones with}} an [...] in the numerator, the <b>time</b> <b>slicing</b> {{produces}} convolved Gaussians, just as before. Now, however, the convolution product is marginally singular, since it requires careful limits {{to evaluate the}} oscillating integrals. To make the factors well defined, the easiest way is to add a small imaginary part to the time increment [...] This {{is closely related to}} Wick rotation. Then the same convolution argument as before gives the propagation kernel: ...|$|E
50|$|OS-9’s {{real-time}} kernel allows multiple independent {{applications to}} execute simultaneously through task switching and inter-process communication facilities. All OS-9 programs run as processes containing {{at least one}} lightweight process (thread) but may contain an effectively unlimited number of threads. Within a process, these lightweight processes share memory, I/O paths, and other resources {{in accordance with the}} POSIX threads specification and API. OS-9 schedules the threads using a fixed-priority preemptive scheduling algorithm with round-robin scheduling within each priority. <b>Time</b> <b>slicing</b> is supported. The priority levels can be divided into a range that supports aging and a higher-priority range that uses strict priority scheduling. Each process can access any system resource by issuing the appropriate OS-9 service request. At every scheduling point, OS-9 compares the priority of the thread {{at the head of the}} active queue to the priority of the current thread. It context switches to the thread on the active queue if its priority is higher than the current processes’ priority. Aging artificially increases the effective priority of threads in the active queue as time passes. At defined intervals, <b>time</b> <b>slicing</b> returns the current thread to the active queue behind other threads at the same priority.|$|E
50|$|A {{computer}} with a single processor can only perform one process at a time, regardless {{of the amount of}} programs loaded by the user (or initiated on start-up). Computers using single processors appear to be running multiple programs at once because the processor quickly alternates between programs, processing what is needed in very small amounts of time. This process is known as multitasking or <b>time</b> <b>slicing.</b> The time allocation is automatic, however higher or lower priority may be given to certain processes, essentially giving high priority programs more/bigger slices of the processor's time.|$|E
40|$|Compared to {{the steady}} phase, quality {{prediction}} {{in the transition}} period of batch process has been explored as a difficult task in recent years. Unlike the data behavior in the steady phase, there may be significant correlations among the data samples in each transition period. Without considering the relationships among different <b>time</b> <b>slices</b> (<b>time</b> pieces in the batch dataset), {{the performance of the}} quality prediction model may be degraded. In the present work, an information transfer PLS model is particularly proposed for quality prediction in transition periods of the batch process. By transferring the main data information of one <b>time</b> <b>slice</b> to the next one, different <b>time</b> <b>slices</b> in the transition period are connected. As a result, most available data information in the previous <b>time</b> <b>slices</b> can be efficiently used for quality modeling of a specific <b>time</b> <b>slice</b> in the transition period. For performance evaluation of the developed method, a case study of an industrial injection molding process is provided...|$|R
50|$|This {{contrasts}} with continuous simulation {{in which the}} simulation continuously tracks the system dynamics over time. Instead of being event-based, this is called an activity-based simulation; time is broken up into small <b>time</b> <b>slices</b> and the system state is updated according to the set of activities happening in the <b>time</b> <b>slice.</b> Because discrete-event simulations {{do not have to}} simulate every <b>time</b> <b>slice,</b> they can typically run much faster than the corresponding continuous simulation.|$|R
50|$|In non-homotopic paths, one cannot {{get from}} any point at one <b>time</b> <b>slice</b> {{to any other}} point at the next <b>time</b> <b>slice.</b> This means that we can {{consider}} homotopic equivalence class of paths to have different weighting factors.|$|R
50|$|The minimum {{processing}} capacity per processor is 1/10 {{of a physical}} processor core, with a further granularity of 1/100, and the PHYP uses a 10 ms <b>time</b> <b>slicing</b> dispatch window for scheduling all shared processor partitions' virtual processor queues to the PHYP physical processor core queues. A shared processor partition can be either capped or uncapped. A capped partition can never exceed the currently configured {{processing capacity}}, whereas an uncapped partition can exceed the currently configured processing capacity up to 100% {{of the number of}} the currently configured virtual processors.|$|E
5000|$|The {{form of the}} {{relativistic}} composition law can {{be understood}} as an effect of the failure of simultaneity at a distance. For the parallel component, the time dilation decreases the speed, the length contraction increases it, and the two effects cancel out. The failure of simultaneity means that the fly is changing simultaneity slices as the projection of [...] onto [...] Since this effect is entirely due to the <b>time</b> <b>slicing,</b> the same factor multiplies the perpendicular component, but for the perpendicular component there is no length contraction, so the time dilation multiplies by a factor of [...]---- ...|$|E
50|$|<b>Time</b> <b>slicing</b> {{technology}} is employed to reduce power consumption for small handheld terminals. IP datagrams are transmitted as data bursts in small time slots. Each burst may contain {{up to two}} megabits of data (including parity bits). There are 64 parity bits for each 191 data bits, protected by Reed-Solomon codes. The {{front end of the}} receiver switches on only for the time interval when the data burst of a selected service is on air. Within this short period of time a high data rate is received which can be stored in a buffer. This buffer can either store the downloaded applications or playout live streams.|$|E
50|$|Batch {{and demand}} always use {{dynamically}} adjusted priorities. Programs that are I/O limited {{or are in}} a conversation with a time-sharing user get higher priorities but short <b>time</b> <b>slices.</b> More compute-oriented programs get lower priorities and longer <b>time</b> <b>slices.</b>|$|R
50|$|The <b>time</b> <b>slice</b> ends.|$|R
5000|$|A single <b>time</b> <b>slice</b> {{can never}} be {{configured}} smaller than {{the size of the}} guard band. Especially with lower speed Ethernet connections and growing guard band size, this has a negative impact on the lowest achievable <b>time</b> <b>slice</b> length and cycle time.|$|R
