3539|18|Public
25|$|<b>Tabu</b> <b>search</b> (TS) {{is similar}} to {{simulated}} annealing in that both traverse the solution space by testing mutations of an individual solution. While simulated annealing generates only one mutated solution, <b>tabu</b> <b>search</b> generates many mutated solutions {{and moves to the}} solution with the lowest fitness of those generated. To prevent cycling and encourage greater movement through the solution space, a tabu list is maintained of partial or complete solutions. It is forbidden to move to a solution that contains elements of the tabu list, which is updated as the solution traverses the solution space.|$|E
25|$|Implementations of: the GPU <b>Tabu</b> <b>Search</b> {{algorithm}} {{solving the}} Resource Constrained Project Scheduling problem is freely available on GitHub; the GPU algorithm solving the Nurse Rerostering problem is freely available on GitHub.|$|E
25|$|TSP is a touchstone {{for many}} general {{heuristics}} devised for combinatorial optimization such as genetic algorithms, simulated annealing, <b>Tabu</b> <b>search,</b> ant colony optimization, river formation dynamics (see swarm intelligence) and the cross entropy method.|$|E
25|$|In {{optimization}} problems, heuristic algorithms {{can be used}} to find {{a solution}} close to the optimal solution in cases where finding the optimal solution is impractical. These algorithms work by getting {{closer and closer to the}} optimal solution as they progress. In principle, if run for an infinite amount of time, they will find the optimal solution. Their merit is that they can find a solution very close to the optimal solution in a relatively short time. Such algorithms include local search, <b>tabu</b> <b>search,</b> simulated annealing, and genetic algorithms. Some of them, like simulated annealing, are non-deterministic algorithms while others, like <b>tabu</b> <b>search,</b> are deterministic. When a bound on the error of the non-optimal solution is known, the algorithm is further categorized as an approximation algorithm.|$|E
25|$|A {{solution}} to the puzzle is then found. Approaches for shuffling the numbers include simulated annealing, genetic algorithm and <b>tabu</b> <b>search.</b> Stochastic-based algorithms {{are known to be}} fast, though perhaps not as fast as deductive techniques. Unlike the latter however, optimisation algorithms do not necessarily require problems to be logic-solvable, giving them the potential to solve a wider range of problems. Algorithms designed for graph colouring are also known to perform well with Sudokus. It is also possible to express a Sudoku as an integer linear programming problem. Such approaches get close to a solution quickly, and can then use branching towards the end. The simplex algorithm is able to solve non-proper Sudokus, indicating if the Sudoku is not valid (no solution), or providing the set of answers when {{there is more than one}} solution.|$|E
25|$|The variable-opt {{method is}} related to, and a {{generalization}} of the k-opt method. Whereas the k-opt methods remove a fixed number (k) of edges {{from the original}} tour, the variable-opt methods do not fix {{the size of the}} edge set to remove. Instead they grow the set as the search process continues. The best known method in this family is the Lin–Kernighan method (mentioned above as a misnomer for 2-opt). Shen Lin and Brian Kernighan first published their method in 1972, and it was the most reliable heuristic for solving travelling salesman problems for nearly two decades. More advanced variable-opt methods were developed at Bell Labs in the late 1980s by David Johnson and his research team. These methods (sometimes called Lin–Kernighan–Johnson) build on the Lin–Kernighan method, adding ideas from <b>tabu</b> <b>search</b> and evolutionary computing. The basic Lin–Kernighan technique gives results that are guaranteed to be at least 3-opt. The Lin–Kernighan–Johnson methods compute a Lin–Kernighan tour, and then perturb the tour by what {{has been described as a}} mutation that removes at least four edges and reconnecting the tour in a different way, then V-opting the new tour. The mutation is often enough to move the tour from the local minimum identified by Lin–Kernighan. V-opt methods are widely considered the most powerful heuristics for the problem, and are able to address special cases, such as the Hamilton Cycle Problem and other non-metric TSPs that other heuristics fail on. For many years Lin–Kernighan–Johnson had identified optimal solutions for all TSPs where an optimal solution was known and had identified the best known solutions for all other TSPs on which the method had been tried.|$|E
2500|$|<b>Tabu</b> <b>search</b> {{normally}} {{moves to}} neighbouring states of lower energy, but will take uphill moves when it finds itself {{stuck in a}} local minimum; and avoids cycles by keeping a [...] "taboo list" [...] of solutions already seen.|$|E
5000|$|<b>Tabu</b> <b>search</b> is a {{class of}} search methods which can be {{instantiated}} to specific methods. GLS {{can be seen as}} a special case of <b>Tabu</b> <b>search.</b>|$|E
5000|$|Short-term memory alone may {{be enough}} to achieve {{solution}} superior to those found by conventional local search methods, but intermediate and long-term structures are often necessary for solving harder problems. [...] <b>Tabu</b> <b>search</b> is often benchmarked against other metaheuristic methods - such as Simulated annealing, genetic algorithms, Ant colony optimization algorithms, Reactive search optimization, Guided Local Search, or greedy randomized adaptive search. In addition, <b>tabu</b> <b>search</b> is sometimes combined with other metaheuristics to create hybrid methods. The most common <b>tabu</b> <b>search</b> hybrid arises by joining TS with Scatter Search, a class of population-based procedures which has roots in common with <b>tabu</b> <b>search,</b> and is often employed in solving large non-linear optimization problems.|$|E
5000|$|... 1986: Glover proposes <b>tabu</b> <b>search,</b> first {{mention of}} the term metaheuristic.|$|E
5000|$|<b>Tabu</b> <b>search,</b> an {{extension}} of local search capable of escaping from local minima ...|$|E
50|$|Approaches {{for solving}} the {{traveling}} purchaser problem include dynamic programming and <b>tabu</b> <b>search</b> algorithms.|$|E
5000|$|The memory {{structures}} used in <b>tabu</b> <b>search</b> can roughly {{be divided}} into three categories: ...|$|E
5000|$|... 1970: Kernighan and Lin {{propose a}} graph {{partitioning}} method, related to variable-depth search and prohibition-based (<b>tabu)</b> <b>search.</b>|$|E
50|$|<b>Tabu</b> <b>search,</b> {{created by}} Fred W. Glover in 1986 and formalized in 1989, is a metaheuristic search method {{employing}} local search methods used for mathematical optimization.|$|E
50|$|<b>Tabu</b> <b>search</b> (TS) is a metaheuristic {{algorithm}} {{that can}} be used for solving combinatorial optimization problems (problems where an optimal ordering and selection of options is desired).|$|E
50|$|<b>Tabu</b> <b>search</b> (TS) {{is similar}} to {{simulated}} annealing in that both traverse the solution space by testing mutations of an individual solution. While simulated annealing generates only one mutated solution, <b>tabu</b> <b>search</b> generates many mutated solutions {{and moves to the}} solution with the lowest fitness of those generated. To prevent cycling and encourage greater movement through the solution space, a tabu list is maintained of partial or complete solutions. It is forbidden to move to a solution that contains elements of the tabu list, which is updated as the solution traverses the solution space.|$|E
5000|$|The {{traveling}} salesman problem (TSP) {{is sometimes}} used {{to show the}} functionality of <b>tabu</b> <b>search.</b> This problem poses a straightforward question - given a list of cities, what is the shortest route that visits every city? For example, if city A and city B are next to each other, while city C is farther away, the total distance traveled will be shorter if cities A and B are visited {{one after the other}} before visiting city C. Since finding an optimal solution is NP-hard, heuristic-based approximation methods (such as local searches) are useful for devising close-to-optimal solutions. To obtain good TSP solutions, it is essential to exploit the graph structure. The value of exploiting problem structure is a recurring theme in metaheuristic methods, and <b>tabu</b> <b>search</b> is well-suited to this. A class of strategies associated with <b>tabu</b> <b>search</b> called ejection chain methods has made it possible to obtain high-quality TSP solutions efficiently ...|$|E
50|$|Paradiseo-MO {{deals with}} single-solution based metaheuristics, it {{provides}} tools {{for the development}} of single solution-based metaheuristics: Hill climbing, <b>Tabu</b> <b>search,</b> Iterative Local Search (ILS), Simulated annealing, incremental evaluation, partial neighbourhood...|$|E
50|$|New {{solutions}} are created until some stopping criterion, {{such as an}} arbitrary number of iterations, is met. Once the simple <b>tabu</b> <b>search</b> stops, it returns the best solution found during its execution.|$|E
5000|$|Implementations of: the GPU <b>Tabu</b> <b>Search</b> {{algorithm}} {{solving the}} Resource Constrained Project Scheduling problem is freely available on GitHub; the GPU algorithm solving the Nurse Rerostering problem is freely available on GitHub.|$|E
5000|$|<b>Tabu</b> <b>search</b> (TS) {{is similar}} to {{simulated}} annealing in that both traverse the solution space by testing mutations of an individual solution. While simulated annealing generates only one mutated solution, <b>tabu</b> <b>search</b> generates many mutated solutions {{and moves to the}} solution with the lowest energy of those generated. In order to prevent cycling and encourage greater movement through the solution space, a tabu list is maintained of partial or complete solutions. It is forbidden to move to a solution that contains elements of the tabu list, which is updated as the solution traverses the solution space.|$|E
50|$|TSP is a touchstone {{for many}} general {{heuristics}} devised for combinatorial optimization such as genetic algorithms, simulated annealing, <b>Tabu</b> <b>search,</b> ant colony optimization, river formation dynamics (see swarm intelligence) and the cross entropy method.|$|E
50|$|Solutions to {{the problem}} {{use a variety of}} techniques, {{including}} both mathematically exact solutions and a variety of heuristic solutions using decomposition, parallel computing, stochastic optimization, genetic algorithms, colony optimization, simulated annealing, <b>Tabu</b> <b>search,</b> and coordinate descent.|$|E
5000|$|<b>Tabu</b> <b>search</b> {{normally}} {{moves to}} neighbouring states of lower energy, but will take uphill moves when it finds itself {{stuck in a}} local minimum; and avoids cycles by keeping a [...] "taboo list" [...] of solutions already seen.|$|E
50|$|In many cases, local optima deliver sub-optimal {{solutions}} to the global problem, anda local search method needs to be modified to continue the searchbeyond local optimality; see for example iterated local search, <b>tabu</b> <b>search,</b> reactive search optimization, andsimulated annealing.|$|E
5000|$|Current {{applications}} of TS span {{the areas of}} resource planning, telecommunications, VLSI design, financial analysis, scheduling, space planning, energy distribution, molecular engineering, logistics, pattern classification, flexible manufacturing, waste management, mineral exploration, biomedical analysis, environmental conservation and scores of others. In recent years, journals {{in a wide variety}} of fields have published tutorial articles and computational studies documenting successes by <b>tabu</b> <b>search</b> in extending the frontier of problems that can be handled effectively — yielding solutions whose quality often significantly surpasses that obtained by methods previously applied. A comprehensive list of applications, including summary descriptions of gains achieved from practical implementations, can be found in [...] Recent TS developments and applications can also be found in <b>Tabu</b> <b>Search</b> Vignettes.|$|E
50|$|Many metaheuristic {{ideas were}} {{proposed}} to improve local search heuristic {{in order to find}} better solutions. Such metaheuristics include simulated annealing, <b>tabu</b> <b>search,</b> iterated local search, variable neighborhood search, and GRASP. These metaheuristics can both be classified as local search-based or global search metaheuristics.|$|E
50|$|In {{optimization}} problems, heuristic algorithms {{can be used}} to find {{a solution}} close to the optimal solution in cases where finding the optimal solution is impractical. These algorithms work by getting {{closer and closer to the}} optimal solution as they progress. In principle, if run for an infinite amount of time, they will find the optimal solution. Their merit is that they can find a solution very close to the optimal solution in a relatively short time. Such algorithms include local search, <b>tabu</b> <b>search,</b> simulated annealing, and genetic algorithms. Some of them, like simulated annealing, are non-deterministic algorithms while others, like <b>tabu</b> <b>search,</b> are deterministic. When a bound on the error of the non-optimal solution is known, the algorithm is further categorized as an approximation algorithm.|$|E
5000|$|Since integer linear {{programming}} is NP-hard, many problem instances are intractable and so heuristic methods {{must be used}} instead. For example, <b>tabu</b> <b>search</b> {{can be used to}} search for solutions to ILPs. [...] To use <b>tabu</b> <b>search</b> to solve ILPs, moves can be defined as incrementing or decrementing an integer constrained variable of a feasible solution, while keeping all other integer-constrained variables constant. The unrestricted variables are then solved for. Short term memory can consist of previous tried solutions while medium term memory can consist of values for the integer constrained variables that have resulted in high objective values (assuming the ILP is a maximization problem). Finally, long term memory can guide the search towards integer values that have not previously been tried.|$|E
5000|$|<b>Tabu</b> <b>search</b> uses a {{local or}} {{neighborhood}} search procedure to iteratively {{move from one}} potential solution [...] to an improved solution [...] {{in the neighborhood of}} , until some stopping criterion has been satisfied (generally, an attempt limit or a score threshold). Local search procedures often become stuck in poor-scoring areas or areas where scores plateau. In order to avoid these pitfalls and explore regions of the search space that would be left unexplored by other local search procedures, <b>tabu</b> <b>search</b> carefully explores the neighborhood of each solution as the search progresses. The solutions admitted to the new neighborhood, , are determined through the use of memory structures. Using these memory structures, the search progresses by iteratively moving from the current solution [...] to an improved solution [...] in [...]|$|E
5000|$|... methods.The basic {{principle}} of the method is to add a memory-dependent potential energy term in the simulation so as to prevent the simulation to revisit already sampled configurations, {{which leads to the}} increased probability of discovering new configurations. The method {{can be seen as a}} continuous variant of the <b>Tabu</b> <b>search</b> method.|$|E
5000|$|The {{following}} pseudocode {{presents a}} simplified {{version of the}} <b>tabu</b> <b>search</b> algorithm as described above. This implementation has a rudimentary short-term memory, but contains no intermediate or long-term memory structures. The term [...] "fitness" [...] refers to {{an evaluation of the}} candidate solution, as embodied in an objective function for mathematical optimization.|$|E
50|$|<b>Tabu</b> <b>search</b> {{enhances the}} {{performance}} of local search by relaxing its basic rule.First, at each step worsening moves can be accepted if no improving move is available (like when the search is stuck at a strict local minimum).In addition, prohibitions (henceforth the term tabu) are introduced to discourage the search from coming back to previously-visited solutions.|$|E
5000|$|The {{implementation}} of <b>tabu</b> <b>search</b> uses memory structures that describe the visited solutions or user-provided sets of rules. If a potential solution {{has been previously}} visited within a certain short-term period or if it has violated a rule, it is marked as [...] "tabu" [...] (forbidden) so that the algorithm does not consider that possibility repeatedly.|$|E
50|$|Heuristic methods change {{accuracy}} by speed. Their {{goal is to}} find a good solution {{faster than}} the traditional methods, when they are too slow or fail in solving the problem. Usually they find local optimal instead of the optimal value; however, the values are considered close enough of the final solution. Examples of this kind of method is <b>tabu</b> <b>search</b> or Genetic algorithm.|$|E
