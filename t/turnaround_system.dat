1|16|Public
40|$|Ballscrews are {{important}} motion transfer and positioning units of industrial machinery and precision machines. Positioning {{accuracy of the}} feed drive system depends upon axial stiffness of ballscrew systems. As the nut stiffness depends upon preload and operating conditions, analytical modeling of the stiffness is performed through the contact and body deformation analysis. For accurate contact analysis, the contact angle variation between balls and grooves is incorporated in the developed model. To verify the developed mathematical stiffness model, experiments are conducted on the test-rig. Through the uncertainty analysis according to GUM (Guide to the expression of Uncertainty in Measurement), {{it is confirmed that}} the formulated stiffness model has over 85 % estimation accuracy. After constructing the ballscrew DB, a quick <b>turnaround</b> <b>system</b> for the nut stiffness estimation has been developed in this research...|$|E
50|$|In case of batch <b>systems,</b> <b>turnaround</b> {{time will}} include time taken in forming batches, batch {{execution}} and printing results.|$|R
40|$|The study {{reported}} was undertaken {{to investigate the}} requirements placed on the Space Tug by the ground operations. On {{the basis of the}} results obtained, {{it will be possible to}} consider in future Tug systems studies the full spectrum of both ground and flight operations requirements in defining selected Tug configurations. The central core of the study consists of a functional analysis of ground operations during the Tug <b>turnaround.</b> Electronic <b>system</b> studies were initiated concurrently with the functional analysis study phase to evaluate interrelationships between ground and vehicle checkout and fault isolation capability...|$|R
40|$|In view of {{the energy}} <b>turnaround</b> get the <b>system</b> of power {{generation}} and consumption increasingly out of balance. The incentive systems of supply-oriented power demand are varied and must be supported for reasons of network stability and associated with it security of supply. An essential condition for an energy adaptable production is an energy optimized production planning...|$|R
50|$|SuperDot was the {{electronic}} system {{used by the}} New York Stock Exchange to route market orders and limit orders from investors or their agents to a specialist located {{on the floor of}} the exchange. SuperDot was the upgraded form of the previous electronic system used to route orders, known as the Designated Order <b>Turnaround</b> (DOT) <b>system.</b> Since 1976, most of the orders in NYSE had been transmitting electronically to specialists screens over the DOT or via the upgraded SuperDot. In 2009, SuperDOT was replaced by the new NYSE Super Display Book system (SDBK) for processing orders. In 2012, Display Book was replaced by Universal Trading Platform (UTP).|$|R
40|$|Two {{decision-makers}} {{from the}} acute-care sector {{weigh in on}} the issue of relevant research. Between the two of them they look for patient-defined research, evidence to support the conclusions, information that can lead to interventions designed to improve quality and outcomes and defined control mechanisms to properly identify the practices that improved the system. Three examples are cited and discussed. The context is set by comments from one of Canada’s leading researchers and the use of research from one of this decade’s most lauded <b>system</b> <b>turnarounds...</b>|$|R
40|$|Initial {{calculations}} of a redesign {{of the solid}} rocket booster joint that failed during the shuttle tragedy showed that the design had a weight penalty associated with it. Optimization techniques were {{to be applied to}} determine if there was any way to reduce the weight while keeping the joint opening closed and limiting the stresses. To allow engineers to examine as many alternatives as possible, a system was developed consisting of existing software that coupled structural analysis with optimization which would execute on a network of computer workstations. To increase <b>turnaround,</b> this <b>system</b> took advantage of the parallelism offered by the finite difference technique of computing gradients to allow several workstations to contribute to the solution of the problem simultaneously. The resulting system reduced the amount of time to complete one optimization cycle from two hours to one-half hour with a potential of reducing it to 15 minutes. The current distributed system, which contains numerous extensions, requires one hour turnaround per optimization cycle. This would take four hours for the sequential system...|$|R
40|$|Interconnecting {{processors}} is {{one approach}} to organizing a computer facility to better serve its users. The objective of such system organization {{is to reduce}} the elapsed time a job resides in the <b>system</b> (<b>turnaround</b> time) while simultaneously increasing the workload the equipment can handle (throughput.) Alternative philosophies of multiprocessing are discussed and, in particular, a concept which enables coupling an IBM 7090 and an IBM 7040 to meet this objective. In this system the smaller machine performs supervisory and input-output functions while one performs program assembly and computation. th larger A directly coupled multiprocessing system by E. C. Smith, Jr. We will be concerned with a general computer center which processes, primarily, problems originating with engineers an...|$|R
40|$|This paper {{describes}} the MetaCore system {{which is an}} ASIP (Application-Specific Instruction set Processor) development system targeted for DSP applications. The goal of MetaCore system is to offer an efficient design methodology meeting specifications given as a combination of performance, cost and design <b>turnaround</b> time. MetaCore <b>system</b> consists of two major design stages: design exploration and design generation. In the design exploration stage, MetaCore system accepts a set of benchmark programs and a formal specification of ISA (Instruction Set Architecture), and estimates the hardware cost and performance for each hardware configuration being explored. Once a hardware configuration is chosen, the system helps generate a VLSI processor design {{in the form of}} HDL along with the application program development tools such as C compiler, assembler and instruction set simulator...|$|R
40|$|With the {{emergence}} of portable products as {{major players in the}} electronics market, controlling the power dissipation of integrated circuits is gaining increased importance. While progress is being made in improved battery technology to supply a larger amountofpower per unit weight of the battery,itmust also be coupled with an accompanying reduction in the power dissipation of IC's. Even for nonportable applications, as the system complexity increases, it {{is becoming more and more}} important to limit the power dissipation so as to avoid additional costs for cooling down electronic systems. In this context, it has become increasingly important to design CMOS digital circuits to ensure a lowpower dissipation. At the same time, however, it is also necessary to ensure that the speed of the circuit is not unduly sacri#ced. An additional consideration is the need for fast <b>system</b> <b>turnaround</b> times, which necessitates the use of semicustom design styles. In this work, we address...|$|R
40|$|Clinical {{decision}} support (CDS) systems can support vaccine forecasting and immunization reminders; however, immunization decision-making requires data from fragmented, independent systems. Interoperability and accurate data exchange between immunization information systems (IIS) {{is an essential}} factor to utilize Immunization CDS systems. Service oriented architecture (SOA) and Health Level 7 (HL 7) are dominant standards for web-based exchange of clinical information. We implemented a system based on SOA and HL 7 v 3 to support immunization CDS in Iran. We evaluated system performance by exchanging 1500 immunization records for roughly 400 infants between two IISs. <b>System</b> <b>turnaround</b> time {{is less than a}} minute for synchronous operation calls and the retrieved immunization history of infants were always identical in different systems. CDS generated reports were accordant to immunization guidelines and the calculations for next visit times were accurate. Interoperability is rare or nonexistent between IIS. Since inter-state data exchange is rare in United States, this approach could be a good prototype to achieve interoperability of immunization information...|$|R
40|$|The VentureStar {{reusable}} {{launch vehicle}} is discussed in this viewgraph presentation. The objectives of the VentureStar program are reviewed: (1) expendables cost too much, (2) commercial space market is growing (3) meets NASA's goals, (4) Users want fast ground turnaround, (5) users want quick access to space, (6) the offline payload processing saves time, (7) low cost access to space will enable new markets. Flight tests of the X- 33, {{which was designed to}} test the technology and is pictured in several slides, built credibility for VentureStar. One slide shows the dimensions, weight, length, LEO payload capacity, and the propulsion, in comparison for the X- 33, the VentureStar, the Space Shuttle, the Proton D- 1 e, and the Ariane V. Yet other slides outline the vehicle's features, the plan for the operation of the vehicle, from the runway, to the pad, to orbit. The planned containerized payload operation will allow for a 7 day <b>turnaround</b> for the <b>system,</b> which will allow for the planned 40 flights per year...|$|R
40|$|Abstract-This paper {{presents}} a fast and efficient contiguous allocation strategy for 3 D mesh multicomputers, {{referred to as}} Turning Busy List (TBL for short), which can identify a free sub-mesh of the requested size {{as long as it}} exists in the mesh system. Turning means that the orientation of the allocation request is changed when no sub-mesh is available in the requested orientation. The TBL strategy relies on a new approach that maintains a list of allocated sub-meshes to determine all the regions consisting of nodes that cannot be used as base nodes for the requested sub-mesh. These nodes are then subtracted from the right border plane of the allocated sub-meshes to find the nodes that can be used as base nodes for the required sub-mesh size. Results from extensive simulations under a variety of system loads confirm that the TBL strategy incurs much less allocation overhead than all of the existing contiguous allocation strategies for 3 D mesh multicomputers and delivers competitive performance in terms of parameters such as the average <b>turnaround</b> times and <b>system</b> utilization. Moreover, the time complexity of the TBL strategy is much lower than that of the existing strategies...|$|R
40|$|The {{proposed}} Europa Mission concept {{contains many}} engineering and scientific instruments that consume varying amounts {{of power and}} produce varying amounts of data throughout the mission. System-level power and data usage must be well understood and analyzed to verify design requirements. Numerous cross-disciplinary tools and analysis models are used to simulate the system-level spacecraft power and data behavior. This paper addresses the problem of orchestrating a consistent set of models, tools, and data in a unified analysis toolchain when ownership is distributed among numerous domain experts. An analysis and simulation environment was developed {{as a way to}} manage the complexity of the power and data analysis toolchain and to reduce the simulation <b>turnaround</b> time. A <b>system</b> model data repository is used as the trusted store of high-level inputs and results while other remote servers are used for archival of larger data sets and for analysis tool execution. Simulation data passes through numerous domain-specific analysis tools and end-to-end simulation execution is enabled through a web-based tool. The use of a cloud-based service facilitates coordination among distributed developers and enables scalable computation and storage needs, and ensures a consistent execution environment. Configuration management is emphasized to maintain traceability between current and historical simulation runs and their corresponding versions of models, tools and data...|$|R
40|$|Since {{multicore}} systems offer greater performance via parallelism, future computing is progressing towards use of multicore {{machines with}} {{large number of}} cores. However, the performance of emerging multithreaded programs often does not scale to fully utilize the available cores. Therefore, simultaneously running multiple multithreaded applications becomes inevitable to fully exploit such machines. However, multicore machines pose a challenge for the OS with respect to maximizing performance and throughput {{in the presence of}} multiple multithreaded programs. We have observed that the state-of-the-art contention management algorithms fail to effectively coschedule multithreaded programs on multicore machines. To address the above challenge, we present ADAPT, a scheduling framework that continuously monitors the resource usage of multithreaded programs and adaptively coschedules them such that they interfere with each other’s performance as little as possible. In addition, it adaptively selects appropriate memory allocation and scheduling policies according to the workload characteristics. We have implemented ADAPT on a 64 -core Supermicro server running Solaris 11 and evaluated it using 26 multithreaded programs including the TATP database application, SPECjbb 2005, programs from Phoenix, PARSEC, and SPEC OMP. The experimental results show that ADAPT substantially improves total <b>turnaround</b> time and <b>system</b> utilization relative to the default Solaris 11 scheduler...|$|R
40|$|Abstract-In this paper, a {{fast and}} {{efficient}} busy-list sub-mesh allocation strategy, {{referred to as}} Turning Busy List (TBL), is suggested for 3 D mesh connected multicomputers. Turning means that {{the orientation of the}} allocation request is changed when no sub-mesh is available in the requested orientation. The TBL strategy considers only those available free sub-meshes that border from the left on some allocated sub-meshes or have their left boundaries aligned with that of the mesh. Moreover, the TBL strategy uses an efficient scheme to facilitate the detection of such available sub-meshes with low allocation overhead. The basic idea in this strategy is to maintain a list of allocated sub-meshes to determine all the nodes that cannot be used as base nodes for the requested sub-mesh. These nodes are then subtracted from the right border plane of the allocated sub-meshes to find the nodes that can be used as base nodes for the required sub-mesh size. The TBL strategy is able to identify a free sub-mesh of the requested size as long as it exists in the mesh. Results from extensive simulations under various system loads have revealed that the TBL strategy incurs much less allocation overhead than all of the existing contiguous allocation strategies for 3 D mesh and delivers competitive performance in terms of parameters such as the average <b>turnaround</b> times and <b>system</b> utilization. Moreover, the time complexity of the TBL strategy is much lower than that of the existing strategies...|$|R
40|$|Abstract Efficient {{processor}} allocation and {{job scheduling}} algorithms are critical if the full computational power of large-scale multicomputers {{is to be}} harnessed effectively. Processor allocation is responsible for selecting the set of processors on which parallel jobs are executed, whereas job scheduling is responsible for determining {{the order in which}} the jobs are executed. Many processor allocation strategies have been devised for mesh-connected multicomputers and these can be divided into two main categories: contiguous and non-contiguous. In contiguous allocation, jobs are allocated distinct contiguous processor sub-meshes for the duration of their execution. Such a strategy could lead to high processor fragmentation which degrades system performance in terms of, for example, the <b>turnaround</b> time and <b>system</b> utilisation. In non-contiguous allocation, a job can execute on multiple disjoint smaller sub-meshes rather than waiting until a single sub-mesh of the requested size and shape is available. Although non-contiguous allocation increases message contention inside the network, lifting the contiguity condition can reduce processor fragmentation and increase system utilisation. Processor fragmentation can be of two types: internal and external. The former occurs when more processors are allocated to a job than it requires while the latter occurs when there are free processors enough in number to satisfy another job request, but they are not allocated to it because they are not contiguous. A lot of efforts have been devoted to reducing fragmentation, and a number of contiguous allocation strategies have been devised to recognize complete sub-meshes during allocation. Most of these strategies have been suggested for 2 D mesh-connected multicomputers. However, although the 3 D mesh has been the underlying network topology for a number of important multicomputers, there has been relatively little activity with regard to designing similar strategies for such a network. The very few contiguous allocation strategies suggested for the 3 D mesh achieve complete sub-mesh recognition ability only at the expense of a high allocation overhead (i. e., allocation and de-allocation time). Furthermore, the allocation overhead in the existing contiguous strategies often grows with system size. The main challenge is therefore to devise an efficient contiguous allocation strategy that can exhibit good performance (e. g., a low job turnaround time and high system utilisation) with a low allocation overhead. The first part of the research presents a new contiguous allocation strategy, referred to as Turning Busy List (TBL), for 3 D mesh-connected multicomputers. The TBL strategy considers only those available free sub-meshes which border from the left of those already allocated sub-meshes or which have their left boundaries aligned with that of the whole mesh network. Moreover TBL uses an efficient scheme to facilitate the detection of such available sub-meshes while maintaining a low allocation overhead. This is achieved through maintaining a list of allocated sub-meshes in order to efficiently determine the processors that can form an allocation sub-mesh for a new allocation request. The new strategy is able to identify a free sub-mesh of the requested size as long as it exists in the mesh. Results from extensive simulations under various operating loads reveal that TBL manages to deliver competitive performance (i. e., low turnaround times and high system utilisation) with a much lower allocation overhead compared to other well-known existing strategies. Most existing non-contiguous allocation strategies that have been suggested for the mesh suffer from several problems that include internal fragmentation, external fragmentation, and message contention inside the network. Furthermore, the allocation of processors to job requests is not based on free contiguous sub-meshes in these existing strategies. The second part of this research proposes a new non-contiguous allocation strategy, referred to as Greedy Available Busy List (GABL) strategy that eliminates both internal and external fragmentation and alleviates the contention in the network. GABL combines the desirable features of both contiguous and non-contiguous allocation strategies as it adopts the contiguous allocation used in our TBL strategy. Moreover, GABL is flexible enough in that it could be applied to either the 2 D or 3 D mesh. However, {{for the sake of the}} present study, the new non-contiguous allocation strategy is discussed for the 2 D mesh and compares its performance against that of well-known non-contiguous allocation strategies suggested for this network. One of the desirable features of GABL is that it can maintain a high degree of contiguity between processors compared to the previous allocation strategies. This, in turn, decreases the number of sub-meshes allocated to a job, and thus decreases message distances, resulting in a low inter-processor communication overhead. The performance analysis here indicates that the new proposed strategy has lower turnaround time than the previous non-contiguous allocation strategies for most considered cases. Moreover, in the presence of high message contention due to heavy network traffic, GABL exhibits superior performance in terms of the turnaround time over the previous contiguous and non-contiguous allocation strategies. Furthermore, GABL exhibits a high system utilisation as it manages to eliminate both internal and external fragmentation. The performance of many allocation strategies including the ones suggested above, has been evaluated under the assumption that job execution times follow an exponential distribution. However, many measurement studies have convincingly demonstrated that the execution times of certain computational applications are best characterized by heavy-tailed job execution times; that is, many jobs have short execution times and comparatively few have very long execution times. Motivated by this observation, the final part of this thesis reviews the performance of several contiguous allocation strategies, including TBL, in the context of heavy-tailed distributions. This research is the first to analyze the performance impact of heavy-tailed job execution times on the allocation strategies suggested for mesh-connected multicomputers. The results show that the performance of the contiguous allocation strategies degrades sharply when the distribution of job execution times is heavy-tailed. Further, adopting an appropriate scheduling strategy, such as Shortest-Service-Demand (SSD) as opposed to First-Come-First-Served (FCFS), can significantly reduce the detrimental effects of heavy-tailed distributions. Finally, while the new contiguous allocation strategy (TBL) is as good as the best competitor of the previous contiguous allocation strategies in terms of job <b>turnaround</b> time and <b>system</b> utilisation, it is substantially more efficient in terms of allocation overhead...|$|R

