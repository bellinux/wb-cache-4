274|1999|Public
500|$|Here [...] is the unitary {{operator}} representing [...] on the Hilbert {{space on}} which [...] is defined and [...] is an -dimensional {{representation of the}} Lorentz group. The <b>transformation</b> <b>rule</b> is the second Wightman axiom of quantum field theory.|$|E
2500|$|It can {{be shown}} that the stress tensor is a {{contravariant}} second order tensor, which is a statement of how it transforms under a change of the coordinate system. From an xi-system to an [...] xi' -system, the components σij in the initial system are transformed into the components σij' [...] in the new system according to the tensor <b>transformation</b> <b>rule</b> (Figure 2.4): ...|$|E
2500|$|... {{should be}} treated as 4-vectors in manipulations. It also means that indices can be raised and lowered on the [...] using the metric [...] as with any 4-vector. The {{notation}} is called the Feynman slash notation. The slash operation maps the basis [...] of , or any 4-dimensional vector space, to basis vectors [...] The <b>transformation</b> <b>rule</b> for slashed quantities is simply ...|$|E
40|$|Part 2 : Full PapersInternational audienceModel <b>{{transformation}}</b> <b>rules</b> are {{the central}} part of model transformation. Many model transformation approaches provide some mechanisms to construct <b>transformation</b> <b>rules</b> in industrial and academic research. However, <b>transformation</b> <b>rules</b> are typically created manually in these approaches. As far as we know, there are no complete solutions that construct <b>transformation</b> <b>rules</b> automatically. In this paper, we propose a rough set based approach to construct <b>transformation</b> <b>rules</b> semi-automatically. Construction approach of rough set is improved in order to support the transformations between different meta-models, then the corresponding algorithm to construct <b>transformation</b> <b>rules</b> is presented. We also provide the measurement indicators of <b>transformation</b> <b>rules</b> to support selecting proper rules from many <b>rules</b> which meet <b>transformation</b> requirement. Three kinds of experiments for problems with distinct complexity and size are given for the validation of the proposed method...|$|R
40|$|In {{this paper}} we {{introduce}} formal definitions for several graph transformation systems modeling three dimensional h-adaptive Finite Element Method (3 D h-FEM) algorithms with tetrahedral finite elements. We introduce a composite graph {{representation of the}} computational mesh and graph <b>transformation</b> <b>rules</b> expressing the mesh operations. In particular, there are graph <b>transformation</b> <b>rules</b> expressing the generation of the initial mesh consisting with tetrahedral finite elements, graph <b>transformation</b> <b>rules</b> expressing {{the construction of an}} elimination tree for interfacing with multi-frontal direct solver algorithm, graph <b>transformation</b> <b>rules</b> selecting sub-graph representing finite elements for further refinements, graph <b>transformation</b> <b>rules</b> responsible for execution of mesh refinements. We also discuss several benefits of using graph transformation system instead of classical FEM approach, including the benefits from the viewpoint of multi-frontal direct solvers...|$|R
40|$|This paper {{describes}} the ongoing {{work in the}} design and implementation of a program transformation system for educational purposes. The system is based on Asf+Sdf for the implementation of the application of <b>transformation</b> <b>rules</b> and on Seal for the implementation of the user interface. The <b>transformation</b> <b>rules</b> are given in a mixture of CIP-L and Clean: Disciplean. The Disciplean <b>transformation</b> <b>rules</b> are not `hard-wired' in the system but they are stored in a kind of data base and they are available via an editor. This allows a flexible way of extending the set of <b>transformation</b> <b>rules...</b>|$|R
2500|$|One {{should note}} that this is {{different}} from the <b>transformation</b> <b>rule</b> for the , which are now treated as (fixed) basis vectors. The designation of the 4-tuple [...] as a 4-vector sometimes found in the literature is thus a slight misnomer. The latter transformation corresponds to an active transformation of the components of a slashed quantity in terms of the basis , and the former to a passive transformation of the basis [...] itself.|$|E
2500|$|A {{cellular}} automata (CA) is {{a discrete}} dynamical system {{consisting of a}} uniform (finite or infinite) grid of cells. Each cell can be in only one of {{a finite number of}} states at a discrete time. As time moves forward, the state of each cell in the grid is determined by a <b>transformation</b> <b>rule</b> that factors in its previous state and the states of the immediately adjacent cells (the cell's [...] "neighborhood"). The most well-known example of a cellular automaton is John Horton Conway's [...] "Game of Life", which he described in 1970.|$|E
2500|$|In the {{discussion}} to follow, a proof {{is presented as}} a sequence of numbered lines, with each line consisting of a single formula followed by a reason or justification for introducing that formula. Each premise of the argument, that is, an assumption introduced as an hypothesis of the argument, is listed {{at the beginning of the}} sequence and is marked as a [...] "premise" [...] in lieu of other justification. The conclusion is listed on the last line. A proof is complete if every line follows from the previous ones by the correct application of a <b>transformation</b> <b>rule.</b> (For a contrasting approach, see proof-trees).|$|E
40|$|Abstract. Formal program {{development}} by stepwise refinement involves {{a lot of}} work discharging proof obligations. Transformational techniques can reduce this work: applying correct <b>transformation</b> <b>rules</b> removes the need for verifying the correctness of each refinement step individually. However, a crucial problem is how to identify appropriate <b>transformation</b> <b>rules.</b> In this paper, a method is proposed to incrementally construct a set of correctness preserving <b>transformation</b> <b>rules</b> for refinement relations in arbitrary specification formalisms. Transformational developments are considered as proofs, which are generalised. This results in a framework where specific example refinements can be systematically generalised to more applicable <b>transformation</b> <b>rules.</b> The method is implemented in the Isabelle theorem prover and demonstrated on an example of data refinement...|$|R
50|$|The {{basic concept}} in {{defining}} model transformations within VIATRA2 is the (graph) pattern. A pattern {{is a collection}} of model elements arranged into a certain structure fulfilling additional constraints (as defined by attribute conditions or other patterns). Patterns can be matched on certain model instances, and upon successful pattern matching, elementary model manipulation is specified by graph <b>transformation</b> <b>rules.</b> Like OCL, graph <b>transformation</b> <b>rules</b> describe pre- and postconditions to the transformations, but graph <b>transformation</b> <b>rules</b> are guaranteed to be executable, which is a main conceptual difference. Graph <b>transformation</b> <b>rules</b> are assembled into complex model transformations by abstract state machine rules, which provide a set of commonly used imperative control structures with precise semantics.|$|R
40|$|Abstract. The STREAM (Strategy for Transition Between Requirements and Architectural Models) process allows {{systematic}} {{generation of}} initial architectural design models from oriented goals requirements models through an informal definition of model <b>transformation</b> <b>rules.</b> It was {{observed that the}} first two activities in this process are time-consuming and error-prone because they involve model <b>transformation</b> <b>rules</b> that are not automated. This article advocates the automation of such <b>transformation</b> <b>rules,</b> {{with the intention of}} improving the productivity of the process {{and the quality of the}} models produced...|$|R
2500|$|In {{describing}} the transformation rules, we may introduce a metalanguage symbol [...] It {{is basically a}} convenient shorthand for saying [...] "infer that". The format is , in which [...] is a (possibly empty) set of formulas called premises, and [...] is a formula called conclusion. The <b>transformation</b> <b>rule</b> [...] means that if every proposition in [...] is a theorem (or has the same truth value as the axioms), then [...] is also a theorem. Note that considering the following rule Conjunction introduction, we will know whenever [...] {{has more than one}} formula, we can always safely reduce it into one formula using conjunction. So for short, from that time on we may represent [...] as one formula instead of a set. Another omission for convenience is when [...] is an empty set, in which case [...] may not appear.|$|E
50|$|The needed {{transformation}} of v {{is called the}} contravariant <b>transformation</b> <b>rule.</b>|$|E
50|$|Negation {{introduction}} is {{a rule of}} inference, or <b>transformation</b> <b>rule,</b> in {{the field}} of propositional calculus.|$|E
40|$|This paper {{presents}} an approach for inducing <b>transformation</b> <b>rules</b> that map natural-language sentences into a formal semantic representation language. The approach assumes a formal grammar for the target representation language and learns <b>transformation</b> <b>rules</b> that exploit the non-terminal symbols in this grammar. Patterns for the <b>transformation</b> <b>rules</b> are learned using an induction algorithm based on longestcommon-subsequences previously developed for an information extraction system. Experimental {{results are presented}} on learning to map English coaching instructions for Robocup soccer into an existing formal language for coaching simulated robotic agents. ...|$|R
25|$|The lambda {{calculus}} {{consists of a}} language of lambda terms, which is defined by a certain formal syntax, {{and a set of}} <b>transformation</b> <b>rules,</b> which allow manipulation of the lambda terms. These <b>transformation</b> <b>rules</b> can be viewed as an equational theory or as an operational definition.|$|R
40|$|Abstract. <b>Transformation</b> <b>rules</b> are a {{convenient}} means to specify partially defined and nondeterministic computations. We describe a rulebased programming system which has primitive operators for defining elementary rules and for computing with unions, compositions, reflexivetransitive closures, and normal forms of <b>transformation</b> <b>rules.</b> To this end, we have implemented a Mathematica package called FunLog, which provides full support for programming with the primitive operators proposed by us. We give a brief account {{to the main}} concepts and constructs for programming with <b>transformation</b> <b>rules,</b> and illustrate their usefulness with some interesting examples. ...|$|R
5000|$|... that mixes {{different}} distributions , {{is called}} a mixture distribution, mixture or -parameterization or mixture for short. All such parameterizations are related through an affine transformation [...] A parameterization with such a <b>transformation</b> <b>rule</b> is called flat.|$|E
5000|$|Here [...] is the unitary {{operator}} representing [...] on the Hilbert {{space on}} which [...] is defined and [...] is an -dimensional {{representation of the}} Lorentz group. The <b>transformation</b> <b>rule</b> is the second Wightman axiom of quantum field theory.|$|E
50|$|This is the {{explicit}} {{form of the}} covariant <b>transformation</b> <b>rule.</b> The notation of a normal derivative {{with respect to the}} coordinates sometimes uses a comma, as followswhere the index i is placed as a lower index, because of the covariant transformation.|$|E
40|$|This paper investigates a novel {{approach}} to unsupervised morphology induction relying on community detection in networks. In a first step, morphological <b>transformation</b> <b>rules</b> are automatically acquired based on graphical similarities between words. These rules encode substring substitutions for transforming one word form into another. The <b>transformation</b> <b>rules</b> are then applied {{to the construction of}} a lexical network. The nodes of the network stand for words while edges represent <b>transformation</b> <b>rules.</b> In the next step, a clustering algorithm is applied to the network to detect families of morphologically related words. Finally, morpheme analyses are produced based on the <b>transformation</b> <b>rules</b> and the word families obtained after clustering. While still in its preliminary development stages, this method obtains encouraging results at Morpho Challenge 2009, which demonstrate the viability of the approach...|$|R
40|$|Thèse en co-tutelleWe {{present an}} {{approach}} based on Model-Driven Development ideas to create Software Product Lines(SPLs). In Model-Driven SPL approaches, the derivation {{of a product}} starts from a domain application model. This model is transformed through several stages reusing model <b>transformation</b> <b>rules</b> until a product is obtained. <b>Transformations</b> <b>rules</b> are selected according to variants included in configurations created by product designers. Configurations include variants from variation points, which are relevant characteristics representing the variability of a product line. Our approach (1) provides mechanisms to improve the expression of variability of Model-Driven SPLs by allowing designers to create fine-grained configurations of products, and (2) integrates a product derivation process which uses decision models and Aspect-Oriented Programming facilitating the reuse, adaptation and composition of model <b>transformation</b> <b>rules.</b> We introduce constraint models which {{make it possible for}} product line architects to capture the scope of product lines using the concepts of constraint, cardinality property and structural dependency property. To configure products, we create domain models and binding models, which are sets of bindings between model elements and variants and satisfy the constraint models. We define a decision model as a set of aspects. An aspect maintains information of what and when <b>transformations</b> <b>rules</b> that generate commonalities of products must be intercepted (joinpoints) and what <b>transformation</b> <b>rules</b> (advices) that generate variable structures must be executed instead. Our strategy maintains uncoupled variants from model <b>transformation</b> <b>rules.</b> This solves problems related to modularization, coupling, flexibility and maintainability of <b>transformations</b> <b>rules</b> because they are completely separated from variants; thus, they can evolve independently...|$|R
40|$|International audienceModel transformations occur {{everywhere}} in the Model-Driven Development processes. The substrate of these transformations is often an alignment, more or less precise, between a source and a target. There are two main approaches to help {{the development of model}} transformations by a semi-automatic generation. The first approach is based on meta-model alignement and searches for mappings that provide <b>transformation</b> <b>rules.</b> In the second one (Model Transformation Based Example), <b>transformation</b> <b>rules</b> are inferred from a set of transformation examples. We develop an integrated MTBE approach where examples are semi-automatically aligned before being used for learning the <b>transformation</b> <b>rules</b> with Formal Concept Analysis...|$|R
5000|$|The first <b>transformation</b> <b>rule</b> is {{shorthand}} {{meaning that}} all quark fields for all generations must be rotated by an identical phase simultaneously. The fields [...] and [...] are the 2nd (muon) and 3rd (tau) generation analogs of [...] and [...] fields.|$|E
5000|$|... {{according}} to general theory either is a representation or a projective representation of [...] It {{will turn out}} to be a projective representation. The elements of U, when endowed with the <b>transformation</b> <b>rule</b> given by S, are called bispinors or simply spinors.|$|E
50|$|In the {{fundamental}} branches of modern physics, namely general relativity and its widely applicable subset special relativity, {{as well as}} relativistic quantum mechanics and relativistic quantum field theory, the Lorentz transformation is the <b>transformation</b> <b>rule</b> under which all four-vectors and tensors containing physical quantities transform.|$|E
40|$|Developers of <b>transformation</b> <b>rules</b> for user {{interface}} models {{should have the}} option to support usability in their transformations. As different aspects of usability highly depend on each other, <b>transformation</b> <b>rules</b> should be able to model these dependencies. We provide an example how this can be done in a transformation language through a QVT Relations dialect...|$|R
2500|$|The {{reduction}} in combinator size {{that results from}} the new <b>transformation</b> <b>rules</b> ...|$|R
40|$|We {{present an}} off-shell {{formulation}} of a matter-Yang-Mills system coupled to supergravity in five-dimensional space-time. We give an invariant action {{for a general}} system of vector multiplets and hypermultiplets coupled to supergravity {{as well as the}} supersymmetry <b>transformation</b> <b>rules.</b> All the auxiliary fields are retained, so that the supersymmetry <b>transformation</b> <b>rules</b> remain unchanged even when the action is changed...|$|R
5000|$|Given the {{components}} of the four vectors or tensors in some frame, the [...] "transformation rule" [...] allows one to determine the altered components of the same four vectors or tensors in another frame, which could be boosted or accelerated, relative to the original frame. A [...] "boost" [...] should not be conflated with spatial translation, rather it's characterized by the relative velocity between frames. The <b>transformation</b> <b>rule</b> itself depends on the relative motion of the frames. In the simplest case of two inertial frames the relative velocity between enters the <b>transformation</b> <b>rule.</b> For rotating reference frames or general non-inertial reference frames, more parameters are needed, including the relative velocity (magnitude and direction), the rotation axis and angle turned through.|$|E
5000|$|... jQVT: A {{compiled}} QVT {{engine for}} Java, using Xbase {{in place of}} OCL. A QVT-relational transformation is first compiled into Java source code, which then directly produces the target model from source ones at run-time, without interpreting the <b>transformation</b> <b>rule</b> again. It supports EMF models, as well as plain Java objects.|$|E
5000|$|Here [...] are the {{components}} of the pseudotensor in the new and old bases, respectively, [...] is the transition matrix for the contravariant indices, [...] is the transition matrix for the covariant indices, and [...]This <b>transformation</b> <b>rule</b> differs from the rule for an ordinary tensor only by the presence of the factor (−1)A.|$|E
5000|$|The <b>transformation</b> <b>rules</b> for polar vectors and pseudovectors can be compactly stated as ...|$|R
40|$|We {{show how}} to formalise {{different}} kinds of loop constructs within the refinement calculus, {{and how to use}} this formalisation to derive general <b>transformation</b> <b>rules</b> for loop constructs. The emphasis is on using algebraic methods for reasoning about equivalence and refinement of loop constructs, rather than operational ways of reasoning about loops in terms of their execution sequences. We apply the algebraic reasoning techniques to derive a collection of <b>transformation</b> <b>rules</b> for action systems an for guarded loops. These include <b>transformation</b> <b>rules</b> that have been found important in practical program derivations: data refinement and atomicity refinement of action systems; and merging, reordering, and data refinement of loops with stuttering transitions...|$|R
40|$|Abstract. The paper {{provides}} {{a brief overview}} of the HyperMeData language specifically designed to support data interchange among heterogeneous information systems, and pays attention to meta-level transformation descriptions. The language is sufficiently complex and powerful to catch both intra- and inter-data schema relationships (i. e., to describe both data schemas and data transformations), nonetheless, its routine use requires employing a set of metalevel <b>transformation</b> <b>rules</b> to handle typical schematic differences among semantically similar database objects. The classification of schematic heterogeneities in multidatabases is used as the basis for proposing inter-attribute correspondences (meta-level <b>transformation</b> <b>rules)</b> and the respective translations to HyperMeData descriptions of data <b>transformations</b> (<b>transformation</b> <b>rules).</b> ...|$|R
