5|2145|Public
40|$|This study {{evaluates the}} {{relationship}} between eye gaze and mouse cursor movements in a debugging task. 9 students with relevant programming experience participated in this study. Debugging difficulty was manipulated (error types; lexical, logical and syntactic) {{in order to measure}} the effects on debugging performance (accuracy and reaction time), eye gaze and mouse cursor behavior (frequency and duration of visits of target areas vs. non-target areas). Performance data showed <b>that</b> <b>lexical</b> <b>errors</b> are easier to find than logical errors. Mouse cursor behavior was a significant indication of the level of difficulty and therefore performance. The general pattern of mouse movements was comparable with eye gaze patterns. This study indicates that mouse data does add relevant information on top of eye gaze. These results support the idea of using mouse tracking as an alternative for inferring intentions...|$|E
40|$|This paper {{presents}} {{findings of}} {{an analysis of}} lexical errors caused by semantic similarity and discusses pedagogical implications for teaching of vocabulary in Korean as a foreign or second language (KFL/KSL). It has been reported <b>that</b> <b>lexical</b> <b>errors</b> are caused most frequently or mainly by confusion based on semantic similarity. These lexical errors are related {{to a lack of}} knowledge of the conceptual differences between the competing words. KFL/KSL learners in general feel great difficulties in differentiating lexical items with similar meaning, and the difficulties are primarily associated with the definitional concepts and semantic restrictions (Sohn, 1986 : 499). This study has attempted to refine the working definition of ‘errors of semantic similarity’ and present some examples of lexical errors of semantic similarity by category, along with attempts to explain the cause of such errors. The lexical errors presented in this study are part of 310 lexical errors identified out of 167 examination papers from three tertiary institutions. The study then discusses some pedagogical implications and strategies to deal with such problematic lexical items...|$|E
40|$|Abstract: A {{number of}} {{previous}} studies reported dissociations between the processing of number words and other words and reasoned that there are fundamentally different mental representations and/or processing strategies related to these types of words. Messina et al. reported the performance of Italian aphasic patients with words and number words in different tasks [1]. In line with previous studies, they found <b>that</b> <b>lexical</b> <b>errors</b> formed the dominant error type in number words, whereas phonological errors were the most frequent error type in other words. Messina et al. [1] concluded that speech production processes differ categorically between number words and other words, leading to qualitatively different error patterns in language breakdown. The present study examined error types in number words and other words {{in a sample of}} 15 German patients with aphasia using the same tasks as Messina et al. [1]. Performance in reading and repeating number words and other words was analysed. In general, we replicated the dissociation of error types between number words and other words reported by Messina et al. [1] and others. However, in contrast to previous assumptions this dissociation was not categorical but rather gradual. We suggest that psycholinguistic stimulus properties (such as number of repetitions per morpheme) and type of task influenced error types in a gradual fashion...|$|E
40|$|This {{research}} {{examines the}} order of acquisition of words of four different classes: verbs, nouns, adjectives, and adverbs in three different levels of proficiency in the FL. We apply the procedure of Error Analysis to a corpus of written compositions and analyze the interlingual and intralingual <b>lexical</b> <b>errors</b> (formal and semantic) of the Greek students of Spanish as a Foreign Language (SFL). Our results have shown {{us that there is}} relationship between the type of word and the production of <b>lexical</b> <b>errors</b> and <b>that</b> the <b>lexical</b> <b>errors</b> present different trend in the different word classes. Additionally, our results lead us {{to the conclusion that the}} word class as a stronger predictor of <b>lexical</b> <b>error</b> type than proficiency level...|$|R
40|$|We {{report on}} a phonetic {{analysis}} of instances of spontaneous phonological error repair sampled from Dutch spontaneous speech. We investigate whether phonological error repairs can be ‘prosodically marked’ and what factors constrain repair prosody. Previous studies of ‘prosodic marking’ in self-repair have suggested <b>that</b> while <b>lexical</b> <b>error</b> repairs are regularly realized with marked prosody, phonological error repairs are generally unmarked. Moreover, it has been asserted that the temporal organization of a repair has no bearing on its pitch and intensity characteristics. Our findings suggest that in fact, phonological error repairs are realized with prosodic marking as frequently, and through the same acoustic correlates as lexical repairs. We also show that repair timing is {{a significant predictor of}} prosodic marking judgments and f 0 and intensity measurements...|$|R
40|$|This study investigates {{quantitative}} and qualitative differences {{in the production of}} <b>lexical</b> <b>errors</b> in the English written performance by young Spanish and German learners of English. The essays produced by the subjects were analysed and <b>lexical</b> <b>errors</b> identified, classified, and quantified. A t-test was performed on the data. Results revealed that Spanish learners commit significantly fewer <b>lexical</b> <b>errors</b> than their German counterparts, t = 2. 94 at a significance level p <. 01. Despite quantitative differences, both language groups obtained similar results regarding the <b>lexical</b> <b>error</b> types. Our findings suggest <b>that</b> <b>lexical</b> transfer is an important <b>lexical</b> <b>error</b> source in German, as well as in Spanish informants. ...|$|R
40|$|This {{thesis is}} about an {{analysis}} of the Indonesian translation from an English book, entitled "The New Kid?s Book of Bible People". The writer wants to know what errors occur in the target language. In doing the analysis, the writer uses the theory of Nida and the research done by Djajanegara. The writer uses the theory of Nida in order to know the criteria of a good translation and the writer adopts the methodology of Djajanegara. By using Djajanegara?s methodology, the writer can answer the research questions about what errors that occur in the target language. Djajanegara also used the theory of Nida in doing his research. In collecting the data, the writer takes from the whole forty chapters of the book entitled " 40 Tokoh Alkitab". Then, the data is divided into four groups, which have syntax errors, lexical errors, punctuation errors, and spelling errors. Based on these groups, the writer counts the total of the errors that cause the translation inaccurate. Then, the writer finds that the biggest error that mostly causes inaccurate translation is lexical errors. Next are spelling errors and then punctuation errors. The least number of errors are syntax errors. In conclusion, the writer finds <b>that</b> <b>lexical</b> <b>errors</b> dealt with the word choice that usually causes change in meaning...|$|E
40|$|The {{importance}} of vocabulary in second language (L 2) wnnng is widely accepted, {{but there has}} been relatively little research into the lexical errors learners produce when writing in their second language. Moreover, the error categorisation frameworks used in some previous studies have addressed only a relatively limited number of lexical error categories. In this paper the authors used a more comprehensive error taxonomy based on James (1998), with some additions from Leech's semantics (1981), to analyse Thai third-year university students ' English compositions for lexical errors. The analysis revealed that (a) 'near synonyms ' were the most numerous errors, followed by 'preposition partners ' and 'suffixes', (b) the students had more difficulty with semantics than the forms of words, and (c) the identified sources of errors were mainly from L 2 intrinsic difficulty rather than the first language (Ll) transfer. The findings from the Thai students ' written lexical errors have impli-cations for L 2 vocabulary teaching and learning, which should be of interest to wider English as a Second Language (ESL) /English as a Foreign Language (EFL) contexts. Research into lexical errors The language produced by foreign language (FL) learners almost inevitably contains errors of various types. This is the process of learning a language. Empirical evidence suggests <b>that</b> <b>lexical</b> <b>errors</b> are the most frequently occurrin...|$|E
40|$|One of {{the current}} focuses of {{research}} within natural language processing is the partial and robust parsing of sentences written in natural language. Partial parsing {{could be used in}} diverse applications as data extraction, machine translation, dialogue systems, etc. His main attractiveness is that is able to handle unrestricted sentences, <b>that</b> contain <b>lexical</b> <b>errors</b> or <b>that</b> present constructions not accepted by the defined grammar. Partial parsing is an alternative to the definition of wide coverage grammars whose definition is an expensive and complex task and that present well-known problems such as overgeneration, undergeneration and ambiguity. In this paper, we present a partial parser of unrestricted natural language sentences APOLN (Analizador Parcial de Oraciones en Lenguaje Natural) which is based on finite-state machines. APOLN is an incremental parser that permits the compiling and inheritance of feature structures between levels of processing. We present the results of applying APOLN on an unrestricted Spanish corpus and we will use it in a speech dialogue system. ...|$|R
40|$|In this paper, {{we present}} APOLN (Analizador Parcial de Oraciones en Lenguaje Natural) : a partial parser of {{unrestricted}} natural language sentences based on finite -state techniques. Partial parsing {{has been used}} in several applications: syntactic parsing of unrestricted texts, data extraction systems, machine translation, solving the attachment ambiguity, speech recognition systems, text summarization, etc. The main attractiveness of partial parsing is that is able to handle unrestricted sentences, <b>that</b> contain <b>lexical</b> <b>errors</b> or <b>that</b> present constructions not accepted by the defined grammar. Partial parsing is an alternative to the definition of wide coverage grammars whose definition is an expensive and complex task and that present well-known problems such as overgeneration, undergeneration and ambiguity. We present APOLN as a tool {{that can be used to}} construct syntactically annotated corpora from lexically tagged corpora. We also present the results (precision and recall rates) of applying APOLN on unrestricted Spanish corpora, and how tagging errors influence the performance of the parser. 2...|$|R
40|$|AbstractIn this work, we analyze phonetic and {{prosodic}} pronunciation patterns from iCALL, {{a speech}} corpus designed to evaluate Mandarin mispronunciations by non-native speakers of European origin and {{to address the}} lack of large-scale, non-native corpora with comprehensive annotations for applications in CAPT (computer-assisted pronunciation training). iCALL consists of 90, 841 utterances from 305 speakers with a total duration of 142 hours. The speakers are from diverse linguistic backgrounds (spanning Germanic, Romance, and Slavic native languages). The read utterances are phonetically balanced with phonetic, tonal, and fluency annotations. Our findings on iCALL reveal <b>that</b> <b>lexical</b> tone <b>errors</b> are over six times more prevalent than phonetic errors, French speakers {{are twice as likely}} to mispronounce Tone 2, 3, 4 when compared to English speakers, native Romance language speakers are more likely to make de-aspiration and aspiration mistakes, and fluency scores correlate inversely with tone and phone error rate...|$|R
40|$|Thesis (M. A.) [...] University of Wisconsin-River Falls, 2013. 108 leaves. Includes bibliographical {{references}} (leaves 104 - 108). Advanced {{language learners}} have unique challenges with vocabulary instruction. At the advanced level, learners most likely have an extensive vocabulary {{that covers the}} high frequency words of the language. However, traditional vocabulary instruction focuses on creating breadth in vocabulary and not depth. This approach {{does not meet the}} needs of ALLs. This study aims to provide instructional suggestions through a <b>lexical</b> <b>error</b> analysis of ALL writing. The area of <b>lexical</b> <b>errors</b> in advanced language learners (ALLs) has been researched very little. This study {{takes a look at the}} <b>lexical</b> <b>errors</b> committed by advanced language learners in the university setting. The purpose of the study was to determine what types of <b>lexical</b> <b>errors</b> ALLs make, the influence of first language direct translations on <b>lexical</b> <b>errors,</b> the affect of split category cases on <b>lexical</b> <b>errors,</b> and pedagogical implications for ALL vocabulary instruction. The study uses a corpus consisting of thirty-one essays from Russian speaking and Korean speaking students at the post-secondary level. The essays were analyzed for <b>lexical</b> <b>errors.</b> Those <b>lexical</b> <b>errors</b> were then sorted and classified. Two surveys were then administered to determine the likelihood of calques and split categories as an influence on <b>lexical</b> <b>errors.</b> It was found that a statistically significant number of <b>lexical</b> <b>errors</b> were made. Over 50 % <b>lexical</b> <b>errors</b> had to do with the learner not understanding the semantic range of the word and not understanding appropriate collocations of the word. In light of the findings, several approaches and activities are provided to use with ALLs. The focus of the activities are to create individualized and differentiated instruction through the use of student writing and goal setting. The activities also focus on giving ALLs a deeper knowledge of vocabulary by using semantic mapping, studying collocations, and using concordances...|$|R
40|$|This thesis {{builds on}} {{previous}} taxonomies of <b>lexical</b> <b>errors</b> {{in order to}} find patterns of <b>lexical</b> <b>errors</b> in Norwegian intermediate and advanced English texts. This study uses a taxonomy created by Angela Hasselgren to determine patterns of <b>lexical</b> <b>errors.</b> <b>Lexical</b> <b>errors</b> are labeled by their routes (how the learner chooses the wrong word), effects (why the word is wrong) and influences (what causes the error). By locating and labeling <b>lexical</b> <b>errors</b> in two corpora, this study illustrates how <b>lexical</b> <b>errors</b> are distributed across texts written by Norwegian speakers of English. The distribution of errors uncovers patterns that in turn explain how and why some errors are repeated. By contrasting intermediate and advanced speakers, it is determined that the distributions of intermediate and advanced <b>lexical</b> <b>errors</b> are significantly different. The amount of errors is significantly smaller in the advanced texts. Comparative distributions show that intermediate and advanced learners have different ways of choosing words (routes), but the distribution of effects remains constant. Advanced learners appear to use direct L 1 -influence and intralingual influence more, while intermediate learners depend on indirect L 1 -influence...|$|R
40|$|Abstract: This {{research}} study examines {{the order of}} acquisition of four different classes of words: verbs, nouns, adjectives, and adverbs in three different levels of proficiency in the FL. We apply the procedure of Error Analysis to a corpus of written compositions and analyze the interlingual and intralingual <b>lexical</b> <b>errors</b> (formal and semantic) of Greek students studying Spanish as a Foreign Language (SFL). Our results have shown i) {{that there is a}} relationship between the type of word and the production of <b>lexical</b> <b>errors</b> and ii) <b>that</b> the evolution of <b>lexical</b> <b>errors</b> presents different trends for different word classes. Additionally, our results lead us to the conclusion that word class is a stronger predictor of <b>lexical</b> <b>error</b> type than proficiency level...|$|R
40|$|AbstractThe {{purpose of}} this study was to {{identify}} and categorize the <b>lexical</b> <b>errors</b> <b>that</b> appear in a group of elementary level Turkish EFL learners’ compositions. The participants of the study were 53 EFL students at Anadolu University, School of Foreign Languages. The <b>lexical</b> <b>errors</b> in their 4 - 5 paragraph compositions were counted and classified into seven categories. It was hoped that the results could provide some guidance for both Turkish EFL students and their teachers in terms of reducing the number of <b>lexical</b> <b>errors</b> in their compositions...|$|R
40|$|This paper {{examines}} <b>lexical</b> <b>errors</b> {{produced by}} sixty-nine (Years 7 - 12) Korean-Australian learners of Korean as a Heritage Language (KHL) in their compositions. Utilising the error analysis method {{the present study}} identifies types of high frequency <b>lexical</b> <b>errors,</b> explains the possible causes and discusses pedagogical implications derived from the results. The study identifies six types of <b>lexical</b> <b>errors</b> such as simplification and code-switching and has provides interpretations and/or explanations for each type along with examples. It is suggested {{that the nature of}} their <b>lexical</b> <b>errors</b> is largely affected by both interlingual and intralingual factors, as well as socio-linguistic factors such as their exposure to the heritage contexts. It is argued {{that there is a need}} for heritage learners to participate in remedial teaching and active learning for vocabulary acquisition, and it concludes with discussions of some pedagogical suggestions...|$|R
40|$|My {{study is}} of error types that are {{particularly}} {{focused on the}} types of errors in English compositions. The types of errors in English compositions {{are based on the}} theory of Professor James Hendrickson, in which the types of errors are classified according to the linguistic category. Therefore, it includes the <b>errors</b> in <b>lexical,</b> morphological, syntactic and orthographic categories. By discovering the students? errors in writing their compositions, this thesis is also to show the most committed type of errors based on linguistic category. I conduct my study by using descriptive and text analysis approach. In this study, I collect the data from Indonesian students who are learning English as a second language at the English Department in Petra Christian University. Specifically, they are the students of 2003 who take their Writing I class in 2003 / 2004 academic year. I particularly use picture story in order to raise their ideas in writing a composition. There are fifteen drafts to be the data samples, which are then analyzed. The results of the analyses show that the morphological errors gain the highest percentage, while the orthographic errors get the lowest percentage in the compositions. It {{is important to note that}} the syntactic errors also take a dominant percentage in the compositions. Since the students mostly produced the morphological and syntactic errors, the findings might suggest that most of the students have problems and difficulties in the application of the Standard English grammar. In addition, it might also suggest that the students? repertoire of English vocabulary items is sufficient in writing a composition, due to the fact <b>that</b> the <b>lexical</b> <b>errors</b> only count for a small percentage. Here, the students are able to use simple lexical items in appropriate situation in writing their compositions...|$|R
40|$|Abstract This article {{deals with}} <b>lexical</b> <b>errors,</b> i. e., errors {{stemming}} from an insufficient knowledge of properties—semantic, formal and combinatorial—of <b>lexical</b> units. Such <b>errors</b> are frequent in written texts produced by language learners. They {{indicate that there}} are gaps to be filled in the learner’s lexical knowledge, in particular, {{when it comes to}} learners’ ability to efficiently use lexical and paraphrastic relations in text production. Our analysis of a corpus of texts produced by learners of French as a second language, based on a typology of <b>lexical</b> <b>errors</b> we have developed, has revealed a high number of <b>lexical</b> <b>errors,</b> in particular those involving meaning properties of lexical units and their restricted lexical cooccurrence properties. These findings will be used {{for the development of a}} learners’ dictionary based on the Meaning-Text linguistic theory and designed in such a way as to facilitate the acquisition and active use of lexical and paraphrastic relations...|$|R
40|$|Because many translators fail {{to deliver}} {{the message of the}} {{original}} text into the target language, the writer wants to do a research about a translation of Jeffrey Archer?s novel, which is not so comfortable to read and confusing. In researching, the writer uses Peter Newmark?s theory, who stated {{that the most important thing}} of translation is transferring the meaning. For this research, the writer collects the data, that is the Indonesian version from chapter one, two, five, seven and nine because they have more <b>lexical</b> <b>errors</b> than the others; then she uses tables in showing the kind of <b>lexical</b> <b>errors</b> of each word or phrase. There are five kinds of <b>lexical</b> <b>error,</b> <b>that</b> are misstatement of fact, less formal, less accurate according to what is stated in the original text, less accurate because there are words added in the translation and less accurate because there are words omitted in the translation. The writer finds that there are three kinds of less accurate that happen in the translation as her findings; they are less accurate according to what is stated in the original text, less accurate because there are words added in the translation and less accurate because there are words omitted in the translation. The <b>lexical</b> <b>errors</b> which are included in three of them, do not have the same message like what is meant in the original text. As the conclusion, the writer has an opinion that the Indonesian version of the novel has many <b>lexical</b> <b>errors</b> which cause different interpretations and confusion to the readers...|$|R
50|$|Features of an {{expressive}} language disorder vary, but have certain features in common such as: limited vocabulary, inability to produce complex grammar, and more <b>lexical</b> <b>errors.</b>|$|R
40|$|The writer {{takes the}} title "An Analysis of Grammatical and <b>Lexical</b> <b>Errors</b> in 1001 English Conversation Percakapan Bahasa Ingqris Written by Syafi'i Mashur". The {{problems}} {{the writer is}} going to find out are: what grammatical and <b>lexical</b> <b>errors</b> are in the book and identifying the frequency of occurence of each type of errors. The writer applies the error analysis the kinds of errors in grammar and lexicon, which are classified into the types of errors of omission, addition, misformation and misordering according to surface strategy taxonomy. The approach is qualitative and the method used is the error analysis. The analysis of the data is done by identifying the grammatical and <b>lexical</b> <b>errors</b> found in the book; forming the reconstructed corrections in the target language; classifying the errors of omission, addition, misformation and misordering; and counting and tabulating of occurrence of errors. The research findings are the total grammatical errors are (131 / 215 x 100 X) 60. 93...|$|R
40|$|This article {{examines}} the relationship between lexical and syntactic competences of fairly advanced learners of English. The data consisted of written tasks where the {{subjects were asked to}} translate a text written in their L 1 Finnish into their L 2 English. The subjects were participants in an entrance examination, seeking admittance to study English Philology at the university. The results confirmed the findings of an earlier study (Pietilä, 2009), where the best candidates were found to manifest almost faultless syntax but produced a considerable number of <b>lexical</b> <b>errors.</b> In the present study, the performance of the 50 most successful candidates in the translation task was further compared with the performance of those 50 candidates who got the lowest grades in this task. The least proficient applicants also produced more <b>lexical</b> than syntactic <b>errors,</b> but the difference was smaller than {{in the case of the}} top candidates. In other words, the least proficient candidates had considerable problems with some syntactic features as well. The results seem to imply <b>that</b> <b>lexical</b> and syntactic competence do not develop in parallel. What is more, advanced learners tend to lack precision in their vocabulary...|$|R
40|$|Abstract. We {{present a}} novel {{approach}} to <b>lexical</b> <b>error</b> recovery on textual input. An advanced robust tokenizer has been implemented that can not only correct spelling mistakes, but also recover from segmentation errors. Apart from the orthographic considerations taken, the tokenizer also makes use of linguistic expectations extracted from a training corpus. The idea is to arrange Hidden Markov Models (HMM) in multiple layers where the HMMs in each layer are responsible for {{different aspects of the}} processing of the input. We report on experimental evaluations with alternative probabilistic language models to guide the <b>lexical</b> <b>error</b> recovery process. ...|$|R
40|$|The study {{investigated}} the provision of corrective feedback and learner repair of errors following feedback in interactional context of peer-to-peer conversations, particularly in a group setting. A total of four students in their early twenties participated in the study. These students are participants of the “Friends of English” (FoE) programme conducted by Centre of Teaching and Learning, Universiti Teknologi Malaysia. The relationship among error types, feedback types and learner repairs were examined. The interaction between these students in a group setting was recorded using Sony Sound Forge. The recorded interactions were transcribed and coded for types of <b>errors</b> (Syntactic / <b>Lexical</b> / L 1), types of negative implicit feedback (Negotiation / Recasts) and learner repairs. Findings indicate that the mentor focused on recasts. He provided implicit negative {{feedback in the form}} of recasts to all three types of learner errors while engaging in the discussions. The majority of L 1 errors were corrected followed by <b>Lexical</b> <b>errors.</b> Syntactic errors had the least number of repairs. <b>Lexical</b> <b>error</b> was the focus of the mentor as over half of <b>Lexical</b> <b>errors</b> received feedback followed by Syntactic error and L 1 use...|$|R
40|$|We {{present a}} novel {{approach}} to <b>lexical</b> <b>error</b> recovery on textual input. An advanced robust tokenizer has been implemented that can not only correct spelling mistakes, but also recover from segmentation errors. Apart from the orthographic considerations taken, the tokenizer also makes use of linguistic expectations extracted from a training corpus. The idea is to arrange Hidden Markov Models (HMM) in multiple layers where the HMMs in each layer are responsible for {{different aspects of the}} processing of the input. We report on experimental evaluations with alternative probabilistic language models to guide the <b>lexical</b> <b>error</b> recovery process. Comment: 12 pages, LaTeX format, 3 encapsulated Postscript figures, uses nemlap. st...|$|R
40|$|This study aims to {{describe}} the types of <b>lexical</b> <b>errors,</b> syntactical errors and discourse errors made by 10 th grade students of SMA Negeri 1 Wuryantoro; explain the frequency of each types of errors and describe the dominant type of errors; and identify the sources of error. The type {{of this research is}} descriptive qualitative research. In collecting data the researcher used elicitation technique. The steps that the researcher used in collecting the data are; the researcher asked the students to make a descriptive text, the researcher collected the data and marked the errors that occurred in students’ writing and documented the erroneous and classified the errors based on the theory of linguistic category and surface strategy taxonomy to classify the errors. The result of this research are <b>lexical</b> <b>errors</b> (86 errors or 24, 85...|$|R
40|$|Interaction is {{regarded}} as a fundamental requirement of second language acquisition (SLA). The study investigated the provision of corrective feedback and learner repair of errors following feedback in interactional context of peer-to-peer conversations, particularly in a group setting. A total of four students in their early twenties participated in the study. These students are participants of the “Friends of English” (FoE) programme conducted by Centre of Teaching and Learning, Universiti Teknologi Malaysia. The relationship among error types, feedback types and learner repairs were examined. The interaction between these students in a group setting was recorded using Sony Sound Forge. The recorded interactions were transcribed and coded for types of <b>errors</b> (Syntactic / <b>Lexical</b> / L 1), types of negative implicit feedback (Negotiation / Recasts) and learner repairs. Findings indicate that the mentor focused on recasts. He provided implicit negative feedback in the form of recasts to all three types of learner errors while engaging in the discussions. The majority of L 1 errors were corrected followed by <b>Lexical</b> <b>errors.</b> Syntactic errors had the least number of repairs. <b>Lexical</b> <b>error</b> was the focus of the mentor as over half of <b>Lexical</b> <b>errors</b> received feedback followed by Syntactic error and L 1 use...|$|R
2500|$|According to {{the final}} analysis, the word {{capacity}} achieved by the children was remarkably good: they spontaneously conversed about various topics, their pronunciation was correct, they occasionally ran into grammatical and <b>lexical</b> <b>errors,</b> but without affecting reciprocal comprehension; ...|$|R
30|$|He {{had used}} the wrong word (<b>lexical</b> <b>error)</b> so the {{mediator}} first used an implicit meditational strategy (line 2). When the student failed to correct his mistake, the mediator used more concrete or explicit meditational strategies (lines 6 and 10).|$|R
40|$|Event-related {{potentials}} {{were used}} to investigate {{if there is a}} lexical bias effect in comprehension monitoring. The lexical bias effect in language production (the tendency of phonological errors to result in existing words rather than nonwords) has been attributed to an internal self-monitoring system, which uses the comprehension system, and which employs lexical status as a monitoring criterion. It has been suggested that we monitor language comprehension too, and that the P 600 reflects comprehension monitoring processes. If both production and comprehension monitoring rely on the comprehension system it is plausible that both processes are very similar. Hence the lexical bias effect is expected in comprehension monitoring. We presented high-cloze sentences that could contain a correct word, a <b>lexical</b> <b>error,</b> or a nonlexical error. There was a larger N 400 in the <b>lexical</b> <b>error</b> and the nonlexical error conditions compared with the correct word condition. Importantly, the P 600 was the largest in the nonlexical error condition, intermediate in the <b>lexical</b> <b>error</b> condition, and the smallest in the correct condition. Apparently, the comprehension monitor is sensitive to lexicality, suggesting that production and comprehension monitoring use similar criteria for error detection...|$|R
40|$|This {{study was}} done to find out: (1) the types of oral {{corrective}} feedback (CF) strategies used by the teacher of an intermediate EFL conversation class and (2) the pedagogical focus of the oral CF in the intermediate EFL conversation class. This {{study was limited to}} oral CF given for grammatical and <b>lexical</b> <b>errors</b> found in the conversation class. The theory used as a guideline in this study was the eight major types of oral CF strategies by Sheen and Ellis (2011), supported by Sheen (2011). This study used descriptive qualitative approach. Video recording and semi-structured interview were used in this study. The writer found seven out of eight major types of oral CF strategies in the conversation class in which Didactic Recast was the strategy used the most. The teacher used the oral CF to correct both grammatical and <b>lexical</b> <b>errors</b> in the class; the emphasis, however, was on grammar. Thus, the pedagogical focus of the lesson is grammatical accuracy {{despite the fact that it}} is a conversation class because the teacher provided more oral CF strategies aiming at the learners’ grammatical accuracy compared to <b>lexical</b> <b>error...</b>|$|R
40|$|Background: Psycholinguistic error {{analysis}} of dyslexic responses in various reading tasks provides the primary basis for clinically discriminating subtypes of pathological reading. Within this framework, phonology-related errors {{are indicative of}} a sequential word processing strategy, whereas <b>lexical</b> and semantic <b>errors</b> {{are associated with a}} lexical reading strategy. Despite the large number of published intervention studies, relatively little is known about changes in error distributions during recovery in dyslexic patients. Aims: The main purpose of the present work was to extend the scope of research on the time course of recovery in readers with acquired dyslexia, using eye tracking methodol-ogy to examine word processing in real time. The guiding hypothesis was <b>that</b> in <b>lexical</b> readers a reduction of <b>lexical</b> <b>errors</b> and an emerging predominant production of phonological errors should be associated with a change to a more segmental moment-to-moment reading behaviour. Methods & Procedures: Five patients participated in an eye movement supported reading intervention, where both lexical and segmental reading was facilitated. Reading perfor...|$|R
40|$|This {{study is}} about the <b>lexical</b> <b>errors</b> made by the {{students}} of Writing I and Writing IV at the English Department, of Petra Christian University. During their process of acquiring English, they have learnt about grammar, syntax, and also lexical items, or commonly known as vocabulary. However, {{many of the students}} still make <b>lexical</b> <b>errors</b> in writing paragraphs or essays. The writer is interested in studying those errors further. She is curious to know what <b>lexical</b> <b>errors</b> are oommonly made by the students of Writing I and Writing IV. However, she limits her study to verbs, nouns, and adjec-tives, since they are considered the main parts of speech. Then, she also wants to find out whether the students of Writing I make more or fewer errors than the students of Writing IV. Finally, the writer will look for any <b>lexical</b> <b>errors</b> which are commonly shared by both stud-ents of Writing I and Writing IV. This study is based on the Error Analysis Theory. The writer gives a vocabulary test to the students. It is a multiple choice test in which the students has to choose the right answer out of four choices provided. The test items are compiled from many sources, such as books about common errors, the students' compositions in their writing courses, and the writer's own personal experience. In the test, the writer includes the incorrect lexical items which are com-monly used by the students among the other options. Then the writer will count the errors made by the students, and present them in tables. Later on, the data on the tables will be analysed further to find out what <b>lexical</b> <b>errors</b> are mostly made by the students, and also what errors are com-monly shared by both students of Writing I and Writing IV. The tables will also show whether Writing IV students make fewer or more errors than Writing I students, since it will be very useful to describe any progress made by the students in their process of learning English. After doing the research, she finds that students of Writing IV mostly make fewer errors than students of Writing I. However, they seem to repeat the same <b>errors</b> in several <b>lexical</b> items...|$|R
40|$|The {{purpose of}} this study is to {{evaluate}} written expression of students learning Turkish as a foreign language at B 2 (intermediate) level according to error analysis approach. The data of the study have been obtained by essay writing of forty two students. These students have been learning Turkish at B level in Gaziantep University TÖMER. The data collected have been classified as grammar errors, syntactical errors, spelling-punctuation <b>errors</b> and <b>lexical</b> <b>errors.</b> The errors determined have been evaluated as an error analysis approach. The evaluation of errors has been limited by intralingual and developmental errors. As a result of evaluation, total error number has been determined as 1282. Errors made are 31 % grammatical error, 9, 9 % syntactical error, 44, 46 % spelling-punctuation error and 14, 4 % <b>lexical</b> <b>error.</b> According to the results obtained, the solutions have been proposed concerning writing skill errors of foreign students...|$|R
3000|$|It {{carries out}} a lexical tagging process by {{retrieving}} the syntactic category of each query word from a lexicon {{stored in a}} database. In this layer, <b>lexical</b> <b>errors</b> should be corrected and syntactic category ambiguity and homography problems should be resolved. The result obtained consists of the tagged query.|$|R
40|$|Translation {{into and}} between foreign {{languages}} {{has become a}} common practice in the professional setting. However, this translation directionality {{has yet to be}} thoroughly explored, especially when post-editing is involved. The present study conducts experiments on the application of machine translation (MT) and translation memory (TM) in a translation classroom setting. A group of Malay speakers, who are non-native speakers of Arabic and English, used MemoQ 2014 to translate technical Arabic and English texts by post-editing raw MT and modified TM outputs containing several errors. The non-native trainee translators’ productivity was measured {{and the quality of the}} translation was assessed through error analysis approach based on the MeLLANGE error typology so that it could provide a comprehensive analysis of the types of errors commonly found in the non-native trainee translators’ translations. The error annotation also aims to provide guidelines for translators who work with the Arabic-English language pair and non-native translators. The present study revealed that the translation technologies helped improve the non-native translators’ speed and quality. The study also discovered <b>that</b> syntactic and <b>lexical</b> <b>errors</b> are the most problematic in the PE tasks. The trainee translators tend to overlook the errors that were caused by cross-linguistic influence, such as articles, gender, number and the conjunction “wa”. However, this could have been avoided if the participants revised their translations thoroughly because most of the errors are minor. The study also revealed that the non-native trainee translators could be as productive as the professional native translators because they managed to reach the average daily productivity for professional translators, which is at least 5, 000 words per day...|$|R
