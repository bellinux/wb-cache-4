16|10000|Public
25|$|Malthus {{argued that}} two <b>types</b> <b>of</b> <b>checks</b> hold {{population}} within resource limits: positive checks, which raise the death rate; and preventive ones, which lower the birth rate. The positive checks include hunger, disease and war; the preventive checks: abortion, birth control, prostitution, {{postponement of marriage}} and celibacy.|$|E
2500|$|Malthus {{argued that}} two <b>types</b> <b>of</b> <b>checks</b> hold {{population}} within resource limits: positive checks, which raise the death rate; and preventive ones, which lower the birth rate. The positive checks include hunger, disease and war; the preventive checks, abortion, birth control, prostitution, postponement of marriage, and celibacy. Regarding possibilities for freeing man from these limits, Malthus argued against {{a variety of}} imaginable solutions. For example, he satirically criticized the notion that agricultural improvements could expand without limit: ...|$|E
2500|$|The {{economist}} Thomas Malthus {{argued in}} An Essay on the Principle of Population (1798) that population growth generally expanded in {{times and in}} regions of plenty until {{the size of the}} population relative to the primary resources caused distress. He demonstrated that two <b>types</b> <b>of</b> <b>checks</b> hold population within resource limits: positive checks, which raise the death rate; and preventive ones, which lower the birth rate. The positive checks include hunger, disease and war; the preventive checks, abortion, birth control, prostitution, postponement of marriage and celibacy. Malthus later clarified his view that if society relied on human misery to limit population growth, then sources of misery (e.g., hunger, disease, and war) would inevitably afflict society, as would volatile economic cycles. On the other hand, [...] "preventive checks" [...] to population that limited birthrates, such as later marriages, could ensure a higher standard of living for all, while also increasing economic stability.|$|E
5000|$|Commonly, the {{following}} <b>types</b> <b>of</b> <b>checked</b> baggage are not {{placed on a}} baggage carousel: ...|$|R
5000|$|A {{ball valve}} {{should not be}} {{confused}} with a [...] "ball-check valve", a <b>type</b> <b>of</b> <b>check</b> valve that uses a solid ball to prevent undesired backflow.|$|R
50|$|Reed valves are a <b>type</b> <b>of</b> <b>check</b> valve which {{restrict}} {{the flow of}} fluids to a single direction, opening and closing under changing pressure on each face. Modern versions often consist of flexible metal or composite materials (fiberglass or carbon fiber).|$|R
50|$|Malthus {{argued that}} two <b>types</b> <b>of</b> <b>checks</b> hold {{population}} within resource limits: positive checks, which raise the death rate; and preventive ones, which lower the birth rate. The positive checks include hunger, disease and war; the preventive checks: abortion, birth control, prostitution, {{postponement of marriage}} and celibacy.|$|E
5000|$|Malthus {{argued that}} two <b>types</b> <b>of</b> <b>checks</b> hold {{population}} within resource limits: positive checks, which raise the death rate; and preventive ones, which lower the birth rate. The positive checks include hunger, disease and war; the preventive checks, abortion, birth control, prostitution, postponement of marriage, and celibacy. Regarding possibilities for freeing man from these limits, Malthus argued against {{a variety of}} imaginable solutions. For example, he satirically criticized the notion that agricultural improvements could expand without limit: ...|$|E
5000|$|Birth control {{became a}} contested {{political}} issue in Britain during the 19th century. The economist Thomas Malthus argued in An Essay on the Principle of Population (1798) that population growth generally expanded in {{times and in}} regions of plenty until {{the size of the}} population relative to the primary resources caused distress. He demonstrated that two <b>types</b> <b>of</b> <b>checks</b> hold population within resource limits: positive checks, which raise the death rate; and preventive ones, which lower the birth rate. The positive checks include hunger, disease and war; the preventive checks, abortion, birth control, prostitution, postponement of marriage and celibacy. Malthus later clarified his view that if society relied on human misery to limit population growth, then sources of misery (e.g., hunger, disease, and war) would inevitably afflict society, as would volatile economic cycles. On the other hand, [...] "preventive checks" [...] to population that limited birthrates, such as later marriages, could ensure a higher standard of living for all, while also increasing economic stability.|$|E
50|$|First Security sells {{a variety}} of {{financial}} products and services including personal, commercial and mortgage loans; all <b>types</b> <b>of</b> <b>checking</b> and savings accounts; certificates of deposit; trust services; savings bonds; money orders; safe deposit boxes; wire transfers; internet banking; and locally issued Visa/MasterCard credit cards.|$|R
40|$|Abstract — Prognostics and Health Management is {{emerging}} as new paradigm to address issues related to enhancing the safety as well as availability. The enabling technologies are state-of-the art in on-line monitoring or periodic surveillance tools and availability of degradation assessment approaches that {{provide a framework for}} residual life assessment of component. Availability of physics of failure or mechanics of failure models and intelligent tools are vital for implementation of a prognostics and health management programme. This paper presents an approach for prognostics and health management <b>of</b> <b>Check</b> valves. The results shows that this approach is promising to detect in advance the incipient failure such that maintenance programme can be initiated to improve the availability as well as safety. Even though this approach addresses modelling <b>of</b> swing <b>type</b> <b>of</b> <b>check</b> valves, the models can easily be adopted for other <b>type</b> <b>of</b> <b>check</b> valves als...|$|R
30|$|One of {{the common}} {{countermeasure}} for debris flows are different <b>types</b> <b>of</b> <b>check</b> dams, slit dams and deceleration baffles, the most famous series of which being the SABO dam systems developed by the Japanese, {{such as the ones}} that belt Unzen Volcano on Kyushu Island in Japan (Gomez and Wassmer 2015).|$|R
40|$|Aspects {{promote a}} clear {{separation}} of concerns so that tangled and scattered concerns are modularized throughout software development. We propose a framework to trace aspects identified during goal-oriented requirements analysis to code and testing. Two <b>types</b> <b>of</b> <b>checks</b> are performed to validate the resulting system in light of stakeholders ’ crosscutting concerns. One ensures that systems with and without aspects have the same functionality defined by the hard goals. The other checks whether the weaved system with aspects indeed improves system qualities {{in terms of the}} degree of softgoal satisfaction. We demonstrate the approach using an open-source e-commerce platform. ...|$|E
40|$|A {{lognormal}} {{model for}} response times {{is used to}} check response times for aberrances in examinee behavior on computerized adaptive tests. Both classical procedures and Bayesian posterior predictive checks are presented. For a fixed examinee, responses and response times are independent; checks based on response times offer thus information independent {{of the results of}} checks on response patterns. Empirical examples of the use of classical and Bayesian checks for detecting two different types of aberrances in response times are presented. The detection rates for the Bayesian checks outperformed those for the classical checks, but at the cost of higher false-alarm rates. A guideline for the choice between the two <b>types</b> <b>of</b> <b>checks</b> is offered...|$|E
40|$|Abstract:This paper {{presents}} a conceptual information for calculation of score and identification of {{risk in the}} passport data {{to find out the}} fraud entries in the dataset. This paper also gives information about different level of checks applied on the passport dataset to find out the suspicious entries in the dataset. After computation of the score for each entry in the database risk is identified on the basis of low, medium and high according to the set ranges. Dataset taken for this study is the primary database of the passport holders and applican. In this 3 types of datasets are used to find the score. Different database are required for performing different <b>types</b> <b>of</b> <b>checks</b> for risk computation and its identification...|$|E
50|$|The Transport Parameters {{was sent}} {{typically}} only once, {{during the initial}} connection phase. This packet contained a number of details in a known format that synchronized what features {{both ends of the}} connection were capable of using. It was during this phase that the <b>type</b> <b>of</b> <b>Check</b> Value was selected, for instance.|$|R
30|$|In {{the various}} life cycle processes, CO 2 {{emissions}} were greatest during the production processes for materials and fuel for all <b>types</b> <b>of</b> <b>check</b> dam, with 75  % of the emissions for all-wood timber check dams and over 90  % of those for hybrid timber, concrete, and steel check dams emitted during this process.|$|R
50|$|A {{simple and}} very common <b>type</b> <b>of</b> <b>check</b> {{is when a}} piece moves to {{directly}} attack the opposing king only by itself. Sometimes such a <b>check</b> is part <b>of</b> a chess tactic such as a fork, a skewer, or a discovered attack on another piece. In some cases, a check {{can be used to}} defend against such tactics.|$|R
40|$|Abstract. In {{this paper}} we {{introduce}} the program ScanLD (built on GoTools) which checks solutions of life-and-death problems for correctness. This {{is a task}} for which computer programs are especially useful. Not only can they do the computations, they can also do the handling of data in checking all moves of all solutions for optimality and reporting any errors that occur. Their refutation and their correction would be tedious and error prone if done with a computer, but interactively. After discussing the different <b>types</b> <b>of</b> <b>checks</b> that are performed and giving some statistics resulting from checking a 500 -problem tsume go book, some examples are given. A long list of mistakes {{that have been found}} is given in an on-line addendum to the paper...|$|E
40|$|Our goal is {{to develop}} a tool for {{automatic}} website checking. We created an ex- tensible system that checks the validity of links as well as HTML and CSS syntax. For that, we integrated existing tools and libraries into one application using plu- gins. Our tool looks for links in HTML and sitemaps. Also, robots. txt including crawl-delay implementation and sitemap discovery is supported. The course of inspection can be affected by configuration rules. Plugin categorization allows for customization of inspection. Not only we verify the validity of standard hypertext links but also links through other HTML tags (images, frames, cascading styles, scripts). In addition, canonical addresses and redirection, duplicates in content or usage of non-semantic tags or attributes are detected. The developed application is extensible for other <b>types</b> <b>of</b> <b>checks.</b> ...|$|E
30|$|The {{randomized}} dataset {{was obtained}} from RBS bank, starting in January 2005. Six months later, this credit card company gave different BT check offers to existing customers and then kept track {{of the performance of}} all consumers for 8  months until February 2006, after the campaign. The BT check offer took effect in the seventh month, so that the data before offer receipt were referred to as “historical data” and the data from the seventh month was called “performance data.” Besides the historical and performance datasets, a response dataset was available, indicating whether a consumer accepted the offer or not. If the BT offer was accepted, which contract (i.e., FFL or PR) the consumer accepts, how many times consumers borrowed by using PR or FFL contract, and how much they borrowed from the bank through different <b>types</b> <b>of</b> <b>checks</b> and so on. The dataset had not only the account information at the firm level but was also linked with the Equifax bureau. The availability of both firm-level and industry-level datasets helped us in better understanding on the campaign effect {{in and out of the}} credit card company.|$|E
30|$|On {{the other}} hand, a {{concrete}} check dam {{is the most}} common structural <b>type</b> <b>of</b> <b>check</b> dam. There are two <b>types</b> <b>of</b> dam forms (such as steel and wood) for which concrete is cast and cured: that for which the forms are removed (without forms) and that for which the forms are left in place (with forms) [8]. In this study, we examined the type without forms.|$|R
40|$|The {{debris flow}} event in Hofu City, Yamaguchi Prefecture, Japan on July 21, 2009 yielded {{a large amount}} of {{sediment}} transport and woody debris in the mountain river basin, where a closed <b>type</b> <b>of</b> <b>check</b> dam and an open <b>type</b> <b>of</b> <b>check</b> dam were built (Maricar et al., 2011). Based on laboratory tests, the debris flow control by these check dam was studied. This paper compares the deposition process of sediment grains and pieces of wood at the open and closed check dam in a laboratory flume experiment. The experimental results showed that the open check dam trapped the wood pieces and the trapped pieces deposited the sediment grains behind themselves. On the other hand, the closed check dam made most of wood pieces pass through the check dam and most of sediment grains get trapped in the water pool behind the closed check dam...|$|R
40|$|International audienceThrough a rapid {{survey of}} the architec ture of Low-Density Parity-Check (LDPC) decoders, this paper proposes a general {{framework}} to describe and compare LDPC decoder architectures. A set of parameters {{makes it possible to}} classify the scheduling of iterative decoders, memory organization and <b>type</b> <b>of</b> <b>check</b> node processors and variable node processors. Using the proposed framework, an efficient generic architecture for non-fooding schedules is also given...|$|R
40|$|Every Argo {{data file}} {{submitted}} by a DAC for distribution on the GDAC has its format and data consistency checked by the Argo FileChecker. Two <b>types</b> <b>of</b> <b>checks</b> are applied: 1. Format checks. Ensures the file formats match the Argo standards precisely. 2. Data consistency checks. Additional data consistency checks are performed on a file after it passes the format checks. These checks {{do not duplicate}} any of the quality control checks performed elsewhere. These checks {{can be thought of}} as “sanity checks” to ensure that the data are consistent with each other. The data consistency checks enforce data standards and ensure that certain data values are reasonable and/or consistent with other information in the files. Examples of the “data standard” checks are the “mandatory parameters” defined for meta-data files and the technical parameter names in technical data files. Files with format or consistency errors are rejected by the GDAC and are not distributed. Less serious problems will generate warnings and the file will still be distributed on the GDAC. Reference Tables and Data Standards: Many of the consistency checks involve comparing the data to the published reference tables and data standards. These tables are documented in the User’s Manual. (The FileChecker implements “text versions” of these tables. ...|$|E
40|$|Power Supply {{checkout}} is a necessary, pre-beam, time-critical function. At {{odds are}} {{the desire to}} decrease {{the amount of time}} to perform the checkout {{while at the same time}} maximizing the number and <b>types</b> <b>of</b> <b>checks</b> that can be performed and analyzing the results quickly (in case any problems exist that must be addressed). Controls and Power Supply Group personnel have worked together to develop tools to accomplish these goals. Power Supply checkouts are now accomplished in a time-frame of hours rather than days, reducing the number of person-hours needed to accomplish the checkout and making the system available more quickly for beam development. The goal of the Collider-Accelerator Department (CAD) at Brookhaven National Laboratory is to provide experimenters with collisions of heavy-ions and polarized protons. The Relativistic Heavy-Ion Collider (RHIC) magnets are controlled by 100 's of varying types of power supplies. There is a concentrated effort to perform routine maintenance on the supplies during shutdown periods. There is an effort at RHIC to streamline the time needed for system checkout in order to quickly arrive at a period of beam operations for RHIC. This time-critical period is when the checkout of the power supplies is performed as the RHIC ring becomes cold and the supplies are connected to their physical magnets. The checkout process is used to identify problems in voltage and current regulation by examining data signals related to each for problems in settling and regulation (ripple) ...|$|E
40|$|Compilers can {{generate}} runtime checks {{in order to}} check the valid use of the language operations. Examples of illegal use of language operations are accessing an array ouside its bounds or the addition of integers while the result cannot be represented in an integer (overflow). When the generation of runtime checks is suppressed, the above mentioned illegal operations can overwrite program and data space in memory. This may lead to unreliable results and unpredictable system crashes. If runtime checks are used, violations of the language rules are detected and signaled {{to the rest of}} the program and/or the user. The benefits of using runtime checks are increased reliability, less development and testing costs. However, runtime checks do have a major impact on execution time: programs take about twice as long to execute - even with maximum compiler optimization. The observation that the standard compiler optimization techniques hardly optimize runtime checks leads to the idea of creating an optimizer specialised in the optimization of runtime checks. Optimization of runtime checks is the minimization of the runtime overhead due to the execution of runtime checks. The proposed algorithms use different strategies to accomplish this: avoiding generation of certain <b>types</b> <b>of</b> <b>checks,</b> motion of checks out of loops, elimination of redundant checks and using efficient checks. The check elimination algorithms consist of two phases: at first, information is collected and propagated throughout the program, using dataflow and range analysis techniques. Checks are also moved in order to create more information. In the second stage, redundant checks are removed using the propagated information. Test results indicate that the algorithms are powerful enough to remove virtually all redundant checks, reducing the runtime overhead to an acceptable percentage. In this way one can get the benefits of runtime checks, while paying a very small cost. ...|$|E
30|$|In {{light of}} these {{problems}} with previous studies, {{in the present study}} we designed check dams to prevent the same volume of sediment runoff in the same location to ensure consistency of functional units, and investigated concrete check dams, which have a long track record <b>of</b> construction, steel <b>check</b> dams, and the two <b>types</b> <b>of</b> timber <b>check</b> dams developed in Akita Prefecture (all-wood timber and hybrid timber). We then carried out a comparative evaluation of life cycle CO 2 emissions, and investigated the effectiveness <b>of</b> timber <b>check</b> dams in reducing CO 2 emissions compared with non-timber check dams. We also analyzed the economic efficiency <b>of</b> each <b>type</b> <b>of</b> <b>check</b> dam, with the aim of conducting a comprehensive evaluation that takes into account economic as well as environmental perspectives, and considered the advantages of and issues with timber check dams.|$|R
30|$|We {{investigated}} {{the possibility of}} reducing the costs <b>of</b> all-wood timber <b>check</b> dams, which had the highest costs among the five <b>types</b> <b>of</b> <b>check</b> dam addressed in this study. When considering measures for keeping down the costs <b>of</b> all-wood timber <b>check</b> dams, {{reducing the amount of}} timber used is undesirable from the perspective of timber use, and it would be preferable to investigate cost-cutting in areas other than timber. We therefore calculated the direct construction costs for three different cases: (a) using steel bars for all connectors, (b) not taking into account front apron construction, and (c) not taking into account front apron construction and also using only steel bars for all connectors. The assumption that steel bars could be used for all connectors was based on initiatives currently underway to replace lag screws with steel bars, as their material procurement costs are less than 10  % of those of lag screws [2, 3, 4]. We also considered not taking into account front apron construction, because although this is mandatory for the design <b>of</b> all-wood timber <b>check</b> dams in Akita Prefecture, it is not required for other <b>types</b> <b>of</b> <b>check</b> dams.|$|R
50|$|National Agency Check with Law and Credit (NACLC) is a <b>type</b> <b>of</b> {{background}} <b>check</b> {{required in}} the United States for granting of security clearances.|$|R
40|$|Please see {{the report}} {{for a full}} list of authors. This report is also {{available}} at [URL] chapter of the handbook and the deliverable on data analysis will provide guidance and general principles for - pre-testing to check the usability {{of the system and}} the feasibility of the evaluation process, - controlling the consistency of the chain and the precision with different sampling schemes, - modelling the impact for each indicators and for an integrated evaluation including a systemic and multidisciplinary interpretation of the effects, - integrating and controlling the quality of space-time data from various sources (numerical, video, questionnaires), - selecting the appropriate statistical techniques for data processing, PI estimation and hypothesis testing in accordance to the list of indicators and experimental design, - scaling up from experimental data and identified models to population and network level. Experimentalists stress the role and importance of a preliminary field test in FOT. Three main objectives have been defined to make a preliminary diagnosis of usability of the systems and to check the relevance and feasibility of the evaluation process. These preliminary tests are very important for the practical deployment of the FOT {{as well as for the}} overall scientific evaluation process. Recommendations about the monitoring of local and global consistency of the chain of operations from the database extraction to the hypothesis testing are given, especially to ensure the validation of the calculation of the Performance indicators. Integration of the outputs of the different analysis and hypothesis testing requires a kind of meta-model and the competences of a multidisciplinary evaluation team, specially for interpretation of the system impact and secondary effects (behavioural adaptation, learning process, long-term retroaction, …). In cooperation with WP 2. 2, methods for data quality control have been defined. Four <b>types</b> <b>of</b> <b>checks</b> have been defined to complement the information of the data base in order to prepare the data for the analysis. Statistical methods have been described for three steps of the chain: data processing, PI calculation and hypothesis testing. They belong either to exploratory data analysis or to inferential analysis. Special attention has been given to the precision of the estimates of the effects or impacts of the system on the Performance indicators by stressing the importance of controlled randomisation and application of mixed regression models. Scaling-up relies upon the potential to extrapolate from the PIs to estimates of the impact at an aggregated level. Three approaches have been defined to carry out the scaling up process from direct estimations to simulation models with the related assumptions. Models and methodologies for scaling up results on traffic flow, environmental effects (e. g. PM 10, CO 2, Noise emissions in db) and traffic safety have been collected...|$|E
50|$|Water is {{not present}} in the piping until the system operates; instead, the piping is filled with air at a {{pressure}} below the water supply pressure. To prevent the larger water supply pressure from prematurely forcing water into the piping, {{the design of the}} dry pipe valve (a specialized <b>type</b> <b>of</b> <b>check</b> valve) results in a greater force on top <b>of</b> the <b>check</b> valve clapper by the use of a larger valve clapper area exposed to the piping air pressure, as compared to the higher water pressure but smaller clapper surface area.|$|R
5000|$|Floor hockey {{equipment}} differs {{between each}} code. Some codes use an indoor puck, a ring made of felt or other material ( [...] Gym Ringette [...] ) while others use a lightweight plastic ball, or a heavier ball. Some codes require standard ice hockey, field hockey or bandy sticks, while others use lightweight plastic. In gym ringette plastic bladeless sticks are used while the Special Olympics version of floor hockey uses wooden ones. The <b>types</b> <b>of</b> <b>checking</b> and protective equipment allowed also vary.|$|R
40|$|An {{experimental}} {{evaluation of}} a technique for improving the efficiency of depth-first search on graphs is presented. The technique, referred to as cycle checking, prevents the generation of duplicate nodes in the depth-first search of a graph by comparing each newly generated node to the nodes already on the search path. Although cycle checking {{can be applied to}} any depth-first type search, this paper focuses on its effect with the heuristic depth-first iterative deepening algorithm IDA *. Two <b>types</b> <b>of</b> cycle <b>checking</b> are compared, full cycle checking and parent cycle checking. Full cycle checking compares a new node to all nodes on the search path. Parent cycle checking merely compares a new node to the parent of the node being expanded. Both <b>types</b> <b>of</b> cycle <b>checking</b> are shown to improve the efficiency of IDA * search in a grid search problem and a route planning problem. Simple guidelines are presented showing which <b>type</b> <b>of</b> cycle <b>checking</b> should be used on a given problem. Keyword [...] ...|$|R
40|$|Abstract: An {{experimental}} set-up {{was introduced to}} study the dynamic behaviour <b>of</b> different <b>types</b> <b>of</b> <b>check</b> valves under pressure transient conditions. Three <b>types</b> <b>of</b> transient comparison methods were used, with similar results being obtained from all three methods. The experimen-tal {{results show that the}} check valves with low inertia, assisted by springs or small travelling distance/angle, gave better performance under pressure transient conditions as compared to check valves without these features. Although different amounts of air entrainment were found to affect the experimental readings, the general characteristics <b>of</b> each <b>check</b> valve remain the same when compared between valves. This study can be applied to help in the choosing <b>of</b> suitable <b>check</b> valves for a particular pumping system...|$|R
50|$|E-mail senders can do {{the same}} <b>type</b> <b>of</b> {{anti-spam}} <b>checks</b> on e-mail coming from their users and customers as can be done for e-mail coming {{from the rest of the}} Internet.|$|R
