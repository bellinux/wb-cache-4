238|423|Public
2500|$|... "Student syndrome" [...] {{refers to}} the {{phenomenon}} where a student will begin to fully apply himself or herself to a task only immediately before a deadline. This negates the usefulness of any buffers built into individual <b>task</b> <b>duration</b> estimates. Results from a 2002 study indicate that many students are aware of procrastination and accordingly set binding deadlines long before the date for which a task is due. These self-imposed binding deadlines are correlated with a better performance than without binding deadlines though performance is best for evenly spaced external binding deadlines. Finally, students have difficulties optimally setting self-imposed deadlines, with results suggesting a lack of spacing before the date at which results are due.|$|E
50|$|In either case, {{workspace}} acts as {{an environment}} where a programmer can work, isolated from the outside world, for the <b>task</b> <b>duration.</b>|$|E
50|$|Because <b>task</b> <b>duration</b> {{has been}} planned at the 50% {{probability}} duration, there is pressure on resources to complete critical chain tasks {{as quickly as}} possible, overcoming student's syndrome and Parkinson's Law.|$|E
40|$|Much of {{the project}} {{scheduling}} literature treats <b>task</b> <b>durations</b> as deterministic. In reality, however, <b>task</b> <b>durations</b> are subject to considerable uncertainty and that uncertainty can {{be influenced by the}} resources assigned. The {{purpose of this paper is}} to provide the means for program managers (who may have responsibility for multiple projects) to optimally allocate resources from common resource pools to individual tasks on several competing projects. Instead of the traditional use of schedules, we develop control policies in the form of planned resource allocation to tasks that capture the uncertainty associated with <b>task</b> <b>durations</b> and the impact of resource allocation on those durations. We develop a solution procedure for the model and illustrate the ideas in an example. ...|$|R
40|$|<b>Task</b> <b>durations</b> {{are subject}} to {{uncertainty}} {{and they can be}} influenced by the resources assigned. Commonly there is the opportunity to assign workers to tasks, which require a secondary skill they have. When workers use secondary skills, they are not as efficient as workers for which that skill is their primary skill, however they can contribute to the completion of the task. This paper provides the means for managers to heuristically optimize the allocation of their skilled workers among individual tasks on several competing projects when the <b>task</b> <b>durations</b> are uncertain and workers have multiple skills. ...|$|R
40|$|In the {{industry}} {{there is always}} a demand to shorten the <b>task</b> completion <b>durations</b> in order to maximize the efficiency of the operation. This work aims to provide a solution to minimize the <b>task</b> completion <b>duration</b> for planar <b>tasks</b> by in-troducing kinematic redundancy. An example setting of a redundant planar mech-anism is considered and an algorithm developed for resolving redundancy order to minimize <b>task</b> completion <b>duration</b> is discussed based on this mechanism...|$|R
5000|$|The task node is {{the primary}} element driving the simulation’s outcome. Task nodes {{simulate}} system behavior by allowing programmer specified effects, <b>task</b> <b>duration,</b> failure rates, and pathing. Task Effects are programmer specified C# expressions where programmers can manipulate variables and data structures when a task is invoked. <b>Task</b> <b>duration</b> can be specified by the programmer as a specific value, through a probability distribution, or using a C# expression. Programmers can also specify task success in a similar way. Task success influences {{the effects of the}} task node and the pathing of the entity. Failure consequences include task repetition, task change, and mission failure among other options. Control flow and pathing can also be specified by the programmer. IMPRINT provides a series of other nodes which include special functionality: ...|$|E
5000|$|Limited divisibility of tasks. Adding {{more people}} to a highly {{divisible}} task, such as cleaning rooms in a hotel, decreases the overall <b>task</b> <b>duration</b> (up {{to the point where}} additional workers get in each other's way). Some tasks are less divisible; Brooks points out that while it takes one woman nine months to make one baby, [...] "nine women can't make a baby in one month".|$|E
50|$|In {{order to}} {{determine}} this information {{it is assumed that}} the activities and normal duration times are given. The first step is to determine the ES and EF. The ES is defined as the maximum EF of all predecessor activities, unless the activity in question is the first activity, for which the ES is zero (0). The EF is the ES plus the <b>task</b> <b>duration</b> (EF = ES + duration).|$|E
50|$|Effort-Driven SchedulingFor {{tasks that}} can be {{completed}} faster by adding more resources, use Effort-Driven Scheduling for simple schedule compression. Automatically adjust <b>task</b> <b>durations</b> as resources are added or subtracted, while keeping the total work for a task constant.|$|R
40|$|Due to the {{inherent}} {{nature of the}} construction industry, all construction projects have some amount and type of uncertainty. Personnel involved with the project compensate for the uncertainty by adding buffers. This research is focused on “time buffers ” added to construction <b>task</b> <b>durations.</b> We define “time buffer ” as time added to <b>task</b> <b>durations</b> to compensate for uncertainty and protect against variation. Although previous research acknowledges this addition of time buffer, {{the root causes of}} buffer have not been thoroughly researched. The research objectives include determining which factors are the most prevalent and severe causes of buffer and determining opinion differences amongst various groups. A survey was developed and then completed by 180 construction personnel across the United States. The top twelve most frequent and severe causes of buffer in <b>task</b> <b>durations</b> were identified. The factors were analysed in how they are viewed differently by foremen, superintendents, and project managers; trade to trade; general contractors to subcontractors; level of experience; and companies regularly using the Last Planner System ® and those who do not. The findings will help construction managers understand what drives the need for buffer in construction schedules and focus efforts on strategically addressing critical areas of concern or uncertainty...|$|R
40|$|Abstract. We {{show how}} to {{evaluate}} the performance of solutions to finite-horizon scheduling problems where <b>task</b> <b>durations</b> are specified by bounded uniform dis-tributions. Our computational technique, based on computing the volumes of zones, constitutes {{a contribution to the}} computational study of scheduling under uncertainty and stochastic systems in general. ...|$|R
50|$|Configuration {{management}} is {{for most of}} time dealing with the system that is large, complexed, has a long life duration (more than 10 years) and involve more people. The key issues for engineering support are to coordinate the participants and to provide each engineer an environment, also called a workspace where they can work independently in the <b>task</b> <b>duration.</b> The former one refers the cooperative work support and the latter one is mostly called workspace support.|$|E
50|$|Barring any {{unforeseen}} events, {{the project}} should take 19.51 work days to complete. The {{next step is}} to determine the late start (LS) and late finish (LF) of each activity. This will eventually show if there are activities that have slack. The LF is defined as the minimum LS of all successor activities, unless the activity is the last activity, for which the LF equals the EF. The LS is the LF minus the <b>task</b> <b>duration</b> (LS = LF − duration).|$|E
5000|$|The {{figure on}} the left shows a work {{breakdown}} structure construction technique that demonstrates the 100% rule and the [...] "progressive elaboration" [...] technique. At WBS Level 1 it shows 100 units of work as the total scope of a project to design and build a custom bicycle. At WBS Level 2, the 100 units are divided into seven elements. The number of units allocated to each element of work can be based on effort or cost; it is not an estimate of <b>task</b> <b>duration.</b>|$|E
30|$|There were {{differences}} in the cognitive workload of the different IVIS systems over and above any differences associated with simply driving the vehicles. We found that robust, intuitive systems {{with lower levels of}} complexity and shorter <b>task</b> <b>durations</b> tend to have lower cognitive workload than more rigid, error-prone, time-consuming systems.|$|R
40|$|Invited PaperInternational audienceWe {{show how}} to {{evaluate}} the performance of solutions to finite-horizon scheduling problems where <b>task</b> <b>durations</b> are specified by bounded uniform distributions. Our computational technique, based on computing the volumes of zones, constitutes {{a contribution to the}} computational study of scheduling under uncertainty and stochastic systems in general...|$|R
40|$|AbstractIn this work, {{we present}} timed automata {{as a natural}} tool for posing and solving {{scheduling}} problems. We show how efficient shortest path algorithms for timed automata can find optimal schedules for the classical job-shop problem. We then extend these results to synthesize adaptive scheduling strategies for problems with uncertainty in <b>task</b> <b>durations...</b>|$|R
50|$|In project management, a {{schedule}} is {{a listing of}} a project's milestones, activities, and deliverables, usually with intended start and finish dates. Those items are often estimated by other information included in the project schedule of resource allocation, budget, <b>task</b> <b>duration,</b> and linkages of dependencies and scheduled events. A schedule is commonly used in the project planning and project portfolio management parts of project management. Elements on {{a schedule}} may be {{closely related to the}} work breakdown structure (WBS) terminal elements, the Statement of work, or a Contract Data Requirements List.|$|E
50|$|There are {{differences}} between Open Workbench and Microsoft Project. Chief {{among them is}} that Open Workbench schedules based on effort whereas MS Projects default scheduling method is based on duration, although the user can change the method to work (effort). In other words, in an Open Workbench plan, task schedule {{is driven by the}} number of hours each resource will work per week to cover the total number of hours required for the tasks; whereas Microsoft Project does the reverse by generating estimates for the resources based on the <b>task</b> <b>duration</b> rather than their work availability. For this reason, resource leveling is also different: Open Workbench will do it based on resource availability whereas MS Project will do it based on the next available block of time that fits the task.|$|E
5000|$|... "Student syndrome" [...] {{refers to}} the {{phenomenon}} where a student will begin to fully apply himself or herself to a task only immediately before a deadline. This negates the usefulness of any buffers built into individual <b>task</b> <b>duration</b> estimates. Results from a 2002 study indicate that many students are aware of procrastination and accordingly set binding deadlines long before the date for which a task is due. These self-imposed binding deadlines are correlated with a better performance than without binding deadlines though performance is best for evenly spaced external binding deadlines. Finally, students have difficulties optimally setting self-imposed deadlines, with results suggesting a lack of spacing before the date at which results are due.In one experiment, participation in online exercises {{was found to be}} five times higher in the final week before a deadline than in the summed total of the first three weeks for which the exercises were available. Procrastinators end up being the ones doing most of the work in the final week before a deadline.|$|E
40|$|In {{this ongoing}} work, we are {{interested}} in multiprocessor energy efficient systems, where <b>task</b> <b>durations</b> are not known in advance, but are know stochastically. More precisely, we consider global scheduling algorithms for frame-based multiprocessor stochastic DVFS (Dynamic Voltage and Frequency Scaling) systems. Moreover, we consider processors with a discrete set of available frequencies...|$|R
40|$|International audienceIn this work, {{we present}} timed automata {{as a natural}} tool for posing and solving {{scheduling}} problems. We show how efficient shortest path algorithms for timed automata can find optimal schedules for the classical job-shop problem. We then extend these results to synthesize adaptive scheduling strategies for problems with uncertainty in <b>task</b> <b>durations...</b>|$|R
40|$|Purpose: Deceptive {{manipulations}} of performance intensity have previously been investigated in cycling time trials (TT) but used different magnitudes, methods, and <b>task</b> <b>durations.</b> This study examines previously used magnitudes of deception during 16. 1 -km TT and explores yet unexamined psychological responses. Methods: Twelve trained cyclists completed five TT, performing two baseline trials alone, one against a simulated dynamic avatar representing 102...|$|R
40|$|Remembering {{to perform}} an action when a {{specific}} event occurs {{is referred to as}} Event-Based Prospective Memory (EBPM). This study investigated how EBPM performance is affected by <b>task</b> <b>duration</b> by having university students (n = 223) perform an EBPM task that was embedded within an ongoing computer-based color-matching task. For this experiment, we separated the overall task’s duration into the filler <b>task</b> <b>duration</b> and the ongoing <b>task</b> <b>duration.</b> The filler <b>task</b> <b>duration</b> is the length of time between the intention {{and the beginning of the}} ongoing task, and the ongoing <b>task</b> <b>duration</b> is the length of time between the beginning of the ongoing task and the appearance of the first Prospective Memory (PM) cue. The filler <b>task</b> <b>duration</b> and ongoing <b>task</b> <b>duration</b> were further divided into three levels: 3, 6, and 9 min. Two factors were then orthogonally manipulated between-subjects using a multinomial processing tree model to separate the effects of different task durations on the two EBPM components. A mediation model was then created to verify whether <b>task</b> <b>duration</b> influences EBPM via self-reminding or discrimination. The results reveal three points. (1) Lengthening the duration of ongoing tasks had a negative effect on EBPM performance while lengthening the duration of the filler task had no significant effect on it. (2) As the filler task was lengthened, both the prospective and retrospective components show a decreasing and then increasing trend. Also, when the ongoing <b>task</b> <b>duration</b> was lengthened, the prospective component decreased while the retrospective component significantly increased. (3) The mediating effect of discrimination between the <b>task</b> <b>duration</b> and EBPM performance was significant. We concluded that different task durations influence EBPM performance through different components with discrimination being the mediator between <b>task</b> <b>duration</b> and EBPM performance...|$|E
40|$|Research in <b>task</b> <b>duration</b> {{judgment}} {{has shown}} that unpacking a multifaceted task into components prior to estimating its duration increases estimates. In three studies, we find that unpacking a complex task can increase, decrease, or leave unaffected <b>task</b> <b>duration</b> estimates depending on the typicality of the unpacked components and their temporal position in the task sequence. Unpacking atypical long components increases <b>task</b> <b>duration</b> estimates, while unpacking atypical short components decreases estimates (Study 1). Unpacking atypical early components increases <b>task</b> <b>duration</b> estimates, while unpacking atypical late components decreases estimates (Study 2). Unpacking typical early or late components leaves estimates unaffected (Study 3). We explain these results {{based on the idea}} that <b>task</b> <b>duration</b> estimation involves a mental simulation process, and by drawing on theories of unpacking in probability judgment that emphasize the role of the typicality of the unpacked components. These findings hint at a deep conceptual link between probability judgment and <b>task</b> <b>duration</b> estimation but also show differences, such as the influence that temporality exerts on estimated duration. © 2013 Elsevier Inc...|$|E
40|$|People {{are often}} {{inaccurate}} in predicting <b>task</b> <b>duration.</b> The memory bias explanation holds that this error {{is due to}} people having incorrect memories of how long previous tasks have taken, and these biased memories cause biased predictions. Therefore, the authors examined the effect on increasing predictive accuracy of correcting memory through supplying feedback for actual <b>task</b> <b>duration.</b> For Experiments 1 (paper-counting task) and 2 (essay-writing task), college students were supplied with duration informa-tion about their previous performance on a similar task before predicting <b>task</b> <b>duration.</b> For Experiment 3, participants were recruited at various locations, such as fast food restaurants and video arcades, and supplied with average <b>task</b> <b>duration</b> for others before predicting how long the task would take. In all 3 experiments, supplying feedback increased predictive accuracy. Overall, results indicate that, when predicting duration, people do well when they rely not on memory of past <b>task</b> <b>duration</b> but instead on measures of actual duration, whether their own or that of others...|$|E
40|$|This paper {{describes}} how sensitivity analysis {{can be used}} to improve the completion time of sequential design processes. The sensitivities, which are calculated using the adjoint method, are illustrated in two applications: 1) Pareto Analysis - determining the impact of individual <b>task</b> <b>durations</b> and iteration rates on the process completion time and 2) Optimization - minimizing the overall process completion time over the individual <b>task</b> <b>durations.</b> Examples and results for each of the applications is presented. 1. 0 Introduction In today's highly-competitive market, it is imperative to deliver high quality products in a short amount of time. While great effort and expense has been invested in developing powerful CAD tools to create the quality products, surprisingly little work has been done in developing techniques for analyzing and minimizing {{the time it takes to}} complete the product. To address this need, this paper {{describes how}} sensitivity analysis {{can be used to}} improve the time [...] ...|$|R
40|$|In this paper, {{we present}} an {{extension}} to the TSALB problem (Time and Space constrained Assembly Line Balancing) with ergonomic risk restrictions. This ergonomic risk is defi ned from the <b>task</b> <b>durations</b> and their categories {{regarding to the}} risk factor for the workers. A study is presented through a case linked to an engine assembly line in the Automobile industry, considering variable demand. Postprint (published version...|$|R
40|$|This paper {{presents}} {{a novel approach}} supporting administrative tasks within the lifecycle of design projects. Based upon comprehensive models of design environments and design activities it combines techniques known from project management and mechanisms for design flow control. As a result it allows the planning, controlling and reviewing of design projects and supports algorithmic estimation of <b>task</b> <b>durations</b> and automatic computation of plan revisions...|$|R
40|$|The aims of {{this study}} were (1) to {{investigate}} the relationship between self-perception of effort and <b>task</b> <b>duration</b> in an intermittent isometric fatigue trial (IIF) and (2) to evaluate the capability of two assessment paradigms (perceived exertion; perceived <b>task</b> <b>duration)</b> to reflect changes in IIF intensity. Fifteen participants performed two IIF tasks of the knee extensors at intensities of 60 and 70 Â % of daily peak force, each separated by 48 - 72 Â h. Ordering of the tasks was counter-balanced and participants were blinded to the precise intensity of each IIF. A category-ratio scale (CR- 10) and visual analogue scale were used during each IIF task to record measures of perceived exertion and perceived <b>task</b> <b>duration,</b> respectively. Measures were recorded at 10 Â % intervals across the relative duration of each IIF task. Pearson product-moment correlation coefficients revealed strong positive correlations (rÂ >Â 0. 99; pÂ <Â 0. 01) between completed <b>task</b> <b>duration</b> and both perceptual scales at the two IIF intensities. Separate two-way repeated measures ANOVAs of CR- 10 and perceived <b>task</b> <b>duration</b> responses revealed significant main effects for time only (F [2. 2, 30. 1]Â =Â 126. 8; pÂ <Â 0. 001; F [2. 6, 36. 8]Â =Â 117. 2; pÂ <Â 0. 001, CR- 10 and perceived <b>task</b> <b>duration,</b> respectively). The results suggest that perceived exertion and perceived <b>task</b> <b>duration</b> are equally effective predictors of IIF end-point. However, neither measure was sufficiently responsive to discriminate between 10 Â % changes in exercise intensity. Â© 2012 Springer-Verlag...|$|E
40|$|The Lane Change Test (ISO, 2008; Mattes, 2003) {{was used}} to assess {{distraction}} demand when drivers completed three typical navigation tasks (an easy navigation task, a point of interest task and a difficult navigation task) using three different navigation systems. In order for the LCT to be a useful procedure, it must distinguish good from poor navigation systems and acceptable from unacceptable tasks performed using those systems. The results provide some general support for the LCT as a sensitive measure of distraction. Some aspects of the results, however, called into question the adequacy of the LCT as a sufficient measure of distraction. In particular, the LCT was found to be insensitive to task demands arising from excessive <b>task</b> <b>duration.</b> Since risk exposure is a function of secondary <b>task</b> <b>duration</b> (as well as other factors such as intensity, frequency and timing), it is recommended that a measure of <b>task</b> <b>duration</b> be incorporated in the LCT procedure. When the MDEV was modified to incorporate <b>task</b> <b>duration,</b> the resulting measure (mean deviation per average task) reflected more adequately the interaction demands of the various navigation tasks...|$|E
40|$|This paper {{analyzes}} the existing types of duration estimation models for software projects. We focus on Metrix model and investigate its applicability for duration estimation of software projects {{that focus on}} delivering workflow based software systems. The Metrix mod-el is a stochastic, knowledge-based Monte Carlo simulation over an activity graph. The model overcomes the limitations of other existing models by relying on a knowledge-base of pre-calculated discreet probability distributions for <b>task</b> <b>duration.</b> These probability distributions are automatically derived using the historical <b>task</b> <b>duration</b> estimation of the team members...|$|E
40|$|Project {{scheduling}} is {{an important}} tool that breaks down a complex process into its individual <b>tasks</b> and assigns <b>durations</b> to these. When the <b>task</b> <b>durations</b> are given as statistical distributions, rather than constants, the total project duration also becomes a random variable. This paper demonstrates {{the application of the}} proxel-based simulation method to the simulation of project schedules. Taking a project schedule as an input, the distribution of the total project duration is computed algorithmically, rather than by analytically combining the statistical distributions of the individual tasks. The experiments performed verify the method and point towards future work...|$|R
40|$|Proceedings Paper (for Acquisition Research Program) Acquisition {{programs}} have inherent variability in their <b>task</b> <b>durations,</b> which {{often results in}} unforecasted completion delay. Using concepts from Lean Production and Lean Product Development, queues {{that are at the}} heart of these delays can be made visible and can be managed. Observing queues in acquisition programs can give early warning of project problems. Several techniques can be used to manage queues. Acquisition Research Progra...|$|R
40|$|The paper {{presents}} {{research results}} concerning scheduling of software projects under uncertainty {{that have been}} obtained by the authors in recent years. The uncertainty is connected with imprecision of some project parameters, mainly <b>task</b> <b>durations,</b> and with user's preferences with respect to multiple project performance measures. The results advance both the general methodology of project scheduling under uncertainty and the tools of software project management. Prototype integrated tools are described...|$|R
