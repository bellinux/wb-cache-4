424|10000|Public
5|$|The Gunmen cleverly trick Agent Dana Scully (Gillian Anderson) into {{coming to}} Las Vegas using a <b>text</b> <b>to</b> <b>speech</b> program. Their friend Jimmy uses his special {{technique}} for {{gaining access to}} a secret meeting room where he believes he will learn about new assassination techniques employed by the government. However, Jimmy is discovered and injected with a mystery drug which forces him to kill himself. Meanwhile, Byers discovers that Susanne is alive and well, but has seemingly become a secretive government agent.|$|E
25|$|Assistive {{technology}} {{in this area}} is broken down into low, mid, and high tech categories. Low tech encompasses equipment that is often low cost and does not include batteries or requires charging. Examples include adapted paper and pencil grips for writing or masks and color overlays for reading. Mid tech supports used in the school setting include the use of handheld spelling dictionaries and portable word processors used to keyboard writing. High tech supports involve the use of tablet devices and computers with accompanying software. Software supports for writing include the use of auditory feedback while keyboarding, word prediction for spelling, and speech to text. Supports for reading include the use of <b>text</b> <b>to</b> <b>speech</b> (TTS) software and font modification via access to digital text. Limited supports are available for math instruction and mostly consist of grid based software to allow younger students to keyboard equations and auditory feedback of more complex equations using MathML and Daisy.|$|E
2500|$|Speech {{synthesis}} {{was first}} introduced in Windows with Windows 2000, {{but it has been}} significantly enhanced for Windows Vista (code name [...] ). The old voice, Microsoft Sam, has been replaced with two new, more natural sounding voices of generally greater intelligibility: Anna and Lili, the latter of which is capable of speaking Chinese. The screen-reader Narrator which uses these voices has also been updated. Microsoft Agent and other <b>text</b> <b>to</b> <b>speech</b> applications now use the newer SAPI 5 voices.|$|E
5000|$|JSML is {{primarily}} an XML text format used by Java applications <b>to</b> annotate <b>text</b> input <b>to</b> <b>speech</b> synthesizers. Elements of JSML provide speech synthesizer with {{detailed information on}} how <b>to</b> speak <b>text</b> in a naturalized fashion.|$|R
40|$|Data Happenings: A maker {{workshop}} exploring {{data driven}} text, code and {{sound from the}} network By Helen Pritchard x Winnie Soon 數據藝術「聲」「字」「碼」工作坊 海倫．派查德 x 孫詠怡 Networked texts are unpredictable, amazing and endless, distributed across an assemblage human and non-human writers. In this workshop, drawing {{on the history of}} rule-based writing, we will explore the potential for generative devices to enable new forms of collaboration with unpredictable outcomes. Using procedure based methods we will scrape, copy and paste texts from social media. We will then convert these <b>texts</b> <b>to</b> <b>speech</b> and create a collective generative sound work. If you have access to a laptop + headphones, please bring it in. Previous to the workshop please make sure you downloaded and/or installed ‘Audacity’. [URL]...|$|R
50|$|The {{statement}} {{was published in}} a book by Milton Mayer, They Thought They Were Free (1955), based on interviews he had conducted in Germany several years earlier. The quotation was circulated by civil rights activists and educators in the United States in the late 1950s. Some research traces the <b>text</b> <b>to</b> several <b>speeches</b> given by Niemöller in 1946.|$|R
2500|$|The YTMND {{character}} [...] "Moon Man", a {{white supremacist}} rapper character based on source videos of the McDonald's advertising campaign Mac Tonight, garnered controversy shortly after its first remix in 2007. AT's <b>text</b> <b>to</b> <b>speech</b> program provided Moon Man's voice {{and was soon}} edited to block any racially derogatory epithets or swear words {{in an attempt to}} cull the number of remixes. McDonald's began removing existing Mac Tonight sculptures and animatronics from some of its restaurants in response to the widespread remixes, and YouTube began automatically striking down many Moon Man-related videos from 2007 to the present. Several videos were also DMCA-claimed and taken down by McDonald's from 2007–2008. Multiple change.org petitions were filed demanding YouTube cease removing the videos, the most recent of which from May 2015 having reaching over 1200 signatures. YouTube has since stopped taking Moon Man videos down unless they have been flagged by users.|$|E
50|$|Some app {{developers}} have started adapting and tweaking their Android Auto apps to include <b>Text</b> <b>to</b> <b>Speech,</b> such as Hyundai in 2015. Apps such as textPlus and WhatsApp use <b>Text</b> <b>to</b> <b>Speech</b> to read notifications aloud and provide voice-reply functionality.|$|E
5000|$|First Punjabi <b>Text</b> <b>to</b> <b>Speech</b> Synthesis System (Project Leader) ...|$|E
30|$|Audio-to-audio alignment: Here, the <b>text</b> is {{converted}} <b>to</b> <b>speech</b> using a TTS system, and the synthesized speech is {{aligned with the}} audio [6, 7]. This method requires {{the existence of a}} TTS system.|$|R
50|$|Also called open captioning, or {{real-time}} stenography, {{or simply}} real-time captioning, Communication Access Real Time Captioning (CART) {{is the general}} name {{of the system that}} court reporters, closed captioners and voice writers, and others use <b>to</b> convert <b>speech</b> <b>to</b> <b>text.</b> A trained operator uses keyboard or stenography methods <b>to</b> transcribe spoken <b>speech</b> into written <b>text.</b> <b>Speech</b> <b>to</b> <b>text</b> software is used when voice writers provide CART.|$|R
40|$|Here is the <b>text</b> <b>to</b> my <b>speech</b> {{given at}} Lafayette Square, on April 15, 2009 at the National Tax Day TEA Party event. I had not {{concluded}} my remarks when the Secret Service {{shut down the}} event for safety concerns over a package being thrown over the fence onto the White House lawn. In the end it only had tea bags in it, but it effectively shut down the event...|$|R
50|$|In recent years, <b>Text</b> <b>to</b> <b>Speech</b> for {{disability}} and handicapped communication aids have become widely deployed in Mass Transit. <b>Text</b> <b>to</b> <b>Speech</b> is also finding new applications outside the disability market. For example, speech synthesis, combined with speech recognition, allows for interaction with mobile devices via {{natural language processing}} interfaces.|$|E
5000|$|Direct <b>Text</b> <b>To</b> <b>Speech</b> - {{objects for}} direct control of {{synthesis}} engine ...|$|E
5000|$|Tanoshii Japanese, {{features}} EDICT-based dictionary, <b>Text</b> <b>to</b> <b>Speech,</b> KANJIDIC, KanjiVG {{and learning}} features ...|$|E
50|$|Because {{a part of}} PBX {{functionality}} {{is provided}} in software, it is relatively inexpensive and {{makes it easy to}} add additional functionality, such as conferencing, XML-RPC control of live calls, Interactive voice response (IVR), TTS/ASR (<b>text</b> <b>to</b> speech/automatic <b>speech</b> recognition), Public switched telephone network (PSTN) interconnection ability supporting both analog and digital circuits, Voice over IP protocols including SIP, Inter-Asterisk eXchange, H.323, Jingle (extension of XMPP protocol introduced by Google Talk) and others.|$|R
40|$|We {{describe}} {{a method for}} the automatic production of phonetic transcriptions in large speech corpora. First, {{we focus on the}} application of different techniques for the generation of pronunciation variants. Then, we explain the application of a speech recognition system for selecting the acoustically best matching phonetic transcription. The system is evaluated on different test sets selected from the Spoken Dutch Corpus, ranging from read-aloud <b>text</b> <b>to</b> spontaneous <b>speech,</b> and achieves promising first results. 1...|$|R
50|$|Java Speech API Markup Language (JSML) is an XML-based markup {{language}} for annotating <b>text</b> input <b>to</b> <b>speech</b> synthesizers. JSML is used within the Java Speech API. JSML is an XML application and {{conforms to the}} requirements of well-formed XML documents. Java Speech API Markup Language is referred to as JSpeech Markup Language when describing the W3C documentation of the standard. Java Speech API Markup Language and JSpeech Markup Language identical apart from the change in name, which is made to protect Sun trademarks.|$|R
5000|$|Development of Urdu Lexicon, Machine Translation & <b>Text</b> <b>to</b> <b>Speech</b> Software for Urdu Language ...|$|E
5000|$|Indus Reader - an OS {{integrated}} <b>text</b> <b>to</b> <b>speech</b> {{feature in}} 9 regional languages ...|$|E
5000|$|... 2009 - Introduced world’s {{smallest}} <b>text</b> <b>to</b> <b>speech</b> system (TTS) and Truly HandsfreeTM Triggers ...|$|E
40|$|Speech {{has been}} {{processed}} {{for a wide}} variety of applications right from mobile communications to automatic reading machines. In this paper, we have developed an application for sending emails, bringing to use the conversion of <b>speech</b> <b>to</b> <b>text</b> and vice versa. The application also has a feature that enables simple calculation by the user through our talking calculator that takes <b>speech</b> as input <b>to</b> perform the operations. All the text instructions are given to the user by its conversion into speech. Speech is input at run time through a microphone and the sampled speech is processed and converted <b>to</b> <b>text.</b> <b>Speech</b> <b>to</b> <b>text</b> conversion is done via the Internet, connecting to Google's server. The application is adapted to input messages in English. In this paper we have also proposed an efficient means of login for users to provide increased security...|$|R
5000|$|Some sources {{will use}} only colloquial Cantonese forms, {{resulting}} in <b>text</b> similar <b>to</b> natural <b>speech.</b> However, {{it is more}} common to use a mixture of colloquial forms and Standard Chinese forms, {{some of which are}} alien <b>to</b> natural <b>speech.</b> Thus the resulting [...] "hybrid" [...] text lies on a continuum between two norms: Standard Chinese, and colloquial Cantonese as spoken.|$|R
50|$|This {{feature is}} {{available}} for AIM 7 and allows for a user {{to see what the}} other is typing as it is being done. It was developed and built with assistance from Trace Research and Development Centre at University of Wisconsin-Madison and Gallaudet University. The application provides visually impaired users the ability to convert messages from <b>text</b> (words) <b>to</b> <b>speech.</b> For the application to work users must have AIM 6.8 or higher, as it is not compatible with older versions of AIM software, AIM for Mac or iChat.|$|R
50|$|Multiple {{companies}} offer TTS APIs {{to their customers}} to accelerate development of new applications utilizing TTS technology. Companies offering TTS APIs include AT&T, CereProc, DIOTEK, IVONA, Neospeech, Readspeaker, SYNVO, YAKiToMe! and CPqD. For mobile app development, Android operating system has been offering <b>text</b> <b>to</b> <b>speech</b> API for a long time. Most recently, with iOS7, Apple started offering an API for <b>text</b> <b>to</b> <b>speech.</b>|$|E
5000|$|... #Caption: Keyboard used {{to create}} speech over a {{telephone}} using a <b>Text</b> <b>to</b> <b>Speech</b> converter.|$|E
5000|$|<b>Text</b> <b>to</b> <b>speech</b> allows {{to listen}} to a book, a page or a text {{selection}} ...|$|E
50|$|AmigaOS {{was one of}} {{the first}} {{operating}} systems <b>to</b> feature <b>speech</b> synthesis with software developed by Softvoice, Inc., which allowed text-to-speech conversion of American English. This had three main components: narrator.device, which modulates the phonemes used in American English, translator.library, which translates English <b>text</b> <b>to</b> American English phonemes using a set of rules, and a high-level SPEAK: handler, which allows command-line users <b>to</b> redirect <b>text</b> output <b>to</b> <b>speech.</b> A utility called Say was included with the OS, which allowed text-to-speech synthesis with some control of voice and speech parameters. A demo was also included with AmigaBASIC programming examples. Speech synthesis was occasionally used in third-party programs, particularly educational software. For example, the word processors Prowrite and Excellence! could read out documents using the synthesizer. These speech synthesis components remained largely unchanged in later OS releases and Commodore eventually removed speech synthesis support from AmigaOS 2.1 onward because of licensing restrictions.|$|R
40|$|In this thesis, a diphone [...] based <b>text</b> [...] <b>to</b> [...] <b>speech</b> {{system for}} Scottish Gaelic, a {{language}} spoken by about 80. 000 native speakers in Scotland and Canada, is presented. <b>Text</b> [...] <b>to</b> [...] <b>speech</b> systems convert orthographic text input into speech output. The present system {{consists of two}} main parts: ffl an automatic phonetic transcription module which produces an orthophonic transcription of the orthographic input text ffl a speech synthesis module which synthesizes an utterance from its transcription by concatenating and modifying previously recorded speech units. Diphones, speech units that cover two sounds and the transition between them, {{form the basis of}} the synthesis module. Duration and intonation are modelled on the basis of simple heuristics. The diphone inventory was designed for the Gaelic of Bayble, Lewis. Scottish Gaelic distinguishes four main phonetic settings: velarised, palatalised, nasalised, and neutral. As the domain of these settings is the syllable, they are difficult t [...] ...|$|R
40|$|A {{great variety}} of Natural Language Processing tasks, from word sense {{disambiguation}} <b>to</b> <b>text</b> summarization <b>to</b> <b>speech</b> recognition, rely heavily {{on the ability to}} measure semantic relatedness or distance between words of a natural language. This report is a comprehensive study of recent computational methods of measuring lexical semantic relatedness. A survey of methods, as well as their applications, is presented, and the question of evaluation is addressed both theoretically and experimentally. Application to the specific task of intelligent spelling checking is discussed in detail: the design of a prototype system for the detection and correction of malapropisms (words that are similar in spelling or sound to, but quite different in meaning from, intended words) is described, and results of experiments on using vario [...] ...|$|R
50|$|In March 2017, {{the project}} began {{fundraising}} for research into creating a <b>Text</b> <b>to</b> <b>Speech</b> application for Yoruba.|$|E
50|$|RomajiDesu, {{features}} EDICT-based dictionary, Japanese to Romaji/Kana/English translator, {{also includes}} KANJIDIC, KanjiVG, sample sentences, and <b>Text</b> <b>to</b> <b>Speech.</b>|$|E
50|$|To {{activate}} <b>text</b> <b>to</b> <b>speech</b> on the Android platform, {{install a}} TTS plugin, such as TTS+ plugin from Hyperionics.|$|E
40|$|This {{software}} project based {{paper is}} for {{a vision of the}} near future in which computer interaction is characterized by natural face-to-face conversations with lifelike characters that speak, emote, and gesture. The first step is speech. The dream of a true virtual reality, a complete human-computer interaction system will not come true unless we try to give some perception to machine and make it perceive the outside world as humans communicate with each other. This software project is under development for listening and replying machine (Computer) through speech. The Speech interface is developed <b>to</b> convert <b>speech</b> input into some parametric form (Speech-to-Text) for further processing and the results, <b>text</b> output <b>to</b> <b>speech</b> synthesis (Text-to-Speech) Comment: Pages: 06 Figures : 06. arXiv admin note: text overlap with arXiv: 1305. 1429, arXiv: 1305. 142...|$|R
40|$|Audio-driven facial {{animation}} is {{an interesting}} and evolving technique for human-computer interaction. Based on an incoming audio stream, a face image is animated with full lip synchronization. This requires a speech recognition system in the language in which audio is provided to get the time alignment for the phonetic sequence of the audio signal. However, building a speech recognition system is data intensive and is a very tedious and time consuming task. We present a novel scheme to implement a language independent system for audio-driven facial animation given a speech recognition system for just one language, in our case, English. The method presented here {{can also be used}} for <b>text</b> <b>to</b> audio-visual <b>speech</b> synthesis. 1...|$|R
40|$|Abstract. In this paper, a {{real time}} {{system based on}} ARM 11 is {{designed}} to monitor the indoor air quality (IAQ) which includes the temperature, humidity and soot concentration. The system contains acquisition terminal and control terminal, and the two parts communicate through the wireless channel. The main function of the former is to collect IAQ indicators, while that of the later is to analyze and process the indicators collected, display the corresponding results. To effectively prompt or alarm the user, the core control unit of the control terminal creates corresponding control commands and <b>texts</b> <b>to</b> the <b>speech</b> synthesis chip which will drive the loudspeaker to sound. Hence, it {{plays an important role}} on the monitoring of the IAQ...|$|R
