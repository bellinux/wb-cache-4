4|10000|Public
3000|$|This {{result can}} be easily {{obtained}} by the standard estimation methods. We omit the proof here and put <b>the</b> <b>details</b> <b>in</b> <b>our</b> technical report (Proposition  3.2) on the website: [URL] [...]...|$|E
40|$|Figure 1 : A video {{sequence}} (a) is interactively decomposed into temporally consistent components for reflectance (b, top) and illumination (b, bottom). Now, editing the textures in the reflectance image {{does not affect}} the illumination (c) : changes to the brick walls, the roof tiles, and the pathway leading up to the building all maintain the complex illumination of the light through the trees. We encourage readers to zoom into this figure to see <b>the</b> <b>details</b> <b>in</b> <b>our</b> results, and refer them to the accompanying video to see the temporally consistent nature of our decomposition. Separating a photograph into its reflectance and illumination intrinsic images is a fundamentally ambiguous problem, and state-of-the-art algorithms combine sophisticated reflectance and illumination priors with user annotations to create plausible results. However, these algorithms cannot be easily extended to videos for two reasons: first, naı̈vely applying algorithms designed for single images to videos produce results that are temporally incoherent; second, effectively specifying user annotations for a video requires interactive feed-back, and current approaches are orders of magnitudes too slow to support this. We introduce a fast and temporally consistent al...|$|E
40|$|This study {{intends to}} expand the {{historical}} language and gender debate (Chapter 1) by examining the cognitive structures that underlie human beliefs about gender. Although the work does not profess to be a feminist work, it does seek to offer an opinion about how and why linguistic and social change can occur within a population. It examines {{the current state of}} gendered language usage and the potential for change in gendered language usage within a Western population. The foundational methods for this study include cognitive linguistic and metaphor theories (Chapter 2) combined with narrative theory (Chapter 3), and the study incorporates Christian theological (Chapter 4) and feminist history (Chapters 1 & 4) as a basis for understanding the cultural conventions about gender in the West. Narratives are considered to be "Instruments of Mind" (3. 6). They consist of systematic structures necessary for all human cognition, principally consisting of metaphorical mappings between source and target domains (2. 6). Narrative structures therefore enable us to reason throughout daily life. As a crucial part of our reasoning strategies, narratives point to <b>the</b> <b>details</b> <b>in</b> <b>our</b> moral systems (Chapter 4). A moral system is the coherent foundation of a person's beliefs and choices. Moral systems are culturally shared, but there may be several versions of moral systems in any given culture (4. 1). Due to the prolific capacity of metaphorical reasoning, spreading activation in neural structures that enables such reasoning (2. 4), and the radial characteristics of real human categorization strategies (2. 2, 2. 3), no human being reasons with complete consistency. Exceptions abound and point to the blending of moral systems in individuals' reasoning strategies (Chapter 10). Crucially, exceptions indicate both the potential for change and an innate human creativity (2. 11, Chapter 10). We can draw inferences (3. 1) about human reasoning structures and individuals' moral systems from the language individuals choose to discuss culturally shared stories. Constellations of words, collocations, phrases, and metaphors point to the values, or moral systems, of each individual. Constellations and collocations (3. 4) often demonstrate beliefs in cultural folk models (2. 3, 4. 1. 5). Folk models primarily consist of prototypes and basic-level effects (2. 2), and speakers employ these to make speedy and efficient judgments about people, things, and actions in everyday life. Prototype categories, however, are radial categories (2. 2, 2. 3), which means that membership in a category is based on relationship to the central member, but that categories have indistinct boundaries and allow for unique or novel inclusion radiating from the central members. The capacity for novel usage (2. 11) {{is one of the most}} salient qualities of human cognition, and it is the quality that allows for both linguistic and social change through cognitive transformation. The primary folk models in the West point to two moral systems used by speakers to reason about daily, mundane and complex functions and actions. Both prototypical moral systems stem from the Christian heritage: the Strict Father system of morality (SFM) and the Nurturant Parent system of morality (NPM) (Chapter 4). SFM involves hierarchies, strict boundaries, moral strength, and purity, while NPM is based on empathy and dissolves notions of hierarchies. This study demonstrates through interviews with 26 native speakers of modern German regarding stories of Christian saints (Chapters 5 - 9) that the leading moral system both historically and currently in this Western population segment is SFM (Chapter 10). While many speakers demonstrate occasional features of NPM reasoning, female consultants tend to demonstrate more of these features than male consultants (Chapters 7 - 10). It appears that women's historical status as a subordinate group under a SFM system may predispose them to the use of empathy (10. 1) and therefore to the use of NPM reasoning. Women tend to be the primary instigators of change in gendered language usage. Finally, the analysis of the study suggests that language and social change occur over time as a result of the creative potential inherent in empathetic cognition, found more often in subordinate groups, due to their perception of a need for alternatives from the norm (Chapter 10). Change rarely occurs "from above", through those who make up the status quo, but originates out of a need by subordinate groups to break down strict boundaries and rigid divisions. Change is always possible, as human cognition is based on fuzzy boundaries and radial categories. Nonetheless, change is a slow process because it requires long-term and often radical alterations in the tenacious narrative and cognitive structures of a shared culture...|$|E
60|$|We were obliged {{indeed to}} give up the idea of {{following}} <b>the</b> plan <b>detailed</b> <b>in</b> <b>our</b> book, because we hadn't the sum upon which the furnishing of a small house was therein based.|$|R
6000|$|... "If {{the public}} would only attend," [...] {{observed}} Mr Bright, in commenting on these facts, [...] "to the regulations laid down for their guidance by <b>the</b> Post-Office--as <b>detailed</b> <b>in</b> <b>our</b> Directories and Postal Guides--such errors would seldom occur, for I believe that things of this sort {{are the result of}} ignorance rather than dishonesty." ...|$|R
40|$|We {{present an}} {{efficient}} algorithm for progressive transmission of cutting plane data extracted from large scale Computational Field Simulation (CFS) datasets. Since cutting planes {{are the most}} frequently-used method for examination of 3 D simulation results, efficient compression of both the geometry/topography and the associated field data is important for good visualization performance, especially when the simulation is running on a geographically remote server or the simulation results are stored in a remote repository. Progressive compression is ideal for exploratory visualization since the data can be presented naturally starting with a coarse view and progressing down to <b>the</b> <b>detail.</b> <b>In</b> <b>our</b> algorithm, each cutting plane, which is a triangle mesh, is reduced at the server to triangle strips which contain each contour location. On the local visualization machine (the client), the original surface is reconstructed by filling in the area between the triangle strips using a triangulati [...] ...|$|R
40|$|The DTI’s Corporate Law and Governance {{strategy}} aims {{to promote}} and deliver an effective framework for corporate governance in the UK, giving confidence to investors, business, and other stakeholders to underpin the relationship between an organisation and those who hold future financial claims against that organisation. However, corporate governance involves various problems of asymmetric information and incomplete contracts that generate a need for public policy responses to mitigate market failures and ensuring that companies moves towards ‘good’ corporate governance. Since the early 1990 s, the UK has been very active in undertaking policy reforms that includes a number of corporate governance codes, expert reports, a high level review of company law, and new regulations and legislation. These policy initiatives need to be monitored and evaluated {{in terms of their}} success in influencing the key drivers of ‘good’ corporate governance. This Report undertaken for the DTI has several aims: to identify key drivers of good corporate governance based on a review of social science literature; to describe the content of UK regulatory initiatives with regard to those drivers; and to evaluate gaps in the content and implementation of UK policy regarding corporate governance, using those drivers as benchmarks. In addition, some further implications of this study are discussed for future policy and research on UK corporate governance. The Report identifies key drivers of good corporate governance based on extensive review of the broad social science literature. Good corporate governance is defined here with regard to the rights and responsibilities of company stakeholders, and the wealth-creating and wealthprotecting functions of corporate governance within this context. Based on this definition, a detailed review of the theoretical and empirical social science literature on corporate governance was undertaken across seven broad areas: boards of directors, shareholder activism, information disclosure, auditing and internal controls, executive pay, the market for corporate control, and stakeholders. The result was the identification of 18 key ‘drivers’ or governance mechanisms, which promote ‘good’ corporate governance. An internet-based survey of international corporate governance experts was conducted in order to confirm and further specify these drivers in relation to the UK context. Next, key gaps in the UK regulatory framework are explored with reference to the drivers of good corporate governance. A comprehensive review was undertaken to evaluate corporate governance-related developments in UK regulation since 1990. Policy initiatives were analysed with regard to both their content and effectiveness in promoting each of the identified drivers. Several potential gaps in coverage were identified in the areas of executive pay and employees stakeholders. A number of potential gaps in effectiveness were also identified with regard to other key drivers such as boards, shareholder involvement, information disclosure, auditing, and the market for corporate control. The analysis was supported by feedback from a Focus Group of expert practitioners that took place at the DTI in January 2006. The Report also emphasises that the effectiveness of corporate governance regulation depends very much on balancing different governance demands and regulatory trade-offs. Corporate governance is shaped by a number of contingencies, complementarities, and costs. Various organisational contingencies may place different demands on corporate governance drivers, and their implementation is also associated with different sorts of costs. Looking more generally, different drivers may act as complements or substitutes for one another. Better appreciation of such interdependencies is crucial to formulating a coherent regulatory strategy and balancing important regulatory trade-offs between the following - mandatory regulation (uniform requirements) and more flexible forms of soft-law such as codes based on comply-or-explain principles and self-regulatory norms of professional groups. This analysis suggests a number of areas for future research. Bearing in mind the depth and breadth of the UK regulatory initiatives, it is important to verify whether they were followed by behavioural changes of the participants in corporate governance mechanisms, including unintended consequences such as the development of ‘gaming’ practices. Further research is needed on a potential ‘gatekeeper failure’ in situations where reliance on ‘reputational intermediaries’, such as auditors, securities analysts, attorneys, and other professionals, is not fully justified. Other research recommendations are related to wealth creation and performance trade-offs. It is important to go beyond the question of maximizing shareholder returns and consider to what extent different corporate governance configurations promote long-term, value-creating economic production in a fashion that benefits not only shareholders but also other groups that make specific investments in corporations. Finally, a more holistic approach to the effectiveness of corporate governance drivers requires further research on such aspects as stakeholder involvement, contingencies, complementarities, and cost aspects that may affect the effectiveness of corporate governance mechanisms. The authors would like to point out that, since the report was written, there have been various developments, not least changes in UK law, which have overtaken some of <b>the</b> <b>details</b> <b>in</b> <b>our</b> analysis. However, the basic review of the evidence basis and the perspectives offered remain very much current...|$|E
5000|$|In September 2016, the Open Philanthropy Project {{granted the}} panel a $1.3 million grant {{in support of}} the panel's {{influential}} leadership role in the evaluation of the nation’s biodefense systems. Tom Ridge said, [...] "It is troubling that we still do not have a comprehensive approach to preparing for and responding to biological events. That is why this grant from Open Philanthropy is so critical. It will allow us to push forward <b>the</b> recommendations <b>detailed</b> <b>in</b> <b>our</b> National Blueprint and seek to put them into action." ...|$|R
40|$|We {{present a}} {{discussion}} of and results from the ESO Remote Galaxy Survey (ERGS), a spectroscopic survey of Lyman-break galaxies with z ~ 5 and above. The survey directly explores the properties of these early star-forming galaxies, increasing <b>the</b> observational <b>detail</b> <b>in</b> <b>our</b> picture of early galaxy evolution. The survey provides a sample of galaxies ideally matched in spatial distribution to the capabilities of current and imminently available instrumentation. We discuss {{the results of the}} first follow-on studies of the sample in the mm/sub-mm that signpost the potential of these facilities for exploring early galaxy evolution...|$|R
30|$|The {{microstructure}} and morphology of the nanostructures {{were characterized}} with a high-resolution {{scanning electron microscope}} (Ultra Plus, Zeiss, Oberkochen, Germany). X-ray diffraction (X'Pert Pro system, PANalytical, Almelo, The Netherlands) data was obtained in grazing incident geometry with fixed angles of 1.5 ° and 0.05 ° step using monochromatic Cu Kα radiation ((λ[*]=[*] 1.5418 Å)). The process steps for preparing <b>the</b> nanostructures were <b>detailed</b> <b>in</b> <b>our</b> previous paper [32] and are described briefly below.|$|R
40|$|This work {{presents}} {{some space}} decomposition algorithms for a convex minimization problem. The algorithms has linear {{rate of convergence}} {{and the rate of}} convergence depends only on four constants. The space decomposition could be a multigrid or domain decomposition method. We explain <b>the</b> <b>detailed</b> procedure <b>in</b> implementing <b>our</b> algorithms for a two-level overlapping domain decomposition method and estimate the needed constants. Numerical tests are reported for linear as well as nonlinear elliptic problems...|$|R
40|$|This report <b>details</b> <b>the</b> changes <b>in</b> <b>our</b> {{transportation}} {{systems that are}} occurring {{and will continue to}} evolve with more advanced car sharing services as ZipCar and Car 2 Go and with transportation innovations which fill niches such as Transportation Network Companies (TNC). We will focus on the Goliath in TNC: Uber. Uber’s technology strategies will be discussed. This report also analyzes the effect on society, employees, and the public of those three services...|$|R
30|$|It is {{worthwhile}} mentioning that there exist sites {{much larger than}} those <b>in</b> <b>our</b> sample, such as, for example, The Pirate Bay. Although using data from one of such sites is desirable, obtaining such data with <b>the</b> level of <b>detail</b> <b>in</b> <b>our</b> traces is arguably infeasible: {{there are millions of}} users and no accessible centralized registry for their state. Furthermore, one should note {{that the vast majority of}} BitTorrent sites with large user bases are not nearly as large as The Pirate Bay [57]. <b>In</b> this perspective, <b>our</b> traces represent the typical large BitTorrent sites [57].|$|R
40|$|This paper {{estimates}} {{the impact of}} road improvements on firm employment and productivity using plant level longitudinal data for Britain. Exposure to transport improvements is measured by changes in employment accessibility along the road network. These changes are constructed using data on employment for small geographical units, <b>details</b> of <b>the</b> main road network and of road construction schemes carried out between 1998 and 2007. We deal with the central problem of endogenous scheme placement by using changes due to new road links and exploiting <b>the</b> spatial <b>detail</b> <b>in</b> <b>our</b> data to focus on accessibility changes close to new schemes. We find substantial effects on employment and numbers of plants for small-scale geographical areas (electoral wards), but no employment response at plant level. This suggests that road construction affects firm entry and exit, but not the employment of existing firms. We also find effects on labour productivity and wages at the firm level, although these results are less robust...|$|R
40|$|This paper {{deals with}} the basic {{approximation}} properties of the h-p version of the boundary element method (BEM) in IR 3. We extend the results on the exponential convergence of the h-p version of the boundary element method on geometric meshes from problems in polygonal domains to problems in polyhedral domains. In 2 D elliptic boundary value problems the solutions have only corner singularities whereas in 3 D problems they contain additional edge and corner-edge singularities. The solutions of the corresponding boundary integral equations inherit those singularities. <b>The</b> <b>detailed</b> investigations <b>in</b> <b>our</b> analysis {{take care of the}} various types of those singularities. While edge singularities can be analyzed using standard one-dimensional approximation results the corner-edge singularities demand a new analysis. Subject Classifications: AMS(MOS) 65 N 38, 65 R 20, 45 L 10 Key Words: boundary element methods, h-p version, exponential rate of convergence 1 Introduction The solutions of three-di [...] ...|$|R
40|$|We study {{dielectric}} breakdown in a semi-classical bond percolation model for nonlinear composite materials introduced by {{us and the}} related breakdown exponent near the percolation threshold in two dimensions. The breakdown exponent after doing finite size scaling analysis {{is found to be}} t_B ≃ 1. 42. We discuss <b>in</b> <b>detail</b> <b>the</b> differences <b>in</b> <b>our</b> model from the traditional models for {{dielectric breakdown}} and argue that our result seems to be different from the standard result of 4 / 3 obtained in the previous models. Comment: 20 pages, LaTex file (6 postscript figures included...|$|R
3000|$|Polysilicon nanoribbon biosensors were {{fabricated}} {{with different}} channel lengths using <b>the</b> TFT process <b>detailed</b> <b>in</b> <b>our</b> previous work [6] and measured in dry and wet ambient. Electrical characterization was performed using an Agilent B 1500 A I/V-based probe-station (Agilent Technologies Singapore (International) Pte. Ltd., Singapore). The sensors were measured in a Faraday cage enclosure box to minimize interference. For {{the characterization of}} the sensors, electrical contact was made on the TiN electrodes using Cascade micropositioner probes. The backside of the substrate was grounded through the probe-station chuck to prevent biasing of the channel through it. Transmission line measurements (TLMs) were performed on test structures, and values of sheet resistance (R [...]...|$|R
40|$|Newcomers to the DIG System often {{inquire about}} the {{possibility}} of performing Northern blot hybridizations with nonradioactive techniques. With the following examples, we would like to share our protocol for performing highly sensitive Northern blots. This procedure strictly adheres to <b>the</b> standard procedures <b>detailed</b> <b>in</b> <b>our</b> manuals and pack inserts, and there are no special “tricks ” required. As a target, we have used total human skeletal muscle RNA (Clontech). We selected two probes: b-actin and a probe comprising the cDNA of the transcription factor CTF 1, which expresses a low abundant mRNA. We used in vitro transcribed RNAs exclusively as probes because, during the development of the DIG System, w...|$|R
40|$|We {{encountered}} {{a patient with}} an adult Bochdalek hernia discovered asymptomatically. A 77 -year-old Japanese woman visited a local clinic with chief complaints of melena and difficulty in defecation. Based {{on the results of}} <b>the</b> <b>detailed</b> examination <b>in</b> <b>our</b> hospital, she was diagnosed with a rectal gastrointestinal stromal tumor (GIST) with a concurrent asymptomatic adult right-sided Bochdalek hernia. Because the tumor was large, laparoscopic abdominoperineal rectal amputation was performed after systemic imatinib therapy. During the surgery, we found a right diaphragmatic defect more than 13 cm in long dia., through which the right hepatic lobe, colon, and greater omentum had prolapsed into the right thoracic cavity. No visceral adhesions were noted. No hernia sac was observed. Adult Bochdalek hernia is a relatively rare condition, and only three (incidentally discovered) cases of asymptomatic Bochdalek hernia, including the present case, have been reported in Japan. Here we provide a case report for the patient, who was followed-up without hernia surgery, plus a review of the literature...|$|R
40|$|The time {{required}} for decay of a metastable state, through tunneling, is a well settled subject. During this lifetime of the initial state, the particle oscillates within its initial well. By contrast, questions about {{the duration of the}} actual tunneling process, when it finally occurs, have led to widely divergent answers. In recent years, Jonson, Stevens, and we, have, through independent approaches, pointed out that there is an effective barrier traversal velocity obtained by dividing the magnitude of the imaginary momentum, under the barrier, by the particle mass. Here we present a fourth approach to this earlier answer, by considering a time modulated stream incident on the barrier. At low modulation frequencies the transmitted beam reproduces the incident modulation without lag, and without change in modulation depth. As the modulation frequency is increased we eventually depart from this simple behavior, and that is taken as a measure of the transversal time. We also provide some of <b>the</b> <b>details</b> omitted <b>in</b> <b>our</b> earlier analysis...|$|R
40|$|Basic {{problems}} of acousto-optic interaction in terahertz region of electromagnetic spectrum are considered. We obtained experimental {{results that are}} fitted by generalized theoretical model developed with the goals to describe <b>the</b> interaction <b>in</b> <b>detail.</b> <b>Our</b> analysis showed that crystalline germanium {{is one of the}} best materials to observe the acousto-optic interaction in the terahertz range. The carried out study proved that a germanium based acousto-optic device could be used for fast and reliable deflection of monochromatic radiation in the terahertz spectral region. DOI: 10. 12693 /APhysPolA. 127. 4...|$|R
40|$|In this study, {{we explore}} {{nucleation}} and the transition state ensemble of the ribosomal protein S 6 using a Monte Carlo (MC) Go model {{in conjunction with}} restraints from experiment. The results are analyzed {{in the context of}} extensive experimental and evolutionary data. The roles of individual residues in the folding nucleus are identified, and the order of events in the S 6 folding mechanism is explored <b>in</b> <b>detail.</b> Interpretation of <b>our</b> results agrees with, and extends the utility of, experiments that shift φ-values by modulating denaturant concentration and presents strong evidence for the realism of <b>the</b> mechanistic <b>details</b> <b>in</b> <b>our</b> MC Go model and the structural interpretation of experimental φ-values. We also observe plasticity in the contacts of the hydrophobic core that support the specific nucleus. For S 6, which binds to RNA and protein after folding, this plasticity may result from the conformational flexibility required to achieve biological function. These results present a theoretical and conceptual picture that is relevant in understanding the mechanism of nucleation in protein folding...|$|R
40|$|Presented {{here are}} <b>the</b> <b>detailed</b> methods {{employed}} <b>in</b> <b>our</b> laboratory for gene mapping and cytogenetic analyses in human beings, {{in the domestic}} cat, and in other mammalian species. Included in the procedures are: 1) establishment of primary fibroblast and lymphoid cell cultures; 2) heterologous cell fusion for production of rapidly proliferating cell hybrids; 3) cellular transformation of primary fibroblasts using an oncogenic retrovirus; 4) cell synchronization for high-resolution banding of prometaphase chromosomes; 5) chromosome-banding procedures, including G-banding, alkaline G- 11, and Q-banding; and 6) in situ hybridization of radiolabeled molecular clones to metaphase chromosomes for regional gene localization...|$|R
40|$|<b>In</b> {{this paper}} <b>detailed</b> {{calculations}} of <b>the</b> complete O(α_s) corrections to top quark decay widths Γ(t→ q+V) are presented (V=g,γ,Z). Besides describing <b>in</b> <b>detail</b> <b>the</b> calculations <b>in</b> <b>our</b> previous paper (arXiv: 0810. 3889), we {{also include the}} mixing effects of the Flavor-Changing Neutral-Current (FCNC) operators for t→ q+γ and t→ q+Z, which were not considered <b>in</b> <b>our</b> previous paper. The results for t→ q+g {{are the same as}} <b>in</b> <b>our</b> previous paper. But the mixing effects can either be large or small, and increase or decrease the branching ratios for t→ q+γ and t→ q+Z, depending on the values of the anomalous couplings (κ^g,γ,Z_tq/Λ, f^g,γ,Z_tq and h^g,γ,Z_tq). Comment: 21 pages, 12 figure...|$|R
40|$|We {{present a}} new {{calculus}} for first-order theorem proving with equality, ME+Sup, which generalizes both the Superposition calculus and the Model Evolution calculus (with equality) by integrating their inference rules and redundancy criteria in a non-trivial way. The main motivation is {{to combine the}} advantageous features of both [...] -rather complementary [...] -calculi in a single framework. For instance, Model Evolution, as a lifted version of the propositional DPLL procedure, contributes a non-ground splitting rule that effectively permits to split a clause into non variable disjoint subclauses. In the paper we present <b>the</b> calculus <b>in</b> <b>detail.</b> <b>Our</b> main result is its completeness under semantically justified redundancy criteria and simplification rules...|$|R
40|$|In this {{longitudinal}} {{case study}} we have followed a small software product {{company that has}} turned from a waterfall-like process to evolutionary project management (Evo). The most prominent feature of the new process is the close engagement of customers. We have interviewed both internals and customers to investigate the practicalities, costs, gains and prerequisites of such a transition. We have gathered data from {{a period of two}} years covering four consecutive release projects using the new process and analyzed <b>the</b> material <b>in</b> <b>detail.</b> <b>Our</b> findings implicate that close customer engagement does give certain benefits but that it comes with a cost and needs careful attention to management...|$|R
40|$|Abstract. This paper {{presents}} a scalable leader election protocol for large process groups {{with a weak}} membership requirement. The underlying network {{is assumed to be}} unreliable but characterized by probabilistic failure rates of processes and message deliveries. The protocol trades correctness for scale, that is, it provides very good probabilistic guarantees on correct termination {{in the sense of the}} classical specification of the election problem, and of generating a constant number of messages, both independent of group size. After formally specifying the probabilistic properties, we describe <b>the</b> protocol <b>in</b> <b>detail.</b> <b>Our</b> subsequent mathematical analysis provides probabilistic bounds on the complexity of the protocol. Finally, the results of simulation show that the performance of the protocol is satisfactory...|$|R
40|$|Abstract. We {{describe}} {{the implementation of}} a 2 D optical flow algorithm published in the European Conference on Computer Vision (ECCV 2004) by Brox et al. [1] (best paper award) and a qualitative and quantitative evaluation of it for a number of synthetic and real image sequences. Their optical flow method combines three assumptions: a brightness constancy assumption, a gradient constancy assumption and a spatio-temporal smoothness constraint. A numerical scheme based on fixed point iterations is used. Their method uses a coarse-to-fine warping strategy to measure larger optical flow vectors. We have investigated <b>the</b> algorithm <b>in</b> <b>detail</b> and <b>our</b> evaluation of the method demonstrates that it produces very accurate optical flow fields from only 2 input images...|$|R
40|$|Dynamic taint {{analysis}} {{is a well-known}} information flow analysis problem with many possible applications. Taint tracking allows for analysis of application data flow by assigning labels to inputs, and then propagating those labels through data flow. Taint tracking systems traditionally compromise among performance, precision, accuracy, and portability. Performance can be critical, as these systems are typically intended to be deployed with software, and hence must have low overhead. To be deployed in security-conscious settings, taint tracking must also be accurate and precise. Dynamic taint tracking must be portable {{in order to be}} easily deployed and adopted for real world purposes, without requiring recompilation of the operating system or language interpreter, and without requiring access to application source code. We present Phosphor, a dynamic taint tracking system for the Java Virtual Machine (JVM) that simultaneously achieves our goals of performance, accuracy, precision, and portability. Moreover, to our knowledge, it is the first portable general purpose taint tracking system for the JVM. We evaluated Phosphor's performance on two commonly used JVM languages (Java and Scala), on two versions of two commonly used JVMs (Oracle's HotSpot and OpenJDK's IcedTea) and on Android's Dalvik Virtual Machine, finding its performance to be impressive: as low as 3 % (53 % on average), using the DaCapo macro benchmark suite. This artifact contains the code needed to reproduce <b>the</b> experiments <b>detailed</b> <b>in</b> <b>our</b> paper...|$|R
40|$|Pacemaker {{activity}} of the sinoatrial node has been studied extensively in various animal species, but is virtually unexplored in man. As such, it is unknown whether the fast sodium current (I Na) {{plays a role in}} the pacemaker {{activity of}} the human sinoatrial node. Recently, we had the unique opportunity to perform patch-clamp experiments on single pacemaker cells isolated from a human sinoatrial node. In 2 out of the 3 cells measured, we observed large inward currents with characteristics of I Na. Although we were unable to analyze <b>the</b> current <b>in</b> <b>detail,</b> <b>our</b> findings provide strong evidence that I Na is present in human sinoatrial node pacemaker cells, and that this I Na is functionally available at potentials negative to - 60 mV. </p...|$|R
40|$|The current {{production}} of the Hungarian agricultural machinery manufacturing sector, which used to see better days, lags behind the {{production of}} the previous years to a great extent. Our study reveals the initial results of longer research work. We examine how the innovation activity of organisations changed during the period between 2007 and 2009. The conclusions of our paper are based on the examination results of questionnaires and in-depth interviews that were carried out at 40 Hungarian agricultural machinery manufacturing companies. The characteristic features of the companies that were involved in the examination reflect the Hungarian conditions properly. Besides the brand-new or higly developed products and technological (procedure) innovations, novelties in organisation and marketing are also paid attention. Furthermore, some of the indicators of the innovation performance of the companies are also presented. The question of cooperation between the organisations taking part in innovation is referred to, as well. The other results of <b>the</b> research are <b>detailed</b> <b>in</b> <b>our</b> further publications...|$|R
40|$|Abstract We {{present a}} new {{calculus}} for first-order theorem proving with equality, ME+Sup, which generalizes both the Superposition calculus and the Model Evolution calculus (with equality) by integrating their inference rules and redundancy criteria in a non-trivial way. The main motivation is {{to combine the}} advantageous features of these two rather complementary calculi in a single framework. In particular, Model Evolution, as a lifted version of the propositional DPLL procedure, contributes a non-ground splitting rule that effectively permits to split a clause into non variable disjoint subclauses. In the paper we present <b>the</b> calculus <b>in</b> <b>detail.</b> <b>Our</b> main result is its completeness under semantically justified redundancy criteria and simplification rules. We also show how under certain assumptions the model representation computed by a (finite and fair) derivation can be queried in an effective way. ...|$|R
40|$|This {{is a case}} of {{idiopathic}} pulmonary calcification and ossification in a 70 {{year old}} with long-standing diabetes and hypertension. Thirteen years prior to her demise, she was first noticed to have multiple calcific deposits in her lungs on a chest X-ray film. She had no risk factors for soft tissue calcification and ossification. Histology of tissue from autopsy showed intraparenchymal pulmonary calcification and ossification with marrow elements. Idiopathic pulmonary calcification and ossification is rare. At autopsy, she was also found to have had bilateral subarachnoid haemorrhage (SAH), a diagnosis missed during clinical evaluation. We highlight <b>the</b> pertinent <b>details</b> <b>in</b> <b>our</b> patient’s management that could have helped to prevent a missed diagnosis of SAH. Even though SAH occurs most commonly following head trauma, the more familiar medical use of SAH is for non-traumatic SAH occurring following a ruptured cerebral aneurysm. This patient had notable risk factors for cerebral aneurysm formation but an aneurysm was not identified at autopsy. The location of the blood high on the cerebral convexities further suggests a traumatic origin rather than a ruptured aneurysm. Heterotopic calcification and ossification (HO) is known to occur in the setting of severe neurologic disorders such as traumatic brain injury {{but the fact that the}} lung calcification <b>in</b> <b>our</b> patient predated the brain injury by over 10 years makes it unlikely for the HO to have been due to the brain trauma. Other organ pathologies found at autopsy include chromophobe renal cell carcinoma, renal papillary necrosis, lymphocytic thyroiditis, and seborrheic keratosis...|$|R
40|$|Independent {{optimization}} for workload {{and power}} management, and active cooling control {{have been studied}} extensively to improve data center energy efficiency. Recently, proposals have started to advocate unified workload, power, and cooling management for further energy savings. In this paper, we study this problem with the objectives of both saving energy and capping power. We present <b>the</b> <b>detailed</b> models derived <b>in</b> <b>our</b> previous work from experiments on an blade enclosure system that can be representative of a data center, discuss the optimization opportunities for coordinated power and cooling management, and the challenges for controller design. We then propose a few design principles and examples for unified workload management, power minimization, and power capping. Our simulation-based evaluation shows that the controllers can cap the total power consumption while maintaining the thermal conditions and improve the overall energy efficiency. We argue that the same opportunities, challenges, and designs are also generally applicable to data center level management. 1...|$|R
40|$|We {{present a}} review of {{elemental}} abundances in the Milky Way stellar disk, bulge, and halo {{with a focus on}} data derived from high-resolution stellar spectra. These data are fundamental in disentangling the formation history and subsequent evolution of the Milky Way. Information from such data is still limited and confined to narrowly defined stellar samples. The astrometric Gala satellite will soon be launched by the European Space Agency. Its final data set will revolutionize information on the motions of a billion stars in the Milky Way. This will be complemented by several ground-based observational campaigns, in particular spectroscopic follow-up to study elemental abundances <b>in</b> <b>the</b> stars <b>in</b> <b>detail.</b> <b>Our</b> review shows <b>the</b> very rich and intriguing picture built from rather small and local samples. The Gaia data deserve to be complemented by data of the same high quality that have been collected for the solar neighborhood. (C) 2013 Elsevier B. V. All rights reserved...|$|R
40|$|In {{this article}} we use a {{combination}} of neural networks with other techniques for the analysis of orthophotos. Our goal is to obtain results that can serve as a useful groundwork for interactive exploration of <b>the</b> terrain <b>in</b> <b>detail.</b> <b>In</b> <b>our</b> approach we split an aerial photo into a regular grid of segments and for each segment we detect a set of features. These features depict the segment from the viewpoint of a general image analysis (color, tint, etc.) {{as well as from the}} viewpoint of the shapes in the segment. We perform clustering based on the Formal Concept Analysis (FCA) and Non-negative Matrix Factorization (NMF) methods and project the results using effective visualization techniques back to the aerial photo. The FCA as a tool allows users to be involved in the exploration of particular clusters by navigation in the space of clusters. In {{this article we}} also present two of our own computer systems that support the process of the validation of extracted features using a neural network and also the process of navigation in clusters. Despite the fact that <b>in</b> <b>our</b> approach we use only general properties of images, the results of our experiments demonstrate the usefulness of our approach and the potential for further development. Web of Science 22212110...|$|R
