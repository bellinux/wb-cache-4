0|10000|Public
5000|$|These {{include three}} [...] "small" [...] Shahnamehs, perhaps the earliest, whose small size (<b>text</b> and <b>image</b> <b>area</b> of 250 x 170 mm {{in a typical}} example) may have suited nomadic owners, and four manuscripts for the semi-independent Injuid rulers of Shiraz and Isfahan in the south-west. This latter group, {{probably}} all later than the Great Mongol Shahnameh, are influenced by it, though much less complex in style.|$|R
40|$|Extensive {{research}} has been done on image classification for different purposes like face recognition, identification of different objects and identification/extraction of <b>text</b> from <b>image</b> having some background. Text identification is an active research area where by system tries to identify the text area in a given <b>image.</b> <b>Text</b> <b>area</b> identified is then passed to OCR system for further recognition of the text. This work is about classifying <b>image</b> <b>area</b> in two classes text and non text using SVM (support vector machine). We identified the features and train a model based on the feature vector which is then used to classify text and non <b>text</b> <b>area</b> in an <b>image.</b> The system reports 70. 5 % accuracy for caption <b>text</b> <b>images,</b> 70. 43 % for document <b>text</b> <b>images</b> and 50. 40 % for scene <b>text</b> <b>image...</b>|$|R
40|$|Post {{processing}} and automatic interpretation of images plays {{an increasingly important}} role in the mobile area. Both for the efficient compression and for the automatic evaluation of text, it is useful to store text content as textual information rather than as graphics information. For this purpose pictures from magazines are recorded with the camera of a smartphone and classified according to <b>text</b> and <b>image</b> <b>areas.</b> In this work established desktop procedures are presented and analysed in terms of their applications on mobile devices. Based on these methods, an approach for image segmentation and classification on mobile devices is developed, taking into account the limited resources of these mobile devices...|$|R
40|$|Abstract: Classification of <b>text</b> and <b>image</b> using {{statistical}} features (mean {{and standard}} deviation of pixel color values) {{is found to be}} a simple yet powerful method for <b>text</b> and <b>image</b> segmentation. The features constitute a systematic structure that segregates one from another. We identified this segregation in the form of class clustering by means of Fuzzy C-Mean method, which determined each cluster location using maximum membership defuzzification and neighborhood smoothing techniques. The method can then be applied to classify <b>text,</b> <b>image,</b> and background <b>areas</b> in optical character recognition (OCR) application for elaborated open document systems. Key words: segmentation, clustering, statistical classification. 1...|$|R
50|$|In particular, {{several authors}} {{investigated}} {{the possibility of}} recognizing image spam with obfuscated images by using generic low-level image features (like number of colours, prevalent colour coverage, <b>image</b> aspect ratio, <b>text</b> <b>area),</b> <b>image</b> metadata, etc. (see for a comprehensive survey).Notably, some authors also tried detecting the presence into attached <b>images</b> of <b>text</b> with artifacts denoting an adversarial attempt to obfuscate it.|$|R
40|$|Starting with a {{description}} of the software and hardware used for corpus linguistics in the late 1980 s to early 1990 s, this contribution discusses difficulties faced by the software designer when attempting to allow users to study text. Future human-machine interfaces may develop to be much more sophisticated, and certainly the aspects of text which can be studied will progress beyond plain <b>text</b> without <b>images.</b> Another <b>area</b> which will develop further is the study of patternings involving not just single words but word-relations across large stretches of text...|$|R
40|$|Text segmentation, or named text binarization, {{is usually}} an {{essential}} step for text information extraction from images and videos. However, most existing text segmentation methods have difficulties in extracting multi-polarity texts, where multi-polarity texts mean those texts with multiple colors or intensities {{in the same}} line. In this paper, we propose a novel algorithm for multi-polarity text segmentation based on graph theory. By representing a <b>text</b> <b>image</b> with an undirected weighted graph and partitioning it iteratively, multi-polarity <b>text</b> <b>image</b> can be effectively split into several single-polarity <b>text</b> <b>images.</b> As a result, these <b>text</b> <b>images</b> are then segmented by single-polarity text segmentation algorithms. Experiments on thousands of multi-polarity <b>text</b> <b>images</b> show that our algorithm can effectively segment multi-polarity texts...|$|R
40|$|In {{order to}} solve the problem of <b>text</b> <b>image</b> {{containing}} the complex background in which the <b>text</b> of <b>image</b> cannot be read clearly and intuitively, this paper proposed a filtering method based on the Harris corner-point detection. The experimental results show that the algorithm can filter the background which contains <b>text</b> <b>image</b> commendably, making it possible for visually reading...|$|R
40|$|In this paper, a novel {{neural network}} {{architecture}} is proposed attempting to rectify <b>text</b> <b>images</b> with mild assumptions. A new dataset of <b>text</b> <b>images</b> is collected to verify our model {{and open to}} public. We explored the capability of deep neural network in learning geometric transformation and found the model could segment the <b>text</b> <b>image</b> without explicit supervised segmentation information. Experiments show the architecture proposed can restore planar transformations with wonderful robustness and effectiveness. Comment: 9 pages, 10 figure...|$|R
40|$|Recently, several {{algorithms}} {{have been}} developed to hide data in either <b>text</b> <b>images</b> or halftone images. According to an observation that the number of transitions between black pixel and white pixel in the halftone image is much larger than that in the <b>text</b> <b>image,</b> this paper presents a unified min-max transition (MMT) scheme to embed data into the above two types of images without visual degradation. For <b>text</b> (halftone) <b>images,</b> data hiding can be performed by modifying the values of pixels to minimize (maximize) the number of the transitions. Based on our proposed MMT scheme, a unified block- and MMT-based data hiding (BMMTDH) algorithm is developed for <b>text</b> <b>images,</b> halftone images, and mixed text/halftone (MTH) images. Experimental results demonstrate that for MTH images, our proposed BMMTDH algorithm outperforms the previous relevant algorithms...|$|R
50|$|Cloud Share: {{supports}} sharing <b>text,</b> <b>images,</b> websites/links {{and files}} online.|$|R
50|$|The output video {{consists}} of <b>text,</b> <b>images,</b> videos, and sounds.|$|R
5000|$|Ecole Initiative Online {{collection}} of patristic <b>texts,</b> <b>images,</b> and information.|$|R
5000|$|Cloud Share: {{supports}} sharing <b>text,</b> <b>images,</b> websites/links {{and files}} online ...|$|R
40|$|A {{technique}} that {{can improve the}} optical character recognition (OCR) accuracy of <b>text</b> <b>images</b> is presented. By using the output from an OCR system and a distorted <b>text</b> <b>image,</b> this technique trains an adaptive restoration ﬁlter and then applies the ﬁlter to the distorted text that the OCR system could not recognize. The restored <b>text</b> <b>image</b> is then reprocessed by the OCR system, and the restored characters are recognized with a higher accuracy than the distorted text. A series of experiments were performed to determine a feasible adaptive restoration ﬁlter architecture, to establish this technique’s ability to restore uniformly distorted text, and to demonstrate this technique’s ability to improve the OCR accuracy of real world text documents. The results of these experiments show that this technique can improve both pixel and OCR accuracy of distorted <b>text</b> <b>image...</b>|$|R
5000|$|... finding, exploring, {{developing}} and presenting information including <b>text,</b> <b>images</b> and numbers ...|$|R
40|$|In this paper, {{compression}} {{scheme is}} presented for Indian Language handwritten <b>text</b> document <b>images.</b> Document image compression {{is an active}} area of research. Current OCR technology is not effective for handling the handwritten <b>text</b> <b>images.</b> The proposed compression scheme deals with the handwritten gray level document in Devnagri script. The method {{is based on the}} separation of foreground and background of an image and connected component labeling. Experiments are done with handwritten images in Devnagri (Hindi and Marathi). Compression schemes are available for the printed text in Indian language. But there is little work reported towards the compression standards for handwritten <b>text</b> <b>image.</b> The results of the modules are showing good compression ratio. Hence compression of handwritten <b>text</b> <b>images</b> in Indian language is important...|$|R
50|$|Cloud Share: {{supports}} sharing <b>text,</b> <b>images,</b> websites/links {{and files}} with other people.|$|R
5000|$|Coding of <b>text,</b> <b>image,</b> geo, {{audio and}} video {{materials}} (interactive and automated)) ...|$|R
40|$|Computer <b>text</b> and {{ordinary}} <b>images</b> displayed together without text jitter. Scan converter enables superposition of alphanumerical text generated by computer-driven video generator on National Television System Committee (NTSC) standard interlaced-scan image. Made of commercially available integrated circuits and operates {{in conjunction with}} NTSC synchronizing-signal generator. Standard television picture transmitted in two interlaced fields. Without scan converter, <b>text</b> <b>image</b> moves up and down by one line as fields change. With scan converter, <b>text</b> <b>image</b> stands still...|$|R
2500|$|... (<b>texts,</b> <b>images,</b> videos,...) – CVCE – Virtual Resource Centre for Knowledge about Europe ...|$|R
5000|$|Rich text {{notes with}} {{formatted}} <b>text,</b> <b>images,</b> hyperlink, tables, bullets, SWF, OLE object.|$|R
40|$|Abstract — In this paper, {{a robust}} {{technique}} for identifying and recognizing Handwritten <b>Text</b> <b>images</b> is presented. There are many methods for Handwritten Text, {{but most of}} them require segmentation or connected component analysis. The Recognition process utilizes the determinant value that produces the features for the Handwritten <b>Text.</b> <b>Image’s</b> determinants values are computed by dividing image into blocks then designed Threshold (T) to extract feature, afterwards, use chain code to find the centric point and direction of text. The least square criterion is then utilized to determine the similarity between the existed (in Database file) Handwritten Text with a new query Handwritten <b>Text’s</b> <b>images...</b>|$|R
5000|$|Crossroads Poetics: <b>Text,</b> <b>Image,</b> Music, Film & Beyond (Prague: Litteraria Pragensia/Charles University Prague, 2013) ...|$|R
5000|$|... the height/width {{describes}} {{the dimensions of}} the actual content of the box (<b>text,</b> <b>images,</b> ...) ...|$|R
5000|$|... 1999, Legal {{culture in}} the early medieval west: law as <b>text,</b> <b>image</b> and experience.|$|R
5000|$|... {{alternate}} {{forms of}} knowledge representation (multiple representations of knowledge, e.g. video, audio, <b>text,</b> <b>image,</b> data) ...|$|R
5000|$|Users can add {{different}} {{items to}} their reports (tables, <b>texts,</b> <b>images,</b> stored post-processing views, etc.).|$|R
50|$|Bauer, M., and Gaskell, G. (Eds). (2000). Qualitative researching with <b>text,</b> <b>image</b> and sound. London: Sage.|$|R
50|$|Cloud Push: {{supports}} sending <b>text,</b> <b>images,</b> websites/links and tabs to Mac, Android and Windows operating systems.|$|R
40|$|This paper {{presents}} {{a new technique}} for segmenting corrupted <b>text</b> <b>images</b> {{on the basis of}} color feature analysis by second order tensors. It is show how feature analysis can benefit from analyzing features using second order tensor with chromatic and achromatic components. Proposed technique is applied to <b>text</b> <b>images</b> corrupted by manifold types of various noises. Firstly, we decompose an image into chromatic and achromatic components. Secondly, we analyze color features by second order tensors, and remove noises using a vector median. Lastly, mode estimation and segmentation are performed by adaptive mean shift and separated clustering method respectively. The experimental results show that proposed approach is efficient and robust in terms of restoring and segmenting corrupted <b>text</b> <b>images...</b>|$|R
40|$|<b>Text</b> <b>image</b> super-resolution is a {{challenging}} yet open research {{problem in the}} computer vision community. In particular, low-resolution images hamper the performance of typical optical character recognition (OCR) systems. In this article, we summarize our entry to the ICDAR 2015 Competition on <b>Text</b> <b>Image</b> Super-Resolution. Experiments {{are based on the}} provided ICDAR 2015 TextSR dataset and the released Tesseract-OCR 3. 02 system. We report that our winning entry of <b>text</b> <b>image</b> super-resolution framework has largely improved the OCR performance with low-resolution images used as input, reaching an OCR accuracy score of 77. 19 %, which is comparable with that of using the original high-resolution images 78. 80 %. Comment: 5 pages, 8 figure...|$|R
5000|$|Qualitative researching with <b>text,</b> <b>image</b> {{and sound}} - a {{practical}} handbook (London, Sage, 2000, with G Gaskell) ...|$|R
5000|$|Variety: {{big data}} draws from <b>text,</b> <b>images,</b> audio, video; plus it completes missing pieces through data fusion ...|$|R
40|$|In {{this short}} note, we test various edge-preserving regularization schemes {{in the context}} of {{deblurring}} a <b>text</b> <b>image</b> with random noise. The blurred <b>text</b> <b>image</b> was created by Nagy and O’Leary (2003 a) as a test case. Even if the blurring filter is known exactly, as it is in this case, sharp features are nearly in the nullspace of the filter which we must “invert”, or deblur. Thos...|$|R
40|$|Abstract: In last decades {{different}} {{techniques have}} been created for hiding information. The role of hiding information {{is to create a}} secure communication between authorize parties in terms of exchange their vital data in safe channel. Steganography is a method of hiding data in such an approach no one can feel there is a hidden data or found it. I. e. Only the authorize party can extract these data because he know the achievement of hiding information. in this paper, an efficient method of hiding binary <b>text</b> <b>image</b> via an optimal using of Fibonacci sequence. Digital image is considered to be the cover <b>image.</b> A binary <b>text</b> <b>image</b> is used to represent the secret message instead of normal text. This method is used for the purpose of having a chance to read the binary <b>text</b> <b>image</b> if should any modification happen along the communication channel. (E. g. JPEG compression). A binary <b>text</b> <b>image</b> is an image which includes a text and can be construct by using any software for image processing like paint...|$|R
