19|210|Public
50|$|The M chip (DC329) was {{responsible}} for memory management and interrupt handling. It contained the backup <b>translation</b> <b>buffer</b> (BTB) tags, cache tags and internal processor registers. The M chip also contained the I/O functionality defined by the VAX architecture and generated the clock signal for the chip set.|$|E
50|$|The backup <b>translation</b> <b>buffer</b> was {{essentially}} a translation lookaside buffer (TLB) which handled a miss in the MTB. The BTB contained 512 page table entries (PTEs), of which 256 were for system-space pages and 256 were for process-space pages. There are 128 BTB tags, one for every four PTEs, located in the M chip. The BTB was implemented with external RAMs.|$|E
50|$|The {{chips in}} the chip set were {{connected}} with four buses: the MIB, DAL, PAL and CAL. The MIB (microinstruction bus) carried microinstructions control signals and addresses {{from the control}} store to the I/E and F chips. The MIB is 40 bits wide, the same width as a microword and is parity protected. The DAL is a 32-bit parity-protected bus that carries data addresses {{to and from the}} I/E, M and F chips, cache, backup <b>translation</b> <b>buffer</b> RAMs and the port interface.|$|E
25|$|Performance of Address <b>Translation</b> <b>Buffers</b> {{has been}} enhanced.|$|R
50|$|The I-box {{contains}} two <b>translation</b> lookaside <b>buffers</b> (TLBs) for translating virtual addresses to physical addresses. These TLBs {{are referred to}} as instruction <b>translation</b> <b>buffers</b> (ITBs). The ITBs cache recently used page table entries for the instruction stream. An eight-entry ITB is used for 8 KB pages and a four-entry ITB for 4 MB pages. Both ITBs are fully associative and use a not-last used replacement algorithm.|$|R
5000|$|All <b>translation</b> lookaside <b>buffers</b> (TLBs) are 4-way associative.|$|R
5000|$|The address unit, {{also known}} as the [...] "A-box", {{executed}} load and store instructions. To enable the address unit and integer unit to operate in parallel, the address unit has its own displacement adder, which it uses to calculate virtual addresses, instead of using the adder in the integer unit. A 32-entry fully associative translation lookaside buffer (TLB) is used to translate virtual addresses into physical addresses. This TLB {{is referred to as the}} data <b>translation</b> <b>buffer</b> (DTB). The 21064 implemented a 43-bit virtual address and a 34-bit physical address, and is therefore capable of addressing 8 TB of virtual memory and 16 GB of physical memory.|$|E
50|$|The I/E chip (DC328) {{contained}} an instruction buffer, a microsequencer, an execution unit and a mini-translation buffer (MTB). The instruction buffer is a two-entry 32-bit buffer that held prefetched instructions. It improved performance by maintaining {{a number of}} instructions ready for execution. The hardware attempted to keep the instruction buffer full at all times. The execution unit consisted of sixteen 32-bit general purpose registers defined by the VAX ISA, an arithmetic logic unit (ALU) and a shifter. The MTB is a translation lookaside buffer (TLB). It contained five page table entries (PTEs), one for instruction and four for data. In {{the event of a}} miss, the backup <b>translation</b> <b>buffer</b> (BTB) in the M chip is used. The I/E chip consisted of 60,000 transistors on a die measuring 354 mils by 358 mils (8.99 mm by 9.09 mm) for an area of 126,732 mil2 (81.76 mm2). It dissipated 5 W.|$|E
40|$|This short {{technical}} note shows {{how to measure}} data <b>translation</b> <b>buffer</b> (DTB) misses using the Compaq Continuous Profiling Infrastructure (DCPI.) It assumes that the reader is already somewhat familiar with DCPI. The measurement process is demonstrated through a small example, which illustrates data <b>translation</b> <b>buffer</b> behavior on the Alpha 21264 A. The problem Systems implementing virtual memory rely upon the hardware to map virtual program addresses to physical memory addresses. This mapping must be performed very quickly for each load and store instruction. In contemporary processors, the mapping is assisted by a hardware structure called a "translation look-aside buffer, " or "TLB. " The TLB is a small memory that holds the mostly recently used virtual to physical page mapping information. Alpha implementations have two TLBs: an instruction <b>translation</b> <b>buffer</b> (ITB) and a data <b>translation</b> <b>buffer</b> (DTB.) The Alpha 21264 TLBs each have 128 entries. When a load or store instruction executes, the processor looks up the virtual page information of the effective address in the data <b>translation</b> <b>buffer.</b> If the information is found, the processor uses it to compute the physical address of the memory item and the memory operation continues. If the information is not found, the page information must be loaded from...|$|E
5000|$|CPU fully {{associative}} cache controllers and <b>translation</b> lookaside <b>buffers</b> ...|$|R
5000|$|Larger L1 <b>translation</b> lookaside <b>buffers</b> (TLB) and L2 {{efficiency}} improvements ...|$|R
5000|$|Cache space, {{including}} CPU cache and MMU cache (<b>translation</b> lookaside <b>buffer)</b> ...|$|R
40|$|We {{describe}} the hardware {{support in the}} DELFT-JAVA processor which enables efficient dynamic linking of JAVA programs. The proposed mechanism supports method invocation of dynamically linked classes {{through the use of}} a Link <b>Translation</b> <b>Buffer</b> (LTB). Since our Instruction Set Architecture directly supports dynamically linked method invocation, the Link <b>Translation</b> <b>Buffer</b> is architecturally transparent to the executing program. The operation of the LTB is described and preliminary performance results are reported. Method invocation differences between the C++ programming language and the JAVA programming language are outlined. Preliminary performance results for the Link <b>Translation</b> <b>Buffer</b> suggest that program performance may improve from 1. 1 x to 1. 5 x when a suitable LTB is used to cache frequently utilized methods. 1...|$|E
40|$|We {{developed}} an in organello system to label newly synthesized mitochondrially encoded proteins of Trypanosoma brucei. Highly purified mitochondria, prepared under isotonic conditions, were incubated with radioactive methionine and cysteine in a suitable <b>translation</b> <b>buffer.</b> Analysis of mitochondrial extracts on TRIS-Tricine gels revealed {{a subset of}} labeled, NP- 40 -insoluble proteins. The labeling of these proteins was resistant to the cytosol-specific translation inhibitor cycloheximide. The proteins, however, were not labeled {{in the presence of}} chloramphenicol or erythromycin, inhibitors of prokaryotic type translation, or puromycin, a general translation inhibitor. These results indicate that isotonically isolated mitochondria of T. brucei are capable of protein synthesi...|$|E
30|$|For PCR-based protein {{expression}} (MINI scale, 55  μl translation), {{the following}} {{changes have been}} implemented in the transcription and translation protocols: (1) for transcription, 0.5  μl of the PCR product (2  μg/μl) was mixed with 4.5  μl of the Transcription premix and left incubated at 37  °C for 4  h, (2) for translation, 2  μl of the resulting mRNA was mixed with 0.5  μl of FluoroTect GreenLys and 2.5  μl of the wheat germ extract (WEPRO 7240) and transferred under 50  μl of the <b>translation</b> <b>buffer</b> (1 × SUB-AMIX SGC), placed in the 96 -well half-area plate. The FluoroTect GreenLys in vitro Labeling System was purchased from Promega. The translation was carried out overnight and the protein products were analyzed by SDS-PAGE.|$|E
50|$|In a Harvard {{architecture}} {{or modified}} Harvard architecture, a separate virtual address space or memory access hardware may exist for instructions and data. This {{can lead to}} distinct TLBs for each access type, an Instruction <b>Translation</b> Lookaside <b>Buffer</b> (ITLB) and a Data <b>Translation</b> Lookaside <b>Buffer</b> (DTLB). Various benefits have been demonstrated with separate data and instruction TLBs.|$|R
5000|$|... #Caption: Flowchart [...] {{shows the}} working of a <b>Translation</b> Lookaside <b>Buffer.</b> For simplicity, the page fault routine is not mentioned.|$|R
40|$|Takes {{a unique}} systems {{approach}} to programming and {{architecture of the}} VAX Using the VAX as a detailed example, {{the first half of}} this book offers a complete course in assembly language programming. The second describes higher-level systems issues in computer architecture. Highlights include the VAX assembler and debugger, other modern architectures such as RISCs, multiprocessing and parallel computing, microprogramming, caches and <b>translation</b> <b>buffers,</b> and an appendix on the Berkeley UNIX assembler. <br...|$|R
40|$|This paper {{presents}} {{methods that}} {{make it possible to}} efficiently support irregular problems using data parallel languages. The approach involves the use of a portable, compiler-independent, runtime support library called CHAOS. The CHAOS runtime support library contains procedures that ffl support static and dynamic distributed array partitioning, ffl partition loop iterations and indirection arrays, ffl remap arrays from one distribution to another, and ffl carry out index <b>translation,</b> <b>buffer</b> allocation and communication schedule generation. The CHAOS runtime procedures are used by a prototype Fortran 90 D compiler as runtime support for irregular problems. This paper also presents performance results of compiler-generated and hand-parallelized versions of two stripped down applications codes. The first code is derived from an unstructured mesh computational fluid dynamics flow solver and the second is derived from the molecular dynamics code CHARMM. A method is described that make [...] ...|$|E
40|$|This paper {{reports the}} results of a study of VAX- 11 / 780 {{processor}} performance using a novel hardware monitoring technique. A micro-PC histogram monitor was built for these measurements. It keeps a count of the number of microcode cycles executed at each microcode location. Measurement experiments were performed on live timesharing workloads as well as on synthetic workloads of several types. The histogram counts allow the calculation of the frequency of various architectural events, such as the frequency of different types of opcodes and operand specifiers, as well as the frequency of some implementation-specific events, such as <b>translation</b> <b>buffer</b> misses. The measurement technique also yields the amount of processing time spent in various activities, such as ordinary microcode computation, memory management, and processor stalls of different kinds. This, paper reports in detail the amount of time the 'average'fVAX instruction spends in these activities. 1...|$|E
40|$|Modern {{processors}} don't use a {{hard wired}} mechanism to translate virtual addresses into physical addresses. Instead, software has {{to fill the}} <b>translation</b> <b>buffer</b> (TB). To achieve high performance, {{it is very important}} to find a fast algorithm. Guarded Page Tables (GPT) are known to provide a fast translation from virtual addresses into physical addresses in large, sparsy filled address spaces. This paper describes an implementation of GPTs on an Alpha 21064 microprocessor including the adaption into PALcode, a very interesting feature of all Alpha machines to implement various strategies for hardware dependent requirements. This paper describes an implementation of Guarded Page Tables as introduced in [3] and [4] on an Alpha. A similar implementation on MIPS machines can be found at [5]. 1 Guarded Page Tables In sparsy filled address spaces, many tables of an n-level page table tree are filled with only one entry and used to go on to the next level. Guarded Page Tables skip these inte [...] ...|$|E
50|$|<b>Translation</b> lookaside <b>buffer</b> (TLB) entries {{and page}} table entries in PA-RISC 1.1 and PA-RISC 2.0 support read-only, read/write, read/execute, and read/write/execute pages.|$|R
5000|$|... flushes {{of memory}} {{management}} unit caches, such as <b>translation</b> lookaside <b>buffers,</b> on other processors when memory mappings are changed by one processor; ...|$|R
5000|$|... 48-entry fully {{associative}} L1 instruction <b>translation</b> lookaside <b>buffer</b> (TLB) {{with native}} support for 4 KiB, 64 KiB, and 1 MB page sizes ...|$|R
40|$|Heterogeneous {{computing}} utilizing both CPU and FPGA requires {{access to}} data in the main memory from both devices. While a typical system relies on software executing on the CPU to orchestrate all data movements between the FPGA and the main memory, our demo presents a complementary FPGA-centric approach that allows gateware to directly access the virtual memory space {{as part of the}} executing process without involving the CPU. A caching address <b>translation</b> <b>buffer</b> was implemented alongside the user FPGA gateware to provide runtime mapping between virtual and physical memory addresses. The system was implemented on a commercial off-the-shelf FPGA add-on card to demonstrate the viability of such approach in low-cost systems. Experiment demonstrated reasonable performance improvement when compared to a typical software-centric implementation; while the number of context switches between FPGA and CPU in both kernel and user mode was significantly reduced, freeing the CPU for other concurrent user tasks. © 2013 IEEE. published_or_final_versio...|$|E
40|$|Virtualization {{has become}} much more {{important}} throughout the computer industry both to improve security and to support multiple workloads on the same hardware with effective isolation between those workloads. The most widely used chip architecture, the Intel and AMD x 86 processors, have begun to support virtualization, but the initial implementations show some limitations. This paper examines the virtualization properties of the Alpha architecture with particular emphasis on features that improve performance and security. It shows how the Alpha’s features of PALcode, address space numbers, software handling of <b>translation</b> <b>buffer</b> misses, lack of used and modified bits, and secure handling of unpredictable results all contribute to making virtualization of the Alpha particularly easy. The paper then compares the virtual architecture of the Alpha with Intel’s and AMD’s virtualization approaches for x 86. It also comments briefly on Intel’s virtualization technology for Itanium, IBM’s zSeries and pSeries hypervisors and Sun’s UltraSPARC virtualization. It particularly identifies some differences between translation buffers on x 86 and translation buffers on VAX and Alpha that can have adverse performance consequences...|$|E
40|$|Processor {{designers}} require {{estimates of}} the architectural vulnerability factor (AVF) of on-chip structures to make accurate soft error rate estimates. AVF is the fraction of faults from alpha particle and neutron strikes that result in user-visible errors. This paper shows {{how to use a}} performance model to calculate the AVF of address-based structures, using a data cache, a data <b>translation</b> <b>buffer,</b> and a store buffer as examples. We describe how to perform a detailed breakdown of lifetime components (e. g., fill-toread, read-to-evict) of bits in these structures into ACE (required for architecturally correct execution), un-ACE (unnecessary for ACE), and unknown components. This lifetime analysis produces best estimate AVFs for these three structures ’ data arrays of 6 %, 36 %, and 4 %, respectively. We then present a new technique, hammingdistance-one analysis, and show that it predicts surprisingly low best estimate AVFs of 0. 41 %, 3 %, and 7. 7 % for the structures ’ tag arrays. Finally, using our lifetime analysis framework, we show how two AVF reduction techniques [...] periodic flushing and incremental scrubbing [...] can reduce the AVF by converting ACE lifetime components into un-ACE without affecting performance significantly...|$|E
5000|$|Virtual memory - Traditional memory {{virtualization}} on {{a single}} computer, typically using the <b>translation</b> lookaside <b>buffer</b> (TLB) to translate between virtual and physical memory addresses ...|$|R
50|$|The CPU's memory {{management}} unit (MMU) stores a cache of recently used mappings from the operating system's page table. This is called the <b>translation</b> lookaside <b>buffer</b> (TLB), which is an associative cache.|$|R
5000|$|Richard Rashid et al. {{described}} a lazy <b>translation</b> lookaside <b>buffer</b> (TLB) implementation that deferred reclaiming virtual-address space until all CPUs flushed their TLB, {{which is similar}} in spirit to some RCU implementations.|$|R
40|$|The Distributed Shared Memory (DSM) {{model is}} {{designed}} to leverage the ease of programming of the shared memory paradigm, while enabling the highperformance by expressing locality as in the messagepassing model. Experience, however, has shown that DSM programming languages, such as UPC, {{may be unable to}} deliver the expected high level of performance. Initial investigations have shown that among the major reasons is the overhead of translating from the UPC memory model to the target architecture virtual addresses space, which can be very costly. Experimental measurements have shown this overhead increasing execution time by up to three orders of magnitude. Previous work has also shown that some of this overhead can be avoided by hand-tuning, which on the other hand can significantly decrease the UPC ease of use. In addition, such tuning can only improve the performance of local shared accesses but not remote shared accesses. Therefore, a new technique that resembles the Translation Look Aside Buffers (TLBs) is proposed here. This technique, which is called the Memory Model <b>Translation</b> <b>Buffer</b> (MMTB) has been implemented in the GCC-UPC compiler using two alternative strategies, full-table (FT) and reduced-table (RT). It will be shown that the MMTB strategies can lead to a performance boost of up to 700 %, enabling ease-of-programming while performing at a similar performance to hand-tuned UPC and MPI codes. 1...|$|E
30|$|Protein {{synthesis}} {{was carried}} out using Wheat Germ Protein Research Kits (WEPRO 7240 and WEPRO 7240 H) from CellFree Sciences {{as suggested by the}} manufacturer. All translation reactions were carried out in the bilayer format where total translation volume accounts for the SUB-AMIX layer. For MIDI-scale plasmid-based protein expression (1.2  ml total translation volume), 5  μl of pEU plasmid (1  μg/μl) was mixed with 10  μl of 5 × Transcription Buffer, 5  μl of 25  mM NTP mix, 0.625  μl of RNase inhibitor and 0.625  μl of SP 6 polymerase and incubated at 37  °C for 3 – 4  h with gentle shaking. Upon completion, 1  μl of the transcription mixture was loaded on the E-gel precast agarose gel (Invitrogen) to assess the mRNA integrity. Then, 50  μl of transcription reaction was mixed with 50  μl of wheat germ extract (WEPRO 7240) and 4.25  μl of 1  mg/ml creatine kinase by a pipette, and the entire mixture was then transferred {{to the bottom of the}} individual well of a standard 24 -well plate, prefilled with 1.1  ml of <b>translation</b> <b>buffer</b> (1 ×[*]SUB-AMIX SGC). To prevent evaporation, wells were sealed with Parafilm. These reactions were carried out for at least 20  h at 15  °C with no mixing at Thermomixer C from Eppendorf. At the end, the contents were gently mixed by a pipette and centrifuged at 20, 000 g for 15  min. The supernatant fraction was then buffer exchanged to TBS (50  mM Tris-HCl, pH 7.5, 150  mM NaCl) using pre-equilibrated in TBS Zeba Spin Desalting Columns (5  ml) from Thermo Fisher (this step is critical to remove DTT) and further subjected to the protein purification procedure of choice. For MAXI- and MEGA-scale plasmid-based protein expression (6 - and 24  ml translation volumes), all reagents were scaled linearly, and a 6 -well plate was used instead.|$|E
40|$|In this dissertation, we {{describe}} the DELFT-JAVA engine - a 32 -bit RISC-based architecture that provides high performance JAVA program execution. More specifically {{we describe}} a microarchitecture that accelerates JAVA execution and provide details of the DELFT-JAVA architecture for executing JAVA Virtual Machine bytecode. The basic architecture implements a Media Processor with Signal Processing capabilities. The perspective of the approach is that to maximally accelerate a compiled application, the machine language should accurately reflect the type of operations the compiler specifies. Except where JAVA Virtual Machine operations are unusually complex, we prefer to allow the compiler to optimize directly to the implementation. This is independent of any particular machine organization. The architecture is then a superset of the JAVA Virtual Machine and provides operations that are necessary for system execution (e. g., I/O, supervision, etc.). Rather than just supporting the JAVA Virtual Machine, the architecture takes a more general purpose approach in that it also {{is intended to be}} programmed from a number of additional high-level languages including C and C++. Furthermore, we introduce the concept of JAVA dynamic instruction translation, a new approach to JAVA hardware acceleration. In hardware assisted dynamic translation, JAVA Virtual Machine instructions are translated on-the-fly into the DELFT-JAVA instruction set. The hardware requirements to perform this translation are not excessive. Consequently, support for JAVA language constructs are also incorporated into the processor's Instruction Set Architecture. This technique allows application level parallelism inherent in the JAVA language to be efficiently utilized as instruction level parallelism. In addition to dynamic translation, a special Link <b>Translation</b> <b>Buffer</b> (LTB) can be used to improve the performance of dynamic linking. In addition, there are some key organization structures which we deem appropriate to provide architectural support for including: a) synchronization for multithreaded organizations, b) garbage collection, c) array bounds checking, d) real-time caches, e) multiple machines which can time-share the same datapath (e. g., the JAVA Virtual Machine and Media Processing functions), and f) vector/dsp operations. By building several models of the DELFT-JAVA engine, we were able to characterize performance metrics of kernels executing on our processor. We found that when compared to realizable stack-based machines, our techniques could improve performance by 2. 7 x. Furthermore, by converting stack-based dependencies into pipeline dependencies, we showed that out-of-order superscalar machines could remove up to 60 % of the hazards. Information Systems and Technolog...|$|E
50|$|The R8000 {{controlled}} the chip set and executed integer instructions. It contained the integer execution units, integer register file, primary caches and hardware for instruction fetch, branch prediction the <b>translation</b> lookaside <b>buffers</b> (TLBs).|$|R
50|$|Memory-level {{parallelism}} (MLP) {{is a term}} {{in computer}} architecture referring {{to the ability to}} have pending multiple memory operations, in particular cache misses or <b>translation</b> lookaside <b>buffer</b> (TLB) misses, at the same time.|$|R
50|$|The R4200 has a 32-entry <b>translation</b> lookaside <b>buffer</b> (TLB) for data, and a 4-entry TLB for instructions. A 33-bit {{physical}} address is supported. The system bus is 64 bits wide and operates at half the internal clock frequency.|$|R
