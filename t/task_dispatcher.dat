12|14|Public
50|$|ATS/360 {{was very}} {{efficient}} {{in its use}} of main storage, {{and it was not}} uncommon to support quite a few terminals in a minimum size partition or region. It was also very efficient in its use of system resources, and it had its own <b>task</b> <b>dispatcher</b> which worked seamlessly with PCP, MFT/MFT-II and MVT, for which it was originally designed, with SVS and, later, with Haas's support, with MVS.|$|E
40|$|In this paper, we {{introduce}} a novel deep learning framework, termed Purine. In Purine, a deep network is {{expressed as a}} bipartite graph (bi-graph), which is composed of interconnected operators and data tensors. With the bi-graph abstraction, networks are easily solvable with event-driven <b>task</b> <b>dispatcher.</b> We then demonstrate that different parallelism schemes over GPUs and/or CPUs on single or multiple PCs can be universally implemented by graph composition. This eases researchers from coding for various parallelization schemes, and the same dispatcher {{can be used for}} solving variant graphs. Scheduled by the <b>task</b> <b>dispatcher,</b> memory transfers are fully overlapped with other computations, which greatly reduce the communication overhead and help us achieve approximate linear acceleration. Comment: Submitted to ICLR 2015 worksho...|$|E
40|$|Providing QoS and {{performance}} guarantees to arbitrar-ily divisible loads {{has become a}} significant problem for many cluster-based research computing facilities. While {{progress is being made}} in scheduling arbitrarily divisi-ble loads, current approaches are not efficient and do not scale well. In this paper, we propose a linear al-gorithm for real-time divisible load scheduling. Unlike existing approaches, the new algorithm relaxes the tight coupling between the task admission controller and the <b>task</b> <b>dispatcher.</b> By eliminating the need to generate ex-act schedules in the admission controller, the algorithm avoids high overhead. We experimentally evaluate the new algorithm. Simulation results demonstrate that the algorithm scales well, can schedule large numbers of tasks efficiently, and performs similarly to existing approaches in terms of providing real-time guarantees. ...|$|E
30|$|Should the {{development}} proceed {{in the direction}} of the tool scenario and should human beings keep their freedom to shape, this technology could be employed as a kind of assistance system. One example for this development is the simplification of the planning activities for dispatchers in forwarding companies. The application of technologies according to the “Internet of Things” could result in the fact that the vehicle driver takes over some selected <b>tasks</b> from the <b>dispatcher.</b> Man and machine thus interact as authorized acting units that control each other reciprocally. The driver could carry out the <b>dispatcher’s</b> <b>tasks</b> directly at the customer’s or en route in his or her vehicle. The technology provides the driver with adequate aids on site (data forms, selection of driving jobs). He or she would not simply work off his or her jobs but could even intervene in the order sequence according to the particular situation. The driver could thus directly react to traffic imponderabilities or customer wishes and could shape his or her tour in an optimal way. At the same time the technology could offer support with the autonomous acquisition of new orders.|$|R
40|$|Railway {{conflict}} detection and resolution is the daily <b>task</b> faced by <b>dispatchers</b> {{and consists of}} adjusting train schedules whenever disturbances make the timetable infeasible. The main objective pursued by <b>dispatchers</b> in this <b>task</b> is the minimization of train delays, while train operating companies are also interested in other indicators of passenger dissatisfaction. The two objectives are conflicting whenever train delay reduction requires cancellation of some connected services, causing extra waiting times to transferring passengers. In fact, the infrastructure company and the train operating companies discuss on which connection to keep or drop {{in order to reach}} a compromise solution. status: publishe...|$|R
40|$|In {{support of}} the NASA Advanced Air Transportation Technologies Project, the Volpe National Transportation Systems Center has {{developed}} a methodology to perform safety risk assessments for air traffic control/air traffic management decision Support systems and concepts. Changes in controller, pilot, and/or airline <b>dispatcher</b> <b>tasks</b> that {{are affected by the}} decision support system are related to associated hazards. These hazards are then assessed either qualitatively or quantitatively in terms of likelihood of occurring and the impact if they do occur. Those items that show a potential safety hazard level increase can then have research plans developed to address those safety risks areas. An application of this methodology will he demonstrated using the AATT decision support tool Expedite Departure Path...|$|R
40|$|The work {{reported}} here provides protection against software {{failures in the}} <b>task</b> <b>dispatcher</b> of the FTMP, a particularly critical portion of the system software. Faults in other system modules and application programs can be handled by similar techniques but are not covered in this effort. Goals of the work {{reported here}} are: (1) to develop provisions in the software design that will detect and mitigate software failures in the dispatcher portion of the FTMP Executive and, (2) to propose the implementation of specific software reliability measures {{in other parts of}} the system. Beyond the specific support to the FTMP project, the work reported here represents a considerable advance in the practical application of the recovery block methodology for fault tolerant software design...|$|E
40|$|International audienceThe {{complexity}} of multiprocessor architectures for mobile multimedia applications renders their validation challenging. In addition, {{to provide the}} necessary flexibility, {{a part of the}} functionality is realized by software. Thus, a formal model has to take into account both hardware and software. In this article we report {{on the use of the}} CADP toolbox for the formal modeling and analysis of the DTD (Dynamic <b>Task</b> <b>Dispatcher),</b> a complex hardware block of an industrial hardware architecture developed by STMicroelectronics. The formal LNT model developed by an industry engineer was appropriate to discuss implementation details with the architect and enabled model-checking temporal properties expressed in MCL, which discovered a possible problem. We investigated the existence of the problem in the architect's C++ model using co-simulation of the C++ and the formal LNT models...|$|E
40|$|International audienceThe {{complexity}} of multiprocessor architectures for mobile multi-media applications renders their validation challenging. In addition, {{to provide the}} necessary flexibility, {{a part of the}} functionality is realized by software. Thus, a formal model has to take into account both hardware and software. In this paper we report on the use of LOTOS NT and CADP for the formal modeling and analysis of the DTD (Dynamic <b>Task</b> <b>Dispatcher),</b> a complex hardware block of an industrial hardware architecture developed by STMicroelectronics. Using LOTOS NT facilitated exploration of alternative design choices and increased the confidence in the DTD, by, on the one hand, automatic analysis of formal models easily understood by the architect of the DTD, and, on the other hand, co-simulation of the formal model with the implementation used for synthesis...|$|E
40|$|We {{consider}} {{a system of}} N parallel queues with identical exponential service rates and a single <b>dispatcher</b> where <b>tasks</b> arrive as a Poisson process. When a <b>task</b> arrives, the <b>dispatcher</b> always assigns it to an idle server, if there is any, and to a server with the shortest queue among d randomly selected servers otherwise (1 ≤ d ≤ N). This load balancing scheme subsumes the so-called Join-the-Idle Queue (JIQ) policy (d = 1) and the celebrated Join-the-Shortest Queue (JSQ) policy (d = N) as two crucial special cases. We develop a stochastic coupling construction to obtain the diffusion limit of the queue process in the Halfin-Whitt heavy-traffic regime, and establish {{that it does not}} depend on the value of d, implying that assigning tasks to idle servers is sufficient for diffusion level optimality...|$|R
40|$|Optimal {{alternative}} {{selection to}} address the emergency situation is critical for dispatcher group in Unattended Train Operation (UTO) to guide emergency process. It is difficult to provide the precise decision value under one criterion and to evaluate the emergency alternatives among multiple dispatchers. This paper presents a hybrid emergency decision-making method integrating fuzzy analytic hierarchy process (FAHP) described by linguistic terms with enhanced weighted ordered weighted averaging (WOWA) operator. The enhanced WOWA operator aggregates the preference matrices of multidispatcher through the constructed emergency response <b>task</b> model of <b>dispatcher</b> group in OCC. This calculation approach takes into consideration the relations of emergency tasks to derive the importance weights of dispatchers and integrates them into the ordered weighted averaging (OWA) operator weights based on a fuzzy membership relation. A case study of applying the method in an emergency of a train fire is given to demonstrate the feasibility and usefulness of the methods associated with the group multicriteria decision-making (GMCDM) theory in emergency management of UTO metro system...|$|R
40|$|Emergency dispatchers {{must make}} complex {{life or death}} {{decisions}} under extreme time pressure. Using Ecological Task Analysis (ETA), a technique normally applied to aerospace human factors problems, a new display was designed that would better assist their decision making task. The major design constraints were identified to be the beat number and priority of incidents, available units, and the spatial relationship of the those units to the incident. Using these and other less formal factors, a GUI interface was designed and an evaluation was conducted at the Richmond, CA police dispatch center. The {{results suggest that the}} GUI display may reduce training times and increase situational awareness. Emergency dispatchers must make complex life or death decisions, under extreme time pressure. In addition, they must often perform their task with partial, or potentially incorrect information. The <b>dispatchers</b> <b>task</b> is to determine what action an incident requires and assign the appropriate police unit(s) in response. The information flows in from several sources; emergency calls, normal calls, polic...|$|R
40|$|The {{complexity}} of multiprocessor architectures for mobile multimedia applications renders their validation challenging. In addition, {{to provide the}} necessary flexibility, {{a part of the}} functionality is realized by software. Thus, a formal model has to take into account both hardware and software. In this article we report {{on the use of the}} CADP toolbox for the formal modeling and analysis of the DTD (Dynamic <b>Task</b> <b>Dispatcher),</b> a complex hardware block of an industrial hardware architecture developed by STMicroelectronics. The formal LNT model developed by an industry engineer was appropriate to discuss implementation details with the architect and enabled model-checking temporal properties expressed in MCL, which discovered a possible problem. We investigated the existence of the problem in the architect’s C++ model using co-simulation of the C++ and the formal LNT models...|$|E
40|$|Skeletons {{are common}} {{patterns}} of parallelism such as farm and pipeline {{that can be}} abstracted and offered to the application programmer as programming primitives. We describe the use and implementation of skeletons in a distributed computation environment, with the Java-based system Lithium as our reference implementation. Our main contribution is optimization techniques based on an asynchronous, optimized RMI interaction mechanism, which we integrated into the macro data flow (MDF) evaluation technology of Lithium. In detail, we show three different optimizations: 1) a lookahead mechanism that allows to process multiple tasks concurrently at each single server and thereby increases the overall degree of parallelism, 2) a lazy task-binding technique that reduces interactions between remote servers and the <b>task</b> <b>dispatcher,</b> and 3) dynamic improvements based on process monitoring that optimize the collection of results and the work-load balancing. We report experimental results that demonstrate the achieved improvements due to the proposed optimizations on various testbeds, including heterogeneous environments. ...|$|E
40|$|Several {{approaches}} {{have been proposed}} {{to deal with the}} issue of load distribution, however they all have similar limitations, such as: (i) tasks are executed in an arbitrary order (which may cause large tasks to be delayed), (ii) the <b>task</b> <b>dispatcher</b> does not take into consideration the server processing capacity (which may cause a large task to be assigned to a server with low processing power) or (iii) they do not consider task deadlines (which if not met, may cause task starvation). This paper proposes an extension of LFF (Least Flow-time First) task assignment policy [9], called LFF-PRIORITY, to deal with these limitations. LFF-PRIORITY dynamically computes two priorities, namely task size and task size priorities, and put them in a priority based multi-section queue. The testing results clearly show that LFF-PRIORITY out performs existing load distribution strategies (that are based on heavy tailed distribution). The testing results also show that more than 80 % of tasks meet their task deadline under LFF-PRIORITY...|$|E
40|$|This {{research}} was conducted to organize and model a comprehensive paratransit dispatching task activity in a computer-assisted control room. The dispatching task involves continuous monitoring and interaction with archived and real-time data using a dispatch software. Extensive field observations and video recordings of dispatch operations were conducted. Then, an expert dispatcher was used to generate a skeleton decision model of the <b>dispatcher’s</b> <b>task</b> performance. Hierarchical Task Analysis (HTA) was used to further refine this model into a comprehensive HTA decision hierarchy (decision tree). To capture the complexity of multi-dispatcher operation, we extended this model to a simultaneous operation of two collaborative dispatchers in the same control room [...] a van dispatcher and a lead dispatcher. The results of this analysis have shown that HTA {{can be used to}} model such an activity with a user-defined degree of fidelity. The sequential decision tree format of the HTA also shows promise as a training tool for entry-level dispatch personnel...|$|R
40|$|We {{consider}} {{a system of}} N parallel queues with unit exponential service rates and a single <b>dispatcher</b> where <b>tasks</b> arrive as a Poisson process of rate Λ(N). When a <b>task</b> arrives, the <b>dispatcher</b> assigns it to a server with the shortest queue among d(N) ≤ N randomly selected servers. This load balancing policy {{is referred to as}} a power-of-d(N) or JSQ(d(N)) scheme, and subsumes the Join-the-Shortest Queue (JSQ) policy as a crucial special case for d(N) = N. We construct a coupling to bound the difference in the queue length processes between the JSQ policy and an arbitrary value of d(N). We use the coupling to derive the fluid limit in the regime where Λ(N) /N → Λ 0 and d(N) /√N log N → ∞ as N → ∞ corresponds to that for the JSQ policy. These results indicate that the stochastic optimality of the JSQ policy can be preserved at the fluid-level and diffusion-level while reducing the overhead by nearly a factor O(N) and O(√N), respectively. 3 page(s...|$|R
40|$|Railway {{conflict}} detection and resolution is the daily <b>task</b> faced by <b>dispatchers</b> {{and consists of}} adjusting train schedules whenever disturbances make the timetable infeasible. The main objective pursued by <b>dispatchers</b> in this <b>task</b> is the minimization of train delays, while train operating companies are also interested in other indicators of passenger dissatisfaction. The two objectives are conflicting whenever train delay reduction requires cancellation of some connected services, causing extra waiting times to transferring passengers. In fact, the infrastructure company and the train operating companies discuss on which connection to keep or drop {{in order to reach}} a compromise solution. This paper considers the bi-objective problem of minimizing train delays and missed connections in order to provide a set of feasible non-dominated schedules to support this decisional process. We use a detailed alternative graph model to ensure schedule feasibility and develop two heuristic algorithms to compute the Pareto front of non-dominated schedules. Our computational study, based on a complex and densely occupied Dutch railway network, shows that good coordination of connected train services is important to achieve real-time efficiency of railway services since the management of connections may heavily affect train punctuality. The two algorithms approximate accurately the Pareto front in a limited computation time...|$|R
40|$|Abstract: Many-task {{computing}} aims {{to bridge}} the gap between two computing paradigms, high throughput computing and high performance computing. Many-task computing denotes high-performance computations comprising multiple distinct activities, coupled via file system operations. The aggregate number of tasks, quantity of computing, and volumes of data may be extremely large. Traditional techniques found in production systems in the scientific community to support many-task computing do not scale to today's largest systems, due to issues in local resource manager scalability and granularity, efficient utilization of the raw hardware, long wait queue times, and shared/parallel file system contention and scalability. To address these limitations, we adopted a "top-down " approach to building a middleware called Falkon, to support the most demanding many-task computing applications at the largest scales. Falkon (Fast and Light-weight tasK executiON framework) integrates (1) multi-level scheduling to enable dynamic resource provisioning and minimize wait queue times, (2) a streamlined <b>task</b> <b>dispatcher</b> able to achieve orders-of-magnitude higher task dispatch rates than conventional schedulers, and (3) data diffusion which performs data caching and uses a data-aware scheduler to co-locate computational and storage resources. Micro-benchmarks have shown Falkon to achieve over 15 K+ tasks/sec throughputs, scale to hundreds of thousands of processors and to million...|$|E
40|$|Published by the IEEE Computer Society A {{solution}} paradigm {{that has}} emerged in the embedded-systems market {{over the past few}} years is the programmable system on a chip (SoC) —an integrated design that incorporates programmable cores, custom or semicustom blocks, and memories in a single chip. This paradigm allows the reuse of predesigned intellectual-property (IP) cores, thus amortizing a core’s design cost over many system generations. We have designed a new architecture that simplifies integration of heterogeneous IP for multimedia and streaming applications. The Multilevel Computing Architecture (MLCA) is a template architecture featuring multiple processing units and a top-level controller that follows well-developed superscalar principles to automatically exploit parallelism among coarse-grained units of computation or tasks. Like the sequential-programming model, the MLCA’s programming model does not require programmers to specify synchronization and data communication. We also developed a set of code transformations for porting programs to the MLCA and improving their performance. These transformations are based on standard compiler analyses and hence can be incorporated into compilers for the MLCA. Architectural overview The MLCA is a two-level hierarchical architecture. The lower level consists of multiple processing units. A PU can be a full-edged processor core (superscalar or very-longinstruction-word, for example), a digital signal processor (DSP), a field-programmable gate array (FPGA) block, or custom hardware. The upper level consists of a control processor (CP), a <b>task</b> <b>dispatcher</b> (TD), and a universal register file (URF). A dedicated interconnect links the PUs to the URF and to memory. Figure 1 a shows a block diagram of the MLCA, which bears considerable similarity to th...|$|E
40|$|The {{usefulness}} of cardiovascular measures {{as indicators of}} changes in cognitive workload has been addressed in several studies. In this paper the question is explored whether cardiovascular patterns in heart rate, blood pressure, baroreflex sensitivity and HRV that are found are consistent within and between two simulated working environments. Two studies, were performed, both with 21 participants: one in an ambulance dispatch simulation and one in a driving simulator. In the ambulance <b>dispatcher</b> <b>task</b> an initial strong increase in blood pressure {{is followed by a}} moderate on-going increase in blood pressure during the next hour of task performance. This pattern is accompanied by a strong increase in baroreflex sensitivity while heart rate decreases. In the driving simulator study, blood pressure initially increases but decreases almost to baseline level in the next hour. This pattern is accompanied by a decrease in baroreflex sensitivity, while heart rate decreases. Results of both studies are interpreted in terms of autonomic control (related to both sympathetic and para-sympathetic effects), using a simplified simulation of a baroreflex regulation model. Interpretation of the results leads {{to the conclusion that the}} cardiovascular response patterns in both tasks are a combination of an initial defensive reaction, in combination with compensatory blood pressure control. The level of compensatory blood pressure control, however, is quite different for the two tasks. This helps to understand the differences in response patterns between the two studies in this paper and may be helpful as well for understanding differences in cardiovascular response patterns in general. A substantial part of the effects observed during task performance are regulatory effects and are not always directly related to workload manipulations. Making this distinction may also contribute to the understanding of differences in cardiovascular response patterns during cognitive workload...|$|R
40|$|When {{measuring}} operator {{states the}} predictive power of cardiovascular and respiratory measures {{in relation to}} mental workload has been questioned. One of the main questions is {{to what extent do}} cardiovascular measures actually reflect mental workload. This question arises because good measures of mental workload should be sensitive to changes in mental effort alone and not to other influences or at least the changes associated with mental workload should be easy to isolate. In the case of cardiovascular measures, the physiological change brought on by the baroreflex is a compensatory control effect that can potentially overshadow changes in physiology due to mental effort and therefore reduce the usefulness of cardiovascular measures. However, this {{does not need to be}} the case. Despite the effects caused by the baroreflex differences in heart rate, heart rate variability and other cardiovascular measures associated with task related effort can still be found using short-term response patterns. The short-segment analysis approach described in this paper is based on a time-frequency method in which the spectral power of the cardiovascular measures in specified spectral bands is computed from small time segments, i. e. 30 s. To demonstrate the effectiveness of this technique two studies which made use of a simulation of an ambulance <b>dispatcher's</b> <b>task</b> are described, both with easy and difficult task conditions. A short-lasting increase in task demand was found to be reflected in short-lasting increases in heart rate and blood pressure in combination with corresponding decreases in heart rate variability and blood pressure variability. These effects were larger in easy task conditions than in hard conditions, likely due to a higher overall effort-level during the hard task conditions. However, the developed measures are still very sensitive to mental effort and if this brief segmentation approach is used cardiovascular measures show promise as good candidates for reflecting mental effort during the assessment of operator state. (C) 2012 Elsevier B. V. All rights reserved...|$|R
40|$|In current {{research}} on mental workload and task performance a large gap exists between laboratory based studies and research projects {{in real life}} working practice. Tasks conducted within a laboratory environment often lack a strong resemblance with real life working situations. This paper presents an experimental approach to minimizing this gap by designing a very flexible experimentation system with adequate hardware and software components. The first goal {{of the system is}} to design a laboratory based environment in which a broad range of computer supported daily life work can be simulated, including co-operative working situations. Moreover, several behavioral and physiological measurement and analysis techniques are supported, such as video based behavioral analysis, task related event registration, cardiovascular state analysis, determining mental workload indices as well as EEG background and ERP analysis. An important requirement for relating the different measured variables to task performance is synchronization of data sources and task parameters at varying time scales. The highest time accuracy should be at least 10 milliseconds. The present system fulfils this requirement by using software system components and libraries that allow real time experiment control and measurement. Additionally, the new system should work within a Microsoft Windows based environment, providing the possibility to use standard office software that is well known to subjects having to work in the new environment. The option to use such standard software, in combination with new (simulation) techniques for presenting more realistic tasks, results in a powerful laboratory environment in which task elements in semi-realistic tasks can be manipulated experimentally. The {{way to do this is}} by defining adequate scenarios that can be simulated. At present, is that both a simple, less realistic task has been realized (Synwork) with a high time accuracy (1 ms), as well as a more realistic simulation of an ambulance <b>dispatcher</b> <b>task</b> with lower time accuracy (10 - 100 ms). Both types of task can be seen as examples of the range of tasks to be implemented in the near future...|$|R
40|$|This study {{focuses on}} how to define and measure {{usability}} in systems used for operational train traffic control. The study is conducted as a project for the Swedish Transport Administration (Trafikverket); the authority that {{is in charge of}} the train traffic in Sweden. The train dispatchers are the ones that control the train traffic. Their job includes much decision-making and problem solving and they need to have complete control in each situation. The systems used for train dispatching therefore need to be designed to comply with human cognitive capabilities and skills, to support the users in their work and also to be well adapted to the work <b>tasks</b> of the <b>dispatchers.</b> It was therefore decided to evaluate the usability of the systems by looking at how well they support the train dispatchers when they carry out their work tasks. The analysis of the evaluation focused on finding indicators of bad usability in the interaction between the user and his/her systems. Such problems can affect the user's cognitive capabilities and result in unnecessary cognitive demands. Such issues can affect their abilities to control the systems and their work situation. An analysis of the social support in their work environment and their use of the systems was also conducted. The analysis showed that the systems used today had indicators of both good and bad usability. The usability issues that were found caused cognitive work environment problems for the users. Problems like tunnel vision, short-term memory load, orientation issues and unnecessary cognitive workload was the most distinct ones. To investigate further the specific systems used for traffic control, an evaluation instrument was developed. The purpose of the instrument is to be used by the authority to evaluate the usability in their operational traffic control systems. The evaluation of the systems' usability will give greater insight and knowledge about how it actually affects the user's work situation and cognitive capabilities. Key words: Human-computer interaction, usability, train traffic control, train dispatcher, cognitive work environment problems, psychosocial work environment, techno stress, evaluation instrument USOT...|$|R
40|$|We {{consider}} {{a system of}} N identical server pools and a single <b>dispatcher</b> where <b>tasks</b> arrive as a Poisson process of rate λ(N). Arriving tasks cannot be queued, and must immediately be {{assigned to one of}} the server pools to start execution, or discarded. The execution times are assumed to be exponentially distributed with unit mean, and do not depend on the number of other tasks receiving service. However, the experienced performance (e. g. in terms of received throughput) does degrade with an increasing number of concurrent tasks at the same server pool. The dispatcher therefore aims to evenly distribute the tasks across the various server pools. Specifically, when a <b>task</b> arrives, the <b>dispatcher</b> assigns it to the server pool with the minimum number of tasks among d(N) randomly selected server pools. This assignment strategy is called the JSQ(d(N)) scheme, as it resembles the power-of-d version of the Join-the-Shortest-Queue (JSQ) policy, and will also be referred to as such in the special case d(N) = N. We construct a stochastic coupling to bound the difference in the system occupancy processes between the JSQ policy and a scheme with an arbitrary value of d(N). We use the coupling to derive the fluid limit in case d(N) →∞ and λ(N) /N →λ as N →∞, along with the associated fixed point. The fluid limit turns out to be insensitive to the exact growth rate of d(N), and coincides with that for the JSQ policy. We further leverage the coupling to establish that the diffusion limit corresponds to that for the JSQ policy as well, as long as d(N) /√(N) (N) →∞, and characterize the common limiting diffusion process. These results indicate that the JSQ optimality can be preserved at the fluid-level and diffusion-level while reducing the overhead by nearly a factor O(N) and O(√(N) /(N)), respectively. Comment: 48 pages, 3 figures, companion paper of arXiv: 1612. 0072...|$|R

