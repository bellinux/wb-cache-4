26|10000|Public
2500|$|There {{are several}} ways of {{evaluating}} how well a hearing aid compensates for hearing loss. [...] One approach is audiometry which measures a subject's hearing levels in laboratory conditions. [...] The <b>threshold</b> <b>of</b> <b>audibility</b> for various sounds and intensities is measured {{in a variety of}} conditions. [...] Although audiometric tests may attempt to mimic real-world conditions, the patient's own every day experiences may differ. [...] An alternative approach is self-report assessment, where the patient reports their experience with the hearing aid.|$|E
5000|$|Group delay {{has some}} {{importance}} in the audio field {{and especially in the}} sound reproduction field. Many components of an audio reproduction chain, notably loudspeakers and multiway loudspeaker crossover networks, introduce group delay in the audio signal. It is therefore important to know the <b>threshold</b> <b>of</b> <b>audibility</b> of group delay with respect to frequency, especially if the audio chain is supposed to provide high fidelity reproduction. The best thresholds of audibility table has been provided by [...]|$|E
50|$|Apart from testing hearing, {{part of the}} {{function}} of audiometry is in assessing or evaluating hearing from the test results. The most commonly used assessment of hearing is {{the determination of the}} <b>threshold</b> <b>of</b> <b>audibility,</b> i.e. the level of sound required to be just audible. This level can varyfor an individual over a range of up to 5 Decibels from day to day and from determination to determination, but it provides an additional and useful tool in monitoring the potential ill effects of exposure to noise. Before carrying out a hearing test, it is important to obtain information about the person’s past medical history, not only concerning the ears but also other conditions which may have a bearing on possible hearing loss detected by an audiometric test. Hearing loss may be unilateral or bilateral, and bilateral hearing loss may not be symmetrical. The most common types of hearing loss, due to age and noise exposure, are usually bilateral and symmetrical. Wax in the ear can also cause hearing loss, so the ear should be examined to see if syringing is needed; also to determine if the eardrum has suffered any damage which may reduce the ability of sound to be transmitted to the middle ear.|$|E
40|$|Listening {{tests were}} {{conducted}} {{in order to find}} out the <b>audibility</b> <b>of</b> inharmonicity in musical sounds produced by string instruments, such as the piano or the guitar. The <b>threshold</b> <b>of</b> the <b>audibility</b> <b>of</b> inharmonicity was measured {{as a function of the}} inharmonicity coefficient at five fundamental frequencies. It was found that the detection of inharmonicity is strongly dependent on the fundamental frequency. A simple model is presented for estimating the threshold as a function of the fundamental frequency. The need to implement inharmonicity in digital sound synthesis is discussed. 1...|$|R
40|$|The {{binaural}} {{synthesis of}} acoustical environments {{is based on}} binaural room impulse responses (BRIRs) measured with a dummy head for discrete head positions and angular resolutions of typically between 1 °and 15 °. The resolution of the BRIR grid defines {{the size of the}} BRIR database as well as the duration of its measurement. To determine the minimum grid resolution required for dynamic binaural synthesis a listening test was performed. Following an adaptive 3 AFC procedure, a spatial grid of BRIR data was gradually coarsened from a maximum resolution of 1 ° / 1 ° until audible artefacts were introduced. <b>Thresholds</b> <b>of</b> <b>audibility</b> were tested for a sound source located at 0 ° / 0 ° with dynamical auralization in two rotational degrees of freedom. The datasets used were acquired in an anechoic environment and in two rooms of different size and reverberation time. Pink noise and acoustical guitar were used as stimuli. A third octave band filter bank analysis of the data sets, using a 1 dB-deviation-in-a-band criterion for the <b>audibility</b> <b>of</b> spectral differences, was in good accordance with the listening test results...|$|R
5000|$|Sets of six values {{determine}} the entire work. Pitches {{are drawn from}} a series of intervals: a falling minor tenth, rising major third, falling minor sixth, rising minor tenth, and falling major third. Expressed as justly intoned numeric ratios, these are 12/5, 4/5, 8/5, 5/12, and 5/4. Starting from 1920 Hz, near the upper <b>threshold</b> <b>of</b> pitch <b>audibility,</b> thirty-six series <b>of</b> six pitches each are projected, starting with 1920, 800, 1000, 625, 1500, and 1200. The lowest value of 66 Hz is reached at the fourth value of the twenty-second series: 203, 84, 105, 66, 158, 127 [...] All of these ratios are derived from the 5:4 major third, and the resulting timbral combinations resemble the pleasant chiming of a crystal goblet or the combination of vibraphone and glockenspiel—sounds which Stockhausen had previously employed in 1952, in his orchestral compositions Spiel and Formel, respectively [...]|$|R
40|$|In work {{comparison}} of statistical {{individual and group}} frequency dependences of a <b>threshold</b> <b>of</b> <b>audibility</b> {{on the basis of}} the equivalent scheme of a middle ear is carried out. It gave the chance to differentiate a hearing disorder and to offer a method of an objective audiometry on the basis of individual frequency dependence of a <b>threshold</b> <b>of</b> <b>audibility</b> which considerably increases reliability of diagnostics of hearing of the person. ? ?????? ????????? ????????? ?????????????? ?????????????? ? ????????? ????????? ???????????? ?????? ?????????? ?? ?????? ????????????? ????? ???????? ???. ??? ???? ??????????? ???????????????? ????????? ????? ? ?????????? ????? ??????????? ??????????? ?? ?????? ?????????????? ????????? ??????????? ?????? ??????????, ??????? ??????????? ???????? ????????????? ??????????? ????? ????????...|$|E
40|$|This study {{investigated}} the following questions: 1) What is the spectra of human heart sounds when transmitted to the listener 2 ̆ 7 s ear through amplified and acoustic stethoscopes? 2) How does the acoustic spectrum of normal heart sounds compare to the <b>threshold</b> <b>of</b> <b>audibility</b> for normal hearing sensitivity? 3) Do normal hearing listeners elect to listen to heart sounds at a higher intensity than the acoustic stethoscope is able to transmit...|$|E
40|$|Abstract: The paper {{discusses}} {{the problem of}} the detection of audible resonances. The basic psychoacoustic researches have shown that the threshold of resonance detection can be classified by resonance level and Q-factor. In this work a third criteria is introduced. It is the energy of the resonance. By analyzing the influence of resonances on the frequency response and group delay, it is shown that {{it is almost impossible to}} detect resonances that are near the <b>threshold</b> <b>of</b> <b>audibility.</b> Finally, three common techniques for resonance detection are compared: the cumulative spectral decay, the shaped sine burst decay and the transfer function pole–zero identification. In the conclusion suggestions for the use of the particular method are given...|$|E
2500|$|A more {{rigorous}} {{exploration of the}} lower limits <b>of</b> <b>audibility</b> determines that the minimum threshold at which a sound can be heard is frequency dependent. [...] By measuring this minimum intensity for testing tones of various frequencies, a frequency dependent absolute <b>threshold</b> <b>of</b> hearing (ATH) curve may be derived. [...] Typically, the ear shows a peak of sensitivity (i.e., its lowest ATH) between [...] though the threshold changes with age, with older ears showing decreased sensitivity above 2kHz.|$|R
50|$|Grossly changed phase relationships, without {{changing}} amplitudes, can be audible but the degree <b>of</b> <b>audibility</b> <b>of</b> {{the type of}} phase shifts expected from typical sound systems remains debated.|$|R
40|$|The {{purpose of}} this study was to {{investigate}} the sufficient perceptual cues used in the recognition of four voiceless fricative consonants [s, f,, f] followed by the same vowel [i:] in normal-hearing and hearing-impaired adult listeners. Subjects identified the four CV speech tokens in a closed-set response task across a range of presentation levels. Fricative syllables were either produced by a human speaker in the natural stimulus set, or generated by a computer program in the synthetic stimulus set. By comparing conditions in which the subjects were presented with equivalent degrees <b>of</b> <b>audibility</b> for individual fricatives, it was possible to isolate the factor <b>of</b> lack <b>of</b> <b>audibility</b> from that <b>of</b> loss of suprathreshold discriminability. Results indicate that (a) the frication burst portion may serve as a sufficient cue for correct recognition of voiceless fricatives by normal-hearing subjects, whereas the more intense CV transition portion, though it may not be necessary, can also assist these subjects to distinguish place information, particularly at low presentation levels; (b) hearing-impaired subjects achieved close-to-normal recognition performance when given equivalent degrees <b>of</b> <b>audibility</b> <b>of</b> the frication cue, but they obtained poorer-than-normal performance if only given equivalent degrees <b>of</b> <b>audibility</b> <b>of</b> the transition cue; (c) the difficulty that hearing-impaired subjects have in perceiving fricatives under normal circumstances may be due to two factors: the lack <b>of</b> <b>audibility</b> <b>of</b> the frication cue and the loss of discriminability of the transition cue. KEY WORDS: speech perception, fricative, hearing loss The main body of today's knowledge on fricative recognition is found in the pioneering studies of the acoustic analysis of fricatives conducted about 20 - 30 years ag...|$|R
40|$|The {{long-term}} listening {{range was}} defined as extending, at any frequency, from the <b>threshold</b> <b>of</b> <b>audibility</b> to the upper limit of the comfortable loudness range. The relationship between the aided preferred listening level and the long-term listening range was investigated by analyzing data obtained from 16 hearing impaired subjects. Results support a tentative conclusion that the aided preferred listening level {{is equal to the}} midpoint of the long-term listening range. Application of this relationship to the specification of frequency/gain function is discussed. In an earlier article, Cox and Bisset ’ reported an inves-tigation of measurements of the upper limit of the com-fortable loudness range (ULCL) for one-third octave noise bands. Their results indicated that: (1) noise band ULCLs occurred at about the same level as corresponding band...|$|E
40|$|Sound {{is one of}} the {{fundamental}} parameters monitored during the classification of work hygiene. More and more {{attention has been paid to}} the evaluation and management of noise outdoors. Frequent exposure to noise may result in hearing impairment. Exposure to a loud sound results in an acute increase of the <b>threshold</b> <b>of</b> <b>audibility,</b> especially for frequencies similar to those of the given sound. However, the hearing goes back to normal after a certain period of time. Repeated exposure to the high intensity sounds shifts the <b>threshold</b> <b>of</b> <b>audibility</b> gradually but permanently upwards. The loss of hearing gradually excludes people from regular life and forces them to compensate their disability. As a preventive measure in the working environment the employers shall provide to their employees hearing protection aids in order to eliminate such cases. The main objective of this thesis was to prove the harmful effect of noise on hearing in the working environment and to propose potential solutions. The project also refers to the efficiency of employment of hearing protection aids in a noisy working environment. This bachelor thesis deals with a survey of thresholds of audibility among workers of an engineering factory, depending on various noise conditions in the working environment. Audiometric curves of persons exposed the sound intensity exceeding 85 dB for a prolonged period of time were taken immediately after the exposure (after the working hours). The measured data were compared with reference audiograms taken after a quiet period (before the working hours). Dependence of changes in the threshold of hearing on various factors was investigated for the individual surveyed persons, while in practical terms the most important one was the dependence on the type of the employed hearing protection aids. The thesis also evaluates how the hearing loss is affected by the noise level at the workplace, method of transport to work and frequency of the sound...|$|E
40|$|Fan {{noise from}} {{personal}} computers is, for many, a constant presence. It {{would be a}} beneficial development if they were less obtrusive and hardly noticeable. With this in mind, a psychoacoustic listening test was conducted {{with the goal of}} determining the limen of detection for a tone ramping like a computer fan increasing its speed to full power. The results of this test indicate that, in the tested octave, a change rate of &# 916;Lp / &# 916;t &# 8776; 0. 17 dB/s and &# 916;f / &# 916;t &# 8776; 2. 9 Hz/s and lower are detected at approximately the same point in the ramp. An additional test was conducted as an investigation into the <b>threshold</b> <b>of</b> <b>audibility</b> for hearing the tonal component of a fan in its normal running mode where the only background noise is the computer. This threshold was found to be Lp &# 8776; 1. 5 dB louder than the background noise...|$|E
50|$|Some chord voicings {{devised by}} composers are so {{striking}} {{that they are}} instantly recognizable when heard. For example, The Unanswered Question by Charles Ives opens with strings playing a widely spaced G major chord very softly, at the limits <b>of</b> <b>audibility.</b>|$|R
5000|$|The {{spectrum}} model {{refers to}} the range <b>of</b> <b>audibility,</b> sensibility, and visibility under which people function. The model asserts that disability {{does not necessarily mean}} reduced spectrum of operations. Rather, disability is often defined according to thresholds set on a continuum of disability.|$|R
40|$|Acoustical {{engineers}} and forensic acoustical experts are sometimes {{called upon to}} render opinions on the <b>audibility</b> <b>of</b> specific sounds at a given distance. Such sounds include speech, gunfire, warning signals such as fire alarms or locomotive horns, and in certain cases, human screaming. The <b>audibility</b> <b>of</b> female screaming has been questioned in several cases, where the expert can use both analytical and demonstrative techniques in order to form an opinion. The determination <b>of</b> <b>audibility</b> may be refined in terms of detection, discrimination and identification. This paper addresses measurement and typical levels of female screams, and reports on two different audibility analyses...|$|R
40|$|The {{noise from}} {{personal}} computers is generally characterized by their fan noises. These may operate {{at a constant}} speed or have speed control based on component or ambient temperature. In domestic environments, any noise is of concern if it is attention-grabbing enough to cause annoyance. With this in mind, two listening experiments were conducted. The first test was conducted as {{an investigation into the}} <b>threshold</b> <b>of</b> <b>audibility</b> for hearing the tonal component of a fan in its normal running mode in the presence of background noise. The second test determined the limen of perception for a tone ramping in frequency and level as a fan increases its speed. Surprisingly, the results indicate that, in the tested octave, reduced ramp rates decreased the threshold of perception. The experiments further show the limen of perception of the tones to be the same for slowly ramped and stationary tones, and response times seem relatively shorter for lower ramp rates...|$|E
40|$|State {{of the art}} audio coders {{exploit the}} {{redundancy}} in audio signals by shaping their quantization noise below the signal's masking curve, which is a signal-dependent <b>threshold</b> <b>of</b> <b>audibility.</b> This framework can be extended to the context of data hiding, where the data {{play the role of}} noise. To minimize audio distortion the data power should be closely adapted to the time-varying masking curve; each power switch, however, reduces the net throughput via its associated side information. This tradeoff can be cast in a rate/distortion framework: the optimal sequence of power levels and the optimal sequence of power switchpoints is found by minimizing a Lagrange cost functional relating perceptual audio distortion to throughput, and is implemented as a linear-time trellis search. For 16 -bit, 44. 1 KHz PCM stereo signals, a net throughput of the order of 30 kbits/sec can usually be achieved at no perceptual cost in an algorithmically efficient way. Keywords: Steganography, data hiding, rate [...] ...|$|E
40|$|Abstract Elevation of the <b>threshold</b> <b>of</b> <b>audibility</b> {{occurs in}} hearing-impaired people, and these {{individuals}} have an expanded auditory filter (Glasberg and Moore, 1986). Threshold elevation {{is assumed to}} occur due {{to an increase in}} frequency components that pass the auditory filter; an assumption known as the “power spectrum model ” of masking (Patterson and Moore, 1986). Therefore, we attempted here to remove from the speech signal the frequency components that are not related to speech perception, but are instead related to threshold elevation. We calculated the masking pattern using the spreading function (Painter and Spanias, 1997), and processed monosyllabic speech samples using nine kinds of masking patterns. Both normal-hearing and hearing-impaired subjects evaluated the intelligibility and sound quality of the original and processed monosyllables. For hearing-impaired subjects, the intelligibility of a small number of certain processed monosyllables increased, but sound quality did not improve. For normal-hearing subjects, speech intelligibility decreased as the masking pattern expanded, and application of the proposed method showed no significant improvement in sound quality...|$|E
5000|$|The {{lower limit}} <b>of</b> <b>audibility</b> {{is defined as}} SPL of , but the upper limit is not as clearly defined. While [...] ( [...] or [...] ) is the largest {{pressure}} variation an undistorted sound wave can have in Earth's atmosphere, larger sound waves can be present in other atmospheres or other media such as under water, or through the Earth.|$|R
50|$|An {{additional}} effect is also important. As far as returning a wave to the ground, {{the velocity of}} {{the wind in the}} direction of propagation can be added to the velocity relative to the air. Since the temperature maximum is indeed about equal to the ground temperature, a wind in the direction of propagation will encourage return to the ground, while a contrary wind will oppose it. It was, indeed, found that in the winter, when the stratospheric winds were westerly in Europe, there was a zone <b>of</b> anomalous <b>audibility</b> to the east, but none to the west. In the summer, when the winds were reversed, the zone <b>of</b> <b>audibility</b> was moved to the west. On occasion, a second zone of silence and a second zone <b>of</b> anomalous <b>audibility</b> were observed, the sound making a double skip. Surface winds will have no strong effect, except in the launching of the wave.|$|R
40|$|Abstract [...] Although most {{clinical}} tests {{focus on}} how much a particular hearing aid improves speech audibility under controlled conditions, {{it is unclear how}} these measures relate to hearing aid effectiveness, or the benefit perceived by the patient under everyday conditions. In this study, the relationship between audibility and hearing aid effectiveness was examined in a cohort of patients who obtained hearing aids through the Veteran's Administration. The measure <b>of</b> <b>audibility</b> was the Articulation Index, a common index <b>of</b> speech <b>audibility.</b> Measures <b>of</b> effectiveness included two hearing-specific surveys and self-reported ratings of global satisfaction and hearing aid use adherence. Results indicated that there were no systematic relationships between measurements <b>of</b> improved <b>audibility</b> and patient ratings of communication ability. Additionally, improved audibility was not related to overall satisfaction with the amplification characteristics of the hearing aid (fitting). However, improved audibility is related to hearing aid use adherence, with patients who achieve better audibility reporting that they use their hearing aids more frequently...|$|R
40|$|Abstract:- Normally, {{the level}} of {{audibility}} is investigated {{by means of the}} Evoked Potentials. These patterns are examined by two independent observers in order to define their features. In particular, the threshold value is obtained by calculating, for each ear, the average of the lowest intensity at which the response was revealed and the highest intensity at which the response disappeared. The aim of the work is to objective the determination of <b>threshold</b> <b>of</b> <b>audibility</b> of auditory Evoked Potentials response and their classification in terms of reliability based on the multiresolution analysis performed by wavelets. Actually the analysis performed by wavelet represents an advanced technique of windowing. It concurs to use a long interval in the case the information must be excreted from detailed low frequency signal. A wavelet is, like suggests the name, a small wave. Many physical phenomena show a structure like wavelet. From a methodological point of view, the wavelet technique provides a multiscale analysis of the signal as a sum of orthogonal signals corresponding to different time scales hierarchically organized...|$|E
40|$|The {{establishment}} of welfare measures for preschool children with speech impediments caused by hearing disorders {{has now become}} one of the most important of social questions in this country. In order to effect an early and timely discovery of preschool children with such physical handicaps, there is no choice for it but to resort to child audiometry. Getting hint from the fact that little children are found of playing with the toy telephone, the author has contrived a new apparatus for their audiome-tric examination, putting some improvements into the toy telephone set, and studied on clinical application of this apparatus. The objects were 25 normal adults, 100 normed children, 5 or 6 year old, and 10 children hard of hearing. The method employed in this study consisted of the comparative study on results of hearing test for normal adult through standard audiometer and those obtained through new apparatus, examination of liminal <b>threshold</b> <b>of</b> <b>audibility</b> and auditory responses through hearing test for normal preschool children and experimental application of the apparatus to hearin...|$|E
40|$|Normally, {{the level}} of {{audibility}} is investigated {{by means of the}} Evoked Potentials. In this work we illustrate the use of the Discrete Wavelet Transform for the exploration of observed signals. The results point to validate the decomposition of Evoked Potentials by wavelet analysis in order to allow to us a good identification of the level in auditory sensitivity of chinchillas. The aim of the work is to objective the determination of <b>threshold</b> <b>of</b> <b>audibility</b> of auditory Evoked Potentials response and their classification in terms of reliability based on the multiresolution analysis performed by wavelets. Usually, the Evoked Potentials are examined by two independent observers in order to define their features. In particular, the threshold value is obtained by calculating, for each ear, the average of the lowest intensity at which the response was revealed and the highest intensity at which the response disappeared. The use of wavelets for statistical purposes is still in its infancy, and it will be some years before their genuine practical advantages and disadvantages are understood properly. In particular the statistical ideas presented in this paper are clearly in need of further development but the results so far are extremely promising...|$|E
5000|$|In 1999 Koistinen {{designed}} and built the first solid body electric kantele. A 39-string instrument supplied with 2 microphone systems, contact and magnetic, has opened an entirely new perspective of the kantele. The problem <b>of</b> <b>audibility</b> was now solved and the instrument could be incorporated in a band. Koistinen Electric 1 was featured in Finnish Design Yearbook 2006 along with the products by Marimekko and Iittala.|$|R
40|$|The {{article will}} be {{available}} in SOAR after six month embargo (October 2017.) Read it at the publisher's website at: [URL] :The House of the Seven Gables" Nathaniel Hawthorne employs a soundscape particularly attuned to the modern dissonances and spiritual soundings of antebellum America. His novel interrogates the impact of these auditory-acoustic structures on constructions of the self, ultimately revealing the politics <b>of</b> <b>audibility</b> emerging in the nineteenth century. 2017 - 10 - 0...|$|R
40|$|Timing jitter {{in digital}} audio {{equipment}} can subtley degrade the audio quality or even cause data transmission failure. This paper examines the jitter performance requirements for digital audio {{equipment in the}} context <b>of</b> the <b>audibility</b> <b>of</b> sampling jitter modulation effects and the digital audio interface specification. It concludes by presenting techniques for the measurement of jitter performance. 1...|$|R
40|$|Background: Computerized {{analysis}} of breath sounds {{has relied on}} human auditory perception as the reference standard for identifying crackles. In this study, we tested the human audibility of crackles by superimposing artificial clicks on recorded breath sounds and having physicians listen to the recordings {{to see if they}} could identify the crackles. Objectives: To establish the audibility of simulated crackles introduced in breath sounds of different intensity, to study the effects of crackle characteristics on their audibility, and to investigate crackle detection within and between observers. Methods: Fine, medium, and coarse crackles with large and small amplitude were synthesized by computer software. Waveform parameters were based on published characteristics of lung sound crackles. The amplitude for small crackles was defined as just above the <b>threshold</b> <b>of</b> <b>audibility</b> for simulated crackles inserted in sound recorded during breath hold. Simulated crackles were then superimposed on breath sounds recorded at 0 L/s (breath hold), 1 L/s, and 2 L/s airflow. Five physicians listened during playback on two separate occasions to determine if crackles could be heard and to calculate the interobserver and intraobserver variations. Results: Failed detection of crackles was significantly more common in the following conditions...|$|E
40|$|Spectral masking is {{when the}} <b>threshold</b> <b>of</b> <b>audibility</b> for one sound is raised by the simul-taneous {{presence}} of another sound. In multitrack music production, this results in less ability to fully hear and distinguish the sound sources in the mix. We design a simplified measure of masking based on best practices in sound engineering. We implement both off-line and real-time, low latency autonomous multitrack equalization systems to reduce masking in multitrack audio. We perform objective measurement of the spectral masking in the resultant mixes and conduct a listening test for subjective comparison between the mix results of different imple-mentations of our system, a raw mix, and manual mixes made by an amateur and a professional mix engineer. The results show that autonomous systems reduce both the perceived masking and objective spectral masking and improve {{the overall quality of}} the mix. We show that our offline semi-autonomous system is capable of improving the raw mix better than an amateur and close to a professional mix by simply controlling one user parameter. Our results also suggest that existing objective measures of masking are ill-suited for quantifying perceived masking in multitrack musical audio. ...|$|E
40|$|Head-related {{transfer}} functions (HRTFs) incorporate fundamental cues {{required for}} human spatial hearing {{and are often}} applied to auralize results obtained from room acoustic simulations. HRTFs are typically available for various directions of sound incidence and a fixed head-above-torso orientation (HATO). If-in interactive auralizations-HRTFs are exchanged according to the head rotations of a listener, the auralization result most often corresponds to a listener turning head and torso simultaneously, while-in reality-listeners usually turn their head independently above a fixed torso. In the present study, we show that accounting for HATO produces clearly audible differences, thereby suggesting the relevance of correct HATO when aiming at perceptually transparent binaural synthesis. Furthermore, we addressed the efficient representation of variable HATO in interactive acoustic simulations using spatial interpolation. Hereby, we evaluated two different approaches: interpolating between HRTFs with identical torso-to-source but different head-to-source orientations (head interpolation) and interpolating between HRTFs with the same head-to-source but different torso-to-source orientations (torso interpolation). Torso interpolation {{turned out to be}} more robust against increasing interpolation step width. In this case the median <b>threshold</b> <b>of</b> <b>audibility</b> for the head-above-torso resolution was about 25 degrees, whereas with head interpolation the threshold was about 10 degrees. Additionally, we tested a non-interpolation approach (nearest neighbor) as a suitable means for mobile applications with limited computational capacities...|$|E
60|$|The joke pleased Symons. He laughed {{within a}} sixteenth of a note <b>of</b> the <b>audibility</b> {{permitted}} {{by the laws}} governing employees.|$|R
40|$|This article {{investigated}} {{the relationship between}} age at onset of canonical babbling and <b>audibility</b> <b>of</b> amplified speech in children with hearing impairment. Thirteen children with severe–profound hearing impairment and two children with normal hearing participated in a longitudinal investigation of vocalization development. A nonconcurrent multiple baseline design was used to analyze vocalization recordings obtained during two phases (hearing aid [HA] and cochlear implant [CI]). Audibility during HA and CI use was calculated using the Speech Intelligibility Index (SII). Earlier ages of canonical babble onset were related to greater <b>audibility</b> <b>of</b> the speech signal during HA use. Children who developed canonical babble had an SII of. 35 or greater. SII was a statistically significant predictor of age of onset of canonical babble. Results support {{the concept of an}} “essential” level <b>of</b> <b>audibility</b> for onset <b>of</b> canonical babble. Findings are discussed relative to their methodological and clinical implications regarding treatment decision making...|$|R
40|$|The effects <b>of</b> <b>audibility</b> and age on masking for {{sentences}} in continuous and interrupted noise {{were examined in}} listeners with real and simulated hearing loss. The absolute <b>thresholds</b> <b>of</b> each of ten listeners with sensorineural hearing loss were simulated in normal-hearing listeners through a combination <b>of</b> spectrally-shaped <b>threshold</b> noise and multi-band expansion for octave bands with center frequencies from 0. 25 – 8 kHz. Each individual hearing loss was simulated in two groups of three normal-hearing listeners (an age-matched and a non-age-matched group). The speech-to-noise ratio (S∕N) for 50 %-correct identification of hearing in noise test (HINT) sentences was measured in backgrounds of continuous and temporally-modulated (10 Hz square-wave) noise at two overall levels for unprocessed speech and for speech that was amplified with the NAL-RP prescription. The S∕N in both continuous and interrupted noise of the hearing-impaired listeners was relatively well-simulated in both groups of normal-hearing listeners. Thus, release from masking (the difference in S∕N obtained in continuous versus interrupted noise) appears to be determined primarily by audibility. Minimal age effects were observed in this small sample. Observed values of masking release were compared to predictions derived from intelligibility curves generated using the extended speech intelligibility index (ESII) [Rhebergen et al. (2006). J. Acoust. Soc. Am. 120, 3988 – 3997]...|$|R
