1008|592|Public
25|$|In {{areas of}} {{language}} modeling, there are {{limitations on the}} applicability of any language model as the statistics for different types of text will be different. When a language technology application is put into use (applied to a new text type), it is not certain that the language model will fare {{in the same way}} as how it would when applied to the <b>training</b> <b>corpus.</b> It is found that there are substantial variations in model performance when the <b>training</b> <b>corpus</b> changes. This lack of theory types limits the assessment of the usefulness of language-modeling work.|$|E
2500|$|Microsoft's Bing Translator {{attempts}} to translate Klingon from {{and to other}} languages. It can {{do a good job}} with individual words, and with phrases included in its <b>training</b> <b>corpus,</b> but it is not well tuned for Klingon's system of prefixes and suffixes. For example, DaHaDnIS [...] "You must study it" [...] is rendered instead as [...] "They Must Study." ...|$|E
2500|$|... the {{possible}} combinations are huge: 27 letters if you include the final forms × 9 niqqudim (more {{if we consider}} biblical niqqud) × cantillation marks. This means for an algorithm based on classification (such as Jochre), there are far too many classes, and it’s virtually impossible to get sufficient representation in an annotated <b>training</b> <b>corpus.</b> It {{would be better to}} imagine a two-pass algorithm: the first pass recognizes the letter, and the second pass recognizes the diacritics (niqqud + cantillation). However, this would require development in Jochre – it’s hard to guess how much without analyzing further. Note that Yiddish doesn’t suffer from the same difficulty, since there is very little niqqud used, and only in certain fixed places (e.g. komets aleph, etc.).|$|E
40|$|POS tagging {{is used as}} {{the first}} step in many NLP workflows, {{although}} the accuracy of tag assignment frequently goes unchecked. We hypothesize that changing the <b>training</b> <b>corpora</b> for a parser will affect its POS tagging of a target corpus. To this end we train the Charniak-Lease parser on the WSJ corpus and two biomedical corpora and evaluate its output to MedPost, a POS tagger with a reported 97 % accuracy on biomedical text. Our findings indicate that using biomedical <b>training</b> <b>corpora</b> significantly improves performance, but that minor differences in the biomedical <b>training</b> <b>corpora</b> {{have a significant effect on}} the correctness of POS tagging. Specifically, the tagging of hyphenated words and verbs was affected. This work suggests that the choice of <b>training</b> <b>corpora</b> is crucial to domain targeted NLP analysis. 1...|$|R
3000|$|... of all video frames in poet-verses <b>train</b> <b>corpus</b> and {{illustrated}} its variations along the principal eigenvector [...]...|$|R
5000|$|The {{benefits}} {{obtained for}} translation between Western European languages are {{not representative of}} results for other language pairs, owing to smaller <b>training</b> <b>corpora</b> and greater grammatical differences.|$|R
50|$|Compilation by Nuance-specific {{criteria}} {{turns the}} grammar into speech recognition packages. The final step uses the <b>training</b> <b>corpus</b> again for statistical tuning {{of the language}} model.|$|E
50|$|In {{areas of}} {{language}} modeling, there are {{limitations on the}} applicability of any language model as the statistics for different types of text will be different. When a language technology application is put into use (applied to a new text type), it is not certain that the language model will fare {{in the same way}} as how it would when applied to the <b>training</b> <b>corpus.</b> It is found that there are substantial variations in model performance when the <b>training</b> <b>corpus</b> changes. This lack of theory types limits the assessment of the usefulness of language-modeling work.|$|E
5000|$|Stops with an {{informative}} message {{if any of}} the phases of training (language model building, recaser <b>training,</b> <b>corpus</b> training, memory-mapping, tuning or training test) doesn’t produce the expected results; ...|$|E
40|$|Abstract- We {{propose a}} simple {{approach}} for Chinese syntactic parsing postprocess in this paper. It uses verb subcategorization syntactic mode to match n-best candidate parsing trees outputed from baseline parser system. We extract various features of verb subcategorization from <b>train</b> <b>corpora.</b> And use those features of verb subcategorization extracted from <b>train</b> <b>corpus</b> to rerank the n-best list via {{a similar pattern}} matching approach, and with the rule-based method, but no use statistic information. We called this method as rule-based reranking. The result shows our approach reaches a good performance...|$|R
40|$|Statistical machine {{translation}} {{relies heavily on}} available parallel corpora, but SMT {{may not have the}} ability or intelligence to make full use of the training set. Instead of collecting more and more parallel <b>training</b> <b>corpora,</b> this paper aims to improve SMT performance by exploiting the full potential of existing parallel corpora. We first identify literally translated sentence pairs via lexical and grammatical compatibility, and then use these data to train SMT models. One experiment indicates that larger <b>training</b> <b>corpora</b> do not always lead to higher decoding performance when the added dat...|$|R
40|$|This paper {{describes}} a referential semantic language model that achievesaccuraterecognitioninuser-defineddomainswithnoavailable domain-specific <b>training</b> <b>corpora.</b> This model is interesting in that, unlike similar recent systems, it exploits context dynamically, usingincrementalprocessingandlimitedstackmemoryofanHMMlike timeseries modeltoconstrain search...|$|R
50|$|The {{specialisation}} {{uses the}} Explanation-based learning algorithm {{to create a}} treebank from the <b>training</b> <b>corpus.</b> These examples are divided into sets of subtrees by using domain- and grammar-specific rules (also known as operationality criteria in Machine Translation).|$|E
50|$|This {{approach}} involves using {{statistical data}} to generate lexical and syntactic rules.The input is then processed with these rules {{as if it}} were a rule-based translator. This approach attempts to avoid the difficult and time-consuming task of creating a set of comprehensive, fine-grained linguistic rules by extracting those rules from the <b>training</b> <b>corpus.</b> This approach still suffers from many problems of normal statistical machine translation, namely that the accuracy of the translation will depend heavily on the similarity of the input text to the text of the <b>training</b> <b>corpus.</b> As a result, this technique has had the most success in domain-specific applications, and has the same difficulties with domain adaptation as many statistical machine translation systems.|$|E
5000|$|Microsoft's Bing Translator {{attempts}} to translate Klingon from {{and to other}} languages. It can {{do a good job}} with individual words, and with phrases included in its <b>training</b> <b>corpus,</b> but it is not well tuned for Klingon's system of prefixes and suffixes. For example, [...] "You must study it" [...] is rendered instead as [...] "They Must Study." ...|$|E
30|$|This {{process is}} {{achieved}} offline, involving potentially heavy process {{based on the}} analysis of the <b>train</b> <b>corpus.</b> It aims to optimize the term-detector efficency, that will be critical during the phase of speech stream scanning.|$|R
40|$|We present {{techniques}} for improving domain-specific translation quality {{with a relatively}} high OOV ratio on test data sets. The key idea is to maximize the vocabulary coverage without degrading the translation quality. We maximize vocabulary coverage by segmenting a word into a sequence of morphemes, prefix*-stem-suffix* and by adding {{a large amount of}} out-of-domain <b>training</b> <b>corpora.</b> To preserve the domain-specific meaning of vocabularies occurring in both domain-specific and out-of-domain <b>training</b> <b>corpora,</b> we assign a higher weight to the domain-specific corpus than to the out-of-domain corpora. IBM Arabic-to-English spoken language translation systems using these techniques have demonstrated the best performances in the Open Data Track of th...|$|R
40|$|The {{annotation}} or {{extraction of}} temporal information from text documents {{is becoming increasingly}} important in many natural language processing applications such as text summarization, information retrieval, question answering, etc [...] This paper presents an original method for easy recognition of temporal expressions in text documents. The method creates semantically classified temporal patterns, using word co-occurrences obtained from <b>training</b> <b>corpora</b> and a pre-defined seed keywords set, derived from the used language temporal references. A participation on a Portuguese named entity evaluation contest showed promising effectiveness and efficiency results. This approach {{can be adapted to}} recognize other type of expressions or languages, within other contexts, by defining the suitable word sets and <b>training</b> <b>corpora.</b> FC...|$|R
50|$|CMUdict {{provides}} a mapping orthopraphic/phonetic for English words in their North American pronunciations. It {{is commonly used}} to generate representations for speech recognition (ASR), e.g. the CMU Sphinx system, and speech synthesis (TTS), e.g. the Festival system. CMUdict {{can be used as}} a <b>training</b> <b>corpus</b> for building statistical grapheme-to-phoneme (g2p) models that will generate pronunciations for words not yet included in the dictionary.|$|E
5000|$|A common {{example that}} {{illustrates}} the concept behind {{this method is}} {{the frequency of the}} bigram [...] "San Francisco". If it appears several times in a <b>training</b> <b>corpus,</b> the frequency of the unigram [...] "Francisco" [...] will also be high. Relying on only the unigram frequency to predict the frequencies of n-grams leads to skewed results; however, Kneser-Ney smoothing corrects this by considering the frequency of the unigram in relation to possible words preceding it.|$|E
50|$|The {{bootstrapping}} approach {{starts from}} {{a small amount of}} seed data for each word: either manually tagged training examples or a small number of surefire decision rules (e.g., 'play' in the context of 'bass' almost always indicates the musical instrument). The seeds are used to train an initial classifier, using any supervised method. This classifier is then used on the untagged portion of the corpus to extract a larger training set, in which only the most confident classifications are included. The process repeats, each new classifier being trained on a successively larger <b>training</b> <b>corpus,</b> until the whole corpus is consumed, or until a given maximum number of iterations is reached.|$|E
5000|$|Extraction of {{specific}} or general sub-corpora following particular criteria (subject, author, year / period of publication, source, etc.), {{which could be}} used as <b>training</b> <b>corpora</b> for a number of applications - grammatical and semantic tagging, among others, as well as for other research purposes.|$|R
40|$|Banko and Brill (2001) {{suggested}} {{that the development of}} very large <b>training</b> <b>corpora</b> may be more effective for progress in empirical Natural Language Processing than improving methods that use existing smaller <b>training</b> <b>corpora.</b> This work tests their claim by exploring whether a very large corpus can eliminate the sparseness problems associated with estimating unigram probabilities. We do this by empirically investigating the convergence behaviour of unigram probability estimates on a one billion word corpus. When using one billion words, as expected, we do find that many of our estimates do converge to their eventual value. However, we also find that for some words, no such convergence occurs. This leads us to conclude that simply relying upon large corpora is not in itself sufficient: we must pay attention to the statistical modelling as well. ...|$|R
40|$|Ensemble {{methods are}} {{state of the}} art for many NLP tasks. Recent work by Banko and Brill (2001) {{suggests}} that this would not necessarily be true if very large <b>training</b> <b>corpora</b> were available. However, their results are limited by the simplicity of their evaluation task and individual classifiers. Our wor...|$|R
5000|$|Chen Changxing (陳長興 Chén Chángxīng, Ch'en Chang-hsing, 1771-1853), 14th {{generation}} Chen Village martial artist, synthesized Chen Wangting's open fist <b>training</b> <b>corpus</b> {{into two}} routines {{that came to}} be known as [...] "Old Frame" [...] (老架; lao jia). Those two routines are named individually as the First Form (Yilu; 一路) and the Second Form (Erlu; 二路, more commonly known as the Cannon Fist 炮捶). Chen Changxing, contrary to Chen family tradition, also took the first recorded non-family member as a disciple, Yang Luchan (1799-1871), who went on to popularize the art throughout China, but as his own family tradition known as Yang-style t'ai chi ch'uan. The Chen family system was only taught within the Chen village region until 1928.|$|E
5000|$|Shallow {{approaches}} don't try {{to understand}} the text. They just consider the surrounding words, using information such as [...] "if bass has words sea or fishing nearby, it probably is in the fish sense; if bass has the words music or song nearby, it is probably in the music sense." [...] These rules can be automatically derived by the computer, using a <b>training</b> <b>corpus</b> of words tagged with their word senses. This approach, while theoretically not as powerful as deep approaches, gives superior results in practice, due to the computer's limited world knowledge. However, it can be confused by sentences like The dogs bark at the tree which contains the word bark near both tree and dogs.|$|E
5000|$|... the {{possible}} combinations are huge: 27 letters if you include the final forms × 9 niqqudim (more {{if we consider}} biblical niqqud) × cantillation marks. This means for an algorithm based on classification (such as Jochre), there are far too many classes, and it’s virtually impossible to get sufficient representation in an annotated <b>training</b> <b>corpus.</b> It {{would be better to}} imagine a two-pass algorithm: the first pass recognizes the letter, and the second pass recognizes the diacritics (niqqud + cantillation). However, this would require development in Jochre - it’s hard to guess how much without analyzing further. Note that Yiddish doesn’t suffer from the same difficulty, since there is very little niqqud used, and only in certain fixed places (e.g. komets aleph, etc.).|$|E
5000|$|Undergraduate Pilot <b>Training,</b> NAS <b>Corpus</b> Christi, Texas, March 1995 - September 1995 ...|$|R
25|$|To {{choose a}} {{value for n}} in an n-gram model, it is {{necessary}} to find the right trade off between the stability of the estimate against its appropriateness. This means that trigram (i.e. triplets of words) is a common choice with large <b>training</b> <b>corpora</b> (millions of words), whereas a bigram is often used with smaller ones.|$|R
40|$|Investigations of how {{to detect}} {{deception}} in speech have lagged behind research in other types of speaker state, {{largely due to the}} lack of cleanly recorded <b>training</b> <b>corpora</b> that adequately represent the phenomenon and for which ground truth is known. We survey the current state of deceptive speech research and discuss problems and possibilities for the future...|$|R
50|$|Web content mining is {{differentiated}} {{from two}} different points of view: Information Retrieval View and Database View. summarized the research works done for unstructured data and semi-structured data from information retrieval view. It shows {{that most of the}} researches use bag of words, which is based on the statistics about single words in isolation, to represent unstructured text and take single word found in the <b>training</b> <b>corpus</b> as features. For the semi-structured data, all the works utilize the HTML structures inside the documents and some utilized the hyperlink structure between the documents for document representation. As for the database view, in order to have the better information management and querying on the web, the mining always tries to infer the structure of the web site to transform a web site to become a database.|$|E
5000|$|Disambiguation {{requires}} two strict inputs: {{a dictionary}} {{to specify the}} senses which are to be disambiguated and a corpus of language data to be disambiguated (in some methods, a <b>training</b> <b>corpus</b> of language examples is also required). WSD task has two variants: [...] "lexical sample" [...] and [...] "all words" [...] task. The former comprises disambiguating the occurrences of {{a small sample of}} target words which were previously selected, while in the latter all the words in a piece of running text need to be disambiguated. The latter is deemed a more realistic form of evaluation, but the corpus is more expensive to produce because human annotators have to read the definitions for each word in the sequence every time they need to make a tagging judgement, rather than once for a block of instances for the same target word.|$|E
40|$|How {{to utilize}} as much {{information}} as possible from the <b>training</b> <b>corpus</b> to adapt a segmentation system towards a segmentation standard has been a critical issue. Kit et al. (2002) and Kit et al. (2003) attempt to integrate case-based learning with statistical models (e. g., n-gram) by extracting transformation rules from the <b>training</b> <b>corpus</b> for disambiguation via error correction; Gao et al. (2004) adopt a similar strategy for adaptive segmentation, with transformation templates (instead of case-based rules) to modify word boundaries (instead of individual words). The basic idea of example-based segmentation is very simple: existing pre-segmented strings in <b>training</b> <b>corpus</b> provide reliable examples for segmentin...|$|E
50|$|To {{choose a}} {{value for n}} in an n-gram model, it is {{necessary}} to find the right trade off between the stability of the estimate against its appropriateness. This means that trigram (i.e. triplets of words) is a common choice with large <b>training</b> <b>corpora</b> (millions of words), whereas a bigram is often used with smaller ones.|$|R
5000|$|T-34A Pilot Instructor <b>Training,</b> NS <b>Corpus</b> Christi, Texas, June 2000 - December 2000 ...|$|R
40|$|Abstract. The article {{describes}} a prototype system aimed at monitor-ing attitudes toward any social group. The approach involves web mining and content analysis based on Rectitude Gain category from the Laswell dictionary of political values, extended into shallow predicate rules. The system requires no lexical sentiment resources and no <b>training</b> <b>corpora.</b> It has been designed, implemented and tested in Polish...|$|R
