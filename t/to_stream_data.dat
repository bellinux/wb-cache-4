37|10000|Public
5|$|The PS3 {{client was}} {{developed}} in a collaborative effort between Sony and the Pande lab and was first released as a standalone client on March23, 2007. Its release made Folding@home the first distributed computing project to use PS3s. On September18 of the following year, the PS3 client became a channel of Life with PlayStation on its launch. In the types of calculations it can perform, {{at the time of}} its introduction, the client fit in between a CPU's flexibility and a GPU's speed. However, unlike CPUs and GPUs, users were unable to perform other activities on their PS3 while running Folding@home. The PS3's uniform console environment made technical support easier and made Folding@home more user friendly. The PS3 also has the ability <b>to</b> <b>stream</b> <b>data</b> quickly to its GPU, which was used for real-time atomic-level visualizing of the current protein dynamics.|$|E
25|$|Mobile device {{applications}} allow mobile {{devices such}} as cell phones and tablets to display and manipulate the OBD-II data accessed via USB adaptor cables, bluetooth or WiFi adapters plugged into the car's OBD II connector. A number of new devices allow the vehicle's OBD port <b>to</b> <b>stream</b> <b>data</b> directly to the Internet via a cellular connection.|$|E
50|$|Lossy formats {{are often}} used for the {{distribution}} of streaming audio or interactive applications (such as the coding of speech for digital transmission in cell phone networks). In such applications, the data must be decompressed as the data flows, rather than after the entire data stream has been transmitted. Not all audio codecs {{can be used for}} streaming applications, and for such applications a codec designed <b>to</b> <b>stream</b> <b>data</b> effectively will usually be chosen.|$|E
3000|$|... titan {{is geared}} <b>to</b> <b>streaming</b> <b>data</b> {{processing}} and machine learning, which are typically used to realize activity recognition service graphs {{to be run}} within the network on and around the body. Custom services can be downloaded to realize the core logic of Pervasive Apps.|$|R
50|$|All MUTE {{compatible}} clients use RSA encryption {{to exchange}} keys, and AES (128 bits) <b>to</b> encrypt <b>stream</b> <b>data.</b>|$|R
40|$|Abstract. In {{this work}} we {{describe}} a high-performance stream-oriented distributed database manager and query processor under development that allows efficient execution of database queries <b>to</b> <b>streamed</b> <b>data</b> involving numerical and other data. Very high performance is attained by utilizing many object-relational main-memory database engines running on PCs and connected through the GRID. ...|$|R
5000|$|We {{can block}} the loops again, {{again for the}} level-2 cache sizes. With {{a total of three}} levels of {{blocking}} (for the register file, for the L1 cache, and for the L2 cache), the code will minimize the required bandwidth at each level of the memory hierarchy. Unfortunately, the extra levels of blocking will incur still more loop overhead, which for some problem sizes on some hardware may be more time consuming than any shortcomings in the hardware's ability <b>to</b> <b>stream</b> <b>data</b> from the L2 cache.|$|E
50|$|While drives {{are burning}} DVD+R, DVD+RW and all Blu-ray formats, {{they do not}} require any such error {{correcting}} recovery as the recorder is able to place the new data exactly {{on the end of}} the suspended write effectively producing a continuous track (this is what the DVD+ technology achieved). Although later interfaces were able <b>to</b> <b>stream</b> <b>data</b> at the required speed, many drives now write in a 'zoned constant linear velocity'. This means that the drive has to temporarily suspend the write operation while it changes speed and then recommence it once the new speed is attained. This is handled in the same manner as a buffer underrun.|$|E
50|$|Mehdi Yahyanejad is a tech {{entrepreneur}} who founded Balatarin.com, a news sharing website in Persian in 2006. Balatarin has been {{blocked by the}} Iranian government in Iran and has {{been the target of}} hacking and DDOS attacks by the Iranian government. Mehdi Yahyanejad has also co-founded NetFreedom Pioneers which is an organization dedicated increasing access to Internet. He launched the Toosheh project, a method <b>to</b> <b>stream</b> <b>data</b> files to Iran through satellite TV in April 2016. He works on building technologies to allow Internet access in remote areas and offline content sharing. He has also published a number of articles and educational videos on cyber security to train journalist and citizen journalists.|$|E
50|$|Applications of SQLstream Blaze include {{real-time}} {{service and}} sensor (Internet of Things) data management, real-time <b>data</b> integration, <b>streaming</b> log file analytics and real-time data warehousing. SQLstream Blaze provides {{an effective way}} of processing large volumes of data in real-time enabling {{a wide variety of}} smart services to be real-time responsive <b>to</b> <b>streaming</b> <b>data</b> even at massive data volumes.|$|R
5000|$|There is {{at least}} one {{alternative}} to BitTorrent that is a commercial applications, for example Push2Peers which claims <b>to</b> <b>stream</b> the <b>data</b> in order. http://www.djingle.fr/index.php?tree_id=8 ...|$|R
40|$|Abstract- Most of the {{existing}} privacy-preserving techniques, such as k-anonymity methods, are designed for static data sets. As such, they cannot be applied <b>to</b> <b>streaming</b> <b>data</b> which are continuous, transient, and usually unbounded. Moreover, in streaming applications, {{there is a need}} to offer strong guarantees on the maximum allowed delay between incoming data and the corresponding anonymized output. To cope with these requirements, in this project, we present Continuously Anonymizing <b>Streaming</b> <b>data</b> via adaptive clustering; a clusterbased scheme that anonymizes <b>data</b> <b>streams</b> on-the-fly and, at the same time, ensures the freshness of the anonymized data by satisfying specified delay constraints...|$|R
50|$|The PS3 {{client was}} {{developed}} in a collaborative effort between Sony and the Pande lab and was first released as a standalone client on March 23, 2007. Its release made Folding@home the first distributed computing project to use PS3s. On September 18 of the following year, the PS3 client became a channel of Life with PlayStation on its launch. In the types of calculations it can perform, {{at the time of}} its introduction, the client fit in between a CPU's flexibility and a GPU's speed. However, unlike CPUs and GPUs, users were unable to perform other activities on their PS3 while running Folding@home. The PS3's uniform console environment made technical support easier and made Folding@home more user friendly. The PS3 also has the ability <b>to</b> <b>stream</b> <b>data</b> quickly to its GPU, which was used for real-time atomic-level visualizing of the current protein dynamics.|$|E
50|$|The {{file system}} itself is {{implemented}} {{entirely in the}} Linux userspace. The primary reason TiVo devised such a system is because they needed a way to store large continuous sections of data easily {{in a manner that}} lent itself well to streaming that data directly to the media decoders in the TiVo devices, without being CPU dependent. Thus, the CPU has very little involvement in playback and recording functionality, simply directing the encoder/decoder chips <b>to</b> <b>stream</b> <b>data</b> directly to the drives via direct memory access while mapping sections of virtual memory onto the drive. The main CPU then orchestrates the entire affair. The result of this is that data stored on the MFS media region is not formatted into normal files, as such, but is a direct data stream that is indexed by the database sections in the MFS application region.|$|E
40|$|Abstractâ€”The ability <b>to</b> <b>stream</b> <b>data</b> between web-services {{could be}} an {{alternative}} way of data transfer in grid environments, {{for a number of}} applications. This work intents to investigate various protocols as to their suitability for streaming, taking into consideration issues such as security, reliability and speed over different Grid configurations. To perform these comparisons we have implemented a Server/Client library together with a web service that provides a simple API through which Java applications can stream data. Furthermore, this architecture can be reused by scientific programmers who want <b>to</b> <b>stream</b> <b>data</b> without having to deal with protocol or web service trivialities. Finally, an evaluation of streaming as an alternative to file transfer on Grid environments is offered, based on a number of test case scenarios. I...|$|E
40|$|International audienceWe propose two asynchronously {{distributed}} {{approaches for}} graph-based semi-supervised learning. The first approach {{is based on}} stochastic approximation, whereas the second approach is based on randomized Kaczmarz algorithm. In addition {{to the possibility of}} distributed implementation, both approaches can be naturally applied online <b>to</b> <b>streaming</b> <b>data.</b> We analyse both approaches theoretically and by experiments. It appears that there is no clear winner and we provide indications about cases of superiority for each approach...|$|R
40|$|We {{postulate}} {{that the}} popularity {{and efficiency of}} SQL for querying relational databases makes the language a viable solution to retrieving <b>data</b> from <b>data</b> <b>streams.</b> In response, we have developed a system, dQUOB, that uses SQL queries <b>to</b> extract <b>data</b> from <b>streaming</b> <b>data</b> in real time. The high performance needs of applications such as scientific visualization motivates our search for optimizations to improve query evaluation efficiency. The {{purpose of this paper}} is to discuss the unique optimizations we have realized by a database point of view <b>to</b> <b>streaming</b> <b>data</b> and <b>to</b> show that the enhanced conceptual model of viewing <b>data</b> <b>streams</b> as relations has reasonable overhead. ...|$|R
50|$|Adaptive coding {{refers to}} {{variants}} of entropy encoding methods of lossless data compression. They are particularly suited <b>to</b> <b>streaming</b> <b>data,</b> as they adapt to localized {{changes in the}} characteristics of the data, and don't require a first pass over the data to calculate a probability model. The cost paid for these advantages is that the encoder and decoder must be more complex to keep their states synchronized, and more computational power is needed to keep adapting the encoder/decoder state.|$|R
40|$|Smart mobile {{devices that}} support {{internet}} access {{are widely used}} nowadays. Those devices have differentcapabilities based on the manufactures and the model. This paper proposes a new framework for adapting thecontent of Mobil-government services with respect of four contexts; personal, device, connectivity and locationcontexts. The framework {{is based on a}} 3 -layer mediation architecture that uses XML as semi-structure mediationlanguage. The flexibility of the mediation and XML provide an adaptive environment <b>to</b> <b>stream</b> <b>data</b> based on thecapabilities of the device sending the query to the system...|$|E
40|$|Rapid {{spread of}} smart mobile {{technology}} that supports internet access is transforming the way governments {{provide services to}} their citizens. Mobile devices have different capabilities based on the manufacturers and models. This paper proposes a new framework for adapting the content of M-government services using mobile agent technology. The framework {{is based on a}} mediation architecture that uses multiple mobile agents and XML as semi-structure mediation language. The flexibility of the mediation and XML provide an adaptive environment <b>to</b> <b>stream</b> <b>data</b> based on the capabilities of the device sending the query to the system...|$|E
40|$|In data clustering, many {{approaches}} {{have been proposed}} such as K-means method and hierarchical method. One {{of the problems is}} that the results depend heavily on initial values and criterion to combine clusters. In this investigation, we propose a new method to cluster stream data while avoiding this deficiency. Here we assume there exists aspects of local regression in data. Then we develop our theory to combine clusters using values by regression analysis as criterion and to adapt <b>to</b> <b>stream</b> <b>data.</b> We examine experiments and show how well the theory works...|$|E
5000|$|ITU-T H.223 for bit <b>streams</b> <b>to</b> <b>data</b> packets multiplexer/demultiplexer ...|$|R
40|$|A new {{algorithm}} {{for building}} decision tree classifiers is proposed. The algorithm is executed in a distributed environment and is especially designed for classifying large datasets and <b>streaming</b> <b>data.</b> It is empirically {{shown to be}} as accurate as standard decision tree classifiers, while being scalable <b>to</b> infinite <b>streaming</b> <b>data</b> and multiple processors. 1...|$|R
40|$|Geometric measure {{theory is}} just {{beginning}} to be exploited for its large potential <b>to</b> <b>streaming</b> <b>data</b> analysis. Recently, it has been used to develop a variety of promising tools for various sorts of data. Our interest in this problem spans the-ory and the application of this theory <b>to</b> analysis of <b>streaming</b> images. In this work, we demonstrate new multiscale signa-tures as well as fast surrogates for those signatures that permit processing of <b>streaming</b> <b>data.</b> The multiscale flatnorm surrogates give us streaming speeds for shape recognition tasks: The development of scale based surrogates lead to new signatures for shapes and effi-cient methods for image streams. Moderate parallelization promises very high throughput speeds for image and shape analysis tasks that are focused on scale-based features...|$|R
40|$|The {{amount of}} sensors {{publishing}} {{data on the}} Web is increasing {{as a result of}} the online availability of Sensor Web platforms that provide support for this task. With such increase in sensor data publication, new challenges arise for the identification, discovery and access to this data. Following the set of best practices to publish and link structured data on the web proposed by the Linked Data community, in this paper we introduce the concept of Linked Stream Data, a way in which the Linked Data principles can be applied <b>to</b> <b>stream</b> <b>data</b> and be part of the Web of Linked Data...|$|E
40|$|Data streams are {{generated}} by many real time systems. Data stream is fast changing and massive. In stream data mining traditional methods are not efficient so that many methodologies developed <b>to</b> <b>stream</b> <b>data</b> processing. Many applications require data into {{groups based on}} its characteristics. So clustering on data streams is applied. Clustering of non liner data density based clustering is used. Review of clustering algorithm and methodologies is represented and evaluated if they meet requirement of users. Study of density based clustering algorithm is presented here because of advantages of density based clustering method over other clustering method...|$|E
40|$|With the {{adoption}} of 2 G and 3 G cellular network technologies, mobile phones now have the bandwidth capability <b>to</b> <b>stream</b> <b>data</b> back to monitoring stations in real-time. Our paper describes the design and evaluation of a Bluetooth electrocardiogram sensor that transmits medical data to a cell phone. This data is displayed and stored on the phone. Future development of the system will relay this data over a cellular GPRS network. The current system provides a low cost and lightweight alternative to existing EKG event monitors. The final GPRS connected system will provide continuous monitoring of a patientâ€™s heart anywhere cellular coverage is available...|$|E
5000|$|The {{application}} of digital computation to signal processing allows for many advantages over analog processing in many applications, such as error detection and correction in transmission {{as well as}} data compression. [...] DSP is applicable <b>to</b> both <b>streaming</b> <b>data</b> and static (stored) data.|$|R
40|$|In this demo proposal, we {{illustrate}} ACStream, {{a system}} built {{on top of}} <b>Stream</b> Base [1], <b>to</b> specify and enforce access control policies over <b>data</b> <b>streams.</b> ACStream supports a very flexible role-based access control model specifically designed to protect against unauthorized access <b>to</b> <b>streaming</b> <b>data.</b> The core component of ACStream is a query rewriting mechanism that, by exploiting a set of secure operators proposed by us in [2], rewrites a user query {{in such a way}} that it does not violate the specified access control policies during its execution. The demo will show how policies modelling a variety of access control requirements can be easily specified and enforced using ACStream...|$|R
40|$|Content based {{methods are}} {{necessary}} when text annotations are non-existent or incomplete. Furthermore, content based methods can potentially improve retrieval accuracy even when text annotations are present by giving additional {{insight into the}} media collections. For domain specific videos, associations among different events are used for indexing purpose, which contributed a lot in bringing vast knowledge from video libraries and databases. In this paper, we are introducing multicore Fp (frequent pattern) -growth tree building algorithm applicable <b>to</b> <b>streamed</b> <b>data.</b> This algorithm will improve efficiency to retrieve videos through parallelizing frequent pattern constructing steps. Index Terms: Multicore, multithreading, indexing. I...|$|R
40|$|We {{present a}} simple and {{effective}} algorithm for ray tracing iso-surfaces of time varying data sets. Each time step is partitioned into separate ranges of potentional iso-surface values. This creates {{a large number of}} relatively small files. Out-of-core rendering is implemented by reading for each time step the relevant iso-surface file, which contains its own spatial subdivision as well as the volumetric data. Since any of these data partitions is smaller than a single time step, the I/O bottleneck is overcome. Our method capitalizes on the ability of modern architectures <b>to</b> <b>stream</b> <b>data</b> off disk without interference of the operating system. Additionally, only a fraction of a time-step is held in memory at any moment during the visualization, which significantly reduces the required amount of internal memory...|$|E
40|$|In this thesis, I {{designed}} and implemented an XML-based messaging protocol for interfacing galaxy systems with external applications. This protocol is TCP-based, and data are {{sent in the}} form of messages. Messages are well-formed and easily-parsed lines of text that encode separate ASCII and binary payloads. Protocol specifications are defined that provide robustness and flexibility. The ASCII portions of messages are encoded using XML to o#er extensibility for using the protocol across a wide variety of applications. The binary portions carry raw data and can be used <b>to</b> <b>stream</b> <b>data</b> across several messages. We demonstrated the C++ implementation of this protocol in several test applications. These included simple variations of instant messaging that let users send text messages to each other, and a modified galaxy audio application that transmits audio from one machine to another...|$|E
40|$|Abstract: Discovering {{interesting}} patterns or substructures in data streams is {{an important}} challenge in data mining. Clustering algorithms are very often applied to identify single substructures although {{they are designed to}} partition a data set. Another problem of clustering algorithms is that most of them are not designed for data streams. This paper discusses a recently introduced procedure that deals with both problems. The procedure explores ideas from cluster analysis, but was designed to identify single clusters without the necessity to partition the whole data set into clusters. The new extended version of the algorithm is an incremental clustering approach applicable <b>to</b> <b>stream</b> <b>data.</b> It identifies new clusters formed by the incoming data and updates the data space partition. Clustering of artificial and real data sets illustrates the abilities of the proposed method. 1...|$|E
40|$|Most of {{existing}} privacy preserving techniques, such as k-anonymity methods, {{are designed for}} static data sets. As such, they cannot be applied <b>to</b> <b>streaming</b> <b>data</b> which are continuous, transient and usually unbounded. Moreover, in streaming applications, {{there is a need}} to offer strong guarantees on the maximum allowed delay between incoming data and the corresponding anonymized output. To cope with these requirements, in this paper, we present CASTLE (Continuously Anonymizing <b>STreaming</b> <b>data</b> via adaptive cLustEring), a cluster-based scheme that anonymizes <b>data</b> <b>streams</b> on-the-fly and, at the same time, ensures the freshness of the anonymized data by satisfying specified delay constraints. We further show how CASTLE can be easily extended to handle l-diversity. Our extensive performance study shows that CASTLE is efficient and effective w. r. t. the quality of the output data...|$|R
40|$|<b>Streaming</b> <b>data</b> {{is growing}} in {{prevalence}} as connectivity increases and <b>data</b> <b>streaming</b> sources proliferate. But getting precisely the data one needs from <b>data</b> <b>streams</b> can be difficult. Given the low resource capabilities of some clients, the decision process of which data to keep often must be made `upstream' of the client. We postulate that the popularity of SQL for querying relational databases makes the language a viable solution to retrieving <b>data</b> from <b>data</b> <b>streams.</b> In response, we have developed a system, dQUOB, that uses SQL queries <b>to</b> extract <b>data</b> from <b>streaming</b> <b>data</b> in real time. The high performance needs of, say, scientific visualization, motivates our search for optimizations to improve query evaluation efficiency. The primary {{purpose of this paper}} is to discuss the unique optimizations we have realized by a database point of view <b>to</b> <b>streaming</b> <b>data.</b> 1 Introduction Passage of time and widespread adoption have made the benefits of queries as a means of retrieving data [...] ...|$|R
40|$|<b>Data</b> <b>streams</b> are a {{prevalent}} {{and growing}} source of timely data. Existing systems that handle <b>streaming</b> <b>data</b> are often explicitly designed <b>to</b> serve the <b>data</b> <b>streams.</b> In {{the future we}} expect <b>data</b> <b>streams</b> <b>to</b> be viewed as just another input source to be consulted at will and on demand. These on-demand applications are often distributed, and either have significant computational or data access needs. This paper introduces an architecture for flexible access <b>to</b> real-time <b>streaming</b> <b>data</b> on the grid based on the following fundamental observations: Aggregation of <b>data</b> <b>streams</b> as <b>data</b> resource â€“ for a class of <b>data</b> <b>stream</b> systems, a viable view of the <b>data</b> <b>streams</b> they produce is as a data resource, where the canonical data resource is a database. Stream access through database operations â€“ an intuitive view of stream access operations {{is in terms of}} database operations, specifically by means of a database query language. The recent burgeoning interest in the database research community on the topic of <b>streams</b> attests <b>to</b> this viability. Grid service-based access <b>to</b> <b>data</b> <b>streams</b> â€“ access <b>to</b> <b>data</b> <b>streams</b> has a natural realization through the proposed Global Grid Forum Grid Data Service specification, which currently specifies access to databases. The primary contributions of this paper are the definition of a <b>data</b> <b>stream</b> resource, an architecture for a <b>data</b> <b>stream</b> resource on the grid, and an identification of open research issues...|$|R
