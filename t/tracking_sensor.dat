199|957|Public
25|$|Disney has {{partnered with}} Lenovo {{to create the}} Augmented Reality game 'Star Wars: Jedi Challenges' that works with a Lenovo Mirage AR headset, a <b>tracking</b> <b>sensor</b> and a Lightsaber {{controller}} that will launch in December 2017.|$|E
50|$|The TrackIR 5 was {{introduced}} in early 2009 with a similar design as the TrackIR 4:PRO. It features a wider field of view and higher resolution <b>tracking</b> <b>sensor</b> than previous models.|$|E
5000|$|... a {{tracking}} infrared sensor, {{designed to}} follow missiles, warheads, {{and other objects}} such as debris and decoys during the middle and later stages of flight. The <b>tracking</b> <b>sensor</b> would be cooled to very low temperatures.|$|E
5000|$|Precision <b>track</b> <b>sensor</b> {{operation}} {{below the}} horizon during daylight - 05.08.2010First autonomous acquisition <b>sensor</b> to <b>track</b> <b>sensor</b> handover of an aircraft ...|$|R
50|$|Cross <b>Track</b> <b>Sensor</b> (CTS): The cross <b>track</b> <b>sensor</b> is {{a hollow}} {{hemispherical}} dome {{divided into four}} independent chambers with a miniaturized Bayard-Alpert hot filament ionization gauge in each chamber. Four small holes in the dome allow the neutral gas to stream into the chambers. The pressure in any chamber {{will depend on the}} arrival angle of the neutral wind.|$|R
5000|$|First {{autonomous}} acquisition <b>sensor</b> to <b>track</b> <b>sensor</b> handover of a boosted targetICBM Minuteman III test launch - 17.09.2010 ...|$|R
50|$|Constellation can be {{used with}} a single <b>tracking</b> <b>sensor</b> or with {{multiple}} sensors working together. One sensor is included with the Rift (without Touch), since in this scenario there are no tracked controllers that could occlude this sensor.|$|E
5000|$|ShadowView {{continued}} to operate throughout 2014 {{in a variety}} of private reserves in South Africa.In January 2017 The Internet of Life and the ShadowView Foundation organisations co-developed a LoRa-equipped sensor that is implanted directly into the rhino’s horn. The sensor gives park rangers the ability to accurately monitor the whereabouts and activities of the endangered black rhinos and keep them safe from poachers. The LoRa-equipped <b>tracking</b> <b>sensor</b> is part of a comprehensive LoRaWAN™-based IoT security solution that is deployed throughout Mkomazi National Park.|$|E
50|$|Each Joy-Con {{contains}} an accelerometer and gyroscope, {{which can be}} used for motion tracking. Games can support using the Joy-Con for pointing controls similar to the Wii Remote while detached without the need of a sensor bar. Joy-Con R {{contains an}} infrared depth <b>tracking</b> <b>sensor,</b> which can read objects and motions held in front of it; as an example of its functionality, Nintendo stated that the sensor could distinguish between the hand shapes of rock-paper-scissors. Joy-Con R also contains a near-field communication reader for use with Amiibo.|$|E
50|$|A {{virtual reality}} headset {{provides}} virtual reality for the wearer. VR headsets {{are widely used}} with computer games {{but they are also}} used in other applications, including simulators and trainers. They comprise a stereoscopic head-mounted display (providing separate images for each eye), stereo sound, and head motion <b>tracking</b> <b>sensors</b> (which may include gyroscopes, accelerometers, structured light systems, etc.). Some VR headsets also have eye <b>tracking</b> <b>sensors</b> and gaming controllers.|$|R
5000|$|Aegis Launch on Remote CampaignFirst <b>Track</b> <b>sensor</b> stereo <b>track</b> of a dim boosted targetFirst stereo post boost {{tracking}} of midcourse target ...|$|R
5000|$|First post boost track {{continuation}} of a target with track sensorFirst demonstration of <b>track</b> <b>sensor</b> generating multiple <b>tracks</b> for separating objects ...|$|R
5000|$|The company uses surveys with {{programs}} such as InsideTracker, where a detailed online analysis offers nutritional recommendations based on biomarkers like glucose, folic acid and vitamin D. One other tool used is the Dexcom continuous blood glucose <b>tracking</b> <b>sensor,</b> to help with diet. According to Sky Christopherson, [...] "Something important to note about biometrics being adopted by my clients is that they’re not using these tools simply to improve performance - what they are actually doing is maximizing their baseline health, something we call ‘Health Performance’." ...|$|E
50|$|A WiTrack is a 3-D motion <b>tracking</b> <b>sensor</b> that {{is capable}} of {{monitoring}} human body movements.This sensor is able to serve three main purposes, such functions being the following: turning on/off home appliances, tracking a lethal fall, and improving gaming experience. This new piece of technology, currently in its developing stages, was developed by Dina Kati's research group at the MIT Computer Science and Artificial Intelligence Lab. The WiTrack functions through the use of radio signals, which help perform the task of finding a person's current location, the radio signals not been affected at all by walls and other physical obstacles present.|$|E
5000|$|Your Shape: Fitness Evolved is {{a fitness}} game {{developed}} {{and published by}} Ubisoft. The game was released on November 4, 2010 as a launch title for Kinect, a montion <b>tracking</b> <b>sensor</b> accessory for the Xbox 360. It is a sequel to Your Shape, making it the second game in the franchise. The game uses [...] "player projection" [...] technology to capture the player's shape and form, dynamically incorporate them into the in-game environment, and tailor routines for the player. The game also features more emphasis {{on the use of}} resistance training, along with exercise programs developed in partnership with the magazines Men's Health and Women's Health.|$|E
5000|$|Tracked a NOAA weather {{satellite}} 19.07.2010 {{for several minutes}} (externally queued)First autonomous acquisition <b>sensor</b> to <b>track</b> <b>sensor</b> handover of a target - 23.07.2010 ...|$|R
40|$|This paper {{introduced}} {{the adoption of}} a <b>Track</b> <b>Sensor</b> on the satellite of the STSS to improve the precision of the STSS. The concepts of space coverage were proposed and the corresponding models established. A simplified computation strategy of space coverage was proposed to obtain the simulation results. Space coverage rate under different scenarios was simulated as well as its characteristics illustrated. Finally, a valuable result about the optimal orbit altitude for the given working distance of the <b>Track</b> <b>Sensor</b> regardless of the specific constellation was obtained...|$|R
40|$|Through this our {{expectation}} is that the car should break automatics if any obstacle detection as per sensor input. It should also break if the car does not follow driving track and re-track car. If the above said condition it should generate alert message for immediate help and send that message to a predefined mobile number. In that SMS it is should send current place latitude and longitude obtained from GPS so using that latitude and longitude,we can find its location on earth and we can provide fast help in case of emergency. The Microcontroller PIC 18 F 26 K 22 is interfaced with a <b>track</b> <b>sensor</b> that continuously detect, track, vehicle is in motion if <b>track</b> <b>sensor</b> output detect off road path,then microcontroller immediately slow down vehicle speed and try to move the vehicle back on path depending on <b>track</b> <b>sensor</b> output. Also microcontroller interfaced with IR sensors to detect any obstacle is present in vehicle path, is in movement...|$|R
5000|$|The Void's {{mixed reality}} {{experiences}} utilize aspects of virtual reality, haptic feedback, and other physical effects; users wear a helmet with a head-mounted display, noise cancelling headphones and a hand <b>tracking</b> <b>sensor,</b> and a haptic suit containing 22 vibrators {{and a computer}} to power the headset. The system is designed to allow its users to freely walk through and explore a virtual world; in reality, the user is confined to a [...] "stage" [...] equipped with ceiling-mounted motion tracking cameras to read the user's movements. To provide physical feedback, the [...] "stage" [...] contains foam walls, special effects equipment such as fans, mist machines, and heat lamps, as well as props representing items such as guns and torches; all of these physical elements correspond with elements within the virtual world seen through the headset, increasing the illusion of immersion.|$|E
40|$|In {{order to}} fully realize the {{potential}} of sensor networks, energy awareness should be incorporated into every stage of the network design and operation. As a representative application of sensor networks, object <b>tracking</b> <b>sensor</b> network faces many system and design challenges in terms of energy management. By studying the role of semantic location in object tracking queries, data dissemination and sensing data storage, we propose a power-aware networking paradigm involving sensor nodes, networks protocols and application softwares for object <b>tracking</b> <b>sensor</b> networks. ...|$|E
40|$|Energy {{is one of}} {{the most}} {{critical}} constraints for sensor network applications. In this paper, we exploit the localized prediction paradigm for power-efficient object <b>tracking</b> <b>sensor</b> network. Localized prediction consists of a localized network architecture and a prediction mechanism called dual prediction, which achieve power savings by allowing most of the sensor nodes stay in sleep mode and by reducing the amount of long-range transmissions. Performance evaluation, based on mathematical analysis, shows that localized prediction can significantly reduce the power consumption in object <b>tracking</b> <b>sensor</b> networks. ...|$|E
40|$|We {{introduce}} a novel sensor fusion approach for automated initialization of marker-less tracking systems. It is not limitated in tracking range and working environment, given a 3 D {{model of the}} objects or the real scene. This is achieved based on a statistical analysis and probabilistic estimation of the uncertainties of the <b>tracking</b> <b>sensors.</b> The explicit representation of the error distribution allows the fusion of different sensor data, e. g. of mobile <b>tracking</b> <b>sensors</b> with stationary sensors, in order to estimate the initial pose and improve the registration accuracy. This methodology was applied to an augmented reality system, using a mobile camera and several stationary <b>tracking</b> <b>sensors,</b> and can be easily extended {{to the case of}} anny additional sensors. The initialization consists of an iterative pose estimation and refinement process using both stationary and mobile cameras. Thereby the registration error is minimized in 3 D object space rather than in 2 D image. Experimental results show how complex objects can be registered efficiently and accurately to an single initial image. 1...|$|R
40|$|This paper {{reports on}} the status of {{tracking}} and alignment for the LHCb detector. Topics covered are: tracking efficiency, primary vertex precision, impact parameters, and software alignment of the <b>tracking</b> <b>sensors.</b> Special emphasis is placed on the agreement between data and Monte Carlo. The first physics results are discussed in relation to the alignment and tracking quality, and the LHCb <b>tracking</b> detectors and <b>sensor</b> types are described...|$|R
50|$|LEDS-150 {{consists}} of laser warning sensors, an ADC-150 Active Defence Controller, {{a number of}} MCTS Munition Confirmation and <b>Tracking</b> <b>Sensors,</b> and High Speed Directed Launchers, HSDL, which allows the combination of soft- and hard-kill countermeasure deployment capability to the platform, optional displays, and interconnecting harnesses.|$|R
40|$|We {{consider}} the maximum lifetime routing problem for target <b>tracking</b> <b>sensor</b> network. The {{goal is to}} find the optimal routing to not only maximize the lifetime of the network but also provide real-time data transmission services. We first propose a novel model to formally define the lifetime of target <b>tracking</b> <b>sensor</b> network by establishing the relationship between individual sensors and the whole sensor network. In this model, we derive the key factor in routing that determines the lifetime bound. Then, considering this factor, we discuss the implementation of an ant-based routing algorithm. Preliminary result demonstrates the appealing performance of our proposed scheme...|$|E
40|$|We {{examine the}} effect of varying levels of {{immersion}} on the performance of a target following task in augmented reality (AR) X-ray vision. We do this using virtual reality (VR) based simulation. We analyze participant performance while varying the field of view of the AR display, as well as the reliability of the head <b>tracking</b> <b>sensor</b> as our components of immersion. In low reliability conditions, we simulate sensor dropouts by disabling the augmented view of the scene for brief time periods. Our study gives insight into {{the effect of}} <b>tracking</b> <b>sensor</b> reliability, as well as the relationship between sensor reliability and field of view on user performance in a target following task in a simulated AR system...|$|E
40|$|A Global Positioning System Synchronized Active Light Autonomous Docking System (GPSSALADS) for {{automatically}} docking a chase {{vehicle with}} a target vehicle comprises {{at least one}} active light emitting target which is operatively attached to the target vehicle. The target includes a three-dimensional array of concomitantly flashing lights which flash at a controlled common frequency. The GPSSALADS further comprises a visual <b>tracking</b> <b>sensor</b> operatively attached to the chase vehicle for detecting and tracking the target vehicle. Its performance is synchronized with the flash frequency of the lights by a synchronization means which is comprised of first and second internal clocks operatively connected to the active light target and visual <b>tracking</b> <b>sensor,</b> respectively, for providing timing control signals thereto, respectively. The synchronization means further includes first and second Global Positioning System receivers operatively connected to {{the first and second}} internal clocks, respectively, for repeatedly providing simultaneous synchronization pulses to the internal clocks, respectively. In addition, the GPSSALADS includes a docking process controller means which is operatively attached to the chase vehicle and is responsive to the visual <b>tracking</b> <b>sensor</b> for producing commands for the guidance and propulsion system of the chase vehicle...|$|E
25|$|In 2014, Boeing {{revealed}} a Super Hornet hybrid concept, {{equipped with the}} EA-18G Growler's electronic signal detection capabilities to allow for targets engagement using the receiver; the concept {{did not include the}} ALQ-99 jamming pod. Growth capabilities could include the addition of a long-range infrared search and <b>track</b> <b>sensor</b> and new air-to-air tracking modes.|$|R
40|$|Abstract- Future {{applications}} {{running on}} mobile platforms will sometimes need to query <b>sensors</b> and <b>track</b> <b>sensor</b> data over time. This paper uses the publishsubscribe paradigm {{as a natural}} solution to querying sensors from mobile platforms, and proposes a scalable approach to implement publish-subcribe, driven by the querying application. Our approach is evaluated by simulation, focusing on scalability. I...|$|R
40|$|Abstract: Future {{applications}} {{running on}} mobile platforms will sometimes need to query <b>sensors</b> and <b>track</b> <b>sensor</b> data over time. This paper proposes a novel, but natural, solution to querying sensors from mobile platforms, {{based on the}} publish-subscribe paradigm. Various options are discussed and the most promising one is included into an implementation. Our evaluation focuses on scalability...|$|R
40|$|This paper {{presents}} a practical framework to synthesize multi-sensor navigation information for localization of a rotary-wing {{unmanned aerial vehicle}} (RUAV) and estimation of unknown ship positions when the RUAV approaches the landing deck. The estimation performance of the visual <b>tracking</b> <b>sensor</b> can also be improved through integrated navigation. Three different sensors (inertial navigation, Global Positioning System, and visual <b>tracking</b> <b>sensor)</b> are utilized complementarily to perform the navigation tasks {{for the purpose of}} an automatic landing. An extended Kalman filter (EKF) is developed to fuse data from various navigation sensors to provide the reliable navigation information. The performance of the fusion algorithm has been evaluated using real ship motion data. Simulation results suggest that the proposed method can be used to construct a practical navigation system for a UAV-ship landing system...|$|E
40|$|The {{distinctive}} {{characteristic of}} target <b>tracking</b> <b>sensor</b> networks {{is that the}} delay of data transmission is constrained, which poses a difficult problem for predicting the application lifetime for such sensor networks. In this paper, we first map the delay constraints to the hop bound in routing. By analysing the energy consumption in recurring bounded hop routing, we establish the relationship between individual sensors and the whole sensor network. On {{the basis of this}} relationship, we propose a novel model to formally define the lifetime of target <b>tracking</b> <b>sensor</b> networks. The model not only implies the best routing strategy, but also exposes the dependence of lifetime on factors such as hop bound, radio transmission range, sensing range and target behaviour. Finally, we present the results of extensive simulation to investigate the influence of some adjustable parameters in engineering on the lifetime...|$|E
40|$|In this paper, {{we present}} a {{filtering}} method for estimating the shape and end effector pose of a highly articulated surgical snake robot. Our algorithm introduces new kinematic models {{that are used in}} the prediction step of an extended Kalman filter whose update step incorporates measurements from a 5 -DOF electromagnetic <b>tracking</b> <b>sensor</b> situated at the distal end of the robot. A single <b>tracking</b> <b>sensor</b> is sufficient for estimating the shape of the system because the robot is inherently a follow-the-leader mechanism with well defined motion characteristics. We therefore show that, with appropriate steering motion, the state of the filter is fully observable. The goal of our shape estimation algorithm is to create a more accurate and representative 3 D rendered visualization for image-guided surgery. We demonstrate the feasibility of our method with results from an animal experiment in which our shape and pose estimate was used as feedback in a control scheme that semi-autonomously drove the robot along the epicardial surface of a porcine heart...|$|E
40|$|This {{symposium}} on {{measurement and control}} in robotics included sessions on: (1) rendering, including tactile perception and applied virtual reality; (2) applications in simulated medical procedures and telerobotics; (3) <b>tracking</b> <b>sensors</b> in a virtual environment; (4) displays for virtual reality applications; (5) sensory feedback including a virtual environment application with partial gravity simulation; and (6) applications in education, entertainment, technical writing, and animation...|$|R
50|$|Constellation is the headset's {{positional}} tracking system, used {{to track}} {{the position of the}} user's head as well as other VR devices, consisting of external infrared <b>tracking</b> <b>sensors</b> which optically <b>track</b> specially designed VR devices. The constellation sensor comes with a stand of a desk lamp form factor, but has standard screw holes and can be detached from this stand and mounted anywhere appropriate to the user.|$|R
50|$|The basic {{electro-optical}} (EO) sensor {{is essentially}} a closed-circuit television camera, usually with a magnification lens, helping the aircrew to locate and identify targets. For night and adverse weather use, many EO sensors incorporate low-light light-amplification systems. Some pods supplement the basic visual EO with forward-looking infra-red (FLIR) to aid in locating and identifying targets in darkness. Such systems are sometimes called infrared search and <b>track</b> <b>sensors.</b>|$|R
