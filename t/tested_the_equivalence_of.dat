2|10000|Public
40|$|This study <b>tested</b> <b>the</b> <b>equivalence</b> <b>of</b> a {{theoretical}} model of parenting behaviors linking financial strain to adolescents' achievement for African American and European American families and for single- and two-parent families. The sample included an economic cross-section of African American (n = 387) and European American families (n = 230) from single- (n = 171) and two-parent (n = 446) homes. Multi-group analyses {{revealed no significant}} differences in the structural equation models between the African American and European American families, or between the single- and two-parent families. Results demonstrated that negative parent – adolescent relationships and parental school involvement mediated the relation between financial strain and adolescents' academic achievement...|$|E
40|$|Background: Intake {{of added}} sugar {{has been shown}} to {{correlate}} with many human metabolic diseases, and rodent models have characterized numerous aspects of the resulting disease phenotypes. However, there is a controversy about whether differential health effects occur because of the consumption of either of the two common types of added sugar—high-fructose corn syrup (fructose and glucose monosaccharides; F/G) or table sugar (sucrose, a fructose and glucose disaccharide). Objectives: We <b>tested</b> <b>the</b> <b>equivalence</b> <b>of</b> sucrose- vs. F/G-containing diets on mouse (Mus musculus) longevity, reproductive success, and social dominance. Methods: We fed wild-derived mice, outbred mice descended from wild-caught ancestors, a diet in which 25 % of the calories came from either an equal ratio of F/G or an isocaloric amount of sucrose (both diets had 63 % of total calories as carbohydrates). Exposure lasted 40 wk, starting at weaning (21 d of age), and then mice (104 females and 56 males) were released into organismal performances assays—seminatural enclosures where mice competed for territories, resources, and mates for 32 wk. Within enclosures all mice consumed the F/G diet. Results: Females initially fed the F/G diet experienced a mortality rate 1. 9 times the rate (P = 0. 012) and produced 26. 4 % fewer offspring than females initially fed sucrose (P = 0. 001). This reproductive deficiency was present before mortality differences, suggesting the F/G diet was causing physiologic performance deficits prior to mortality. No differential patterns i...|$|E
40|$|Although {{they can}} be topologically different, two {{distinct}} transducers may actually recognize the same rational relation. Being able to <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> transducers allows to implement such operations as incremental minimization and iterative composition. This paper presents an algorithm for <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> deterministic weighted finite-state transducers, and outlines an implementation of its applications in a prototype weighted finite-state calculus tool...|$|R
40|$|This paper <b>tests</b> <b>the</b> <b>equivalence</b> <b>of</b> {{conjoint}} {{ratings and}} rankings {{to estimate the}} values of prevention of forest pest infestations. It was found that rankings constructed from ratings were not statistically different from actual rankings. This implies that the easier ratings format {{can be used in}} conjoint analysis. Resource /Energy Economics and Policy,...|$|R
40|$|This paper {{studies the}} uniform {{convergence}} {{rate of the}} truncated seminonparametric (SNP) density estimator. Using the uniform convergence rate result we obtain, we propose a <b>test</b> statistic <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two unknown densities where two densities are estimated using the SNP estimator and supports of densities are possibly unbounded. Copyright Royal Economic Society 2007...|$|R
40|$|Abstract. Second-Order tuple {{generating}} dependencies (SO tgds) {{were introduced}} by Fagin et al. {{to capture the}} composition of simple schema mappings. <b>Testing</b> <b>the</b> <b>equivalence</b> <b>of</b> SO tgds would be important for applications like model management and mapping optimization. However, we prove the undecidability <b>of</b> <b>the</b> logical <b>equivalence</b> <b>of</b> SO tgds. Moreover, under weak additional assumptions, we also show the undecidability of a relaxed notion <b>of</b> <b>equivalence</b> between two SO tgds, namely the so-called conjunctive query equivalence. ...|$|R
40|$|Abstract. Today Finite Automata {{are used}} in several areas of economy and research, for example in {{language}} and text processing or E-Commerce. There are often automata with more than hundred thousand states. Minimization of such automata can only be done by classical minimization methods. But this doesn’t produce Minimal Finite Automata with output. A Transducer is a special Finite Automata that produces an output. One of the challenges is to <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> Transducers, this will be shown in this paper...|$|R
40|$|This work {{presents}} a mechanically verified implementation of an algorithm for deciding <b>the</b> (in-) <b>equivalence</b> <b>of</b> Kleene algebra with tests (KAT) terms. This mechanization {{was carried out}} in the Coq proof assistant. The algorithm decides KAT terms equivalence through an iterated process <b>of</b> <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> their partial derivatives. It is a purely syntactical decision procedure and so, it does not construct the underlying automata. The motivation for this work comes from the possibility of using KAT encoding of propositional Hoare logic for reasoning about the partial correctness of imperative programs. ...|$|R
40|$|ABSTRACT. Stratght line {{programs}} with assignment statements involving both simple and array variables are considered Two such programs are equivalent if they compute {{the same values}} as a function <b>of</b> <b>the</b> inputs. <b>Testing</b> <b>the</b> <b>equivalence</b> <b>of</b> array programs ts shown to be NP-hard If array variables are updated but never subsequently referenced, equivalence can be tested in polynomial time Programs without array varmbles can be tested for equivalence in expected linear t~me KEY WORDS AND PHRASES semanttcs, array asstgnments, data structures, NP-complete CR CATEGORIES 5. 24, 5 2...|$|R
40|$|Experiments on {{gravitation}} {{and general}} relativity suggested by different {{workers in the}} past ten or more years are reviewed, their feasibility examined, and the advantages of performing them in space were studied. The experiments include: (1) the gyro relativity experiment; (2) experiments to <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> gravitational and inertial mass; (3) an experiment to look for nongeodesic motion of spinning bodies in orbit around the earth; (4) experiments to look for changes of the gravitational constant G with time; (5) a variety of suggestions; laboratory tests of experimental gravity; and (6) gravitational wave experiments...|$|R
40|$|Technological {{advances}} {{have led to}} an increase in the collection of high-dimensional, nearly continuously sampled signals. Evolutionary correlations between such signals are salient to many studies, as they provide important information about associations between different dynamic processes and can be used to understand how these processes relate to larger complex mechanisms. Despite the large number of methods for analyzing functional data that have been explored in the past twenty-five years, there is a dearth of methods for analyzing functional correlations. This dissertation introduces new methods for addressing three questions pertaining to functional correlations. First, we address the problem of estimating a single functional correlation by developing a smoothing spline estimator and accompanying bootstrap procedure for forming confidence intervals. Next, we consider <b>the</b> problem <b>of</b> <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two functional correlations from independent samples by developing a novel adaptive Neyman testing procedure. Lastly, we address <b>the</b> problem <b>of</b> <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two functional correlations from dependent samples by extending <b>the</b> adaptive Neyman <b>test</b> to this more complicated setting, and by embedding the problem in a state-space framework to formulate a practical Kalman filter-based algorithm for its implementation. These methods are motivated by questions in sleep medicine and chronobiology and are used to analyze the dynamic coupling between delta EEG power and high frequency heart rate variability during sleep...|$|R
40|$|AbstractA partial {{function}} F:Σ∗→Ω∗ {{is called a}} simple function if F(w) ∈Ω∗ is the output produced in the leftmost derivation of a word w∈Σ∗ from a nonterminal of a simple context free grammar G with output alphabet Ω. In this paper we present an efficient algorithm for <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> simple functions. Such functions correspond also to one-state deterministic pushdown transducers. Our algorithm works in time polynomial with respect to |G|+v(G), where |G| {{is the size of}} the textual description of G, and v(G) is the maximum of the shortest lengths of words generated by nonterminals of G...|$|R
5000|$|In 1982, the German School of Connecticut was {{the first}} German {{language}} school in the United States to be selected by The Standing Conference of the Ministers of Education and Cultural Affairs in the Federal Republic of Germany (Kultusministerkonferenz), and the Central Agency for Schools Abroad (Zentralstelle für das Auslandsschulwesen) [...] to administer the official Sprachdiplom I examination, and in 1983 added the Sprachdiplom II examination. These annual exams <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> ten and twelve years of German language study, i.e. language proficiency on the B1/A2 and C1/B2 Common European Framework of Reference [...] level, respectively.|$|R
5000|$|The Satellite Test <b>of</b> <b>the</b> <b>Equivalence</b> Principle (STEP) is a {{proposed}} (...) space science experiment to <b>test</b> <b>the</b> <b>equivalence</b> principle <b>of</b> general relativity. The experiment {{is thought to}} be sensitive enough to test Einstein's theory of gravity and other theories.|$|R
40|$|The minimal {{deterministic}} {{finite automaton}} is generally {{used to determine}} regular languages equality. Antimirov and Mosses proposed a rewrite system for deciding regular expressions <b>equivalence</b> <b>of</b> which Almeida et al. presented an improved variant. Hopcroft and Karp proposed an almost linear algorithm for <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two deterministic finite automata that avoids minimisation. In this paper we improve the best-case running time, present an extension of this algorithm to non-deterministic finite automata, and establish a relationship between this algorithm and the one proposed in Almeida et al. We also present some experimental comparative results. All these algorithms are closely related with the recent coalgebraic approach to automata proposed by Rutten...|$|R
40|$|AbstractWe {{present a}} simple {{construction}} of linear size test sets for regular languages and of single exponential test sets for context-free languages. In {{the case of}} regular sets {{the size of our}} test set is exactly the number of transitions of the automaton. This improves the best-known upper bounds: exponential for regular and doubly exponential for context-free languages. We give also an O(n log n) time algorithm for <b>the</b> morphism <b>equivalence</b> and an O(n 3 log n) time algorithm to <b>test</b> <b>the</b> gsm <b>equivalence</b> on a regular language. An O(n 2 log n) time algorithm is given to <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> two deterministic gsm's {{as well as that of}} two deterministic finite transducers...|$|R
40|$|To solve {{a problem}} in answer set programming, one needs to {{construct}} a logic program so that its answer sets correspond to the {{solutions to the problem}} at hand. It is common in program development to have several versions of the program for a particular problem, that e. g. optimize the execution time or space. The programmer, however, faces a new problem, for it is necessary to ensure that different encodings yield the same answer sets. To ease this task, we present a method for <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> logic programs P and Q. We translate P and Q into a single logic program. The answer set of the [...] ...|$|R
40|$|This paper {{presents}} a mechanically verified implementation of an algorithm for deciding <b>the</b> <b>equivalence</b> <b>of</b> Kleene algebra terms within the Coq proof assistant. <b>The</b> algorithm decides <b>equivalence</b> <b>of</b> two given regular expressions through an iterated process <b>of</b> <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> their partial derivatives {{and does not}} require the construction of the corresponding automata. Recent theoretical and experimental research provides evidence that this method is, on average, more efficient than the classical methods based on automata. We present some performance tests, comparisons with similar approaches, and also introduce a generalization of the algorithm to decide <b>the</b> <b>equivalence</b> <b>of</b> terms of Kleene algebra with <b>tests.</b> <b>The</b> motivation for the work presented in this paper is that of using the libraries developed as trusted frameworks for carrying out certified program verification...|$|R
40|$|We {{consider}} <b>testing</b> whether <b>the</b> nonparametric {{function in}} a semiparametric additive mixed model is a simple fixed degree polynomial, for example, a simple linear function. This test provides a goodnessof-fit test for checking parametric models against nonparametric models. It {{is based on the}} mixedmodel representation of the smoothing spline estimator of the nonparametric function and the variance component score <b>test</b> by treating <b>the</b> inverse of the smoothing parameter as an extra variance component. We also consider <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two nonparametric functions in semiparametric additive mixed models for two groups, such as treatment and placebo groups. <b>The</b> proposed <b>tests</b> are applied to data from an epidemiological study and a clinical trial and their performance is evaluated through simulations...|$|R
40|$|A {{new type}} of Petri nets: Generalized Stochastic High-Level Petri nets (GSHLPN’s), {{collecting}} the qualities of GSPN’s and SHLPN’s, is presented. The automated construction of compound continuous-time Markov chains (CTMC’s) from GSHLPN’s is also considered. A formalism for the description of compound markings allowing a symbolic firing of the net to obtain a compound CTMC with correct state grouping is derived. The construction of the compound CTMC requires an algorithm to <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> compound markings. It is shown that, in the general case and for bounded number of rotation groups, the problem is polynomially equivalent to GRAPH ISOMORPHISM, a problem whose classification in the NP world is currently open. Postprint (published version...|$|R
40|$|We {{investigate}} {{the role of}} local force balance in {{the transition from a}} microcanonical ensemble of static granular packings, characterized by an invariant stress, to a canonical ensemble. Packings in two dimensions admit a reciprocal tiling, and a collective effect of force balance is that the area of this tiling is also invariant in a microcanonical ensemble. We present analytical relations between stress, tiling area and tiling area fluctuations, and show that a canonical ensemble can be characterized by an intensive thermodynamic parameter conjugate to one or <b>the</b> other. We <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> different ensembles through the first canonical simulations of the force network ensemble, a model system. Comment: 9 pages, 9 figures, submitted to JSTA...|$|R
40|$|We {{present a}} case study {{concerning}} manipulation of [...] . -OBDDs based on a probabilistic equivalence test. Efficient Boolean function manipulation requires efficient algorithms for Boolean synthesis as well as <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two Boolean functions. Due {{to the fact that}} [...] . -OBDDs do not provide a canonical representation <b>the</b> <b>equivalence</b> <b>test</b> becomes an extensive operation. A recently introduced deterministic equivalence test performs only in high polynomial degree execution time and therefore, it is not qualified for practical purposes. Hence, we tried to work with a probabilistic equivalence test (with one-sided error probability) based on Boolean signatures. Due to our experimental results we can conclude that the application <b>of</b> <b>the</b> probabilistic <b>equivalence</b> <b>test</b> is well suited for working in the field of Computer Aided Design...|$|R
40|$|This paper {{examines}} the volatility and covariance dynamics {{of cash and}} futures contracts that underlie the Optimal Hedge Ratio (OHR) across different hedging time horizons. We examine whether hedge ratios calculated over a short term hedging horizon can be scaled and successfully applied to longer term horizons. We also <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> scaled hedge ratios with those calculated directly from lower frequency data and compare {{them in terms of}} hedging effectiveness. Our findings show that the volatility and covariance dynamics may differ considerably depending on the hedging horizon and this gives rise to significant differences between short term and longer term hedges. Despite this, scaling provides good hedging outcomes in terms of risk reduction which are comparable to those based on direct estimation. ...|$|R
40|$|In {{this paper}} we study <b>the</b> topological <b>equivalence</b> problem <b>of</b> {{multistage}} interconnection networks (MINs). We prove a new characterization of topologically equivalent MINs {{by means of}} a novel approach. Applying this characterization to log N stage MINs we completely describe <b>the</b> <b>equivalence</b> class which <b>the</b> Reverse Baseline belongs to. Most important, we apply the characterization to (2 log N - 1) stage MINs obtained as concatenation of two log N stage Reverse Baseline equivalent MINs: in this way, we deduce an O(N log N) time algorithm <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two such MINs. This result substantially improves the time complexity of the previously known algorithms (O(N- 4 log N)). Finally, we determine <b>the</b> number <b>of</b> different <b>equivalence</b> classes <b>of</b> (2 log N - 1) stage MINs and we characterize each of them. (C) 2003 Elsevier Inc. All rights reserved...|$|R
40|$|AbstractA prefix-free {{language}} is prime if it cannot be decomposed into a concatenation of two prefix-free languages. We {{show that we}} can check in polynomial time if a language generated by a simple context-free grammar is prime. Our algorithm computes a canonical representation of a simple language, converting its arbitrary simple grammar into prime normal form (PNF); a simple grammar is in PNF if all its nonterminals define primes. We also improve <b>the</b> complexity <b>of</b> <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> simple grammars. <b>The</b> best previously known algorithm for this problem worked in O(n 13) time. We improve it to O(n 7 log 2 n) and O(n 5 polylogv) time, where n is the total size of the grammars involved, and v is {{the length of a}} shortest string derivable from a nonterminal, maximized over all nonterminals...|$|R
40|$|We {{consider}} the problem <b>of</b> detecting <b>the</b> <b>equivalence</b> <b>of</b> two single-output Boolean functions, considering the permutation and complementation of their inputs, complementation of outputs, and their associated don't-care sets. This {{is often referred}} to as the Boolean matching problem. Boolean matching is a verification problem, and it has important applications in logic synthesis problems such as technology-mapping [1, 2, 3]. In this paper, we present a new algorithm for solving the Boolean matching problem which is based on Boolean unification and branch-and-bound techniques. We have applied this algorithm to the task of technologymapping for cell-based designs, and experimental results show that it is an efficient and effective algorithm. Comparisons with existing Boolean matching algorithms will also be presented. 1 Introduction and Review of Previous Work In design verification, we often need to <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> two combinational circuits. If the correspondence of the inputs [...] ...|$|R
40|$|Information physics {{considers}} physical laws {{to result}} from the consistent quantification and processing of information about physical phenomena. In previous efforts, one of us (Knuth) has shown that a simple model of particles that directly influence one another results in a partially ordered set {{referred to as the}} influence network, from which emerge the Minkowski metric and Lorentz transformations of special relativity. Here, we extend earlier work on receipt of influence to the case of one particle influencing another, finding that this gives rise to equations of the form of geodesic equations from general relativity in 1 + 1 dimensions. Future work will <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> <b>the</b> current result to general relativity in 1 + 1 dimensions. Comment: 8 pages, 2 figures, MaxEnt 2015 Conference, Bayesian Inference and Maximum Entropy Methods in Science and Engineering, Potsdam, NY, USA, 201...|$|R
40|$|We {{propose a}} three step {{procedure}} to investigate measurement bias and response shift, {{a special case}} of measurement bias in longitudinal data. Structural equation modelling is used {{in each of the}} three steps, which can be described as (1) establishing a measurement model using confirmatory factor analysis, (2) detecting measurement bias by <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> model parameters across measurement occasions, (3) detecting measurement bias with respect to additional exogenous variables by testing their direct effects on the indicator variables. The resulting model can be used to investigate true change in the attributes of interest, by testing changes in common factor means. Solutions for the issue of constraint interaction and for chance capitalisation in model specification searches are discussed as part of the procedure. The procedure is illustrated by applying it to longitudinal health-related quality-of-life data of HIV/AIDS patients, collected at four semi-annual measurement occasion...|$|R
40|$|The {{reciprocal}} effects model (REM) {{predicts a}} reciprocal relation between academic self-concept and academic achievement, whereby prior academic self-concept {{is associated with}} future gains in achievement, and prior achievement is related to subsequent academic self-concept. Although {{research in this area}} has been extensive, there has been a paucity of research specifically examining the REM from the standpoint of students who attend academically selective schools. The present research aimed to rectify this gap in <b>the</b> literature by <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> <b>the</b> REM across a sample of high school students who attend both academically selective (n = 738) and mixed-ability comprehensive (n = 2, 048) schools. Multigroup analyses revealed that the REM existed for both groups and that there were no differences between the groups in either the size or the direction of the paths that constitute the REM. Implications for REM theory and teaching practice are discussed...|$|R
40|$|In {{this paper}} we {{give an answer}} to an open problem posed by Paredaens in 1995, i. e., {{determining}} the time complexity required to <b>test</b> <b>the</b> topological <b>equivalence</b> <b>of</b> two 2 -dimensional spatial databases. Intuitively, two spatial databases are topologically equivalent if their topological properties do not change {{as a consequence of}} topological transformations (for instance, homeomorphisms or isotopies). We provide an algorithm that, given two 2 -dimensional spatial databases D 1 and D 2, decides whether D 1 and D 2 are topologically equivalent with respect to isotopies. The time complexity of the algorithm is polynomial {{in the size of the}} databases. Up to now, it was only known that <b>testing</b> <b>the</b> topological <b>equivalence</b> <b>of</b> two 2 -dimensional spatial databases is decidable. Three main ingredients have been used: the notion of topological invariant of a spatial database, that is, a finite structure that captures exactly the topological properties of the database up to isotopies; th [...] ...|$|R
40|$|The {{purpose of}} these {{experiments}} was to <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> pulmonary artery, urinary bladder, tympanic, rectal and femoral artery methods of temperature measurement in healthy and critically ill swine under clinical intensive care unit (ICU) conditions using a prospective, time series design. First, sensors were tested for error and sensitivity to change in temperature with a precision-controlled water bath and a laboratory-certified digital thermometer for temperatures 34 - 42 degrees C. There was virtually no systematic (bias) or random (precision) error (or= 0. 5 degrees C) and/or precision (>or= 0. 2 degrees C). Response time varied from 7 s with the femoral artery method to 280 s (4. 7 min) with the tympanic method. We concluded that <b>equivalence</b> <b>of</b> <b>the</b> methods was insufficient {{for them to be}} used interchangeably in the porcine ICU. Intravascular monitoring of core body temperature produces optimal measurement of porcine temperature under varying conditions of physiological stability...|$|R
30|$|The {{ranking method}} used for <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two {{distributions}} {{has been studied}} for decades and is widely adopted for its simplicity. However, due {{to the complexity of}} calculations, the power of <b>the</b> <b>test</b> is either estimated by a normal approximation or found when an appropriate alternative is given. Here, via the Finite Markov chain imbedding technique, we are able to establish the marginal and joint distributions of the rank statistics considering the shift and scale parameters, respectively and simultaneously, under two different continuous distribution functions. Furthermore, <b>the</b> procedures <b>of</b> distribution <b>equivalence</b> <b>tests</b> and their power functions are discussed. Numerical results of a joint distribution of rank statistics under the standard normal distribution and the powers for a sequence of alternative normal distributions with means from − 20 to 20 and standard deviations from 1 to 9 and their reciprocal are presented. In addition, we discuss the powers of the rank statistics under the Lehmann alternatives.|$|R
30|$|In conclusion, the {{literature}} on robotic-assisted radical hysterectomy supports its safety and feasibility for the surgical management of early cervical cancer. Both robotic and laparoscopic radical hysterectomy {{have been shown to}} have advantages for patients over the open approach in terms of blood loss, blood transfusions, complications, and length of hospital stay, with the exception of prolonged operation. The available literature suggests that robotic technology may be associated with improved operative outcomes as compared to a traditional laparoscopic approach for radical hysterectomy but no randomized data has been published. Similar recurrence and cure rates have been reported when comparing the results of both techniques. Long-term follow-up data is not available at this time regarding recurrence rates and overall survival. The results of a phase III randomized clinical trial <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> outcomes after laparoscopic or robotic radical hysterectomy with abdominal radical hysterectomy in patients with early cervical cancer are expected [22].|$|R
40|$|A prefix-free {{language}} is a prime if it cannot be decomposed into a concatenation of two prefix-free languages. We show that we can check in polynomial time if a language generated by a simple contextfree grammar is a prime. Our algorithm computes a canonical representation of a simple language, converting its arbitrary simple grammar into Prime Normal Form (PNF); a simple grammar is in PNF if all its nonterminals define primes. We also improve <b>the</b> complexity <b>of</b> <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> simple grammars. <b>The</b> best previously known algorithm for this problem worked in O(n) time. We improve it to O(n n) and O(n polylog v) deterministic time, and O(n polylog n) randomized time, where n is the total size of the grammars involved, and v is {{the length of a}} shortest string derivable from a nonterminal, maximized over all nonterminals. Our improvement is based on a version of Caucal's algorithm from [1]...|$|R
40|$|Bayesian network {{classifiers}} {{are used}} in many fields, and one common class of classifiers are naive Bayes classifiers. In this paper, we introduce an approach for reasoning about Bayesian network classifiers in which we explicitly convert them into Ordered Decision Diagrams (ODDs), which are then used to reason about the properties of these classifiers. Specifically, we present an algorithm for converting any naive Bayes classifier into an ODD, and we show theoretically and experimentally that this algorithm can give us an ODD that is tractable in size even given an intractable number of instances. Since ODDs are tractable representations of classifiers, our algorithm allows us to efficiently <b>test</b> <b>the</b> <b>equivalence</b> <b>of</b> two naive Bayes classifiers and characterize discrepancies between them. We also show a number of additional results including a count of distinct classifiers that can be induced by changing some CPT in a naive Bayes classifier, {{and the range of}} allowable changes to a CPT which keeps the current classifier unchanged. ...|$|R
40|$|We give {{a general}} unified method {{that can be}} used for L_ 1 {{closeness}} testing of a wide range of univariate structured distribution families. More specifically, we design a sample optimal and computationally efficient algorithm for <b>testing</b> <b>the</b> <b>equivalence</b> <b>of</b> two unknown (potentially arbitrary) univariate distributions under the A_k-distance metric: Given sample access to distributions with density functions p, q: I →R, we want to distinguish between the cases that p=q and p-q_A_k>ϵ with probability at least 2 / 3. We show that for any k > 2, ϵ> 0, the optimal sample complexity of <b>the</b> A_k-closeness <b>testing</b> problem is Θ({ k^ 4 / 5 /ϵ^ 6 / 5, k^ 1 / 2 /ϵ^ 2 }). This is the first o(k) sample algorithm for this problem, and yields new, simple L_ 1 closeness testers, in most cases with optimal sample complexity, for broad classes of structured distributions. Comment: 27 pages, to appear in FOCS' 1...|$|R
