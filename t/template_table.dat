7|35|Public
50|$|To generalize the Hough {{algorithm}} to non-analytic curves, Ballard {{defines the}} following parameters for a generalized shape: a={y,s,θ}where y is a reference origin for the shape, θ is its orientation, and s = (sx, sy) describes two orthogonal scale factors. As {{in the case}} of initial Hough Transforms, there is an algorithm for computing the best set of parameters for a given shape from edge pixel data. These parameters no longer have equal status. The reference origin location, y, is described in terms of a <b>template</b> <b>table</b> called the R table of possible edge pixel orientations. The computation of the additional parameters s and θ is then accomplished by straightforward transformations to this table.The key to generalizing the Hough algorithm to arbitrary shapes is the use of directional information. Given any shape and a fixed reference point on it, instead of a parametric curve, the information provided by the boundary pixels is stored {{in the form of the}} R-table in the transform stage. For every edge point on the test image, the properties of the point are looked up on the R-table and reference point is retrieved and the appropriate cell in a matrix called the Accumulator matrix is incremented. The cell with maximum ‘votes’ in the Accumulator matrix can be a possible point of existence of fixed reference of the object in the test image.|$|E
40|$|The {{expression}} of tumour staging {{is an important}} component of clinical care and the electronic capture of this data offers great potential. Version 3 of the Read Thesaurus includes a <b>template</b> <b>table</b> which offers a robust mechanism for applying specific staging detail to tumours within the clinical record...|$|E
40|$|Each {{concept in}} the {{surgical}} operations {{chapter of the}} Read Thesaurus has been analysed to determine its anatomical site component. The underlying structure of this chapter {{and its relationship to}} the anatomy chapter are explored. The defined anatomical sites have been included as atomic maps in the Read Code <b>template</b> <b>table,</b> one of the key component files of the Thesaurus, relevant features of which are described. The analysis methodology is outlined and the value of an anatomically characterised surgical procedure terminology is discussed together with the implications of semantically defining a wider range of characteristics of surgical procedures...|$|E
5000|$|Using Object Oriented {{modeling}} create <b>table</b> <b>templates</b> which {{define the}} structures of a table and then create instances of the <b>table</b> <b>template</b> {{which is used to}} physically create the tables in the database ...|$|R
5000|$|Software: Sale of {{licensed}} {{copies of}} (i) the company's Power IC Model Library for PSpice, and (ii) WCCA <b>templates</b> and <b>tables.</b>|$|R
40|$|Are you {{confused}} {{about the difference}} between style <b>templates,</b> <b>table</b> <b>templates,</b> tagset templates, and graph templates? Do you wonder how they're all used with ODS? This paper provides an overview of all the different template types and how they're used with the Output Delivery System. From style and <b>table</b> <b>templates,</b> that first appeared with SAS ® 7 to the newest graph templates that appeared with SAS ® 9. 2, this paper will provide an overview and several concrete examples for each template type. Along the way, we'll also discuss the template garden (SASHELP. TMPLMST) where all the templates live, how to transplant your templates to a different garden, how to come up with your own new variety of templates (PROC TEMPLATE), and how to find your way to the new template garden (ODS PATH). New features of PROC TEMPLATE syntax (such as the IMPORT statement) will be highlighted...|$|R
40|$|The Read Thesaurus (Version 3 of the Read Codes) is a {{controlled}} medical vocabulary produced during the Clinical Terms Projects with {{the involvement of}} over 2, 000 health care professionals from all United Kingdom specialties. In addition to allowing the transfer of clinical information in a meaningful way, it supports analysis of this information and provides {{a basis for the}} development of shareable medical knowledge bases. The thesaurus includes a comprehensive, dynamic set of over 7, 000 gross anatomic concepts richly linked in a network with over 16, 000 operative procedures and 40, 000 disorders. The representation of anatomic concepts aims to balance the requirements for expressivity, clearness, and simplicity. The underlying directed acyclic graph hierarchy is independent of the alphanumeric code and enables continued refinement and expansion. A <b>template</b> <b>table</b> allows semantic definition, qualification, and linkage of concepts...|$|E
40|$|Each {{scenario}} {{has been}} defined by the PSTF has been broken down into sub-scenario variations, e. g. 4 b, "TDM-ATM Dual MGC over BICC/IP". Each sub-scenario {{is to have a}} test plan document based on this template, containing at least the agreed mandatory tests for this scenario. The template was based upon msf 2002. 067. 00, msf 2002. 079. 00 and msf 2002. 106. 00 This contribution provides a interoperability test plan for sub-scenario 5 c as defined by sub-scenario <b>Template</b> (<b>Table</b> 1). This test plan is suitable for the Global MSF Interoperability event. By submitting this contribution, the representative(s) of the source company(ies) acknowledge reading and agrees to the MSF IPR Policy Statement. This contribution has been prepared to assist the MSF. This contribution is made on behalf of the source organization named above as a basis for discussion. This contribution should not be construed as a binding proposal on the contributor, who reserves the right to amend, modify, or retract the statements contained herein. “Note: Attention is called to the possibility that use or implementation of this MSF Implementation Agreement may require use of subject matter covered by intellectual property rights owned by parties who have not authorized such use. By publication of this Implementation Agreement, no position is taken b...|$|E
40|$|While it is {{understood}} that macro variables are referenced in ODS by using MVAR and NMVAR statements, macro programs {{continue to play a}} vital role in ODS. To back up this claim, the TABLETEMPLATE macro that generates a customized table in ODS is reviewed in depth. Looping in the macro eliminates the need for hard coding, and multiple ampersand macro variables (&&f&i) provide the only viable means for inserting data dependent text strings into a table. Pre and Post macro versions of the code are presented to emphasize the role played by macros in ODS. PROBLEM DEFINITION To generalize PROC <b>TEMPLATE</b> <b>table</b> definitions, it is recommended that DYNAMIC variables reference structural components such as headers or footers and that MVAR and NMVAR be reserved for constants that can change each time a compiled template is called in a DATA step. However, what if the macro variables you need to define come from the set of unique values in a column from the input data? Furthermore, what if you need a different outcome in a PROC TEMPLATE CELLSTYLE-AS statement for each unique value in the column? In this situation, a reliable table definition requires the assistance of a full-fledged macro with looping capabilities. What the paper describes is an application where an ODS table definition is nested inside the macro TABLETEMPLATE. The table definition uses MVAR and DYNAMIC variables in addition to conventional macro variables with multiple ampersands for managing the CELLSTYLE-AS statement...|$|E
40|$|Transposition tables {{have long}} been a viable tool in the pruning {{mechanisms}} of game-tree search algorithms. In such applications, a transposition table can reduce a game-tree to a game-graph with unique board positions at the nodes. This paper proposes a transposition table extension, called a <b>template</b> matching <b>table,</b> where <b>templates</b> that prove winning positions are used to map features of board positions to board values. This paper demonstrates that a game-tree search for the game of Hex can have a more effective pruning mechanism using a <b>template</b> matching <b>table</b> than it does using a transposition table...|$|R
5000|$|... (Table taken {{directly}} from source and converted to Wikipedia <b>Table</b> <b>Template)</b> ...|$|R
50|$|This feature {{allows the}} {{creation}} of database tables following the paradigms of object oriented programming. You can have a base table (called a <b>table</b> <b>template),</b> and you can derive (specialize) tables from it. The specialized table will have the columns inherited from the base table, and also you can add new columns to it. The table instances can be populated with default values, and after population they are deployed in the selected database(s). There can be more instance of a <b>table</b> <b>template,</b> each of them can have {{its own set of}} default values.|$|R
40|$|The gToW plasmid, pSBI 40, is an episomal plasmid {{containing}} two selective markers; URA 3 and leu 2 -d, {{as described}} elsewhere (Moriya et al, 2006). Target ORFs were amplified by PCR with {{as close to}} complete upstream and downstream regions as possible, using genomic DNA from BY 4743 as <b>template</b> (<b>Table</b> SI). Strains and plasmids were generated simultaneously with the gap repair strategy, by cotransformation of HindIII/KpnI digested pSBI 40 with each corresponding PCR fragment into BY 4743 cells using yeast electroporation. Transformants were selected and maintained on plates lacking uracil but {{in the presence of}} abundant leucine. Eight clones of each transformant were transferred to 96 well plates and frozen to- 80 °C after addition of glycerol to a final concentration of 20 %. Plasmids were extracted from the strains used, amplified in E. coli, and digested with HindIII and KpnI, and the digestion pattern verified by gel electrophoresis. Growth assays Strains deep-frozen (- 80 °C) in 20 % glycerol were inoculated in 350 µl of SD medium and incubated for ∼ 72 h at 30 °C (pre-pre culture). This procedure was repeated once (second incubation∼ 48 h – preculture). For experimental runs, strains were inoculated to an OD of 0. 03 - 0. 1 in 350 µl of SD medium and cultivated for 47 h in a Bioscreen analyzer C (Labsystems Oy, Finland). Optical density was measured using a wide band (450 - 580 nm) filter. Incubation was at 30. 0 °C (± 0. 1 °C) with ten minutes preheating time. Plates were subjected to shaking at highest shaking intensity with 60 s of shaking every other minute. OD measurements were taken every 20 minutes during a 47 h period. Strains were run as five replicates in one single experiment with five wildtype strains (WT) included in each experiment. Growth rates were calculated as earlier described (Warringer et al, 2003). Strain growth defects as compared to the WT in a particular environment, termed Logarithmic Strain Coefficients (LSCs), were calculated a...|$|E
40|$|Are you a DATA step programmer? Do {{you want}} to route DATA _NULL _ output to the Output Delivery System (ODS) ? Do {{you want to}} convert classic DATA _NULL _ and FILE PRINT {{programs}} {{to take advantage of}} the ODS? This paper explains how to create and use a custom <b>TABLE</b> <b>template</b> with a DATA _NULL _ program. Through the use of concrete examples, you will learn how to become a power user of custom <b>TABLE</b> <b>templates</b> and DATA _NULL_. Topics covered include defining a new template, defining headers and footers, using GENERIC columns, and performing traffic-lighting based on data cell values...|$|R
5000|$|XBRL Table Linkbase - This module allows {{taxonomy}} {{authors to}} define tabular reporting <b>templates.</b> The <b>Table</b> Linkbase {{can be used}} for presentation of XBRL data, and also for data entry, by allowing software to present a template for completion by the user. The Table Linkbase is well-suited to handling large, highly-dimensional reporting templates such as those used for Solvency II reporting to EIOPA, and COREP and FINREP reporting to the EBA.|$|R
40|$|Wikipedia puts forward {{that each}} article gains more quality {{over time as}} the process of {{consensus}} building results in a neutral point of view. In this study we analyze the same article across different Wikipedia language versions, comparing the article titles, <b>templates,</b> <b>tables</b> of contents, particular content details, talk pages, editors’ names and locations, references and images. For the contentious articles in existence {{for at least five}} years, we found that they could be said to express rather national than neutral points of view. In the case in question, the Srebrenica massacre, the Bosnian, Dutch and Serbian article’s respective viewpoints can be attributed to specific sets of editors contributing in their own language version, and the references they employ. Editors of the various language versions participate in the English version, which results in a continually contested article often referred to (in the Serbian) as western. The Serbo-­‐ Croatian strives to be anti-­‐nationalist and apolitical, employing a variety of means to unify the Bosnian and Serbian points of view. In general, the analysis provides footing for studying Wikipedia's language versions as cultural references...|$|R
40|$|Abstract. The {{problem of}} finding duplicates in data is {{ubiquitous}} in data mining. We cast {{the problem of}} finding duplicates in sequential data into a poly-cut problem on a fully connected graph. The edge weights can be identified with parameterized pairwise similarities between objects that are optimized by structural support vector machines on labeled training sets. Our approach adapts the similarity measure to the data and is independent {{of the number of}} clusters. We present three large margin approximations of learning the pairwise similarities: an integrated QPformulation, a sequential multi-class approach and a pairwise classifier. We report on experimental results. 1 Introduction The problem of identifying duplicates has applications ranging from recognizingobjects from different perspectives and angles to the identification of objects that are intentionally altered to obfuscate their true identity, origin, or purpose. This occurs, for instance, in the context of email spam and virus detection. Spam and virus senders avoid mailing identical copies of their messages be-cause it would be an easy giveaway. Identifying a batch of messages would allow email service providers to hold back the entire batch, and to identify hijackedservers that are being used to disseminate spam or viruses. Therefore, spam senders generate messages according to <b>templates.</b> <b>Table</b> 1 shows an exampleof two spam messages that have been generated with a spamming tool. Slots of a common template are filled according to a grammar; the tool also appliesobfuscation techniques such as random insertions of spaces...|$|R
40|$|During {{this phase}} of the project, we {{finalized}} the daytyping method to be followed, and started processing the data sets previously approved by the PMSC. So far, we processed a total of 23 buildings (ESL). The final product will include typical load shapes and diversity factors from 27 Office Buildings monitored by ESL and 9 Office Buildings provided by LBNL (Energy-Edge Buildings). If time allows, we will process 28 additional buildings provided to us by PNNL. These additional buildings were monitored under the ELCAP project. We prepared typical templates (with Microsoft Word) to describe each building along with the corresponding results of the analysis. Mr. Micheal Witte, from Gard Analytics, helped us in writing the BLAST input files, and he also automated the procedure of copying the results from EXCEL to the WORD <b>templates.</b> <b>Table</b> 4 shows the final set of buildings that are currently analysed. This is a draft of the Final Report in the ASHRAE RP- 1093 project that, first summarizes the work completed during the scheduled Phase I and Phase II (presented to the PMSC in Seattle - June 1999, and Dallas February 2000), and reports on the progress during the scheduled Phase III effort (Table 1). It {{should be noted that the}} PMSC approved a one-year extension after the May- 2000 -Completion-date noted in Table 1. Tables 2 and 3 show the buildings that were approved by the PMSC in previous meetings...|$|R
5000|$|WertV's general {{regulations}} are further {{supported by the}} Wertermittlungsrichtlinie (abbr. WertR, [...] "directive on the determination of value"). The WertR provides <b>templates</b> for calculations, <b>tables</b> (e.g., economic depreciation) and guidelines for the consideration of different influences. WertV and WertR are not binding for appraisals for nonofficial use, nonetheless, they {{should be regarded as}} best practice or Generally Accepted (German) Valuation Practice (GAVP).|$|R
40|$|Authors {{often do}} not give {{sufficient}} information to draw conclu-sions about the size and statistical significance of interaction on the additive and multiplicative scales. To improve this, we provide four steps, <b>template</b> <b>tables</b> and examples. We distinguish two cases: when the causal effect of intervening on one exposure, across strata of another factor, is of interest (‘effect modification’); and when the causal effect of intervening on two exposures is of inter-est (‘interaction’). Assume we study whether X modifies the effect of A on D, where A, X and D are dichotomous. We propose presenting: (i) relative risks (RRs), odds ratios (ORs) or risk differences (RDs) for each (A, X) stratum with a single reference category taken as the stratum with the lowest risk of D; (ii) RRs, ORs or RDs for A within strata of X; (iii) interaction measures on additive and multiplicative scales; (iv) the A–D confounders adjusted for. Assume we study the interaction between A and B on D, where A, B and D are dichotomous. Steps (i) and (iii) are similar to present-ing effect modification. (ii) Present RRs, ORs or RDs for A within strata of B and for B within strata of A. (iv) List the A–D and B–D confounders adjusted for. These four pieces of information will provide a reader the informa-tion needed to assess effect modification or interaction. The pres-entation can be further enriched when exposures have multiple categories. Our proposal hopefully encourages researchers to present effect modification and interaction analyses in as informative a manner as possible...|$|R
40|$|Thoroughly updated {{and revised}} to {{emphasize}} the link between research and evidence-based practice, this Ninth Edition of a classic textbook presents state-of-the-art methods for conducting high-quality studies. The ancillary Resource Manual includes application exercises, models of comprehensive research critiques, a full NINR grant application, and a Toolkit on a CD-ROM, containing exemplary research tools (e. g., consent forms, a demographic questionnaire, statistical <b>table</b> <b>templates)</b> [...] all in easily-adapted Word documents. Griffith Health, School of Nursing and MidwiferyNo Full Tex...|$|R
40|$|The Workshop on Guidelines for Management Strategy Evaluations (WKGMSE) met 21 - 23 January in Copenhagen Denmark, The {{meeting was}} chaired by Dankert Skagen and John Simmonds, with 19 {{participants}} from 10 nations. The {{purpose of the}} meeting was to review and bring up to date the methodologies and tech-nical specifications that should be incorporated in MSE. The workshop also considered appro-priate risk definitions for MSE, taking into account practices in ICES and elsewhere and developed an updated set of guidelines for MSE evaluations in ICES. In order to review the methodologies and standards {{used in the past}} a summary template was prepared and circulated to participants. Eighteen MSEs were summarised using the template and reviewed at the workshop, these <b>template</b> <b>tables</b> are annexed to the report. Based on these reviews and the subsequent discussion the guidelines from SGMAS 2008 were revised at the workshop. A report evaluating the historic use of precautionary criteria used by ICES was prepared in advance of the meeting. This report is annexed to the report. The different precau-tionary criteria used for different MSEs were compared and following this the workshop rec-ommended revised criteria that are consistent with the ICES precautionary approach for stocks not subject to MSEs based on Blim and the 95 % biomass buffer Bpa. The workshop also includ-ed consideration of short lived species where the stocks may have greater than 5 % probability of being below Blim with zero fishery. The report describes first the review of past MSE work in Section 3 and then consideration of ICES standards for precautionary approach in Section 4. Based on these considerations revised guidelines for modelling and brief standards for reporting are provided, including a revised version of the reporting template to summarise the work. The main results of the workshop are the revised guidelines and recommendations for revision of ICES precautionary criteria for management plans...|$|R
40|$|This paper {{takes on}} an {{existing}} company {{that does not}} have a risk management system in place and attempts to implement it. The company is in the field of manufacturing red bricks. It is planning to expand to take the opportunity presented to it through the huge governmental investments occurring nowadays. The company managed to survive so far but it is tough times due to competition now and the company has to evaluate its options very carefully to succeed. In order to implement a useful Risk Management System, we have to implement different tools needed to support the risk management system such as the Work Breakdown Structure, Responsibility Interface Matrix, Critical Path Method, and Earned Value Analysis. Then we will describe the Risk Management System and provide the <b>templates</b> and <b>tables</b> to assist the project manager within the company to assess risks in an easy and effective manner...|$|R
40|$|All {{case reports}} must be {{submitted}} onlineusing this <b>template.</b> • <b>Tables,</b> images and multimedia files must be uploaded separately on submission. • Articles {{should be no}} more than 2, 000 words in length, and include a maximum of 10 references. • It is essential that you list the learning points of the case; these are the messages that readers should remember when dealing with their own patients. • You must have signed informed consent from patients (or relatives/guardians) prior to publication, using our consent form. If the patient is deceased, the consent form is not required. • Echo Research and Practiceis an open access publication. Expenses such as peer review systems, journal production, online hosting, marketing and archiving are covered by a publishing fee. The publishing fee will only become payable upon acceptance of a manuscript and needs to be paid for an article to proceed to publication. Accepted authors benefit from FREE publication if their articles are submitted in 2014...|$|R
40|$|We {{present a}} set of low {{resolution}} empirical SED templates for AGNs and galaxies in the wavelength range from 0. 03 to 30 microns based on the multi-wavelength photometric observations of the NOAO Deep-Wide Field Survey Bootes field and the spectroscopic observations of the AGN and Galaxy Evolution Survey. Our training sample is comprised of 14448 galaxies in the redshift range 0 ~ 3. 4. Comment: Accepted for publication in The Astrophysical Journal. 26 text pages + 3 tables + 20 figures, modified to include comments made by the referee. Fortran codes, <b>templates</b> and electronic <b>tables</b> available at [URL]...|$|R
30|$|The {{question}} generation method {{proposed in}} this paper may have drawbacks due to using question templates. That is, the question templates can be very specific for a special domain as discussed in Sect.  3. We were aware of this problem and tried to define question templates which should be general enough for several discussion domains. For example, the question <b>templates</b> in <b>Table</b> 3 {{can be used to}} generate questions for the discussion topic “charity” by replacing the placeholder: (1) What is charity? (2) What do you have in mind when you think about charity? (3) What does charity remind you of? These questions are appropriate for helping participants think about the topic when they have to discuss about charity. Whether all question templates are general enough for other discussion topics, this needs to be evaluated and is a part of our future work. Since the goal of our research is to support students during brainstorming argumentation activities, we also intend to conduct an empirical evaluation study for this purpose.|$|R
5000|$|Real estate {{appraisal}} in Germany {{is regulated}} by the federal Baugesetzbuch (abbr. BauGB, the German statutory code of building and construction). This federal law {{is supported by the}} Wertermittlungsverordnung (abbr. WertV, [...] "regulation on the determination of value"). The WertV defines the codified valuation approaches and the general valuation technique. WertV's general regulations are further supported by the Wertermittlungsrichtlinie (abbr. WertR, [...] "directive on the determination of value"). The WertR provides <b>templates</b> for calculations, <b>tables</b> (e. g. economic depreciation) and guidelines for the consideration of different influences. WertV and WertR are not binding for appraisals for non-official use, nonetheless they should be regarded as best practice or German Professional Appraisal Practice (PAP).|$|R
40|$|This article {{introduces}} TableMaker, a Microsoft Excel macro {{that produces}} publicationquality tables and includes them as new sheets in workbooks. The macro provides an intuitive {{graphical user interface}} that allows for the full customization of all table features. It also allows users to save and load <b>table</b> <b>templates,</b> and thus allows layouts to be both reproducible and transferable. It is distributed in a single computer file. As such, the macro is easy to share, as well as accessible to even beginning and casual users of Excel. Since it allows for the quick creation of reproducible and fully customizable tables, TableMaker can be very useful to academics, policy-makers and businesses by making the presentation and formatting of results faster and more efficient...|$|R
40|$|Traditionally, {{information}} extraction from web tables {{has focused on}} small, more or less homogeneous corpora, often based on assumptions {{about the use of}} tags. A multitude of different HTML implementations of web tables make these approaches difficult to scale. In this paper, we approach the problem of domain-independent {{information extraction}} from web tables by shifting our attention from the tree-based representation of web pages to a variation of the two-dimensional visual box model used by web browsers to display the information on the screen. The thereby obtained topological and style information allows us to fill the gap created by missing domain-specific knowledge about content and <b>table</b> <b>templates.</b> We believe that, in a future step, this approach can become the basis for a new way of large-scale knowledge acquisition from the current “Visual Web. ...|$|R
40|$|AbstractEnhancing {{the offer}} for {{entrepreneurship}} education {{is an important}} challenge for the nowadays knowledge societies. The eSG project is addressing this issue by analysing the added value that could be contributed by employing serious games (SGs) {{as a tool for}} allowing students – in particular technology students - to become familiar, mainly through practice, with basic concepts of entrepreneurship and company management. This paper presents the main requirements for the course and SGs obtained by surveying literature, entrepreneurs, students and teachers. We represented the requirements in a <b>table</b> <b>template</b> keeping into account usability, pedagogy, the entrepreneurship skills expressed by state of the art models and three major axes for entrepreneurship education at universities. These table descriptors were then used to assess validity of SGs and choose an appropriate mix for the courses. We have also defined a set of metrics to evaluate the advancement of students during the course. Based on these tools and knowledge, the next steps of the project will involve extensive user testing in the actual courses that are being performed in Genoa, Delft and Barcelona...|$|R
40|$|Progress {{in science}} {{depends on the}} {{effective}} exchange of ideas among scientists. New ideas can be assessed and criticized in a meaningful manner {{only if they are}} formulated precisely. This applies to simulation studies as well as to experiments and theories. But after more than 50 years of neuronal network simulations, we still lack a clear and common understanding of the role of computational models in neuroscience as well as established practices for describing network models in publications. This hinders the critical evaluation of network models as well as their re-use. We analyze here 14 research papers proposing neuronal network models of different complexity and find widely varying approaches to model descriptions, with regard to both the means of description and the ordering and placement of material. We further observe great variation in the graphical representation of networks and the notation used in equations. Based on our observations, we propose a good model description practice, composed of guidelines for the organization of publications, a checklist for model descriptions, <b>templates</b> for <b>tables</b> presenting model structure, and guidelines for diagrams of networks. The main purpose of this good practice is to trigger a debate about the communication of neuronal network models in a manner comprehensible to humans, as opposed to machine-readable model description languages. We believe that the good model description practice proposed here, together with a number of other recent initiatives on data-, model-, and software-sharing, may lead to a deeper and more fruitful exchange of ideas among computational neuroscientists in years to come. We further hope that work on standardized ways of describing [...] and thinking about [...] complex neuronal networks will lead the scientific community to a clearer understanding of high-level concepts in network dynamics, and will thus lead to deeper insights into the function of the brain...|$|R
40|$|Potential {{solutions}} to applied measurement problems are commonly evaluated using simulated data, largely {{because it is}} often impossible, difficult, or prohibitively expensive to supply the needed volumes of real data. However, answers proved by simulation studied generalize real-world problems {{only to the extent}} that the simulated data resembles the real thing. Research has suggested that in the case of generating item responses using traditional unidimensional, logistic response models, this resemblance is less than complete. While gross features of the data such as item passing rates, score distributions, and test reliabilities are modeled adequately, subtler characteristics of real data are often absent in simulation. Accordingly, high-dimensional simulation procedures have been developed that preserve the more subtle characteristics. The simulation process begins by fitting a multidimensional latent trait to a large sample of actual data. Estimated multidimensional item response functions are used to generate data by procedures directly analogoui to those used with unidimensional simulations. The procedure is illustrated with an English usage and a mathematics test as simulation <b>templates.</b> (Contains 1 <b>table,</b> 12 figures, and 18 references.) (Author/SLD) Reproductions supplied by EDRS are the best that can be made from the original document...|$|R
40|$|A huge {{discrepancy}} {{between theory and}} practice exists in one popular application area of functional programming [...] spreadsheets. Although spreadsheets are the most frequently used (functional) programs, few formal models of computation and type systems exist that would provide the foundation for creating reliable spreadsheets. Consequently, existing spreadsheets contain many errors, some of which have serious impacts. We argue in favor of creating a formal foundation for spreadsheets to help improve spreadsheet systems and make spreadsheets more reliable software assets. To this end, we have developed a table specification language that allows the definition of <b>table</b> <b>templates</b> that describe possible spreadsheet evolutions. This language is based on a table calculus that formally captures the process of creating and modifying spreadsheets. We have developed a type system for this calculus that can prevent type, reference, and omission errors from occurring in spreadsheets. On the basis of the table calculus we have developed Gencel, a system for generating reliable spreadsheets. We have implemented a prototype version of Gencel as an extension of Excel. A pilot study has indicated that the system is well accepted by end-user programmers...|$|R
40|$|ABSTRACT A new multibody, whole-residue {{potential}} for protein tertiary structure is described. The potential {{is based on}} the local environment surrounding each main-chain � carbon (CA), defined as the set of all residues whose CA coordinates lie within a spherical volume of set radius in 3 -dimensional (3 D) space surrounding that position. It is shown that the relative positions of the CAs in these local environments belong to a set of preferred templates. The templates are derived by cluster analysis of the presently available database of over 3000 protein chains (750, 000 residues) having not more than 30 % sequence similarity. For each template is derived also a set of residue propensities for each topological position in the <b>template.</b> Using lookup <b>tables</b> of these derived templates, it is then possible to calculate an energy for any conformation of a given protein sequence. The application of the potential to ab initio protein tertiary structure prediction is evaluated by performing Monte Carlo simulated annealing on test protein sequences. Proteins 2004; 00 : 000 – 000. © 2004 Wiley-Liss, Inc. Key words: packing motifs; structural motifs; multibody potentials; statistical potentials; simulated annealing; structure predictio...|$|R
40|$|Enhancing {{the offer}} for {{entrepreneurship}} education {{is an important}} challenge for the nowadays knowledge societies. The eSG project is addressing this issue by analysing the added value that could be contributed by employing serious games (SGs) {{as a tool for}} allowing students – in particular technology students - to become familiar, mainly through practice, with basic concepts of entrepreneurship and company management. This paper presents the main requirements for the course and SGs obtained by surveying literature, entrepreneurs, students and teachers. We represented the requirements in a <b>table</b> <b>template</b> keeping into account usability, pedagogy, the entrepreneurship skills expressed by state of the art models and three major axes for entrepreneurship education at universities. These table descriptors were then used to assess validity of SGs and choose an appropriate mix for the courses. We have also defined a set of metrics to evaluate the advancement of students during the course. Based on these tools and knowledge, the next steps of the project will involve extensive user testing in the actual courses that are being performed in Genoa, Delft and Barcelona. Multi Actor SystemsTechnology, Policy and Managemen...|$|R
40|$|Every day {{more and}} more users with {{different}} abilities and/or temporally or permanent disabilities are accessing the Web, {{and many of them}} have difficulties in reaching the desired information. However, the development of this kind of software is complicated for several reasons. Though some of them are technological, the majority are related with the need to compose different and, many times, unrelated design concerns which may be functional {{as in the case of}} most of the application’s requirements, or non-functional such as Accessibility. Even though, there is a huge number of tools and proposals to help developers assess Accessibility of Web applications, looking from the designer perspective, there is no such a similar situation. In this thesis, we present a novel approach to conceive, design and develop Accessible Web applications using concepts from Aspect-Orientation. In order to accomplish our goal, we provide some modeling techniques that we explicitly developed for handling the non-functional, generic and crosscutting characteristics of Accessibility. Specifically, we have enriched the UID technique with integration points to record Accessibility concerns that will be taken into account when designing the user interface. Then, by instantiating the SIG <b>template</b> with association <b>tables,</b> we work on an abstract interface model with Accessibility softgoals to obtain a concrete and accessible interface model for the Web application being developed. We explain deeply our ideas and point out the advantages of a clear separation of concerns throughout the development life-cycle. Thus, our proposal is based on recognized design techniques, which we embedded in a software tool to facilitate the transfer of the approach to the industry. Eje: Tesi...|$|R
