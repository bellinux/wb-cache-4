26|290|Public
50|$|Widespread {{fatigue damage}} (WFD) in a {{structure}} is characterised by the simultaneous presence of cracks at multiple points, {{that are of}} sufficient size and density such that, the structure will no longer meet its damage <b>tolerance</b> <b>requirement</b> and could fail. For example, small fatigue cracks developed along a row of fastener holes coalesce, this moves to adjacent sites and propagates. The objective of a designer is to determine when large numbers of small cracks could degrade the joint strength to an unacceptable level.|$|E
40|$|Abstract. The {{research}} actuality {{and development}} of roller module replacement technology are talked over in this paper. Positioning scheme of one plane and two pins with the special rounded edge diamond pin that is suitable for the longer roller is discussed, which is meeting the parallelism <b>tolerance</b> <b>requirement</b> for the roller within the full length; thus reducing manufacturing <b>tolerance</b> <b>requirement</b> for the spacing between pin axes and reducing manufacturing difficulty. And on this basis, adaptable interface design of roller module rapid replacement system which is suitable for the longer roller has been completed. The invention patent on the roller module rapid replacement system has already been applied for, and the precise positioning of roller module can be realized...|$|E
40|$|Nowadays, {{networked}} {{computers are}} present in most aspects of everyday life. Moreover, essential parts of society come to depend on distributed systems formed of networked computers, thus making such systems secure and fault tolerant is a top priority. If the particular fault <b>tolerance</b> <b>requirement</b> is high availability, replication of components is a natural choice. Replication is a difficult problem as {{the state of the}} replicas must be kept consistent even if some replicas fail, and because in distributed systems, relying on centralized control or a certain timing behavior is often not feasible...|$|E
40|$|Current design {{practices}} are described and future trends in spacecraft electronics which {{are likely to}} alter traditional approaches are discussed. A summary of radiation effects and radiation <b>tolerance</b> <b>requirements</b> typically levied on spacecraft designs is provided. Methods of dealing with radiation and testability issues are considered...|$|R
5|$|As {{the number}} of {{cavities}} {{play a vital role}} in moulding costs, so does the complexity of the part's design. Complexity can be incorporated into many factors such as surface finishing, <b>tolerance</b> <b>requirements,</b> internal or external threads, fine detailing or {{the number of}} undercuts that may be incorporated.|$|R
40|$|Fault {{tolerance}} is {{a constant}} concern in data centers where servers have to run with a minimal level of failures. Changes on the operating conditions or on server demands, and variations of the systems own failure rate have to be handled {{in such a way}} that SLAs are honored and services are not interrupted. We present an approach to handle fault <b>tolerance</b> <b>requirements,</b> based on component replication, which is supported by a context-aware infrastructure and guided by contracts that describe adaptation policies for each application. At run-time the infrastructure autonomically manages the deployment, the monitoring of resources, the maintenance of the fault <b>tolerance</b> <b>requirements</b> described in the contract, and reconfigures the application when necessary, to maintain compliance. An example with an Apache web server and replicated Tomcat servers is used to validate the approach...|$|R
40|$|Validated {{methods for}} initial value {{problems}} for ordinary differential equations produce bounds that {{are guaranteed to}} contain the true solution of a problem. When computing such bounds, these methods verify that a unique {{solution to the problem}} exists in the interval of integration and compute a priori bounds for the solution in this interval. A major difficulty in this verification phase is how to take as large a stepsize as possible, subject to some <b>tolerance</b> <b>requirement.</b> We propose a high-order enclosure method for proving existence and uniqueness of the solution and computing a priori bounds...|$|E
40|$|The {{research}} describes {{part of a}} "Pipeline of De-sign and Manufacturing Tools" for product de-signers who {{are driven}} by short delivery-times. The overall project has been called CyberCut be-cause the modules can interoperate in a distrib-uted, Internet-based environment. This particular paper focuses on tool path generation of sculp-tured surfaces using 3 -axis CNC machines. Im-portance is given to generating cutter location points that will meet the <b>tolerance</b> <b>requirement</b> while maintaining a certain surface finish. Sec-tions of the paper describe: a) the offset-generation method, b) the tool path generation scheme and c) the tool holder collision detection algorithm. The algorithms that have been devel-oped are used to machine sample parts...|$|E
30|$|In this work, {{topology}} optimization of considering the fault tolerance and network interference in WNMs was investigated. We proposed a fault-tolerance-and-interference-aware topology control (FICTC) algorithm for WNMs. We first analyzed the network performance under {{the requirement of}} k-connectivity. Then, the interference model and the problem formulation of improving the network performance for k-connectivity topology were presented. By the analysis of FICTC algorithm, we proved that FICTC not only meets the fault-tolerant requirement, but also minimizes the maximum node interference. Moreover, the distributed implementation of the proposed FICTC was proposed. The proposed FICTC algorithm {{plays an important role}} for improving network and fault tolerance performance in WNMs. We integrate the disjoint paths between any two nodes into {{topology optimization}} with fault <b>tolerance</b> <b>requirement.</b> For different fault <b>tolerance</b> <b>requirement,</b> graph-based simulations results indicated that FICTC outperforms the state-of-the-art fault-tolerant topology control algorithms in terms of average node degree, maximum transmit radius, and maximum link interference. Furthermore, the ns- 2 simulations showed FICTC achieves higher throughput and lower E 2 E delay. In term of energy consumption, we use the average expended energy ratio (EER) to evaluate the energy performance of our proposed FICTC. The result indicated the proposed FICTC achieve lower EER than other algorithms. These results demonstrate that the proposed solutions are promising for specific fault-tolerant requirement in practical network deployment. However, There are several problems for further research on fault-tolerance-and-interference-aware topology control. The proposed FICTC does not analyze the network performance of considering sophisticated model for the radio signal propagation. Moreover, the FICTC algorithm needs to deal with mobile WNMs. In future study, we plan to investigate the network performance for these problems.|$|E
50|$|A {{very similar}} engine {{developed}} for the United States Navy was the 540T. This engine used a welded block. The welded construction was required because the specified shock <b>tolerance</b> <b>requirements</b> prohibit the use of cast blocks. The Navy 540 was used in Patrol Boats, Mine Sweepers, Mine Layers, and tug boats.|$|R
40|$|The radar {{equation}} for laser ranging of satellites is described {{and the effect}} of the velocity aberration explained. Equations for the cross sections of cube corners and arrays of cube corners are derived. Interference effects on the distribution of the array cross section and upon range error are described. <b>Tolerance</b> <b>requirements</b> for cube corners are briefly outlined...|$|R
40|$|Increasingly Solid Freeform Fabrication (SFF) {{processes}} are {{being considered for}} creating functional parts. In such applications, SFF can either be used for creating tooling (i. e., patterns for casting, low volume molds, etc.) or directly creating the functional part itself. In order to create defect free functional parts, it is extremely important to fabricate the parts within allowable dimensional and geometric tolerances. This paper describes a systematic approach to analyzing manufacturability of parts produced using SFF processes with flatness <b>tolerance</b> <b>requirements</b> on the planar faces of the part. Our research is expected to help SFF designers and process providers in the following ways. By evaluating design tolerances against a given process capability, it will help designers in eliminating manufacturing problems and selecting the right SFF process for the given design. It will help process providers in selecting a build direction that can meet all design <b>tolerance</b> <b>requirements...</b>|$|R
40|$|An {{important}} {{investigation of}} time series involves searching for "movement" patterns, such as "going up" or "going down" or some combinations of them. Movement patterns {{can be in}} various scales: a large scale pattern may cover a long time period, while a small scale pattern usually covers a short time period. This paper considers such scale requirement. More specifically, a pattern {{is defined as a}} regular expression of letters, where each letter describes a movement direction and covers a specified length of time (called pattern unit length). To find if a time series (or a part of it) matches a pattern, the time series is first partitioned into consecutive sub-series of the unit length, and for each subseries, the direction of its best fitting line is taken as the movement direction of the sub-series if the distance between the best fitting line and the sub-series is within a specified tolerance (<b>tolerance</b> <b>requirement).</b> A direct implementation of pattern search will undoubtedly yield poor performance if the number of time series or the length of them is large. This paper introduces a pre-computation and indexing method to facilitate fast evaluation of pattern queries in user-specified scales. An efficient pre-computation algorithm is given to find the movement directions for all the sub-series that satisfy the <b>tolerance</b> <b>requirement.</b> Bounding triangles are used to represent clusters of sub-series. Relational database is then used to store these bounding triangles and relational operations are employed to facilitate the evaluation of pattern queries. The paper also reports some experiments performed on a real-life data set to show the efficiency and the scalability of the algorithms...|$|E
40|$|The GOL ASIC is a {{serializer}} chip {{developed by}} CERN {{based on a}} 0. 25 µm CMOS technology [1]. The GOL operates with two data rates: 800 Mbps and 1. 6 Gbps. This ASIC has been evaluated with radiation <b>tolerance</b> <b>requirement</b> for the ATLAS Inner Detector upgrade for the SLHC 1. A demo-link has been designed and constructed to read out silicon detectors in the test staves through fiber optics. Through this demo-link we plan to study system issues in a giga-bit optical link. This concept will be extended to future serializer ASICs like the GBTx and the LOC when they become available. Experience gained from these demo-links will help us design and build a reliable optical readout system for new ATLAS Inner Detector readout...|$|E
40|$|Most {{structures}} made of laminated {{polymer matrix}} composites (PMCs) must {{be designed to}} some damage <b>tolerance</b> <b>requirement</b> that includes foreign object impact damage. Thus {{from the beginning of}} a part s life, impact damage is assumed to exist in the material and the part is designed to carry the required load with the prescribed impact damage present. By doing this, some processing defects may automatically be accounted for in the reduced design allowable due to these impacts. This paper will present examples of how a given level of impact damage and certain processing defects affect the compression strength of a laminate that contains both. Knowledge of the impact damage tolerance requirements, before processing begins, can broaden material options and processing techniques since the structure is not being designed to pristine properties...|$|E
40|$|In {{this paper}} we show how an {{understanding}} of a dynamic system {{from the point of}} view of the tasks that it supports and {{an understanding of}} human error can guide a process of deriving human error <b>tolerance</b> <b>requirements.</b> Our aim is to provide a means whereby, rather than relying on training as a means of improving operator performance, designers may develop interactive systems with human error tolerance in mind. We extend an established methodology (SHARP) by employing a software engineering notation (CSP) that provides a bridge between a theory of error and the practice of design and implementation. In this paper we outline approaches to human error, describe a task notation based on CSP which helps us to elicit <b>requirements</b> on human-error <b>tolerance</b> expressed as functional properties of the system. The technique is used to analyse an engine fire recovery procedure in order to derive human error <b>tolerance</b> <b>requirements.</b> ...|$|R
40|$|A {{recently}} developed approach for pattern recognition using spatial filters with reduced <b>tolerance</b> <b>requirements</b> is employed for {{the generation of}} filters containing mainly phase information. As anticipated, the recognition levels were decreased, but they remain adequate for unambiguous identification together with appreciable amounts of distortion immunity. Furthermore, the information content of the filters is compatible with low devices like spatial light modulators...|$|R
40|$|Increasingly, Solid Freeform Fabrication (SFF) {{processes}} are {{being considered for}} creating functional parts. In such applications, SFF can either be used for creating tooling (i. e., patterns for casting, low volume molds, etc.) or directly creating the functional part itself. In order to create defect free functional parts, it is extremely important to fabricate the parts within allowable dimensional and geometric tolerances. This paper describes a systematic approach to analyzing manufacturability of parts produced using SFF processes with flatness <b>tolerance</b> <b>requirements</b> on the planar faces of the part. Our research is expected to help SFF designers and process providers in the following ways. By evaluating design tolerances against a given process capability, it will help designers in eliminating manufacturing problems and selecting the right SFF process for the given design. It will help process providers in selecting a build direction that can meet all design <b>tolerance</b> <b>requirements.</b> �DOI: 10. 1115 / 1. 1326439 �...|$|R
40|$|Abstract. This paper {{presents}} a generic precision optimisation methodology for quadrature computation targeting reconfigurable hardware to maximise performance {{at a given}} error tolerance level. The proposed methodology optimises performance by considering integration grid density versus mantissa size of floating-point operators. The optimisation provides the number of integration points and mantissa size with maximised throughput while meeting given error <b>tolerance</b> <b>requirement.</b> Three case {{studies show that the}} proposed reduced precision designs on a Virtex- 6 SX 475 T FPGA are up to 6 times faster than comparable FPGA designs with double precision arithmetic. They are up to 15. 1 times faster and 234. 9 times more energy efficient than an i 7 - 870 quadcore CPU, and are 1. 2 times faster and 42. 2 times more energy efficient than a Tesla C 2070 GPU. ...|$|E
40|$|In the {{application}} of photoacoustic human infant brain imaging, debubbled ultrasound gel or water is commonly used as a couplant for ultrasonic transducers due to their acoustic properties. The main challenge in using such a couplant is its discomfort for the patient. In this study, we explore the feasibility of a semi-dry coupling configuration {{to be used in}} photoacoustic computed tomography (PACT) systems. The coupling system includes an inflatable container consisting of a thin layer of Aqualene with ultrasound gel or water inside of it. Finite element method (FEM) is used for static and dynamic structural analysis of the proposed configuration to be used in PACT for infant brain imaging. The outcome of the analysis is an optimum thickness of Aqualene {{in order to meet the}} weight <b>tolerance</b> <b>requirement</b> with the least attenuation and best impedance match to recommend for an experimental setting...|$|E
40|$|This paper {{demonstrates}} the progressive failure analysis capability in NASA Langley's COMET-AR {{finite element analysis}} code on a large-scale built-up composite structure. A large-scale five stringer composite panel with a 7 -in. long discrete source damage was analyzed from initial loading to final failure including the geometric and material nonlinearities. Predictions using different mesh sizes, different saw cut modeling approaches, and different failure criteria were performed and assessed. All failure predictions have a reasonably good correlation with the test result. Introduction For composite material to be successfully used in primary aircraft structures such as wings and fuselages, one of the design requirements is a two-bay crack damage tolerance capability. The two-bay crack, representing a discrete source damage caused by fragments from a failed engine, spans from one bay to the other bay and severs one stiffener. To meet the damage <b>tolerance</b> <b>requirement,</b> this two-bay dam [...] ...|$|E
40|$|The hybrid {{proximal}} point algorithm {{introduced by}} Solodov and Svaiter allowing significant relaxation of the <b>tolerance</b> <b>requirements</b> {{imposed on the}} solution of proximal subproblems will be combined with the inertial method introduced by Alvarez and Attouch which incorporates second order information to achieve faster convergence. The weak convergence of the resulting method will be investigated for finding zeroes of a maximal monotone operator in a Hilber...|$|R
50|$|The {{assembly}} tolerances {{were very}} tight and required {{state of the}} art use of metrology systems including Laser Tracker and photogrammetry equipment. $50 million of additional funding was needed, spread over the next 3 years, to complete the assembly within <b>tolerance</b> <b>requirements.</b> Components for the Stellarator were measured with 3d laser scanning, and inspected to design models at multiple stages in the manufacturing process.|$|R
40|$|A new SIMD {{parallel}} algorithm {{to extract}} a Boundary representation from Classical Octrees is presented. The algorithm {{makes use of}} a Geometrically Deformed Model (GDM) to smooth an initial naive polygonization. The GDM used is profited as well to compute a Face Octree from the raw data. The smoothed verbose polygonization and the Face Octree are combined to obtain a more concise boundary representation within <b>tolerance</b> <b>requirements.</b> Postprint (published version...|$|R
40|$|This {{investigation}} {{presents a}} novel method of image processing using the polynomial bidirectional hetero-associative network (PBHAN). This network {{can be used}} for industrial application of optical character recognition. According to the results of detailed simulations, the PBHAN has a higher capacity for pattern pair storage than do the conventional bidirectional associative memories and fuzzy memories. The practical capacity of a PBHAN considering fault tolerance is discussed. The fault <b>tolerance</b> <b>requirement</b> leads to the discovery of the attraction radius of the basin for each stored pattern pair. PBHAN takes advantage of fuzzy characteristics in evolution equations such that the signal-noise-ratio is significantly increased. In this work, we apply the result of this research to pattern recognition problems. The practical capacity of fuzzy data recognition using PBHAN and considering fault tolerance in the worst case is also estimated. Simulation results are presented to verify the derived theory. Keyworks: associative networks, optical character recognition, fuzzy data, neural networks, PBHAN 1...|$|E
40|$|Abstract: This paper {{integrates}} {{energy management}} with fault tolerance for real time systems. A typical system {{composed of a}} processor (frequency dependent) and peripheral devices (frequency independent) when operates in harsh environmental conditions may collapse due to occurrence of transient faults or shortage of battery backup. The fault tolerance is achieved via checkpointing while dynamic voltage scaling, dynamic power down and preemption control techniques are used to improve the battery life. We adopt a two phase approach. In the first phase, we estimate a critical speed which effectively balances the fault <b>tolerance</b> <b>requirement</b> and the energy consumed by both the associated frequency dependent and independent devices. The Phase- 1 uses energy aware greedy based speed assignment technique to assign the speeds to each task such that the task set is feasible with low enenergy requirement. The second phase further, reduces energy consumption by preemption control technique. The simulations results illustrate that our proposed approach provides better tolerance to faults where existing approaches fail to survive and still consume lesser energy...|$|E
40|$|Abstract. Computer aided process {{planning}} is the bridge between CAD and CAM. Setup planning {{is the major}} key to transform design concept into manufacturing domain, which is mainly experience based activity in modern manufacturing industry. Setup planning is a complicated non-linear task constrained by many factors such as tool approach direction, geometric feature relationship, fixturing constraint, <b>tolerance</b> <b>requirement</b> and manufacturing practice. Setup planning identifies which features must be machined in each setup and determines locating datum for each setup. This paper focuses {{on the development of}} a formalized procedure for automatic generation of feasible setups. For preventing of tolerance stack-up tried to use datum face as reference plane in fixture design. So, this paper presents a new method for setup planning with accurate respect to datum faces in design and machining. For the proposed work the authors have introduced two concepts namely, “inferiority face ” and “control face”. A rule-based procedure in several steps is used for solving the problem. The system is developed in Visual Basic on a Solid Works platform. Trial runs with industrial parts indicate that the system is applicable for industrial use...|$|E
40|$|International audienceThe hybrid {{proximal}} point algorithm {{introduced by}} Solodov and Svaiter allowing significant relaxation of the <b>tolerance</b> <b>requirements</b> {{imposed on the}} solution of proximal subproblems will be combined with the inertial method introduced by Alvarez and Attouch which incorporates second order information to achieve faster convergence. The weak convergence of the resulting method will be investigated for finding zeroes of a maximal monotone operator in a Hilbert space...|$|R
40|$|International audienceHighly {{individualized}} and customized {{products with}} dynamic lifecycles increase {{the need for}} flexible and reconfigurable assembly systems. Industrial robots are a key technology for future production systems especially for large scale components. The trade off between increasing work piece dimensions and constant or even increasing <b>tolerance</b> <b>requirements,</b> that are in some cases comparable to micro assembly systems, has to be solved by flexible and precise manufacturing and fixtureless assembly processes...|$|R
40|$|ABSTRACT. The hybrid {{proximal}} point algorithm {{introduced by}} Solodov and Svaiter allowing significant relaxation of the <b>tolerance</b> <b>requirements</b> {{imposed on the}} solution of proximal subproblems will be combined with the inertial method introduced by Alvarez and Attouch which incorporates second order information to achieve faster convergence. The weak convergence of the resulting method will be investigated for finding zeroes of a maximal monotone operator in a Hilbert space...|$|R
40|$|To {{guarantee}} the high stability and high precision of an off-axis thee-mirror optical system space camera, a integration front frame structure {{was designed to}} support the second mirror and folded mirror according to {{the characteristics of the}} same height of second mirror and folded mirror in optical axis direction, and a topology optimization method based on constraint mode and free mode was proposed to optimize the front frame structure. Then, the integrated structure was assembled into the entire camera after optimization, and the finite element analysis of static was carried out. The results show that the camera maintains excellent static performance with the optical tilt between the primary mirror and secondary mirror being less than 9 ″ and the optical tilt between the primary mirror and fold mirror being less than 22. 4 ″, the optical eccentricity between the primary mirror and secondary mirror being less than 0. 021 mm, meeting the <b>tolerance</b> <b>requirement</b> of system. By free modal analysis and test to the integrated front frame structure, the results verify the correctness of the design method. The proposed topology optimization method can efficient avoid the defect of topology optimization based on constraint modal frequency that there is no relationship between the constraint points. It can provide reference for design the space camera with high-resolution and wide field. © 2017, Science Press. All right reserved. </p...|$|E
40|$|Most {{design of}} {{experiments}} assumes predetermined design regions. Design regions with uncertainty are {{of interest in the}} first chapter. This chapter proposes optimal designs under a two-part model to handle the uncertainty in the design region. In particular, the logit model in the two-part model is used to assess the uncertainty on the boundary of the design region. The second chapter proposes an efficient and effective multi-layer data collection scheme (Layers of Experiments) for building accurate statistical models to meet tight <b>tolerance</b> <b>requirement</b> commonly encountered in nano-fabrication. "Layers-of-Experiments" (LOE) obtain sub-regions of interest (layer) where the process optimum is expected to lie and collect more data in the sub-regions with concentrated focus. The third chapter contributes a new design criterion combining model-based optimal design and model-free space-filling design in a constraint manner. The proposed design is useful when the fitted statistical model is required to have both characteristics: accuracy in statistical inference and design space exploration. The fourth chapter proposes adaptive combined designs in the layers of experiments. This chapter also develops methods to improve model quality by combining information from various layers and from engineering models. Combined designs are modified to improve its efficiency by incorporate collected field data from several layers of experiments. Updated engineering models are used to build more accurate statistical models. PhDCommittee Chair: Lu, Jye-Chyi; Committee Co-Chair: Grover, Martha; Committee Member: Jeong, Myong K.; Committee Member: Mei, Yajun; Committee Member: Shi, Jianju...|$|E
40|$|The {{first chapter}} proposes multifractal {{analysis}} to measure inhomogeneity of regularity of 1 H-NMR spectrum using wavelet-based multifractal tools. The geometric summaries of multifractal spectrum are informative summaries, {{and as such}} employed to discriminate 1 H-NMR spectra associated with different treatments. The methodology is applied to evaluate the effect of sulfur amino acids. The second part of this thesis provides essential materials for understanding engineering background of a nano-particle fabrication process. The third chapter introduces a constrained random effect model. Since there are certain combinations of process variables resulting to unproductive process outcomes, a logistic model is used to characterize such a process behavior. For the cases with productive outcomes a normal regression serves {{the second part of}} the model. Additionally, random-effects are included in both logistics and normal regression models to describe the potential spatial correlation among data. This chapter researches a way to approximate the likelihood function and to find estimates for maximizing the approximated likelihood. The last chapter presents a method to decide the sample size under multi-layer system. The multi-layer is a series of layers, which become smaller and smaller. Our focus is to decide the sample size in each layer. The sample size decision has several objectives, and the most important purpose is the sample size should be enough to give a right direction to the next layer. Specifically, the bottom layer, which is the smallest neighborhood around the optimum, should meet the <b>tolerance</b> <b>requirement.</b> Performing the hypothesis test of whether the next layer includes the optimum gives the required sample size. PhDCommittee Chair: Brani Vidakovic; Committee Chair: Jye-Chyi (JC) Lu; Committee Co-Chair: Martha Grover; Committee Member: Jianjun Shi; Committee Member: Kamran Paynaba...|$|E
40|$|In {{this paper}} we discuss on planar polylines and their inflections. This work derives from our {{interest}} in {{the problem of the}} fairing modification of a polyline curve whose movement is constrained by some <b>tolerance</b> <b>requirements.</b> We are interested in finding out the minimum number of inflections in a polyline satisfying those requirements. We introduce some new definitions and provide some results on the subject. Postprint (published version...|$|R
40|$|This paper {{describes}} {{the design and}} realization of a transition from a microstrip line to a ridge gap waveguide operating between 95 and 115 GHz. The study includes simulations, measurements, and a Monte Carlo analysis of the assembly tolerances. The purpose of this tolerance study is to identify the most critical misalignments that affect the circuit performance and to provide guidelines about the assembly <b>tolerance</b> <b>requirements</b> for the proposed transition design...|$|R
40|$|Physarum polycephalum, a true slime mould, is a primitive, {{unicellular}} organism {{that creates}} networks to transport nutrients while foraging. The design of these natural networks {{proved to be}} advanced, e. g. the slime mould {{was able to find}} the shortest path through a maze. The underlying principles of this design have been mathematically modelled in literature. As in real life the slime mould can design fault tolerant networks, its principles {{can be applied to the}} design of man-made networks. In this paper, an existing model and algorithm are adapted and extended with stimulation and migration mechanisms which encourage formation of alternative paths, optimize edge positioning and allow for automated design. The extended model can then be used to better design fault tolerant networks. The extended algorithm is applied to several national and international network configurations. Results show that the extensions allow the model to capture the fault <b>tolerance</b> <b>requirements</b> more accurately. The resulting extended algorithm overcomes weaknesses in geometric graph design and can be used to design fault tolerant networks such as telecommunication networks with varying fault <b>tolerance</b> <b>requirements...</b>|$|R
