0|8063|Public
5000|$|... expressing disgust at {{the child}} <b>through</b> {{gestures}} <b>or</b> <b>facial</b> expressions ...|$|R
40|$|The {{biometric}} identifier relies {{on an individual}} 2 ̆ 7 s unique biological information such as a hand, iris, fingerprint, <b>facial</b> <b>or</b> <b>voice</b> print. When used for verification purposes, a 2 ̆ 2 one-to-one 2 ̆ 2 match is generated in under one second. Biometric technology can substantially improve national security by identifying and verifying individuals {{in a number of}} different contexts, providing security in ways that exceed current identification technology and limiting access to areas where security breaches are especially high, such as airport tarmacs and critical infrastructure facilities. At the same time, a legitimate public concern exists concerning the misuse of biometric technology to invade or violate personal privacy...|$|R
40|$|Following a {{multidisciplinary}} perspective (that combines the literature from management, information systems, marketing and engineering telecommunications perspectives), {{the purpose of}} this article is to create and analyze a conceptual framework and to propose a new methodology that encompasses different techniques for pervasive information gathering in hotels and for identifying clients’ habits. Focusing on the future of hotels, this work presents new technologies for hotels suitable for correlating the customers’ on-site activities with online activities including passive location tracking using Wi-Fi devices’ connectivity, customer satisfaction evaluated via <b>facial</b> <b>or</b> <b>voice</b> recognition using inbuilt cameras/microphones altogether with data mining analysis. Moreover, this article explains how multidisciplinary consumer behavior can be analyzed by data mining to include this information in the vacation marketing approach for efficient business administration. The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This research work was supported by Universitat Polite`cnica de Vale`ncia 10. 13039 / 501100004233 PAID- 10 - 14...|$|R
50|$|Valence {{could be}} {{assigned}} a number and {{treated as if}} it were measured, but the validity of a measurement based on a subjective report is questionable. Measurement based on observations of facial expressions, using the Facial Action Coding System and microexpressions (see Paul Ekman) or muscle activity detected <b>through</b> <b>facial</b> electromyography, <b>or</b> on modern functional brain imaging may overcome this objection. Emotional valence is represented in right posterior superior temporal sulcus and medial prefrontal cortex.|$|R
5000|$|Two subtypes are {{distinguished}} behaviorally {{as being}} associative or apperceptive in nature. Associative prosopagnosia {{is characterized by}} an impairment in recognition of a familiar face as familiar; however, individuals retain the ability to distinguish between faces based on general features, such as, age, gender and emotional expression. [...] This subtype is distinguished <b>through</b> <b>facial</b> matching tasks <b>or</b> feature identification tasks of unknown faces.|$|R
40|$|This thesis {{considers}} infant {{social development}} {{from the viewpoint}} of the perceptual and memory capacities necessary for particular social abilities. Some social abilities, e. g. <b>facial</b> <b>or</b> <b>voice</b> discrimination, require visual or auditory integrity, thus the development of visual and auditory capacities are reviewed. Recognition of familiar faces and/or voices requires memory. Hence the development of memory abilities is considered. Subsequently the development of social behaviour is reviewed. After these literature reviews, three experimental studies are described. The first of these investigates the recognition of mother's voice and reports evidence of that such recognition develops during the first month of life. The second experiment considers visual recognition of the mother and differential responsivity to face-to-face and averted gaze and to different tones of voice. One month old infants did not reveal any conclusive evidence on these points. However, post-hoc analysis suggested the importance of the physical characteristics of faces in eliciting infant visual attention. Experience in these studies suggested the need for the study of more naturalistic encounters and hence a methodology for the study and analysis of naturalistic social interactions was developed. This methodology was then applied to a study of interactions between mothers and strangers with infants seen from one to eight months of age. This study revealed a surprising developmental pattern of differentiation between mother and stranger, with an unexpected period of positive responsiveness to strangers occurring at five months of age. The sequential analysis of interactions revealed evidence of a progressive development of infant receptivity to gaze, and also an exploratory analysis of receptivity to adult smiles and vocalizations suggested infants may respond to these adult behaviours. Subsequently the results of these studies are linked to other recent research. <p...|$|R
5000|$|Most teams {{communicate}} <b>through</b> body <b>or</b> <b>facial</b> signals {{as a way}} {{of making}} their parters aware of their hands without having to show it to everyone at the table. The signals for each trump card are standard among most players, making it easy for new teammates {{to communicate with each other}} without previously defining signals, although long-time partners usually develop their own unique signals. The standard signals are the following: ...|$|R
40|$|Although {{psychological}} {{research indicates}} that bodily expressions convey important affective information, to date research in emotion recognition focused mainly on <b>facial</b> expression <b>or</b> <b>voice</b> analysis. In this paper we propose an approach to realtime automatic emotion recognition from body movements. A set of postural, kinematic, and geometrical features are extracted from sequences 3 D skeletons and fed to a multi-class SVM classifier. The proposed method has been assessed on data acquired through two different systems: a professionalgrade optical motion capture system, and Microsoft Kinect. The system has been assessed on a "six emotions" recognition problem, and using a leave-one-subject-out cross validation strategy, reached an overall recognition rate of 61. 3 % which {{is very close to}} the recognition rate of 61. 9 % obtained by human observers. To provide further testing of the system, two games were developed, where one or two users have to interact to understand and express emotions with their body...|$|R
40|$|The {{obstetrical}} {{population is}} prone to difficult or failed intubation. Control of the airway is complicated by several factors specific to obstetric anesthesia: time of apnea is short due to a reduced functional residual capacity and pregnancy-induced hypertension and obesity are relatively frequent; anesthetist's skill can also be mentioned. The best approach to this problem lies in its prevention, using epidural analgesia as soon as possible. Furthermore, the number of difficult intubations can be considerably reduced by a thorough pre-anesthetic examination. Each anesthetist must keep an algorithm in mind, should a difficult or failed intubation in obstetrical patient occur. Whichever method is used (ventilation <b>through</b> a <b>facial</b> mask <b>or</b> laryngeal mask, transtracheal oxygenation), the anesthetist must never forget that the first priority is always {{the safety of the}} mother...|$|R
40|$|Objective. To {{optimize}} {{the results of}} treatment in patients with acute respiratory failure (ARF) due to lung contusion, by using the methods of non-invasive mask respiratory support. Materials and methods. The study covered 31 patients with severe blunt chest injury, multiple costal fractures, and hypoxemic ARF. The patients underwent assisted ventilation (AV) in the CPAP+PSV mode <b>through</b> a <b>facial</b> <b>or</b> nasal mask. Physiological parameters were recorded during non-invasive mask ventilation (NIMV) in the stepwise fashion. A control group comprised 25 patients with the similar severity of injury and ARF who were given conventional AV. Results. In 67. 7 % of the study group patients, NIMV was effective in improving oxygenation and external respiration, without exerting negative hemodynamic effects. Endotracheal intubation and AV could be avoided in these patients. Comparison {{of the study and}} control groups revealed a significant reduction in the incidence of secondary pneumonias in the NIMV group and in the duration of treatment. Mask ventilation could decrease mortality from 44 % in the control group to 9. 7 % in the NIMV group. Conclusion. NIMV applied to patients with hypoxemic ARF in the presence of lung contusion improves pulmonary function and, in the bulk of patients, allows endotracheal intubation and AV and consequently their associated complications. When mask ventilation is employed, management of patients becomes shorter and simpler and mortality rates substantially decrease.  </p...|$|R
3000|$|When {{it comes}} to the {{formation}} of the child’s superego, {{there are two kinds of}} reward and punishment, psychological or physical. In respect to the psychological, this may relate to withholding approval or in the child’s mind the withdrawal of love. For example, one may point to the disapproval of the parent, or the emotional rejection of the child by the parent <b>through</b> words <b>or</b> <b>facial</b> expressions (Freud, [2003], pp. 124 – 143). With regard to the physical, this may be demonstrated by an actual spanking or by taking away the things that the child might want (deprivation, acts of denial or aggressiveness) (Freud, [2003], pp. 124 – 143). Freud claims: [...]...|$|R
40|$|Abstract—Awareness of {{the emotion}} of those who {{communicate}} with others is a fundamental challenge in building affective intelligent systems. Emotion is a complex state of the mind influenced by external events, physiological changes, or relationships with others. Because emotions can represent a user’s internal context or intention, researchers suggested various methods to measure the user’s emotions from analysis of physiological signals, <b>facial</b> expressions, <b>or</b> <b>voice.</b> However, existing methods have practical limitations {{to be used with}} consumer devices, such as smartphones; they may cause inconvenience to users and require special equipment such as a skin conductance sensor. Our approach is to recognize emotions of the user by inconspicuously collecting and analyzing user-generated data from different types of sensors on the smartphone. To achieve this, we adopted a machine learning approach to gather, analyze and classify device usage patterns, and developed a social network service client for Android smartphones which unobtrusively find various behavioral patterns and the current context of users. Also, we conducted a pilot study to gather real-world data which imply various behaviors and situations of a participant in her/his everyday life. From these data, we extracted 10 features and applied them to build a Bayesian Network classifier for emotion recognition. Experimental results show that our system can classify user emotions into 7 classes such as happiness, surprise, anger, disgust, sadness, fear, and neutral with a surprisingly high accuracy. The proposed system applied to a smartphone demonstrated the feasibility of an unobtrusive emotion recognition approach and a user scenario for emotion-oriented social communication between users. Index Terms—Affective computing, Computer mediate...|$|R
40|$|Emotions {{are defined}} as a mental state that occurs instinctively rather than through {{voluntary}} effort. They are strong feelings triggered by experiencing the joy, hate, fear, love and is followed by some physiological changes. Emotions {{play a vital role}} in social interactions and facilitate the decision making and perception in human being. Emotions are conveyed <b>through</b> speech, <b>facial</b> expression <b>or</b> by physiological signals. There are 6 emotions which are treated as universal emotions: anger, happiness, sadness, disgust, surprise and fear. This paper projects different emotion recognition systems which aim at enhancing the Human-Machine interaction. The techniques and systems used in emotion detection may vary depending on the features inspected. This paper explores them in a descriptive and comparative manner. Further the various applications that adopt these systems to reduce the difficulties in implementing the models in real-time are contemplated. Also, A multimodal system with both speech and facial features is proposed for emotion recognition through which it is possible to obtain an enhanced accuracy compare with the existing systems. </p...|$|R
40|$|International {{audience}} Information on a customer’s emotional states {{concerning a}} product or an advertisement {{is a very important}} aspect of marketing research. Most studies aimed at identifying emotions <b>through</b> speech <b>or</b> <b>facial</b> expressions. However, these two vary greatly with people’s talking habits, which cause the data lacking continuous availability. Furthermore, bio-signal data is also required in order to fully assess a user’s emotional state in some cases. We focused on recognising the six basic primary emotions proposed by Ekman using biofeedback sensors, which measure heart rate and skin conductance. Participants were shown a series of 12 video-based stimuli that have been validated by a subjective rating protocol. Experiment results showed that the collected signals allow us to identify user's emotional state with a good ratio. In addition, a partial correlation between objective and subjective data has been observed</p...|$|R
5000|$|Expressive behaviors. Emotion is communicated <b>through</b> <b>facial</b> {{and bodily}} expressions, {{postural}} and voice changes.|$|R
50|$|Most of {{the major}} {{characters}} are portrayed as animals <b>through</b> <b>facial</b> and body gestures, {{as well as their}} speech.|$|R
40|$|People {{naturally}} {{express themselves}} <b>through</b> <b>facial</b> gestures. We have implemented an interface that tracks a person's facial features robustly {{in real time}} (30 Hz) and does not require artificial artifacts such as special illumination <b>or</b> <b>facial</b> makeup. Even if features become occluded the system is capable of recovering tracking {{in a couple of}} frames after the features reappear in the image. Based on this fault tolerant face tracker we have implemented realtime gesture recognition capable of distinguish 12 different gestures ranging from &quot;yes&quot;, &quot;no&quot; and &quot;may be &quot; to winks, blinks and &quot;asleep&quot;. ...|$|R
5000|$|Headache <b>or</b> <b>facial</b> <b>or</b> neck pain {{attributed}} to arterial dissection ...|$|R
5000|$|... #Caption: In his 16th-century {{portrait}} of an unidentified man, Albrecht Dürer powerfully captures personality <b>through</b> <b>facial</b> expression, body language, and clothing. Work: Bildnis eines unbekannten Mannes (1521) ...|$|R
5|$|Typical {{attachment}} development {{begins with}} unlearned infant reactions to social signals from caregivers. The ability to {{send and receive}} social communications <b>through</b> <b>facial</b> expressions, gestures and voice develops with social experience by seven to nine months. This {{makes it possible for}} an infant to interpret messages of calm or alarm from face <b>or</b> <b>voice.</b> At about eight months, infants typically begin to respond with fear to unfamiliar or startling situations, and to look to the faces of familiar caregivers for information that either justifies or soothes their fear. This developmental combination of social skills and the emergence of fear reactions results in attachment behavior such as proximity-seeking, if a familiar, sensitive, responsive, and cooperative adult is available. Further developments in attachment, such as negotiation of separation in the toddler and preschool period, depend on factors such as the caregiver's interaction style and ability to understand the child's emotional communications.|$|R
50|$|Actors Norman Reedus and Mads Mikkelsen will portray leading {{characters}} in the game, <b>through</b> motion capture, <b>facial</b> scanning, and vocal performance; director Guillermo del Toro will also contribute his likeness to another character <b>through</b> <b>facial</b> and body scanning. The game's title is {{a reference to the}} cetacean stranding phenomenon.|$|R
2500|$|Class V – {{cervical}} {{third of}} <b>facial</b> <b>or</b> lingual surface of tooth ...|$|R
50|$|Seven basic {{emotions}} are communicated <b>through</b> <b>facial</b> expression: anger, fear, sadness, joy, disgust, surprise and contempt. These {{emotions are}} recognized universally. These expressions are innate of develop through socialization.|$|R
5000|$|No speech, <b>facial</b> <b>or</b> bodily {{movements}} {{except when}} {{as required by}} military drill.|$|R
5000|$|... #Subtitle level 4: ICHD 11, ICD10 G44.84: Headache <b>or</b> <b>facial</b> pain {{attributed}} to disorder of cranium, neck, eyes, ears, nose, sinuses, teeth, mouth <b>or</b> other <b>facial</b> <b>or</b> cranial structures ...|$|R
5000|$|Peeling (French, Romanian, German, Russian, Polish, Portuguese, Serbo-Croatian, Spanish, Swedish) - <b>facial</b> <b>or</b> body scrub ...|$|R
40|$|Treballs Finals de Grau d'Enginyeria Informàtica, Facultat de Matemàtiques, Universitat de Barcelona, Any: 2014, Director: Lluís Garrido OstermannFew {{years ago}} the {{computer}} vision was relegated to research, education and industry areas, {{but in recent years}} it has been approaching to the common user. Some new technological developments such as the Microsoft Kinect sensor, the Android smartphones unlocking system <b>through</b> <b>facial</b> recognition <b>or</b> the capacity to read road signs that were introduced in some new car are some examples of the introduction of the computer vision into the daily routine of the common user. This project aims to contribute to this introduction of the computer vision by developing a mobile application for the mobile operating system Android using computer vision. The main objective of this application is to create a platform game where the user can draw on paper the desired screen beforehand, then make photography and finally play it on his mobile device. The application uses latest software such as the development environment and language Processing and the development environment Eclipse. The game performance begins with the user drawing the desired screen {{on a piece of paper}} and using different colours to identify the different game concepts such as walls and floor, the starting point for the player in the game, the final position where the game ends and some obstacles that can kill the player. Then the user takes a picture of the drawn screen with the device camera and the picture is processed. After that the system analyzes the colours painted by the user throughout the HSV colour model in order to interpret what kind of game element is each colour and the location of each element. These saved locations create a new game screen placing the elements where the user has indicated in his paper and finally the user can play his own screen. This project uses the Java programming language and the Eclipse environment with the plugging ADT (Android Developer Tools) to develop all the code for the image processing and the colour identification of the elements of the game. It has uses language and environment Processing to develop all the construction and the generation of the game based on the picture taken by the user...|$|R
50|$|Class V Caries {{affecting}} gingival 1/3 of <b>facial</b> <b>or</b> lingual {{surfaces of}} anterior or posterior teeth.|$|R
25|$|Since her discovery, {{the girl}} was reconstructed forensically in efforts to {{identify}} her <b>through</b> <b>facial</b> recognition. The National Center for Missing & Exploited Children has released two illustrations and other artists have produced their own renderings.|$|R
50|$|Among the signs/symptoms of {{arteriosclerosis}} are: sudden weakness, <b>facial</b> <b>or</b> lower limbs numbness, confusion, difficulty understanding {{speech and}} problems seeing.|$|R
25|$|Lie to Me, a TV series {{based on}} {{behavior}} analysts who read lies <b>through</b> <b>facial</b> expressions and body language. The protagonists, Dr. Cal Lightman and Dr. Gillian Foster {{are based on}} the above-mentioned Dr. Paul Ekman and Dr. Maureen O'Sullivan.|$|R
50|$|NIGERIA • Afrique Organization Amazon of Light Award: This {{award was}} given to Modupe Ozolua for her {{outstanding}} effort and encouragement of indigent young people in Nigeria by giving hope to deformed young people <b>through</b> <b>facial</b> and body reconstructive surgeries.|$|R
5000|$|Lie to Me, a TV series {{based on}} {{behavior}} analysts who read lies <b>through</b> <b>facial</b> expressions and body language. The protagonists, Dr. Cal Lightman and Dr. Gillian Foster {{are based on}} the above-mentioned Dr. Paul Ekman and Dr. Maureen O'Sullivan.|$|R
50|$|Facial coding is {{the process}} of {{measuring}} human emotions <b>through</b> <b>facial</b> expressions. Emotions can be detected by computer algorithms for automatic emotion recognition that record facial expressions via webcam. This can be applied to better understanding of people’s reactions to visual stimuli.|$|R
50|$|In Bedtime for Sniffles, for example, {{he struggles}} to stay awake into the wee hours on Christmas Eve in order to glimpse Santa Claus (which of course never happens). This scene is a {{showcase}} for Jones' facility of realizing character <b>through</b> <b>facial</b> expression.|$|R
50|$|Christian Copelin (born 23 February 1990) is an American former child actor {{best known}} for his role as Lanny Onasis, in Disney's comedy show Lizzie McGuire. He {{appeared}} in 21 episodes. His character, Lanny Onasis, only expressed himself <b>through</b> <b>facial</b> gestures and body language.|$|R
