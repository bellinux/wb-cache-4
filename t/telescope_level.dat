9|41|Public
50|$|The builder's {{level is}} {{sometimes}} {{mistaken for a}} transit theodolite, but it measures neither horizontal nor vertical angles. It uses a spirit level to set a <b>telescope</b> <b>level</b> to define a line of sight along a horizontal plane.|$|E
50|$|Microlensing {{events with}} medium {{aperture}} telescopes are discovered primarily through observatories and typically require a heftier computer system and observation team. The basic {{set up and}} data requirements are also described in detail on the μFUN website. Getting involved at the medium-aperture <b>telescope</b> <b>level</b> most likely would mean joining an observation group in a professional research lab. There are many observation sites around the globe, and they are primarily in the southern hemisphere. A full list of observation groups and their corresponding equipment {{can be found at}} μFUN's website.|$|E
40|$|The SPHERE {{instrument}} (Beuzit, et al., 2010) {{is dedicated}} to the direct imaging of extra-solar planets. This kind of observation allows one to study the photons emitted by the planet’s atmosphere itself, or reflected by its surface. The search for bio-markers is therefore made possible. The SPHERE instrument has been installed and commissioned at VLT Paranal Observatory during 2014 and now routinely delivers high contrast images to the exoplanet community. This paper presents a study of the main actual limitation of the SPHERE instrument, as known as the Low Wind Effect [LWE]. This effect has been discovered on SPHERE during commissioning period. Its effect is a strong degradation of the instrument PSF, preventing instrument to perform high contrast imaging. It happens during particularly low wind conditions (below 1 m/s at the <b>telescope</b> <b>level)</b> which happens one night out of five...|$|E
50|$|Ground-based Electro-Optical Deep Space Surveillance, or GEODSS, is {{an optical}} system that uses <b>telescopes,</b> low-light <b>level</b> TV cameras, and computers. It {{replaced}} an older system of six 20 inch (half meter) Baker-Nunn cameras which used photographic film.|$|R
50|$|In 2016, the 20th Space Control Squadron {{acquired}} the three Ground-based Electro-Optical Deep Space Surveillance (GEODSS) sites. GEODSS is an optical system that uses <b>telescopes,</b> low-light <b>level</b> TV cameras, and computers. It replaced an older system of six 20 inch (half meter) Baker-Nunn cameras which used photographic film.|$|R
40|$|An Integrated Product Team (IPT) {{was formed}} to develop a {{detailed}} concept for optical test methodology for testing of the NGST individual primary, secondary and tertiary mirrors and the full telescope system on the ground. Optical testing is a significant cost driver therefore the testing has to understood in detailed fashion early. A brief summary of the preliminary metrology test plan at the mirror component and <b>telescope</b> system <b>level</b> is presented...|$|R
40|$|Are we {{alone in}} the Universe is {{probably}} the most compelling science question of our generation. To answer it requires a large aperture telescope with extreme wavefront stability. To image and characterize Earth-like planets requires the ability to block 10 (exp 10) of the host stars light with a 10 (exp - 11) stability. For an internal coronagraph, this requires correcting wavefront errors and keeping that correction stable to a few picometers rms {{for the duration of the}} science observation. This requirement places severe specifications upon the performance of the observatory, telescope and primary mirror. A key task of the AMTD project (initiated in FY 12) is to define <b>telescope</b> <b>level</b> specifications traceable to science requirements and flow those specifications to the primary mirror. From a systems perspective, probably the most important question is: What is the telescope wavefront stability specification? Previously, we suggested this specification should be 10 picometers per 10 minutes; considered issues of how this specification relates to architecture, i. e. monolithic or segmented primary mirror; and asked whether it was better to have few or many segmented. This paper reviews the 10 picometers per 10 minutes specification; provides analysis related to the application of this specification to segmented apertures; and suggests that a 3 or 4 ring segmented aperture is more sensitive to segment rigid body motion that an aperture with fewer or more segments...|$|E
40|$|Balloon-borne {{astronomy}} {{is unique}} in that it allows for a level of image stability, resolution, and optical backgrounds that are comparable to space-borne systems due to greatly reduced atmospheric interference, but {{at a fraction of}} the cost and over a significantly reduced development time-scale. Instruments operating within visible-to-near-UV bands (300 - 900 um) can achieve a theoretical diffraction limited resolution of 0. 01 " from the stratosphere (35 - 40 km altitude) without the need for extensive adaptive optical systems required by ground-based systems. The Superpressure Balloon-borne Imaging Telescope ("SuperBIT") is a wide-field imager designed to achieve 0. 02 " stability over a 0. 5 ^∘ field-of-view, for deep single exposures of up to 5 minutes. SuperBIT is thus well-suited for many astronomical observations, from solar or extrasolar planetary observations, to resolved stellar populations and distant galaxies (whether to study their morphology, evolution, or gravitational lensing by foreground mass). We report SuperBIT's design and implementation, emphasizing its two-stage real-time stabilization: telescope stability to 1 - 2 " at the <b>telescope</b> <b>level</b> (a goal surpassed during a test flight in September 2015) and image stability down to 0. 02 " via an actuated tip-tilt mirror in the optical path (to be tested during a flight in 2016). The project is progressing toward a fully operational, three month flight from New Zealand by 2018 Comment: 12 pages, 5 figures, 2 tables, SPIE Astronomical Telescopes and Instrumentation 201...|$|E
40|$|In {{order to}} achieve the high {{performance}} required for the astronomical science programs with coming Extremely Large Telescopes (ELTs), the errors due to segment misalignment must be reduced to tens of nm. Therefore {{the development of new}} co-phasing techniques is of critical importance for ground-based telescopes, and to a large extent for future space-based missions. We propose a new co-phasing method directly exploiting the scientific image delivered by the Self-Coherent Camera (SCC) by adequately combining segment misalignment estimators (piston and tip/tilt) and image processing. The Self-Coherent Camera Phasing Sensor (SCC-PS) is shown to be capable of estimating accurately and simultaneously piston and tip/tilt misalignments and to correct them in close-loop operation in a few iterations. By contrast to several phasing sensor concepts the SCC-PS does not require any a priori on the signal at the segment boundaries, or a dedicated optical path. The SCC-PS is a non-invasive concept that works directly on the scientific image of the instrument, either in a coronagrahic or a non-coronagraphic observing mode. The primary results obtained in this study are very promising and demonstrate that the SCC-PS is a serious candidate for segment co-phasing at the instrument level or at the <b>telescope</b> <b>level</b> for both ground- and space-based applications. Applications of the estimators and algorithm developed for the SCC-PS seem to be possible to other on-segment aberration measurement. Early studies are already in progress to adapt these processes...|$|E
40|$|An Integrated Product Team (IPT) {{was formed}} to develop a {{detailed}} optical test methodology for testing of the Next Generation Space Telescope (NGST) mirrors and the optical system on the ground. Optical testing is a significant cost driver therefore the testing has to be planned in detailed fashion early. This paper will discuss the preliminary metrology test plan at the mirror component and <b>telescope</b> system <b>level.</b> Instrumentation, facilities and schedule will also be addressed...|$|R
40|$|This paper {{describes}} the statistical {{issues involved in}} analyzing data from high-energy gamma-ray <b>telescopes,</b> at <b>levels</b> from event reconstruction to correlations of populations of astrophysical sources. Some motivation for attempting to do astronomy with high-energy gamma rays is also given, {{along with some of}} the constraints implied by operating the instrument in orbit. Specific attention is given to the Large Area Telescope (LAT) under development for launch in late 2006 on the Gamma-ray Large Area Space Telescope (GLAST) mission. 1...|$|R
40|$|Abstract: VERITAS {{employs a}} {{multi-stage}} data acquisition chain that {{extends from the}} VME readout of custom 500 MS/s flash ADC electronics {{to the construction of}} telescope events and ultimately the compilation of information from each <b>telescope</b> into array <b>level</b> data. These systems provide access to the programming of the channel level triggers and the FADCs. They also ensure the proper synchronization of event information across the array and provide the first level of data quality monitoring. Additionally, the data acquisition includes features to handle the readout of special trigger types and to monitor channel scaler rates. In this paper we describe the software and hardware components of the systems and the protocols used to communicate between the VME, <b>telescope,</b> and array <b>levels.</b> We also discuss the performance of the data acquisition for array operations...|$|R
40|$|The ATHENA X-ray {{observatory}} is a large-class ESA approved mission, with launch {{scheduled in}} 2028. The technology of silicon pore optics (SPO) {{was selected as}} baseline to assemble ATHENA's optic with more than 1000 mirror modules, obtained by stacking wedged and ribbed silicon wafer plates onto silicon mandrels to form the Wolter-I configuration. Even if the current baseline design fulfills the required effective area of 2 m 2 at 1 keV on-axis, alternative design solutions, e. g., privileging {{the field of view}} or the off-axis angular resolution, are also possible. Moreover, the stringent requirement of a 5 arcsec HEW angular resolution at 1 keV entails very small profile errors and excellent surface smoothness, as well as a precise alignment of the 1000 mirror modules to avoid imaging degradation and effective area loss. Finally, the stray light issue has to be kept under control. In this paper we show the preliminary results of simulations of optical systems based on SPO for the ATHENA X-ray telescope, from pore to <b>telescope</b> <b>level,</b> carried out at INAF/OAB and DTU Space under ESA contract. We show ray-tracing results, including assessment of the misalignments of mirror modules and the impact of stray light. We also deal with a detailed description of diffractive effects expected in an SPO module from UV light, where the aperture diffraction prevails, to X-rays where the surface diffraction plays a major role. Finally, we analyze the results of X-ray tests performed at the BESSY synchrotron, we compare them with surface finishing measurements, and we estimate the expected HEW degradation caused by the X-ray scattering...|$|E
40|$|Direct imaging of Earth-like exoplanets {{requires}} {{high contrast}} imaging capability and high angular resolution. Primary mirror segmentation {{is a key}} technological solution for large-aperture telescopes because it opens the path toward significantly increasing the angular resolution. The segments are kept aligned by an active optics system that must reduce segment misalignments below tens of nm RMS to achieve the high optical quality required for astronomical science programs. The development of cophasing techniques is mandatory {{for the next generation}} of space- and ground-based segmented telescopes, which both share the need for increasing spatial resolution. We propose a new focal plane cophasing sensor that exploits the scientific image of a coronagraphic instrument to retrieve simultaneously piston and tip-tilt misalignments. The self-coherent camera phasing sensor (SCC-PS) adequately combines the SCC properties to segmented telescope architectures with adapted segment misalignment estimators and image processing. An overview of the system architecture, and a thorough performance and sensitivity analysis, including a closed-loop efficiency, are presented by means of numerical simulations. The SCC-PS estimates simultaneously piston and tip-tilt misalignments and corrects them in closed-loop operation. The SCC-PS does not require any a priori on the signal at the segment boundaries or any dedicated optical path. It has a moderate sensitivity to misalignments, virtually none to pupil shear, and is insensitive to segment gaps and edge effects. Primary mirror phasing can be achieved with bright natural guide star. The SCC-PS is a noninvasive concept and an efficient phasing sensor from the image domain. It is an attractive candidate for segment cophasing at the instrument level or alternatively at the <b>telescope</b> <b>level,</b> as usually envisioned in current space- and ground-based observatories. Comment: 10 pages. 9 figures. Accepted for publication in Astronomy & Astrophysic...|$|E
40|$|Local {{atmospheric}} turbulence at the <b>telescope</b> <b>level</b> {{is regarded as}} a major reason for affecting the performance of the adaptive optics systems using wavelengths in the visible and infrared for solar observations. During the day the air masses around the telescope dome are influenced by flow distortions. Additionally heating of the infrastructure close to telescope causes thermal turbulence. Thereby optical turbulence is produced and leads to quality changes in the local seeing throughout the day. Image degradation will be yielded affecting the performance of adaptive optical systems. The spatial resolution of the solar observations will be reduced. For this study measurements of the optical turbulence, represented by the structure function parameter of the refractive index Cn 2 were performed on several locations at the GREGOR telescope at the Teide observatory at Tenerife at the Canary Islands / Spain. Since September 2012 measurements of Cn 2 were carried out between the towers of the Vacuum Tower Telescope (VTT) and of GREGOR with a laser-scintillometer. The horizontal distance of the measurement path was about 75 m. Additional from May 2015 up to March 2016 the optical turbulence was determined at three additional locations close to the solar telescope GREGOR. The optical turbulence is derived from sonic anemometer measurements. Time series of the sonic temperature are analyzed and compared to the direct measurements of the laser scintillometer. Meteorological conditions are investigated, especially the influence of the wind direction. Turbulence of upper atmospheric layers is not regarded. The measured local turbulence is compared to the system performance of the GREGOR telescopes. It appears that the mountain ridge effects on turbulence are more relevant than any local causes of seeing close to the telescope. Results of these analyses and comparison of nearly one year of measurements are presented and discussed...|$|E
40|$|VERITAS {{employs a}} {{multi-stage}} data acquisition chain that {{extends from the}} VME readout of custom 500 MS/s flash ADC electronics {{to the construction of}} telescope events and ultimately the compilation of information from each <b>telescope</b> into array <b>level</b> data. These systems provide access to the programming of the channel level triggers and the FADCs. They also ensure the proper synchronization of event information across the array and provide the first level of data quality monitoring. Additionally, the data acquisition includes features to handle the readout of special trigger types and to monitor channel scaler rates. In this paper we describe the software and hardware components of the systems and the protocols used to communicate between the VME, <b>telescope,</b> and array <b>levels.</b> We also discuss the performance of the data acquisition for array operations. Comment: 4 pages; contribution to the 30 th International Cosmic Ray Conference, Merida, Mexico, July 200...|$|R
40|$|These videos, {{and audio}} {{accompany}} the slide presentation "Flux of Kilogram-sized Meteoroids from Lunar Impact Monitoring. " The slide presentation reviews the routine lunar impact monitoring that has harvested over 110 impacts in 2 years of observations using <b>telescopes</b> and low-light <b>level</b> video cameras. The night {{side of the}} lunar surface provides a large collecting area for detecting these impacts and allows estimation of the flux of meteoroids down to a limiting luminous energy...|$|R
50|$|HEAO 2, more {{commonly}} known as the Einstein Observatory, launched 13 November 1978 into a 23.5 deg inclination orbit. It carried a single large grazing-incidence focusing X-ray <b>telescope,</b> providing unprecedented <b>levels</b> of sensitivity (hundreds of times better than previously achieved) and arc-second angular resolution for pointed observations of known objects, and operated over the 0.2 to 3.5 keV energy range. HEAO 2 differed from HEAO 1 and HEAO 3 in that it was used for pointed, deep, small-field-of-view observations rather than sky-survey studies.|$|R
40|$|We {{present and}} discuss the design details of an extensible, modular, open source {{software}} framework called EXOSIMS, which creates end-to-end simulations of space-based exoplanet imaging missions. We motivate the development and baseline implementation of the component parts of this software with models of the WFIRST-AFTA coronagraph, and present initial results of mission simulations for various iterations of the WFIRST-AFTA coronagraph design. We present and discuss two sets of simulations: The first compares the science yield of completely different instruments {{in the form of}} early competing coronagraph designs for WFIRST-AFTA. The second set of simulations evaluates the effects of different operating assumptions, specifically the assumed post-processing capabilities and <b>telescope</b> vibration <b>levels.</b> We discuss how these results can guide further instrument development and the expected evolution of science yields. Comment: 43 pages, 14 figures; accepted for publication in WFIRST Coronagraph special issue of JATI...|$|R
40|$|In {{ground-based}} astronomy seeing {{remains one}} of the biggest problem due to the presence of atmospheric turbulence affecting the radiation from the astronomical object of interest, along its travel path to the telescope device. The correction of the turbulence effects at the <b>telescope</b> pupil <b>level,</b> characterized statistically according to well-accepted models, is the focus of current generation of adaptive optics systems. Moreover, the representation of atmospheric turbulence, which is limited to the phase contribution since the amplitude degradation can be considered as negligible, is obtained through a modal decomposition. The choice of the modal representation is therefore a key issue in the turbulence study and the consequent design of control system to drive the deformation of the corrective mirrors. In the paper we discuss a possible solution to the problem, resorting to the principal component analysis of the atmospheric turbulence, and comparing this approach to the classically adopted Zernike's expansion...|$|R
40|$|This online Flash game is hosted on the James Webb Space Telescope Web site. Because the Webb Telescope {{is unusual}} in appearance, it doesn't look like a {{telescope}} - but it actually does {{have a lot in}} common with simple tube-shaped telescopes. "Scope It Out!" includes an introduction to reflecting and refracting <b>telescopes</b> and four <b>levels</b> of matching games, where you compare a simple reflecting telescope to the Webb and Hubble. The information contained in a level will help one solve the puzzles in the next round. Educational levels: High school, High school...|$|R
40|$|International audienceThe tasks {{execution}} scheduling is {{a common}} problem in computer science. The typical problem, as in industrial or computer processing applications, has some restrictions that are inapplicable for certain cases. For example, all available tasks have to be executed at some point, and ambient factors do not affect the execution order. In the astronomical observations field, projects are scheduled as observation blocks, and their execution depends on parameters like science goals priority and target visibility, but is also restricted by external factors: atmospheric conditions, equipment failure, etc. A telescope scheduler is mainly in charge of handling projects, commanding the <b>telescope's</b> high <b>level</b> movement to targets, and starting data acquisition. With the growth of observatories' capacities and maintenance costs, it is now mandatory to optimize the observation time allocation. Currently, at professional observatories there is still strong human intervention dependency, with no fully automatic solution so far. This paper aims to describe the dynamic scheduling problem in astronomical observations, {{and to provide a}} survey on existing solutions, opening some new application opportunities for computer science...|$|R
500|$|By the 19th century, the {{resolution}} of <b>telescopes</b> reached a <b>level</b> sufficient for surface features to be identified. A perihelic opposition of Mars occurred on September 5, 1877. In that year, the Italian astronomer Giovanni Schiaparelli used a [...] telescope in Milan to help produce the first detailed map of Mars. These maps notably contained features he called canali, which were later shown to be an optical illusion. These canali were supposedly long, straight lines {{on the surface of}} Mars, to which he gave names of famous rivers on Earth. His term, which means [...] "channels" [...] or [...] "grooves", was popularly mistranslated in English as [...] "canals".|$|R
40|$|The {{atmospheric}} effect {{correction of}} the muon flux measured by ground <b>level</b> <b>telescopes</b> is of special importance {{for further study}} of cosmic ray variations. The Duperier method is used to correct atmospheric effects on the muon intensity observed by the MuSTAnG telescope. Linear multiple correlation and regression analysis are applied to the data registered during the year 2009. The aerological data are obtained from daily radiosonde balloon flights of Deutscher Wetterdienst. The regression coefficients and total correlation coefficients are calculated for all directional channels. The seasonal variations are eliminated from the MuSTAnG telescope data. The results are compared with theoretical elimination of temperature variations. Key words. Space weather – muon telescope – atmospheric effec...|$|R
40|$|Between March 16, 1997 and April 14, 1997, a {{high flux}} level of TeV {{gamma-rays}} was observed from Mkn 501, using the HEGRA stereoscopic system of four imaging Cherenkov <b>telescopes.</b> The flux <b>level</b> varied {{during this period}} from about one half up to six times the flux observed from the Crab Nebula. Changes of the detection rate {{by a factor of}} up to 4 within 1 day have been observed. The measured differential energy spectrum of the radiation follows a power law from 1 TeV to 10 TeV. The differential spectral index of 2. 47 {+-} 0. 07 {+-} 0. 25 is close to that of the Crab Nebula of 2. 66 {+-} 0. 12 {+-} 0. 25. Comment: 4 Pages, 4 figures, Latex, uses l-aa. sty; revised version with minor corrections; Accepted for publication in A&A (Letters...|$|R
40|$|ABSTRACT. The unique {{atmospheric}} conditions present at {{sites such as}} Dome C on the Antarctic plateau are very favorable for high spatial resolution astronomy. At Dome C, {{the majority of the}} optical turbulence is confined to a 30 to 40 m thick stable boundary layer that results from the strong temperature inversion created by the heat exchange between the air and the ice-covered ground. To fully realize the potential of the exceptionally calm free atmosphere, this boundary layer must be overcome. In this article we compare the performance of two methods proposed to beat the boundary layer: mounting a telescope on a tower that physically puts it above the turbulent layer, and installing a <b>telescope</b> at ground <b>level</b> with a ground-layer adaptive optics system. A case is also made to combine these two methods to further improve the image quality. 1...|$|R
5000|$|In 1938, {{the group}} {{purchased}} the land the institute presently occupies and initial construction {{was completed in}} the spring of 1939. The 100-seat lecture hall was added in 1945. In 1947, through donations by Charles Elmer and Mr. Polk, the 3-story tower/library and observatory dome were built.In 1954, Charles Elmer died; that same year, the Institute added the shed, which houses three sliding roof observatories.Over the years, Custer has acquired a large collection of telescopes of all sizes and descriptions. Most recently, this includes a 25-inch (f/5) Newtonian reflector, which is now the premier telescope in the newly-rebuilt dome.(Article not found) [...] In order to bring the eyepiece of this <b>telescope</b> to a <b>level</b> that does not require observers to climb a high ladder, the optics on this telescope were modified by Custer's Research Director, Jeffrey Owen Katz, Ph.D., and Research Committee Member, Justine Haupt.|$|R
40|$|In radio astronomy, cosmic {{sources are}} {{observed}} which are many {{orders of magnitude}} weaker than the <b>telescope</b> system noise <b>level.</b> The necessary sensitivity is achieved by large telescope collecting areas, long integration times, and large bandwidths. In the coming two decades, telescopes are planned which are even one to two orders of magnitude more sensitive than the current generation. Examples are the Low Frequency Array (LOFAR), currently under construction in the Netherlands, and the Square Kilometer Array, for which the envisaged start of construction is in 2012. For this next generation of telescopes a dynamic range in the sky maps of over 106 is required. In order to reach these numbers, accurate calibration is needed. As these telescopes will observe with relatively large bandwidths, {{and because of the}} changing spectrum environment, interference mitigation techniques become increasingly important. In this paper, approaches for calibration and interference mitigation are presented, and results from the LOFAR initial phased array test station (ITS) are given. 1...|$|R
40|$|Abstract This article reviews water-related urban {{environmental}} conditions in Southeast Asia. It {{argues that the}} development of urban environmental chal-lenges in the region follows a unique pattern compared with those experienced in the now developed world. The new pattern is defined by the so called time–space telescoping of the development process. The process of time–space <b>telescoping</b> reduces the <b>levels</b> of income at which environmental challenges emerge and forces their appearance in a simultaneous fashion, as sets of problems. During previous eras, cities experienced sequential environmental transitions. Urban water-re-lated environmental burdens emerged on local scales and expanded geographically and temporally in im-pact, with growing levels of affluence. Moreover, certain environmental challenges appeared later in economic growth because the technologies and practices that induced these problems emerged at higher levels of income. The article has two main findings. First, except for wealthy urban centers, for example Singapore, cities in the region are experiencing multi-scaled water burdens simultaneously. Second, low-income and middle-income cities are experiencing burdens at lower levels of income than did their contemporaries in the north...|$|R
40|$|Water vapor in the Earth's {{troposphere}} introduces {{an extra}} electrical {{path in the}} propagation of radio signals through the atmosphere. The distribution of water vapor is irregular and distorts the wavefronts of incoming radio waves, limiting the angular resolution {{that can be achieved}} with ground-based <b>telescopes.</b> The <b>level</b> of fluctuations depends both on the location of the site,and on the prevailing atmospheric conditions. The ability to measure the fluctuations is therefore important when choosing a site for a new instrument, and for scheduling observations of existing telescopes. Existing phase monitors are radio interferometers that monitor monochromatic beacon tones from geostationary communications satellites at a frequency of about 12 GHz. They have a classical heterodyne design based on two satellite receiving antennas; each has a front-end for amplifying and down-converting the incoming signals using a local oscillator that is phase-locked to a common reference frequency. In addition to multiple phase-locked loops these instruments require expensive phase-stable cabling to reduce the effects of thermal drift. The new system uses two consumer 18 " digital satellite TV dishes to monitor satellite TV broadcast signals over a bandwidth of 500 MHz (12. 2 to 12. 7 GHz). The novel design eliminates the need for phase-locked loops and thermally stable components, and uses a pair of Gilbert Cell multipliers to perform the broadband correlation. A phase monitor has been been built and deployed {{at the site of the}} Berkeley-Illinois-Maryland Association Millimeter Array in Northern California, and has been operating successfully since June 1998, measuring the difference in electrical path length for parallel lines of sight to the satellite separated by a baseline of 100 m. With a hardware cost of approximately $ 4000, it is much cheaper than previous instruments, and the low power requirements and high reliability make the system suitable for site testing in remote locations...|$|R
40|$|Between March 16, 1997 and April 14, 1997, a {{high flux}} level of TeV fl-rays was {{observed}} from Mkn 501, using the HEGRA stereoscopic system of four imaging Cherenkov <b>telescopes.</b> The flux <b>level</b> varied {{during this period}} from about one half up to six times the flux observed from the Crab Nebula. Changes of the detection rate {{by a factor of}} up to 4 within 1 day have been observed. The measured differential energy spectrum of the radiation follows a power law from 1 TeV to 10 TeV. The differential spectral index of 2. 47 Σ 0 : 07 Σ 0 : 25 is close to that of the Crab Nebula of 2 : 66 Σ 0 : 12 Σ 0 : 25. Key words: gamma rays: observations - BL Lacertae objects: individual: Mkn 501 1. Introduction Among the TeV cosmic fl-ray sources observed by groundbased imaging atmospheric Cherenkov telescopes (IACTs) are two nearby active galactic nuclei (AGNs), Mkn 421 (Punch et al. 1992, Petry et al. 1996) and Mkn 501 (Quinn et al., 1996, Bradbury et al. 1997). In contrast to steady Send of [...] ...|$|R
40|$|Utilizing {{the unique}} and {{reliable}} ultrasmall [...] x {{predictions of the}} dynamical (radiative) parton model, nominal event rates and their detailed energy dependence caused {{by a variety of}} cosmic UHE neutrino fluxes are calculated and analyzed. In addition, maximal Regge [...] model inspired small [...] x structure functions are employed for obtaining optimal rates which do not necessarily require `new' physics interpretations. Upward μ^+ +μ^- event rates are estimated by taking into account total and nadir [...] angle dependent regeneration effects due to neutral current interactions. For exploring extragalactic neutrino sources at highest energies (- 0. 1 cm>∼ 10 ^ 8 GeV) with modern (future) ground [...] <b>level</b> <b>telescopes,</b> we analyze horizontal air shower event rates and shower events caused by Earth [...] skimming tau [...] neutrinos, in particular their detailed shower [...] and cosmic neutrino [...] energy dependence. As an illustration of `new physics' implications we estimate the relevant horizontal air shower event rates due to spin [...] 2 Kaluza [...] Klein `graviton' exchanges in neutral current neutrino [...] quark and neutrino [...] gluon interactions at low TeV [...] scales. Comment: 3 figures changed, discussions and references adde...|$|R
50|$|Conventional {{over-the-counter}} {{film has}} long been used for astrophotography. Film exposures range from 10 minutes to over an hour. Commercially available color film stock is subject to reciprocal failure over long exposures, in which sensitivity to light of different wavelengths appears to drop off as the exposure time increases, leading to color shift in the image. This is compensated for by using the same technique used in professional astronomy of taking photographs at different wavelengths that are then combined to create a correct color image. Since film is much slower than digital sensors, tiny errors in tracking can be corrected without much noticeable effect on the final image. Film astrophotography is becoming less popular due to the low cost of digital photography.Since the late 1990s amateurs have been following the professional observatories in the switch from film to digital CCDs for astronomical imaging. CCDs are more sensitive than film, allowing much shorter exposure times, and have a linear response to light. Images can be captured in many short exposures to create a synthetic long exposure. Digital cameras also have minimal or no moving parts {{and the ability to}} be operated remotely via an infrared remote or computer tethering, limiting vibration. Simple digital devices such as webcams can be modified to allow access to the focal plane and even (after the cutting of a few wires), for long exposure photography. Digital video cameras are also used. There are many techniques and pieces of commercially manufactured equipment for attaching digital single lens reflex(DSLR) cameras and even basic point and shoot cameras to <b>telescopes.</b> Consumer <b>level</b> digital cameras suffer from image noise over long exposures, so there are many techniques for cooling the camera, including cryogenic cooling. Astronomical equipment companies also now offer a wide range of purpose-built astronomical CCD cameras complete with hardware and processing software. Many commercially available DSLR cameras have the ability to take long time exposures combined with sequential (time-lapse) images allowing the photographer to create a motion picture of the night sky.|$|R
40|$|Preliminary {{requirements}} and possible technological {{solutions for the}} next generation of ground-based optical telescopes were laid down at ESO in 1998. Since then, a phase A study has been commissioned, the objective of which is to produce a conceptual design compatible, to the maximum possible extent, with proven technology, and establish realistic plans for detailed design, site selection, construction and operation for a 100 -m class optical, diffractionlimited telescope. There was no doubt about how daunting such a challenge would be, but, somewhat surprisingly, it turns out to be firmly confined to adaptive optics concepts and technologies. The telescope itself appears to be feasible within the allocated budget and without reliance on exotic assumptions. Fabrication of key subsystems is fully within the reach of a properly engineered, industrialized process. A consolidated baseline is taking shape, and alternative system and subsystem solutions are being explored, strengthening the confidence that requirements could be met. Extensive development of wavefront measurement techniques enlarges the palette of solutions available for active wavefront control of a segmented, active <b>telescope.</b> At system <b>level,</b> ESO is developing enabling experiments to validate multi-conjugate adaptive optics (MAD for Multi-conjugate Adaptive optics Demonstrator) and telescope wavefront control (APE, for Active Phasing Experiment) ...|$|R
40|$|Received; {{accepted}} Context. With {{the advent}} of visible and infrared long-baseline interferometers with more than two telescopes, both the size and the completeness of interferometric data sets have significantly increased, allowing images based on models with no a priori assumptions to be reconstructed with an aperture synthesis technique. Aims. Our main objective is to analyze the multiple parameters of the image reconstruction process with {{particular attention to the}} regularization term and the study of their behavior in different situations (types of astrophysical objects, <b>telescope</b> array configurations, <b>level</b> of noise, etc.). The secondary goal is to derive practical rules for the users. Methods. Using the Multi-aperture image Reconstruction Algorithm (MiRA), we performed multiple systematic tests, analyzing 11 regularization terms commonly used. The tests are made on different astrophysical objects, different (u, v) plane coverages and several signal-to-noise ratios to determine the minimal configuration needed to reconstruct an image. We establish a methodology and we introduce the mean-square errors (MSE) to discuss the results. Results. From the ∼ 24000 simulations performed for the benchmarking of image reconstruction with MiRA, we are able to classify the different regularizations {{in the context of the}} observations. We find typical values of the regularization weight. A minimal (u, v) coverage is required to reconstruct an acceptable image, whereas no limits are found for the studied values of the signal-to-noise ratio...|$|R
40|$|Ly alpha spheres, that is, regions {{around the}} first stars that are {{illuminated}} by Ly alpha photons and exhibit a 21 cm absorption feature against the cosmic microwave background, are smoking guns {{at the dawn of}} the reionization epoch. Although an overwhelming radio foreground makes their detection extremely difficult, we point out that strong gravitational lensing can significantly improve the feasibility of observing these objects. Since Ly alpha spheres have similar to 10 &# 39;&# 39; sizes, comparable to the size of galaxy-cluster caustics, the individual images of a strongly lensed Ly alpha sphere will often merge together and form an irregularly shaped single structure in the 21 cm sky. Using high- resolution N-body Lambda CDM simulations, we find that the lensing probability to have a magnification greater than 10 is similar to 10 (- 5). This results in greater than or similar to 10 (6) strongly lensed Ly alpha spheres across the sky, which should be the primary targets for first detections of Ly alpha spheres. Although the required total radio-array collecting area for their detection is large (similar to 100 km(2)), a design composed of long fixed cylindrical reflectors can significantly reduce the total cost of such a radio <b>telescope</b> to the <b>level</b> of the Square Kilometre Array and make the detection of these very first objects feasible...|$|R
