1695|3789|Public
25|$|Tested: Every change must {{be tested}} in a safe <b>test</b> <b>environment,</b> which closely {{reflects}} the actual production environment, before the change {{is applied to the}} production environment. The backout plan must also be tested.|$|E
25|$|These {{assumptions}} {{could soon}} be validated. Advances in virtual reality technology have pried {{open the door to}} this enigmatic field. Now experimenters find themselves creating scenarios that were impossible to imagine fifteen years ago. Virtual reality affords experimenters the luxury of extreme control over their <b>test</b> <b>environment.</b> Any variable can be manipulated, including things that would not be possible in reality.|$|E
500|$|Developing the {{gameplay}} {{began at}} the start of development, with a <b>test</b> <b>environment</b> being built to develop and refine the basics of the battle system. Work within the test build spanned approximately one and a half years. While creating the battle system, the staff decided that the key words should be [...] "order" [...] and [...] "chaos": whoever gained order on the battlefield would be the victor. One of the concepts that emerged from this was Gathering, Zael's ability to direct all enemies' attention towards him. At first, Gathering ended up generating an unwanted amount of chaos on the battlefield, and this resulted in the trial-and-error period for it running on for a long time. The biggest challenge, once the concept had been finalized, was adjusting its effectiveness on the battlefield depending on the situation and enemy types. A concept that did not make it into the final game was [...] "Replay": after an enemy successfully cast a spell, players could rewatch the last few seconds of battle from an overhead view to see what type it was and take that into their strategy. This slowed the pace of combat down too much, so the concept was entirely removed. Hangovers of it include the ability to freeze time during certain actions, and the overhead perspective when commanding party members The cover system was designed around the limitations of the camera control born from the Wii Remote's control scheme.|$|E
5000|$|Keynote {{launches}} Web Site Performance {{index for}} 2008 Olympics Keynotes introduces KITE (Keynote Internet <b>Testing</b> <b>Environment)</b> [...] Keynote launches MITE (Mobile Internet <b>Testing</b> <b>Environment)</b> - desktop based mobile testing ...|$|R
50|$|CUTEr (Constrained and Unconstrained <b>Testing</b> <b>Environment,</b> revisited) is an {{open source}} <b>testing</b> <b>environment</b> for {{optimization}} and linear algebra solvers. CUTEr provides a collection of test problems along {{with a set of}} tools to help developers design, compare, and improve new and existing test problem solvers.|$|R
50|$|To ensure {{consistent}} results, {{the performance}} <b>testing</b> <b>environment</b> should be isolated from other environments, such as user acceptance testing (UAT) or development. As a best practice {{it is always}} advisable to have a separate performance <b>testing</b> <b>environment</b> resembling the production environment as much as possible.|$|R
2500|$|Zen Studios Managing Director Zsolt Kigyossy {{detailed}} {{the reasons for}} focusing primarily on pinball games. [...] "We have guys in the studio who have spent countless hours and pockets full of money at arcades playing pinball." [...] Kigyossy explained that the design process for the tables begins with a conceptual design on paper. [...] Basic 3D models and shapes are then created and implemented into a <b>test</b> <b>environment.</b> [...] The artists then add graphical details and animations. [...] Once gameplay and visual design is complete a final pass is made [...] "properly lighting the table, so the tables becomes lifelike." [...] Simultaneously other designers work on the LED display system, sound and gameplay mechanics. [...] The game then spends {{two to three months}} in testing before the table is considered ready for release. [...] The entire process takes approximately six months per table. [...] Kigyossy further stated the team plans to [...] "keep the tables coming, support our games long term, and give fans a great selection to choose from." ...|$|E
5000|$|Configure the <b>Test</b> <b>Environment.</b> Prepare the <b>test</b> <b>environment,</b> tools, and {{resources}} necessary to execute each strategy, as features and components become available for test. Ensure that the <b>test</b> <b>environment</b> is instrumented for resource monitoring as necessary.|$|E
50|$|<b>Test</b> <b>Environment</b> Management (TEM) is a {{function}} in the software delivery process which aids the software testing cycle by providing a validated, stable and usable <b>test</b> <b>environment</b> to execute the test scenarios or replicate bugs.|$|E
5000|$|Creation of new <b>test</b> <b>environments</b> as per requirement. (Supply management) ...|$|R
5000|$|Allocation of <b>test</b> <b>environments</b> to {{teams as}} per requirement. (Demand management) ...|$|R
50|$|Simulator: Simulates the <b>testing</b> <b>environment</b> {{where the}} {{software}} product {{is to be}} used.|$|R
5000|$|Once the {{developer}} {{thinks it is}} ready, the product is copied to a <b>Test</b> <b>environment,</b> to verify it works as expected. This <b>test</b> <b>environment</b> is supposedly standardized and in close alignment with the target environment.|$|E
5000|$|Identify the <b>Test</b> <b>Environment.</b> Identify the {{physical}} <b>test</b> <b>environment</b> {{and the production}} environment {{as well as the}} tools and resources available to the test team. The physical environment includes hardware, software, and network configurations. Having a thorough understanding of the entire <b>test</b> <b>environment</b> at the outset enables more efficient test design and planning and helps you identify testing challenges early in the project. In some situations, this process must be revisited periodically throughout the project's life cycle.|$|E
50|$|In {{the test}} plan the <b>test</b> <b>environment</b> is described.|$|E
5000|$|COPE - IMS {{virtualization}} {{to deploy}} multiple virtual IMS development or <b>testing</b> <b>environments</b> ...|$|R
5000|$|... {{developing}} the future education and <b>testing</b> <b>environment</b> through its Learning to Drive programme ...|$|R
5000|$|Xpediter/TSO offers {{complete}} control of application code execution in the batch <b>testing</b> <b>environment</b> ...|$|R
5000|$|... #Caption: A Galileo <b>test</b> <b>environment</b> Pseudolite in the Berchtesgaden Alps ...|$|E
5000|$|Specify a {{profiling}} {{tool for the}} development/component unit <b>test</b> <b>environment</b> ...|$|E
50|$|The {{purpose of}} the <b>test</b> <b>environment</b> is to allow either {{automated}} tests or human testers to exercise new and changed code. After the developer accepts the new code and configurations through unit testing in the development environment, the items are moved {{to one or more}} test environments. Upon test failure, the <b>test</b> <b>environment</b> can remove the faulty code from the test platforms, contact the responsible developer, and provide detailed test and result logs. If all tests pass, the <b>test</b> <b>environment</b> or a continuous integration framework controlling the tests can automatically promote the code to the next deployment environment.|$|E
5000|$|User {{acceptance}} <b>testing</b> <b>environment,</b> where business stakeholders {{can test}} against their original business requirements, ...|$|R
50|$|For testing non-internet applications, virtual {{instances}} of <b>testing</b> <b>environment</b> {{can be quickly}} set up to do automated testing of the application.The cloud testing service providers provide essential <b>testing</b> <b>environment</b> as per the requirement of the application under test. The actual testing of applications is performed by the testing team of the organization which owns the application or third party testing vendors.|$|R
40|$|Phenotypic {{and genetic}} {{parameters}} for harvest body weight were estimated {{within and across}} multiple <b>test</b> <b>environments</b> and five consecutive generations of the synthetic GIFT population. Of {{a total of about}} 62, 000 individually tagged fish, 43, 066 individuals from 461 sires and 815 dams across generations had body weights recorded in two to eight different <b>test</b> <b>environments</b> per generation from 1991 to 1996. The <b>test</b> <b>environments</b> included earthen ponds (fertilized with inorganic fertilizer, organic manure, or on-farm agricultural residues), cage culture, rice-fish, and ponds at test stations located in different agro-climatic regions. Heritability estimates for harvest body weight within <b>test</b> <b>environments</b> and generation were on average h 2 = 0. 31 (range 0. 06 – 0. 68) and the estimates for effects common to full sibs other than additive genetic effects c 2 = 0. 09 (range 0. 04 – 0. 16). The estimates tended to be higher in cage <b>test</b> <b>environments.</b> After adjusting for heterogeneous variances of harvest body weight across generations, <b>test</b> <b>environments</b> and sexes, the estimates across <b>test</b> <b>environments</b> within generations were on average h 2 = 0. 23 and c 2 = 0. 03 over the five generations, while the estimate across all <b>test</b> <b>environments</b> and generations was h 2 = 0. 16 ± 0. 02 and c 2 = 0. 10 ± 0. 01. The genetic correlations (rg) between harvest body weights of sibs in different <b>test</b> <b>environments</b> were in general high (0. 53 – 0. 99, mean 0. 89) for all environments except for intensive cage culture, implying minor genotype by environment (G × E) interactions. The genetic correlations involving the intensive cage culture environment were lower (0. 08 – 0. 43) and not significantly different from zero, suggesting that G × E interactions may occur if <b>test</b> <b>environments</b> differ widely. It is proposed that this G × E interaction may involve effects of sexual maturation on growth in pond environments. The overall heritability for body weight at harvest of females (0. 20 ± 0. 02) was not significantly different from that of males (0. 16 ± 0. 02). However, these estimates were lower in ponds than in cages, in particular for male body weight. Estimates of genetic correlations between harvest body weight of sib males and females also suggested a moderate sex by genotype interaction in ponds (rg = 0. 78 ± 0. 04) that did not occur in cages (rg = 0. 97 ± 0. 04). These results are consistent with the realization that the GIFT population responds well to selection for increased body weight at harvest across a wide range of pond farm environments (including rice–fish culture) without the need to develop environment specific selection lines. The benefits of specialized selection for intensive cage farming systems should be investigated further...|$|R
5000|$|May 2, 2016 BSE Migrates Algorithm Trading <b>Test</b> <b>Environment</b> to Cloud Infrastructure ...|$|E
5000|$|Oracle Live SQL makes {{available}} a <b>test</b> <b>environment</b> for Oracle Database users.|$|E
5000|$|... {{from the}} command line as a {{stand-alone}} {{process in a}} <b>test</b> <b>environment</b> ...|$|E
40|$|In {{this work}} we propose a <b>testing</b> <b>environment</b> {{based on a}} {{personal}} computer, a data acquisition card and the LabVIEW^TM software. The <b>testing</b> <b>environment</b> {{will be able to}} accept a test plan and convert it into test cases, provide means to test ANN-specific aspects in the implementation, run the designed tests and generate reports. Here we present our first results {{in the development of the}} test bench...|$|R
40|$|In {{the frame}} of a joint project the basis for an {{integrated}} <b>testing</b> <b>environment</b> for microsystems has been compliled. For this purpose the main problem fields have been analyzed, test and diagnosis concepts have been developed and the properties and capabilities of the integrated <b>testing</b> <b>environment</b> has been specified. For validation a modular constructed prototypic test system has been implemented consisting of data logging modules matched to the interfaces of the microsystems. The performance of the <b>testing</b> <b>environment</b> has been demonstrated with system-adaptive microsensors and microactors. (WEN) SIGLEAvailable from TIB Hannover: F 96 B 838 +a / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekBundesministerium fuer Bildung, Wissenschaft, Forschung und Technologie, Bonn (Germany) DEGerman...|$|R
40|$|While {{new product}} {{evaluation}} testing plays {{a pivotal role}} in the NPD process, there is little empirical evidence on the influence of the virtual <b>testing</b> <b>environment</b> on the evaluation results and the data quality. The present study addresses this gap in the literature by using a split-sample online concept testing-like study to compare the testing results in traditional and virtual environments for five heterogeneous innovations. The findings indicate that both traditional and virtual <b>testing</b> <b>environments</b> yield identical mean scores, while the latter provides higher-quality data given the same sampling design. Early concept or product tests, therefore, may be carried out in a more realistic <b>testing</b> <b>environment</b> using virtual techniques, which could substantially enhance the quality of testing data...|$|R
5000|$|In {{case there}} is {{component}} that communicates to other components (SOA environment or by simply using 3rd party services/microservices) but {{need to be}} tested without the availability of other components, Wilma can act as stub. The environment can be - among others - a local development environment, a CI <b>test</b> <b>environment,</b> or an integration <b>test</b> <b>environment</b> ...|$|E
50|$|The {{supporting}} processes are <b>test</b> <b>environment,</b> test tools, and selection of test professionals.|$|E
5000|$|... #Caption: A blind woman {{learns to}} use her guide dog in a <b>test</b> <b>environment</b> ...|$|E
40|$|Purpose – The {{purpose of}} this paper is to examine the {{influence}} of innovativeness, change seeking and cognitive effort on consumer responses to traditional versus virtual <b>testing</b> <b>environment.</b> Design/methodology/approach – The empirical study collects concept evaluations of five heterogeneous consumer appliances, from 400 members of an online panel. Generalizability theory (hereafter G theory) is used to assess the psychometric quality of the evaluation data in different <b>testing</b> <b>environments.</b> Findings – The results show that subjects with high innovativeness and change seeking report significantly more favorable concept evaluations and generate better quality data. However, the effect of innovativeness on testing outcomes and data quality would be reduced in virtual <b>testing</b> <b>environment.</b> Practical implications – The results indicate that using firm or industry norms to interpret the testing outcome will be biased unless it accounts for whether the screening processes result in equally innovative or variety seeking samples of respondents. Originality/value – Managerially, the current results indicate that a product manager wanting to concept test a pool of appliance concepts can benefit from screening for the respondents, who will provide higher quality concept testing data in a traditional <b>testing</b> <b>environment.</b> However, the effects of traits on data quality are mitigated in a virtual <b>testing</b> <b>environment.</b> The findings provide a surprising insight that subject selection is not a more critical issue in virtual testing...|$|R
5000|$|A CAPE-OPEN <b>testing</b> <b>environment</b> {{into which}} {{components}} can be plugged and tested for conformity against the CAPE-OPEN specifications.|$|R
5000|$|Designers (such as fashion designers, {{industrial}} designers, architects) use {{virtual artifacts}} (e.g. prototypes, <b>testing</b> <b>environments)</b> {{in their work}} process.|$|R
