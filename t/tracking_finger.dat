11|206|Public
50|$|Johnny Chung Lee (born 1979) is a human-computer {{interaction}} researcher currently working at Google on the Project Tango platform. Lee {{is best known}} for his work on Kinect development, and for extending the functionality of the Wii Remote controller of the Wii video game console, most notably by taking advantage of its high resolution IR camera.Lee's other projects include an interactive whiteboard, 3D head <b>tracking,</b> <b>finger</b> tracking, and a DIY telepresence robot.|$|E
40|$|The {{touchpad}} is the {{de facto}} standard input device for controlling the GUI on portable computers. Most touch-pads detect only finger contact and ignores other phys-ical actions, such as applying force or hovering over the device. In this paper, we introduce a novel touchpad capable of <b>tracking</b> <b>finger</b> hover and measuring normal and shear forces. We also present two design strategies for the hover- and force-enhanced touchpad: multi-level user interaction and mimicry of physical manipulation. We illustrate the two design strategies using two applica-tions that we developed based on the design strategies. Author Keywords Force sensing, hover tracking, proximity sensing, touchpa...|$|E
40|$|Abstract — Recent {{trends in}} {{technology}} aim to build highly interactive {{and easy to}} use applications using non conventional interaction devices such as Web Cam, Projector, Data Gloves etc. Among them Web Cam can be used for development of variety of applications such as Virtual Mouse, Image Grabber etc. these applications are tracking various gestures of human hand by some means, and using them programmatically. The aim {{of this paper is to}} present fundamentals of tracking colors from an image and video, so that using those colors as markers, user may be able to track fingers in a real time video. Keywords- Color detection, Finger <b>tracking,</b> <b>Finger</b> tracking using Computer vision, Color detection in real time video, Color identification using Computer vision. I...|$|E
5000|$|A <b>finger</b> <b>tracking</b> device <b>tracks</b> <b>fingers</b> in the 3D {{space or}} {{close to the surface}} without contact with a screen. Fingers are {{triangulated}} by technologies like stereo camera, time-of-flight and laser. Good examples of <b>finger</b> <b>tracking</b> pointing devices are LM3LABS' Ubiq'window and AirStrike ...|$|R
40|$|We {{present an}} {{algorithm}} called <b>finger</b> <b>tracking</b> for in-hand manipulation of three dimensional objects with independent robot fingers. We describe {{and analyze the}} differential control for <b>finger</b> <b>tracking</b> and extend it to on-line continuous control {{for a set of}} cooperating robot fingers. We show experimental data from a simulation. Finally, we discuss global control issues for <b>finger</b> <b>tracking</b> and compute lower bounds for reorientation by <b>finger</b> <b>tracking.</b> Our algorithm is computationally efficient, exact, and takes into consideration the full dynamics of the system...|$|R
40|$|Tactile {{maps are}} the {{standard}} media to convey geographical information to blind people. An approach for an interactive substitute for tactile maps is presented, called virtual tactile maps. It {{is based on}} an image processing system <b>tracking</b> <b>fingers</b> and game piece-like objects. Output is done through speech and sound. Users learn routes by constructing them with route bricks. 1...|$|R
40|$|Tabletop {{computers}} featuring multi-touch {{input and}} object tracking {{are a common}} platform for research on Tangible User Interfaces (also known as Tangible Interaction). However, such systems are confined to sensing activity on the tabletop surface, disregarding the rich and relatively unexplored interaction canvas above the tabletop. This dissertation contributes with tCAD, a 3 D modeling tool combining fiducial marker <b>tracking,</b> <b>finger</b> tracking and depth sensing in a single system. This dissertation presents the technical details of how these features were integrated, attesting to its viability through the design, development and early evaluation of the tCAD application. A key aspect of this work is {{a description of the}} interaction techniques enabled by merging tracked objects with direct user input on and above a table surface. Universidade da Madeir...|$|E
40|$|Abstract—The {{kinematics}} of {{the human}} hand is optimal with respect to force distribution during pinch as well as power grasp, reducing the tissue strain when exerting forces through opposing fingers and optimising contact faces. Quantifying this optimality is of key importance when constructing biomimetic robotic hands, but un-derstanding the exact human finger motion {{is also an important}} asset in, e. g., <b>tracking</b> <b>finger</b> movement during manipulation. The goal of the method presented here is to determine the precise orientations and positions of the axes of rotation of the finger joints by using suitable magnetic resonance imaging (MRI) images of a hand in various postures. The bones are segmented from the images, and their poses are estimated with respect to a reference posture. The axis orientations and positions ar...|$|E
40|$|A radial {{cumulative}} similarity transform for robust image correspondence We {{develop a}} local image-correspondence algorithm which performs well near occluding boundaries. Unlike traditional robust methods, our method can find correspondences {{when the only}} contrast present is the occluding boundary itself and when the sign of contrast along the boundary is possibly reversed. We define a new image transform which characterizes local image homogeneity, defined as an attribute value in a central region and a function describing the surrounding local similarity structure. In this paper we use radial similarity functions and color attributes; within each window we compute the central color and an image with the cumulative probability that color is unchanged along a ray from the center to a given point in the window. This representation is insensitive to structure outside an occluding boundary, but can model the boundary itself. We show comparative results <b>tracking</b> <b>finger,</b> mouth, and eye features. ...|$|E
40|$|Increasing {{interest}} in {{virtual and augmented}} reality is encouraging the development of unobtrusive, intuitive input interfaces for gesture recognition and 3 D interaction. Current approaches require the user to wear instrumented gloves, or rely on fixed cameras that lack precise <b>finger</b> <b>tracking.</b> The UbiHand is an input device that uses a miniature wrist-worn camera to <b>track</b> <b>finger</b> position, providing a natural and compact wearable input interface. A hand model is used to generate a 3 D representation of the hand, and a gesture recognition system can interpret finger movements as commands. ...|$|R
50|$|Concerns {{have been}} raised by cyber {{forensics}} experts at the University of Massachusetts who have developed a way to steal smartphone and tablet passwords using Google Glass. The specialists developed a software program that uses Google Glass to <b>track</b> <b>finger</b> shadows as someone types in their password. Their program then converts the touchpoints into the keys they were touching, allowing them to catch the passcodes.|$|R
40|$|We {{explored}} {{the use of}} a hover tracking touchpad in a laptop environment. In order to study the new experience, we im-plemented a prototype touchpad consisting of infrared LEDs and photo-transistors, which can <b>track</b> <b>fingers</b> as far as 10 mm over the surface. We demonstrate here three major interac-tion techniques that would become possible when a hover-tracking touchpad meets a laptop. ACM Classification: H 5. 2 [Information interfaces and pres...|$|R
40|$|Visually {{capturing}} {{human hand}} motion requires estimating the 3 D hand global pose {{as well as}} its local finger articulations. This is a challenging task that requires a search in a high dimensional space due to the high degrees of freedom that fingers exhibit and the self occlusions caused by global hand motion. In this paper we propose a divide and conquer approach to estimate both global and local hand motion. By looking into the palm and extra feature points provided by fingers, the hand pose is determined from the palm using Iterative Closed Point (ICP) algorithm and factorization method. The hand global pose serves as the base frame for the finger motion capturing. Noticing the natural hand motion constraints, we propose an efficient tracking algorithm based on sequential Monte Carlo technique for <b>tracking</b> <b>finger</b> motion. To enhance the accuracy, pose estimations and finger articulation tracking are performed in an iterative manner. Our experiments show that our approach is accurate and robust for natural hand movements. 1...|$|E
40|$|The {{development}} of techniques for monitoring finger movement {{is becoming increasingly}} important in areas, such as robotics, virtual reality, and rehabilitation. To date, various techniques have been proposed for tracking hand movements, but the majority suffer from poor accuracy and repeatability. Inspired by the articulated structure of finger joints, we propose a novel 3 -D printed optical sensor with a compact hinged configuration for <b>tracking</b> <b>finger</b> flexion. This sensor exploits Malus' law using the attenuation of light transmitted through crossed polarizers. The sensor consists of a single LED, two pieces of linear polarizing film, and a photodetector that detects the changes in polarized light intensity proportional to the angle of finger flexion. This paper presents the characterization of the proposed optical sensor and compares it with a commonly used commercial bend sensor. Results show that the bend sensor exhibits hysteresis error, low sensitivity at small angles, and significant temporal drift. In contrast, the optical sensor is more accurate (± 0. 5 °) in the measuring range from 0 ° to 90 °, and exhibits high repeatability and stability, {{as well as a}} fast dynamic response. Overall, the optical sensor outperforms the commercial bend sensor, and shows excellent potential for monitoring hand movements in real time...|$|E
40|$|The {{study of}} finger {{kinematics}} has developed into an important research area. Various hand tracking systems are currently available; however, {{they all have}} limited functionality. Generally, the most commonly adopted sensors are limited to measurements with one degree of freedom, i. e., flexion/extension of fingers. More advanced measurements including finger abduction, adduction, and circumduction are {{much more difficult to}} achieve. To overcome these limitations, we propose a two-axis 3 D printed optical sensor with a compact configuration for <b>tracking</b> <b>finger</b> motion. Based on Malus’ law, this sensor detects the angular changes by analyzing the attenuation of light transmitted through polarizing film. The sensor consists of two orthogonal axes each containing two pathways. The two readings from each axis are fused using a weighted average approach, enabling a measurement range up to 180 ∘ and an improvement in sensitivity. The sensor demonstrates high accuracy (± 0. 3 ∘), high repeatability, and low hysteresis error. Attaching the sensor to the index finger’s metacarpophalangeal joint, real-time movements consisting of flexion/extension, abduction/adduction and circumduction have been successfully recorded. The proposed two-axis sensor has demonstrated its capability for measuring finger movements with two degrees of freedom and can be potentially used to monitor other types of body motion...|$|E
40|$|This paper {{discusses}} about {{a simple}} Humanoid platform EkInBot, {{specifically designed for}} Human Robot Interaction Using Dynamic Finger gestures. EkInBot stands for Electronically Interactive Robot and has 8 Degrees of Freedom. The paper emphasis on design and realization of a simplified humanoid robot and implementing finger gesture identification using a system analogous to „Data Glove‟. The proposed gesture recognition mechanism has accelerometer sensors, that <b>tracks</b> <b>finger</b> movements and moves the robot with respect to it...|$|R
2500|$|Siouxsie Sioux – vocals, {{acoustic}} (track 2) {{and electric}} guitar (<b>track</b> 10), <b>finger</b> cymbals, camera (<b>track</b> 8), melodica (track 11), production ...|$|R
40|$|When using {{non-contact}} <b>finger</b> <b>tracking,</b> <b>fingers</b> can {{be classified}} as to which hand they belong to by analysing the phase relation of physiological tremor. In this paper, we show how 3 D capacitive sensors can pick up muscle tremor in fingers above a device. We develop a signal processing pipeline based on nonlinear phase synchronisation that can reliably group fingers to hands and experimentally validate our technique. This allows significant new gestural capabilities for 3 D finger sensing without additional hardware...|$|R
40|$|The {{kinematics}} of {{the human}} hand are optimal with respect to force distribution during pinch as well as power grasp, reducing the tissue strain when exerting forces through opposing fingers and optimising contact faces. Quantifying this optimality is of key importance when constructing biomimetic robotic hands, but understanding the exact human finger motion {{is also an important}} asset in, e. g., <b>tracking</b> <b>finger</b> movement during manipulation. The goal of the method presented here is to determine the precise orientations and positions of the axes of rotation of the finger joints by using suitable magnetic resonance imaging (MRI) images of a hand in various postures. The bones are segmented from the images, and their poses are estimated with respect to a reference posture. The axis orientations and positions are fitted numerically to match the measured bone motions. Eight joint types with varying degrees of freedom (DoF) are investigated for each joint, and the joint type is selected by setting a limit on the rotational and translational mean discrepancy. The method results in hand models with differing accuracy and complexity, of which three examples, ranging from 22 to 33 DoF, are presented. The ranges of motion of the joints show some consensus and some disagreement with data from literature. One of the models is published as an implementation for the free OpenSim simulation environment...|$|E
40|$|We {{present a}} new tactile {{feedback}} system for finger-based in-teractions in immersive virtual reality applications {{that consists of}} shape memory alloy wires wrapped around <b>tracked</b> <b>finger</b> thim-bles. The wires touch {{the inside of the}} finger tips and provide an impression when they are shortened. We use this system to com-municate finger contacts with virtual objects in an application for usability and reachability studies of car interiors. Our experiments and an initial pilot study revealed that this type of feedback helps users to perform direct manipulation tasks with more reliability...|$|R
5000|$|Pip Pyle - drums, {{glockenspiel}} (tracks 2, 5), pixiphone (track 5), gong (track 1), cowbell (track 1), tambourine (<b>track</b> 1), <b>finger</b> cymbals (<b>track</b> 2), shakers (track 2), bells (track 2) ...|$|R
5000|$|Dresscode black I - Shake (Exclusive <b>Track),</b> Lilith, Sperm <b>finger</b> ...|$|R
50|$|Zippy Chippy's 100th loss {{occurred}} on September 10, 2004, in the Northampton Fair at the Three County Fairgrounds. He went off at odds of 7-2, {{making him the}} second betting choice; however, Zippy Chippy finished last. In December 2004, he retired from racing to become an outrider pony at his hometown <b>track,</b> <b>Finger</b> Lakes racetrack in Farmington, New York, where he'd been banned from racing on September 8, 1998, after failing to leave the gate {{with the rest of}} the field for the third consecutive time. As an outrider pony, he escorted horses in the post parade and led them to the gate.|$|R
5000|$|TX5018 -- Lost Trax - Previously {{unreleased}} <b>tracks</b> by Mr. <b>Fingers</b> ...|$|R
5000|$|... #Caption: The game's {{scores are}} <b>tracked</b> on the <b>fingers</b> of both hands ...|$|R
50|$|Crunchfish's Touchless A3D {{software}} {{is able to}} detect and <b>track</b> objects (<b>fingers,</b> hand gestures and face movements) in three dimensions based on the video stream from an embedded standard camera in e.g. a mobile device.|$|R
40|$|We {{describe}} a particle filtering approach to inferring finger movements on capacitive sensing arrays. This technique allows the efficient combination of human movement models with accurate sensing models, and gives high-fidelity results with low-resolution sensor grids and <b>tracks</b> <b>finger</b> height. Our model provides uncertainty estimates, {{which can be}} linked to the interaction to provide appropriately smoothed responses as sensing perfomance degrades; system autonomy is increased as estimates of user behaviour become less certain. We demonstrate the particle filter approach with a map browser running with a very small sensor board, where finger position uncertainty is linked to autonomy handover. Author Keywords Uncertainty,particle filters, probabilistic interaction, capacitive sensing, H-metaphor...|$|R
40|$|In {{this paper}} we utilise magnetoresistive sensors and an Unscented Kalman Filter {{to develop a}} <b>finger</b> <b>tracking</b> system for {{physical}} therapy and human-machine interaction. The aim of this <b>finger</b> <b>tracking</b> system {{is to provide a}} light weight apparatus with a prolonged operational period. The <b>finger</b> <b>tracking</b> algorithm utilises two-dimensional measurements of each joint relative to a magnetic field reference point to obtain an accurate model of the finger position as opposed to other light weight systems that provide information in only one dimension. The nonlinear interaction between joint movements and sensor measurement requires a nonlinear filtering technique, as such, a Kalman filter that utilises an unscented transformation was utilised...|$|R
5000|$|... #Caption: <b>Finger</b> <b>tracking</b> of two pianists' fingers {{playing the}} same piece (slow motion, no sound).|$|R
50|$|In {{the field}} of {{technology}} and image processing, <b>finger</b> <b>tracking</b> is a high-resolution technique that is employed to know the consecutive position of the fingers of the user and hence represent objects in 3D.In addition to that, the <b>finger</b> <b>tracking</b> technique {{is used as a}} tool of the computer, acting as an external device in our computer, similar to a keyboard and a mouse.|$|R
3000|$|Corporate standard: CRT {{organized}} and completed some corporate standards with independent intellectual property rights, such as “straddle monorail traffic PC <b>track</b> beam <b>finger</b> board manufacturing and acceptance criteria” and “straddle monorail traffic PC track beam steel tension bearing manufacture and acceptance standard.” [...]...|$|R
40|$|Condensation, {{a form of}} likelihood-weighted {{particle}} filtering, {{has been}} successfully used to infer the shapes of highly constrained "active" contours in video sequences. However, when the contours are highly flexible (e. g. for <b>tracking</b> <b>fingers</b> of a hand), a computationally burdensome number of particles is needed to successfully approximate the contour distribution. We show how the Metropolis algorithm {{can be used to}} update a particle set representing a distribution over contours at each frame in a video sequence. We compare this method to condensation using a video sequence that requires highly flexible contours, and show that the new algorithm performs dramatically better that the condensation algorithm. We discuss the incorporation of this method into the "active contour" framework where a shape-subspace is used constrain shape variation. ...|$|R
5000|$|As {{described}} below, {{because of}} marker occlusion during capturing, <b>tracking</b> <b>fingers</b> {{is the most}} challenging part for optical motion capture systems (like Vicon, Optitracks, ART, [...].).Users of optical mocap systems claims that the most post-process work is usually due to finger capture. As the inertial mocap systems (if properly calibrated) are mostly {{without the need for}} post-process, the typical use for high end mocap users is to fuse data from inertial mocap systems (fingers) with optical mocap systems (body + position in space).The process of fusing mocap data is based on matching time codes of each frame for inertial and optical mocap system data source. This way any 3rd party software (for example MotionBuilder, Blender) can apply motions from two sources, independently of the mocap method used.|$|R
5000|$|... "She's So Modern" [...] (Geldof, Johnny <b>Fingers)</b> (<b>Track</b> 6 - 1 on Side 2 - on the European version) ...|$|R
40|$|The {{main goal}} of the bachelor’s thesis was to develop an {{application}} that allows users to interact with a computer without using any intermediate devices that require physical contact. The resulting interface {{makes it possible to}} use the functionalities of a Windows desktop relying only on gestures, provided the computer meets the requirements of using a Kinect sensor and is equipped with one. Because the library used to <b>track</b> <b>fingers</b> is still in development, the functionalities are limited at this point. The possibilities for future development in human-computer interaction using vision based hand recognition are endless and the interaction will become more natural and effortless. As the equipment used to recognize hand poses is becoming more affordable and available, the possibility that mechanical devices which need physical contact will become obsolete becomes progressively more of a reality...|$|R
5000|$|On {{the top of}} <b>finger</b> <b>tracking,</b> {{many users}} require {{positional}} tracking for the whole hand in space. Multiple methods {{can be used for}} this purpose: ...|$|R
