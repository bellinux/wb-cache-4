108|2034|Public
5000|$|... #Caption: An example {{implementation}} of the image preprocessing steps in <b>Traffic</b> <b>Sign</b> <b>detection</b> algorithm ...|$|E
5000|$|The {{equipment}} {{also include}} adaptive cruise control, lane departure warning, <b>traffic</b> <b>sign</b> <b>detection</b> with excess speed warning and blind spot alert. The car scored a five star rating at the 2015 Euro NCAP tests.|$|E
50|$|In July 2005 CycloMedia {{introduced}} {{another new}} production system, DCR 3, and a portable system {{making it possible}} to make recordings at locations that a car cannot reach. In 2006 the company again started to build a photo database of the Netherlands. Further developments were put in hand in the fields of camera technology (DCR 7, to make recordings while driving) and 3D imaging. In 2009 CycloMedia began automated <b>traffic</b> <b>sign</b> <b>detection</b> using Cyclorama.|$|E
40|$|This {{bachelor}} thesis {{focuses on}} <b>detection</b> of <b>traffic</b> <b>signs</b> in real-time. First of all, algorithms used for <b>traffic</b> <b>signs</b> <b>detection</b> will be presented. Description of approach {{used in this}} thesis based on shapes of <b>traffic</b> <b>signs</b> and modifications of this algorithm will follow. Evaluation of accomplished results with this algorithm will be also presented...|$|R
40|$|The Driving Assistance Systems (DAS) aim to {{help the}} vehicle drivers to proceed through {{different}} road situations. However, their main task {{is not only to}} safe one particular driver, but also to increase the safety for all traffic members. The problem domain here is huge and might be divided into the subtopics, like driver's fatigue detection, pedestrian tracking, obstacle collision avoidance, lane departure warnings and <b>traffic</b> <b>signs</b> <b>detection</b> and recognition. Advanced computer vision techniques are widely used in order to develop sufficient and robust systems for driving assistance. In this paper we discuss the video-based Hough-Transform driven objects detection algorithms and their applications for lane departure warnings, as well as for <b>traffic</b> <b>signs</b> <b>detection.</b> Furthermore, a high-speed hardware implementation of these algorithms on the FPGA/ASIC is also presented...|$|R
40|$|This bachelor's {{thesis is}} {{concerned}} about known methods of <b>detection</b> <b>traffic</b> <b>signs</b> in video sequence. In introduction are explained and located main benefits {{in the light of}} process speed and accuracy of detection. At the next chapters is designed system for <b>traffic</b> <b>signs</b> <b>detection</b> and classification. In the end is this system tested on prepared testing data and results are evaluated. The work is focused on method Template Matching for classification and color appearance model CieCam 97 for detecting candidate areas...|$|R
50|$|There are diverse {{algorithms}} {{for traffic}} sign recognition. Common ones {{are the ones}} based on {{the shape of the}} sign board. Typical sign board shapes like hexagon, circle, rectangle defines different types of signs, which can be used for classification. Other major algorithms for character recognition includes Haar-like features, Freeman Chain code, AdaBoost detection and deep learning neural networks methods. Haar-like features can be used to create cascaded classifiers which then can help detect the sign board characters. Deep learning can be incorporated for <b>traffic</b> <b>sign</b> <b>detection.</b> Polygonal approximation of digital curves using Ramer-Douglas-Peucker algorithm can be used to detect the shape of the sign boards and methods like Support Vector Machines and Byte-MCT with an AdaBoost classifier has been used in one of the methods to detect traffic signs.|$|E
40|$|This bachelor's {{thesis is}} about <b>traffic</b> <b>sign</b> <b>detection</b> in picture. There are written some known methods, their {{advantages}} and disadvantages. There is present {{implementation of the}} system for <b>traffic</b> <b>sign</b> <b>detection.</b> There {{are present in the}} last chapter      some tests that were done on the system with using testing set, which was created specialy for this purpose...|$|E
40|$|Abstract — <b>Traffic</b> <b>sign</b> <b>detection</b> {{is crucial}} in {{intelligent}} vehi-cles, no matter if one’s objective is to develop Advanced Driver Assistance Systems or autonomous cars. Recent advances in <b>traffic</b> <b>sign</b> <b>detection,</b> especially the great effort put into the competition German <b>Traffic</b> <b>Sign</b> <b>Detection</b> Benchmark, {{have given rise to}} very reliable detection systems when tested on European signs. The U. S., however, has a rather different approach to traffic sign design. This paper evaluates whether a current state-of-the-art traffic sign detector is useful for American signs. We find that for colorful, distinctively shaped signs, Integral Channel Features work well, but it fails on the large superclass of speed limit signs and similar designs. We also introduce an extension to the largest public dataset of American signs, the LISA Traffic Sign Dataset, and present an evaluation of tracking in the context of sign detection. We show that tracking essentially suppresses all false positives in our test set, and argue that in order to be useful for higher level analysis, any <b>traffic</b> <b>sign</b> <b>detection</b> system should contain tracking...|$|E
40|$|The aim of {{this paper}} is to present the first steps of the systems design that will be able to detect {{vertical}} <b>traffic</b> <b>signs</b> and to provide descriptions of the applied data processing methods. This system includes various functional blocks that are described in this paper. The basis of Vertical <b>Traffic</b> <b>Signs</b> <b>Detection</b> System is a pre-processing of a captured traffic scene ahead of vehicle. Main part of this paper contains a description of user friendly software interface for an image pre-processing...|$|R
40|$|Feature {{detection}} is {{a method}} for taking abstract information called features in an image and confirming whether there are the features on other images or not. One application of feature detection is object detection. This study aims to describe how to detect visual object at high speed, which {{is applied to the}} problem of <b>traffic</b> <b>signs</b> <b>detection.</b> In this study, the application was developed for the <b>detection</b> of <b>traffic</b> <b>signs,</b> which can be used on a moving vehicle, using the speeded up robust features (SURF) algorithm...|$|R
40|$|<b>Traffic</b> road <b>sign</b> <b>detection</b> and {{recognition}} {{is important to}} transport system with a robotic eyes or camera while driving in the road. This paper presents and overview the <b>traffic</b> road <b>sign</b> <b>detection</b> {{and recognition}}, we developed and implemented the procedure to extract the road sign from a natural complex image. The main objective {{of this paper is}} to design and construct a computer based system which can automatically detect the direction of the road sign. This paper is based upon a major approach to detect the direction. In this paper, we will demonstrate the basic idea of how detect the area and extract it. This system will play an important role for the detection purpose of specific domains like island, schools, <b>traffic</b> <b>sign,</b> universities, hospitals, offices etc...|$|R
40|$|<b>Traffic</b> <b>sign</b> <b>detection</b> and {{recognition}} {{is a difficult}} task, especially if we aim at detecting and recognizing signs in images captured under poor conditions. Complex backgrounds, obstructing objects, inappropriate distance of signs, shadow, and other lighting-related problems may {{make it difficult to}} detect and recognize signs in both rural and urban areas. In this paper we propose and test a system that employs image pre-processing, color filtering, color segmentation for <b>traffic</b> <b>sign</b> <b>detection</b> at the detection stage, feature extraction and trained neural networks for unique identification of signs at the recognition stage. The <b>traffic</b> <b>sign</b> <b>detection</b> {{and recognition}} system has been tested on actual roadside images taken under poor conditions. The images were selected in order to test the efficiency of the system under challenging conditions of inappropriate distance, traffic sign size, poor lighting and complex background. Suggestions are made for improving the performance of the system...|$|E
40|$|Abstract- In {{this paper}} {{a system for}} {{off-line}} traiiic sign detection is shown. Matlab-Image-processing toolbox is used for this purpose. The vision-based <b>traffic</b> <b>sign</b> <b>detection</b> module developed in this work manages 172 x 352 color images in RGB (Red, Green, Blue) format. The {{first step in the}} algorithm is to obtain the gradient image and its vertical edge projection. In a second step, a color and shape analisys is performed. <b>Traffic</b> <b>sign</b> <b>detection</b> and recognition have experimented increasing importance in the last times. This is due to the wide range of applications where this system can be used, as for instance, in intelligent vehicles, driver support systems, etc...|$|E
40|$|Abstract: A {{system for}} {{real-time}} <b>traffic</b> <b>sign</b> <b>detection</b> {{is described in}} this paper. The vision-based <b>traffic</b> <b>sign</b> <b>detection</b> module developed in this work is intended for assisted driving of road vehicles by handling color images in RGB (Red, Green and Blue) format. In a first step a preattentive area of interest is determined based on the vertical projection of edge pixels. In a second step, a shape analysis is performed. In a third step, a color analysis is performed, and finally, a template is fitted. Some results obtained {{on a series of}} real road images are presented in order to illustrate the robustness of the detection system. ...|$|E
40|$|Licence {{plates and}} <b>traffic</b> <b>signs</b> <b>detection</b> and {{recognition}} {{have a number}} of different applications relevant for transportation systems, such as traffic monitoring, detection of stolen vehicles, driver navigation support or any statistical research. A number of methods have been proposed, but only for particular cases and working under constraints (e. g. known text direction or high resolution). Therefore a new class of locally threshold separable detectors based on extremal regions, which can be adapted by machine learning techniques to arbitrary shapes, is proposed. In the test set of licence plate images taken from different viewpoints (- 45 °, 45 °), scales (from seven to hundreds of pixels height) even in bad illumination conditions and partial occlusions, the high detection accuracy is achieved (95 %). Finally we present the detector generic abilities by <b>traffic</b> <b>signs</b> <b>detection.</b> The standard classifier (neural network) within the detector selects a relevant subset of extremal regions, i. e. regions that are connected components of a thresholded image. Properties of extremal regions render the detector very robust to illumination change and partial occlusions. Robustness to a viewpoint change is achieved by using invariant descriptors and/or by modelling shape variations by the classifier. The time-complexity of the detection is approximately linear in the number of pixel and a non-optimized implementation runs at about 1 frame per second for a 640 × 480 image on a high-end PC...|$|R
40|$|Abstract: We {{present a}} new modular <b>traffic</b> <b>signs</b> {{recognition}} system, successfully applied to both American and European speed limit <b>signs.</b> Our <b>sign</b> <b>detection</b> step is {{based only on}} shape-detection (rectangles or circles). This enables it to work on grayscale images, contrary to most European competitors, which eases robustness to illumination conditions (notably night operation). Speed sign candidates are classified (or rejected) by segmenting potential digits inside them (which is rather original and has several advantages), and then applying a neural digit recognition. The global detection rate is ~ 90 % for both (standard) U. S. and E. U. speed signs, with a misclassification rate 150 minutes of video. The system processes in real-time ~ 20 frames/s on a standard high-end laptop. INTRODUCTION AND RELATED WORKS Automatic <b>traffic</b> <b>signs</b> <b>detection</b> and recognition (TSR) is a key module for new driving assistance smart functions, {{as it is a}} requirement for the necessary level of traffic scene understanding. For example a robust visual real-time TSR system is a pre-requisite for developing a system for reminding the driver what is the current speed limit. Some of th...|$|R
5000|$|<b>Traffic</b> <b>sign</b> {{recognition}} is a technology {{by which a}} vehicle is able to recognise the <b>traffic</b> <b>signs</b> put on the road e.g. [...] "speed limit" [...] or [...] "children" [...] or [...] "turn ahead". This {{is part of the}} features collectively called ADAS. The technology is being developed by many automotive suppliers, including Continental and Delphi. It uses Image processing techniques to detect the <b>traffic</b> <b>signs.</b> The <b>detection</b> methods can be generally divided into color based, shape based and learning based methods.|$|R
40|$|Conference Name:International Conference on Informatics and Management Science, IMS 2012. Conference Address: Kunming, China. Time:December 21, 2012 - December 23, 2012. National Natural Science Foundation of China, (NSFC) As an {{important}} part of the Intelligent Traffic System (ITS), <b>traffic</b> <b>sign</b> <b>detection</b> is {{an important}} pre-procession for ITS. This paper developed a novel sign detection algorithm based on the Shape-band template matching which models an object within a bandwidth of its sketch/contour. Moreover, shape-band is also used as a feature selection method in this paper. Experimental results show the <b>traffic</b> <b>sign</b> <b>detection</b> is robust towards deformation of signs, illumination change and partial occlusion. ? 2013 Springer-Verlag...|$|E
40|$|Abstract — This paper {{proposes a}} {{computer}} vision based method for <b>traffic</b> <b>sign</b> <b>detection</b> recognition and tracking {{based on the}} color {{and shape of the}} road sign and its geometric attributes. The study of <b>traffic</b> <b>sign</b> <b>detection</b> has been of great interests and often addressed by a three-stage procedure involving detection, tracking and classification. Road safety is an issue of national concern and its impacts is on the economy, public health and the general welfare of the people. We report on-going efforts to develop an intelligent agent for detecting and tracking traffic signs for vision based Driver Assistance System (DAS). Initially paper describes general framework for <b>traffic</b> <b>sign</b> <b>detection</b> and their important subsystems. Generally, computer vision techniques consist of three important stages, color segmentation, sign detection and classification. We explore the important sub-systems of each of these stages, and identify their advantages and disadvantages. We propose a system based on the framework to detect circular and triangular road traffic signs making use of artificial intelligence techniques such as heuristics functions for detecting shapes. System is implemented in real time environment and tested on national highway and aims to help vehicle driver to have safer and enjoyable driving thereby concentrating on his actual workload. Index Terms — Computer vision, driver assistance system, object detection, openCV I...|$|E
40|$|Conference Name: 14 th Pacific-Rim Conference on Multimedia, PCM 2013. Conference Address: Nanjing, China. Time:December 13, 2013 - December 16, 2013. <b>Traffic</b> <b>sign</b> <b>detection</b> is very {{important}} to the vehicle intelligent auxiliary driving system and the driverless system. However, <b>traffic</b> <b>sign</b> <b>detection</b> is still a challenging problem, and there is not a satisfactory solution until now. In this paper, we aim at improving the speed and accuracy of <b>traffic</b> <b>sign</b> <b>detection.</b> In order to improve the detection speed, we use the image-forming principle to select the scale of sliding windows instead of the standard sliding window scheme. This operation will reduce the computational complexity from O(N 4) to O(N 2). In order to improve the detection accuracy, we adopt the hierarchical detection scheme. In the first stage, we use the cascade GentleAdaBoost classifier combined with the Haar-like features; in the second stage, we use the GentleAdaboost classifier combined with the multiple features fusing the color cues. The hierarchical detection scheme greatly reduces the false positive rate. We implement our approach on the Swedish Traffic Signs Dataset, the experimental results demonstrate our approach is effective and our approach could greatly reduce the false positive rate while keeping the detection rate. ? Springer International Publishing Switzerland 2013...|$|E
40|$|<b>Traffic</b> <b>signs</b> provide drivers {{important}} information {{for safety and}} efficient navigation. Automatic detection and recognition of <b>traffic</b> <b>signs</b> inevitably become more popular. In this paper, an efficient algorithm/platform is presented to achieve automatic alert <b>traffic</b> <b>signs</b> <b>detection</b> and recognition. Histogram of Gradient (HOG) is adapted to extract features and an over-complete set of 1680 features is designed. A cascade classifier for each sign is trained and built with Support Vector Machine (SVM) as the single stage classifier. To encode the color information, features from different layers in RGB space are combined into a single vector as the feature descriptor. Furthermore, color segmentation is performed to reduce the search regions and a specially designed integral image is used to extract features in a look-up manner. Experimental results show that our system can achieve invariance to illumination, scale and pose. The smallest detectable size is 14 ! 14. The average detection rate is around 98 % and the false positive rate is around 1. 6 %. The processing time for a typical 640 ! 480 image is around 7 - 9 seconds. 1...|$|R
40|$|The present paper {{describes}} the framework and components of an instrumented vehicle for driver assistance and safety. The experimental platform {{is based on}} the use of an on-board computer vision system to capture the <b>traffic</b> <b>signs,</b> and on a multiple of electronic components to capture the vehicle state and identify drivers. The hardware architecture is designed with the purpose of making the deployment of functionalities related to driver assistance and road safety easy. The paper covers firstly the description of the hardware architecture, and then describes some of the implemented functionalities such as driver assistance based on <b>traffic</b> <b>signs</b> <b>detection</b> and recognition, <b>traffic</b> violation recorder, and a realization of an emergency call system. Manuscript received 15 February, 2012. This work {{was supported in part by}} the Regional Government of Madrid under the S 2009 /DPI- 1509 -SEGVAUTO grant, and the PN I+D+i under the TRA 2010 - 20225 -C 03 - 02 SAMPLER grant...|$|R
40|$|Abstract — <b>Traffic</b> <b>signs</b> <b>detection</b> {{has been}} {{thoroughly}} studied {{for a long}} time. However, road panels detection still remains a challenge in computer vision due to the huge variability of types of traffic panels, as the information depicted in them is not restricted. This paper presents a method to detect traffic panels in street-level images as an application to Intelligent Transportation Systems (ITS), since the main purpose can be to make an automatic inventory of the traffic panels located in a road to support maintenance and to assist drivers {{in order to improve}} human quality of life. The proposed method extracts local descriptors at some interest points after applying a color detection method for blue and white pixels. Then, the images are modeled using a Bag of Visual Words technique and classified using Naı̈ve Bayes theory and SVM. Experimental results on real images from Google Street View prove the efficiency of the proposed method and give way to using street-level images for different applications on robotics and ITS. I...|$|R
40|$|We {{present a}} General Purpose Graphics Processing Unit (GPGPU) based {{real-time}} <b>traffic</b> <b>sign</b> <b>detection</b> and recognition method that is robust against illumination changes. There {{have been many}} approaches to traffic sign recognition in various research fields; however, previous approaches faced several limitations when under low illumination or wide variance of light conditions. To overcome these drawbacks and improve processing speeds, we propose a method that 1) is robust against illumination changes, 2) uses GPGPU-based real-time <b>traffic</b> <b>sign</b> <b>detection,</b> and 3) performs region detecting and recognition using a hierarchical model. This method produces stable results in low illumination environments. Both detection and hierarchical recognition are performed in real-time, and the proposed method achieves 0. 97 F 1 -score on our collective dataset, which uses the Vienna convention traffic rules (Germany and South Korea) ...|$|E
40|$|Automatic <b>traffic</b> <b>sign</b> <b>detection</b> is {{challenging}} {{due to the}} complexity of scene images, and fast detection is required in real applications such as driver assistance systems. In this paper, we propose a fast <b>traffic</b> <b>sign</b> <b>detection</b> method based on a cascade method with saliency test and neighboring scale awareness. In the cascade method, feature maps of several channels are extracted efficiently using approximation techniques. Sliding windows are pruned hierarchically using coarse-to-fine classifiers and the correlation between neighboring scales. The cascade system has only one free parameter, while the multiple thresholds are selected by a data-driven approach. To further increase speed, we also use a novel saliency test based on mid-level features to pre-prune background windows. Experiments on two public traffic sign data sets show that the proposed method achieves competing performance and runs 27 times as fast as most of the state-of-the-art methods...|$|E
40|$|TSR (Traffic sign recognition) is an {{important}} problem in ITS (intelligent traffic system), which is being paid more and more attention for realizing drivers assisting system and unmanned vehicle etc. TSR consists of two steps: detection and recognition, and this paper describe a new <b>traffic</b> <b>sign</b> <b>detection</b> method. The design principle of the traffic sign is comply with the visual attention mechanism of human, so we propose a method using visual attention mechanism to detect traffic sign,which is reasonable. In our method, the whole scene will firstly be analyzed by visual attention model to acquire the area where traffic signs might be placed. And then, these candidate areas will be analyzed according to the shape characteristics of the traffic sign to detect traffic signs. In <b>traffic</b> <b>sign</b> <b>detection</b> experiments, the result shows the proposed method is effectively and robust than other existing saliency detection method...|$|E
40|$|This {{thesis is}} all about the visual attention, {{starting}} from understanding the human visual system up till applying this mechanism to a real-world computer vision application. This has been achieved by taking the advantage of latest findings about the human visual attention and the increased performance of the computers. These two facts played a vital role in simulating the many different aspects of this visual behavior. In addition, the concept of bio-inspired visual attention systems have become applicable due to the emergence of different interdisciplinary approaches to vision which leads to a beneficial interaction between the scientists related to different fields. The problems of high complexities in computer vision lead to consider the visual attention paradigm {{to become a part of}} real time computer vision solutions which have increasing demand.   In this thesis work, different aspects of visual attention paradigm have been dealt ranging from the biological modeling to the real-world computer vision tasks implementation based on this visual behavior. The implementation of <b>traffic</b> <b>signs</b> <b>detection</b> and recognition system benefited from this mechanism is the central part of this thesis work. ...|$|R
40|$|The paper {{describes}} a colour-based segmentation method of European <b>traffic</b> <b>signs</b> for <b>detection</b> in an image and a feature-based recognition method for categorizing them into given classes. At first, we have performed analysis of several well-known colour spaces as the RGB, HSV and YCbCr {{often used for}} segmentation purposes. The HSV colour space has been chosen as the most convenient for segmentation step and colour-based models of <b>traffic</b> <b>signs</b> representatives were created. Next, the fast radial symmetry (FRS) detection method and the Harris corner detector were used to recognize circles, triangles and squares as main geometrical shapes of the <b>traffic</b> <b>signs.</b> For these purposes a new gallery of real-life images containing <b>traffic</b> <b>signs</b> has been created and analysed. Overall efficiency of our recognition method is approx. 93 % on our gallery and is usable for real-time implementations...|$|R
40|$|The {{objective}} of the diploma thesis {{is to develop a}} speed <b>traffic</b> <b>signs</b> <b>detection</b> application on the Android platform, which could be extended to other mobile operating systems with minimal adjustments. The programme is intended for all vehicles and other transport means in traffic, where the tablet or phone can be assembled so that does not disturb the driver at driving. The programme is appropriate for drivers who have not had similar systems installed in their cars. The diploma thesis presents a programme that is mostly prepared in the Java programming language for the Android operating system, used tools and a short description as well as procedures required for proper operations of the programme. The thesis also explains the <b>sign</b> <b>detection</b> issues and methods used to enable detection, as well as solutions used in the existing systems. Signs are detected by a camera set on the device; acquired data are processed by the OpenCV library. The programme does not use other technologies for detection and is not connected to the GPS system. The programme is intended for a long-term use in the vehicle, therefore, the battery autonomy is provided with the appropriate selection of the background colour that covers most of the screen, and with imaging in lower resolution. During the use, the driver set the device in a holder and turns it in the direction of driving so that the camera is not covered and slightly directed to the right side facing the signs...|$|R
40|$|Robust {{and fast}} traffic sign {{recognition}} is very important but difficult for safe driving assistance systems. This study addresses fast and robust {{traffic sign recognition}} to enhance driving safety. The proposed method includes three stages. First, a typical Hough transformation is adopted to implement coarse-grained location of the candidate regions of traffic signs. Second, a RIBP (Rotation Invariant Binary Pattern) based feature in the affine and Gaussian space is proposed to reduce the time of <b>traffic</b> <b>sign</b> <b>detection</b> and achieve robust <b>traffic</b> <b>sign</b> <b>detection</b> in terms of scale, rotation, and illumination. Third, the techniques of ANN (Artificial Neutral Network) based feature dimension reduction and classification are designed to reduce the traffic sign recognition time. Compared with the current work, the experimental results in the public datasets show that this work achieves robustness in traffic sign recognition with comparable recognition accuracy and faster processing speed, including training speed and recognition speed...|$|E
40|$|Abstract — An {{automatic}} <b>traffic</b> <b>sign</b> <b>detection</b> {{system would}} be important in a driver assistance system. In this paper, an approach for detecting Norwegian speed limit signs is proposed. It consists of three major steps: Color-based filtering, locating sign(s) in an image and detection of numbers on the sign. About 91 % correct recognition is achieved for a selection of 198 images. I...|$|E
40|$|Abstract — We {{present a}} <b>traffic</b> <b>sign</b> <b>detection</b> model consist-ing of two modules. The first module is for ROI (region of interest) extraction. By {{supervised}} learning, it transforms the color images to gray images {{such that the}} characteristic colors for the traffic signs are more distinguishable in the gray images. It follows shape template matching, where a set of template...|$|E
40|$|Digital {{documents}} {{are easy to}} handle, share and store than hard copy of documents. These made people to prefer digital document over hard copy of documents. Digital {{documents are}} nothing but scanned images of a document or natural images of notice boards, <b>traffic</b> <b>signs.</b> Text <b>detection</b> is an important process required to extract text from images. Text from images can be extracted using Optical Character Recognition (OCR). OCR works in three phases as pre-processing, segmentation, character recognition. Pre-processing is the first phase which uses different techniques for making text easy to extract from images. In segmentation phase, each character is isolated. Then this will be given as input to OCR recognition phase which will compare it with training data-set and will recognize character. In this survey paper, different techniques for OCR are discussed...|$|R
40|$|Conference Name: 4 th International Conference on Internet Multimedia Computing and Service, ICIMCS 2012. Conference Address: Wuhan, China. Time:September 9, 2012 - September 11, 2012. ACM SIGMM China Chapter; Central China Normal University; National Science Foundation of China Academy of Sciences; NEC Laboratories China; Microsoft Research; Wuhan Daqian Information Technology Company LimitedIn this paper, {{we design}} the color fused {{multiple}} features {{to describe a}} <b>traffic</b> <b>sign,</b> and we further implement this description method to detect <b>traffic</b> <b>signs</b> and to classify multi-class <b>traffic</b> <b>signs.</b> At the <b>detection</b> stage, we utilize the GentleAdaboost classifier to separate <b>traffic</b> <b>signs</b> from the background; at the classification stage, we implement the random forest classifier to classify multi-class <b>traffic</b> <b>signs.</b> We do the extensive experiments on the popular standard <b>traffic</b> <b>sign</b> datasets: the German <b>Traffic</b> <b>Sign</b> Recognition Benchmark and the Swedish <b>Traffic</b> <b>Signs</b> Dataset. We compare eight features which include the HOG feature, the LBP feature, the color cues and their different combinations. We also compare the popular classifiers for <b>traffic</b> <b>sign</b> recognition. The experimental results demonstrate that the color fused feature achieves better classification performance than the feature without color cues, and the GentleAdaboost classifier achieves the better comprehensive performance of the binary classification, and the random forest classifier achieves the best multi-class classification accuracy. Copyright 漏 2012 ACM...|$|R
40|$|This {{technical}} report describes the research work on automatic recognizing Chinese <b>traffic</b> <b>signs</b> from an implicit public resource, i. e. street views. First, we give a comprehensive survey on Chinese <b>traffic</b> <b>signs</b> and introduce our approaches for collecting street view images {{that can be}} used for experimental purposes. Then, we introduce our coarse-to-fine recognition framework consisting of <b>sign</b> <b>detection,</b> <b>sign</b> salient region segmentation, feature extraction (including simple text recognition from signs), and subsequent sign classification. We also propose to incrementally build a sign dataset in a semi-automatic way, aiming at reducing manual effort. Experiments on collected datasets for both <b>sign</b> <b>detection</b> and classification have validated that the proposed framework is feasible and capable of recognizing multiple categories of Chinese <b>traffic</b> <b>signs</b> in a single input image...|$|R
