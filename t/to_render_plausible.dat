10|10000|Public
40|$|The {{ability to}} {{interpolate}} between images taken at different time and viewpoints directly in image space opens up new possiblities. The goal {{of our work}} is to create plausible in-between images in real time {{without the need for}} anintermediate 3 Dreconstruction. Thisenablesustoalsointerpolatebetweenimagesrecordedwithuncalibrated andunsynchronizedcameras. Inourapproachweuseanoveldiscontiniuitypreservingimagedeformationmodel torobustlyestimatedensecorrespondencesbasedonlocalhomographies. Oncecorrespondenceshavebeencomputed we are able <b>to</b> <b>render</b> <b>plausible</b> in-between images in real time while properly handling occlusions. We discusstherelation ofour approach tohuman motionperception andother image interpolation techniques. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 3 [Computer Graphics]: Bitmap and framebuffer operations 1...|$|E
40|$|International audienceThis paper {{presents}} a novel image-based approach <b>to</b> <b>render</b> <b>plausible</b> soft shadows for complex dynamic scenes with rectangular light sources. The algorithm's performance is mostly {{independent of the}} scene complexity and the source's size. Occluders and receivers {{do not need to}} be separated and no knowledge about the scene representation is required, making the method easy to use. The main idea is to approximate the occlusion in the scene with pre- filtered occlusion textures. The visibility of the light source at a point in space is estimated by accumulating the occlusion caused by each texture, using a novel formula based on probabilities...|$|E
40|$|Abstract—Reflections, refractions, and {{caustics}} {{are very}} important for rendering global illumination images. Although many methods {{can be applied to}} generate these effects, the rendering performance is not satisfactory for interactive applications. In this paper, complex ray-object intersections are simplified so that the intersections can be computed on a GPU, and an iterative computing scheme based on the depth buffers is used for correcting the approximate results caused by the simplification. As a result, reflections and refractions of environment maps and nearby geometry can be rendered on a GPU interactively without preprocessing. We can even achieve interactive recursive reflections and refractions by using an object-impostor technique. Moreover, caustic effects caused by reflections and refractions can be rendered by placing the eye at the light. Rendered results prove that our method is sufficiently efficient <b>to</b> <b>render</b> <b>plausible</b> images interactively for many interactive applications...|$|E
40|$|For a {{brilliant}} satire on humanity, I {{can think of}} no better author to turn to than Aldous Huxley. His rhetoric is flawless, his characters unbelievably typical, and his satire tinged with {{just the right amount of}} reality <b>to</b> <b>render</b> it <b>plausible.</b> Born in England, Mr. Huxley has no more mercy on his own countrymen than he has on those of other nationalities. His satire is universal and completely nonpartisan...|$|R
40|$|The {{purpose of}} this paper is twofold. First, we present a {{conjecture}} to the effect that the ranks of the syzygy modules of a smooth projective variety become normally distributed as the positivity of the embedding line bundle grows. Then, in an attempt <b>to</b> <b>render</b> the conjecture <b>plausible,</b> we prove a result suggesting that this is in any event the typical behavior fro...|$|R
40|$|Figure 1 : Soft shadows {{generated}} by ESSM, tested with different scenes. In this paper we present an image-based algorithm <b>to</b> <b>render</b> visually <b>plausible</b> anti-aliased soft shadows in real time. Our technique employs a new shadow pre-filtering method {{based on an}} extended exponential shadow map-ping theory. The algorithm achieves faithful contact shadows by adopting an optimal approximation to exponential shadow reconstruction function. Benefiting from a novel overflow free summed area table tile grid data structure, numerical stability is guaranteed and error filtering response is avoided. By integrating an adaptive anisotropic filtering method, the proposed algorithm can produce high quality smooth shadows both in large penumbra areas and in high frequency sharp transitions, meanwhile guarantee cheap memory consumption and high performance...|$|R
40|$|This paper investigates {{contemporary}} Mandarin Chinese and English discourse topic across text genres <b>to</b> <b>render</b> <b>plausible</b> interpretations {{based upon}} a relevance-theoretic approach, as opposed to previous studies from syntactic/structural and functional/ cognitive points of view. Examining discourse topic from a cognitive-pragmatic perspective will not merely facilitate readers with more accessible contextual effects such as implicatures, but also subtopics such as grounding and composite topics can also be approached layer by layer with regard to cognition and language. This {{plays a crucial role}} in perception, comprehension and interpretation of utterances and non-verbal communication, and hence the mental processes of assigning/deciding a topic. The topic may thus vary from a word, short phrases to a sentence, and, above all, it is the gist that inferred by the audience that eventually forms the basis for the topic of the text/discourse...|$|E
30|$|In this paper, we {{reflect on}} the process in which we iteratively {{developed}} and refined the scaffolding support. We present a generic framework for designing distributed scaffolding that has guided us in examining and refining (or revising) the interplay among various forms of scaffolding in the learning model across various design-based research (DBR) cycles of our study on Chinese-PP. We adopt DBR {{to carry out the}} iterative process of designing, experimenting, reflecting upon, and redesigning the learning model and applications, and to integrate design principles with technological affordances <b>to</b> <b>render</b> <b>plausible</b> solutions (Brown 1992; Collins 1992). We will narrate two completed DBR cycles of our study to demonstrate how our scaffolding design framework has assisted us in accomplishing crucial revamps in the learning and technological design, in addressing the challenges we encountered and in preserving good practices that emerged among the students and the teacher during the study.|$|E
40|$|The {{history of}} {{philosophy}} {{is in no}} small measure a series of attempts to institute a fail-safe method. In response to what they take to be the scandal of disagreement (disagreement itself being judged as scandalous), a number of historically influential philosophers (e. g., Descartes, Peirce, Husserl, and Carnap) have time and again tried to craft a method for guaranteeing agreement. In light of the failure of these attempts, this tendency might be seen as remotely analogous to what is called in psychoanalytic parlance a ???repetition compulsion. ??? In any event, historical reflections on this repeated tendency promise to be illuminating. But there is a polemical purpose animating these historical reflections. The author tries, in light of these reflections, <b>to</b> <b>render</b> <b>plausible</b> the suggestion that this tendency amounts to a tyranny of method and, in turn, such tyranny results in an inevitable impoverishment of philosophical thought...|$|E
40|$|The {{simulation}} of complex layers of folds of cloth {{can be handled}} through algorithms which take the physical dynamics into account. In many cases, however, it is sufficient to generate wrinkles {{on a piece of}} garment which mostly appears spread out. This paper presents a corresponding fully GPU-based, easy-to-control, and robust method <b>to</b> generate and <b>render</b> <b>plausible</b> and detailed folds. This simulation is generated from an animated mesh. A relaxation step ensures that the behavior remains globally consistent. The resulting wrinkle field controls the lighting and distorts the texture in a way which closely simulates an actually deformed surface. No highly tessellated mesh is required to compute the position of the folds or <b>to</b> <b>render</b> them. Furthermore, the solution provides a 3 D paint interface through which the user may bias the computation {{in such a way that}} folds already appear in the rest pose...|$|R
40|$|Bradley’s essay marks a key {{historical}} {{moment in the}} development of penal theories. The orthodox view is that different penal goals cannot be united in a coherent framework. Bradley demonstrates that penal pluralism in a coherent theory is possible, but there remains the problem of whether it can be rendered compelling. While Bradley’s specific proposal may require revisions, his approach helps to reveal how we might construct the coherent framework we require for the penal pluralism adopted in our widely used sentencing guidelines. Bradley shows that penal pluralism can be possible. Our project is <b>to</b> <b>render</b> it more <b>plausible...</b>|$|R
40|$|The {{purpose of}} this paper is twofold. First, we present a {{conjecture}} to the effect that the ranks of the syzygy modules of a smooth projective variety become normally distributed as the positivity of the embedding line bundle grows. Then, in an attempt <b>to</b> <b>render</b> the conjecture <b>plausible,</b> we prove a result suggesting that this is in any event the typical behavior from a probabilistic point of view. Specifically, we consider a "random" Betti table with a fixed number of rows, sampled according to a uniform choice of Boij-Soderberg coefficients. We compute the asymptotics of the entries as the length of the table goes to infinity, and show that they become normally distributed with high probability...|$|R
40|$|I seek {{in these}} pages to set out a new account of {{political}} disobedience that underwrites a sympathetic reconstruction of the prominent contemporary cases of disobedient protest and, moreover, justifies some of them. This theory of disobedience {{is very different from}} the traditional liberal view; it in some respects takes an opposite approach. In particular, the view that I propose departs from the liberal project ofjustifying political disobedience from without democracy, by reference to inherent limits on political authority, including even the authority of democratic governments-an idea that renders liberal political disobedience, among other things, democracy-limiting disobedience. My proposal, by contrast, attempts to justify political disobedience from within democratic theory, emphasizing the support that political disobedience can provide for the broader political process by correcting democratic deficits in law and policy that inevitably threaten every democracy. The argument aims to construct a precise account of these deficits and of the contribution that political disobedience can play in overcoming them. Instead of being a theory of democracy-limiting disobedience, this is a theory of democracy-enhancing disobedience or, more simply, democratic disobedience. It aims <b>to</b> <b>render</b> <b>plausible</b> the counterintuitive claim that disobeying the laws of a democratic state can serve democracy. Indeed, the argument casts democratic disobedience as an unavoidable, integral part of a wellfunctioning democratic process...|$|E
40|$|As {{long as we}} rely {{on human}} beings to resolve {{conflicts}} with respect for legal certainty and justice, a continued investment in (a realistic assessment of) the condition humana is crucial. This (for lawyers rather atypical) thesis wants <b>to</b> <b>render</b> <b>plausible</b> the claim that Belgian judges are having a rough time. To that end we develop, on the one hand, a ‘phenomenological’ argument – i. e. we lay bare phenomena and symptoms that become highly visible when one aims at carefully sketching the “judicial condition” – and, on the other hand, we focus in a more philosophical manner on the reasons {{as to why the}} women and men on the bench have to discharge their judicial duties and considerable responsibilities under all but common circumstances, with the juridization of the social fabric, the judicialization of politics, and the judiciary's bureaucratization inducing unpalatable consequences and nervousness regarding the separation and collaboration of powers. In order to justify all this, a quite circumstantial problematization as well as an explanation of the rather unusual methodology was needed. Indeed, a fairly essayistic approach with its inevitable digressions was adopted and aggregated insights from multiple disciplines were applied. In the second part, some four phenomena, among which judicial candor both in- and outside the courtroom as well as the rise of New Public Management-thinking, are commented upon and are contextualized more broadly. A longer third part attempts to trace these symptoms back to the rather reductionist anthropology undergirding the “classic” image of the judge as “bouche de la loi”. Free will skepticism and radical-immanentism (with collectivisms and statisms as somehow predictable result) are linked to the phenomena studied in the second part, and subsequently criticized. Being increasingly forced to empathically render custom-made verdicts in plain language, judges operate in a far from obvious societal climate characterized by a certain meaninglessness, by frequent calls for more government interventionism, and by a lasting and sometimes even cultivated opaqueness. Upon reflexion, it is somewhat understandable that radicalisms of different stripe flourish nowadays. A thorough reconsideration of the task (and scope) of both government and legal training, and a realistic, confidence-building transparency when it comes to pertinent aspects of the personality of (future) judges (as is the case abroad and especially in common-law systems) are highly recommended. status: accepte...|$|E
40|$|Pulsed tissue Doppler {{is a new}} technique, {{which can}} {{investigate}} longitudinal left ventricular(LV) function, by measuring tissue velocities and timings. Patients with acute coronarysyndromes (ACS) frequently display a reduced longitudinal function. They also developglobal LV filling impairment. This pathology involves an elevated LV filling pressure (FP),left atrial (LA) enlargement and elevation of right ventricular pressure (RVp). We aimed toinvestigate the relative timing of the onsets of the LV early diastolic longitudinal wall motionand blood flow, and further, to evaluate clinical tools to assess global LV filling. We studied 160 ACS patients and 60 controls with echocardiography, including pulsed tissueDoppler. Using pulsed blood pool Doppler, we semi-quantitatively classified the patients withrespect to LV filling: normal (group 0); delayed relaxation (group 1); isolated pathologicalmitral-pulmonary venous-A-wave-duration difference (group 2); pseudo normal (group 3); ora restrictive (group 4) filling pattern. The temporal onset relationship of the LV early diastolicwall lengthening (e) and the mitral inflow (E) was explored, for a regional wall analysis(paper I). In order to evaluate a recent application, suggested to predict pulmonary capillarywedge pressure (PCWP) through the formulas tau= 32 + 0. 7 x (e-E) and PCWP = LV endsystolicpressure x e-IVRT/ tau (IVRT=the isovolumic relaxation time), we tested these formulasin normal individuals, at rest and during non-pharmacological preload alterations (Paper IV). The sensitivity of a new LV filling variable, the E/e (=E/E) filling index was investigatedby comparing E/e to RVp in their identification of a Doppler-assumed elevated LVFP, i. e. apseudo normal or a restrictive filling pattern (Paper II). We compared the intraindividual atrialsize difference and absolute LA size, as detectors of LA enlargement (Paper III). In the patients, e started later than E (12 ± 30 vs. 2 ± 19 ms later, p 15 and an RVp > 30 mmHg had the following (%) sensitivity (32 / 94),specificity (95 / 76), positive (68 / 59), and negative (80 / 97) predictive value of a diagnosedgroup 3 or 4. Absolute LA area, LA area/body height and LA-right atrial area indicated aLA enlargement in; for controls: 2 %, 2 % and 4 %; and for patients: group 0 and 1 : 15 %, 17 %and 46 %; group 2 : 26 %, 29 % and 52 %; and group 3 and 4 : 42 %, 38 % and 54 %. In ACS patients, the early diastolic LV tissue- to blood temporal relationship may reveal anasynchronous, and {{in relation to the}} mitral inflow delayed, initial LV wall lengthening. The formulas to predict PCWP failed <b>to</b> <b>render</b> <b>plausible</b> values in normal individuals. TheE/e filling index > 15, as a single variable, may have a limited sensitivity of an elevated LVFP. An RVp of ! 30 mmHg could exclude a currently elevated LVFP. Atrial size inequality cansensitively detect LA enlargement, especially in only mildly impaired LV filling...|$|E
40|$|Exploring {{temporal}} coherence among light transport paths {{is very important}} to remove temporally perception-sensitive artifacts in animation rendering. Using the contribution of a light transport path to all frames in an animation as the sampling distribution function allows us to adapt Markov Chain Monte Carlo (MCMC) algorithms to exploit the temporal and spatial coherence among paths in order to generate a perceptually pleasant animation. A new perturbation technique called time perturbation is developed to explore the {{temporal coherence}} among paths. Furthermore, in order <b>to</b> make animation <b>rendering</b> <b>plausible,</b> we distribute iterative computational tasks to a pool of computers for parallel computation. Each task is rendered with a set of parameters adapted according to the local properties of each task. We demonstrate that this local adaptation does not introduce bias statistically. The resulting animations are perceptually better than those rendered in a frame-by-frame manner. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 7 [Computer Graphics]: Raytracing 1...|$|R
40|$|International audienceIn {{this paper}} {{we present a}} novel image based {{algorithm}} <b>to</b> <b>render</b> visually <b>plausible</b> anti-aliased soft shadows in a robust and efﬁcient manner. To achieve both high visual quality and high performance, it employs an accurate shadow map ﬁltering method which guarantees smooth penumbrae and high quality anisotropic anti-aliasing of the sharp transitions. Unlike approaches based on pre-ﬁltering approximations, our approach does not suffer from light bleeding or losing contact shadows. Discretization artefacts are avoided by creating virtual shadow maps on the ﬂy according to a novel shadow map resolution prediction model. This model {{takes into account the}} screen space frequency of the penumbrae via a perceptual metric which has been directly established from an appropriate user study. Consequently, our algorithm always generates shadow maps with minimal resolutions enabling high performance while guarantying high quality. Thanks to this perceptual model, our algorithm can sometimes be faster at rendering soft shadows than hard shadows. It can render game-like scenes at very high frame rates, and extremely large and complex scenes such as CAD models at interactive rates. In addition, our algorithm is highly scalable, and the quality versus performance trade-off can be easily tweaked...|$|R
40|$|The {{claim that}} {{consciousness}} is propositional has be widely debated in the past. For instance, {{it has been}} discussed whether consciousness is always propositional, whether all propositional consciousness is linguistic, whether propositional consciousness is always articulated, or whether there can be non-articulated propositions. In contrast, {{the question of whether}} propositions are conscious has not very often been the focus of attention. In this paper, we would like <b>to</b> <b>render</b> two ideas <b>plausible</b> and defend them against certain objections that have been raised against them. The first, perhaps less controversial idea is that at least certain propositional mental states- such as judgements, thoughts or felt desires- involve a particular kind of consciousness, which has often been called phenomenal or qualitative consciousness. The second and more important, since far more controversial, idea is that propositions- and concepts as their constituents- possess distinct and specific phenomenal characters, or qualia, in virtue of which they are experienced differently when entertained or held in thought. Both claims, we shall see, have immediate consequences on our conception of understanding and communication. Contrary to a widespread view, a view which {{has its roots in the}} linguistic turn, we maintain that phenomenal quality is constitutive of the understanding and grasping of meanings. 1. Phenomenal consciousness and propositional states Franz Brentano (Brentano 1924), and many authors after him (Bloc...|$|R
40|$|Martin Heidegger and Jacques Ellul propounded substantivist {{accounts}} of technology which rejected the received instrumentalist view of technology {{according to which}} only the ends to which technologies are applied can be evaluated. In opposition to instrumentalism, they claimed that modern technology involves a displacement of non-technological values or (in Heidegger’s case) other ways of relating to Being. The theory of technical autonomy that Jacques Ellul sets out in The Technological Society is distinguished from Heidegger’s brand of substantivism, however, in providing a non-transcendental, naturalistic account of {{the conditions under which}} technique displaces non-technical values in modern societies. I show how Ellul’s theory resolves into two components – 1) a theory of the essence of technique given in terms of the notion of efficiency and 2) a theory of the conditions for autonomy - and set out some criticisms of Ellul’s essentialism by way of an analysis of the concept of efficiency. I argue that component (2) is incompatible with his essentialism because it is committed to techniques being replicable across different contexts of use. I then use Jacques Derrida’s notions of iterability and generalised writing to develop a theory of technical replicability which accounts for the historical particularity of techniques and for their mechanism-dependent replicability. I support this account of technical iteration by showing how it allows explanatory connections to be made between specific mechanisms of technical replication and the fragile cultural forms or phenomenologies they support. I then use it to reformulate Ellul’s theory without its essentialist commitments and claim that the background assumptions of the resultant theory are sufficiently weak <b>to</b> <b>render</b> it <b>plausible.</b> However, while this supports certain aspects of Ellul’s original thesis, I argue that the modified theory no longer implies a hegemonic role for technique. While technical process may be self-augmenting and uncontrollable (much as Ellul describes it) there are no grounds for claiming that it prescribes a particular set of values...|$|R
40|$|Master of EducationThis {{thesis is}} not so much a {{confrontation}} of the arguments advanced by Paul Hirst, as an endeavour to show that his position, within its own terms, fails to afford genuine plausibility to the "forms of knowledge"; indeed, to show that this could not be done, that his arguments cannot be made. The failure <b>to</b> <b>render</b> the "forms" <b>plausible</b> is examined at two levels; the level of Hirst's expressions and the level of, for want of a better term, his vision. In Part 1 the case is made that despite all fair appearance, the Hirst thesis is in crucial ways not intelligible. In Part 2 it is argued that Hirst's conception of the "forms of knowledge" is fatally contradictory. Part 3 returns from this study of disharmony to the problem of knowledge and human freedom which is the whole concern of the liberal education Hirst has sought to re-proclaim. In it his idea of freedom is examined and rejected. It is rejected without any resort to a "metaphysical" basis such as he would scorn. Keeping, instead, strictly to description of language, the possibility of an understanding of knowledge and freedom is offered which - in the end - can only be conceived of if that which "metaphysics" stands for is not legislated out of relevance. Within his own terms then, this thesis finds not only central disharmonies in Hirst's "forms of knowledge" but also reason to affirm the premises he rejects. Restricted Access: Metadata Onl...|$|R
40|$|We present {{variance}} soft shadow mapping (VSSM) for <b>rendering</b> <b>plausible</b> soft {{shadow in}} real-time. VSSM {{is based on}} the theoretical framework of percentage-closer soft shadows (PCSS) and exploits recent advances in variance shadow mapping (VSM). Our new formulation allows for the efficient computation of (average) blocker distances, a common bottleneck in PCSS-based methods. Furthermore, we avoid incorrectly lit pixels commonly encountered in VSM-based methods by appropriately subdividing the filter kernel. We demonstrate that VSSM renders highquality soft shadows efficiently (usually over 100 fps) for complex scene settings. Its speed is at least one order of magnitude faster than PCSS for large penumbra...|$|R
40|$|Normal rat hepatocytes were {{isolated}} and cultivated in vitro. Synthesis of secretory component was demonstrated by its accumulation {{in the culture}} medium, as measured by radioimmunoassay; by incorporation of 14 C‐leucine in the protein specifically precipitated with anti‐secretory component antiserum; and by a positive precipitin reaction of concentrated culture medium with the same antiserum. The results explain {{the high levels of}} secretory component found in rat bile and <b>render</b> <b>plausible</b> a mechanism of hepatic IgA transfer involving secretory component as the hepatocyte membrane receptor for polymeric IgA. Copyright © 1980, Wiley Blackwell. All rights reservedSCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
60|$|John Effingham had insensibly imbibed {{the sentiments}} of his {{particular}} sect, though the large fortune inherited from his father had left him too independent to pursue the sinuous policy of trade. He had permitted temperament to act on prejudice {{to such an extent}} that he vindicated the right of England to force men from under the American flag, a doctrine that his cousin was too simple-minded and clear-headed ever to entertain for an instant: and he was singularly ingenious in discovering blunders in all the acts of the republic, when they conflicted with the policy of Great Britain. In short, his talents were necessary, perhaps, to reconcile so much sophistry, or <b>to</b> <b>render</b> that reasonably <b>plausible</b> that was so fundamentally false. After the peace of 1815, John Effingham went abroad for the second time, and he hurried through England with the eagerness of strong affection; an affection that owed its existence even more to opposition than to settled notions of truth, or to natural ties. The result was disappointment, as happens nineteen times in twenty, and this solely because, in the zeal of a partisan he had fancied theories, and imagined results. Like the English radical, who rushes into America with a mind unsettled by impracticable dogmas, he experienced a reaction, and this chiefly because he found that men were not superior to nature, and discovered so late in the day, what he might have known at starting, that particular causes must produce particular effects. From this time, John Effingham became a wiser and a more moderate man; though, as the shock had not been sufficiently violent to throw him backward on truth, or rather upon the opposing prejudices of another sect, the remains of the old notions were still to be discovered lingering in his opinions, and throwing a species of twilight shading over his mind; as, in nature, the hues of evening and the shadows of the morning follow, or precede, the light of the sun.|$|R
40|$|A {{fundamental}} {{challenge for}} existing shadow map based algorithms {{is dealing with}} partially illuminated surfaces. A conventional shadow map built with a pinhole camera only determines a binary light visibility at each point, and this all-or-nothing approach to visibility does not capture penumbral regions. We present an interactive soft shadow algorithm based on {{a variant of the}} depth discontinuity occlusion camera, a non-pinhole camera with rays that reach around blockers to sample normally hidden surfaces. Our soft shadow occlusion camera (SSOC) classifies a fragment on a continuum from fully visible to fully hidden, as seen from the light. The SSOC is used directly in fragment illumination computation without building an explicit “soft shadow map. ” This method <b>renders</b> <b>plausible</b> soft shadows at interactive speeds under fully dynamic conditions. ...|$|R
5000|$|Adopting {{a lengthy}} {{leaching}} process <b>to</b> <b>render</b> nuts with high alkaloid content and potentially toxic, in order <b>to</b> <b>render</b> the fruit edible.|$|R
40|$|Figure 1 : Different {{rendering}} results {{generated by}} our variance soft shadow mapping method without any precomputation. We present variance soft shadow mapping (VSSM) for <b>rendering</b> <b>plausible</b> soft shadow in real-time. VSSM {{is based on}} the theoretical framework of percentage-closer soft shadows (PCSS) and exploits recent advances in variance shadow mapping (VSM). Our new formulation allows for the efficient computation of (average) blocker distances, a common bottleneck in PCSS-based methods. Furthermore, we avoid incorrectly lit pixels commonly encountered in VSM-based methods by appropriately subdividing the filter kernel. We demonstrate that VSSM renders highquality soft shadows efficiently (usually over 100 fps) for complex scene settings. Its speed is at least one order of magnitude faster than PCSS for large penumbra. Categories and Subject Descriptors (according to ACM CCS) : I. 3. 7 [Computer Graphics]: Three-Dimensional Graphics and Realism – Color, Shading, Shadowing, and Texture 1...|$|R
30|$|Summary (4 lines): Ergonomics and Strategies are {{important}} <b>to</b> <b>render</b> laparoscopic surgery safe and effective. The aim in minimal access surgery is <b>to</b> <b>render</b> optimal exposure with minimal access for effective tissue dissection.|$|R
5000|$|... {{inability}} <b>to</b> <b>render</b> the new {{route number}} in a legible manner (it {{is necessary to}} use the thinnest font <b>to</b> <b>render</b> the number, and the shield is wider than the standard Interstate shield) ...|$|R
2500|$|Wāʾo is used <b>to</b> <b>render</b> the vowels [...] "ū", [...] "o", [...] "u" [...] and [...] "au" [...] ( [...] , , [...] and [...] respectively), {{and it is}} {{also used}} <b>to</b> <b>render</b> the labiodental approximant, [...]|$|R
5000|$|Wāʾo is used <b>to</b> <b>render</b> the vowels [...] "ū", [...] "o", [...] "u" [...] and [...] "au" [...] (uː, oː, ʊ and ɔː respectively), {{and it is}} {{also used}} <b>to</b> <b>render</b> the labiodental approximant, ʋ.|$|R
40|$|We propose an {{efficient}} technique for <b>rendering</b> visually <b>plausible</b> real-time soft shadows in screen space. First, we propose a novel blocker estimation technique {{based on a}} separable filter. Second, our technique performs a separable Gaussian blur in screen space over the hard shadows produced by the standard shadow mapping technique. Although blurring the hard shadows with a separable filter was done before in the literature using bilateral filtering, we use an alternative approach that minimizes artifacts. Since separated calculation is not possible for all cases, we provide data reutilization criteria based on two user-defined error thresholds called α and β. As a consequence of using separable approaches for both stages of the light visibility estimation, our technique is able <b>to</b> improve <b>rendering</b> performance, especially when high-resolution shadow maps and filtering kernels are used...|$|R
60|$|At {{the first}} {{inspection}} {{it would appear}} that each country bears its own cost of carriage, that is, that each country pays the carriage of the commodity which it imports. Upon this supposition, each country would gain whatever share of the joint saving of labour would otherwise fall to its lot, minus the cost of bringing from the other country the commodity which it imports. This solution is <b>rendered</b> <b>plausible</b> by the circumstance just now mentioned, that the price of the commodity will be higher in the country which imports it, than in the country which exports it, by the amount of the cost of carriage. If linen is sold in England at a higher price than in Germany, by a per-centage equal to the cost of carriage of the linen, it appears obvious that England pays for the carriage of the linen, and Germany, by parity of reason, for that of the cloth.|$|R
5000|$|... librsvg uses {{two other}} {{libraries}} to perform tasks from reading the file <b>to</b> <b>rendering</b> <b>to</b> the screen.|$|R
5000|$|Tertullian, in De Idololatria, interprets Jesus {{as saying}} <b>to</b> <b>render</b> [...] "the image of Caesar, {{which is on}} the coin, to Caesar, and the image of God, which is on man, to God; so as <b>to</b> <b>render</b> <b>to</b> Caesar indeed money, to God yourself. Otherwise, what will be God's, if all things are Caesar's?" ...|$|R
60|$|It is {{remarkable}} how very slight a modification will suffice <b>to</b> <b>render</b> Mr. Ricardo's doctrine completely true. It is even doubtful whether he himself, if {{called upon to}} adapt his expressions to this peculiar case, would not have so explained his doctrine as <b>to</b> <b>render</b> it entirely unobjectionable.|$|R
40|$|Despite {{the growing}} {{popularity}} of mobile web browsing, the energy consumed by a phone browser while surfing the web is poorly understood. We present an infrastructure for measuring the precise energy used by a mobile browser <b>to</b> <b>render</b> web pages. We then measure the energy needed <b>to</b> <b>render</b> financial, e-commerce, email, blogging, news and social networking sites. Our tools are sufficiently precise to measure the energy needed <b>to</b> <b>render</b> individual web elements, such as cascade style sheets (CSS), Javascript, images, and plug-in objects. Our results show that for popular sites, downloading and parsing cascade style sheets and Javascript consumes a significant fraction of the total energy needed <b>to</b> <b>render</b> the page. Using the data we collected we make concrete recommendations on how to design web pages so as to minimize the energy needed <b>to</b> <b>render</b> the page. As an example, by modifying scripts on the Wikipedia mobile site we reduced by 30 % the energy needed <b>to</b> download and <b>render</b> Wikipedia pages with no change to the user experience. We conclude by estimating the point at which offloading browser computations to a remote proxy can save energy on the phone...|$|R
