244|1509|Public
2500|$|A {{wide range}} of fluorophores {{can be used as}} labels in flow cytometry. Fluorophores, or simply [...] "fluors", are {{typically}} attached to an antibody that recognizes a <b>target</b> <b>feature</b> on or in the cell; they may also be attached to a chemical entity with affinity for the cell membrane or another cellular structure. Each fluorophore has a characteristic peak excitation and emission wavelength, and the emission spectra often overlap. Consequently, the combination of labels which can be used depends on the wavelength of the lamp(s) or laser(s) used to excite the fluorochromes and on the detectors available. The maximum number of distinguishable fluorescent labels is thought to be 17 or 18, and this level of complexity necessitates laborious optimization to limit artifacts, as well as complex deconvolution algorithms to separate overlapping spectra. Flow cytometry uses fluorescence as a quantitative tool; the utmost sensitivity of flow cytometry is unmatched by other fluorescent detection platforms such as confocal microscopy. Absolute fluorescence sensitivity is generally lower in confocal microscopy because out-of-focus signals are rejected by the confocal optical system and because the image is built up serially from individual measurements at every location across the cell, reducing the amount of time available to collect signal.|$|E
50|$|High {{frequency}} approximations such as geometric optics, Physical Optics, {{the geometric}} theory of diffraction, the uniform theory of diffraction {{and the physical}} theory of diffraction are used when the wavelength is much shorter than the <b>target</b> <b>feature</b> size.|$|E
5000|$|In a final, compressed, or [...] "jammed" [...] state, some {{particles}} are not jammed, {{they are able}} to move within [...] "cages" [...] formed by their immobile, jammed neighbors and the hard boundary, if any. These free-to-move {{particles are}} not an artifact, or pre-designed, or <b>target</b> <b>feature</b> of the LSA, but rather a real phenomenon. The simulation revealed this phenomenon, somewhat unexpectedly for the authors of the LSA. Frank H. Stillinger coined the term [...] "rattlers" [...] for the free-to-move particles, because if one physically shakes a compressed bunch of hard particles, the rattlers will be rattling.|$|E
50|$|In {{metallic}} silhouette shooting only {{knock down}} steel <b>targets</b> <b>featuring</b> animals are used.|$|R
5000|$|... #Caption: An archery <b>target,</b> <b>featuring</b> evenly spaced {{concentric}} circles that surround a [...] "bullseye".|$|R
40|$|Scanning ion {{conductance}} microscopy (SICM) has becomes prevalent {{especially in}} probing biological samples {{taking advantage of}} its non-contact, force free, high resolution imaging ability. There {{are at least two}} imaging modes of SICM - continuous mode and hopping mode. In both imaging modes, the low imaging speed is the common disadvantage that hinders the efficiency of SICM based observation. In this paper, we propose a prior knowledge based fast imaging method to mitigate this problem. The key idea is to achieve a high resolution image on <b>targeted</b> <b>features</b> by scanning the sample twice, the first scan to obtain prior knowledge on <b>targeted</b> <b>features</b> with low resolution and the second scan to obtain images on <b>targeted</b> <b>features</b> with high resolution. In the first scan, the scanning speed can be very fast because the prior knowledge can be obtained from a low resolution image that requires few scanning points. In the second scan, only the interested areas (<b>targeted</b> <b>features)</b> are scanned. Because the scanning area on <b>targeted</b> <b>features</b> is much smaller than the whole scanning region, it takes much less time to obtain high resolution images on <b>targeted</b> <b>features,</b> As a result, the total time to acquire a high resolution is much less than the conventional one scan method. To verify the effectiveness of our proposed method, we performed high-resolution imaging on polydimethylsiloxane grating and microelectrode samples using a home-made SICM. The experimental results demonstrate the increased efficiency of SICM based observation using the twice scan method. © 2013 IEEE. IEEE RAS; IEEE IES; ASME; DSC; University of Wollongon...|$|R
5000|$|Until about 2005, another {{functional}} {{difference between}} the APIs was the way they handled rendering to textures. The Direct3D method (...) is convenient, while prior versions of OpenGL required manipulating pixel buffers (P-buffers). This was cumbersome and risky: if the codepath used in a program was different from that anticipated by a driver maker, the code would fall back to software rendering, causing a substantial performance drop. However, broad support for the frame buffer objects extension, which provided an OpenGL equivalent of the Direct3D method, successfully addressed this shortcoming, and the render <b>target</b> <b>feature</b> of OpenGL brought it up to par with Direct3D in this aspect.|$|E
5000|$|In {{cognitive}} psychology, intertrial priming is {{an accumulation}} of the priming effect over multiple trials, where [...] "priming" [...] {{is the effect of}} the exposure to one stimulus on subsequently presented stimuli. Intertrial priming occurs when a <b>target</b> <b>feature</b> (the characteristic that distinguishes targets from non-targets) is repeated from one trial to the next, and typically results in speeded response times to the target. A target is the stimulus participants are required to search for. For example, intertrial priming occurs when the task is to respond to either a red or a green target, and the response time to a red target is faster if the preceding trial also has a red target.|$|E
50|$|A {{decision}} tree {{is a simple}} representation for classifying examples. For this section, assume {{that all of the}} input features have finite discrete domains, and there is a single <b>target</b> <b>feature</b> called the classification. Each element of the domain of the classification is called a class.A {{decision tree}} or a classification tree is a tree in which each internal (non-leaf) node is labeled with an input feature. The arcs coming from a node labeled with an input feature are labeled with each of the possible values of the target or output feature or the arc leads to a subordinate decision node on a different input feature. Each leaf of the tree is labeled with a class or a probability distribution over the classes.|$|E
40|$|We {{present the}} results we obtain using our RegMT system, which uses transductive {{regression}} techniques to learn mappings between source and <b>target</b> <b>features</b> of given parallel corpora and use these mappings to generate machine translation outputs. Our training instance selection methods perform feature decay for proper selection of training instances, which {{plays an important role}} to learn correct feature mappings. RegMT uses L 2 regularized regression as well as L 1 regularized regression for sparse regression estimation of <b>target</b> <b>features.</b> We present translation results using our training instance selection methods, translation results using graph decoding, system combination results with RegMT, and performance evaluation with the F 1 measure over <b>target</b> <b>features</b> as a metric for evaluating translation quality. ...|$|R
40|$|We used {{a visual}} search task in which {{participants}} searched {{for the presence of}} either both members or just one member of pairs of spatially separated simple visual <b>features.</b> Pairs of <b>target</b> <b>features</b> could be drawn either from within the same dimension (two colours, or two orientations) or from across two different dimensions (one colour and one orientation). In Experiment 1, display items carrying <b>target</b> and non-target <b>features</b> (<b>target</b> and distractor items respectively) were presented at interspersed spatial locations. Reaction times (RTs) to find both of two <b>feature</b> <b>targets</b> were generally slower than to find one <b>feature</b> <b>target</b> for within- and across-dimension target pairs alike. This slowing was approximately constant across display set sizes, with one exception: for within-dimension <b>targets,</b> two <b>features</b> could be detected as fast as single features when there were just two items in displays. Experiment 2 replicated the finding across all display set sizes when target items were always spatially adjacent rather than interspersed with distractor items. We interpret these data in terms of grouping between <b>target</b> <b>features</b> within the same dimension, and argue against there being any qualitative limit on visual processing or selection when <b>target</b> <b>features</b> come from a single dimension relative to when they come from separate dimensions...|$|R
25|$|Peter Bogdanovich's 1968 film <b>Targets</b> <b>features</b> a {{character}} based on Charles Whitman and the UT Tower Shooting.|$|R
5000|$|Many {{theories}} {{focus on}} the repetition of target features as dominant explanation for the repetition effects seen in intertrial priming. If target features are the same over consecutive trials but distractor features are changed, response times are not as fast as if both target and distractor features are kept constant over trials. [...] This suggests that intertrial priming may mainly be due to distractor feature repetition, and <b>target</b> <b>feature</b> repetition influences this only slightly. This distractor-based priming {{may be due to}} faster perceptual grouping of distractors across trials. Perceptual grouping of distractors allows the target presence or absence to be distinguished more quickly. [...] However, the repetition of target defining features cannot be excluded as a contributor to the priming effect found in conjunctive searches ...|$|E
50|$|A cue is a {{presentation}} of a stimulus prior to a trial to inform the participant of an upcoming <b>target</b> <b>feature.</b> For example, a blue circle may be shown before a trial to signify a blue circle will be the target in the upcoming trial. Target relevant cues may be presented to participants to decrease their reaction time to the target in the display. These cues may be valid or invalid. Valid cues correctly predict the target stimulus but invalid cues do not. For example, if the target in an upcoming trial is a blue circle, a blue circle presented as a cue would be valid, but if a red circle was presented as a cue it would be invalid, as it doesn't correctly predict the blue circle target stimulus. Reaction times to valid cues are typically faster than reaction times to invalid cues. This phenomenon is known as a cueing effect.|$|E
5000|$|A {{wide range}} of fluorophores {{can be used as}} labels in flow cytometry. Fluorophores, or simply [...] "fluors", are {{typically}} attached to an antibody that recognizes a <b>target</b> <b>feature</b> on or in the cell; they may also be attached to a chemical entity with affinity for the cell membrane or another cellular structure. Each fluorophore has a characteristic peak excitation and emission wavelength, and the emission spectra often overlap. Consequently, the combination of labels which can be used depends on the wavelength of the lamp(s) or laser(s) used to excite the fluorochromes and on the detectors available. The maximum number of distinguishable fluorescent labels is thought to be 17 or 18, and this level of complexity necessitates laborious optimization to limit artifacts, as well as complex deconvolution algorithms to separate overlapping spectra. Flow cytometry uses fluorescence as a quantitative tool; the utmost sensitivity of flow cytometry is unmatched by other fluorescent detection platforms such as confocal microscopy. Absolute fluorescence sensitivity is generally lower in confocal microscopy because out-of-focus signals are rejected by the confocal optical system and because the image is built up serially from individual measurements at every location across the cell, reducing the amount of time available to collect signal.|$|E
40|$|AbstractFace {{perception}} {{is thought to}} result from the dynamic interplay between holistic and featural modes of processing. What determines the engagement of each mode is currently unknown. Here, we investigated whether the discriminability of local feature cues is a critical determinant of holistic/featural processing engagement. We estimated the strength of holistic processing based on observers’ failure to discriminate <b>target</b> <b>features</b> independently of the context of distracter features in a congruency paradigm. Feature discriminability was manipulated by varying the dissimilarity of <b>target</b> <b>features</b> parametrically, using morphing. We observed {{that the size of}} the congruency effect decayed monotonically {{as a function of the}} dissimilarity of the <b>target</b> <b>features.</b> In other words, the more similar the <b>target</b> <b>features</b> the stronger the holistic processing. A correlation analysis confirmed that local feature discriminability reliably predicted holistic engagement at upright orientation. In contrast, when a clear local feature difference was detected, perceptual contamination by the other surrounding features was prevented. This evidence firmly suggests that the interplay between holistic/featural processing depends on the discriminability of the signal provided at the local featural level...|$|R
30|$|By sorting {{the source}} and <b>target</b> <b>features</b> along each {{coordinate}} we can achieve a relation between {{the source and}} <b>target</b> <b>features</b> that {{is very close to}} linear, as shown in Figure 2 (b) for the first coordinate. The relation without sorting between the source and <b>target</b> <b>features</b> along the first coordinate is plotted in Figure 2 (a) and {{it is clear that the}} number of mixture classes required to model is large. Therefore, this sorting technique allows us to reduce the number of mixture classes because the estimation is easier and consequently the number of conversion parameters is also reduced. In Section 6, we show that this method significantly reduces the conversion errors when compared to our previous method [3] in which no sorting is applied and the number of mixture groups is large.|$|R
50|$|In August 2014, {{the system}} {{successfully}} intercepted a UAV and cruise missile <b>target</b> <b>featuring</b> a semi-active radar homing seeker in a test.|$|R
5000|$|Two major {{concepts}} {{dating back}} {{to the middle of the}} 19th century set the parameters of the discussion here. Johannes Müller emphasized that what matters in a neural path is the connection it makes, and Hermann Lotze, from psychological considerations, enunciated the principle of local sign. Put together in modern neuroanatomical terms they mean that a nerve fiber from a fixed retinal location instructs its target neurons in the brain about the presence of a stimulus in the location in the eye's visual field that is imaged there. The orderly array of retinal locations is preserved in the passage from the retina to the brain, and provides what is aptly called a [...] "retinotopic" [...] mapping in the primary visual cortex. Thus in the first instance brain activity retains the relative spatial ordering of the objects and lays the foundations for a neural substrate of visual space. Unfortunately, as is so common in brain studies, simplicity and transparency ends here. Right at the outset, visual signals are analyzed not only for their position, but also, separately in parallel channels, for many other attributes such as brightness, color, orientation, depth. No single neuron or even neuronal center or circuit represents both the nature of a <b>target</b> <b>feature</b> and its accurate location. The unitary mapping of object space into the coherent visual space without internal contradictions or inconsistencies that we as observer automatically experience, demands concepts of conjoint activity in several parts of the nervous system that is at present beyond the reach of neurophysiological research.|$|E
30|$|The feature {{preparation}} stage {{entails the}} representation of all features sets analyzed in the feature analysis stage alongside CCr, CC, and CCrt. This representation is used to obtain a feature matrix comprising of both an input feature sets and a <b>target</b> <b>feature</b> sets. The feature matrix is formulated as a multi-label and multi-output problem where each label in the input feature set and the <b>target</b> <b>feature</b> set can assume a real value.|$|E
40|$|CurviLinear SAR (CLSAR) is {{increasingly}} attracting considerable {{interest in the}} field of radar remote sensing. Various methods of 3 -D <b>target</b> <b>feature</b> extraction and aperture design have been proposed, and these methods are classified in this paper. The basic theories of these methods are systematically studied and compared, and their advantages and disadvantages are summarized. Moreover, the main 3 -D <b>target</b> <b>feature</b> extraction and aperture methods are described. Finally, the future research fields of CLSAR are proposed...|$|E
30|$|Recently, due {{to their}} strong {{regression}} capabilities, deep neural networks (DNNs) [8, 9] have also been utilized in speech dereverberation. In [10, 11], a DNN-based single-microphone dereverberation system was proposed by adopting a sigmoid activation function at the output layer and min-max normalization of <b>target</b> <b>features.</b> An improved DNN dereverberation system we proposed recently [12] adopted a linear output layer and globally normalized the <b>target</b> <b>features</b> into zero mean and unit variance, achieving the state-of-the-art performances.|$|R
5000|$|The 2005 John Birmingham novel Designated <b>Targets</b> <b>features</b> a cameo of Philby, {{under orders}} from Moscow to assist Otto Skorzeny's mission to assassinate Winston Churchill.|$|R
50|$|Metallic {{silhouette}} is {{a popular}} outdoor shooting sport using either rifles or handguns. In metallic silhouette shooting only knock down steel <b>targets</b> <b>featuring</b> animals are used.|$|R
40|$|AbstractThis paper {{presents}} {{a method of}} automatic generate 3 D assembly dimension chain based on feature model. Use attributes set of feature to express the information of parts and their relationships, an attributes set mainly include: information of <b>target</b> <b>feature,</b> information of features that has dimension or mating relations with <b>target</b> <b>feature</b> and information of the relationship. Then the transmit network between features will be generated, searching through the transmit network and the assembly dimension chain group are extracted finally. In the end a case study is given to verify the feasibility of proposed method...|$|E
40|$|The N 2 -posterior-contralateral (N 2 pc) {{component}} is an index {{in the domain}} of event-related potentials for exploring the underlying mechanism of visual-spatial attention. It has been disputed whether the attentional selection reflected by N 2 pc is primarily due to distracter suppression or target enhancement processes. We addressed this controversy by combining the pop-out item and the <b>target</b> <b>feature,</b> and instructed participants whether the pop-out item included the <b>target</b> <b>feature.</b> Thus, in a visual search task, bilateral visual stimuli including a pop-out item and three distractors were displayed simultaneously. The pop-out detection was analyzed under varying two factors: (a) pop-out item as a target or non-target (b) the distractors containing a <b>target</b> <b>feature</b> or non-target feature. Although all conditions had a salient effect on behavioral performance, the reliable difference of N 2 pc existed only between the target condition and the non-target condition. These results provided strong support for the hypothesis of target enhancement processes...|$|E
30|$|The {{estimation}} algorithm {{plays an}} important role in a radar tracking system. An improved estimation approach using both quantity data and <b>target</b> <b>feature</b> is investigated in this article. The advantage of this approach is that the system will have better estimation based on more target information. A data association denoted one-step conditional maximum likelihood algorithm is applied to match between radar measurements and existing target tracks. Moreover, an adaptive estimator is applied to combine the quantity data and <b>target</b> <b>feature</b> for estimation problems. According to the simulation results, this approach can enhance the performance of multiple-target tracking systems.|$|E
40|$|This thesis {{demonstrates}} {{the potential of}} performing orbital rendezvous and docking using vision navigation. The vision navigation algorithm tracks both known and unknown <b>target</b> <b>features</b> to determine the relative position and attitude between a chaser and target spacecraft. By processing imagery generated from an optical sensor, various <b>target</b> <b>features</b> can be tracked to accurately determine the relative motion between two orbiting vehicles. This research adopts an architecture that uses an extended Kalman filter (EKF) to processes angle measurements to various <b>target</b> <b>features</b> as extracted from the vision navigation algorithm. One potential limitation to this approach is determining the image scale or range. A Monte Carlo simulation evaluates {{the performance of the}} navigation filter in a closed-loop guidance, navigation, and control (GNC) system. This research introduces strategies to overcome the resulting range dilemma and characterizes the performance of using vision navigation for autonomous orbital rendezvous and docking...|$|R
30|$|We {{compared}} our NMF-based VC {{to conventional}} GMM-based VC. In GMM-based VC, the first through 24 th cepstral coefficients extracted by STRAIGHT {{are used as}} source and <b>target</b> <b>features.</b>|$|R
50|$|The <b>target</b> <b>features</b> an 11-time {{attempted}} {{attack on}} {{an ice cream}} van located near Kampa Pelare, Växjö. The van's interior was left burned out while its exteriors remained relatively intact. No suspects have been identified.|$|R
30|$|Decomposition: {{relationship}} {{that indicates that}} a feature is composed of another feature. This relationship specifies a minimum and a maximum multiplicity. The minimum multiplicity indicates whether the <b>target</b> <b>feature</b> is optional (0) or mandatory (1). The maximum multiplicity indicates how many instances of the <b>target</b> <b>feature</b> may be associated to each instance of the source feature. Valid values of the maximum multiplicity are: 1 (simple), for a single feature instance; * (multiple), {{for a list of}} instances of a single feature subclass; and ** (variant), for a list of instances of different subclasses of a feature.|$|E
40|$|Abstract The {{estimation}} algorithm {{plays an}} important role in a radar tracking system. An improved estimation approach using both quantity data and <b>target</b> <b>feature</b> is investigated in this article. The advantage of this approach is that the system will have better estimation based on more target information. A data association denoted one-step conditional maximum likelihood algorithm is applied to match between radar measurements and existing target tracks. Moreover, an adaptive estimator is applied to combine the quantity data and <b>target</b> <b>feature</b> for estimation problems. According to the simulation results, this approach can enhance the performance of multiple-target tracking systems. </p...|$|E
40|$|Patients with {{multimodal}} semantic impairment {{following stroke}} (referred to here as ‘semantic aphasia’, SA) are highly {{sensitive to the}} cognitive control demands of the task being performed and poor at inhibiting strongly associated distracters and focusing on less dominant aspects of meaning. Here, using feature selection tasks, we tested {{the role played by}} a semantic measure of featural salience on the control processes in healthy participants (Experiment 1) and SA patients (Experiment 2). Healthy participants showed a worse performance when the distracter feature was highly salient and the <b>target</b> <b>feature</b> was less salient for the concept, i. e., when there was an interference with voluntary selection of the <b>target</b> <b>feature</b> (Experiment 1). Consistent with these results, the SA patients showed a poorer performance than older controls when the <b>target</b> <b>feature</b> was weakly related to the concept (Experiment 2). In line with the feature-based models of the semantic memory, we discuss these preliminary results in term of greater demands of controlled semantic retrieval when the features are weakly related to the concept in the semantic network...|$|E
50|$|Target is {{a regular}} {{performer}} {{at some of the}} most prestigious alternative comedy clubs in the UK, including ACMS, Weirdos and the Invisible Dot. In 2012 <b>Target</b> <b>featured</b> on BBC Threes Comedy at the Fringe.|$|R
5000|$|Many <b>Target</b> {{commercials}} <b>featuring</b> <b>Target</b> Dog {{included the}} phrase [...] "See Spot save", a take on of the series' famous [...] "See Spot run".|$|R
30|$|In general, {{the fewer}} phonological {{and the more}} individuality-emphasized {{features}} a source input includes for a speaker, {{the easier it is}} to convert the source <b>features</b> to <b>target</b> <b>features.</b> This paper proposes voice conversion using such features.|$|R
