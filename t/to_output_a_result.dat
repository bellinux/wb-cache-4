7|10000|Public
5000|$|RDSMS SQL queries also {{operate on}} data streams over time or row-based windows. The {{following}} example shows a second continuous SQL query using the [...] clause with a one-second duration. The [...] clause changes {{the behavior of}} the query, <b>to</b> <b>output</b> <b>a</b> <b>result</b> for each new record as it arrives. Hence the output is a stream of incrementally updated results with zero result latency.|$|E
30|$|Directly {{solving the}} Original {{optimization}} using LINGO. We set |P| as n. Since solving the Original optimization is time-consuming, we {{set a time}} bound of 30 min. If LINGO fails <b>to</b> <b>output</b> <b>a</b> <b>result</b> within the time bound, we would manually terminate the process and use the latest result as output.|$|E
40|$|This paper {{presents}} some novel {{results on}} Chinese spell checking. In this paper, a concise algorithm based on minimized-path segmentation is proposed {{to reduce the}} cost and suit the needs of current Chinese input systems. The proposed algorithm is actually derived from a simple assumption that spelling errors often make the number of segments larger. The experimental results are quite positive and implicitly verify the effectiveness of the proposed assumption. Finally, all approaches work together <b>to</b> <b>output</b> <b>a</b> <b>result</b> much better than the baseline with 12 % performance improvement...|$|E
5000|$|Correctness: Any {{proper subset}} of {{adversarial}} colluding parties {{willing to share}} information or deviate from the instructions during the protocol execution should {{not be able to}} force honest parties <b>to</b> <b>output</b> <b>an</b> incorrect <b>result.</b> This correctness goal comes in two flavours: either the honest parties are guaranteed to compute the correct <b>output</b> (<b>a</b> “robust” protocol), or they abort if they find an error (an MPC protocol “with abort”).|$|R
40|$|Twenty years ago, the {{semiconductor}} industry was in-vesting millions dollars to build tools to investigate tech-nology defects, to modelize them and guarantee reliability. The technologic knowledge resulting from this investment has made possible the arrival of smartcards as low-cost portable security devices enabling several today applica-tions. As a side effect, the same knowledge also {{provided the basis for}} new attack means allowing one to break security devices. Reliability has for a long time been considered as the final goal in electronic design. Despite internal and ex-ternal perturbations, devices were conceived <b>to</b> eventually <b>output</b> <b>a</b> <b>result,</b> be it correctly computed or partially incor-rect. What we expect today from perturbed devices is also to not compromise their secrets. We will see on some exam-ples how, through the last decade, attacks were devised that take advantage of potential unreliable hardware behaviors to recover internally managed secret key material. Study-ing these examples, we will draw some perspectives for the security industry to win the faults battle. 1...|$|R
40|$|Abstract—Increasing {{speed and}} {{decreasing}} gate sizes make {{it necessary to}} test the correct temporal behavior of a manufactured chip. In this paper, we present an efficient SAT formulation for generating robust test patterns for the transition fault model. For this, we apply a multiple-valued logic that is able to model static values and add structural information to model the robust sensitization criterion. Furthermore, we introduce a SAT technique that pri-oritizes longer paths from the fault site <b>to</b> <b>an</b> <b>output.</b> <b>As</b> <b>a</b> <b>result,</b> the generated test patterns generally sensitize longer paths and consequently {{are more likely to}} detect errors caused by small delay defects. Experiments on ISCAS benchmarks and on industrial circuits show the feasiblity of our approach. I...|$|R
40|$|Abstract —We {{present a}} method of {{generating}} encryptors, in particular, Pseudo Ran-dom Number Generators (PRNG), using evolutionary computing. Working with a sys-tem called Eureqa, designed by the Cornell Creative Machines Lab, we seed the system with natural noise sources obtained from data that can include atmospheric noise gen-erated by radio emissions due to lightening, for example, radioactive decay, electronic noise and so on. The purpose {{of this is to}} ‘force ’ the system <b>to</b> <b>output</b> <b>a</b> <b>result</b> (a non-linear function) that is an approximation to the input noise. This output is then treated as an iterated function which is subjected to a range of tests to check for potential cryp-tographic strength in terms of a positive Lyapunov exponent, maximum entropy, high cycle length, key diffusion characteristics etc. This approach provides the potential for generating an unlimited number of unique PRNG that can be used on a 1 -to- 1 basis. Typical applications include the encryption of data before it is uploaded onto the Cloud by a user that is provided with a personalised encryption algorithm rather than just a personal key using a ‘known algorithm ’ that may be subject to a ‘known algorith...|$|E
40|$|We {{present a}} method of {{generating}} encryptors, in particular, Pseudo Random Number Generators (PRNG), using evolutionary computing. Working with a system called Eureqa, designed by the Cornell Creative Machines Lab, we seed the system with natural noise sources obtained from data that can include atmospheric noise generated by radio emissions due to lightening, for example, radioactive decay, electronic noise and so on. The purpose {{of this is to}} `force' the system <b>to</b> <b>output</b> <b>a</b> <b>result</b> (a nonlinear function) that is an approximation to the input noise. This output is then treated as an iterated function which is subjected to a range of tests to check for potential cryptographic strength in terms of a positive Lyapunov exponent, maximum entropy, high cycle length, key diffusion characteristics etc. This approach provides the potential for generating an unlimited number of unique PRNG that can be used on a 1 -to- 1 basis. Typical applications include the encryption of data before it is uploaded onto the Cloud by a user that is provided with a personalised encryption algorithm rather than just a personal key using a `known algorithm' that may be subject to a `known algorithm attack' and/or is `open' to the very authorities who are promoting its use...|$|E
40|$|This Conference Paper {{is brought}} to you for free and open access by the School of Electrical and Electronic Engineering at ARROW@DIT. It has been {{accepted}} for inclusion in Conference papers by an authorized Recommended Citation We present a method of generating encryptors, in particular, Pseudo Random Number Generators (PRNG), using evolutionary computing. Working with a system called Eureqa, designed by the Cornell Creative Machines Lab, we seed the system with natural noise sources obtained from data that can include atmospheric noise generated by radio emissions due to lightening, for example, radioactive decay, electronic noise and so on. The purpose of the is to "force " the system <b>to</b> <b>output</b> <b>a</b> <b>result</b> (a non-linear function) that is an approximation to the input noise. This output is then treated as an iterated function which is subjected to a range of tests to check for potential cryptographic strength in terms of a positive Lyapunov exponent, maximum entropy,high cycle length, key diffusion characteristics etc. This approach provides the potential for generating an unlimited number of unique PRNG that can be used on a 1 -to- 1 bases. Typical applications inlcude the encryption of data before it is uploaded onto the cloud by a user that is provided with a personalised encryption algorithm rather than just a personal key using a "known algorithm " that may be subject to attack and /or i...|$|E
40|$|International audienceA diplexer-based {{harmonic}} feedback-loop oscillator {{concept is}} presented and demonstrated at 5. 8 GHz. Without additional complexity, the diplexer {{together with an}} RF amplifier creates isolation between nonlinear feedback-loop dynamics and second harmonic signal component that is directed <b>to</b> the <b>output.</b> <b>As</b> <b>a</b> <b>result,</b> the load pulling effect is reduced {{as well as the}} phase noise performance is improved with reference to its fundamental feedback-loop counterpart. Load-pull measured results (VSWR ≤ 9) are observed follows: 1) load dependent frequency drift is significantly reduced from - 19 ‰~ 15 ‰ to - 0. 75 ‰~ 1. 06 ‰; 2) phase noise at 1 MHz offset is improved by 15 dB; and 3) output power is slightly affected only...|$|R
30|$|However, one may {{consider}} when {{the correct answer}} of the DR processing result cannot necessarily be defined or {{it is not necessary}} to be a correct answer. For example, in a case of deleting a manhole on a road, the required quality depends on the purpose of the DR process. It is unclear to us whether the pipe system under the manhole should be visualized or asphalt without manholes should be reproduced. Therefore, in such the case, it is necessary to perform a user study to evaluate whether or not the implemented DR method was able <b>to</b> <b>output</b> <b>a</b> visually convincing <b>result.</b> These evaluation methods are often used in literature related to see-through processing [33, 34, 46 – 48, 71 – 74], and they are helpful.|$|R
40|$|This is a Technical Inform, {{before to}} obtain the Ronny Barra Aquaculture degree, it show the process to design an {{industrial}} photobioreactor to growth Spirulina (Arthrospira platensis). This work star with {{a review of the}} principal open culture systems and the deferments types of know photobioreactors. An abstract about the industrial photobioreactors that have been building and it is running right now give a perspective to design a new industrial photobioreactor. A looking the principals’ criteria of designs give to identify the items more important to design a photobioreactor. To evaluate the performance of photobioreactor is necessary to define methods <b>to</b> measure the <b>output.</b> <b>As</b> <b>result</b> of this work, it shows the design criterions, the calculus, planes, details and budget of building and evaluation of photobioreactor designing. In the discussion of results it is identify the advantages and the disadvantages of the designing system. The conclusions and of this work give important guidelines to make future works in this matter...|$|R
40|$|Projecte fet en col. laboració amb University of Southern DenmarkThe {{objective}} of Data Mining (DM) is to classify {{information from the}} real world. That kind of information is commonly heterogeneous data: information that needs different kind of data to be represented. How to deal with heterogeneous data has been usually something DM lacks about because DM is not deeply used with real world problems. Different solutions has been shown and our objective is to show a new one using similarities and Support Vector Machines (SVM). How to use similarities instead of kernels in SVM and later how to combine similarities to work with heterogeneous data. The idea is that any type of data will have a similarity related and then all this similarities will be combined <b>to</b> <b>output</b> <b>a</b> <b>result.</b> What makes this idea powerful {{is the way we}} can combine similarities, it can be practically anything while other methods to work with heterogeneous data only do linear combinations. First of all understand how SVM works and what does it means to use similarities instead of Kernels. Later implement in a SVM library what explained before and show it working with an example. We will work with documents so it would be also required to do some NLP, learn about a NLP is another of my goals. Another of our goals is to use OO techniques and get a good design. Make our framework easy to be modified by anybody. Make an easy implementation. The objective is to extend the library used not to fork it...|$|E
40|$|AbstractVerification of {{temporal}} logic properties plays {{a crucial role}} in proving the desired behaviors of hybrid systems. In this paper, we propose an interval method for verifying the properties described by a bounded linear temporal logic. We relax the problem <b>to</b> allow <b>outputting</b> <b>an</b> inconclusive <b>result</b> when verification process cannot succeed with a prescribed precision, and present an efficient and rigorous monitoring algorithm that demonstrates that the problem is decidable. This algorithm performs a forward simulation of a hybrid automaton, detects a set of time intervals in which the atomic propositions hold, and validates the property by propagating the time intervals. A continuous state at a certain time computed in each step is enclosed by an interval vector that is proven to contain a unique solution. In the experiments, we show that the proposed method provides a useful tool for formal analysis of nonlinear and complex hybrid systems...|$|R
40|$|Verification of {{temporal}} logic properties plays {{a crucial role}} in proving the desired behaviors of hybrid systems. In this paper, we propose an interval method for verifying the properties described by a bounded linear temporal logic. We relax the problem <b>to</b> allow <b>outputting</b> <b>an</b> inconclusive <b>result</b> when verification process cannot succeed with a prescribed precision, and present an efficient and rigorous monitoring algorithm that demonstrates that the problem is decidable. This algorithm performs a forward simulation of a hybrid automaton, detects a set of time intervals in which the atomic propositions hold, and validates the property by propagating the time intervals. A continuous state at a certain time computed in each step is enclosed by an interval vector that is proven to contain a unique solution. In the experiments, we show that the proposed method provides a useful tool for formal analysis of nonlinear and complex hybrid systems. Comment: Appeared in NSV' 1...|$|R
40|$|This paper {{shows that}} {{international}} financial integration can increase consump-tion volatility in {{a developing country}} facing credit market imperfections. I use a two country international real business cycle model where each country produces a traded and a non-traded good. I assume {{that one of the}} countries is small and faces two financial frictions. First, the non-traded goods sector faces borrowing constraints due to enforceability problems. Second, the owners of the non-traded sector firms {{do not have access to}} international asset markets even when the coun-try is financially integrated with the rest of the world. The interaction of these two frictions may cause consumption volatility to increase (in absolute terms and relative <b>to</b> <b>output</b> volatility) as <b>a</b> <b>result</b> of financial integration. This is consistent with the empirical evidence for developing countries. Such evidence cannot be rationalized in the context of the standard international real business cycle model...|$|R
40|$|According to the invention, {{a highly}} {{optically}} dispersive medium {{is one in}} which the absolute value of the group index of refraction of the medium is equal to or greater than four. An optical spectroscopic parameter detection and/or measurement apparatus may be {{in the form of an}} interferometer, a spectral interferometer, a spectrometer, a wavemeter, a tunable narrowband filter. The embodied devices include a highly dispersive medium that appropriately can facilitate either a slow-light effect or a fast-light effect, which is disposed in a propagation path of an electro-magnetic (EM) input field and, a detector disposed in a manner <b>to</b> detect <b>an</b> <b>output</b> field <b>resulting</b> from the input filed interaction with the highly dispersive medium. Methods involve measuring a spectroscopic parameter using an optical spectroscopic parameter detection and/or measurement apparatus that incorporates a highly dispersive medium...|$|R
40|$|In this paper, we {{contribute}} a new paradigmof combining string recognizers and propose genericfericl 1 ## ff hierarchical and parallel combinationof multiple string recognizers. The fl#(R) 3 lH {{are open to}} any new achievement in either recognizers or combination algorithms, and {{can be applied to}} both machine-printed and handwritten string recognition problems. A parallel combination system, StrCombo, is implemented based on three independent alphanumeric handwritten string recognizers that act as black boxes. We propose a graph-based approach that regards each segmentfgm individualstring recognizers as nodesof a graph, and choose the optimalpath with the lowest cost <b>to</b> <b>output</b> <b>a</b> combined <b>result.</b> Allfll(99 such as the agreementof size, classification, and the position are converted into <b>a</b> measurement <b>resulting</b> in asof decision. StrCombo has achieved a substantialimprovement over any oneof the individualrecognizers, as demonstrated by experimentalresults on standard numeralstring databases and a non-standard alphanumeric string databasefta real-lif applications. # 2002 Elsevier Science B. V. All rights reserved. Keywords: Handwritten string recognition; Combinationof multiple experts; Alphanumeric string recognizers 1. I- 5 oduction In recent years, a new trend called "Combinationof Multiple Experts" (CME) has been intensively investigated to solve complex pattern recognition problems. This idea is based on the intuition that classifiers with di#erent methodologies and fdl ures can complement each other, andtheref re a higher perf -l ance can be achieved if their results are combined properly. With the emergenceof the theory and related methodsfh combining multiple classifiers, promising results have been obtained in many diverse domains, such as handwriting recognition, fingerpr [...] ...|$|R
40|$|International audienceA {{method for}} the {{generation}} of attractive and neutrally stable limit cycles for nonlinear systems is presented. It consists in designing <b>an</b> <b>output</b> that, when regulated through a suitable feedback, forces {{the existence of a}} limit cycle or neutral oscillations in the zero dynamics. Conditions are then given to ensure that those characteristics of the zero-dynamics translate to the whole system. A particular focus is made on the gen- eration of neutrally stable oscillations through that method, because it is not always easy <b>to</b> build <b>an</b> <b>output</b> that <b>results</b> in the existence of a limit-cycle in the zero-dynamics. A special case where such a difficulty arises is given in the analysis of oscillations generation around the up- per vertical for the pendubot. The regulation of the output results in neutrally stable oscillations, and we present a method for imposing that those oscillations converge towards the desired ones...|$|R
40|$|The {{literature}} {{appears to}} have reached a consensus that financial globalization has had a "disciplining effect" on monetary policy, as it has reduced the returns from [...] and hence the temptation for [...] using monetary policy <b>to</b> stabilize <b>output.</b> <b>As</b> <b>a</b> <b>result,</b> monetary policy over recent years has placed more emphasis on stabilizing inflation, resulting in reduced inflation and greater output stability. However, this consensus has not been accompanied by convincing empirical evidence that such a relationship exists. One reason {{is likely to be}} that de facto measures of financial globalization are endogenous, and that instruments for financial globalization are elusive. In this paper, I introduce a new instrument, financial remoteness, as a plausibly exogenous instrument for financial openness. I examine the relationship between financial globalization and median inflation levels over an 11 year cross-section from 1994 through 2004, as well as a panel of 5 -year median inflation levels between 1980 and 2004. The <b>results</b> confirm <b>a</b> negative relationship between median inflation and financial globalization in the base specification, but this relationship is sensitive to the inclusion of conditioning variables or country fixed effects, precluding any strong inferences. Monetary policy; Inflation (Finance); Globalization...|$|R
40|$|Organizational {{capital is}} a {{specific}} form of capital that firms accumulate. It relates {{to the development of}} codes, technical languages, practical arrangements about how the work is done and to the creation of an organizational culture. The distinctive feature of this form of capital {{is the fact that it}} does not contribute directly <b>to</b> <b>an</b> <b>output</b> <b>result.</b> Instead, it can be thought as creating the correct environment for the human factor to maximize its capability of generating value, that is, organizational capital works as an external effect on the accumulation of the human capital input. Nevertheless, organizational capital is a form of capital and therefore it has an investment process associated with it. The paper considers the process of investment in this form of capital and recognizes that it introduces important changes over the firm's profit maximization problem. The problem gains new features relating to its dynamic nature and a condition that guarantees saddle-path stability can be derived. Copyright © 2007 John Wiley & Sons, Ltd. ...|$|R
40|$|The {{resource}} allocating network(RAN) {{provides a}} simple and powerful method for on-line modeling with incremental growth in model complexity. However, the network growing algorithm is susceptible to outliers in the output domain. Pruning techniques subsequently proposed for RAN, though satisfactory for dealing with outliers in the input domain, are incapable of removing units grown in response to outliers in the output domain. The addition of a coarse scale unit in response <b>to</b> <b>an</b> <b>output</b> outlier <b>results</b> in <b>a</b> much larger network where units are wasted to negate {{the effect of the}} spurious unit. The resulting network generalizes poorly. In this paper, we discuss the problems associated with RAN in the presence of outliers, and provide a modified learning algorithm which recognizes and prunes units associated with spurious data. We also present a strategy to modify the remaining units, once a unit is pruned. Keywords: Resource allocating network, outlier, pruning, function approximation 1 [...] . ...|$|R
40|$|This thesis studies {{submarine}} sliding and tsunami generation at the Rockall Bank, NE Atlantic Ocean through numerical {{and statistical}} modelling. Two numerical codes {{are used to}} perform the simulations from the submarine sliding to tsunami generation, propagation and inundation. The landslide model is VolcFlow and the tsunami model is VOLNA. Some of the basic rheological regimes used to model submarine landslides are briefly discussed, with a comparison {{in the case of}} the Rockall Bank. The latest version of VOLNA is validated against an analytical solution. The brief geological history of the area under study is also given. The numerical simulations explore different scenarios of failure in the area, and assess their tsunamigenic potential and the impact of the tsunamis on the current topography of the Irish shoreline. The results of the simulations exhibit a great variability that derives from the parameters used as input in the landslide model. There is a need to quantify this uncertainty. To do so, a Bayesian calibration of the parameters is initially performed, which leads to the posterior distributions of the input parameters. A statistical emulator, which acts as a surrogate of the numerical process is then built. The emulator can lead to predictions of the process in excessively fast (when compared to the simulations) computational speeds. For the examined case, the emulator propagates the uncertainties in the distributions of the input parameters resulting from the calibration, <b>to</b> the <b>outputs.</b> <b>As</b> <b>a</b> <b>result,</b> the predictions of the maximum free surface elevation at specified locations are obtained...|$|R
40|$|Investigating a {{range of}} {{commonly}} asserted characteristics relating to British family firms, this study concluded that, although they retained ownership and control and did not adopt mass-production, no persuasive evidence was found {{to suggest that the}} family managers of L. Gardner and Sons behaved unprofessionally or irrationally during the first eighty-seven years of the firm?s existence. Analysed from the perspective of markets and workplace industrial relations, {{it was found that the}} Gardner family managers coped reasonably well with most of the macroenvironmental shifts that occurred between 1955 and 1975. However, two serious errors were made: the first, which caused a short-term loss of revenue and a long-term loss of market leadership, was <b>a</b> <b>result</b> of negligence, the second stemmed from an outdated authoritarian approach to industrial relations that resulted in intense discord in the workplace, alleviated only after the management was replaced by a more astute and enlightened regime. A third error occurred after Gardner was sold to Hawker Siddeley, a large British industrial group, in 1977. Based on a perception that Gardner's plant was outdated, the new owners invested in expensive computer controlled manufacturing systems, and increased the volume of subcontracted components, strategies that caused disruptions to production schedules, eroded quality standards, and failed <b>to</b> improve <b>output.</b> <b>As</b> <b>a</b> <b>result,</b> Gardner's superlative reputation for reliability and service became tarnished and its market share plummeted. In 1986, when mounting trading losses became unacceptable, the firm was sold-on to a competitor and production effectively ceased. This thesis asserts that, as a family firm, Gardner traded profitably and provided incomes for thousands of employees for more than a century. Moreover, the sale to Hawker Siddeley conferred wealth on the family shareholders and financial security on their descendents. Gardner was not therefore, a failure either between 1898 and 1955, or before 1978...|$|R
40|$|Brain-computer {{interfaces}} (BCIs) use brain {{signals to}} convey a user’s intent. Some BCI approaches begin by decoding kinematic parameters of movements from brain signals, and then proceed to using these signals, in absence of movements, to allow a user <b>to</b> control <b>an</b> <b>output.</b> Recent <b>results</b> have shown that electrocorticographic (ECoG) recordings {{from the surface of}} the brain in humans can give information about kinematic parameters (e. g., hand velocity or finger flexion). The decoding approaches in these demonstrations usually employed classical classification/regression algorithms that derive a linear mapping between brain signals and outputs. However, they typically only incorporate little prior information about the target kinematic parameter. In this paper, we show that different types of anatomical constraints that govern finger flexion can be exploited in this context. Specifically, we incorporate these constraints in the construction, structure, and the probabilistic functions of a switched non-parametric dynamic system (SNDS) model. We then apply the resulting SNDS decoder to infer the flexion of individual fingers from the same ECoG dataset used in a recent study. Our results show that the application of the proposed model, which incorporates anatomical constraints, improves decoding performance compared to the results in the previous work. Thus, the results presented in this paper may ultimately lead to neurally controlled hand prostheses with full fine-grained finger articulation. ...|$|R
30|$|The aim of {{simulator}} is <b>to</b> <b>output</b> <b>a</b> value μ* as a guess of μ.|$|R
30|$|Once {{the buffer}} is full, the {{detector}} is able <b>to</b> <b>output</b> <b>a</b> set of {{objects to the}} tracker.|$|R
50|$|FDAUs {{are often}} used <b>to</b> <b>output</b> <b>a</b> second non {{mandated}} data steam {{to be used by}} the FOQA system.|$|R
50|$|The XZ LZMA2 encoder {{processes}} {{the input}} in chunks (of up to 2 MB uncompressed size or 64 KB compressed size, whichever is lower), handing each chunk to the LZMA encoder, and then deciding whether <b>to</b> <b>output</b> <b>an</b> LZMA2 LZMA chunk including the encoded data, or <b>to</b> <b>output</b> <b>an</b> LZMA2 uncompressed chunk, {{depending on which}} is shorter (LZMA, like any other compressor, will necessarily expand rather than compress some kinds of data).|$|R
3000|$|... (·). In {{the second}} part, the adversary has <b>to</b> <b>output</b> <b>a</b> forgery, which is {{different}} from all the outputs from E [...]...|$|R
50|$|In contrast, an offline {{algorithm}} {{is given the}} whole problem data {{from the beginning and}} is required <b>to</b> <b>output</b> <b>an</b> answer which solves the problem at hand.|$|R
5000|$|There {{may not be}} {{sufficient}} capacity on the media to save any data being buffered or <b>to</b> <b>output</b> <b>a</b> structure indicating that the object was successfully updated.|$|R
5000|$|Many {{programming}} languages implement <b>a</b> '''''' function <b>to</b> <b>output</b> <b>a</b> formatted string. It {{originated from}} the C programming language, {{where it has}} a prototype similar to the following: ...|$|R
5000|$|<b>To</b> <b>output</b> <b>an</b> object (i.e. a numeric value) and to {{show its}} result in the canvas. This result can be used when {{building}} subsequent objects (geometric or script).|$|R
30|$|In the {{traditional}} linear block code, it cannot correct errors which exceed dmin/ 2. The so-called list decoding, proposed independently by Elias {{in the late}} 50 s, allows the decoder <b>to</b> <b>output</b> <b>a</b> list of all code words that differ from the received word in {{a certain number of}} positions. Even when constrained <b>to</b> <b>output</b> <b>a</b> relatively small number of answers, list decoding permits recovery from errors well beyond the dmin/ 2 barrier and opens up the possibility of meaningful error correction from large amounts of noise [36].|$|R
5000|$|In 2007 an {{open source}} tool known as TransXChange2GoogleTransit http://code.google.com/p/googletransitdatafeed/ <b>to</b> <b>output</b> <b>a</b> TransXChange {{schedule}} in General Transit Feed Specification (GTFS), the format used by Google Transit, was released.|$|R
