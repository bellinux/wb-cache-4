1|100|Public
40|$|Diploma Thesis Abstract This thesis {{deals with}} a new {{institute}} in the financial law - an unreliable value added tax payor. This institute was established {{as one of the}} means of improving tax collection and is closely related to the liability of a third party - the payor of value added tax; the recipient of taxable <b>transaction.</b> <b>Listing</b> tax payors in a list of unreliable payors caters to the potential guarantor, but this is at the expense of increasing the administrative burden since the recipient of taxable transactions has to consult the list of tax payors before making any transaction and, as the case may be, enter into a contract in order to gain protection in the event that the provider of taxable transaction is included in the list of unreliable payors. The designation of a value added tax payor as an unreliable payor is not stipulated by law quite clearly, but it is based on an internal regulation known as the Information of the General Tax Directorate. The protection from tax evasion in the form of blacklisting business entities - in the records of unreliable payors - may represent an administrative burden that is too onerous for entrepreneurs as well as substantial financial costs associated with the entire unreliable payor agendas. In all probability, it is also contrary to Council Directive [...] ...|$|E
50|$|<b>Transactions</b> <b>listed</b> {{are from}} July 1, 1969 to June 30, 1970.|$|R
50|$|<b>Transactions</b> <b>listed</b> {{are from}} July 1, 1972 to June 30, 1973.|$|R
50|$|<b>Transactions</b> <b>listed</b> {{are from}} July 1, 2004 to June 30, 2005.|$|R
50|$|<b>Transactions</b> <b>listed</b> {{are from}} July 1, 2005 to June 30, 2006.|$|R
5000|$|Cards {{retain a}} <b>transaction</b> <b>list</b> (amount, times and {{identifier}} of the terminal) ...|$|R
5000|$|Each <b>{{transaction}}</b> <b>listed</b> on the Form 4 filing has {{a transaction}} code: ...|$|R
5000|$|Source:Any <b>transactions</b> <b>listed</b> below {{without a}} {{reference}} were originally announced on NPF's transactions page ...|$|R
2500|$|Raising {{debt and}} {{restructuring}} debt, especially when {{linked to the}} types of <b>transactions</b> <b>listed</b> above ...|$|R
25|$|Secondary equity issues, {{whether by}} means of private placing or further issues on a stock market, {{especially}} where linked {{to one of the}} <b>transactions</b> <b>listed</b> above.|$|R
5000|$|Non-exchange member {{arranging}} for <b>transactions</b> in <b>listed</b> securities by exchange member ...|$|R
5000|$|Double entry {{bookkeeping}}. The CPA {{did not use}} a double-entry bookkeeping system. Instead, it used {{what that}} auditors called a single entry, cash-based, <b>transaction</b> <b>list</b> — $ 20 billion of petty cash. The CPA did not do a cash-reconciliation until April 2004, eleven months into its administration. At that point, the CPA had disbursed $ 6 billion in $ 100 bills.|$|R
5000|$|The 2017 CFL {{free agency}} period officially opened at 12:00pm EST on February 14, 2017. Key <b>transactions</b> are <b>listed</b> below: ...|$|R
40|$|Apriori and Eclat are {{the best-known}} basic {{algorithms}} for mining frequent item sets {{in a set}} of transactions. In this paper I describe implementations of these two algorithms that use several optimizations to achieve maximum performance, w. r. t. both execution time and memory usage. The Apriori implementation is based on a prefix tree representation of the needed counters and uses a doubly recursive scheme to count the transactions. The Eclat implementation uses (sparse) bit matrices to represent <b>transactions</b> <b>lists</b> and to filter closed and maximal item sets. 1...|$|R
3000|$|It {{maintains}} the sensitive itemset with corresponding supporting <b>transaction</b> Ids <b>list</b> and Delta value(Δ). It is maintained with the master node and shared {{with all other}} computing nodes in a cluster [...]...|$|R
5000|$|... (1) {{appropriate}} {{personnel from}} the Drug Enforcement Administration and other Federal, State, and {{local law enforcement}} and regulatory agencies with the experience in investigating and prosecuting illegal <b>transactions</b> of <b>listed</b> chemicals and supplies ...|$|R
5000|$|A ledger is {{a record}} of accounts.The ledger is a {{permanent}} summary of all amounts entered in supporting Journals which <b>list</b> individual <b>transactions</b> by date. These accounts are recorded separately, showing their beginning/ending balance. A journal <b>lists</b> financial <b>transactions</b> in chronological order, without showing their balance but showing how much {{is going to be}} charged in each account. A ledger takes each financial transaction from the journal and records it into the corresponding account for every <b>transaction</b> <b>listed.</b> The ledger also sums up the total of every account, which is transferred into the balance sheet and the income statement. There are three different kinds of ledgers that deal with book-keeping: ...|$|R
5000|$|... (B) For 2 {{years after}} {{the date of the}} <b>transaction,</b> if the <b>listed</b> {{chemical}} is an essential chemical.|$|R
40|$|Transactions {{involving}} {{water rights}} have been taking place in Western States for many decades. Although publications, which describe sales and leases of water rights, exist, never has a broad focused database been created reflecting the details {{of these types of}} transactions. The purpose of this report is to provide a database that compiles and reports some of the details of these transactions including the entities involved, the number of acrefeet of water sold or leased, and the prices paid per acre-foot of leased or purchased water rights. This information is provided in tables for all possible <b>transactions</b> <b>listed</b> in both the Water Strategist and Water Intelligence Monthly publications for the period 1990 to 2001. Working Paper # 2002 - 00...|$|R
50|$|Many {{players were}} signed, lost and traded during free agency. See <b>Transactions</b> for a <b>list</b> of lost and {{acquired}} players.|$|R
40|$|Abstract In {{this paper}} we {{describe}} a new parallel Frequent Itemset Mining algorithm called “Frontier Expansion. ” This implementation is optimized to achieve high {{performance on a}} heterogeneous platform consisting of a shared memory multiprocessor and multiple Graphics Processing Unit (GPU) coprocessors. Frontier Expansion is an improved data-parallel algorithm derived from the Equivalent Class Clustering (Eclat) method, in which a partial breadth-first search is utilized to exploit maximum parallelism while being constrained by the available memory capacity. In our approach, the vertical <b>transaction</b> <b>lists</b> are represented using a “bitset ” representation and operated using wide bitwise operations across multiple threads on a GPU. We evaluate our approach using four NVIDIA Tesla GPUs and observed a 6 – 30 × speedup relative to state-of-the-art sequential Eclat and FPGrowth implementations executed on a multicore CPU...|$|R
5000|$|Nevins, Ralph G. [...] "Psychrometrics {{and modern}} comfort". ASHRAE <b>Transactions</b> 67 (1961):609-621. <b>Listed</b> among the 100 most {{important}} papers in ASHRAE's history ...|$|R
5000|$|... (2) Information {{referred}} to a regulated <b>transaction</b> involving a <b>listed</b> chemical, a tableting machine, or an encapsulating machine may be disclosed only — ...|$|R
40|$|Title varies slightly; v. 67 - 70 have title: <b>Transactions.</b> <b>List</b> of fellows in v. 1 - 5, 7 - 16, 20 - 30, 32 - 33, 35 - 41, 45; {{continued}} since 1908 in the Proceedings, v. 28 -Description based on: Vol. 64, no. 1; {{title from}} cover. Suspended 1804 -Dec. 1832. The first 4 vols. are each in 3 sections: History of the society; Papers of the Physical class; Papers of the Literary class. The Literary class ceased to appear after v. 4; the "History", {{which appeared in}} v. 1 - 5, included the proceedings for 1783 - 1803, after which the publication of proceedings was suspended until Dec. 1832, when the society began to issue an independent series entitled Proceedings. Mode of access: Internet. Vols. 1 (1783) - 34 (1888). 1 v.; Vols. 35 (1889) - 46 (1908). 1 v...|$|R
40|$|This paper {{examines}} the disclosure obligations on listed companies as stipulated by the Listing Requirements of the Stock Exchange. The {{focus will be}} on the disclosure requirements on corporate real estate proposals and <b>transactions</b> by <b>listed</b> non-real estate companies. This paper will also discuss the requirements and procedures in making announcements relating to corporate proposals of a company...|$|R
50|$|On June 8, 2017, Hendricks {{was placed}} on the 10-day {{disabled}} <b>list</b> (<b>transaction</b> retroactive 3 days prior) due to middle finger tendon inflammation in his right hand.|$|R
40|$|Eclat {{algorithm}} {{is used to}} find frequent item sets. This algorithm uses a vertical data type and perform depth-first search in the lattice sections and determine the set of items to support cuts <b>transaction</b> <b>list.</b> Research is carried out by comparing the data pattern generated sales Eclat algorithm. The data used is the sales data in 2011 and 2012. Analyzes were performed using the minimum support ranging from 5 % to 20 %. At a minimum support of 15 % and 20 % reporting no sales rules. This is because too many variations of groups of goods. The data are too diverse causes minimum support value can not be more than 15 %, {{this is because the}} average customer bought stuff that was as much as 3 items only. 2010 and 2011 sales data has the same relative pattern of rules seen from the support and lift values. Olie is not found in the rule because most sales Olie is a single sale...|$|R
50|$|Since June 2010 {{it is also}} a free iPhone app {{that can}} be found in Apple's AppStore. It makes it {{possible}} to <b>list</b> <b>transactions,</b> perform transfers and view your portfolio.|$|R
5000|$|... (a) (1) Each {{regulated}} {{person who}} engages in a regulated <b>transaction</b> involving a <b>listed</b> chemical, a tableting machine, or an encapsulating machine shall keep {{a record of}} the transaction — ...|$|R
5000|$|... (A) For 4 {{years after}} {{the date of the}} <b>transaction,</b> if the <b>listed</b> {{chemical}} is a precursor chemical or if the transaction involves a tableting machine or an encapsulating machine.|$|R
5000|$|... (IV) any <b>transaction</b> in a <b>listed</b> {{chemical}} that {{is contained in}} a drug that may be marketed or distributed lawfully in the United States under the Federal Food, Drug, and Cosmetic Act ...|$|R
5000|$|A journal {{is a book}} or {{computer}} file in which monetary transactions are entered {{the first time they}} are processed. This journal <b>lists</b> <b>transactions</b> in chronological sequence by date prior to a transfer of the same transactions to a ledger in the process of bookkeeping ...|$|R
50|$|NeighborCity uses {{real-estate}} <b>transaction</b> and <b>listing</b> database {{information from}} national sources to construct its rankings. The company developed and uses AgentMatch, {{a system for}} matching private home buyers and sellers with agents based {{on the characteristics of}} the property for sale, including its location, price, and property type, and how they relate to the past experience and performance of the licensed real estate agents in that area. NeighborCity receives a portion of the commission earned by brokers on closed transactions that result from referrals.|$|R
50|$|The company rates {{virtually}} {{every member of}} the National Association of Realtors in the United States, based on <b>transaction</b> and <b>listing</b> history. NeighborCity analyzes agents’ performance based on closing rate, number of closings, number of active listings, geographic specialization, number of days on market, rate of dual agency, sales price per square foot, and the difference between ask and sale price, for the homes they sell. NeighborCity provides an evaluation of the quality of service delivered by agents, with respect to their clients’ interests and relative to competing real-estate agents.|$|R
40|$|AbstractPlanning for savings {{remains one}} of the most {{critical}} decisions for any user. The most important factor in this process is decision making. Most of the time, we can take decisions on how much money to save at a time based on our spending pattern. But automating this process is not easy, since it involves a number of parameters. Here, we attempt to incorporate intelligence into this decision making. The algorithm will attempt to predict the maximum amount to save based on the current account balance, clubbed with the entire database of available transactions on that account / user. Every transaction will be assigned an impact factor based on the time of occurrence, relative to the current date. Every month is divided into four quarters to track recurring expenses like EMIs. These impacts have to be taken by a machine learning algorithm to predict the maximum possible savings in that quarter. The impact factor will also depend upon the fraction of balance being spent on that quarter. If there is a goal set for savings, it will also be taken into consideration. If a considerable expense is predicted for that month, the savings will be kept low so that the account won’t go into overdraft. Recurring expenses are kept in check and accounted for to the maximum extent using information gain ratio from the <b>transaction</b> <b>list...</b>|$|R
40|$|We {{present an}} {{overview}} of data mining techniques for extracting knowledge from large databases with a special emphasis on the unsupervised technique pattern mining. Pattern mining is often defined as the automatic search for interesting patterns and regularities in large databases. In practise this definition most often comes down to listing all patterns that exceed a user-defined threshold for a fixed interestingness measure. The simplest such problem is that of listing all frequent itemsets: given a database of sets, called <b>transactions,</b> <b>list</b> all sets of items that are subset {{of at least a}} given number of the transactions. We revisit the two main strategies for mining all frequent itemsets: the breadth-first Apriori algorithm and the depth-first FPGrowth, after which we show what are the main issues when extending to more complex patterns such as listing all frequent subsequences or subgraphs. In {{the second part of the}} paper we then look into the pattern explosion problem. Due to redundancy among patterns, most often the list of all patterns satisfying the frequency thresholds is so large that post-processing is required to extract useful information from them. We give {{an overview of}} some recent techniques to reduce the redundancy in pattern collections using statistical methods to model the expectation of a user given background knowledge on the one hand, and the minimal description length principle on the other. © Springer International Publishing Switzerland 2014. SCOPUS: cp. kinfo:eu-repo/semantics/publishe...|$|R
