8|28|Public
40|$|The paper {{shows how}} {{to solve the problem}} {{concerning}} reveal of changes in mathematical models and electric parameters of symmetric three-phase short-circuited asynchronous electric motors in case of their connection to single- or <b>two-phase</b> <b>network</b> in comparison with their connection to three-phase network. The uniform methodological approach permitting to generalize the known data and receive new results is offered in the paper. </p...|$|E
30|$|<b>Two-phase</b> <b>network</b> {{modeling}} code—“Poreflow” software (2008, Valvatne 2004)—which {{has been}} written in C++. Although its source code is accessible free of charge from the website of Imperial College London (2008), it cannot be technically considered as an open-source software. Poreflow has been designed specifically for petroleum engineering applications. Nevertheless, it supports {{only a limited number}} of geometries for pores/throats cross section. In addition, investigating the code reveals that performance has not been a concern in Poreflow implementation. Parallel programming techniques have not been employed in Poreflow, and hence, it cannot benefit from multi-core/cluster system to reduce its runtime.|$|E
40|$|In my {{graduation}} thesis I {{first of}} all shortly mentioned frequency–selection filters and their utilisations. However, the base point of this project was to acquaint with different types of signal flow diagrams with whom I should design and analyse frequency-selection filtres with conventional and also innovative active components. As the first I created signal flow diagrams for both voltage and current conveyors. These modern active components are well known today and enable the construction of circuits with better properties than circuits with traditional differentiating amplifiers with voltage feedback. Thereinafter I made signal flow diagrams for OTA component. Transconductancal amplifiers are well known active components used in various areas of analog signal processing. OTA amplifier {{is in fact the}} current source controlled by voltage difference, which is characterised by gm transconductance. Ulterior components were IOZ and IZN models of voltage amplifier with voltage gain A. The last component was COA amplifier. It is a current operational amplifier. COA model is fully dual component to VOA, which is classical voltage amplifier. In my project I used filters with two OTA components. This filter offers functions like low-pass filter, band-pass filter, high-pass filter, band-stop filter and <b>two-phase</b> <b>network.</b> Following this I used circuits with two GCC conveyors. These offer band-pass filter, low-pass filter, high-pass filter, band-stop filter and <b>two-phase</b> <b>network.</b> Ultimately I designed filters with COA components, which offer three transmission functions simultaneously (DP, PP and HP). Analysis of these filters was made with a help of PSpice computer programme...|$|E
40|$|The {{accurate}} {{modeling and}} analysis of <b>two-phase</b> fluid <b>networks</b> found in environmental control and life support systems is presently undertaken by computer-aided engineering (CAE) techniques whose generalized fluid dynamics package can solve arbitrary flow networks. The CAE system for integrated test bed modeling and analysis will also furnish interfaces and subsystem/test-article mathematical models. Three-dimensional diagrams of the test bed are generated by the system after performing the requisite simulation and analysis...|$|R
40|$|Abstract. The {{mathematical}} model based on graph {{theory and the}} refrigerant natural cycle system of gas-liquid <b>two-phase</b> flow <b>network</b> is established. Incidence matrix was {{used to describe the}} relationships between the various components. The node conservation equations, branch equations, momentum conservation equation in return circuit and mass conservation equations of system are established. The model was solved by using variable step gird iterative method. Then refrigerant state of each node and refrigerant flow of each branch in network model are obtained. Establishment and solution of the RNC network model provides an effective way for the further performance analysis of system...|$|R
40|$|Spheres of the {{metallic}} glass Au 55 Pb 22. 5 Sb 22. 5 {{have been formed}} up to a size of approximately 1. 5 mm in diameter. X-ray diffraction was used to establish the glassy nature of the samples and to provide evidence of two phase-separated glass regions. Scanning electron microscopy provided a direct visual observation of the <b>two-phase</b> amorphous <b>network</b> {{on the surface of}} the sphere. The physical dimensions of the phase-separated regions were observed to be cooling-rate sensitive. Energy dispersive spectroscopy indicated that the compositions of these two glassy phases were Au-rich and Pb-rich, respectively, confirming the results of Kim and Johnson (1981). In addition, the spheres exhibited an unusual surface smoothness of better than + or - 250...|$|R
40|$|Recently, {{few studies}} have {{investigated}} the relationships between advice seeking and giving network densities and IT system use. To fill the gap, this study explores IT system use by drawing on theories of advice networks, user adaptation and IT system use. Specifically, four types of user adaptation are examined, including IT adaptation, task adaptation, positive reappraisal and emotional venting. We predict that advice seeking and giving network densities play different roles in each type of user adaptation. Furthermore, IT adaptation, task adaptation and positive reappraisal will positively influence IT system use, whereas emotional venting will negatively influence it. To investigate the research model, a <b>two-phase</b> <b>network</b> survey is being conducted {{in the context of}} a newly implemented EMR in a hospital. We aim to theoretically open the black box between advice networks and IT system use, and provide practical insights for implementing, designing and using IT systems in organizations...|$|E
40|$|A {{number of}} {{experiments}} on fluid flow at the micro/nano-scale {{have demonstrated that}} flow velocity obviously deviates from the classical Poiseuille’s law due to the micro forces between {{the wall and the}} fluid. Based on an oil–water <b>two-phase</b> <b>network</b> simulation model, a three-dimensional pore-scale micro network model with solid–liquid interfacial effects was established. The influences of solid–liquid interface effects including van der Waals force and wettability on the residual oil distribution and relative permeability were investigated through microscopic simulation. The effects of pore radius, pore–throat size ratio, shaping factor, and coordination number on the residual oil distribution were analyzed at the same time. The results showed that the oil recovery would be overestimated by about 4 % without van der Waals force in a water-wet reservoir. The impact of van der Waals force on water-wet reservoirs was significantly obvious in contrast with oil-wet reservoirs. In addition, the residual oil distribution was significantly influenced by pore radius in water-wet reservoir, comparatively influenced by pore–throat size ratio in oil-wet reservoir. The present study illustrates the successful application of three-dimensional micro network models considering solid–liquid interfacial effects, and provides new insights for oil recovery enhancement...|$|E
40|$|Hydrogels {{have long}} been {{considered}} ideal candidates for biomaterial and tissue engineering applications due to their many desirable properties, such as high water content and tunable gelation conditions. Although these materials have undergone extensive research and development, some mechanical and physical properties are still difficult to achieve. The {{reason for this is}} often related to the structure of the hydrogel network. Understanding how network structures are influenced by changes in formulation parameters (i. e. polymer molecular weight, initial polymer concentration, ratio of hydrophilic to hydrophobic polymer), and correlating these results to known mechanical and physical properties would yield well characterized systems that are more easily tuned for specific applications. The work presented in this thesis focuses on the characterization of the micro- to nano-scale network structures of three distinct hydrogel systems: tetra-functional poly(ethylene glycol) (PEG) -based hydrogels, tetra-functional PEG/polydimethylsiloxane (PDMS) -based hydrogels, and commercial contact lenses. The tetra-functional PEG and PEG/PDMS hydrogel systems were synthesized with a novel cross-linking technique that was developed by the Tew Group in the Polymer Science and Engineering department at the University of Massachusetts Amherst. This technique was designed to reduce the formation of network defects. The resulting hydrogels are optically clear, and display highly resilient mechanical properties which suggest relatively defect free (or ideal) network structures. In collaboration with the Tew group, we performed a series of small-angle neutron scattering (SANS) studies on these systems. The results from the tetra-functional PEG hydrogels confirmed the presence of nearly ideal network structures. Additionally, those from the tetra-functional PEG/PDMS hydrogels revealed the presence of a <b>two-phase</b> <b>network</b> structure with a local, lamellar-like order. For both systems, the resulting structures were found to be dependent upon polymer molecular weight, initial polymer concentration, and the ratio of hydrophilic to hydrophobic polymer. These results confirm the effectiveness of the novel cross-linking technique used to synthesize the PEG and PEG/PDMS tetra-functional hydrogels. Their unique and predictable network structures provide an excellent starting point for the development of these systems for specific applications, such as tendon tissue engineering scaffolds...|$|E
40|$|Graduation date: 2011 Fractal-like {{branching}} microchannel flow {{networks have}} been found to improve wall temperature uniformity and decrease both pressure drop and flow power compared to arrays of straight microchannels. The present study seeks to maximize the benefits of fractal-like branching channels by means of a gradient-based optimization algorithm. The algorithm identifies the geometric parameters that yield the highest ratio of benefit to cost; the benefit being the heat transfer with cost being flow power. The stream-wise pressure and wall temperature distributions were determined numerically using one-dimensional models validated using experimental diagnostics and computational flow analyses. Pressure distributions were used to assess flow power, and wall temperature was used as an optimization constraint. Several geometric constraints were imposed during optimization to ensure sufficient bonding area for fabrication, to maximize convective surface area and to prevent channel overlap. Three fractal-like devices were studied and optimized: a single-phase heat sink, a two-phase heat sink and a single-phase oil-to-water heat exchanger. The flow rate of the three devices was constrained using a maximum wall temperature constraint for the single-phase heat sink, the critical heat flux for the two-phase heat sink, and a fixed cold side mass flow rate and temperature rise {{in the case of the}} heat exchanger. The optimized solutions were found to depend highly on both the geometric and flow constraints imposed. As the terminal channel width was reduced, flow power was reduced in both single-phase and two-phase heat sinks. However, the flow power was increased in the heat exchanger due to the constrained volumetric flow rate. In addition, results show that if a maximum wall temperature constraint is employed, single-phase flow outperforms two-phase flow in terms of reduction in flow power. However when constrained by a critical heat flux, <b>two-phase</b> <b>networks</b> outperform single-phase networks by up to 150...|$|R
40|$|Conventional single-relay aided <b>two-phase</b> {{cooperative}} <b>networks</b> employing {{coherent detection}} algorithms incur a significant 50 % throughput loss. Furthermore, {{it is unrealistic}} to expect that in addition to the task of relaying, the relay-station would dedicate further precious resources to the estimation of the source-relay channel in support of coherent detection. In order to circumvent these problems, we propose decode and-forward (DF) based successive relaying employing noncoherent detection schemes. A crucial challenge in this context is that of suppressing the successive relaying induced interference, despite dispensing with any channel state information (CSI). We overcome this challenge by introducing a novel adaptive Newton algorithm based multiple-symbol differential interference suppression (MS-DIS) scheme. Correspondingly, a three-stage concatenated transceiver architecture is devised. We demonstrate that our proposed system is capable of near-error-free transmissions at low signal-to-noise ratios...|$|R
40|$|The {{conventional}} single-relay aided <b>two-phase</b> cooperative <b>network</b> {{employing a}} so-called soft-input soft-output multiple-symbol differential sphere detection (SISO-MSDSD) and {{operating in a}} distributed turbo decoding mode incurs a high complexity and imposes a 50 % half-duplex relaying induced throughput loss. In this paper, we combat both of these critical problems. We commence by evaluating the Discrete-input Continuous-output Memoryless Channel (DCMC) capacity of the Decode-and-Forward (DF) based successive relaying aided networks (SRAN) as our theoretical benchmark. Then a relay-aided SISO-MSDSD is designed, which is then incorporated in the DF based SRAN. As our novel contribution, we demonstrate that the proposed transceiver is capable of significantly reducing the system’s complexity, whilst recovering the 50 % half-duplex relaying induced throughput loss. The system is capable of performing within 2. 9 dB from the corresponding noncoherent DCMC capacity...|$|R
40|$|Graduation date: 2008 It is {{hypothesized}} that increases in pressure drop due to vapor generation during boiling in microchannels {{can be reduced}} by extraction of vapor at its point of inception. Ultimately, this local vapor extraction decreases the pressure drop required to drive the flow through a fractal-like branching, microchannel flow network within the heat sink. Indeed, by lowering the overall flow rate by vapor extraction the pressure drop can, in principle, be lowered to that of single-phase flow. In the current study, the feasibility of vapor extraction and its influence on the pressure drop across the microchannels are investigated. The concept also {{has the potential to}} separate flow independent of heat sink orientation or the influence of gravity. The fractal-like flow network used here is one that has been previously shown to reduce pressure drop and yield a more uniform surface temperature distribution for single-phase flows than that observed in parallel microchannel flow networks. The disk shaped heat sink was covered with two porous Nylon membranes with an average pore size of 0. 45 microns that were backed with a porous aluminum block. Deionized, degassed water was used as the working fluid. A theoretical model was developed to predict the pressure drop across the flow network as a function of inlet mass flow rate, heat input, and pressure difference driving extraction across the membranes. Results of the model predictions are presented and discussed in both dimensional and non-dimensional format. Model predictions were used to discuss the trends and physical implications of local vapor extraction. It was observed that conditions existed where further increases in the membrane pressure difference had no influence vapor extraction and network pressure drop values. Experimental data was also collected and analyzed in order to assess the validity of the theoretical model. The predictive model and experimental data indicated that the <b>two-phase</b> <b>network</b> pressure drop is reduced by locally extracting vapor from the heat sink. The network pressure drop was reduced by as much as 80...|$|E
40|$|Open-source {{software}} {{becomes increasingly}} popular nowadays. Many startup companies {{and small business}} owners choose to adopt open source software packages to meet their daily office computing needs or to build their IT infrastructure. Unlike proprietary software systems, open source software systems usually have a loosely-organized developer collaboration structure. Developers work on their "assignments" on a voluntary basis. Many developers do not physically meet their "co-workers. " This unique developer collaboration pattern leads to unique software development process, and hence unique structure of software products. It is those unique characteristics of open source software that motivate this dissertation study. Our research follows {{the framework of the}} four key elements of software engineering: Project, People, Process and Product (Jacobson, Booch et al. 1999). This dissertation studies three of the four P's: People, Process and Product. Due to the large sizes and high complexities of many open source software packages, the traditional analysis methods and measures in software engineering can not be readily leveraged to analyze those software packages. In this dissertation, we adopt complex network theory to perform our analysis on open source software packages, software development process, and the collaboration among software developers. We intend to discover some common characteristics that are shared by different open source software packages, and provide a possible explanation of the development process of those software products. Specifically we represent real world entities, such as open source software source code or developer collaborations, with networks composed of inter-connected vertices. We then leverage the topological metrics that have been established in complex network theory to analyze those networks. We also propose our own random network growth model to illustrate open source software development processes. Our research results can be potentially used by software practitioners who are interested to develop high quality software products and reduce the risks in the development process. Chapter 1 is an introduction of the dissertation's structure and research scope. We aim at studying open source software with complex networks. The details of the 4 -P framework will be introduced in that chapter. Chapter 2 analyzes five C-language based open source software packages by leveraging function dependency networks. That chapter calculates the topological measures of the dependency networks extracted from software source code. Chapter 3 analyzes the collaborative relationship among open source software developers. We extract developer's co-working data out of two software bug fixing data sets. Again by leveraging complex network theory, we find out a number of topological characteristics of the software developer networks, such as the scale-free property. We also realize the topological differences between from the bug side and from the developer side for the extracted bipartite networks. Chapter 4 is to compare two widely adopted clustering coefficient definitions, the one proposed by Watts and Strogatz, the other by Newman. The analytical similarities and differences between the two clustering coefficient definitions provide useful guidance to the proposal of the random network growth model that is presented in the next chapter. Chapter 5 aims to characterize the open source software development process. We propose a <b>two-phase</b> <b>network</b> growth model to illustrate the software development process. Our model describes how different software source code units interconnect as the size of the software grows. A case study was performed by using the same five open source software packages that have been adopted in Chapter 2. The empirical results demonstrate that our model provides a possible explanation on the process of how open source software products are developed. Chapter 6 concludes the dissertation and highlights the possible future research directions...|$|E
40|$|AbstractThe daily optimal hydro {{generation}} {{scheduling problem}} (DOHGSB) {{is a complicated}} nonlinear dynamic constrained optimization problem, which {{plays an important role}} in the economic operation of electric power systems. This paper proposes a new enhanced differential evolution algorithm to solve DOHGSB. In the proposed method, chaos theory was applied to obtain self-adaptive parameter settings in differential evolution (DE). In order to handle constraints effectively, three simple feasibility-based selection comparison techniques embedded into DE are devised to guide the process toward the feasible region of the search space. The feasibility of the proposed method is demonstrated for the daily generation scheduling of a hydro system with four interconnected cascade hydro plants, and the test results are compared with those obtained by the conjugate gradient and <b>two-phase</b> neural <b>network</b> method in terms of solution quality. The simulation results show that the proposed method is able to obtain higher quality solutions...|$|R
40|$|Abstract—In {{this paper}} {{physical}} layer network coding (PLNC) in <b>two-phase</b> two-way relaying <b>networks</b> using coded orthogonal frequency division multiplexing (OFDM) transmission is investigated. After receiving the superimposedsignal from both sources, the relay estimates the XOR-based network coded signal, which is broadcast {{back to the}} sources. Assuming that the relay is equipped with multiple antennas, the uplink transmission forms a multiple-input multiple-output (MIMO) system, which allows the application of MIMO detection technologies. To this end, the impact of employing multiple antennas at the relay on different detection and decoding schemes under investigations is studied and compared with respect to mutual information (MI). Numerical simulations verify our theoretical analysis. I...|$|R
40|$|Abstract — A {{framework}} is developed for analyzing capacity gains from user cooperation in slow fading wireless networks {{when the number}} of nodes (network size) is large. The {{framework is}} illustrated for the case of a simple multipath-rich Rayleigh fading channel model. Both unicasting (one source and one destination) and multicasting (one source and several destinations) scenarios are considered. We introduce a meaningful notion of Shannon capacity for such systems, evaluate this capacity as a function of signal-to-noise ratio (SNR), and develop a simple <b>two-phase</b> cooperative <b>network</b> protocol that achieves it. We observe that the resulting capacity is the same for both unicasting and multicasting, but show that the network size required to achieve any target error probability is smaller for unicasting than for multicasting. Finally, we introduce the notion of a network “scaling exponent ” to quantify the rate of decay of error probability with network size {{as a function of the}} targeted fraction of the capacity. This exponent provides additional insights to system designers by enabling a finer grain comparison of candidate cooperative transmission protocols in even moderately sized networks. Index Terms — Wireless networking, multicasting, ad-hoc networks, sensor networks, cooperative diversity, outage capacity, scaling laws. I...|$|R
40|$|Abstract—A {{framework}} is developed for analyzing capacity gains from user cooperation in slow-fading wireless networks {{when the number}} of nodes (network size) is large. The {{framework is}} illustrated for the case of a simple multipath-rich Rayleigh-fading channel model. Both unicasting (one source and one destination) and multicasting (one source and several destinations) scenarios are considered. We introduce a meaningful notion of Shannon capacity for such systems, evaluate this capacity as a function of signal-to-noise ratio (SNR), and develop a simple <b>two-phase</b> cooperative <b>network</b> protocol that achieves it. We observe that the resulting capacity is the same for both unicasting and multicasting, but show that the network size required to achieve any target error probability is smaller for unicasting than for multicasting. Finally, we introduce the notion of a network “scaling exponent ” to quantify the rate of decay of error probability with network size {{as a function of the}} targeted fraction of the capacity. This exponent provides additional insights to system designers by enabling a finer grain comparison of candidate cooperative transmission protocols in even moderately sized networks. Index Terms—Ad hoc networks, cooperative diversity, multicasting, outage capacity, scaling laws, sensor networks, wireless networking. I...|$|R
40|$|International audienceThis aim of {{this paper}} is to place the {{healthcare}} network in a continuum stretching from cooperation to competition [...] according to the endorsement given [...] and, from there, to revisit the relations between care providers and re-focus on how these innovative care organizations are governed in the French healthcare system. We start out with a comprehensive yet condensed study focusing on the results of academic research and then on the effects recorded in different counties (Anglosphere then European) of policies introducing competitive market mechanisms designed to more effectively regulate the health system. This analysis surfaces surface two core strategies, deployed according to whether the implementation of competition policy is oriented solely at "health risk management" or whether it also entails decentralization of the funding function. However, we will see it in the second part, the network should above all be conceptualized as a cooperative arena nurtured in the hands of care staff that are normally isolated or even mutually opposed by market-driven competitive imperatives to contain costs. Our proposal for orchestrating these goals is to initiate a <b>two-phase</b> healthcare <b>network</b> management system, based on externally defining project-indexed incentive contracts (between organization and governing body) and on ushering in a coordination framework targeted towards the convention and internal decisioning (intra-organization) ...|$|R
40|$|A {{framework}} is developed for analyzing capacity gains from user cooperation in slow fading wireless networks {{when the number}} of nodes (network size) is large. The {{framework is}} illustrated for the case of a simple multipath-rich Rayleigh fading channel model. Both unicasting (one source and one destination) and multicasting (one source and several destinations) scenarios are considered. We introduce a meaningful notion of Shannon capacity for such systems, evaluate this capacity as a function of signal-to-noise ratio (SNR), and develop a simple <b>two-phase</b> cooperative <b>network</b> protocol that achieves it. We observe that the resulting capacity is the same for both unicasting and multicasting, but show that the network size required to achieve any target error probability is smaller for unicasting than for multicasting. Finally, we introduce the notion of a network ``scaling exponent'' to quantify the rate of decay of error probability with network size {{as a function of the}} targeted fraction of the capacity. This exponent provides additional insights to system designers by enabling a finer grain comparison of candidate cooperative transmission protocols in even moderately sized networks. Comment: The upper bound in Section (IV) has been modified so that it immediately generalizes to the multiple antenna case. The new version does not rely on Teletar's conjecture being true. Some additional typos have been correcte...|$|R
40|$|This {{thesis is}} on the {{reasoning}} of artificial neural networks based on granules for both crisp and uncertain data. However, understanding the data {{in this way is}} difficult when the data is so complex. Reducing the complexity of the problems that these networks are attempting to learn as well as decreasing the cost of the learning processes are desired for a better prediction. A suitable prediction in artificial neural networks depends on an in-depth understanding of data and fine tracking of relations between data points. Inaccuracies of the prediction are caused by complexity of data set and the complexity is caused by uncertainty and quantity of data. Uncertainties can be represented in granules, and the reasoning based on granules is known as granular computing. This thesis proposed an improvement of granular neural networks to reach an outcome from uncertain and crisp data. Two methods based on genetic algorithms (GAs) are proposed. Firstly, GA-based fuzzy granular neural networks are improved by GA-based fuzzy artificial neural networks. They consist of two parts: granulation using fuzzy c-mean clustering (FCM), and reasoning by GAbased fuzzy artificial neural networks. In order to extract granular rules, a granulation method is proposed. The method has three stages: construction of all possible granular rules, pruning the repetition, and crossing out granular rules. Secondly, the two-phase GA-based fuzzy artificial neural networks are improved by GA-based fuzzy artificial neural networks. They are designed in two phases. In this case, the improvement is based on alpha cuts of fuzzy weight in the network connections. In the first phase, the optimal values of alpha cuts zero and one are obtained to define the place of a fuzzy weight for a network connection. Then, in the second phase, the optimal values of middle alpha cuts are obtained to define the shape of a fuzzy weight. The experiments for the two improved networks are performed in terms of generated error and execution time. The results tested were based on available rule/data sets in University of California Irvine (UCI) machine learning repository. Data sets were used for GA-based fuzzy granular neural networks, and rule sets were used for GA-based fuzzy artificial neural networks. The rule sets used were customer satisfaction, uranium, and the datasets used were wine, iris, servo, concrete compressive strength, and uranium. The results for the <b>two-phase</b> <b>networks</b> revealed the improvements of these methods over the conventional onephase <b>networks.</b> The <b>two-phase</b> GA-based fuzzy artificial neural networks improved 35 % and 98 % for execution time, and 27 % and 26 % for the generated error. The results for GA-based granular neural networks were revealed in comparison with GA-based crisp artificial neural networks. The comparison with other related granular computing methods were done using the iris benchmark data set. The results for these networks showed an average performance of 82. 1 %. The results from the proposed methods were analyzed in terms of statistical measurements for rule strengths and classifier performance using benchmark medical datasets. Therefore, this thesis has shown GA-based fuzzy granular neural networks, and GA-based fuzzy artificial neural networks are capable of reasoning based on granules for both crisp and uncertain data in artificial neural network...|$|R
40|$|Weakly {{supervised}} {{semantic segmentation}} and localiza- tion {{have a problem}} of focusing only {{on the most important}} parts of an image since they use only image-level annota- tions. In this paper, we solve this problem fundamentally via <b>two-phase</b> learning. Our <b>networks</b> are trained in two steps. In the first step, a conventional fully convolutional network (FCN) is trained to find the most discriminative parts of an image. In the second step, the activations on the most salient parts are suppressed by inference conditional feedback, and then the second learning is performed to find the area of the next most important parts. By combining the activations of both phases, the entire portion of the tar- get object can be captured. Our proposed training scheme is novel and can be utilized in well-designed techniques for weakly supervised semantic segmentation, salient region detection, and object location prediction. Detailed experi- ments demonstrate the effectiveness of our two-phase learn- ing in each task. Comment: Accepted at ICCV 201...|$|R
40|$|Abstract: The <b>two-phase</b> MIMO NC (<b>network</b> coding) scheme {{can be used}} {{to boost}} the {{throughput}} in a two-way relay channel in which nodes are equipped with multiple antennas. The obvious strategy is for the relay node to extract the individual packets from the two end nodes and mix the two packets to form a network-coded packet. In this paper, we propose a new scheme called MIMO PNC (physical network coding), in which the relay extracts the summation and difference of the two end packets and then converts them to the network-coded form. MIMO PNC is a natural combination of the single-antenna PNC scheme and the linear MIMO detection scheme. The advantages of MIMO PNC are many. First, it removes the stringent carrier-phase requirement in single-antenna PNC. Second, it is linear in complexity with respect to the constellation size and the number of simultaneous data streams in MIMO. Simulation shows that MIMO PNC outperforms the straightforward MIMO N...|$|R
40|$|Culturometrics {{is a new}} person-centred {{research}} {{philosophy that}} has shaped new tools for measuring and revealing the subjectivities of cultural identities. By focusing on tractable processes of identity communication rather than attempting to categorise the infinitely variable forms of identity outcomes it has developed intuitively acceptable computationally simple bridges across the qualitative /quantitative research divide. By reframing social constructs as cultural identities and categorising cultural groups by the fluidity of their membership it has extended the remit of traditional qualitative research. This paper gives {{a brief overview of}} the humanistic intentions of Culturometrics that underpin its objective methods for measuring and revealing the rich subjectivities of cultural identity. The paper demonstrates one of the selfnorming processes that regulate personal expectations allowing subjective self-evaluations of identity to be compared. It demonstrates efficient <b>two-phase</b> etic/emic social <b>network</b> sampling of cultural groups and effective contrast interviewing for revealing the unique values, attitudes, beliefs and intentions that define cultural Identity in specific research contexts...|$|R
40|$|Abstract—We {{consider}} a half-duplex wireless relay network with hybrid-automatic retransmission request (HARQ) and Rayleigh fading channels. In this paper, we analyze the average throughput and outage probability of the multi-relay delay-limited HARQ system with opportunistic relaying scheme in decode-and-forward mode, {{in which the}} best relay is selected to transmit the source’s regenerated signal. A simple and distributed relay selection strategy is considered for multi-relay HARQ channels. Then, we utilize the non-orthogonal cooperative trans-mission between the source and selected relay for retransmitting of the source data toward the destination if needed, using space-time codes. We analyze {{the performance of the}} system. We first derive the cumulative density function (CDF) and probability density function (PDF) of the selected relay HARQ channels. Then, the CDF and PDF are used to determine the exact outage probability in the l-th round of HARQ. The outage probability is required to compute the throughput-delay performance of this half-duplex opportunistic relaying protocol. The packet delay constraint is represented by L, the maximum number of HARQ rounds. An outage is declared if the packet is unsuccessful after L HARQ rounds. Furthermore, simple closed-form upper-bounds on outage probability are derived. Based on the derived upper-bound expressions, it is shown that the proposed schemes achieve the full spatial diversity order of N + 1, where N is the number of potential relays. Our analytical results are confirmed by simulation results. In addition, simulation show that our proposed scheme can achieve higher average throughput compared to the direct transmission and conventional <b>two-phase</b> relay <b>networks.</b> I...|$|R
40|$|Abstract — We {{consider}} {{the realization of}} traffic-oblivious routing in IP-over-Optical networks where routers are interconnected over a switched optical backbone, also called IP-over-OTN (Optical Transport Network). The traffic-oblivious routing we consider is a scheme where incoming traffic is first distributed in a preset manner {{to a set of}} intermediate nodes. The traffic is then routed from the intermediate nodes to the final destination. This splitting of the routing into <b>two-phases</b> simplifies <b>network</b> configuration significantly [8], [17]. In implementing this scheme, the first and second phase paths are realized at the optical layer with router packet grooming at a single intermediate node only. Studies like [10] indicate that IP routers are 200 times more unreliable than traditional carrier-grade switches and average 1219 minutes of down time per year. Given this unreliability of routers, we consider how two-phase routing in IP-over-OTN can be made resilient against router node failures. We propose two different schemes for provisioning the optical layer to handle router node failures – one that is failure node independent and static, and the other that is failure node dependent and dynamic. We develop linear programming formulations for both schemes and a fast combinatorial algorithm for the second scheme so as to maximize network throughput. In each case, we determine (i) the optimal distribution of traffic to various intermediate routers for both normal (no-failure) and failure conditions, and (ii) provisioning of optical layer circuits to provide the needed inter-router links. We evaluate the performance of the two router failure protection schemes (in terms of throughput) and compare it with that of unprotected routing. For our experiments, we use actual ISP network topologies collected for the Rocketfuel project. I...|$|R
40|$|A fully coupled {{formulation}} for three-phase {{capillary pressure}} and relative permeability, the flow parameters, with hysteresis and miscibility capabilities have been established. This work presents an extension to this formulation where wettability index associated the gridblocks {{has been added}} to the formulation. Also added to the model are analytical expressions of the <b>two-phase</b> flow parameters. <b>Network</b> generated model has been constructed of the core material and flow parameters have been established by numerical simulation. This technology is now reaching a level of maturity where predictability of core displacement experiments is within reach. The generation of flow parameters requires information of the wetting conditions. However, if the wetting condition is uncertain, flow parameters can easily be generated having different wettability once the pore space has been reconstructed. This work also presents simulation results of core displacement experiments having non water-wet condition, and applies flow parameters generated through network modeling at different wetting conditions. The recovery curves from the displacement experiments are history matched by altering the wettability index. Discussions are given, with illustrations. </p...|$|R
40|$|The <b>two-phase</b> MIMO NC (<b>network</b> coding) scheme {{can be used}} {{to boost}} the {{throughput}} in a two-way relay channel in which nodes are equipped with multiple antennas. The obvious strategy is for the relay node to extract the individual packets from the two end nodes and mix the two packets to form a network-coded packet. In this paper, we propose a new scheme called MIMO PNC (physical network coding), in which the relay extracts the summation and difference of the two end packets and then converts them to the network-coded form. MIMO PNC is a natural combination of the single-antenna PNC scheme and the linear MIMO detection scheme. The advantages of MIMO PNC are many. First, it removes the stringent carrier-phase requirement in single-antenna PNC. Second, it is linear in complexity with respect to the constellation size and the number of simultaneous data streams in MIMO. Simulation shows that MIMO PNC outperforms the straightforward MIMO NC significantly under random Rayleigh fading channel. Based on our analysis, we further conjecture that MIMO PNC outperforms MIMO NC under all possible realizations of the channel...|$|R
40|$|To enable massive machine type {{communication}} (mMTC), {{data aggregation}} is a promising approach {{to reduce the}} congestion caused by a massive number of machine type devices (MTDs). In this work, we consider a <b>two-phase</b> cellular-based mMTC <b>network</b> where MTDs transmit to aggregators (i. e., aggregation phase) and the aggregated data is then relayed to base stations (i. e., relaying phase). Due to the limited resources, the aggregators not only aggregate data, but also schedule resources among MTDs. We consider two scheduling schemes: random resource scheduling (RRS) and channel-aware resource scheduling (CRS). By leveraging the stochastic geometry, we present a tractable analytical framework to investigate the signal-to-interference ratio (SIR) for each phase, thereby computing the MTD success probability, {{the average number of}} successful MTDs and probability of successful channel utilization, which are the key metrics characterizing the overall mMTC performance. Our numerical results show that, although the CRS outperforms the RRS in terms of SIR at the aggregation phase, the simpler RRS has almost the same performance as the CRS for most cases with regards to the overall mMTC performance. Furthermore, the provision of more resources at the aggregation phase is not always beneficial to the mMTC performance. Comment: submitted to possible journal publicatio...|$|R
40|$|The {{prediction}} of residual oil saturation (Sor) and relative permeabilities after waterflooding in mixed-wet systems {{is a very}} challenging task. These are important parameters which must be estimated for a full field simulation of waterflooding. The Sor also defines the target oil for any proposed EOR process after an initial waterflood. Pore-scale network modelling {{can be used to}} estimate relative permeabilities, and the amount and nature of the trapped residual oil if the correct physics of oil displacement are properly included. During the waterflooding of mixed-wet systems, oil may drain down to relatively low residual saturations. Such Sor levels can only be calculated correctly when oil layers in pore corners are included in the pore-scale modelling. van Dijke and Sorbie (J. Coll. Int. Sci. 293 (2006) 455) obtained an accurate thermodynamically derived criterion for oil layers’ existence in pores with non-uniform wettability caused by ageing, which is more restrictive than the previously used geometrical layer existence criterion. This thermodynamic criterion has been included in a newly developed <b>two-phase</b> pore <b>network</b> model to calculate realistic Sor values for mixed-wet sandstones. A new ncornered star pore shape characterization technique has also been implemented in this model since the precise description of the pore shape was found to be important. Two unstructured networks, derived from Berea sandstone have been used for a number of sensitivities of the Sor and relative permeabilities with respect to wettability conditions. It is shown that Sor is lower for the more strongly oil-wet cases, while the water relative permeability curves increase gradually with oil-wetness at the higher water saturations. It has also been shown that pore shape approximations and oil layers collapse criterion {{have a significant impact on}} the Sor and the relative permeabilities. In particular, the thermodynamic oil layer existence criterion gives higher and more realistic Sor compared to previously used geometrical criterion. The network modelling has been used to match experimental data for water-wet and mixed-wet systems. In particular, the good agreement with mixed-wet systems strongly indicates that using the correct oil layer existence criteria is a significant step forward in the reliable {{prediction of}} Sor...|$|R
40|$|Two-phase routing, where {{traffic is}} first {{distributed}} to intermediate nodes before being routed {{to the final}} destination, has been proposed for handling widely fluctuating traffic without the need to adapt network routing to changing traffic. Pre-configuring the network in a traffic independent manner using <b>two-phase</b> routing simplifies <b>network</b> operation considerably. In this paper, we extend this routing scheme by providing resiliency against link failures through shared backup path restoration. We view this as important progress towards adding carrier-class reliability to the robustness of the scheme so as to facilitate its future deployment in Internet service provider (ISP) networks. In shared backup path restoration, each connection consists of a link-disjoint primary and backup path pair - two backup paths can share bandwidth on their common links if their primary paths are link disjoint. We show that the optimization problem for maximum throughput two-phase routing with shared backup path restoration is NP-hard. Assuming an approximation oracle for a certain disjoint paths problem (called SBPR-DISJOINT-PATHS, which is also NP-hard) involving the dual variables of a path indexed linear programming formulation for the problem, we design a combinatorial algorithm with provable guarantees. We also provide heuristics for finding approximating solutions to the SBPR-DISJOINT-PATHS problem. We evaluate the throughput performance and number of intermediate nodes in two-phase routing for the above and other restoration mechanisms for two-phase routing on actual ISP topologies collected for the Rocketfuel project...|$|R
40|$|Chemical {{engineering}} {{plants and}} processes models are very often highly nonlinear and of large scale. Handling these systems is a difficult, onerous (?) and time-consuming activity. To facilitate {{the generation of}} the codes, the mathematical solution of the equation systems and the simulation and representation of the problems, the simulator DIVA [4] has been developed in our group since the middle 80 ’s. Today the package has already achieved {{the status of a}} very robust and flexible computer aided process engineering tool. One of the new steps being pursued in the last years in the integrated package is the implementation of dynamic and steady state optimization facilities. First attempts of implementing simple gradient-based algorithms leaded to solutions that strongly depend on the starting points (local-optima) and require high computation times [3]. In this contribution, the focus is on steady-state optimization. To cope with these problems we propose two different approaches using combined stochastic and gradient based optimization methods. The first generates feasible starting points stochastically and then performs a successive quadratic programming search (SQP). The second, a mixed-integer nonlinear programming algorithm, uses a simplex-simulated annealing approach [1] with the possibility of a SQP refinement step. To illustrate the capabilities of the algorithms two examples are presented. The first example is an analytical function consisting of a sum of cosine functions combined with a Gaussian distribution with many local optima and a known global optimum. The other example is the synthesis of a fluid-fluid two phase reactor network [2]. [1] M. F. Cardoso, R. L. Salcedo, S. F. de Azevedo and D. Barbosa: A Simulated Annealing Approach to the Solution of MINLP Problems. Comp. Chem. Engng, 21 (12) : 1349 - 1364, 1997. [2] A. R. J. Esparta, T. Obertopp and E. D. Gilles: Synthesis of isothermal fluid-fluid <b>two-phase</b> CSTR <b>networks.</b> Comp. Chem. Engng, 22, Suppl. :S 671 -S 674, 1998. [3] C. P. Majer: Erweiterung einer Simulationsumgebung für verfahrentechnische Prozesse zur Parameterschätzung, Versuchsplannung und Trajektorienoptimierung. VDI Fortschritt-Berichte Nr. 3 / 538, VDI-Verlag, Düsseldorf, 1998. [4] K. D. Mohl, A. Spieker, E. Stein, and E. D. Gilles: DIVA - Eine Umgebung zur Simulation, Analyse und Optimierung verfahrenstechnischer Prozesse. In A. Kuhn and S. Wenzel (Eds.) : Simulationstechnik, 11. ASIM-Symposium in Dortmund, p. 278 - 283. Vieweg Verlag, Braunschweig/Wiesbaden, 1997...|$|R
40|$|This is the author’s {{version of}} a work that was {{accepted}} for publication in Fuel. Changes resulting from the publishing process, such as peer review, editing, corrections, structural formatting, and other quality control mechanisms may not be reflected in this document. Changes may {{have been made to}} this work since it was submitted for publication. A definitive version was subsequently published at: [URL] a hydrophobic micro-porous layer (MPL) between a gas diffusion layer (GDL) and a catalyst layer (CL) at the cathode of a PEM fuel cell was found capable of improving cell performance. However, how an MPL does this is not well-understood because current techniques are limited in measuring, observing and simulating multiphase pore fluid flow across the full range of pores that vary to a great extent in geometry, topology, surface morphology. In this work, we focused our investigation on estimating flow properties of an MPL volume to assess the limiting effect of strongly hydrophobic sub-micron pores on water transports. We adopted a nano-tomography and pore network flow modelling approach. A pore-structure model, purposely reconstructed from an intact MPL sample using Focused Ion Beam milling and Scanning Electron Microscope (FIB/SEM) previously, was used to extract a realistic pore <b>network.</b> A <b>two-phase</b> pore <b>network</b> flow model, developed recently for simulating the flow of gas, liquid or their mixture in both micrometre and nanometre pores, was applied to the pore network. We firstly tested the validity of the constructed pore network, and then calculated the properties: permeability for both water and selected gases, water entry pressure, and relative permeability. Knudsen diffusion was taken into consideration in calculations when appropriate. Our calculations showed that the water permeability was three orders of magnitude smaller than experimentally measured results reported in the literature, and when the water contact angle increased from 95 ° to 150 °, the water-entry pressure increased from 2. 5 MPa to 28 MPa. Thus our results revealed that for a strongly hydrophobic MPL that contains nanometre pores only it would behave like a buffer to water, and therefore the structural preferential paths in an MPL, such as cracks, are likely to be responsible for significant liquid water transport from the CL to the GDL that has been observed experimentally recently. We highlighted the needs for multi-scale modelling of the interplays of liquid water and gas transfer in MPLs that contain variable pores...|$|R
40|$|Abstract — Two-phase routing, where {{traffic is}} first {{distributed}} to intermediate nodes before being routed {{to the final}} destination, has been recently proposed [10], [11], [18] for handling widely fluctuating traffic without the need to adapt network routing to changing traffic. Pre-configuring the network in a traffic independent manner using <b>two-phase</b> routing simplifies <b>network</b> operation considerably. In this paper, we extend this routing scheme by providing resiliency against link failures through two different fast restoration mechanisms – local (link/span) based and end-to-end (path) based. We view this as important progress towards adding carrier-class reliability to the robustness of the scheme so as to facilitate its future deployment in Internet Service Provider (ISP) networks. The main contribution of {{the paper is the}} development of fast combinatorial algorithms for routing under the scheme with link and path restoration mechanisms so as to minimize the maximum utilization of any link in the network, or equivalently, maximize the throughput. The algorithms developed are Fully Polynomial Time Approximation Schemes (FPTAS) – for any given ɛ> 0, an FPTAS guarantees a solution that is within a (1 + ɛ) -factor of the optimum and runs in time polynomial in the input size and 1. To the best of our knowledge, this is the ɛ first work in the literature that considers making the scheme resilient to link failures through pre-provisioned fast restoration mechanisms. We evaluate the performance of link and path restoration (in terms of throughput) and compare it with that of unprotected routing. For our experiments, we use actual ISP network topologies collected for the Rocketfuel project. I...|$|R
30|$|In recent years, {{there are}} some {{publications}} focusing on the energy efficient design of TWR networks. By using the channel statistics, the authors of [12] proposed a transmit power allocation algorithm to minimize the overall transmit power of the TWR network with asymmetric traffic requirements. Considering the transmit and circuit power consumptions together, a hybrid one- and two-way relaying policy was developed in [13] to enhance the system energy efficiency. By using the instantaneous channel knowledge at transmitters, joint optimum power allocation and beamforming algorithms have been proposed for the <b>two-phase</b> TWR <b>network</b> in [14] and the three-phase TWR network in [15] to minimize the system transmit power, while guaranteeing that the received signal-to-noise ratios (SNRs) at the two sources be larger than the pre-defined thresholds. By exploiting the statistical channel knowledge at transmitters, the authors of [16] addressed an optimization problem minimizing the total transmit power of the TWR network with different outage probability constraints on the two sources. By exploiting the statistical channel knowledge at transmitters, a joint power allocation and relay location algorithm was proposed in [17] to reduce the power consumption of an asymmetric two-way AF relay network while ensuring the required network quality of service. In [18], the hybrid one- and two-way relaying policy proposed in [13] was extended to an orthogonal frequency-division multiplexing (OFDM) modulated TWR network. Moreover, the study of energy efficiency and spectrum efficiency trade-off for TWR networks {{can be found in}} [19] and references therein. In [20], a power allocation technique was proposed for maximizing the bits per unit of Joule of an OFDM modulated two-way AF relay network. The authors of [21] consider a two-way relay network with multiple pairs of source nodes and proposed a joint power and subchannel allocation and active subchannel selection technique maximizing the summation of the information bits per Joule of energy consumed at each terminal pair. The authors of [22] consider an AF two-way relay scenario with multiple relay nodes and CSI errors and proposed a joint implementation algorithm of subcarrier pairing and allocation, relay selection, and transmit power allocation. Moreover, [6 – 8] have expanded the idea of TWR into WSN settings. In [6], a novel policy incorporating single-threshold noncoherent energy detection and digital network coding at the relay side was developed for the WSN, where two sources would like to exchange low-rate data via a shared relay with complexity or latency limit. In order to maximize the secrecy sum rate, the authors of [7] proposed joint subcarrier assignment, subcarrier pairing, and power allocation algorithms for the orthogonal frequency division multiple access two-way relay WSN with and without cooperative jamming. The authors of [8] proposed a communication scheme employing TWR for three sensor nodes to support bi-directional communications of two applications. In [23], an intelligent power allocation algorithm for distributed beamforming is proposed to guarantee the required channel capacity and improve the network lifetime as well. The authors of [24] studied the outage performance of a two-way OFDM-based nonlinear AF relay network. In [25], an optimal power allocation algorithm is proposed to maximize the minimum signal-to-noise plus distortion ratio for a two-way AF OFDM-based relay network. It should be noted that most of the existing studies as mentioned earlier either focus on the single-carrier systems or the power minimization issue is not considered. Thus, it is natural to question how to extend the proposed energy efficient algorithms to multi-carrier settings? Do they need any modifications or should they be redesigned completely? So far, this issue has not been well studied in the literature.|$|R
40|$|A {{noncoherent}} detection based successive relaying aided network (SRAN) {{is proposed}} and investigated {{in the context}} of a multi-user, multi-relay assisted scenario. The potentially excessive complexity of multiple-antenna based power-hungry channel estimation is avoided by replacing the classic coherent detection by multiple-symbol-based noncoherent detection. Then, as the benefit of forming a virtual antenna array (VAA) in a distributed fashion, the proposed cooperative network becomes capable of achieving a substantial spatial diversity gain in the uplink. Furthermore, the 50 % throughput loss incurred by the conventional single relay-aided <b>two-phase</b> cooperative <b>network,</b> which is caused by the half-duplex transmit/receive constraint of practical transceivers is recovered by designing a spectral efficient successive relaying protocol. Hence the proposed noncoherent successive relaying aided multi-user wireless system becomes capable of significantly improving the system’s performance. We demonstrate that multiple-symbol differential detection (MSDD) is capable of eliminating the error floor of the conventional differential detection (CDD), when experiencing severely timeselective Rayleigh fading associated with a high Doppler frequency, since the MSDD algorithm benefits from a higher time-diversity than CDD. However, this is achieved at a potentially excessive complexity, which is unaffordable in many practical applications. As a remedy, the sphere decoding principle is incorporated into the MSDD algorithm. The resultant multiple-symbol differential sphere detection (MSDSD) strikes an attractive trade-off between the achievable BER performance and the complexity imposed. In order to improve the energy-efficiency, the hard-decision-based MSDSD algorithm is further developed to its soft-decision-based version, namely to the soft-input soft-output MSDSD (SISO-MSDSD). Furthermore, for the sake of exploiting the benefits of cooperative communications, we devise a new multiple-path propagation-aided MSDSD algorithm as a beneficial variant of the conventional MSDSD algorithm, which is further developed to the relay-aided MSDSD algorithm. However, relay-assisted transmissions increase the amount of interference imposed. Hence, in order to suppress the successive relaying induced interference, namely both the inter-relay interference (IRI) and the co-channel interference (CCI), we invoke the DS-CDMA multiple access technique. Consequently, a noncoherent successive relaying (NC-SR) aided cooperative DS-CDMA uplink is conceived, where the typical 50 % half-duplex relaying induced throughput loss is converted to a potential user-load reduction for the DS-CDMA system, since the SRAN requires two - rather than a single - spreading codes for each user. First, the AF protocol is invoked for the successive AF relaying aided DS-CDMA uplink, where initially a simple single-user scenario and then a realistic multi-user scenario are investigated. The evaluation of the associated noncoherent discreteinput continuous-output memoryless channel (DCMC) capacity indicates that our AF based SRAN is capable of significantly outperforming both the conventional AF relaying and the single-link direct-transmission. Then, as a counterpart, the successive DF relaying aided DS-CDMA uplink is also conceived, where a multi-user scenario is considered. The noncoherent DCMC capacity of the DF based SRAN reveals that the DF based SRAN may outperform the AF based SRAN, especially in the low SNR region. Furthermore, a relay-aided SISO-MSDSD assisted three-stage iterative transceiver is designed for supporting the operation of the proposed DF based SRAN, which is capable of operating close to the system’s capacity, while halving the system complexity imposed by the conventional single-path SISO-MSDSD aided distributed turbo decoder. As a further advance, we also consider a multi-user multi-relay DS-CDMA uplink. In order to efficiently organize the cooperation among the multiple nodes of this large-scale wireless network, we further develop the concept of adaptive network coded cooperation (ANCC) to its generalized version, namely to our “GANC” regime, which allows arbitrary channel coding schemes to serve as the cross-layer network coding, while still adapting to both network topology changes and to link failures. Upon incorporating the proposed GANC regime into the SRAN, we construct the GANC aided SRAN. In the spirit of the joint network-channel coding (JNCC) scheme, we devise a generalized iterative detection based three-stage transceiver architecture for the proposed GANC aided SRAN. The proposed transceiver is also adaptive to both network topology changes as well as to link failures. We demonstrate that combining two DF based SRANs and operating them under the proposed GANC regime is capable of attaining a significant power gain with respect to operating them independently, i. e. without any cooperative between them. Employing the DS-CDMA technique for suppressing the successive relaying-induced interference may lead to a potential user-load reduction for the DS-CDMA system. In order to mitigate the interference without requiring any extra orthogonal channel resources, we proposed a new multiple-symbol differential interference suppression (MS-DIS) regime, which is a novel amalgam of the adaptive modified Newton algorithm and of our SISO-MSDSD algorithm. Consequently, a MS-DIS-assisted plus relay-aided SISO-MSDSD based three-stage concatenated turbo transceiver is designed, which is capable of efficiently suppressing the interference at the expense of imposing as little as 2 % training overhead, despite experiencing severely time-selective Rayleigh fading associated with a high Doppler frequency...|$|R
