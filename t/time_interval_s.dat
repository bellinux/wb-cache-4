7|10000|Public
3000|$|Step 5 : Based on the {{selected}} s [...] k, for {{the elements in}} the status set of the previous <b>time</b> <b>interval</b> <b>S</b> k− 1, the charge/discharge power x [...] k [...] is determined according to (11). If (8) is satisfied, then it is a feasible transition state, otherwise, another element in S [...] k− 1 needs to be selected.|$|E
3000|$|In the formula, M is the {{cumulative}} water flow through {{a cross-section of}} the reservoir, m 3; Q x [...] is the fluid which flows across the X-direction during Δt time, m 3; Q y [...] is the fluid which flows across the Y-direction during Δt time, m 3; Q z [...] is the fluid which flows across the Z-direction during Δt time, m 3; D x [...] is {{the length of the}} X-direction cross-section, m; D y [...] is the length of the Y-direction cross-section, m; D z [...] is the length of the Z-direction cross-section, m; Δt is the unit <b>time</b> <b>interval,</b> <b>s.</b>|$|E
40|$|Ó The Author(s) 2009. This {{article is}} {{published}} with open access at Springerlink. com Abstract We develop a mathematical framework aimed at analyzing repeat and nearrepeat effects in crime data. Parsing burglary data from Long Beach, CA according to different counting methods, we {{determine the probability}} distribution functions for the <b>time</b> <b>interval</b> <b>s</b> between repeat offenses. We then compare these observed distributions to theoretically derived distributions in which the repeat effects are due solely to persistent risk heterogeneity. We find that risk heterogeneity alone cannot explain the observed distributions, while a form of event dependence (boosts) can. Using this information, we model repeat victimization {{as a series of}} random events, the likelihood of which changes each time an offense occurs. We are able to estimate typical time scales for repeat burglary events in Long Beach by fitting our data to this model. Computer simulations of this model using these observed parameters agree with the empirical data...|$|E
5000|$|... which {{determines the}} mean double-logarithmic <b>time</b> <b>interval</b> {{containing}} <b>s</b> successive eras.|$|R
3000|$|... <b>time</b> <b>interval</b> for {{transmitting}} <b>s.</b> Hence, {{the effective}} data {{rate in the}} asynchronous cooperative network is W/T + δ [...]...|$|R
3000|$|... are the gain, the PRN code, and the {{navigation}} data, respectively. The navigation data {{is assumed to}} be constant over the acquisition <b>time</b> <b>interval.</b> Note that <b>s</b> [...]...|$|R
40|$|We study a {{model in}} which two {{entities}} (e. g., plant species, political ideas, [...] .) compete for space on a plane, starting from randomly distributed seeds, and growing deterministically at possibly different rates. An entity which forms an infinite cluster is considered to dominate over the other (which then cannot percolate). We analyze the occurence of such a form of domination in situations in which one entity starts from a much larger density of seeds than the other one, but the latter one grows at a much faster rate than the former one. The model studied here generalizes the problem of Voronoi percolation. 1 Introduction Suppose that initially the seeds of two plant species A and B are randomly distributed {{on the plane and}} that the region occupied by each species starts to grow radially with constant speed vA and vB for the species A and B, respectively, starting from their seeds, so that after a relatively short <b>time</b> <b>interval</b> <b>s,</b> each seed A, or B, will be the center of a ball of [...] ...|$|E
40|$|The spin of an {{airplane}} occurs for angles of attack beyond stall, where nonlinear aerodynamics dominates and where complex and unpredictable behaviors might induce to question whether or not such a motion is chaotic. To find an answer to this issue, wind-tunnel tests are carried out on {{a model of a}} fighter attached by its center of gravity through an universal joint that allows only the three rotations. These degrees of freedom are analyzed according to modern techniques for the study of “supposedly chaotic data. ” It is found that, for increasing Reynolds number, successive bifurcations take place with a consequent more complex structure of the attractor, which reveals some features typical of quasi-periodic systems evolving toward chaos. The model is tested also in other configurations (different nose and/or leading-edge extensions, presence or absence of tail planes) so as to verify the dependence of the motion on some details. It is found that unpredictability and strong dependence on the initial conditions characterize the basic configuration, whereas a blunt nose and leading-edge extensions make the motion extremely regular. Even though the system might be on its route to chaos, a fully developed chaotic behavior is not observed. Nomenclature c = wing mean chord, m f = frequency, Hz k = reduced frequency, fc=U 1 Re = Reynolds number, U 1 c= t = time, s U = wind-tunnel streamwise velocity, m=s t = <b>time</b> <b>interval,</b> <b>s</b> = kinematic viscosity, m 2 =s = time delay ’,, = degrees of freedom (roll, pitch, and yaw), de...|$|E
40|$|AbstractThe model {{assumes that}} {{following}} treatment {{there are two}} groups of patients, those with P proportion in the “cured” group and (1 -P) in the “non-cured” group. Each group has a constant force of survival of each <b>time</b> <b>interval,</b> <b>S</b> 1 for the first group and S 2 for the second group. For most cancer, their survival experience will be described by the cumulative proportion surviving to the ith year as Si = PSil + (l-P) Si 2 However, for the breast cancer or those with similar curve, the survival experience will be described by a theoretical distribution given as SBi = CSi (l−e-S 2 i) The normalizing factor is C = (1 + e- 1) - 1 and Si is the first equation shown. The degree of spread of the cancer {{is the most important}} determinant of the nature and results of treatment. The stages of the disease can usually be defined, based {{on the size of the}} tumor, its extent of invasion of the organ, spread to surrounding organs, and the presence or absence of metastases. We should expect the parameters P, S 1 and S 2 to change according to the stages of the disease. That is, the proportion of “cured” and the survival rate of the “non-cured” decrease, as we go from local to regional, and to distant stage. In addition, the survival rate of the “cured” group should remain the same throughout the different disease extents. The survival rates for breast cancer patients of localized, regional and distant stages, diagnosed from 1950 to 1959 and from 1960 to 1973 were analyzed by a computer program. For colorectal cancers, four different time periods from 1940 to 1969 were analyzed. This data shows in general the average survival time and the proportion of “cured”, decrease from localized to regional and to distant stages, which does reflect the extent of the disease. This model makes it possible to describe the entire course of survival by means of a curve obeying definite regularities. The regularities inferred by an objective analysis of clinical data correctly reflects the actual effects of the clinical facts...|$|E
3000|$|... for {{the above}} model. Here, K is the maximum {{length of the}} {{continuous}} zeros considered. For example, if the last incident happened before K <b>time</b> <b>intervals</b> at location <b>s</b> [...]...|$|R
40|$|An {{interferometric}} system to stabilize {{and control the}} emission wavelength of pulsed dye lasers with nanosecond or microsecond pulse duration has been constructed and tested during routine lidar field experiments. Switching between predetermined wavelengths can also be performed within short <b>time</b> <b>intervals</b> (1 <b>s).</b> The effective resolution {{of the system is}} 4 x 106...|$|R
40|$|Altered time {{reproduction}} is exhibited by patients with adult {{attention deficit hyperactivity}} disorder (ADHD). It remains unclear whether memory capacity influences the ability of adults with ADHD to reproduce <b>time</b> <b>intervals.</b> We conducted a behavioral study on 30 ADHD patients who were medicated with methylphenidate, 29 unmedicated adult ADHD patients and 32 healthy controls (HCs). We assessed time reproduction using six <b>time</b> <b>intervals</b> (1 <b>s,</b> 4 s, 6 s, 10 s, 24 s and 60 s) and assessed memory performance using the Wechsler memory scale. The patients with ADHD exhibited lower memory performance scores than the HCs. No significant differences in the raw scores for any of the <b>time</b> <b>intervals</b> (p >. 05), {{with the exception of the}} variability at the short <b>time</b> <b>intervals</b> (1 <b>s,</b> 4 s and 6 s) (p. 05). We detected no findings indicating that working memory might influence time reproduction in adult patients with ADHD. Therefore, further studies concerning time reproduction and memory capacity among adult patients with ADHD must be performed to verify and replicate the present findings...|$|R
40|$|The multiple-look notion {{holds that}} the {{difference}} limen (DL) decreases with multiple observations. We investigated this notion for temporal discrimination in isochronous sound sequences. In Experiment 1, we established a multiple-look effect when sequences comprised nine standard <b>time</b> <b>intervals</b> (<b>S)</b> followed by {{an increasing number of}} comparison <b>time</b> <b>intervals</b> (C), but no multiple-look effect when one trailing C interval was preceded by an increasing number of <b>S</b> <b>intervals.</b> In Experiment 2, we extended the design. There were four sequential conditions: (a) 9 leading <b>S</b> <b>intervals</b> followed by 1, 2, …, or 9 C-intervals; (b) 9 leading C intervals followed by 1, 2, …, or 9 S intervals; (c) 9 trailing C-intervals preceded by 1, 2, …, or 9 S-intervals; and (d) 9 trailing S-intervals preceded by 1, 2, …, or 9 C-intervals. Both the interval accretions before and after the tempo change caused multiple-look effects, irrespective of the time order of S and C. Complete deconfounding of the number of intervals before and after the tempo change was accomplished in Experiment 3. The multiple-look effect of interval accretion before the tempo change was twice as big as that after the tempo change. The diminishing returns relation between the DL and interval accretion could be described well by a reciprocal function...|$|R
40|$|International audienceIn {{this paper}} we provide a schedulability test for {{dependant}} periodic task systems scheduled using non-preemptive policies. We {{consider the case}} of one processor and the schedulability test is based on the periodicity of a feasible schedule. A feasible schedule is periodic if it repeats from a time instant s with a period p. In the case of one processor, this property allows a real-time designer to check the deadlines only for instances of tasks within the <b>time</b> <b>interval</b> [s, <b>s</b> + p]...|$|R
30|$|The {{duration}} of the seismic event was about 160 s, with a moment rate concentrated in a <b>time</b> <b>interval</b> t_s= 80 <b>s</b> and a seismic moment m_s = 3.5 × 10 ^ 22 N m (Maercklin et al. 2012; Wei et al. 2012; Bletery et al. 2014). Accordingly, the average seismic slip was u_s = 15 m.|$|R
30|$|The radio map has 164 {{locations}} {{along the}} corridor and 70 locations inside the room. We placed the training points 1.2 m apart and collected 10 samples at each point with a <b>time</b> <b>interval</b> of 1 <b>s.</b> The default parameters for the algorithms are as follows: the parameter k of KNN is 4, {{and the number of}} particles used in the DRMBL is 1000.|$|R
30|$|It is {{well known}} that the finer the meshing of the structure, the more {{accurate}} is the result obtained, particularly in the case of nonlinear problems. A <b>time</b> <b>interval</b> of 0.0005 <b>s</b> is adopted for analysis of collision from MTs. For the force-time history of large trucks (LTs), sudden peaks and variations have compelled the use of a smaller <b>time</b> <b>interval</b> for a stable analysis. Hence, for LTs, the time stepping is set at 0.00025 s and the collision scene is investigated for 0.25 s.|$|R
40|$|Background: Neuron-specific enolase (NSE) and S 100 protein are {{implicated in}} several brain injuries, {{including}} stroke. Our {{objective was to}} analyze the temporal profile and the clinical significance of NSE and S- 100 in acute ischemic (IS) and intracerebral hemorrhage (ICH). Methods: We studied 224 patients with IS and 44 patients with ICH. Computerized tomography (CT) scans were performed to assess infarct volume. Stroke severity was evaluated using the National Institute of Health Stroke Scale (NIHSS), and functional outcome at 3 months with the modified Rankin Scale (mRS). Serum NSE and S 100 protein were measured using an electrochemiluminescence-immunoassay. Results: Peak values were found at 72  h for NSE and at 24  h for S 100 in IS. For ICH, peak values were found at 24  h for both NSE and S 100. At these <b>time</b> <b>intervals</b> <b>S</b> 100 and NSE correlated with the NIHSS score and were independently associated with poor outcome. Conclusions: High serum NSE and S 100 are associated with poor outcome in IS, and high serum NSE is associated with poor outcome in ICH. These findings suggest the potential utility of NSE and S 100 as prognostic markers for acute stroke. Clin Chem Lab Med 2009; 47 : 1513 – 8. Peer Reviewe...|$|R
40|$|BACKGROUND Allergic {{rhinitis}} is characterised by an IgE-mediated {{inflammatory response}} of nasal mucosa to allergens {{and it has}} a close association with bronchial asthma. It has been observed that persons having nasal allergy has a strong risk of developing bronchial asthma in adults. Usually, patients suffering from allergic rhinitis will have impaired FEV 1 (n forced expiratory volume at <b>timed</b> <b>interval</b> of 1 <b>s</b> and FEF 25 - 75...|$|R
3000|$|... ○ Fluctuation: There {{may be a}} {{fluctuation}} of throughputs in our WLAN {{system because}} of the nature of WLAN, which is prone to noise and other interferences. Another factor is the <b>time</b> <b>interval</b> to execute our adaptive traffic control algorithm, in order to update the knowledge about wireless circumstances, e.g., the number of new wireless clients and the current consumed bandwidth. In all experiments, we configured the <b>time</b> <b>interval</b> as 10 <b>s</b> in order to update the rate. However, if the administrator desires a smoother communication, the <b>time</b> <b>interval</b> can be re-configured, such as 5 s, through our user interface. Note that, in the setting of <b>time</b> <b>interval,</b> the administrator should concern about the computational overhead, since the CPU load will increase when the <b>time</b> <b>interval</b> is shorter.|$|R
40|$|The {{magnetic}} relaxation in a Tl 2 Ba 2 Ca 2 Cu 3 O 10 ±x {{superconducting thin film}} has been measured at a range of temperatures (5 – 70 K) and field strengths (500 – 5000 Oe). Measurements reveal that the relaxation obeys a logarithmic time dependence in the <b>time</b> <b>interval</b> 2000 <b>s</b> 3 ̆ct 3 ̆c 12 000 s. The relaxation rate is both temperature and field dependent. The average pinning potential U* calculated from the relationship U*=kT/[(- 1 /Mi) dM/d lnt] is in the range 20 – 70 meV, {{which is similar to}} those of Y-Ba-Cu-O and (Bi,Pb) -Sr-Ca-Cu-O. The anomalous increase of U* at higher temperature is found to be closely related to the irreversibility line...|$|R
40|$|DNA {{synthesis}} must {{be performed}} with extreme precision to maintain genomic integrity. In mammalian cells, different genomic regions are replicated at defined times, perhaps to preserve epigenetic information and cell differentiation status. However, the molecular principles that define this S phase program are unknown. By analyzing replication foci within discrete chromosome territories during interphase, {{we show that}} foci which are active during consecutive <b>intervals</b> of <b>S</b> phase are maintained as spatially adjacent neighbors throughout the cell cycle. Using extended DNA fibers, we demonstrate that this spatial continuity of replication foci correlates with the genetic continuity of adjacent replicon clusters along chromosomes. Finally, we used bioinformatic tools to compare the structure of DNA foci with DNA domains that are seen to replicate during discrete <b>time</b> <b>intervals</b> of <b>S</b> phase using genome-wide strategies. Data presented show that a major mechanism of S phase progression involves the sequential synthesis of regions of the genome because of their genetic continuity along the chromosomal fiber...|$|R
30|$|For the simulations, we {{employed}} the 3 -D staggered grid {{finite difference method}} (Graves, 1996). The shortest target period in the simulations was about 2 s. The smallest shear-wave velocity {{was assumed to be}} 1500 m/s. The finite difference grid size in horizontal directions was 500 m. For depth direction, a non-uniform grid size was used (Pitarka, 1999). For the sedimentary and low-velocity layers shallower than 11, 000 m, a grid span was designed to be 125 m; deeper than 11, 000 m, the grid span was 250 m. For the calculations, we used 9090 time steps at <b>time</b> <b>intervals</b> of 0.022 <b>s.</b>|$|R
30|$|Key frame {{detection}} is {{the mostly}} used technique for video summarization. By {{the extraction of}} key frames, first, a video file is divided into a collection of video episodes that can be examined separately. Second, since we use only the information of video frames for the <b>time</b> <b>interval</b> of 4 <b>s</b> after key frames, the computation burden of the algorithm is reduced. Different methods have been proposed for key frame extraction, including color-based methods [18], methods based on motion vectors [19, 20], object-based techniques [21, 22], and methods based on feature vector space [23, 24] to name a few.|$|R
40|$|We {{consider}} {{the problem of}} evaluating the continuous query of finding the k nearest objects {{with respect to a}} given moving point-object Oq among a set of n moving point-objects. The query returns a sequence of answer-pairs, namely pairs of the form (I, S) such that I is a <b>time</b> <b>interval</b> and <b>S</b> is the set of objects that are closest to Oq during I. Existing work on this problem lacks complexity analysis due to limited understanding of the maximum number of answer-pairs. In this paper we analyze the lower bound and the upper bound on the maximum number of answer-pairs. Then we consider two different types of algorithms. The first is off-line algorithms that compute a priori all the answer-pairs. The second type is on-line algorithms that at any time return the current answer-pair. We present the algorithms and analyze their complexity using the maximum number of answer-pairs...|$|R
40|$|Results of {{long-term}} investigations of variation of cobalt beta decay rate from 28. 12. 2010 till 08. 02. 2012 are presented. The scintillation spectrometer with two LaBr 3 detectors {{is used to}} register of gamma-quanta with energy 1. 173 and 1. 332 MeV accompanying cobalt beta decay. Counting rate of each detector and their gamma-quanta coincidence are collected in successive <b>time</b> <b>intervals</b> 10 <b>s.</b> The statistical Kolmogorov-Smirnov method for data analysis is used. Temperature influence on experimental results is also analyzed. Deviations of beta decay counting rate from constant distribution during the days were detected in those decades: from 11. 03 to 21. 03 with significance level a = 0. 1; from 22. 04 to 02. 05 with a= 0. 0125; from 24. 06 to 04. 07 with a= 0. 05; from 04. 08 to 14. 08 with a= 0. 05. Comment: 11 pages, 6 figure...|$|R
30|$|To {{visualize}} the average waveform of the ULF disturbance, the program developed selects in a specified interval all impulses above a certain threshold separately for H and D components in a running time window. Then, all the waveforms are averaged over the <b>time</b> <b>interval</b> ± 3 <b>s,</b> using the superposed epoch method, choosing {{as a reference}} time the moment of a pulse peak value. To examine the impulsive structure of the ULF activity this time window has been chosen to be larger than the expected time delay between the main and subsequent pulses (∼ 1 s) and short enough to avoid the contamination by pulses from different lightning strokes.|$|R
40|$|Dynamic {{mapping of}} an object’s local {{temperature}} distribution may offer valuable information for failure analysis, system control and improvement. In this letter {{we present a}} computerized measurement system which {{is equipped with a}} hybrid, low-noise mechanical-electrical multiplexer for real-time two-dimensional (2 D) mapping of surface temperatures. We demonstrate the performance of the system on a device embedded with 32 pieces of built-in Cr-Pt thin-film thermocouples arranged in a 4 × 8 matrix. The system can display a continuous 2 D mapping movie of relative temperatures with a <b>time</b> <b>interval</b> around 1 <b>s.</b> This technique may find applications in a variety of practical devices and systems...|$|R
40|$|The paper reports some {{experimental}} measurement results concerning harmonic content of current absorbed by Personal Computers (PC). The measurements provided different samples of PC's being monitored at short <b>time</b> <b>interval</b> lengths (2 <b>s).</b> The relatively large quantity of measurement results has permitted a statistical {{characterization of the}} harmonic content with both different modes of operation and various upstream system characteristics. Curves obtained from the measurement results processing have been proposed which give a parametrical estimate of the mutual influence between harmonics produced by PCs and the supply system characteristics {{at the point of}} common coupling. © 1999 Elsevier Science B. V. All rights reserved...|$|R
40|$|The first {{hydrometeor}} classification technique {{based on}} two-dimensional video disdrometer (2 DVD) data is presented. The method provides {{an estimate of}} the dominant hydrometeor type falling over <b>time</b> <b>intervals</b> of 60 <b>s</b> during precipitation, using the statistical behavior of a set of particle descriptors as input, calculated for each particle image. The employed supervised algorithm is a support vector machine (SVM), trained over 60 s precipitation time steps labeled by visual inspection. In this way, eight dominant hydrometeor classes can be discriminated. The algorithm achieved high classification performances, with median overall accuracies (Cohen's K) of 90 % (0. 88), and with accuracies higher than 84 % for each hydrometeor class...|$|R
40|$|ABSTRACT Several {{approaches}} {{are available for}} estimating soil wa-A method is presented for measuring soil water flux density (J) with a thermo-TDR (time domain reflectometry) probe. Constant ter flux indirectly (Nielsen et al., 1973; Bresler, 1973), but these approaches can be time consuming, mathemat-heat input during a small <b>time</b> <b>interval</b> (15 <b>s)</b> is used to emit a heat ically complicated, and measurement-intensive. pulse from a line heat source. Asymmetry in the thermal field near the Byrne et al. (1967, 1968) first applied heat as a tracer heat source is quantified by computing the maximum dimensionless to measure soil water flux. Their instruments consisted temperature difference (MDTD) between upstream and downstream locations. Heat transfer theory was used to relate MDTD to J. A thermo-TDR probe was used to obtain measurements of MDTD in water-saturated soil materials of different textures (sand, sandy loam, and clay loam) with imposed water flux densities ranging from 1. 16 � 10 of temperature sensors positioned symmetrically wit...|$|R
3000|$|... and {{fractional}} parameter γ are unknown. The magnitudes {{of these}} parameters are assessed using the {{models for the}} tooth movement with time in the viscoelastic PDL that were analysed in (Qian et al. 2009; Slomka et al. 2008). The tooth displacement with time in the viscoelastic PDL was determined for a continuous load that changed from 0 to 15 N (Qian et al. 2009) {{as well as for}} a discrete change in the load magnitude from 0.5 N to 3.0 N with a step of 0.5 N (Slomka et al. 2008); the <b>time</b> <b>intervals</b> were 300 <b>s</b> (Qian et al. 2009) and 1200 s (Slomka et al. 2008). In our case, the calculation of displacements was performed for the <b>time</b> <b>interval</b> from 0 to 300 s; the transition phase was 20 – 25 s (Qian et al. 2009; Slomka et al. 2008).|$|R
40|$|Knowing traffic {{characteristics}} in packet networks {{is important for}} designing algorithms for managing and controlling packet networks. We demonstrate that for realistic traffic traces knowing few elementary traffic characteristics can substantially improve network utilization. Nevertheless, this improvement is often modest {{in comparison with the}} improvement that could be achieved if traffic characterization on more than one time scale were available. I. INTRODUCTION Packet networks are used to transmit traffic generated by applications that often generate complex, bursty, traffic streams. These streams may carry data, voice, image, or video information. Characterizing such traffic streams requires knowing the statistical properties of packet arrivals in <b>time</b> <b>intervals</b> of various durations called time scales. Knowing traffic on a time scale s means knowing the marginal distribution of the arrivals in a <b>time</b> <b>interval</b> of length <b>s.</b> Researchers have adopted various approaches to designin [...] ...|$|R
40|$|Interhemispheric phase {{synchrony}} and amplitude correlation of beta oscillations were studied with MEG in a resting condition. The {{left and right}} hemisphere beta oscillations exhibited phase-locking with a phase-lag near zero degrees. The index of synchronization was strongest when these oscillations had large amplitude. Functionally, we interpret the {{phase synchrony}} {{on the basis of}} bilaterality of movement organization. A positive interhemispheric correlation was also found for the amplitude of spontaneous beta oscillations over long <b>time</b> <b>intervals</b> (> 1 <b>s).</b> The low-frequency correlation of spontaneous rhythmic activity may be the source of the low-frequency correlations of the hemodynamic responses in homologous areas that have been reported previously and have been interpreted as functional connectivity between these areas...|$|R
50|$|In Fig. 1, {{each step}} {{following}} the injection of 1.3 µl of compound B lasts 80 s. The vertical bars mark the theoretical {{value of the}} time needed to reach equilibrium at each titration step. It is seen that with the higher kon value of 15000 M-1 s-1 (upper figure) the <b>time</b> <b>interval</b> of 80 <b>s</b> is always sufficient for returning to equilibrium, whereas with the lower kon value of 7940 M-1 s-1, it becomes too short (red bars) for some injections. The thickest and longest bar marks mid-titration, that is the titration step closest to a unit stoichiometry (A = B). It can be shown that this corresponds to the step with the slowest return to equilibrium.|$|R
30|$|Several metrics can be {{specified}} {{to obtain}} the performance of each configuration. In this study, three metrics were used: the IP Packet Error Ratio (IP PER), the Erroneous Second Ratio (ESR), and the ESR 5 (20). The former represents the percentage of erroneously received IP packets. IP PER only account for the overall transmission errors experienced by the users {{and it does not}} represent the time distribution of the errors, which also affects the QoS of a streaming service perceived by the users. This can be taken into account with the other two metrics. ESR represents the percentage of seconds that contain errors and ESR 5 (20) represents the percentage of <b>time</b> <b>intervals</b> of 20 <b>s</b> with at most 1 s with errors (i.e., 5 % errors).|$|R
