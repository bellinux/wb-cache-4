6|30|Public
40|$|Anti-rumor {{dynamics}} {{is proposed}} {{on the basis}} of rumor dynamics and the characteristics of anti-rumor dynamics are explored by both mean-field equations and numerical simulations on complex network. The main metrics we study are the timing effect of combating rumor and the identification of influential nodes, which are what an efficient strategy against rumor may concern about. The results indicate that, there exists robust time dependence of anti-rumor dynamics and the <b>timing</b> <b>threshold</b> emerges as a consequence of launching the anti-rumor at different delay time after the beginning of rumor spreading. The <b>timing</b> <b>threshold</b> as a critical feature is further verified on a series of Barabasi-Albert scale-free networks (BA networks), where anti-rumor dynamics arises explicitly. The <b>timing</b> <b>threshold</b> is a network-dependent quantity and its value decreases as the average degree of the BA network increases until close to zero. Meanwhile, coreness also constitutes a better topological descriptor to identify hubs. Our results will hopefully be useful for the understanding of spreading behaviors of rumor and anti-rumor and suggest a possible avenue for further study of interplays of multiple pieces of information on complex network. Comment: 11 pages, 5 figures, Physica A: Statistical Mechanics and its Applications (2014...|$|E
40|$|The authors {{present an}} {{investigation}} into the incidences of ectopy and artefact as a function of time of day, heart rate and state changes for 19 normal subjects. State changes are defined to be a statistically significant change in mean or variance over a window of a few minutes. Artefact incidence is shown to be significantly correlated with state change and heart rate in normal humans, whereas ectopy exhibits no significant relationship. Artefact is therefore shown {{to be a source of}} information which can aid identification of activity or state changes and facilitate abnormality detection in patient populations. A <b>timing</b> <b>threshold</b> system is presented which differentiates between artefact, ectopy and sinus beats. A classification system based upon the frequency of artefact occurrences in relation to state changes is presented which correctly separates 78 % of the the real (normal) and artificial RR interval time series in event 2 of the CinC Challenge 2002 (entry no. 38). 1...|$|E
40|$|We {{review the}} {{clinical}} and biochemical criteria used {{for evaluation of}} the transsphenoidal pituitary surgery results {{in the treatment of}} Cushing’s disease (CD). Firstly, we discuss the pathophysiology of the hypothalamic–pituitary–adrenal axis in normal subjects and patients with CD. Considering the series published in the last 25 years, we observed a sig-nificant variation in the remission or cure criteria, including the choice of biochemical tests, <b>timing,</b> <b>threshold</b> values to define remission, and the interference of glucocorticoid replacement or previous treatment. In this context we emphasize serum cortisol levels obtained early (from hours to 12 days) in the postoperative period without any glucocor-ticoid replacement or treatment. Our experience demonstrates that: (i) early cortisol 6 mo, (iii) absence of response of cortisol/ACTH to CRH or DDAVP, (iv) return of dexamethasone suppression, and circadi-an rhythm of cortisol are appropriate indices of remission of CD. In patients with unde-tectable cortisol levels early after surgery, recurrence seems to be low. Finally, although certain biochemical patterns are more suggestive of remission or surgical failure, none has been proven to be completely accurate, with recurrence observed in approximately 10 to 15 % of the patients in long-term follow-up. We recommended that patients with CD should have long-term monitoring of the CRH-ACTH-cortisol axis and associated co-mor-bidities, especially hypopituitarism, diabetes mellitus, hypertension, cardiovascular dis-turbances, and osteoporosis. (Arq Bras Endocrinol Metab 2007; 51 / 8 : 1362 - 1372...|$|E
40|$|International audienceWith the {{emergence}} of Future Internet applications that connect web services, sensor-actuator networks and service feeds, scalability and heterogeneity support of interaction paradigms are of critical importance. Heterogeneous interactions can be abstractly represented by client-service, publish-subscribe and tuple space middleware connectors that are interconnected via bridging mechanisms providing interoperability among the services. In this paper, we {{make use of the}} eXtensible Service Bus (XSB), proposed in the CHOReOS project as the connector enabling interoperability among heterogeneous choreography participants. XSB models transactions among peers through generic post and get operations that represent peer behavior with varying time/space coupling. Nevertheless, the heterogeneous lease and timeout constraints of these operations severely affect latency and success rates of transactions. By precisely studying the related <b>timing</b> <b>thresholds</b> using timed automata models, we verify conditions for successful transactions with XSB connectors. Furthermore, we statistically analyze through simulations, the effect of varying lease and timeout periods to ensure higher probabilities of successful transactions. Simulation experiments are compared with experiments run on the XSB implementation testbed to evaluate the accuracy of results. This work can provide application developers with precise design time information when setting these <b>timing</b> <b>thresholds</b> in order to ensure accurate runtime behavior...|$|R
40|$|The CMS tracker is {{the largest}} silicon {{detector}} ever built, covering 200 square meters and providing an average of 14 high-precision measurements per track. The use of tracker data for reconstruction of charged particles and primary and secondary vertices requires fine-grained monitoring and calibration procedures as well as accurate alignment. Results from <b>timing</b> and <b>threshold</b> optimization, gain calibration, and Lorentz angle determination are shown and the impact on resolution and dE/dx measurements is discussed...|$|R
30|$|Here, {{it should}} be {{emphasized}} that although we cannot specifically estimate the <b>timing</b> and <b>threshold</b> of megathrust fault ruptures, our conceptual model provides plausible rupture scenarios in a spatial resolution for the occurrence of the 2011 Tohoku-Oki earthquake. More megathrust events in the worldwide subduction zones should be examined for a consistent pattern, as observed in this study. Furthermore, techniques which are more quantitative need to be applied in further studies to determine, more objectively and accurately, the difference between the spatial and temporal variations of up-and down-dip earthquakes before, and after, a large earthquake.|$|R
40|$|Abstract Background When to {{initiate}} antiretroviral therapy in HIV infected patients is a diffcult clinical decision. Actually, {{it is still}} a matter of discussion whether early highly active antiretroviral therapy (HAART) during primary HIV infection may influence the dynamics of the viral rebound, in case of therapy interruption, and overall the main disease course. Methods In this article we use a computational model and clinical data to identify the role of HAART timing on the residual capability to control HIV rebound after treatment suspension. Analyses of clinical data from three groups of patients initiating HAART respectively before seroconversion (very early), during the acute phase (early) and in the chronic phase (late), evidence differences arising from the very early events of the viral infection. Results The computational model allows a fine grain assessment of the impact of HAART timing on the disease outcome, from acute to chronic HIV- 1 infection. Both patients' data and computer simulations reveal that HAART timing may indeed affect the HIV control capability after treatment discontinuation. In particular, we find a median time to viral rebound that is significantly longer in very early than in late patients. Conclusions A <b>timing</b> <b>threshold</b> is identified, corresponding to approximately three weeks post-infection, after which the capability to control HIV replication is lost. Conversely, HAART initiation occurring within three weeks from the infection could allow to preserve a significant control capability. This time could be related to the global triggering of uncontrolled immune activation, affecting residual immune competence preservation and HIV reservoir establishment. </p...|$|E
40|$|Sequence {{learning}} is a fundamental brain function that allows for the acquisition {{of a wide range}} of skills. Unlearned movements become faster and more accurate with repetition, due to a process called prediction. Predictive behaviour observed in the eye and hand compensates for the inherent temporal delays in the sensorimotor system and allows for the generation of motor actions prior to visual guidance. We investigated predictive behaviour and the brain areas associated with this processing in (i) the oculomotor system (Eye Only (EO) : saccade vs. pursuit) and (ii) during eye and hand coordination (EH). Participants were asked to track a continuous moving target in predictable or random sequence conditions. EO and EH experiments were divided into 1) EO behavioural and 2) EO fMRI findings, and 3) EH behavioural and 4) EH fMRI findings. Results provide new insights into how individuals predict when learning a sequence of target movements, which is not limited to short [...] ‐term memory capacities and that forms a link between shorter and longer [...] ‐term motor skill learning. Furthermore, brain imaging results revealed distinct levels of activation within and between brain areas for repeated and randomized sequences that reflect the distinct <b>timing</b> <b>threshold</b> and adaptation levels needed for the two oculomotor systems. EH results revealed similar predictive behaviour in the eye and the hand, but also demonstrated enhanced coupling between the two motor systems during sequence learning. EH brain imaging findings have provided novel insights into the brain areas involved in coordination, and those areas more associated with sequence learning. Results show evidence of common predictive networks used for the eye and hand during learning. ...|$|E
40|$|UnrestrictedAs VLSI {{fabrication}} process continues to advance and device and interconnect dimensions approach nano-scale, {{limitations of the}} {{fabrication process}} cause larger percentage variations and higher incidences of small defects. In turn, these alter delays of gates and wires. While {{the change in the}} delay value of a particular gate or wire may be small, changes in delay values of multiple gates and wires along some circuit path may cause that path's delay to exceed the desired clock period. Hence, it is increasingly important to test circuits for delay faults.; While a robust test that satisfies the classical definition guarantees propagation of a transition along the entire target path, detailed circuit simulations have demonstrated that a classical two-pattern robust test for a path delay fault may not excite the worst case delay of the target path. Since the purpose of our framework is to accurately estimate the bounds of the worst-case circuit delay, it is important to identify a minimum set of the paths that are able to excite the delay equal or close to the worst-case circuit delay.; Once a minimum set of paths are identified, an automatic test pattern generator (ATPG) can be used in conjunction with these paths to obtain vectors that are able to excite the delay equal (or close to) the worst-case circuit delay. Current test generation algorithms need to generate a large number of tests to obtain a test that can excite the delay close or equal to the worst-case circuit delay. Developing a timing-oriented ATPG that can exploit both necessary logic and timing conditions for cost-effective pruning of targets, reducing ATPG complexity, and generating high quality tests is becoming important.; The goal of this research is to develop new methodologies and techniques for timing-oriented approaches for delay testing and dynamic timing analysis. We first develop the concepts of settling times and <b>timing</b> <b>threshold</b> to identify a minimum set of paths to be tested. We then identify properties of different types of paths as well as logic and timing conditions that are necessary to cover a target path and develop a new logic-and-timing implication procedure to exploit these conditions. We incorporate newly developed concepts in a new ATPG that also prioritizes the order in which these conditions are used to generate high quality vectors. We use this ATPG to identify paths that cannot or need not be tested and to generate high quality vectors for all other paths. Several applications are implemented, and the experimental results demonstrate the benefit of exploiting proposed concepts...|$|E
40|$|We endogenize the {{threshold}} points in Granovetter’s threshold model of collective behavior (Granovetter 1978). We {{do this in}} a simple model that combines strategic complementarity and private information in a dynamic setup with endogenous order of moves. Looking at Granovetter’s model in the strategic context allows us to highlight the sensitivity of collective outcomes to the timing of the games and the reversibility of the actions, and to emphasize an extra incentive for people to follow other people: to encourage more people to follow them. Endogenous <b>timing,</b> irreversibility, <b>threshold...</b>|$|R
40|$|Due to the {{recursive}} {{nature of}} most foot-mounted zero-velocityupdate-aided (ZUPT-aided) {{inertial navigation systems}} (INSs), the error covariance increases throughout each step and "collapses" {{at the end of}} the step, where the ZUPT correction is done. This gives sharp corrections and discontinuities in the estimated trajectory. For applications with tight real-time constraints, this behavior is unavoidable, since every estimate corresponds to the best estimate given all the information up until that time instant. However, for many applications, some degree of lag (non-causality) can be tolerated and the information provided by the ZUPTs at the end of a step, giving the sharp correction, can be made available throughout the step. Consequently, to eliminate the sharp corrections and the unsymmetrical covariance over the steps, the implementation of a smoothing filter for a ZUPT-aided INS is considered in this thesis. To our knowledge, no formal treatment of smoothing for such systems has previously been presented, even though an extensive literature on the general subject exists. Owing to the customary closed-loop complementary filtering used for aided INS, standard smoothing techniques cannot directly be applied. Also since the measurements (the ZUPTs) are irregularly spaced and appear in clusters, some varying-lag smoothing rule is necessary. Therefore, a method based on a mixed open-closedloop complementary filtering combined with a Rauch-Tung-Striebel (RTS) smoothing is suggested in this thesis. Different types of varying-lag smoothing rules are examined. For near real-time applications, smoothing is applied to the data in a step-wise manner. The intervals (steps) for the smoothing are determined based on measurement availability and covariance and <b>timing</b> <b>thresholds.</b> For complete o-line processing, full data set smoothing is examined. Finally, the consequences of the smoothing and the open-closed-loop filtering are quantified based on real data. The impact of the smoothing throughout the steps is illustrated and analyzed...|$|R
30|$|From the {{simulation}} {{we can see}} that the channel models are of randomness and multipath effect, so that the difference result corresponding to the right timing index is not always the maximum one. What's worse, when a threshold is selected, quantity of difference result exceeding threshold may be more than one or none on the contrary. For example, if we set the threshold as 60, the algorithm could obtain more than one timing samples in the situation of Figure 5 A, C, D. When we set a larger threshold, maybe the difference results are out of range, and no sample could be found out. Therefore, threshold is a key point for <b>timing.</b> And <b>threshold</b> should change as the channel environment changing. Meanwhile, we should notice that the features of correlation difference for preamble pattern 3 (or equivalently 4) are not distinct.|$|R
30|$|For example, TNF-α {{released}} in the striatum is considered to cause neurodegeneration, while release in the hippocampus could promote neuroprotection. One suggests that the detrimental effects occur in the early phase of the inflammatory response and the more beneficial effects in a later stage (Amantea et al. 2009). Another suggests that soluble TNF-α (which binds to TNF receptor 1) would cause primarily detrimental effects whereas membrane bound TNF-α (which binds to TNF receptor 2) would signal for neuroprotection (Fontaine et al. 2002). Other studies suggest that TNF-α can also be neuroprotective by acting through TNF receptor 1 (McCoy and Tansey 2008; Lambertsen et al. 2009). In conclusion, neurotoxic or neuroprotective effects will depend on several {{factors such as the}} extent of microglial activation in specific brain regions, <b>timing</b> and <b>threshold</b> of TNF-α expression and of its receptors and on the conditions that stimulate TNF-α signaling.|$|R
40|$|The CMS tracker is {{the largest}} silicon {{detector}} ever built, covering an area close to 200 m$^ 2 $ and consisting of 15 148 silicon strip and 1440 silicon pixel modules. The use of tracker data in physics analysis requires fine-grained monitoring and calibration procedures. Results from <b>timing</b> studies, <b>threshold</b> optimization, calibration of gains and Lorentz angle determination are shown and the impact on resolution and dE/dx measurements is discussed. In order to achieve an optimal track-parameter resolution, the position and orientation of its modules need to be determined with a precision of few micro meters and an accurate representation {{of the distribution of}} material in the tracker is needed. Results of the alignment of the full tracker are presented, based on the analysis of several million reconstructed tracks recorded during the commissioning of the CMS experiment with cosmic rays and the first proton-proton collisions. They have been validated by several data-driven studies and compared with predictions obtained from a detailed detector simulation. Reconstructed photon conversions and nuclear interactions have been used for a first estimate of the tracker material...|$|R
40|$|The CMS pixel {{detector}} {{consists of}} 15840 readout chips, containing {{a total of}} almost 66 million pixels. In this paper, I describe the preparation for the first data-taking with LHC beams, in which {{the performance of the}} readout chips was optimized using a suite of calibrations. The detector thresholds have been adjusted to be less than 3000 electrons, and the effect of <b>timing</b> on the <b>thresholds</b> has been studied. After the arrival of LHC beam in December of 2009, the timing of the detector was optim ized to achieve maximum efficiency, using both online and offline analysis. I will also discuss the challenges presented by beam backgrounds...|$|R
40|$|The {{foreseen}} {{outcome of}} a rehabilitation treat- ment is a stable improvement on the functional outcomes, which can be longitudinally assessed through multiple measures to help clinicians in functional evaluation. In this study, we propose an automatic comprehensive method of combining multiple measures {{in order to assess}} a functional improvement. As test-bed, a functional electrical stimulation based treatment for foot drop correction performed with chronic post-stroke participants is presented. Patients were assessed on five relevant outcome measures before, after intervention, and at a follow-up time-point. A novel algo- rithm based on variables minimum detectable change is proposed and implemented in a custom-made software, combining the outcome measures to obtain a unique parameter: capacity score. The difference between capacity scores at different <b>timing</b> is <b>thresholded</b> to obtain improve- ment evaluation. Ten clinicians evaluated patients on the Improvement Clinical Global Impression scale. Eleven patients underwent the treatment, and five resulted to achieve a stable functional improvement, as assessed by the proposed algorithm. A statistically significant agreement between intra-clinicians and algorithm-clinicians evaluations was demonstrated. The proposed method evaluates functional improvement on a single-subject yes/no base by merging different measures (e. g., kinematic, muscular) and it is validated against clinical evaluatio...|$|R
30|$|Again, the scaling {{equivalence}} is exact for the listed processes: {{formation of}} bumps, jets, and droplets from jets. Indeed, even a complicated {{process of the}} droplet production is governed by the surface tension and the exponentially fast Rayleigh instability. Thus, it is enough for a jet radius in simulations to be larger than few interatomic distances. This demand is hold in our simulations. In this connection, {{it is necessary to}} say that a phenomenon of restoration of the surface tension coefficient with a number of interatomic layers is carefully studied; see Figs. 8 and 9 and Appendix in [22]. We are not sure only in accuracy of our description of the process of formation of a hole in a stretched film, Figs. 7, 8, and 9. It seems that our simulations here give the order-of-magnitude estimates of <b>timing</b> and <b>threshold.</b> It is necessary to stretch a film down to 1 -nm thickness to cause a rupture. In simulations, we use from few times to one order of magnitude initially thinner films. It is not clear if exponentially fast instability presented here determines the duration of rupture by its inverse increment (like the Rayleigh instability of cylindrical jets). If not, then the duration depends on initial thickness and will be faster for thin films. There are many cases where very strong thinning of films and formation of holes are observed in experiments.|$|R
40|$|Global {{temperature}} is increasing, especially over northern lands (> 50 ◦ N), owing to positive feedbacks 1. As this in-‐ crease is most pronounced in winter, temperature seasonality (ST) —conventionally {{defined as the}} difference between sum-‐ mer and winter temperatures—is diminishing over time 2, a phenomenon that is analogous to its equatorward decline at an annual scale. The initiation, termination and performance of vegetation photosynthetic activity are tied to threshold temperatures 3. Trends in the <b>timing</b> of these <b>thresholds</b> and cumulative temperatures above them may alter vegetation productivity, or modify vegetation seasonality (SV), over time. The relationship between ST and SV is critically examined here with newly improved ground and satellite data sets. The observed diminishment of ST and SV is equivalent to 4 ◦ and 7 ◦ (5 ◦ and 6 ◦) latitudinal shift equatorward durin...|$|R
30|$|Comparisons between {{correlation}} {{difference and}} the algorithms we proposed {{demonstrate that the}} phenomenon of multi-timing synchronization samples is critical. The number of timing symbols achieved after synchronization of correlation difference is more than 1, when threshold ranges from 30 to 80. The proposed estimator could guarantee the uniqueness of synchronization results. From the results shown in tables above, when threshold is set larger than 50, average number of our proposed estimator is less than one. Nevertheless, average number of correlation difference is considerably over one. The phenomenon indicates that if the threshold is set over some value, correlation difference would get more than one synchronization sample, or on the contrast, get none, both scenarios {{would lead to the}} inefficiency of timing synchronization. The proposed algorithm could guarantee uniqueness of <b>timing</b> synchronization, if <b>threshold</b> is not chosen excessively big. That feature is of great significance for system synchronization.|$|R
40|$|The Mars Orbiter Laser Altimeter (MOLA) {{measured}} the pulse width and energy of altimetric laser returns {{during the course}} of two Mars years of operations. As secondary science objectives, MOLA obtains the footprint-scale roughness and the bidirectional reflectivity of Mars. MOLA underwent extensive preflight calibration and pulse measurements were monitored continuously in flight, but anomalous values of roughness have been inferred. A calibration of pulse widths using inflight data yields a slope-corrected roughness over ∼ 75 -m-diameter footprints that may be used for quantitative geomorphic surface characterization, required, for example, for landing site selection. The recalibration uses a total least-squares estimation of pulse characteristics that generalizes the method of Abshire et al. [2000]. This method, utilizing the <b>timing</b> at voltage <b>threshold</b> crossings and the area between crossings, accounts for observation errors and shows that surface roughness as small as 1 m can be resolved...|$|R
40|$|AbstractPulsed {{ultrasound}} {{was found}} to induce pulmonary capillary hemorrhage (PCH) in mice about 25 years ago but remains a poorly understood risk factor for pulmonary diagnostic ultrasound. In early research using laboratory fixed beam ultrasound, thresholds for PCH had frequency variation from 1 - 4 MHz similar to the Mechanical Index. In recent research, thresholds for B mode diagnostic ultrasound from 1. 5 - 12 MHz had little dependence on frequency. To compare the diagnostic ultrasound method to laboratory pulsed exposure, thresholds for fixed beam ultrasound were determined using comparable methods at 1. 5 and 7. 5 MHz. PCH thresholds were lower for simple fixed-beam pulse modes than for B mode and in approximate agreement with early research. However, for comparable <b>timing</b> parameters, PCH <b>thresholds</b> had little dependence on ultrasonic frequency. These {{findings suggest that the}} MI may not be directly useful as a dosimetric parameter for safety guidance in pulmonary ultrasound...|$|R
40|$|Abstract. Large {{wildfires}} in the Santa Monica Mountains {{of southern}} California occur when {{low levels of}} live and dead fuel moisture coincide with Santa Ana wind events. Declining live fuel moisture may reach a threshold that increases susceptibility to large wildfires. Live fuel moisture and fire history data for the Santa Monica Mountains from 1984 to 2005 {{were used to determine}} a potential critical live fuel moisture threshold, below which large fires become much more likely. The ability of live fuel moisture, remote sensing, and precipitation variables to predict the annual timing of 71 and 77 % live fuel moisture thresholds was assessed. Spring precipitation, measured through the months of March, April, and May, was found to be strongly correlated with the annual timing of both live fuel moisture thresholds. Large fires in the Santa Monica Mountains only occurred after the 77 % threshold was surpassed, although most large fires occurred after the less conservative 71 % threshold. Spring precipitation has fluctuated widely over the past 70 years but does not show evidence of long-term trends. Predictive models of live fuel moisture <b>threshold</b> <b>timing</b> may improve planning for large fires in chaparral ecosystems...|$|R
40|$|Animals on {{interval}} schedules {{of reinforcement}} can rapidly adjust a temporal dependent variable, such as wait time, {{to changes in}} the prevailing interreinforcement interval. We describe data on the effects of impulse, step, sine-cyclic, and variable-interval schedules and show that they can be explained by a tuned-trace timing model with a one-back threshold-setting rule. The model can also explain steady-state timing properties such as proportional and Weber law timing and the effects of reinforcement magnitude. The model assumes that food reinforcers and other time markers have a decaying effect (trace) with properties that can be derived from the rate-sensitive property of habituation (the multiple-time-scale model). In <b>timing</b> experiments, response <b>threshold</b> is determined by the trace value {{at the time of the}} most recent reinforcement. The model provides a partial account for the learning of multiple intervals, but does not account for scalloping and other postpause features of responding on interval schedules and has some problems with square-wave schedules. Key words: interval timing, multiple time scale, scalar timing, memory, habituation, pigeons, rats Humans and animals can readily learn to anticipate the time when a reinforcing event will occur. This process is termed interval timing...|$|R
40|$|Timing is {{essential}} for many cellular processes, from cellular responses to external stimuli to the cell cycle and circadian clocks. Many of these processes are based on gene expression. For example, an activated gene {{may be required to}} reach in a precise time a threshold level of expression that triggers a specific downstream process. However, gene expression is subject to stochastic fluctuations, naturally inducing an uncertainty in this threshold-crossing time with potential consequences on biological functions and phenotypes. Here, we consider such "timing fluctuations", and we ask how they can be controlled. Our analytical estimates and simulations show that, for an induced gene, timing variability is minimal if the threshold level of expression is approximately half of the steady-state level. Timing fuctuations can be reduced by increasing the transcription rate, while they are insensitive to the translation rate. In presence of self-regulatory strategies, we show that self-repression reduces <b>timing</b> noise for <b>threshold</b> levels that have to be reached quickly, while selfactivation is optimal at long times. These results lay a framework for understanding stochasticity of endogenous systems such as the cell cycle, {{as well as for the}} design of synthetic trigger circuits. Comment: 10 pages, 5 figure...|$|R
5000|$|In some cases, it is {{possible}} to indirectly detect flicker at rates well beyond 60 Hz in the case of high-speed motion, via the [...] "phantom array" [...] effect. Fast-moving flickering objects zooming across view (either by object motion, or by eye motion such as rolling eyes), can cause a dotted or multicolored blur instead of a continuous blur, as if they were multiple objects. [...] Stroboscopes are sometimes used to induce this effect intentionally. Some special effects, such as certain kinds of electronic glowsticks commonly seen at outdoor events, have the appearance of a solid color when motionless but produce a multicolored or dotted blur when waved about in motion. These are typically LED-based glow sticks. The variation of the duty cycle upon the LED(s), results in usage of less power while by the properties of flicker fusion having the direct effect of varying the brightness. When moved, if the frequency of duty cycle of the driven LED(s) is below the flicker fusion <b>threshold</b> <b>timing</b> differences between the on/off state of the LED(s) becomes evident, and the color(s) appear as evenly spaced points in the peripheral vision.|$|R
40|$|Background. Dendritic cells (DCs) {{are highly}} {{specialized}} antigen-presenting {{cells that are}} crucial for initiation of immune responses. During naturally acquired malaria, DC number and function is reduced. Methods. The <b>timing</b> of, parasitemia <b>threshold</b> of, and contribution of apoptosis to DC loss were prospectively evaluated in 10 men after experimental challenge with approximately 1800 Plasmodium falciparum-parasitized red blood cells (pRBCs) and after drug cure initiated at a parasite level of = 1000 parasites/mL. Results. The nadir levels of total, myeloid, and plasmacytoid DCs occurred 8 days after infection. DC loss was partially attributable to apoptosis, which was first detected on day 5 (median parasite level, 238 parasites/mL) and maximal at day 7. Remaining DCs exhibited a reduced ability to uptake particulate antigen. DC numbers recovered approximately 60 hours after antimalarial drug administration. There was no loss of DC number or function before or after drug cure in 5 men inoculated with < 180 pRBCs and treated on day 6, when their parasite level was approximately 200 parasites/mL. Conclusions. Plasmodium causes DC loss in vivo, which is at least partially explained by apoptosis in response to blood-stage parasites. In primary infection, loss of DC number and function occurs early during the prepatent period and before or with onset of clinical symptoms. These findings may explain in part the inadequate development of immunity to blood-stage malaria infection. No Full Tex...|$|R
40|$|Laser {{altimeters}} {{provide a}} precise and accurate method for mapping topography at fine {{horizontal and vertical}} scales. A laser altimeter provides range by measuring the roundtrip flight time of a short pulse of laser light from the laser altimeter instrument to the target surface. The range is then combined with laser beam pointing knowledge and absolute position knowledge to provide an absolute measurement of the surface topography. Newer generations of laser altimeters measure the range by recording the shape and time of the outgoing and received laser pulses. The shape of the return pulse can also provide unique information about the vertical structure of material such as vegetation within each laser footprint. Distortion of the return pulse {{is caused by the}} time-distributed reflections adding together and representing the vertical distribution of surfaces within the footprint. Larger footprints (10 - 100 m in diameter) can support numerous target surfaces and thus provide the potential for producing complex return pulses. Interpreting the return pulse from laser altimeters has evolved from simple <b>timing</b> between <b>thresholds,</b> range-walk corrections, constant-fraction discriminators, and multi-stop time interval units to actual recording of the time varying return pulse intensity - the return waveform. Interpreting the waveform {{can be as simple as}} digitally thresholding the return pulse, calculating a centroid, to fitting one or more gaussian pulse-shapes to the signal. What we present here is a new technique for using the raw recorded return pulse as a raw observation to detect centimeter-level vertical topographic change using large footprint airborne and spaceborne laser altimetry. We use the correlation of waveforms from coincident footprints as an indication of the similarity in structure of the waveforms from epoch to epoch, and assume that low correlation is an indicator of vertical structure or elevation change. Thus, using vertically and horizontally geolocated waveforms as raw observables (i. e., waveforms tied to a common reference ellipsoid), we assess whether epoch-to-epoch vertical ground motion results in a decrease in the correlation of coincident waveforms over time, and whether this can be used to quantify the magnitude of the deformation. Results of computer models and an example over an area of eroded beachfront will be presented...|$|R
40|$|A {{model of}} the {{effective}} processing of interaural timing disparities in the human auditory system is presented which provides modifications and extensions to existing models motivated by recent physiological findings. In particular, an established model of excitatory-inhibitory (EI) neuronal connectivity is complemented by a model {{that is based on}} a rate code derived from the interaural phase difference (IPD). The IPD model is shown to successfully simulate literature data on fine structure and envelope-based binaural detection and lateralization experiments. In order to investigate the processing of temporal fluctuations of interaural <b>timing</b> disparities, detection <b>thresholds</b> of broadband binaural-beat stimuli were measured in six normal-hearing listeners and were compared with model simulations. In a first experiment, the highest detectable beat frequency was found to be 96 Hz for a noise bandwidth of 550 Hz and 219 Hz for a bandwidth of 1100 Hz. Both models predicted lower thresholds, but performed increasingly better when the integration time constants of the binaural processors were reduced. In a second experiment, the signal-to-noise ratio at the detection threshold of binaural-beat stimuli mixed with interaurally uncorrelated noise was measured {{as a function of the}} beat frequency. The threshold increased about 1. 7 dB per octave which was simulated similarly by both models. The results indicate that the primary temporal resolution of the binaural system for detecting interaural timing disparities is much higher than the temporal resolution found in higher auditory processes as supposedly involved in, e. g., masking...|$|R
40|$|Recent {{observations}} {{suggest that}} the siphonophore Muggiaea atlantica is expanding its geographical distribution. The mechanisms behind this expansion remain unclear due to our limited knowledge of the species’ ecology. We modelled the functional relationship between the 2 main life-cycle stages of M. atlantica over a 5 yr period (2009 ? 2013) in the Western English Channel. Our aims were to determine the key features of the species’ population dynamics {{and the influence of}} local environmental conditions on its population development. Our results highlighted a strong coupling between the timing of specific environmental conditions and the development of the M. atlantica population, thereby explaining interannual differences in the phenology of its blooms. Population development commenced with the initiation of eudoxid production by the overwintering polygastric stages. This reproductive event was linked to the onset of a spring temperature threshold, suggesting a critical basal limit of 10 °C for eudoxid production. Interannual variability in the <b>timing</b> of this <b>threshold</b> modulated the degree of mismatch between the developing M. atlantica population and the availability of copepod prey. Unusually cold conditions in the spring of 2010 and 2013 limited the capacity for M. atlantica to initiate eudoxid production leading to poor trophic phasing and the production of single autumn cohorts. In contrast, warmer conditions during spring 2009, 2011, and 2012 facilitated earlier population development, optimal trophic phasing and the production of both summer and autumn cohorts. These findings represent an important addition {{to our understanding of the}} ecology of M. atlantica in the Northeast Atlanti...|$|R
40|$|The coarse {{resolution}} of climate models creates {{the need for}} future scenarios which are downscaled to an appropriate spatial scale. Considerable effort {{has been devoted to}} the development of downscaling methods but a number of important issues remain in the development of robust, usable climate scenarios. These include the incorporation of various sources of uncertainty into future scenarios and the production of scenarios at timescales relevant to planners. This paper describes a new procedure which addresses these issues by producing a multi-model ensemble of transient climate change scenarios. This method couples an existing stochastic rainfall model to a new, transient implementation of a weather generator, using changes projected by an ensemble of regional climate model (RCM) experiments. The methodology is demonstrated by the generation of transient scenarios of daily rainfall, temperature and potential evapotranspiration (PET) for the Geer catchment in Belgium for the period 2010 to 2085. The utility of these scenarios is demonstrated by assessing the changes projected by the simulated time series of several temperature indices. The Geer is projected to experience a decrease in the occurrence of frost days with a corresponding shortening of the frost season and lengthening of the growing season. By examining a large ensemble of transient scenarios the range of uncertainty in these projections is assessed, but further, it is suggested that additional information on the projected <b>timing</b> of specified <b>threshold</b> events or system responses may be provided which could aid planners in assessing the likely timescales of required interventions and adaptation responses. Peer reviewe...|$|R
40|$|The {{importance}} of understanding age when estimating {{the impact of}} influenza on hospitalizations and deaths has been well described, yet existing surveillance systems have not made adequate use of age-specific data. Monitoring influenza-related morbidity using electronic health data may provide timely and detailed insight into the age-specific course, impact and epidemiology of seasonal drift and reassortment epidemic viruses. The {{purpose of this study}} was to evaluate the use of emergency department (ED) chief complaint data for measuring influenza-attributable morbidity by age and by predominant circulating virus. We analyzed electronically reported ED fever and respiratory chief complaint and viral surveillance data in New York City (NYC) during the 2001 - 2002 through 2005 - 2006 influenza seasons, and inferred dominant circulating viruses from national surveillance reports. We estimated influenza-attributable impact as observed visits in excess of a model-predicted baseline during influenza periods, and epidemic <b>timing</b> by <b>threshold</b> and cross correlation. We found excess fever and respiratory ED visits occurred predominantly among school-aged children (8. 5 excess ED visits per 1, 000 children aged 5 - 17 y) with little or no impact on adults during the early- 2002 B/Victoria-lineage epidemic; increased fever and respiratory ED visits among children younger than 5 y during respiratory syncytial virus-predominant periods preceding epidemic influenza; and excess ED visits across all ages during the 2003 - 2004 (9. 2 excess visits per 1, 000 population) and 2004 - 2005 (5. 2 excess visits per 1, 000 population) A/H 3 N 2 Fujian-lineage epidemics, with the relative impact shifted within and between seasons from younger to older ages. During each influenza epidemic period in the study, ED visits were increased among school-aged children, and each epidemic peaked among school-aged children before other impacted age groups. Influenza-related morbidity in NYC was highly age- and strain-specific. The impact of reemerging B/Victoria-lineage influenza was focused primarily on school-aged children born since the virus was last widespread in the US, while epidemic A/Fujian-lineage influenza affected all age groups, consistent with a novel antigenic variant. The correspondence between predominant circulating viruses and excess ED visits, hospitalizations, and deaths shows that excess fever and respiratory ED visits provide a reliable surrogate measure of incident influenza-attributable morbidity. The highly age-specific impact of influenza by subtype and strain suggests that greater age detail be incorporated into ongoing surveillance. Influenza morbidity surveillance using electronic data currently available in many jurisdictions can provide timely and representative information about the age-specific epidemiology of circulating influenza viruses...|$|R
40|$|Background: More than 50 % of {{patients}} initially resuscitated from out-of- hospital cardiac arrest die in hospital. Objective: To investigate the prognostic value of serum protein S- 100 and neuron-specific enolase (NSE) concentrations for predicting (a) memory impairment at discharge; (b) in-hospital death, after resuscitation from out-of- hospital cardiac arrest. Methods: In a prospective study of 143 consecutive survivors of out-of-hospital cardiac arrest, serum samples were obtained within 12, 24 - 48 and 72 - 96 {{hours after the}} event. S- 100 and NSE concentrations were measured. Pre-discharge cognitive assessment {{of patients}} (n = 49) was obtained by the Rivermead Behavioural Memory Test (RBMT). The relationship between biochemical brain marker concentrations and RBMT scores, and between marker concentrations {{and the risk of}} in-hospital death was examined. Results: A moderate negative relationship was found between S- 100 concentration and memory test score, at all time points. The relationship between NSE and memory test scores was weaker. An S- 100 concentration greater than 0. 29 ?g/l at time B predicted moderate to severe memory impairment with absolute specificity (42. 8 % sensitivity). S- 100 remained an independent predictor of memory function after adjustment for clinical variables and cardiac arrest timing indices. NSE and S- 100 concentrations were greater in patients who died than in those who survived, at all time points. Both NSE and S- 100 remained predictors of in- hospital death after adjustment for clinical variables and cardiac arrest <b>timing</b> indices. The <b>threshold</b> concentrations yielding 100 % specificity for in-hospital death were S- 100 : 1. 20 ?g/l (sensitivity 44. 8 %); NSE 71. 0 ?g/l (sensitivity 14. 0 %). Conclusions: Estimation of serum S- 100 concentration after out-of-hospital cardiac arrest can be used to identify patients at risk of significant cognitive impairment at discharge. Serum S- 100 and NSE concentrations measured 24 - 48 hours after cardiac arrest provide useful additional information...|$|R
40|$|The {{initiation}} of metamorphosis causes {{the cessation of}} the larval growth period which determines the final body size of adult insects. Because larval growth is roughly exponential, differences in timing the {{initiation of}} metamorphosis can cause large differences body size. Although many of the processes involved in metamorphosis have been well characterized, {{little is known about}} how the timing of the initiation of metamorphosis is determined. Using different strains from Tribolium castaneum, Tribolium freemani, and Manduca sexta and varied nutritional conditions, I was able to document the existence of a threshold size, which determines when the larva becomes competent to metamorphose. Threshold size, however, does not dictate the exact timing of initiation. The exact timing for the initiation of metamorphosis is determined by a pulse of the molting hormone, ecdysone, but only after threshold size has been reached. Ecdysone pulses before the larva attains threshold size only cause the larva to molt to another larval instar. These results indicate the timing of metamorphosis initiation is controlled by two factors: (1) attainment of threshold size, at which the larva becomes competent to initiate metamorphosis and (2) the timing of an ecdysone pulse after attaining threshold size. I hypothesize the attainment of threshold size, and therefore competence to metamorphose, is mediated by the effect of changing juvenile hormone concentrations caused by the increase in size of the larva. While the larval body grows nearly exponentially, the corpora allata, which secretes juvenile hormone, grows very little if at all. The difference in relative growth causes juvenile hormone concentrations to gradually become diluted. When juvenile hormone concentrations fall below a threshold, changes in protein-protein binding occur that can cause changes in signaling networks and ultimately gene expression. These changes make the larva competent for metamorphosis. I have demonstrated that only threshold size is consistently correlated with body size; other growth parameters such as growth rate, duration of instars, or number of instars do not consistently correlate with variation in body size. Using the black mutant strain of M. sexta I have shown that lower juvenile hormone titers correlate with lower threshold sizes. My hypothesis is consistent with the large body of literature indicating the involvement of juvenile hormone. I also hypothesize that the diversity of metamorphosis types in holometabolous insects can be explained by heterochronic shifts in the <b>timing</b> of <b>threshold</b> size and other developmental events related to metamorphosis. The heterochronic shifts affect not only the morphology of organs, but can also affect the overall phenotypic response of the larva to changes in the environment. The different phenotypic responses among species may make the more or less suited for certain types of niches. Dissertatio...|$|R
40|$|Homogeneous charge {{compression}} ignition (HCCI) engines {{have the benefit}} of high efficiency with low emissions of nitrogen oxides and particulates. These benefits are due to the autoignition process of the dilute mixture of fuel and air during compression. However, because there is no direct ignition trigger, control of ignition is inherently more difficult than in standard internal combustion engines. This difficulty necessitates that a feedback controller be used to keep the engine at a desired (efficient) setpoint in the face of disturbances. Because of the nonlinear autoignition process, the sensitivity of ignition changes with the operating point. Thus, gain scheduling is required to cover the entire operating range of the engine. Controller tuning can therefore be a time intensive process. With the goal of reducing the time to tune the controller, we use extremum seeking (ES) to tune the parameters of various forms of combustion timing controllers. Additionally, in this dissertation we demonstrate how ES can be used for the determination of an optimal combustion timing setpoint of an experimental HCCI engine. The use of ES has the benefit of achieving both optimal setpoint (for maximizing the engine efficiency) and controller parameter tuning tasks quickly. The lack of a direct combustion trigger makes control of combustion timing during transients especially challenging. To aid in HCCI engine control during transients, we have developed a model {{that can be used to}} derive a controller for a thermally-managed, gasoline and natural gas fueled HCCI engine. The model uses an ignition threshold derived from detailed chemical kinetic simulations of HCCI engine combustion to provide an estimate for the combustion <b>timing.</b> The ignition <b>threshold</b> is a function of both temperature and pressure. An estimate of the residual gas fraction from the previous cycle can also be obtained, which is essential information due to the strong temperature sensitivity of HCCI ignition. This model allows the synthesis of nonlinear control laws, which can be utilized for control of an HCCI engine during transient...|$|R
40|$|The {{time period}} from 60 - 8 ka cal BP {{is marked by}} a series of abrupt climate events that became {{apparent}} from especially the Greenland Ice core records. These ice core records furthermore provided a precise and detailed chronology for the occurrence of these climate events. In the European terrestrial environment numerous studies have shown that these climate events have {{had an impact on the}} environment, ranging from geomorphological changes, changes in vegetation composition, faunal composition, and human behaviour and development. However, the recognition of the impact of the different events is strongly dependent on reliable age models for the environmental records. This requires a careful selection and analysis of existing data. Working Group 4 of the INTIMATE COST action aims to review the nature and quality of climate reconstructions of past environmental change across the full range of European environments (Mediterranean to sub-Arctic). For this we try to enlarge the European network of researchers, stimulate data sharing and eventually synthesise thematic environmental datasets. Important aspects are to identify the impacts of abrupt and extreme change and reveal the <b>timing,</b> duration and <b>thresholds</b> of climate impact. The first results for selected climate events show that clear gradients and thresholds exist, especially in ecotonal environmental settings. Resilience and inertia of the ecosystem and its components will determine whether thresholds are crossed or not and whether changes are so large that they could be considered as a regime shift (for example the change from tundra or steppe to forest). Environmental and particularly biotic responses will always lag the climate driver by very small to considerable amounts of time, depending on the biological traits and distributions of the organisms concerned. Therefore, we should not expect the apparent consequences of climate-driven changes to be synchronous across the European continent. We aim to identify sensitive areas for study from where we will obtain the most useful information about the impacts of climate changes...|$|R
40|$|The {{study of}} animal {{movement}} commonly requires the segmentation of continuous data streams into individual strides. The use of forceplates and foot-mounted accelerometers readily allows {{the detection of}} the foot-on and foot-off events that define a stride. However, when relying on optical methods such as motion capture, there is lack of validated robust, universally applicable stride event detection methods. To date, no method has been validated for movement on a circle, while algorithms are commonly specific to front/hind limbs or gait. In this study, we aimed to develop and validate kinematic stride segmentation methods applicable to movement on straight line and circle at walk and trot, which exclusively rely on a single, dorsal hoof marker. The advantage of such marker placement is the robustness to marker loss and occlusion. Eight horses walked and trotted on a straight line and in a circle over an array of multiple forceplates. Kinetic events were detected based on the vertical force profile and used as the reference values. Kinematic events were detected based on displacement, velocity or acceleration signals of the dorsal hoof marker depending on the algorithm using (i) defined thresholds associated with derived movement signals and (ii) specific events in the derived movement signals. Method comparison was performed by calculating limits of agreement, accuracy, between-horse precision and within-horse precision based on differences between kinetic and kinematic event. In addition, we examined the effect of force thresholds ranging from 50 to 150 N on the timings of kinetic events. The two approaches resulted in very good and comparable performance: of the 3, 074 processed footfall events, 95 % of individual foot on and foot off events differed {{by no more than}} 26 ms from the kinetic event, with average accuracy between − 11 and 10 ms and average within- and between horse precision ≤ 8 ms. While the event-based method may be less likely to suffer from scaling effects, on soft ground the threshold-based method may prove more valuable. While we found that use of velocity thresholds for foot on detection results in biased event estimates for the foot {{on the inside of the}} circle at trot, adjusting thresholds for this condition negated the effect. For the final four algorithms, we found no noteworthy bias between conditions or between front- and hind-foot <b>timings.</b> Different force <b>thresholds</b> in the range of 50 to 150 N had the greatest systematic effect on foot-off estimates in the hind limbs (up to on average 16 ms per condition), being greater than the effect on foot-on estimates or foot-off estimates in the forelimbs (up to on average ± 7 ms per condition) ...|$|R
