72|10000|Public
50|$|In {{ecological}} monitoring, <b>the</b> <b>monitoring</b> <b>strategy</b> {{and effort}} {{is directed at}} the plants and animals in the environment under review and is specific to each individual study.|$|E
5000|$|The Steering Group {{published}} an interim report in May 1993 {{and a final}} report in 1994, which contains details of <b>the</b> <b>monitoring</b> <b>strategy</b> and methods. It found that: ...|$|E
50|$|All {{physical}} principles {{which are}} capable {{to provide information}} about the position of an object are suitable to serve as the starting basis for a sensor function. The ambient conditions prevailing during arc welding and also the requirements which are made by fully mechanised equipments have, however, many restrictions as a consequence. Figure 1 depicts the system overview. <b>The</b> <b>monitoring</b> <b>strategy</b> of the sensor (process or geometry) has been chosen as the superordinate criterion, the further subdivision is orientated on the measuring principle.A further distinctive feature of sensor systems is their design. Leading sensors are, thus, marked by the fact that measuring point and joining point are not located in the same position. Here, the measuring and joining process are mainly running in sequence. For making position-relevant statements about the welding process, those systems require calibration of the relative position. If process-oriented sensors are used, the measuring point and the joining point are identical.What the measuring principles all have in common is the fact that through the evaluation of the sensor signal, geometrical information about the joint and its relative position to the measuring head is provided. The individual active principles allow different processing speed for acquiring the information.|$|E
40|$|This {{study is}} a working paper on <b>monitoring</b> <b>strategies</b> used in <b>the</b> U. K., the FRG and the USA to assess {{exposure}} to airborne chemical substances. After {{a brief description of}} the basic philosophy on <b>monitoring</b> <b>strategies,</b> <b>the</b> requirements formonitoring from the different legal systems in the three countries are presented. <b>The</b> <b>monitoring</b> <b>strategies</b> are divided into small separate entities to facilitate comparison. Successively the initial assessment, surveys which are nonroutinemonitoring, <b>the</b> routine <b>monitoring</b> and their different elements are presented. Special emphasis is laid on how the different elements that can be discerned are covered in practice. A description of reports of <b>monitoring</b> data concludes <b>the</b> presentationof <b>the</b> <b>monitoring</b> <b>strategies.</b> In a final chapter a discussion is given on the material presented...|$|R
40|$|The {{objective}} {{of this paper is}} to discuss and introduce an efficient and reliable power quality (PQ) <b>monitoring</b> <b>strategy</b> that uses <b>the</b> advances in signal processing and pattern recognition to improve power quality <b>monitoring</b> practices. <b>The</b> proposed <b>monitoring</b> <b>strategy</b> is capable of detecting, tracking, and classifying any power quality violation by the use of on-line measurements. Methodologies which can be utilized for identifying the source of PQ problems based on the recognized phenomena will be discussed. Various simulation results are introduced to validate the use of <b>the</b> proposed <b>monitoring</b> <b>strategy.</b> 1...|$|R
50|$|Michael Porter {{is one of}} {{the founders}} of <b>The</b> <b>Monitor</b> Group <b>strategy</b> {{consulting}} firm. It was sold to Deloitte Consulting in 2013 through a structured bankruptcy proceeding.|$|R
5000|$|On May 17, 1998, a 55-year-old patient named Audrey LaRue Jones died {{of acute}} liver failure after taking troglitazone. Importantly, {{she had been}} {{monitored}} closely by physicians at the National Institutes of Health as {{a participant in the}} National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) diabetes prevention study. This called into question the efficacy of <b>the</b> <b>monitoring</b> <b>strategy.</b> The N.I.H. responded on June 4 by dropping troglitazone from the study. Dr. David J. Graham, an F.D.A. epidemiologist charged with evaluating the drug, warned on March 26, 1999 of the dangers of using it and concluded that patient monitoring was not effective in protecting against liver failure. He estimated that the drug could be linked to over 430 liver failures and that patients incurred 1,200 times greater risk of liver failure when taking Rezulin. Dr. Janet B. McGill, an endocrinologist who had assisted in the Warner-Lambert's early clinical testing of Rezulin, wrote in a March 1, 2000 letter to Sen. Edward M. Kennedy (D-Mass.): [...] "I believe that the company [...] [...] [...] deliberately omitted reports of liver toxicity and misrepresented serious adverse events experienced by patients in their clinical studies." ...|$|E
30|$|If {{an event}} occurs which <b>the</b> <b>monitoring</b> <b>strategy</b> fails to detect what action {{is taken to}} improve the strategy.|$|E
3000|$|Second {{in order}} to {{identify}} the actors involved, it is necessary to identify the values, metrics, logs and other data that are collected as part of <b>the</b> <b>monitoring</b> <b>strategy.</b> This typically includes: [...]...|$|E
30|$|This is by {{no means}} and {{extensive}} list but it represents many of the common actors involve in <b>the</b> <b>monitoring</b> process. Failure to consider the relevant actors can lead to ineffective <b>monitoring</b> <b>strategy</b> and can often result in “Shadow IT” use cases emerging whereby human actors circumvent <b>the</b> prescribed <b>monitoring</b> <b>strategy</b> in order to obtain the information necessary to their roles.|$|R
5000|$|Wealth-Lab Version 6.3Prepared for Wealth-Lab Pro {{streaming}} provider integration for <b>the</b> <b>Strategy</b> <b>Monitor</b> tool ...|$|R
40|$|Treating chronic {{conditions}} {{is a fairly}} complex task, which requires well-timed appointments to control one's disease progression. In my dissertation I would like to optimize <b>the</b> <b>monitoring</b> <b>strategies</b> and better predict the demand-for-care of patients with chronic kidney disease (CKD). To do that I design a chronic disease monitoring framework which consists of forecasting, survival analysis and Markov Decision Process (MDP) models. First, I propose a forecasting model which quantifies the impact of CKD-related doctor's appointments on patient's disease progression. The model accounts for patient's comorbidities, vital signs, and important laboratory values. Second, I propose a survival analysis model, which estimates the expected life days of a patient given his or her current health status. Finally, I use the information gained from the first two models to parametrize and solve the MDP, which can suggest <b>monitoring</b> <b>strategies</b> and predict medium-term demand for CKD-patient-care in a clinic. In addition to <b>the</b> chronic disease <b>monitoring</b> framework, I examine CKD patient characteristics associated with a higher resource utilization...|$|R
30|$|Even a {{monitoring}} system which is highly autonomic in nature still relies upon {{some degree of}} human interaction. Failure of human actors to take appropriate action is equally, if not more, problematic than software agents failing. It is therefore essential for human and software actors to abide by <b>the</b> <b>monitoring</b> <b>strategy</b> to ensure effective monitoring.|$|E
40|$|In {{this paper}} we {{consider}} the implications of imperfect mon-itoring in a stochastic environment for both the agents and the normative organisation in a normative MAS. We intro-duce a notion of information asymmetry to characterise the agents ’ knowledge of <b>the</b> <b>monitoring</b> <b>strategy,</b> and show that there are potential benefits of information asymmetry for the normative organisation in reducing its cost of enforcement...|$|E
30|$|Few {{monitoring}} {{strategies are}} perfect {{and the worst}} time to discover imperfections in a monitoring strategy is in production when a service is under high demand. Chaos monkey is a term popularised by Netflix [98], which defines a user or piece of software which introduces failure or error during a pre approved {{period of time in}} order to test the effectiveness of a monitoring strategy and the response of the operations team. In the case of Netflix the chaos monkey terminates a random EC 2 instance in order to simulate a common failure mode. This failure should be handled automatically by <b>the</b> <b>monitoring</b> <b>strategy</b> and accounted for without the need for human intervention. In the case that an unexpected outcome occurs <b>the</b> <b>monitoring</b> <b>strategy</b> is adapted to cover what was previously unexpected. The success of this testing strategy has led to Netflix open sourcing their Simian Army toolkit, a widely adopted tool which not only includes the Chaos Monkey but also several other programs which create latency, security, performance, configuration and other issues in order to test the effectiveness of a monitoring strategy.|$|E
40|$|This study {{compared}} {{the effects of}} two comprehension <b>monitoring</b> <b>strategies</b> on <b>the</b> reading comprehension awareness in expository text read by third and fifth grade students. A secondary purpose {{was to determine if}} <b>the</b> comprehension <b>monitoring</b> <b>strategies</b> influenced reading comprehension achievement. The effects of gender were also studied. The participants were 51 third grade students and 57 fifth grade students from six intact classrooms in four elementary schools in a midwestern school district. One third and one fifth grade classroom was randomly assigned to each of the two experimental groups and the one control group. During a 4 -week intervention, one experimental group was taught <b>the</b> comprehension <b>monitoring</b> <b>strategy</b> K-W-L; <b>the</b> other <b>the</b> comprehension <b>monitoring</b> <b>strategy</b> Predicting/Evaluating. <b>The</b> control group read the same expository text as the experimental groups during sustained silent reading for the 4 -week period with no instruction in a comprehension <b>monitoring</b> <b>strategy.</b> A metacognitive instrument and a standardized norm-referenced test were used as pretest (covariate) and posttest (dependent variable) measures. Two separate analyses of covariance were used to address the four research questions. The following results were suggested. 1. Third grade males with no strategy instruction outperformed third grade males with strategy instruction in reading comprehension awareness. 2. Fifth graders outperformed third graders in reading comprehension awareness regardless of gender and regardless of strategy taught for comprehension monitoring. 3. Females outperformed males in reading comprehension awareness regardless of grade level and regardless of strategy taught for comprehension monitoring. 4. Third and fifth graders achieved equally well in reading achievement whether or not they received instruction and practice using a comprehension <b>monitoring</b> <b>strategy.</b> 5. Males and females achieved equally well in reading achievement whether or not they received instruction and practice using a comprehension <b>monitoring</b> <b>strategy.</b> 6. Third graders outperformed fifth graders in reading achievement regardless of gender and regardless of strategy taught for comprehension monitoring. Department of Elementary EducationThesis (Ph. D. ...|$|R
40|$|We {{present a}} <b>monitoring</b> <b>strategy</b> based on using {{two pieces of}} witness glass, which are brought to the {{measuring}} position in a specially chosen sequence, each witness glass is monitored by one single wavelength. To reduce the thickness error, some thick layers are divided into two layers and monitored by different witness glasses. Theoretical analysis and experimental results have demonstrated that <b>the</b> proposed <b>monitoring</b> <b>strategy</b> can achieve spectral performance close to the theoretical design. (C) 2013 Elsevier Ltd. All rights reserved...|$|R
40|$|Terrebonne Bay Shore Protection Project (TE- 45) was {{modified}} due to budgetary and environmental constraints. Particularly, the Concrete A-Frame (foreshore), Reefball (foreshore), and Submar Mat (onshore) treatments were {{eliminated from the}} project design. These project features were removed {{as a result of}} increased costs incurred after the passage of Hurricanes Katrina and Rita. Therefore, the project will be constructed using only the Reefblock (foreshore), A-Jack (onshore), and Gabion Mat (onshore) structures. In addition, reach B was relocated to a position 91. 4 meters (300 ft) north of the reach A treatments because of high land loss rates in the previous location. <b>The</b> <b>monitoring</b> plan was altered to include these changes in the project design. Specifically, the number of continuous recorders were reduced from 3 to 2 due to the close proximity of reaches A and B, and the frequency of post-construction surveys were also condensed from 3 to 2 for economic reasons. These revisions to <b>the</b> <b>monitoring</b> plan have been incorporated into <b>the</b> <b>monitoring</b> <b>strategies</b> section...|$|R
40|$|The First G-APD Cherenkov Telescope (FACT), {{located on}} the Canary Island of La Palma, has been taking data since October 2011. FACT has been {{optimized}} for longterm monitoring of bright TeV blazars, to study their variability time scales and flare probability. G-APD photo-sensors allow for observations even under strong moonlight conditions, and the telescope can be operated remotely. <b>The</b> <b>monitoring</b> <b>strategy</b> of FACT is discussed and preliminary results of the flare of Mrk 501 in June 2012 are shown...|$|E
40|$|Invasive {{species are}} an {{increasing}} problem, costing several {{billion dollars to}} the global economy. Monitoring methods are needed to provide scientists the necessary information to control populations of invasive species. Adaptive monitoring means that, for each additional survey, the monitoring design is updated {{based on the information}} obtained during the previous surveys. In this thesis we introduce a new general framework for adaptive monitoring. This method focuses on increasing the detection rate of invasive species over consecutive surveys. Compared with the existing monitoring methods, the proposed algorithm aims to improve adaptive monitoring by the following three points: (1) The use of a spatially balanced sampling design to select a sample in each survey, (2) by using both spatial and ecological information to update <b>the</b> <b>monitoring</b> <b>strategy,</b> and (3) by incorporating an eradication strategy to an adaptive monitoring design. In Chapter 1, we emphasise the need for the development of adaptive monitoring methods for invasive species. In Chapter 2, we outline the algorithm of our proposed method for adaptive monitoring and discuss the use of spatially balanced sampling designs. In Chapter 3, several sampling designs are introduced and their use for (adaptive) monitoring is evaluated. We give special attention to a new spatially balanced sampling design, named Balanced Acceptance Sampling, and compare it with a selection of existing (spatially balanced) sampling designs such as Generalized Random Tessellation Stratified sampling. In Chapter 4, we illustrate how ecological information can be used to update <b>the</b> <b>monitoring</b> <b>strategy,</b> which is demonstrated using a case study on the Asian tiger mosquito. In addition, several practical issues with probability sampling are discussed. In Chapter 5, the Nearest Unit Tessellation methods are introduced. These methods can model the observed spatial information of the species to update <b>the</b> <b>monitoring</b> <b>strategy.</b> Finally, we demonstrate how to combine ecological and spatial information to adjust a monitoring strategy. Chapter 6 also explores the use of a method to incorporate an eradication strategy to an adaptive monitoring strategy, using the Great White Butterfly data...|$|E
30|$|This {{trend is}} {{advantageous}} as it allows operations staff {{to choose from}} a {{diverse range of tools}} and devise an implementing which fits <b>the</b> <b>monitoring</b> <b>strategy</b> as closely as possible. This diversification of monitoring tools also represents many potential issues, namely that smaller and less popular tools may lose developers and support if it recedes from vogue. Furthermore a diverse range of tools requires a significant effort to orchestrate the communication between these tools. Unless there is a shared language, protocol or format the orchestration of these tools can become a troublesome.|$|E
40|$|Abstract. In this work, {{time series}} {{analysis}} and control charts are used to devise a real-time <b>monitoring</b> <b>strategy</b> in a BTA deep-hole-drilling process. BTA deep-hole-drilling is used to produce holes with high length to diameter ratio, good surface finish and straightness. The process is subject to dynamic disturbances usually classified as either chatter vibration or spiralling. In this work, we will focus on chatter which is dominated by single frequencies. The results showed that <b>the</b> proposed <b>monitoring</b> <b>strategy</b> can detect chatter and that some alarm signals are related to changing physical conditions of the process...|$|R
40|$|We {{study the}} problem of {{scheduling}} applications composed {{of a large number}} of tasks on heterogeneous clusters. Tasks are identical, independent from each other, and can hence be computed in any order. The goal is to execute all the tasks as quickly as possible. We use the Master-Worker paradigm, where tasks are maintained by the master which will hand out batches of a variable amount of tasks to requesting workers. We introduce a new scheduling <b>strategy,</b> <b>the</b> <b>Monitor</b> <b>strategy,</b> and compare it to other strategies suggested in the literature. An image filtering application, known as matched filtering, has been used to compare the different strategies. Our implementation involves datastaging techniques in order to circumvent the possible bottleneck incurred by the master, and multi-threading to prevent possible processor idleness. </p...|$|R
40|$|The use of COSMO-SkyMed {{constellation}} {{has been}} tested for post-fire monitoring activities. A typical Mediterranean ecosystem, seriously damaged by a wildfire, has been selected as study area. The multitemporal and multipolarization capabilities of COSMO-SkyMed have been exploited for automatic burnt area detection and monitoring of vegetation regrowth. Different imaging configurations have been tested to define <b>the</b> proper <b>monitoring</b> <b>strategy</b> in Mediterranean areas. Results showed X-band suitability for Mediterranean maquis post-fire monitoring...|$|R
40|$|Abstract – In {{precision}} machining processes, major {{problems can be}} related to the condition of the cutting tool. Online tool condition monitoring is hence of great industrial interest. To empower the machining system with adaptivity and intelligence required, an embedded tool condition monitoring system (eTCM) has been developed for online detection of machining process abnormities such as tool breaking, chatter, etc. It employs multiple sensors including accelerometer, acoustic emission (AE) sensor and dynamometer to monitor an end milling process. <b>The</b> <b>monitoring</b> <b>strategy,</b> hardware architecture, monitoring algorithms and results are introduced and discussed in this paper...|$|E
40|$|We {{investigate}} if and how <b>the</b> <b>monitoring</b> <b>strategy</b> for the meridional overturning circulation (MOC) implemented at 26 °N in the Atlantic {{can also}} be applied at a latitude in the South Atlantic. The RAPID 26 °N strategy to monitor the MOC is based on continuous measurements of zonal density differences across a zonal transect, continuous measurements of the western boundary current, and additional estimates of the zonal wind stress from satellite observations. Here, we simulate a monitoring array akin to the RAPID array at 26 °N in the global coupled climate ECHAM 5 /MPI-OM, forced with the IPCC scenario A 1 B. We find that <b>the</b> <b>monitoring</b> <b>strategy</b> can provide reliable estimates of the MOC in the South Atlantic, but the latitude needs to be carefully chosen to ensure adequate coverage of the variability arriving from both {{the north and the}} south. The limitations in the North Atlantic apply in the South Atlantic, however, we find that direct boundary current observations and bottom velocity measurements are of lesser importance for the time-mean value and the variability than in the North Atlantic. However, western boundary observations and bottom velocity measurements are crucial in capturing the vertical structure of the MOC correctly. We suggest that basin-wide MOC monitoring based on the RAPID strategy at 26 °N be conducted only where boundary currents do not hit steep topography, and where bottom velocities are small...|$|E
40|$|Coastal geohazards, such as landslides, mudflows, and rockfalls, {{represent}} a major driver for coastal change {{in many regions}} of the world, and often impinge on aspects of the human and natural environment. In such cases, there is a pressing need {{for the development of}} more effective monitoring strategies, particularly given the uncertainties associated with the impact of future climate change. Traditional survey approaches tend to suffer from limited spatial resolution, while contemporary techniques are generally unsuitable in isolation, due to the often complex coastal topography. To address these issues, this thesis presents the development and application of a strategy for integrated remote monitoring of coastal geohazards. <b>The</b> <b>monitoring</b> <b>strategy</b> is underpinned by a robust least squares surface matching technique, which has been developed to facilitate change detection through the reliable reconciliation of multi-temporal, multi-sensor datasets in dynamic environments. Specifically, this research has concentrated on integrating the developing techniques of airborne and terrestrial laser-scanning. In addition, archival aerial photography has been incorporated in order to provide a historical context for analysis of geohazard development. Robust surface matching provides a mechanism for reliable registration of DEM surfaces contaminated by regions of difference, which may arise through geohazard activity or vegetation change. The development of this algorithm has been presented, and its potential demonstrated through testing with artificial datasets. <b>The</b> <b>monitoring</b> <b>strategy</b> was applied to the soft-cliff test site of Filey Bay, North Yorkshire. This highlighted the viability of the robust matching algorithm, demonstrating the effectiveness of this technique for absolute orientation of DEMs derived from archival aerial photography. Furthermore, the complementary qualities of airborne and terrestrial laser scanning have been confirmed, particularly in relation to their value for multi-scale terrain monitoring. Issues of transferability were explored through application of <b>the</b> <b>monitoring</b> <b>strategy</b> to the hard rock environment of Whitby East Cliff. Investigations in this challenging environment confirmed the potential of the robust matching algorithm, and highlighted a number of valuable issues in relation to the monitoring techniques. Investigations at both test sites enabled in-depth assessment and quantification of geohazard activity over extended periods of time. EThOS - Electronic Theses Online ServiceEnglish Heritage : British Geological SurveyGBUnited Kingdo...|$|E
40|$|When {{operating}} in volatile environments, service-based systems (SBSs) that are dynamically composed from component services must be monitored {{in order to}} guarantee timely and successful delivery of outcomes in response to user requests. However, monitoring consumes resources and very often impacts {{on the quality of}} <b>the</b> SBSs being <b>monitored.</b> Such resource and system costs need to be considered in formulating <b>monitoring</b> <b>strategies</b> for SBSs. <b>The</b> critical path of a composite SBS, i. e., the execution path in the service composition with the maximum execution time, is of particular importance in cost-effective monitoring as it determines the response time of the entire SBS. In volatile operating environments, the critical path of an SBS is probabilistic, as every execution path can be critical with a certain probability, i. e., its criticality. As such, it is important to estimate the criticalities of different execution paths when deciding which parts of <b>the</b> SBS to <b>monitor.</b> Furthermore, cost-effective monitoring also requires management of the trade-off between the benefit and cost of monitoring. In this paper, we propose CriMon, a novel approach to formulating and evaluating <b>monitoring</b> <b>strategies</b> for SBSs. CriMon first calculates the criticalities of the execution paths and the component services of an SBS and then, based on those criticalities, generates <b>the</b> optimal <b>monitoring</b> <b>strategy</b> considering both <b>the</b> benefit and cost of monitoring. CriMon has two <b>monitoring</b> <b>strategy</b> formulation methods, namely local optimisation and global optimisation. In-lab experimental results demonstrate that the response time of an SBS can be managed cost-effectively through CriMon-based <b>monitoring.</b> <b>The</b> effectiveness and efficiency of <b>the</b> two <b>monitoring</b> <b>strategy</b> formulation methods are also evaluated and compared...|$|R
30|$|This {{is taken}} up to show how {{substance}} can be given to <b>the</b> <b>monitoring</b> task. <b>The</b> <b>strategy</b> of engagement with broader actors becomes serious when they are included and a space for interaction is created.|$|R
40|$|Time series {{analysis}} and multivariate control charts {{are used to}} devise a real-time <b>monitoring</b> <b>strategy</b> in a drilling process. The process is used to produce holes with high length-to-diameter ratio, good surface finish and straightness. It is subject to dynamic disturbances that are classified as either chatter vibration or spiralling. A new nonparametric control chart for multivariate processes is proposed. It is used to detect chatter vibration which is dominated by single frequencies. The results showed that <b>the</b> proposed <b>monitoring</b> <b>strategy</b> can detect chatter vibration and that some alarm signals are related to changing physical conditions of the process. ...|$|R
40|$|The final {{performances}} of manufactured thin film filters usually depend on to <b>the</b> <b>monitoring</b> <b>strategy.</b> Some optical monitoring sys-tems provide transmittance measurements while others measure the reflectance. With our system, {{we are able}} to simultaneously measure both transmittance and reflectance over an extended spectral range [400 nm; 1000 nm]. This reflectance channel is necessary for direct monitoring of some kinds of filters like light absorbers. Indeed, in this case, transmittance is cancelled after the first metallic layer depo-sition. The optical system is also very useful for in situ characterization especially for metallic absorbing materials. 2008 Elsevier B. V. All rights reserved. 1...|$|E
40|$|The Mediterranean is an {{important}} eco-region, however, it suffers {{from the lack of}} common procedures for the management and monitoring of its protected areas sustainability. The INNOVA project addresses this issue by developing a procedure namely PASEMP as well as tools which can assist Protected Areas Managers and responsible authorities to develop and implement a monitoring strategy for their areas. This handbook is proposed as a flexible tool, or a reference text which should be used in combination with the PASEMP guidelines to identify indicators, but also contains guidance on how to implement and report <b>the</b> <b>monitoring</b> <b>strategy</b> results...|$|E
40|$|This paper {{presents}} {{a method for}} the monitoring of the safety of rails against thermal buckling caused by temperature changes. <b>The</b> <b>monitoring</b> <b>strategy</b> {{is based on the}} measurement of couples of strains and temperatures by optic fibers. Measured strains and temperatures are observed and examined in order to elaborate an interpretative model to estimate neutral temperature and force eccentricity. The interpretative model is applied to real data showing the evolution of neutral temperature and rail eccentricity in a timespan of a couple of months. The values determined, at least as regards their variation, may provide an indication of the need for intervention when high values of eccentricity and excessive lowering of neutral temperature are observed...|$|E
30|$|One of {{the goals}} of the WFD was to {{harmonise}} <b>the</b> <b>monitoring</b> <b>strategies</b> all over Europe, which differed among countries or even regions with respect to for example parameters recorded or metrics applied for the same endpoint. The WFD distinguishes three different types, in a tiered and cost-effective basic design: surveillance, operational and investigative <b>monitoring.</b> <b>The</b> surveillance <b>monitoring</b> shall be carried out at a sufficient number of sites to provide an assessment of the overall surface water status and aims to <b>monitor</b> <b>the</b> actual status and to assess long-term changes resulting from widespread anthropogenic activity. <b>The</b> operational <b>monitoring</b> should establish <b>the</b> status of those water bodies identified as being at risk of failing to meet the environmental objectives, and to assess any changes in the status of such water bodies that result from the programmes of measures. Investigative monitoring again shall be carried out where the causes of a water body failing to achieve the environmental objectives are unknown. MODELKEY developed innovative environmental assessment tools to support all three monitoring programmes to unravel unknown chemicals that might be responsible for the observed degradation.|$|R
40|$|Abstract—When {{operating}} in volatile environments, service-based systems (SBSs) that are dynamically composed from component services must be monitored {{in order to}} guarantee timely and successful delivery of outcomes in response to user requests. However, monitoring consumes resources and very often impacts {{on the quality of}} <b>the</b> SBSs being <b>monitored.</b> Such resource and system costs need to be considered in formulating <b>monitoring</b> <b>strategies</b> for SBSs. <b>The</b> critical path of a composite SBS, i. e., the execution path in the service composition with the maximum execution time, is of particular importance in cost-effective monitoring as it determines the response time of the entire SBS. In volatile operating environments, the critical path of an SBS is probabilistic, as every execution path can be critical with a certain probability, i. e., its criticality. As such, it is important to estimate the criticalities of different execution paths when deciding which parts of <b>the</b> SBS to <b>monitor.</b> Furthermore, cost-effective monitoring also requires management of the trade-off between the benefit and cost of monitoring. In this paper, we propose CriMon, a novel approach to formulating and evaluating <b>monitoring</b> <b>strategies</b> for SBSs. CriMon first calculates the criticalities of the execution paths and the component services of an SBS and then, based on those criticalities, generates <b>the</b> optimal <b>monitoring</b> <b>strategy</b> considering both <b>the</b> benefit and cost of monitoring. CriMon has two <b>monitoring</b> <b>strategy</b> formulation methods, namely local optimisation and global optimisation. In-lab experimental results demonstrate that the response time of an SBS can be managed cost-effectively through CriMon-based <b>monitoring.</b> <b>The</b> effectiveness and efficiency of <b>the</b> two <b>monitoring</b> <b>strategy</b> formulation methods are also evaluated and compared. Index Terms—Service-based system, web service, QoS, response time, monitoring, criticality, cost of monitoring, value of monitoring Ç...|$|R
40|$|The {{focus of}} the Hubble Space Telescope (HST) has been <b>monitored</b> {{throughout}} <b>the</b> life of the observatory primarily by phase retrieval techniques. This method uses model fits to nearly in-focus Point Spread Functions (PSFs) to solve for coefficients of the Zernike polynomials describing focus, {{and in some cases}} coma and astigmatism. Here, we discuss what these data from <b>the</b> ongoing <b>monitoring</b> <b>strategies</b> and special observations tell us about modes and timescales observed in HST optical variations...|$|R
