0|109|Public
40|$|A good {{classifier}} can correctly predict {{new data}} {{for which the}} class label is unknown, so {{it is important to}} construct a high accuracy classifier. Hence, classification techniques are much useful in ubiquitous computing. Associative classification achieves higher classification accuracy than some <b>traditional</b> <b>rule-based</b> classification approaches. However, the approach also has two major deficiencies. First, it generates {{a very large number of}} association classification rules, especially when the minimum support is set to be low. It is difficult to select a high quality rule set for classification. Second, the accuracy of associative classification depends on the setting of the minimum support and the minimum confidence. In comparison with associative classification, some improved <b>traditional</b> <b>rule-based</b> classification approaches often produce a classification rule set that plays an important role in prediction. Thus, some improved <b>traditional</b> <b>rule-based</b> classification approaches not only achieve better efficiency than associative classification but also get higher accuracy. In this paper, we put forward a new classification approach called CMR (classification based on multiple classification rules). CMR combines the advantages of both associative classification and rule-based classification. Our experimental results show that CMR gets higher accuracy than some <b>traditional</b> <b>rule-based</b> classification methods...|$|R
50|$|Clever is a physics-based {{parasitic}} extractor. It uses 3D field solvers {{to convert}} the mask data of a cell and relevant process information into a SPICE netlist. This process removes inaccuracies resulting from <b>traditional,</b> <b>rule-based</b> parasitic extractors.|$|R
40|$|Recent {{studies in}} data mining have {{proposed}} a new classification approach, called associative classification, which, according to several reports, such as [7, 6], achieves higher classification accuracy than traditional classification approaches such as C 4. 5. However, the approach also suffers from two major deficiencies: (1) it generates {{a very large number}} of association rules, which leads to high processing overhead; and (2) its confidence-based rule evaluation measure may lead to overfitting. In comparison with associative classification, <b>traditional</b> <b>rule-based</b> classifiers, such as C 4. 5, FOIL and RIPPER, are substantially faster but their accuracy, in most cases, may not be as high. In this paper, we propose a new classification approach, CPAR (Classification based on Predictive Association Rules), which combines the advantages of both associative classification and <b>traditional</b> <b>rule-based</b> classification. Instead of generating a large number of candidate rules as in associative classification, CPAR adopts a greedy algorithm to generate rules directly from training data. Moreover, CPAR generates and tests more rules than <b>traditional</b> <b>rule-based</b> classifiers to avoid missing important rules. To avoid overfitting, CPAR uses expected accuracy to evaluate each rule and uses the best k rules in prediction. ...|$|R
50|$|Reason-based system: Unlike the <b>traditional,</b> <b>rule-based</b> system, Behavioral Analytics is the reason-based {{system that}} enables a machine {{to learn what}} is abnormal, without human pre-programing. By {{decreasing}} the number of alerts, it helps security officers to perceive more threats in real time.|$|R
40|$|This paper {{develops}} {{and compares}} two fuzzy logic based and a <b>traditional</b> <b>rule-based</b> pattern recognition system, which perform target recognition {{with data from}} a typical range and doppler resolving radar. The parameters used by the pattern recognition systems are target altitude, velocity, range from nearest base, and radar cross section. The pattern recognition systems identify four classes of aircraft: fighter/interceptors, large bombers, rotary craft, and vertical {{take off and landing}} (VTOL) combat aircraft. The first fuzzy based pattern recognition method classifies targets by selecting the aircraft with the maximum summed amount of membership, giving a classification accuracy of 94 % (average). The second approach classifies targets by selecting the aircraft through a max-min fuzzy decision system. This results in a 99 % average accurate classification. The <b>traditional</b> <b>rule-based</b> method implements an expert system and correctly classifies 75 % (average) of the targets...|$|R
40|$|This paper reconsiders French liaison and elision {{within the}} new {{framework}} of Optimality Theory (Prince & Smolensky 1993; McCarthy & Prince 1993 a,b). The {{goal of this}} reexamination {{is to show that}} OT's constraintbased approach can bring together under the same explanatory umbrella three important sets of liaison/elision phenomena that are handled less generally within <b>traditional</b> <b>rule-based</b> treatments...|$|R
50|$|While {{rule-based}} {{machine learning}} is conceptually {{a type of}} rule-based system, it is distinct from <b>traditional</b> <b>rule-based</b> systems, which are often hand-crafted, and other rule-based decision makers. This is because rule-based machine learning applies some form of learning algorithm to automatically identify useful rules, rather than a human needing to apply prior domain knowledge to manually construct rules and curate a rule set.|$|R
40|$|This paper {{describes}} {{results of}} the investigation of Polish segmental duration for the purpose of speech synthesis. The experiment is a continuation of the previous work of the same authors [1] aiming at improving the outcome of the duration prediction mechanism to enhance the overall quality of synthesized speech. Duration prediction models for speech synthesis range from the more <b>traditional,</b> <b>rule-based</b> techniques to trainable, corpus-based techniques. Nowadays, it is often the case that the two approaches overlap and careful linguistic featur...|$|R
40|$|Rule-based {{classification}} {{systems have}} been widely used in real world applications because of the easy interpretability of rules. Many <b>traditional</b> <b>rule-based</b> classifiers prefer small rule sets to large rule sets, but small classifiers are sensitive to the missing values in unseen test data. In this paper, we present a larger classifier that is less sensitive to the missing values in unseen test data. We experimentally show that it is more accurate than some benchmark classifies when unseen test data have missing values. ...|$|R
50|$|Google Translate {{does not}} apply {{grammatical}} rules, since its algorithms are based on statistical analysis rather than <b>traditional</b> <b>rule-based</b> analysis. The system's original creator, Franz Josef Och, has criticized the effectiveness of rule-based algorithms in favor of statistical approaches. It {{is based on a}} method called statistical machine translation, and more specifically, on research by Och who won the DARPA contest for speed machine translation in 2003. Och was the head of Google's machine translation group until leaving to join Human Longevity, Inc. in July 2014.|$|R
40|$|International audienceData-driven {{learning}} (DDL) {{relies on}} learners {{being able to}} perceive patterns in raw data, typically {{in the form of}} concordances. As with all areas of DDL, empirical support for this is scarce, especially in major areas of grammar. This paper describes an experiment where 100 French engineering students were provided with either a) traditional grammar rules or b) concordances for will and going to. Tests before and after the experiment allow a direct comparison of <b>traditional</b> <b>rule-based</b> learning the pattern-detection “discovery-learning” involved in DDL...|$|R
40|$|This is {{the final}} report of a two-year, Laboratory Directed Research and Development (LDRD) project at the Los Alamos National Laboratory (LANL). A method was {{developed}} to incorporate learning and adaptive capabilities into <b>traditional</b> <b>rule-based</b> descriptions of environments. The learning and adapting capacity is critical to robot programming in highly unstructured and variable environments such as the operation of robots in gloveboxes. The technology {{is based on a}} hybrid expert system technology, called expert networks, and was developed with the associated knowledge capture techniques...|$|R
40|$|AbstractInconsistency {{frequently}} {{exists in}} a rule-based expert system. Detecting the existence of inconsistency in a fuzzy rule-based environment is difficult and may be {{different from that of}} <b>traditional</b> <b>rule-based</b> systems. An affinity measure, which is based on the similarity measure, is introduced to determine the likeness of two fuzzy terms. By using the affinity measure, the techniques for consistency checking in a non-fuzzy environment can be easily applied to a fuzzy environment. A consistency checker (CCFE) is implemented to detect possible inconsistency in a mixed fuzzy and non-fuzzy environment...|$|R
40|$|This paper {{describes}} a prototype intelligent {{intrusion detection system}} (IIDS) that is being developed to demonstrate the effectiveness of data mining techniques that utilize fuzzy logic. This system combines two distinct intrusion detection approaches: 1) anomaly based intrusion detection using fuzzy data mining techniques, and 2) misuse detection using <b>traditional</b> <b>rule-based</b> expert system techniques. The anomaly-based components look for deviations from stored patterns of normal behavior. The misuse detection components look for previously described patterns of behavior {{that are likely to}} indicate an intrusion. Both network traffic and system audit data are used as inputs...|$|R
40|$|The {{present study}} offers an Optimality-Theoretic {{analysis}} of the syllabification of intervocalic consonants and glides in Modern English. It will {{be argued that the}} proposed syllabifications fall out from universal markedness constraints – all of which derive motivation from other languages – and a language-specific ranking. The analysis offered below is therefore an alternative to the <b>traditional</b> <b>rule-based</b> analyses of English syllabification, e. g. Kahn (1976), Borowsky (1986), Giegerich (1992, 1999) and to the Optimality-Theoretic treatment proposed by Hammond (1999), whose analysis requires several language-specific constraints which apparently have no cross-linguistic motivation...|$|R
30|$|Some {{research}} {{works have}} proposed additional parameters {{to improve the}} auto-scaling accuracy. For instance, the proposed method in [12] uses two upper and two lower thresholds to determine the trend of the performance indicator. Considering the trend of the performance indicator helps {{to predict the future}} performance of the cloud service and generate the scale actions ahead of time. Although the proposed method in [12] generates the scale actions ahead of time, it does not have a better accuracy compared to the <b>traditional</b> <b>rule-based</b> systems [3]. This paper uses a typical rule-based system to scale-in (or -out) the cloud service.|$|R
40|$|ABSTRACT: This paper compares {{some of the}} {{different}} claims {{that have been made}} concerning acquisition by <b>traditional</b> <b>rule-based</b> derivational theories and the more recent framework of optimality theory. Case studies of children with phonological delays are examined with special attention given to two seemingly independent error patterns, namely, place harmony and spirantization. Contrary to the expectations of derivational theories, these (and other) error patterns are argued to be implicationally related. Optimality theory is shown to offer a principled explanation for the facts with novel implications for clinical treatment. KEY WORDS: place harmony, spirantization, optimality theory, phonology, treatmen...|$|R
40|$|In this paper, we {{investigate}} the novel problem of automatic question identification in the microblog environment. It contains two steps: detecting tweets that contain questions (we call them “interrogative tweets”) and extracting the tweets which really seek information or {{ask for help}} (so called “qweets”) from interrogative tweets. To detect interrogative tweets, both <b>traditional</b> <b>rule-based</b> approach and state-of-the-art learning-based method are employed. To extract qweets, context features like short urls and Tweetspecific features like Retweets are elaborately selected for classification. We conduct an empirical study with sampled one hour’s English tweets and report our experimental results for question identification on Twitter...|$|R
40|$|AbstractDNS {{provides}} a critical function in directing Internet traffic. <b>Traditional</b> <b>rule-based</b> anomaly or intrusion detection methods {{are not able}} to update the rules dynamically. Data mining based approaches can find various patterns in massive dynamic query traffic data. In this paper, a novel periodic trend mining method is proposed, as well as a periodic trend pattern based traffic prediction method. Clustering is adopted to partition numerous domain names into separate groups by the characteristics of their query traffic time series. Experimental results on a real-word DNS log indicate data mining based approaches are promising in the domain of DNS service...|$|R
40|$|Manual {{development}} of deep linguistic resources is time-consuming and costly and therefore {{often described as}} a bottleneck for <b>traditional</b> <b>rule-based</b> NLP. In my PhD thesis I present a treebank-based method for the automatic acquisition of LFG resources for German. The method automatically creates deep and rich linguistic presentations from labelled data (treebanks) and {{can be applied to}} large data sets. My research is based on and substantially extends previous work on automatically acquiring wide-coverage, deep, constraint-based grammatical resources from the English Penn-II treebank (Cahill et al., 2002; Burke et al., 2004; Cahill, 2004). Best results for English show a dependency f-score of 82. 73...|$|R
40|$|As {{the number}} of alerts {{generated}} by collaborative applications grows, users receive more unwanted alerts. FeedMe is a general alert management system based on XML feed protocols such as RSS and ATOM. In addition to <b>traditional</b> <b>rule-based</b> alert filtering, FeedMe uses techniques from machine-learning to infer alert preferences based on user feedback. In this paper, we present and evaluate a new collaborative naïve Bayes filtering algorithm. Using FeedMe, we collected alert ratings from 33 users over 29 days. We used the data to design and verify {{the accuracy of the}} filtering algorithm and provide insights into alert prediction. Categories and Subject Descriptors H. 5. 3 [Group and Organization Interfaces]: Collaborativ...|$|R
40|$|DNS {{provides}} a critical {{function in the}} Internet infrastructure. Since it is relied on by many Internet applications, security has become a crucial problem in the DNS. <b>Traditional</b> <b>rule-based</b> intrusion detection methods {{are not able to}} update the rules dynamically. In this work, cluster and histogram analyses are employed to detect possible anomalies in DNS query traffic. The proposed methods are used to reveal unusual patterns in a real-word DNS log dataset captured at a country code top level domain server. Experimental results on such log dataset are achieved and compared performing the proposed algorithms on different query parameters and with different time-bin sizes...|$|R
40|$|Unsupervised and semi-supervised {{learning}} of morphology provide practical solutions for processing morphologically rich languages with less human labor than the <b>traditional</b> <b>rule-based</b> analyzers. Direct {{evaluation of the}} learning methods using linguistic reference analyses is important for their development, as evaluation through the final applications is often time consuming. However, even linguistic evaluation is not straightforward for full morphological analysis, because the morpheme labels generated by the learning method can be arbitrary. We review the previous evaluation methods for the learning tasks and propose new variations. In order to compare the methods, we perform an extensive meta-evaluation using the large collection of results from the Morpho Challenge competitions...|$|R
5000|$|Corticon {{was founded}} in 2000 by Dr. Mark Allen and Pedram Abrari. They founded the company after researching {{rule-based}} systems and their application to healthcare delivery. Dr. Allen worked with Dr. Larry Baraff and David Schriger, who were attempting to encode the logic of clinical practice guidelines into rule-based systems to provide in-process guidance to healthcare professionals. [...] Dr. Allen chose to leave the medical profession in 2000 to commercialize an approach to rule modeling. He partnered with Pedram Abrari, who brought experience developing rule-based systems. With a team of engineers knowledgeable in <b>traditional</b> <b>rule-based</b> systems, they developed the Corticon Business Rules Management System.|$|R
5000|$|While {{rule-based}} {{video analytics}} worked economically and reliably for many security applications {{there are many}} situations in which it cannot work. For an indoor or outdoor area where no one belongs during certain times of day, for example overnight, or for areas where no one belongs at any time such as a cell tower, <b>traditional</b> <b>rule-based</b> analytics are perfectly appropriate. In {{the example of a}} cell tower the rare time that a service technician may need to access the area would simply require calling in with a pass-code to put the monitoring response [...] "on test" [...] or inactivated for the brief time the authorized person was there.|$|R
30|$|In this paper, the {{research}} methodology use the information-processing perspective and connectionist perspective categories. Information-processing perspective {{emphasis on the}} roles of strategies and metacognition (cognition about cognition) that control the use of cognitive structures when reasoning about particular problems (Montello and Freundschuh 2005). An example is a person using {{a particular set of}} rules to perform a GIS procedure on several data layers. The information-processing approach is inspired by <b>traditional</b> <b>rule-based</b> digital computing and is represented by work in formal/computational modeling and symbolic AI. In this study, the data processing section utilized this cognition. For example, Landsat imageries classification in this paper which done using ENVI Software is inspired by information-processing cognition.|$|R
40|$|Aiming at the {{limitations}} of the existing knowledge representations in intelligent detection, a new method of Extension-based Knowledge Representation (EKR) was proposed. The definitions, grammar rules, and storage structure of EKR were presented. An Extension Solving Model (ESM) based on EKR was discussed in detail, including creation of the extension constraint graph, extended inference, calculation of relevant functions and generation of extension set. A knowledge base system based on EKR and ESM was developed, which was applied in extension repository system intelligent design of detection in photosynthesis process of D. huoshanense. More reasonable results were obtained than <b>traditional</b> <b>rule-based</b> system. EKR was feasible in intelligent design {{to solve the problem of}} intelligent detection knowledge representations...|$|R
40|$|We are {{developing}} a prototype intelligent intrusion detection system (IIDS) to demonstrate the effectiveness of data mining techniques that utilize fuzzy logic and genetic algorithms. This system combines both anomaly based intrusion detection using fuzzy data mining techniques and misuse detection using <b>traditional</b> <b>rule-based</b> expert system techniques. The anomaly-based components are developed using fuzzy data mining techniques. They look for deviations from stored patterns of normal behavior. Genetic algorithms are used to tune the fuzzy membership functions and to select an appropriate set of features. The misuse detection components look for previously described patterns of behavior {{that are likely to}} indicate an intrusion. Both network traffic and system audit data are used as inputs for both components...|$|R
40|$|Motivated by {{the need}} to {{automate}} medical information extraction from free-text radiological reports, we present a bi-directional long short-term memory (BiLSTM) neural network architecture for modelling radiological language. The model has been used to address two NLP tasks: medical named-entity recognition (NER) and negation detection. We investigate whether learning several types of word embeddings improves BiLSTM's performance on those tasks. Using a large dataset of chest x-ray reports, we compare the proposed model to a baseline dictionary-based NER system and a negation detection system that leverages the hand-crafted rules of the NegEx algorithm and the grammatical relations obtained from the Stanford Dependency Parser. Compared to these more <b>traditional</b> <b>rule-based</b> systems, we argue that BiLSTM offers a strong alternative for both our tasks. Comment: LOUHI 2016 conference proceeding...|$|R
40|$|AbstractForeign {{language}} learners make mechanical errors caused by cross-linguistic influence. It comes {{from trying to}} extract information from a native language (L 1) and apply it in a second or foreign language (L 2 /FL). There are not many didactic materials proposing a set of techniques that train the skills to keep L 1 and L 2 /FL apart and help students to reduce cross- linguistic errors. In alternative to a <b>traditional</b> <b>rule-based</b> teaching, a corpus-based approach provides a framework for exploring online corpora to give insights into authentic language use. The paper describes the types of errors caused by cross-linguistic Portuguese-English and Portuguese-Russian influence, and illustrates how some monolingual and bilingual online corpora may be rich sources for raising learner's awareness to face such linguistic obstacles...|$|R
40|$|Building {{probabilistic}} {{models of}} {{language is a}} central task in natural language and speech processing allowing to integrate the syntactic and/or semantic (and recently pragmatic) constraints of the language into the systems. Probabilistic language models are an attractive alternative to the more <b>traditional</b> <b>rule-based</b> systems, such as context free grammars, because of the recent availability of massive amount of text corpora {{which can be used}} to e#ciently train the models and because instead of binary grammaticality judgement o#ered by the rule-based systems, likelihood of any sequence of lexical units can be obtained, which is a crucial factor in such tasks as speech recognition. Probabilistic language models also find their application in part-of-speech tagging, machine translation, semantic disambiguation and numerous other fields...|$|R
40|$|An {{approach}} to natural language meaning-based parsing {{in which the}} unit of linguistic knowledge is the word rather than the rewrite rule is described. In the word expert parser, knowledge about language is distributed across a population of procedural experts, each representing a word of the language, and each an expert at diagnosing that word's intended usage in context. The parser is structured around a coroutine control {{environment in which the}} generator-like word experts ask questions and exchange information in coming to collective agreement on sentence meaning. The word expert theory is advanced as a better cognitive model of human language expertise than the <b>traditional</b> <b>rule-based</b> approach. The technical discussion is organized around examples taken from the prototype LISP system which implements parts of the theory...|$|R
40|$|Abstract- Automated {{learning}} in medical sensor system {{for health care}} monitoring application is presented in this paper. We worked mainly on cardiology and have tried to integrate the benefits of medical instruments of the said domain. We have used multi-disciplinary concept of learning from different domains like philosophy, sociology, psychology, education apart from computer science. The system uses the concept of expert system, though it overcomes the limitations of any <b>traditional</b> <b>rule-based</b> expert system. The system is designed considering all constraints of a sensor network. It is a real time application and expected to take decision and upgrade its performance in a reactive way. Index terms- Certainty factor (CF), Electrocardiogram (ECG), knowledge base, leads, learning, rules, self directed learning (SDL), sampling interval (SI),sensors. ...|$|R
40|$|In {{this paper}} we {{investigate}} how to model legal abrogation and annulment in Defeasible Logic. We examine some options that embed in this setting, and similar <b>rule-based</b> systems, <b>ideas</b> from belief and base revision. In both cases, our conclusion is negative, which suggests {{to adopt a}} different logical model...|$|R
40|$|Abstract—We propose an {{adaptive}} cyber security monitoring system that integrates {{a number of}} component techniques to collect time-series situation information, perform intrusion detection, keep track of event evolution, and characterize and identify security events so corresponding defense actions can be taken in a timely and effective manner. Particularly, we employ a decision fusion algorithm with analytically proven performance guarantee for intrusion detection based on local votes from distributed sensors. Different from the <b>traditional</b> <b>rule-based</b> pattern matching technique, security events in the proposed system are represented in a graphical form of correlation networks using random matrix theory and identified through the computation of network similarity measurement. Extensive simulation results on event identification illustrate {{the efficacy of the}} proposed system. Index Terms—Cyber security, decision fusion, event correlation, random matrix theory I...|$|R
40|$|Explanation {{facilities}} are a particularly {{important feature of}} expert system frameworks. It is {{an area in which}} <b>traditional</b> <b>rule-based</b> expert system frameworks have had mixed results. While explanations about control are well handled, {{facilities are}} needed for generating better explanations concerning knowledge base content. This paper approaches the explanation problem by examining the effect an event has on a variable of interest within a symmetric Bayesian inferencing system. We argue that any effect measure operating in this context must satisfy certain properties. Such a measure is proposed. It forms the basis for an explanation facility which allows the user of the Generalized Bayesian Inferencing System to question the meaning of the knowledge base. That facility is described in detail. Comment: Appears in Proceedings of the Second Conference on Uncertainty in Artificial Intelligence (UAI 1986...|$|R
