14|1|Public
40|$|Recent {{research}} {{involving a}} trackball with force feedback {{has demonstrated that}} tactile feedback can enhance the acquisition of targets in graphical user interfaces in terms of movement times and errors. The present study seeks to explore {{the degree to which}} <b>tactual</b> <b>feedback</b> over a target, in contrast to changes in the display/control gain over the target, influences target acquisition performance. <b>Tactual</b> <b>feedback</b> over a target is felt as a pulling force towards the centre of a target, with a counterforce applied when moving out of the centre. Changes in the cursor gain can be used to create a cursor-catching effect by requiring more movement effort of the control device to leave than to enter the target centre, without increasing the total amount of effort to enter and leave the target area. User movement in entering a target is thus braked by the change in cursor gain. Results of an experiment indicated that target acquisition performance was generally higher in the <b>tactual</b> <b>feedback</b> condition, followed by cursor gain feedback, in comparison with no-cursor gain feedback. User interface design issues as related to gain feedback in visual interfaces and <b>tactual</b> <b>feedback</b> over targets are considered...|$|E
40|$|In {{this paper}} an {{experimental}} setup is described, {{which will be}} demonstrated at the symposium. Various movement sensors are used in combination with tactile actuators, which provide feedback on the movements made. The aim is to investigate the application of active haptic feedback to improve gestural control of electronic musical instruments. The project is part of ongoing research which aims to improve human-computer interaction at the physical level by applying <b>tactual</b> <b>feedback.</b> The paper describes the background {{and some of the}} theory, rather then presenting results. The {{purpose of this paper is}} to introduce the ideas, set-up and approach. 1. Background designing and applying the active <b>tactual</b> <b>feedback.</b> Ever since the invention of the famous Thereminvox around 1920, an instrument played by moving one’s hands in the air in two planes near a pitch and a volume antenna, gestura...|$|E
40|$|It {{has been}} {{reported}} that operating efficiency for teleoperations using stereoscopic video images is lower than that using the naked eye in real environments. Here, the authors tried to improve the human-machine interface of teleoperational system in order to achieve a higher operating efficiency for stereoscopic video images by adding other information. An experiment was carried out under the two following conditions: Condition 1 was only stereoscopic vision. Condition 2 was that <b>tactual</b> <b>feedback</b> was given through a vibration device put on the subject 2 ̆ 7 s hand, as one object touched another. The vibration device consisted of a small motor, and vibrated when objects touched each other. The subject 2 ̆ 7 s task was to insert a cylindrical object into a round hole. The completion time, when <b>tactual</b> <b>feedback</b> was provided (Condition 2), was shorter than when no additional information was provided (Condition 1). This result leads {{to the conclusion that the}} efficiency becomes higher by the vibration device...|$|E
40|$|An {{experimental}} {{evaluation is}} presented of the usability properties of a multimodal interaction style for music programming. The experiment investigated task performance and learning of procedures while performing music programming tasks {{in the presence}} or absence of a visual display combined with a tactual and auditory interface. The participant's task was to compile a music programme as quickly as possible. Task performance was measured by compilation time and number of actions executed. Procedural knowledge was assessed by a posttask questionnaire. Participants performed equally efficiently, i. e [...] not significantly differently, with and without a visual display, except for the first programming task. In the first task, performing a task without a visual display required significantly more time (approximately one additional minute) and more, but not significantly more, actions, probably due to explorative behaviour required to develop an internal representation of the interaction style. Earlier experience with a visual display did not improve task performance without a visual display. It also appeared that participants who had performed tasks non visually had learned more procedures. Nonvisual interaction requires the explicit discovery and memorization of procedures, which induces a higher degree of cognitive processing. It could therefore be demonstrated that <b>tactual</b> and auditory <b>feedback</b> can compensate for the visual modality in contextsof- use, in which visual display of information is impoverished or even absent. e. g [...] portable devices, remote controls, and car equipment...|$|R
40|$|Although the {{integration}} of tactile feedback within the humancomputer interface could have considerable benefits this channel of communication is often overlooked or, at most, employed on an ad hoc basis. One contributing factor to the reluctance of interface designers to consider using <b>tactual</b> <b>feedback</b> {{is the lack of}} established design principles for doing so. A preliminary set of principles for tactile interface design are described. These have been constructed using the findings of a study into the presentation of music notation to blind people...|$|E
40|$|Target {{acquisition}} {{is greatly}} helped by <b>tactual</b> <b>feedback.</b> To create non-disturbing tactual feedback-effects in human-computer interaction. Ihe user' s goal {{has to be}} predicted, so that the <b>tactual</b> <b>feedback</b> can help the user toward Ihe target and away from non-targets. In this paper we describe an experiment in which we explore cursor movements with an amplitude of 250 pixels, in eight different directions and with three different control devices (a mechanical mouse, an optical mouse, and an oplical trackball). The aim of this exploration was to find characteristics of the cursor path {{that could be used}} to creale a prediction algorithm. The focus was on the mean curvature and variability of the paths. It can be concluded that, on average, cursor paths are rather straight in all eight directions and with all three devices. The variability of the paths depends on three factors: (1) direction (the variability is higher in oblique directions than in horizontal and vertical directions); (2) friction of the control device (the variability is higher when a low friction device is used than when a higher friction device is used - the optical trackball having a lower friction than the two mice); and (3) the user. The amount of variability is used to estimate the maximum target resolution at which an algorithm can predict the user's target with a certain probability...|$|E
40|$|Skilled {{interactions}} with sounding objects, such as drumming, rely on resolving the {{uncertainty in the}} acoustical and <b>tactual</b> <b>feedback</b> signals generated by vibrating objects. Uncertainty may arise from mis-estimation of the objects’ geometry-independent mechanical properties, such as surface stiffness. How multisensory information feeds back into the fine-tuning of sound-generating actions remains unexplored. Participants (percussionists, non-percussion musicians, or non-musicians) held a stylus and learned to control their wrist velocity while repeatedly striking a virtual sounding object whose surface stiffness was under computer control. Sensory feedback was manipulated by perturbing the surface stiffness specified by audition and haptics in a congruent or incongruent manner. [ [...] . ...|$|E
40|$|Abstract The role of {{the sense}} of touch in Human-Computer Interaction as a channel for {{feedback}} in manipulative processes is investigated. The paper describes information as presented by the computer, and focuses on the feedback that supports the articulation of human gesture. Several experiments are described that investigate the use of (redundant) tactual articulatory feedback. The results presented show that a significant improvement of effectivity only occurs when the task is sufficiently difficult, while in other cases the added feedback can actually lower the effectivity. The qualitative data show a positive effect for added <b>tactual</b> <b>feedback.</b> The discussion includes suggestions for further research, particularly investigating the effect in free moving gestures. ...|$|E
40|$|The {{aim of the}} {{reported}} experiment {{was to investigate the}} effect of <b>tactual</b> <b>feedback</b> of human performance in virtual manipulation tasks. We compared performance on a pick-and-place task using the ITR device from Interface Technology Research Limit (UK) and using the LRP force feedback glove (LRP FFG). The ITR device provides binary force information (i. e grasped/not grasped) while the LRP glove provides force feedback to 14 hand locations. Two objects were used : a cube and a cylinder. The experimental conditions were the following : "RWC" condition (manipulation using bare hands), "ITR" condition (manipulation using the ITR device), "GLOVE" condition (manipulation using the LRP FFG without force feedback), and "LRP" condition (manipulation using the LRP FFG). Results showed that experimental condition has a significant effect of task completion time. We observed that the ITR device led to lower completion time that the LRP FFG. Results also showed that force feedback allowed more accu [...] ...|$|E
40|$|It {{has been}} {{reported}} that the teleoperational efficiency using stereoscopic video images is inferior to the working efficiency of using the naked eye in real environments. One of the causes of this is the deficiency of the amount of information for operators. The big improvement on the working efficiency was shown when <b>tactual</b> <b>feedback</b> was given to operators in addition to the sight information. It is not clear how reaction force information helps the improvement in working efficiency. In this report we investigated the effect of the amount of reaction force feedback under sufficient and insufficient visual informational environments. Subjects were instructed to insert cylinders into the holes on the blocks in the virtual reality environment. The results showed that the force feedback brought about a shorter work completion time and lessened the number of errors. However, there are no significant differences both among the work completion times and the numbers of different amounts of reaction force. This result suggests that the tactual cue is effective to improve task performances of the teleoperation...|$|E
40|$|Visual {{information}} {{is important in}} surgeons ’ manipulative performance especially in laparoscopic surgery where <b>tactual</b> <b>feedback</b> is less than in open surgery. The study of surgeons ’ eye movements is an innovative way of assessing skill, in that {{a comparison of the}} eye movement strategies between expert surgeons and novices may show important differences {{that could be used in}} training. We conducted a preliminary study comparing the eye movements of 5 experts and 5 novices performing a one-handed aiming task on a computer-based laparoscopic surgery simulator. The performance results showed that experts were quicker and generally committed fewer errors than novices. We investigated eye movements as a possible factor for experts performing better than novices. The results from eye gaze analysis showed that novices needed more visual feedback of the tool position to complete the task than did experts. In addition, the experts tended to maintain eye gaze on the target while manipulating the tool, whereas novices were more varied in their behaviours. For example, we found that on some trials, novices tracked the movement of the tool until it reached the target...|$|E
40|$|After a {{discussion}} of the influence of experience on perception and a survey of the literature on visual-tactual conflict a previous series of experiments examining the effects of tactual training on perception of minified squares, was described. This led to a similar experiment involving varying amounts of tactual training. Although little support was obtained for the hypothesis that when vision and touch are placed in conflict the demonstrated dominance of vision is due, at least in part, to a difference in previous experience obtained by the two senses at the tasks involved, further experiments were carried out suing Doveprism apparatus. The effects of tactual training with verbal feedback, <b>tactual</b> <b>feedback</b> and no feedback were investigated. While results of a control group showed that there was little change in repeated judgments when not actual training was given, visual dominance was shown to decrease when verbal or tactual knowledge of results (feedback) accompanied tactual training. This decrease did not occur when no feedback was given. It was concluded that the relative familiarity of the displays presented to the two senses {{must be taken into account}} before the results of conflict experiments can justifiably be interpreted as indicating an inherent superiority of vision...|$|E
40|$|Skilled {{interactions}} with sounding objects, such as drumming, rely on resolving the {{uncertainty in the}} acoustical and <b>tactual</b> <b>feedback</b> signals generated by vibrating objects. Uncertainty may arise from mis-estimation of the objects' geometry-independent mechanical properties, such as surface stiffness. How multisensory information feeds back into the fine-tuning of sound-generating actions remains unexplored. Participants (percussionists, non-percussion musicians, or non-musicians) held a stylus and learned to control their wrist velocity while repeatedly striking a virtual sounding object whose surface stiffness was under computer control. Sensory feedback was manipulated by perturbing the surface stiffness specified by audition and haptics in a congruent or incongruent manner. The compensatory changes in striking velocity were measured as the motor effects of the sensory perturbations, and sensory dominance was quantified by the asymmetry of congruency effects across audition and haptics. A pronounced dominance of haptics over audition suggested a superior utility of somatosensation developed through long-term experience with object exploration. Large interindividual differences in the motor effects of haptic perturbation potentially arose from a differential reliance {{on the type of}} tactual prediction error for which participants tend to compensate: vibrotactile force vs. object deformation. Musical experience did not have much of an effect beyond a slightly greater reliance on object deformation in mallet percussionists. The bias towards haptics in the presence of crossmodal perturbations was greater when participants appeared to rely on object-deformation feedback, suggesting a weaker association between haptically sensed object deformation and the acoustical structure of concomitant sound during everyday experience of actions upon objects...|$|E
40|$|This thesis {{builds on}} {{previous}} {{efforts to develop}} tactile speech-reception aids for the hearing-impaired. Whereas conventional hearing aids mainly amplify acoustic signals, tactile speech aids convert acoustic information into a form perceptible via the sense of touch. By facilitating visual speechreading and providing sensory feedback for vocal control, tactile speech aids may substantially enhance speech communication abilities {{in the absence of}} useful hearing. Research for this thesis consisted of several lines of work. First, tactual detection and temporal order discrimination by congenitally deaf adults were examined, in order to assess the practicability of encoding acoustic speech information as temporal relationships among tactual stimuli. Temporal resolution among most congenitally deaf subjects was deemed adequate for reception of tactually-encoded speech cues. Tactual offset-order discrimination thresholds substantially exceeded those measured for onset-order, underscoring fundamental differences between stimulus masking dynamics in the somatosensory and auditory systems. Next, a tactual speech transduction scheme was designed with the aim of extending the amount of articulatory information conveyed by an earlier vocoder-type tactile speech display strategy. The novel transduction scheme derives relative amplitude cues from three frequency-filtered speech bands, preserving the cross-channel timing information required for consonant voicing discriminations, while retaining low-frequency modulations that distinguish voiced and aperiodic signal components. Additionally, a sensorimotor training approach ("directed babbling") was developed with the goal of facilitating tactile speech acquisition through frequent vocal imitation of visuo-tactile speech stimuli and attention to <b>tactual</b> <b>feedback</b> from one's own vocalizations. A final study evaluated the utility of the tactile speech display in resolving ambiguities among visually presented consonants, following either standard or enhanced sensorimotor training. Profoundly deaf and normal-hearing participants trained to exploit tactually-presented acoustic information in conjunction with visual speechreading to facilitate consonant identification in the absence of semantic context. Results indicate that the present transduction scheme can enhance reception of consonant manner and voicing information and facilitate identification of syllableinitial and syllable-final consonants. The sensorimotor training strategy proved selectively advantageous for subjects demonstrating more gradual tactual speech acquisition. Simple, low-cost tactile devices may prove suitable for widespread distribution in developing countries, where hearing aids and cochlear implants remain unaffordable for most severely and profoundly deaf individuals. They have the potential to enhance verbal communication with minimal need for clinical intervention. by Theodore M. Moallem. Thesis (Ph. D.) [...] Harvard-MIT Division of Health Sciences and Technology, 2011. Cataloged from PDF version of thesis. Includes bibliographical references (p. 150 - 159) ...|$|E

