2890|1766|Public
5|$|Wang tiles are squares {{coloured}} on each edge, {{and placed}} so that abutting edges of adjacent tiles {{have the same}} colour; hence they are sometimes called Wang dominoes. A suitable set of Wang dominoes can tile the plane, but only aperiodically. This is known because any <b>Turing</b> <b>machine</b> can be represented {{as a set of}} Wang dominoes that tile the plane if and only if the <b>Turing</b> <b>machine</b> does not halt. Since the halting problem is undecidable, the problem of deciding whether a Wang domino set can tile the plane is also undecidable.|$|E
5|$|Turing {{was highly}} {{influential}} {{in the development of}} theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the <b>Turing</b> <b>machine,</b> which can be considered a model of a general purpose computer. Turing is widely considered to be the father of theoretical computer science and artificial intelligence.|$|E
5|$|Konrad Zuse's Z3 was the world's first working programmable, fully {{automatic}} computer, with binary digital arithmetic logic, but it lacked the conditional branching of a <b>Turing</b> <b>machine.</b> On 12 May 1941, it was successfully presented {{to an audience}} of scientists of the Deutsche Versuchsanstalt für Luftfahrt ("German Laboratory for Aviation") in Berlin. The Z3 stored its program on an external tape, but it was electromechanical rather than electronic. The Colossus of 1943 was the first electronic computing device, {{but it was not a}} general-purpose machine.|$|E
25|$|Many {{types of}} <b>Turing</b> <b>machines</b> {{are used to}} define {{complexity}} classes, such as deterministic <b>Turing</b> <b>machines,</b> probabilistic <b>Turing</b> <b>machines,</b> non-deterministic <b>Turing</b> <b>machines,</b> quantum <b>Turing</b> <b>machines,</b> symmetric <b>Turing</b> <b>machines</b> and alternating <b>Turing</b> <b>machines.</b> They are all equally powerful in principle, but when resources (such as time or space) are bounded, some of these may be more powerful than others.|$|R
50|$|Simple {{inductive}} <b>Turing</b> <b>machines</b> are {{equivalent to}} other models of computation. More advanced inductive <b>Turing</b> <b>machines</b> {{are much more}} powerful. It is proved (Burgin, 2005) that limiting partial recursive functions, trial and error predicates, general <b>Turing</b> <b>machines,</b> and simple inductive <b>Turing</b> <b>machines</b> are equivalent models of computation. However, simple inductive <b>Turing</b> <b>machines</b> and general <b>Turing</b> <b>machines</b> give direct constructions of computing automata, which are thoroughly grounded in physical machines. In contrast, trial and error predicates, limiting recursive functions and limiting partial recursive functions present syntactic systems of symbols with formal rules for their manipulation. Simple inductive <b>Turing</b> <b>machines</b> and general <b>Turing</b> <b>machines</b> are related to limiting partial recursive functions and trial and error predicates as <b>Turing</b> <b>machines</b> are related to partial recursive functions and lambda-calculus.|$|R
40|$|This paper {{introduces}} a new computing model {{based on the}} cooperation among <b>Turing</b> <b>machines</b> called orchestrated <b>machines.</b> Like universal <b>Turing</b> <b>machines,</b> orchestrated machines {{are also designed to}} simulate <b>Turing</b> <b>machines</b> but they can also modify the original operation of the included <b>Turing</b> <b>machines</b> to create a new layer of some kind of collective behavior. Using this new model we can define some interested notions related to cooperation ability of <b>Turing</b> <b>machines</b> such as the intelligence quotient or the emotional intelligence quotient for <b>Turing</b> <b>machines...</b>|$|R
5|$|In {{the late}} 1980s, Putnam {{abandoned}} his adherence to functionalism and other computational theories of mind. His change of mind was {{primarily due to}} the difficulties that computational theories have in explaining certain intuitions {{with respect to the}} externalism of mental content. This is illustrated by Putnam's own Twin Earth thought experiment (see Philosophy of language). He also developed a separate argument against functionalism in 1988, based on Fodor's generalized version of multiple realizability. Asserting that functionalism is really a watered-down identity theory in which mental kinds are identified with functional kinds, Putnam argued that mental kinds may be multiply realizable over functional kinds. The argument for functionalism is that the same mental state could be implemented by the different states of a universal <b>Turing</b> <b>machine.</b>|$|E
25|$|A {{deterministic}} <b>Turing</b> <b>machine</b> is {{the most}} basic <b>Turing</b> <b>machine,</b> which uses a fixed set of rules to determine its future actions. A probabilistic <b>Turing</b> <b>machine</b> is a deterministic <b>Turing</b> <b>machine</b> with an extra supply of random bits. The ability to make probabilistic decisions often helps algorithms solve problems more efficiently. Algorithms that use random bits are called randomized algorithms. A non-deterministic <b>Turing</b> <b>machine</b> is a deterministic <b>Turing</b> <b>machine</b> with an added feature of non-determinism, which allows a <b>Turing</b> <b>machine</b> to have multiple possible future actions from a given state. One way to view non-determinism is that the <b>Turing</b> <b>machine</b> branches into many possible computational paths at each step, and if it solves the problem {{in any of these}} branches, it is said to have solved the problem. Clearly, this model is not meant to be a physically realizable model, it is just a theoretically interesting abstract machine that gives rise to particularly interesting complexity classes. For examples, see non-deterministic algorithm.|$|E
25|$|SAT is in NP {{because any}} {{assignment}} of Boolean values to Boolean variables that is claimed {{to satisfy the}} given expression can be verified in polynomial time by a deterministic <b>Turing</b> <b>machine.</b> (The statements verifiable in polynomial time by a deterministic <b>Turing</b> <b>machine</b> and solvable in polynomial time by a non-deterministic <b>Turing</b> <b>machine</b> are totally equivalent, and {{the proof can be}} found in many textbooks, for example Sipser's Introduction to the Theory of Computation, section 7.3.).|$|E
50|$|Simple {{inductive}} <b>Turing</b> <b>machines</b> are {{equivalent to}} other models of computation such as general <b>Turing</b> <b>machines</b> of Schmidhuber, {{trial and error}} predicates of Hilary Putnam, limiting partial recursive functions of Gold, and trial-and-error machines of Hintikka and Mutanen. More advanced inductive <b>Turing</b> <b>machines</b> are much more powerful. There are hierarchies of inductive <b>Turing</b> <b>machines</b> that can decide membership in arbitrary sets of the arithmetical hierarchy (Burgin 2005). In comparison with other equivalent models of computation, simple inductive <b>Turing</b> <b>machines</b> and general <b>Turing</b> <b>machines</b> give direct constructions of computing automata that are thoroughly grounded in physical machines. In contrast, trial-and-error predicates, limiting recursive functions, and limiting partial recursive functions present only syntactic systems of symbols with formal rules for their manipulation. Simple inductive <b>Turing</b> <b>machines</b> and general <b>Turing</b> <b>machines</b> are related to limiting partial recursive functions and trial-and-error predicates as <b>Turing</b> <b>machines</b> are related to partial recursive functions and lambda calculus.|$|R
40|$|For quantum <b>Turing</b> <b>machines</b> {{we present}} three elements: Its components, its time {{evolution}} operator and its local transition function. The components are related with deterministic <b>Turing</b> <b>machines,</b> the time evolution operator is related with reversible <b>Turing</b> <b>machines</b> {{and the local}} transition function is related with probabilistic and reversible <b>Turing</b> <b>machines...</b>|$|R
25|$|This is true {{simply because}} Diophantine sets, being equal to recursively {{enumerable}} sets, are also equal to <b>Turing</b> <b>machines.</b> It {{is a well}} known property of <b>Turing</b> <b>machines</b> that there exist universal <b>Turing</b> <b>machines,</b> capable of executing any algorithm.|$|R
25|$|A {{reduction}} can {{be demonstrated}} to this problem from the well-known undecidable problem of determining whether a <b>Turing</b> <b>machine</b> accepts a particular input (the halting problem). The reduction uses {{the concept of a}} computation history, a string describing an entire computation of a <b>Turing</b> <b>machine.</b> A CFG can be constructed that generates all strings that are not accepting computation histories for a particular <b>Turing</b> <b>machine</b> on a particular input, and thus it will accept all strings only if the machine doesn't accept that input.|$|E
25|$|If S is a Turing computable set, {{then both}} S and its {{complement}} are recursively enumerable (if T is a <b>Turing</b> <b>machine</b> giving 1 for inputs in S and 0 otherwise, we may build a <b>Turing</b> <b>machine</b> halting {{only on the}} former, and another halting only on the latter).|$|E
25|$|A <b>Turing</b> <b>machine</b> is a {{mathematical}} model of a general computing machine. It is a theoretical device that manipulates symbols contained on a strip of tape. Turing machines are not intended as a practical computing technology, {{but rather as a}} thought experiment representing a computing machine—anything from an advanced supercomputer to a mathematician with a pencil and paper. It is believed that if a problem can be solved by an algorithm, there exists a <b>Turing</b> <b>machine</b> that solves the problem. Indeed, this is the statement of the Church–Turing thesis. Furthermore, it is known that everything that can be computed on other models of computation known to us today, such as a RAM machine, Conway's Game of Life, cellular automata or any programming language can be computed on a <b>Turing</b> <b>machine.</b> Since Turing machines are easy to analyze mathematically, and are believed to be as powerful as any other model of computation, the <b>Turing</b> <b>machine</b> is the most commonly used model in complexity theory.|$|E
40|$|We {{show that}} 2 -tag systems {{efficiently}} simulate <b>Turing</b> <b>machines.</b> As a corollary {{we find that}} the small universal <b>Turing</b> <b>machines</b> of Rogozhin, Minsky and others simulate <b>Turing</b> <b>machines</b> in polynomial time. This is an exponential improvement on the previously known simulation time overhead and improves a forty year old result in the area of small universal <b>Turing</b> <b>machines.</b> Comment: Slightly expanded and updated from conference versio...|$|R
40|$|AbstractThe {{main goal}} {{of this paper is}} to compare {{recursive}} algorithms such as <b>Turing</b> <b>machines</b> with such super-recursive algorithms as inductive <b>Turing</b> <b>machines.</b> This comparison is made in a general setting of dual complexity measures such as Kolmogorov or algorithmic complexity. To make adequate comparison, we reconsider the standard axiomatic approach to complexity of algorithms. The new approach allows us to achieve a more adequate representation of static system complexity in the axiomatic context. It is demonstrated that for solving many problems inductive <b>Turing</b> <b>machines</b> have much lower complexity than <b>Turing</b> <b>machines</b> and other recursive algorithms. Thus, inductive <b>Turing</b> <b>machines</b> are not only more powerful, but also more efficient than <b>Turing</b> <b>machines...</b>|$|R
40|$|The {{main goal}} {{of this paper is}} to compare {{recursive}} algorithms such as <b>Turing</b> <b>machines</b> with such super-recursive algorithms as inductive <b>Turing</b> <b>machines.</b> This comparison is made in a general setting of dual complexity measures such as Kolmogorov or algorithmic complexity. To make adequate comparison, we reconsider the standard axiomatic approach to complexity of algorithms. The new approach allows us to achieve a more adequate representation of static system complexity in the axiomatic context. It is demonstrated that for solving many problems inductive <b>Turing</b> <b>machines</b> have much lower complexity than <b>Turing</b> <b>machines</b> and other recursive algorithms. Thus, inductive <b>Turing</b> <b>machines</b> are not only more powerful, but also more efficient than <b>Turing</b> <b>machines.</b> (C) 2003 Elsevier B. V. All rights reserved...|$|R
25|$|The page of , who, with Jürgen Buntrock, {{found the}} {{above-mentioned}} records for a 5 and 6-state <b>Turing</b> <b>machine.</b>|$|E
25|$|NP: The {{complexity}} {{class of}} decision {{problems that can}} be solved on a non-deterministic <b>Turing</b> <b>machine</b> in polynomial time.|$|E
25|$|We could, alternatively, {{choose an}} {{encoding}} for Turing machines, where an encoding {{is a function}} which associates to each <b>Turing</b> <b>Machine</b> M a bitstring <M>. If M is a <b>Turing</b> <b>Machine</b> which, on input w, outputs string x, then the concatenated string <M> w is a description of x. For theoretical analysis, this approach is more suited for constructing detailed formal proofs and is generally preferred in the research literature. In this article, an informal approach is discussed.|$|E
50|$|Infinite-time <b>Turing</b> <b>machines</b> are {{models of}} {{computation}} that permit computations {{to go on}} for infinitely many steps. They generalize standard <b>Turing</b> <b>machines</b> used in the theory of computability. Benedikt Löwe has shown that there are close connections between computations of infinite-time <b>Turing</b> <b>machines</b> and revision processes.|$|R
40|$|Several {{properties}} of two-dimensional alternating <b>Turing</b> <b>machines</b> are investigated. The {{first part of}} this paper investigates the relationship between the classes of sets accepted by space-bounded and finitely leaf-size bounded three-way two-dimensional alternating <b>Turing</b> <b>machines</b> and the classes of sets which are finite intersections of sets accepted by space-bounded three-way two-dimensional nondeterministic <b>Turing</b> <b>machines.</b> The second part of this paper investigates the accepting power and closure properties (under Boolean operations) of two-dimensional alternating <b>Turing</b> <b>machines</b> with only universal states...|$|R
50|$|Quantum <b>Turing</b> <b>machines</b> can {{be related}} to {{classical}} and probabilistic <b>Turing</b> <b>machines</b> in a framework based on transition matrices, shown by Lance Fortnow.|$|R
25|$|ZPP: The {{complexity}} {{class of}} decision {{problems that can}} be solved with zero error on a probabilistic <b>Turing</b> <b>machine</b> in polynomial time.|$|E
25|$|The article <b>Turing</b> <b>machine</b> gives {{a general}} {{introduction}} to Turing machines, while this article covers a specific class of Turing machines.|$|E
25|$|BPP: The {{complexity}} {{class of}} decision {{problems that can}} be solved with 2-sided error on a probabilistic <b>Turing</b> <b>machine</b> in polynomial time.|$|E
5000|$|... {{inductive}} <b>Turing</b> <b>machines,</b> which perform computations {{similar to}} computations of <b>Turing</b> <b>machines</b> and produce their results after {{a finite number}} of steps (Mark Burgin) ...|$|R
5000|$|... limit <b>Turing</b> <b>machines,</b> which perform {{computations}} {{similar to}} computations of <b>Turing</b> <b>machines</b> but their final results are {{limits of their}} intermediate results (Mark Burgin) ...|$|R
40|$|Abstract. We {{present a}} number of time-efficient small {{universal}} <b>Turing</b> <b>machines.</b> We show that there exists deterministic polynomial time universal <b>Turing</b> <b>machines</b> with state-symbol products of (3, 11), (5, 7), (6, 6), (7, 5) and (8, 4). These machines are the smallest known universal <b>Turing</b> <b>machines</b> that simulate TMs in polynomial time. ...|$|R
25|$|S(n) = max{ s(M) | M ∈ En } = {{the largest}} number of shifts made by any halting n-state 2-symbol <b>Turing</b> <b>machine.</b>|$|E
25|$|However, some {{computational}} {{problems are}} easier to analyze in terms of more unusual resources. For example, a non-deterministic <b>Turing</b> <b>machine</b> is a computational model that is allowed to branch out to check many different possibilities at once. The non-deterministic <b>Turing</b> <b>machine</b> has {{very little to do}} with how we physically want to compute algorithms, but its branching exactly captures many of the mathematical models we want to analyze, so that non-deterministic time is a very important resource in analyzing computational problems.|$|E
25|$|Since the {{negative}} {{answer to the}} halting problem shows that there are problems that cannot be solved by a <b>Turing</b> <b>machine,</b> the Church–Turing thesis limits what {{can be accomplished by}} any machine that implements effective methods. However, not all machines conceivable to human imagination are subject to the Church–Turing thesis (e.g. oracle machines). It is an open question whether there can be actual deterministic physical processes that, in the long run, elude simulation by a <b>Turing</b> <b>machine,</b> and in particular whether any such hypothetical process could usefully be harnessed {{in the form of a}} calculating machine (a hypercomputer) that could solve the halting problem for a <b>Turing</b> <b>machine</b> amongst other things. It is also an open question whether any such unknown physical processes are involved in the working of the human brain, and whether humans can solve the halting problem (Copeland 2004, p.15).|$|E
40|$|It {{is shown}} that the uniform halting problem for one-state <b>Turing</b> <b>machines</b> is {{solvable}}. It remains solvable for various generalizations like one-state <b>Turing</b> <b>machines</b> with two-dimensional tape and jumping reading head. Other generalizations, for example, one-state <b>Turing</b> <b>machines</b> with two tapes, have an unsolvable uniform halting problem. The history {{of the problem is}} summarized...|$|R
40|$|Accelerating <b>Turing</b> <b>machines</b> are {{abstract}} {{devices that}} have the same computational structure as <b>Turing</b> <b>machines,</b> but can perform super-tasks. I argue that performing super-tasks alone does not buy more computational power, and that accelerating <b>Turing</b> <b>machines</b> do not solve the halting problem. To show this, I analyze the reasoning that leads to Thomson's paradox, {{point out that the}} paradox rests on a conflation of different perspectives of accelerating processes, and conclude that the same conflation underlies the claim that accelerating <b>Turing</b> <b>machines</b> can solve the halting problem...|$|R
40|$|Infinite time <b>Turing</b> <b>machines</b> {{extend the}} {{operation}} of ordinary <b>Turing</b> <b>machines</b> into transfinite ordinal time. By doing so, they provide a natural model of infinitary computability, a theoretical setting {{for the analysis of}} the power and limitations of supertask algorithms. Comment: 25 pages. This is an expository account of infinite time <b>Turing</b> <b>machines</b> for a philosophical audienc...|$|R
