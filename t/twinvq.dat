21|0|Public
5000|$|A {{proprietary}} {{audio compression}} format called <b>TwinVQ</b> {{was developed by}} Nippon Telegraph and Telephone Corporation (NTT) (in NTT's Human Interface Laboratories) and marketed by Yamaha under the name SoundVQ. The NTT also offered a <b>TwinVQ</b> demonstration software for non-commercial purposes - NTT <b>TwinVQ</b> Encoder and <b>TwinVQ</b> Player, encoder API, decoder API and header file format. The filename extension is [...]vqf.|$|E
50|$|<b>TwinVQ</b> uses Twin vector quantization. The {{proprietary}} <b>TwinVQ</b> codec supports constant {{bit rate}} encoding at 80, 96, 112, 128, 160 and 192 kbit/s. It was claimed that <b>TwinVQ</b> files are about 30 to 35% smaller than MP3 files of adequate quality. For example, a 96 kbit/s <b>TwinVQ</b> file allegedly has roughly the same quality as a 128 kbit/s MP3 file. The higher quality is achieved {{at the cost of}} higher processor usage.|$|E
50|$|Yamaha marketed <b>TwinVQ</b> as an {{alternative}} to MP3, but the format never became very popular. This could be attributed to the proprietary nature of the format—third party software was scarce and there was no hardware support. Also the encoding was extremely slow and there was not much music available in <b>TwinVQ</b> format. As other MP3 alternatives emerged, <b>TwinVQ</b> quickly became obsolete.|$|E
50|$|Note {{that some}} commercialized {{products}} such as Metasound (Voxware), SoundVQ (Yamaha), and SolidAudio (Hagiwara) are also based on the <b>TwinVQ</b> technology, but the configurations {{are different from the}} MPEG-4 <b>TwinVQ.</b>|$|E
50|$|The {{proprietary}} {{version of}} <b>TwinVQ</b> can be {{also used for}} speech encoding. Compression technology specifically designed to handle voice compression was published by NTT. The NTT <b>TwinVQ</b> implementation supported sampling frequencies from 8 kHz or 11.025 kHz and bit rate from 8 kbit/s.|$|E
5000|$|Subpart 4: General Audio Coding (GA) (Time/Frequency Coding) - AAC, <b>TwinVQ,</b> BSAC ...|$|E
5000|$|<b>TwinVQ</b> - one of {{the object}} types defined in MPEG-4 Audio version 1 ...|$|E
5000|$|Scalable Audio Profile - {{defined in}} 1999, uses AAC-LC, AAC-LTP, AAC Scalable, <b>TwinVQ,</b> CELP, HVXC, TTSI ...|$|E
50|$|In {{the context}} of the MPEG-4 Audio (MPEG-4 Part 3), <b>TwinVQ</b> is an audio codec {{optimized}} for audio coding at ultra low bitrates around 8 kbit/s.|$|E
5000|$|Main Audio Profile - {{defined in}} 1999, uses {{most of the}} MPEG-4 Audio Object Types (AAC Main, AAC-LC, AAC-SSR, AAC-LTP, AAC Scalable, <b>TwinVQ,</b> CELP, HVXC, TTSI, Main synthesis) ...|$|E
50|$|<b>TwinVQ</b> (transform-domain {{weighted}} interleave vector quantization) is {{an audio}} compression technique developed by Nippon Telegraph and Telephone Corporation (NTT) Human Interface Laboratories (now Cyber Space Laboratories) in 1994. The compression technique {{has been used}} in both standardized and proprietary designs.|$|E
50|$|<b>TwinVQ</b> {{is one of}} {{the object}} types defined in MPEG-4 Audio, {{published}} as subpart 4 of ISO/IEC 14496-3 (for the first time in 1999 - a.k.a. MPEG-4 Audio version 1). This object type is based on a general audio transform coding scheme which is integrated with the AAC coding frame work, a spectral flattening module, and a weighted interleave vector quantization module. This scheme reportedly has high coding gain for low bit rate and potential robustness against channel errors and packet loss, since it does not use any variable length coding and adaptive bit allocation. It supports bitrate scalability, both by means of layered <b>TwinVQ</b> coding and in combination with the scalable AAC.|$|E
5000|$|Also MPEG-4 Part 3 audio objects, such as Audio Lossless Coding (ALS), Scalable Lossless Coding (SLS), MP3, MPEG-1 Audio Layer II (MP2), MPEG-1 Audio Layer I (MP1), CELP, HVXC (speech), <b>TwinVQ,</b> Text To Speech Interface (TTSI) and Structured Audio Orchestra Language (SAOL) ...|$|E
50|$|The MPEG-4 Part 3 {{consists}} {{of a variety of}} audio coding technologies - from lossy speech coding (HVXC, CELP), general audio coding (AAC, <b>TwinVQ,</b> BSAC), lossless audio compression (MPEG-4 SLS, Audio Lossless Coding, MPEG-4 DST), a Text-To-Speech Interface (TTSI), Structured Audio (using SAOL, SASL, MIDI) and many additional audio synthesis and coding techniques.|$|E
50|$|In 1999, MPEG-2 Part 7 was updated and {{included}} in the MPEG-4 family of standards and became known as MPEG-4 Part 3, MPEG-4 Audio or ISO/IEC 14496-3:1999. This update included several improvements. One of these improvements was the addition of Audio Object Types which are used to allow interoperability with a diverse range of other audio formats such as <b>TwinVQ,</b> CELP, HVXC, Text-To-Speech Interface and MPEG-4 Structured Audio. Another notable addition in {{this version of the}} AAC standard is Perceptual Noise Substitution (PNS). In that regard, the AAC profiles (AAC-LC, AAC Main and AAC-SSR profiles) are combined with perceptual noise substitution and are defined in the MPEG-4 audio standard as Audio Object Types. MPEG-4 Audio Object Types are combined in four MPEG-4 Audio profiles: Main (which includes most of the MPEG-4 Audio Object Types), Scalable (AAC LC, AAC LTP, CELP, HVXC, <b>TwinVQ,</b> Wavetable Synthesis, TTSI), Speech (CELP, HVXC, TTSI) and Low Rate Synthesis (Wavetable Synthesis, TTSI).|$|E
5000|$|In {{addition}} to the MP4, 3GP and other container formats based on ISO base media file format for file storage, AAC audio data was first packaged in a file for the MPEG-2 standard using Audio Data Interchange Format (ADIF), consisting of a single header followed by the raw AAC audio data blocks. However, if the data is to be streamed within an MPEG-2 transport stream, a self-synchronizing format called an Audio Data Transport Stream (ADTS) is used, consisting {{of a series of}} frames, each frame having a header followed by the AAC audio data. This file and streaming-based format are defined in MPEG-2 Part 7, but are only considered informative by MPEG-4, so an MPEG-4 decoder does not need to support either format. These containers, as well as a raw AAC stream, may bear the [...]aac file extension. MPEG-4 Part 3 also defines its own self-synchronizing format called a Low Overhead Audio Stream (LOAS) that encapsulates not only AAC, but any MPEG-4 audio compression scheme such as <b>TwinVQ</b> and ALS. This format is what was defined for use in DVB transport streams when encoders use either SBR or parametric stereo AAC extensions. However, it is restricted to only a single non-multiplexed AAC stream. This format is also referred to as a Low Overhead Audio Transport Multiplex (LATM), which is just an interleaved multiple stream version of a LOAS.|$|E
40|$|The ISO/IEC MPEG- 4 Audio {{standard}} {{includes the}} <b>TwinVQ</b> encoding tool. This tool {{is suitable for}} low-bit-rate general audio coding, but drawback is the computational complexity of the encoder. To develop a faster <b>TwinVQ</b> encoder, new fast vector quantization algorithms [...] - area localized pre-selection and hit zone masking [...] - are introduced. These algorithms exploit pre- and main-selection procedure scheme of the conjugate structure vector quantization which {{is used in the}} <b>TwinVQ.</b> The improvement is evaluated by measuring the encoding speed and the sound quality of reproduction. 1...|$|E
40|$|The present paper {{describes}} {{a method for}} partial retrieval {{of a piece of}} music using the autocorrelation coefficients computed in the encoding step of <b>TwinVQ</b> (Transform-domain Weighted Interleave Vector Quantization) audio compression (MPEG- 4 audio standard). Our key contribution is to realize partial retrieval of a piece of music that is robust with respect to bit rate using an approximation relation. The approximation relation is {{based on the fact that}} the i-th autocorrelation coefficient with bit rate B 1 of a piece of music computed in the encoding step of <b>TwinVQ</b> audio compression can approximate the j-th autocorrelation ⌊coefficient with bit rate B 2 of the piec...|$|E
40|$|Abstract – The MPEG- 4 <b>TwinVQ</b> {{audio codec}} and the AMR-WB speech codec are {{investigated}} {{in the context}} of a jointly opti-mised turbo transceiver capable of providing unequal error pro-tection. The transceiver advocated consists of serially concate-nated Space-Time Trellis Coding (STTC), Trellis Coded Modula-tion (TCM) and two different-rate Non-Systematic Convolutional codes (NSCs) used for unequal error protection. A benchmarker scheme combining STTC and a single-class protection NSC is used for comparison with the proposed scheme. The audio and speech performance of both schemes is evaluated, when commu-nicating over uncorrelated Rayleigh fading channels. An Eb/N 0 value of about 2. 5 (3. 5) dB is required for near-unimpaired au-dio (speech) transmission, which is about 3. 07 (4. 2) dB from the capacity of the system. 1...|$|E
40|$|The limited {{applicability}} of Shannon’s separation theorem in practical speech/audio systems motivates {{the employment of}} joint source and channel coding techniques. Thus, considerable efforts have been invested in designing various types of joint source and channel coding schemes. This thesis discusses {{two different types of}} Joint Source and Channel Coding (JSCC) schemes, namely Unequal Error Protection (UEP) aided turbo transceivers as well as Iterative Source and Channel Decoding (ISCD) exploiting the residual redundancy inherent in the source encoded parameters. More specifically, in Chapter 2, two different UEP JSCC philosophies were designed for wireless audio and speech transmissions, namely a turbo-detected UEP scheme using twin-class convolutional codes and another turbo detector using more sophisticated Irregular Convolutional Codes (IRCC). In our investigations, the MPEG- 4 Advanced Audio Coding (AAC), the MPEG- 4 Transform-Domain Weighted Interleaved Vector Quantization (<b>TwinVQ)</b> and the Adaptive MultiRate WideBand (AMR-WB) audio/speech codecs were incorporated in the sophisticated UEP turbo transceiver, which consisted of a threestage serially concatenated scheme constituted by Space-Time Trellis Coding (STTC), Trellis Coded Modulation (TCM) and two different-rate Non-Systematic Convolutional codes (NSCs) used for UEP. Explicitly, both the twin-class UEP turbo transceiver assisted MPEG- 4 <b>TwinVQ</b> and the AMR-WB audio/speech schemes outperformed their corresponding single-class audio/speech benchmarkers by approximately 0. 5 dB, in terms of the required Eb/N 0, when communicating over uncorrelated Rayleigh fading channels. By contrast, when employing the MPEG- 4 AAC audio codec and protecting the class- 1 audio bits using a 2 / 3 -rate NSC code, a more substantial Eb/N 0 gain of about 2 dB was achieved. As a further design alternative, we also proposed a turbo transceiver employing IRCCs for the sake of providing UEP for the AMR-WB speech codec. The resultant UEP schemes exhibited a better performance when compared to the corresponding Equal Error Protection (EEP) benchmark schemes, since the former protected the audio/speech bits according to their sensitivity. The proposed UEP aided system using IRCCs exhibits an Eb/N 0 gain of about 0. 4 dB over the EEP system employing regular convolutional codes, when communicating over AWGN channels, at the point of tolerating a SegSNR degradation of 1 dB. In Chapter 3, a novel system that invokes jointly optimised ISCD for enhancing the error resilience of the AMR-WB speech codec was proposed and investigated. The resultant AMR-WB coded speech signal is protected by a Recursive Systematic onvolutional (RSC) code and transmitted using a non-coherently detected Multiple-Input Multiple-Output (MIMO) Differential Space-Time Spreading (DSTS) scheme. To further enhance the attainable system performance and to maximise the coding advantage of the proposed transmission scheme, the system is also combined with multi-dimensional Sphere Packing (SP) modulation. The AMR-WB speech decoder was further developed for the sake of accepting the a priori information passed to it from the channel decoder as extrinsic information, where the residual redundancy inherent in the AMR-WB encoded parameters was exploited. Moreover, the convergence behaviour of the proposed scheme was evaluated with the aid of both Three-Dimensional (3 D) and Two-Dimenstional (2 D) EXtrinsic Information Transfer (EXIT) charts. The proposed scheme benefitted from the exploitation of the residual redundancy inherent in the AMR-WB encoded parameters, where an approximately 0. 5 dB Eb/N 0 gain was achieved in comparison to its corresponding hard speech decoding based counterpart. At the point of tolerating a SegSNR degradation of 1 dB, the advocated scheme exhibited an Eb/N 0 gain of about 1. 0 dB in comparison to the benchmark scheme carrying out joint channel decoding and DSTS aided SP-demodulation in conjunction with separate AMR-WB decoding, when communicating over narrowband temporally correlated Rayleigh fading channels. In Chapter 4, two jointly optimized ISCD schemes invoking the soft-output AMRWB speech codec using DSTS assisted SP modulation were proposed. More specifically, the soft-bit assisted iterative AMR-WB decoder’s convergence characteristics were further enhanced by using Over-Complete source-Mapping (OCM), as well as a recursive precoder. EXIT charts were used to analyse the convergence behaviour of the proposed turbo transceivers using the soft-bit assisted AMR-WB decoder. Explicitly, the OCM aided AMR-WB MIMO transceiver exhibits an Eb/N 0 gain of about 3. 0 dB in comparison to the benchmark scheme also using ISCD as well as DSTS aided SP-demodulation, but dispensing with the OCM scheme, when communicating over narrowband temporally correlated Rayleigh fading channels. Finally, the precoded soft-bit AMR-WB MIMO transceiver exhibits an Eb/N 0 gain of about 1. 5 dB in comparison to the benchmark scheme dispensing with the precoder, when communicating over narrowband temporally correlated Rayleigh fading channels. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|E

