1116|4891|Public
2500|$|Lenna (<b>test</b> <b>image),</b> the {{traditional}} standard image used to <b>test</b> <b>image</b> processing algorithms ...|$|E
50|$|A {{standard}} <b>test</b> <b>image</b> is {{a digital}} image file used across different institutions to <b>test</b> <b>image</b> processing and image compression algorithms. By {{using the same}} standard test images, different labs are able to compare results, both visually and quantitatively.|$|E
5000|$|... #Caption: Old Zeiss pocket {{stereoscope}} with original <b>test</b> <b>image</b> ...|$|E
30|$|For all the <b>test</b> <b>images,</b> their {{visual quality}} has been improved; however, {{improvement}} is quite different, the largest improvement is observed for simple structure images as, e.g., the <b>test</b> <b>images</b> ## 3, 15, 23; the smallest improvement takes {{place for the}} most complex structure <b>test</b> <b>images</b> as, e.g., the <b>test</b> <b>images</b> ## 5, 13, and 14.|$|R
3000|$|... {{take place}} for the most textural <b>images</b> as the <b>test</b> <b>images</b> ## 5, 8, 13, 18. For other <b>test</b> <b>images,</b> the values [...]...|$|R
30|$|The trained {{classifier}} is {{used for}} classifying <b>test</b> <b>images.</b> Similarly to the training image dataset, two groups of <b>test</b> <b>images,</b> {{both positive and negative}} image sets are used. Using the model each test picture gets a certainty score.|$|R
5000|$|Lenna - {{widely used}} {{standard}} <b>test</b> <b>image</b> in image processing experiments ...|$|E
5000|$|Lenna, the {{traditional}} standard image used to <b>test</b> <b>image</b> processing algorithms ...|$|E
5000|$|To {{find this}} optimal , the authors propose to insert the <b>test</b> <b>image</b> I into the {{training}} ensemble for the congealing process. Since {{we assume that}} the <b>test</b> <b>image</b> is drawn from one of the classes , congealing will provide a corresponding [...] which maps I to its latent image. The latent image can now be classified.|$|E
30|$|Dataset I {{included}} 65 <b>test</b> <b>images</b> (13 cameras × 5 contents). University {{students were}} used as observers (n = 25). They were all naïve with respect to image quality. Before the <b>test,</b> all <b>test</b> <b>images</b> and high- and low-quality example images were shown to subjects {{at a rate of}} one second per picture. The reference image was shown on one display during the test, and the <b>test</b> <b>images</b> on the other display. The image-quality value of the reference image was set to 90 on a scale of 0 - 100. The reference image functioned as a high-quality anchor image. A quality value of 90 out of 100 left some latitude for the observers with high-quality <b>test</b> <b>images.</b> Reference images were tuned based on consumer preference expectations. Typical consumers prefer sharp, high contrast, and colorful images.|$|R
40|$|This paper {{addresses}} {{the problem of}} multi-class image classification by proposing a novel multi-view multi-sparsity kernel reconstruction (MMKR for short) model. Given <b>images</b> (including <b>test</b> <b>images</b> and training images) representing with multiple visual features, the MMKR first maps them into a high-dimensional space, e. g., a reproducing kernel Hilbert space (RKHS), where <b>test</b> <b>images</b> are then linearly reconstructed by some representative training images, rather than all of them. Furthermore a classification rule is proposed to classify <b>test</b> <b>images.</b> Experimental results on real datasets show {{the effectiveness of the}} proposed MMKR while comparing to state-of-the-art algorithms...|$|R
3000|$|... (n) {{observed}} for the noisy <b>test</b> <b>images</b> ## 2, 3, 4, 15, 16, 20, and 23 {{are within the}} limits 37.5... 38 dB, i.e., considerably larger than for the case of σ 2 = 65. For the most complex structure images as, e.g., the <b>test</b> <b>images</b> ## 5, 8, 13, and 14, the values of PSNR-HVS-M [...]...|$|R
5000|$|... #Caption: Actual <b>test</b> <b>image</b> of jelly beans {{from the}} USC-SIPI image database.|$|E
5000|$|... {{while the}} amount of {{information}} extracted from the <b>test</b> <b>image</b> is given as ...|$|E
5000|$|To {{use this}} model for classification, we must {{estimate}} the model with the maximum posterior probability given an observed image [...] An application of Bayes' rule to [...] and parametrization by the transformation [...] gives a difficult integral which the authors approximate, and then seek the best transform [...] That is, the transformation which maps the <b>test</b> <b>image</b> to its latent image. Once this transformation is found, the <b>test</b> <b>image</b> {{can be transformed}} into its latent image, and a nearest neighbor classifier based on Hausdorff distance between images is used to classify the latent image (and thus the <b>test</b> <b>image)</b> as belonging to a particular class [...]|$|E
5000|$|Ahn has {{described}} countermeasures which prevent players from [...] "cheating" [...] the game, and introducing false data into the system. By giving players occasional <b>test</b> <b>images</b> for which common labels are known, {{it is possible}} to check that players are answering honestly, and a player's guesses are only stored if they successfully label the <b>test</b> <b>images.</b>|$|R
3000|$|The inputs to the {{framework}} are the reference image Ir {{and the images}} captured with different cameras, called <b>test</b> <b>images</b> It. Before the analysis, the reference and <b>test</b> <b>images</b> are scaled to the same resolution. The [...] "Scene analysis" [...] component characterizes the scene using the reference image and selects candidate blocks for measurement. The output of the [...] "Scene analysis" [...] component is the vector of candidate points, CP, which includes the pixel coordinates of the so-called candidate blocks. The [...] "Correspondence areas" [...] component locates the blocks in the <b>test</b> <b>images</b> that correspond to the candidate blocks. This location {{is based on the}} correspondence features Fr and Ft between the reference and <b>test</b> <b>images.</b> The correspondence features are searched using the well-known SIFT algorithm (scale invariant feature transform). The SIFT algorithm is implemented in the [...] "Correspondence features" [...] component. The correspondence blocks (B [...]...|$|R
30|$|In the MOS experiment, Lenna, Lighthouse, Pepper, and Title {{are used}} as <b>test</b> <b>images.</b>|$|R
5000|$|... #Caption: Pocket {{stereoscope}} with original <b>test</b> <b>image.</b> Used {{by military}} to examine stereoscopic pairs of aerial photographs.|$|E
50|$|Here, four {{different}} gradient operators {{are used to}} estimate {{the magnitude of the}} gradient of the <b>test</b> <b>image.</b>|$|E
5000|$|... == Example {{comparisons}} == Here, {{four different}} gradient operators {{are used to}} estimate {{the magnitude of the}} gradient of the <b>test</b> <b>image.</b>|$|E
30|$|The next {{experiments}} {{show the}} robustness against some geometrical {{attacks on the}} <b>test</b> <b>images.</b>|$|R
30|$|The SIFT {{algorithm}} was applied, and the 20 nearest correspondence {{features of}} the candidate block center in the reference image {{were used for the}} correspondence-block searching in the <b>test</b> <b>images.</b> The block centers in the <b>test</b> <b>images</b> were located by calculating the angle and length of the vectors from the feature points to the candidate block centers in the reference image.|$|R
40|$|In {{the present}} work we analyze the {{performance}} of orthogonal and Biorthogonal wavelet filters for image compression on variety of <b>test</b> <b>images.</b> The <b>test</b> <b>images</b> are of different size and resolution. The compression performance is measured, objectively peak {{signal to noise ratio}} and subjectively visual quality of image and it is found that Biorthogonal wavelets outperform the orthogonal ones in both the criteria...|$|R
5000|$|... #Caption: An Ishihara <b>test</b> <b>image</b> {{as seen by}} {{subjects}} with normal color vision and by those {{with a variety of}} color deficiencies ...|$|E
5000|$|No-{{reference}} (NR) methods - NR metrics try {{to assess}} {{the quality of a}} <b>test</b> <b>image</b> without any reference to the original one.|$|E
50|$|A 2012 {{paper on}} {{compressed}} sensing used {{a photo of}} the model Fabio Lanzoni as a <b>test</b> <b>image</b> to draw attention to this issue.|$|E
3000|$|... pixels <b>test</b> <b>images</b> {{have been}} chosen, namely, Baboon, Barbara, and Goldhill which are {{sufficiently}} different in content.|$|R
30|$|As a whole, the <b>test</b> <b>images</b> of {{this review}} are ideal as objects {{to assess the}} {{performance}} and robustness of the three algorithms/programs on both noise-free and noisy images. As a matter of fact, one may consider the calculated <b>test</b> <b>images</b> to be reasonable equivalents of images that have been recorded at different signal-to-noise ratios with a “perfect microscope” where the microscope’s point spread function is the Dirac delta function.|$|R
40|$|Figure 6. The {{relation}} {{between the number of}} macroblocks of a region and the threshold used to terminate the region growing process. Figure 3. Some <b>test</b> <b>images.</b> Figure 4. The detected skin colour regions in the <b>test</b> <b>images.</b> [3] F. Idis and S. Panchanathan, Review of image and video indexing techniques, Journal of Visual Communication and Image Representation, 8 (2), 1997, pp. 146 - 166. [4] D. LeGall, MPEG: A video compression standard for multimedi...|$|R
5000|$|Full-reference (FR) methods - FR metrics try {{to assess}} {{the quality of a}} <b>test</b> <b>image</b> by {{comparing}} it with a reference image that is assumed to have perfect quality.|$|E
5000|$|... #Caption: Lenna <b>test</b> <b>image</b> {{compressed}} using version 0.30 lossy WebP compression at quality 75 with accompanying RGB histograms. Note {{the breaks}} in the histogram of the compressed image compared to the source.|$|E
50|$|June 17, 2004: SMART-1 took a <b>test</b> <b>image</b> of Earth {{with the}} camera that would later be used for Moon closeup pictures. It shows parts of Europe and Africa. It was taken on May 21 with the AMIE camera.|$|E
30|$|To each of {{the three}} {{original}} <b>test</b> <b>images,</b> additive white Gaussian noise (AWGN) was added with a standard deviation σ= 15.|$|R
3000|$|The SURE {{optimization}} {{approach for}} SigShrink is now given for some standard <b>test</b> <b>images</b> corrupted by AWGN. We consider the standard [...]...|$|R
30|$|Using the {{methodology}} mentioned in Section 3, results are discussed {{here as well}} as our visual evaluations of the <b>test</b> <b>images.</b> We <b>tested</b> the following on the following <b>test</b> <b>images</b> summarized in Table 1. A visual comparison is provided against the ground-truth image as well as numerical metrics such as PSNR (peak signal to noise ratio), RMSE (root mean squared error), and SSIM (structural image similarity). Note that the scaling factor used in the experiments is 4.|$|R
