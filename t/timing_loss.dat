3|91|Public
50|$|Each {{of these}} factors and {{especially}} their combination leads to extreme modes and related stresses (not to mention other circumstances that faced operational staff of plants). However, those approaches are difficult to implement because of financial and <b>timing</b> <b>loss.</b> Except factors caused by external operational activity there are many social stressors as well.|$|E
5000|$|The {{card punch}} had a maximum rate of 150 cards per minute. Timing was quite {{critical}} throughout {{the operation of}} the card punch, the card reader and the printer, all being based on electromechanical principles. The basic card punch mechanism was manufactured by Bull, a French company which owned patents on 80 column punch card machines. The machine came in two versions, the P147 and the P67, the main difference being electromagnetic clutch or a solenoid operated mechanical [...] "dog" [...] clutch to initiate a punch cycle. Since many gears, electrical contact cams were affixed to the main shaft with taper pins, the P 67 with its severe stopping dog clutch would cause <b>timing</b> <b>loss</b> more frequently than the P 147. Most emergency maintenance time was spent replacing worn and damaged taper pins and retiming the machine. The card punch had a preread station, a punch station and a checkread station. The machine could be quite difficult to maintain and required much skill to troubleshoot and maintain. The machine cycle was oddly divided into 420 [...] "points" [...] or [...] "Bull degrees".|$|E
40|$|DE 102009051186 A 1 UPAB: 20100520 NOVELTY - The circuit has {{a direct}} current/direct current {{converter}} (B) with a switching device (S 1) that is synchronized to direct current conversions. A controller (St) controls the switching device, where the controller is designed {{in such a manner}} that the direct current/direct current converter is taken into account during <b>timing</b> <b>loss.</b> A solar cell or a group of solar cells (SM) is attached on inputs (3, 4) of the direct current/direct current converter, where the solar cell or a group of solar cells is operated in a predetermined operating region or operating point. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (1) a solar generator comprising a solar module (2) a method for controlling a direct current/direct current converter. USE - Matching circuit for use in a solar generator for an electric system in a series-connected solar cell or series-connected group of solar cells using a direct current/direct current converter (all claimed). ADVANTAGE - The circuit is designed in such a manner that the current is transmitted from the solar module into the direct current/direct current converter without any loss when the direct current/direct current converter is not operated...|$|E
30|$|The {{message from}} a cell might be not {{received}} due to incorrect <b>timing,</b> connection <b>losses,</b> or {{failure in the}} cell, which cannot be considered a univocal consequence of a sleeping cell failure (as described in Section  5). Therefore, the conditional probabilities for the indicator of that cell are assumed “ 1 ” for both status, which means that such input is not considered in the classifier.|$|R
30|$|Accurate and {{reliable}} synchronization signals {{play a critical}} role in synchrophasor systems. They provide the common timing reference for data measurement and synchronization, and largely determine the accuracy and availability of synchrophasor data. However, according to the statistics in Part I, a large number of PMUs and FDRs experienced <b>timing</b> signal <b>loss</b> (i.e. GPS signal loss). The potential reasons and solutions are explored in this section.|$|R
40|$|Telemetry {{signals from}} several {{channels}} are aligned {{in time and}} combined by the Real-Time Combiner (RTC) {{in order to increase}} the strength of the total signal. In this article, the impact of the timing jitter in the RTC on the bit/symbol error rate is investigated. Equations are derived for the <b>timing</b> jitter <b>loss</b> associated with the coded and uncoded channels. Included are curves that depict the bit-symbol error rate vs. E sub b/N sub 0 and E sub s/N sub 0 for some typical telemetry conditions. The losses are typically below 0. 1 dB...|$|R
30|$|However, {{the actual}} {{measurement}} and communication systems inevitably involve data quality issues. For instance, a measurement device may cause a data accuracy issue because of device errors or <b>timing</b> signal <b>loss</b> [7], and a communication link may induce data loss and latency issues due to unintentional reasons (e.g., equipment malfunctions and communication infrastructure limits) or intentional cyber-attacks [8, 9]. These data quality issues may impact or even disable certain application functionalities. Consequently, {{a great deal}} of research effort in academia and industry has been devoted to addressing the data quality issue, especially the data accuracy, latency, and loss issues.|$|R
40|$|This paper studies whether {{bank credit}} fuels asset prices. Financial {{deregulation}} during the 1980 s allowed keiretsus to obtain finance publicly and reduce {{their dependence on}} banks. Banks that lost these blue-chip customers increased their property lending, and serve as an instrument for the supply of real estate loans. Using this instrument, I find that a 0. 01 increase in a prefecture's real estate loans {{as a share of}} total loans causes 14 - 20 % higher land inflation compared with other prefectures over the 1981 - 91 period. The <b>timing</b> of <b>losses</b> of keiretsu customers also coincides with subsequent land inflation in a prefecture. Copyright 2008 The Ohio State University. ...|$|R
30|$|This work {{studies the}} data quality issue for synchrophasor applications. In Part I, the data quality issue is {{reviewed}} {{in a comprehensive}} way and in Part II the potential reasons and solutions for the data quality issue are investigated. Specifically, Part II pays particular attention to synchronization signal loss and synchrophasor data loss events. For the former, the historical <b>timing</b> signal <b>loss</b> events are analyzed and the potential reasons and solutions are discussed. For the latter, the synchrophasor data loss, especially the scenario of {{a small amount of}} synchrophasor data loss, is studied, and the possible estimation methods like substitution, interpolation, and forecasting methods are examined. The estimation methods can improve the accuracy and availability of synchrophasor measurements, and mitigate the effect of data loss on synchrophasor applications.|$|R
40|$|Abstract — Design and {{analysis}} of low complexity timing error detectors (TEDs) for quasi-orthogonal space-time block coding systems are presented. The detectors operate on data symbols and approximate decision variables, producing timing error mea-surement robust to channel fading. In addition to the estimator S-curve, we obtain the estimation error variance and TED SNR, with the analysis carried out under the assumptions of perfect data and channel knowledge at the receiver. Simulations are {{used to examine the}} effects of decision errors on the detector characteristics, and to evaluate the overall system performance, where the proposed TEDs are incorporated into the receiver timing loop. Receivers with perfect channel knowledge and pilot-based channel estimation are considered. Symbol error rate results show <b>timing</b> synchronization <b>loss</b> of less than 0. 5 dB for a receiver with perfect channel information. I...|$|R
40|$|Manufacturing process {{variations}} lead to {{circuit timing}} variability and a corresponding <b>timing</b> yield <b>loss.</b> Traditional corner analysis consists of checking all process corners (combinations of process parameter extremes) {{to make sure}} that circuit timing constraints are met at all corners, typically by running static timing analysis (STA) at every corner. This approach is becoming too expensive due to the exponential {{increase in the number of}} corners with modern processes. As an alternative, we propose a linear-time approach for STA which covers all process corners in a single pass. Our technique assumes a linear dependence of delay on process parameters and provides tight bounds on the worst-case circuit delay. It exhibits high accuracy (within 1 - 3 %) in practice and, if the circuit has m gates and n relevant process parameters, the complexity of the algorithm is O(mn). 1...|$|R
40|$|Abstract—We {{analyze the}} {{properties}} of a class of low com-plexity timing error detectors {{for the purpose of}} timing error tracking in orthogonal space-time block coding receivers. For symmetrical signal constellations, under the assumptions of ideal data decisions and channel knowledge at the receiver, expressions for the S-curve, estimation error variance and the detector signal-to-noise ratio are derived. Simulations are used to confirm the analytical results and to evaluate the effects of data decision errors on the estimator properties. Symbol-error-rate performance is evaluated for a system operating in a frequency-flat Rayleigh fading environment, where the <b>timing</b> synchronization <b>loss</b> is found to be less than 0. 3 dB. In addition to receiver with perfect channel state information, results for pilot-based channel estimation are included in order {{to examine the effects of}} channel estimation errors on timing synchronization. I...|$|R
40|$|Despite {{increased}} {{attention paid to}} the advent and development of state merit scholarship policies (such as Georgia’s Helping Outstanding Pupils Educationally) and some evidence that suggests differences in scholarship retention by socioeconomic status or other student characteristics, little empirical work has explored factors affecting scholarship retention. Moreover, no work has explored what affects the <b>timing</b> of scholarship <b>loss.</b> This study employs event history modeling to ascertain not only what factors impact students’ retention of the West Virginia PROMISE Scholarship but also when these factors are most influential...|$|R
40|$|Video {{transmission}} {{over the}} Internet is becoming {{very popular with}} the majority of applications transporting stored pre-encoded video from server to client. These new applications have strict <b>timing</b> and <b>loss</b> requirements, which the current deployment of the Internet is unable to guarantee. To enable quality streaming of real time video, the application has to be rate adaptive and use feedback signalling to learn about the network condition, in order to adjust their sending rate to match the available network bandwidth. In this paper we confront this problem by describing: (1) an end-to-end protocol for the transportation of real time video, which gracefully degrades picture quality adapts the video transmission rate (quality) : (2) an efficient and error resilient packetisation scheme: and (3) an effective feedback control scheme that is responsive to varying network conditions. This is achieved by the integration and cooperation between the application and transport layers. ...|$|R
40|$|Process {{variation}} {{has become}} a major concern in the design of many nanometer circuits, including interconnect pipelines. This paper develops closed-form models to pre-dict the delay distribution of an interconnect pipeline stage and the slew distributions of all the nets in the circuit. Also, a buffer sizing and re-placement algorithm is presented to minimize the area of interconnect pipelines while meeting the delay and slew constraints. Experiments show that ig-noring location dependent variation can cause a <b>timing</b> yield <b>loss</b> of 8. 8 % in a delay limited circuit, and the area can be improved by over 10 % when the location depen-dent variation and residual random variation are under-stood and separated. Furthermore, under equivalent area, an interconnect pipeline optimized with only sizing changes may violate the slew constraint on over 50 % of the nets, so location change is needed to best optimize these circuits. 1...|$|R
40|$|Abstract—Manufacturing process {{variations}} lead to {{circuit timing}} variability and a corresponding <b>timing</b> yield <b>loss.</b> Traditional corner analysis consists of checking all process corners (combinations of process parameter extremes) {{to make sure}} that circuit timing constraints are met at all corners, typically by running static timing analysis (STA) at every corner. This approach is becoming too expensive due to {{the increase in the number}} of corners with modern processes. As an alternative, we propose a linear-time approach for STA which covers all process corners in a single pass. Our technique assumes a linear dependence of delays and slews on process parameters and provides estimates of the worst case circuit delay and slew. It exhibits high accuracy in practice, and if the circuit has m gates and n relevant process parameters, the complexity of the algorithm is O(mn). Index Terms—Hyperplanes, multicorner, process variations, static timing analysis (STA) ...|$|R
40|$|The {{problem of}} device {{synchronization}} in a distributed measuring system can present a designer {{with a range}} of choices and solutions, depending on technical specifications, cost, feasibility, robustness and other requirements. In wireless sensor networks (WSNs), synchronization mechanisms often have to be run on lean resources and, in particular, the active and "sleep" time schedules of low-power nodes introduce specific constraints which impact, for instance, on the rate of exchange of <b>timing</b> messages. <b>Loss</b> of <b>timing</b> packets could also be particularly critical. In this paper we analyse how clock instability, timestamp uncertainty and the particular implementation of a servo clock affect the performances of a synchronization algorithm, assuming relevant information are received at a low rate (and, occasionally, missing). An accurate study based on the effect of measurement uncertainty will evaluate the performance of a low-power synchronization mechanism and its robustness to information loss...|$|R
40|$|Recently HIV-infected {{individuals}} have virus-specific responses characterized by IFN-γ/IL- 2 secretion and proliferation rarely seen in chronic infection. To investigate the <b>timing</b> of <b>loss</b> of HIV-specific T-cell function, we screened cells from 59 treatment-naïve HIV-infected individuals with known dates of infection for proteome-wide responses secreting IFN-γ/IL- 2 and IFN-γ alone by ELISPOT. HIV peptide-specific proliferation {{was assessed by}} carboxyfluorescein diacetate succinimidyl ester (CFSE) dilution. The contribution of IFN-γ/IL- 2 and IFN-γ-only secretion to the total HIV-specific response was compared in subjects infected < 6, 6 – 12, and 12 – 36 mo earlier. The frequency of IFN-γ/IL- 2 -secreting cells fell, while that of IFN-γ-only secretion rose with time from infection. HIV peptide-specific proliferative responses were almost exclusively mediated by CD 8 + T cells, and were significantly lower in cells obtained from the 12 – 36 mo versus <[*] 6 mo post-infection groups. By {{the second year of}} infection {{there was a significant difference}} in these functions compared to those assessed within 6 mo...|$|R
40|$|Increasing {{differences}} in United States energy consumption and production has influenced {{the passing of}} legislation for biomass fuel production. To determine feasibility of energy crops for alternative fuels, {{research is needed to}} investigate dry matter yield over an extended harvest season; physical characteristics need to be described for potential harvesting problems; chemical characteristics described to identify selective harvest potential, optimal harvest <b>timing,</b> <b>losses</b> during harvest and storage; various harvest techniques investigated to identify potential cost savings; and impact of various storage techniques on quantity and quality of deliverable biomass. This study investigated the use of two sorghum varieties as a potential bioenergy feedstock where 20 ha were planted for three years. Standing crop samples were collected from August through January to document changes in dry matter yield, moisture, height, fiber content, proximate and ultimate analysis. The sorghum was cut and conditioned ? as a two-cutting ratoon or single-cutting ? using various mower-conditioners and windrow samples taken daily to determine best method of field drying, quantify dry matter loss and soil entrainment. Two storage methods were utilized ? baling with wrapping in a tubeline, and chopping and compressing in bag using a modified cotton module builder ? to determine best method of storage for reduced dry matter loss. The optimal time of harvest for maximum dry matter occurred with the November once-cut where 30 Mg ha^- 1 was documented, but comparable yields were observed with the two-cutting scenario. Fiber content increased with maturity, peaked, and declined, while ash content and moisture decreased with maturity. The achievement of 55 % moisture in January shows field curing to be necessary for transportation at any significant distance, but soil entrainment ? as measured by ash concentration ? was not found to be a significant problem after conditioning, multiple windrow inversions, and harvesting. The geometric mean length of particle was determined to be 1. 4 to 3. 7 times lower than nominal chop length, indicating potential cost savings in comminution. Dry matter loss estimates during storage proved difficult due to mobility of moisture throughout the packages, where losses were documented up to 40 %. Module packages tended to have lower dry matter and constituent losses than bales...|$|R
30|$|We {{applied the}} control method {{based on the}} time-state control form to control a mobile robot in auto-parking situations. The {{proposed}} controller includes the parameter α, which is allowed to switch at arbitrary <b>timings</b> without <b>loss</b> of {{the stability of the}} system. The robot that employed the proposed nonlinear controller switched its traveling direction automatically to avoid collisions with obstacles and reached the target position. However, the shape of the robot gave problems. We used the switchable parameter α to solve the problem and showed the availability of switching the parameter. Furthermore, by appropriately switching the parameter α and the traveling direction, the robot could reach the target faster in the simulations and experiments. In this method, only one parameter is temporarily changed and complicated recalculations such as path optimizations are not required. When the obstacle map was known in advance, the appropriate values of the parameter and the switching points of the traveling direction were searched using the genetic algorithm. In the auto-parking experiments that used the search results, the robot reached the target position faster.|$|R
40|$|BACKGROUND/AIMS: As {{evidence}} accumulates {{relating to}} mother-to-child (vertical) transmission of hepatitis C virus (HCV), it is timely {{to draw up}} guidelines for the clinical management of HCV infected pregnant women and their children. METHODS: A review of evidence from the European Paediatric HCV Network (EPHN) prospective study of HCV infected women and their children and other published studies. Meeting of EPHN clinical experts to reach a consensus on recommendations for management. Each recommendation was graded according {{to the level of}} evidence. RESULTS/CONCLUSIONS: Although several risk factors for mother-to-child transmission have been identified, none are modifiable and there are currently no interventions available to prevent vertical transmission of HCV. Data on <b>timing</b> of <b>loss</b> of maternal antibodies and reliability of diagnostic tests inform the optimum follow-up schedule for confirmation or exclusion of infection in children born to HCV infected women. Based on the current evidence, routine antenatal screening for HCV should not be introduced and neither elective caesarean section nor avoidance of breastfeeding should be recommended to HCV infected women to prevent mother-to-child transmission of HCV. HCV/HIV co-infected women should follow existing HIV guideline...|$|R
40|$|Reciprocating-piston devices {{can be used}} as high-efficiency {{compressors}} and/or expanders. With {{an optimal}} valve design and by carefully adjusting valve <b>timing,</b> pressure <b>losses</b> during intake and exhaust can be largely reduced. The main loss mechanism in reciprocating devices is then the thermal irreversibility due to the unsteady heat transfer between the compressed/expanded gas and the surrounding cylinder walls. In this paper, pressure, volume and temperature measurements in a piston-cylinder crankshaft driven gas spring are compared to numerical results. The experimental apparatus experiences mass leakage while the CFD code predicts heat transfer in an ideal closed gas spring. Comparison of experimental and numerical results allows one to better understand the loss mechanisms in play. Heat and mass losses in the experiment are decoupled and the system losses are calculated over a range of frequencies. As expected, compression and expansion approach adiabatic processes for higher frequencies, resulting in higher efficiency. The objective {{of this study is to}} observe and explain the discrepancies obtained between the computational and experimental results and to propose further steps to improve the analysis of the loss mechanisms...|$|R
40|$|Manufacturing process {{variations}} are {{the primary}} cause of <b>timing</b> yield <b>loss</b> in aggressively scaled technologies. In this paper, we analyze the impact of process variations on the throughput (rate) characteristics of embedded systems comprised of multiple voltage-frequency islands (VFIs) represented as component graphs. We provide an efficient, yet accurate method to compute the throughput of an application in a probabilistic scenario and show that systems implemented with multiple VFIs are more likely to meet throughput constraints than their fully synchronous counterparts. The proposed framework allows designers to investigate the impact of architectural decisions such as the granularity of VFI partitioning on their designs, while determining the likelihood of a system meeting specified throughput constraints. An implementation of the proposed framework is accurate within 1. 2 % of Monte Carlo simulation while yielding speedups ranging from 78 X- 260 X, for a set of synthetic benchmarks. Results on a real benchmark (MPEG- 2 encoder) show that a nine clock domain implementation gives 100 % yield for a throughput constraint for which a fully synchronous design only yields 25 %. For the same throughput constraint, a three clock domain architecture yields 78 %. 1...|$|R
40|$|Manufacturing process variations, {{leading to}} {{variability}} in circuit delay, can cause excessive <b>timing</b> yield <b>loss</b> if not accounted for. Many techniques {{have been proposed}} for statistical timing analysis, which operate at a late stage of the design, by which time many design decisions have already been made. In this paper, we develop an early approach to statistical timing and yield analysis. With early access to timing yield information, one can take corrective action {{at a time when}} it is still possible to do so. The proposed technique does not propagate distributions through the circuit. Instead, it provides “yield-specific ” margins on the maximum and minimum nominal circuit delays (setup and hold margins) which, if applied during standard (deterministic) timing analysis, would guarantee the desired yield. Starting from a generic circuit representation based on classes of paths with different depths, we find a lower bound expression on the timing yield. This lower bound is guaranteed for unknown within-die correlations, and hence the approach can be applied pre-placement. We also propose a novel method that allows “controlled ” budgeting of yield loss between setup and hold violations. 1...|$|R
40|$|Abstract—A general {{framework}} {{for the design of}} low complex-ity timing error detectors (TEDs) for orthogonal space-time block code (OSTBC) receivers is proposed. Specifically, we derive suf-ficient conditions for a difference-of-threshold-crossings timing error estimate to be robust to channel fading. General expressions for the S-curve, estimation error variance and the signal-to-noise ratio are also obtained. As the designed detectors inherently depend on the properties of the OSTBC under consideration, we derive and evaluate the properties of TEDs for a number of known codes. Simulations are used to assess the system performance with the proposed timing detectors incorporated into the receiver timing loop operating in tracking mode. While the theoretical derivations assume a receiver with perfect channel state information and symbol decisions, simulation results include performance for pilot-symbol-based channel estimation and data symbol detection errors. For the case of frequency-flat Rayleigh fading and QPSK modulation, symbol-error-rate results show <b>timing</b> synchronization <b>loss</b> of less than 0. 3 dB for practical timing offsets. In addition it is shown that the receiver is able to track timing drift with a normalized bandwidth of up to 0. 001. Index Terms—Synchronization, symbol timing estimation, tim-ing error tracking, orthogonal space-time block coding. I...|$|R
40|$|Designing {{high-performance}} very large-scale integration (VLSI) chips {{has become}} more challenging than ever due to nanometer effects and accelerating time-to-market cycles. Due to the interconnect delay dominance, a small routing change in the design can increase coupling capacitances on its neighboring paths and significantly increase their path delays. This can cause new timing violations and result in design iterations. While timing convergence is {{getting harder and harder}} to achieve, the accelerating time-to-market cycles further aggravate the problem. Process variations result in interconnect variations, threshold voltage variations, leakage power variations, etc. These effects not only generate reliability issues but also make the circuit performance deviate from the design specification and cause <b>timing</b> yield <b>losses.</b> Due to the increasing process variations in nanometer technologies, timing yield has become an important design concern because it directly affects the manufacturing cost. Clock designs have significant impacts on both timing convergence and timing yield. A carefully de-signed clock distribution network can reduce design-inherited clock skews, the discrepancies between designer intended clock skews and achieved clock skews under perfect process conditions. This can im-prove circuit performance and timing convergence. A clock distribution network can also be optimize...|$|R
40|$|This paper {{presents}} a network architecture {{able to provide}} seamless and ubiquitous communication across multiple and heterogeneous technologies. It addresses seamless mobility with quality of service and authorization services {{in order to support}} multimedia traffic in a 4 G network. The paper addresses the description of the mobility architecture, the integration effort performed in the framework of the IST-Daidalos project, and comments on the evaluation process used to assess the performance of the proposed architecture. We show that this architecture, supporting both mobile terminal and network initiated handovers, is able to prepare all the handover process in the new network, authorized in terms of the profile of the users and the resources available on the new network. In terms of the integration process, it has been significantly difficult in such a complex network: the integration of all the mobility related modules was a cumbersome process, and several issues appeared during this process, such as Mobile IPv 6 implementation instability and different programming styles. In terms of the performance results achieved, we showed that this architecture is able to assure fast handover of mobile terminals with ongoing communications, with small handover <b>timings</b> and <b>losses</b> during handover...|$|R
40|$|This paper {{discusses}} {{the results of}} the thermal-hydraulic investigations of the Total Loss of Feed Water (TLFW). RELAP 5 /MOD 3. 2. computer code has been used to simulate TLFW of VVER- 1000 Nuclear Power Plant (NPP). The model provides a significant analytical capability for the specialists working in the field of NPP safety. This paper provides a discussion of various RELAP 5 parameters calculated for the TLFW scenario. The purpose of the scenario is to predict the behavior of NPP and to help correctly define the operator action for validation and verification of Emergency Operating Instructions (EOIs). EOI analyses are designed to provide the response of monitored plant parameters to identify symptoms available to the operators, <b>timing</b> of <b>loss</b> of critical safety functions and timing of operator actions to avoid loss of critical safety functions or core damage. The principal acceptance criteria for EOIs are averting the onset of core damage. Two scenarios for TLFW are presented in the report: • Base case – Total loss of feed water without operator actions. In Base case is investigated plant response to the event. • TLFW with operator actions. In this analysis are involved additional failures of plant equipment...|$|R
40|$|In higher eukaryotes, {{heritable}} {{gene silencing}} {{is associated with}} histone deacetylation and late replication timing. In Saccharomyces cerevisiae, the histone deacetylase Rpd 3 regulates gene expression and also modulates replication timing; however, these mechanisms have been suggested to be independent, and no global association has been found between replication timing and gene expression levels. Using 5 -Bromo- 2 ′-deoxyuridine (BrdU) incorporation to generate genome-wide replication profiles, we identified > 100 late-firing replication origins that are regulated by Rpd 3 L, which is specifically targeted to promoters to silence transcription. Rpd 3 S, which recompacts chromatin after transcription, plays a primary role at {{only a handful of}} origins, but subtly influences initiation timing globally. The ability of these functionally distinct Rpd 3 complexes to affect replication initiation timing supports the idea that histone deacetylation directly influences initiation <b>timing.</b> Accordingly, <b>loss</b> of Rpd 3 function results in higher levels of histone H 3 and H 4 acetylation surrounding Rpd 3 -regulated origins, and these origins show a significant association with Rpd 3 chromatin binding and gene regulation, supporting a general link between histone acetylation, replication timing, and control of gene expression in budding yeast. Our results also reveal a novel and complementary genomic map of Rpd 3 L- and Rpd 3 S-regulated chromosomal loci...|$|R
40|$|Since the mid- 19 th century, western Oregon 2 ̆ 7 s Willamette Valley {{has been}} a source of remains from a wide variety of extinct megafauna. Few of these have been {{previously}} described or dated, but new chronologic and isotopic analyses in conjunction with updated evaluations of stratigraphic context provide substantial new information on the species present, <b>timing</b> of <b>losses,</b> and paleoenvironmental conditions. Using subfossil material from the northern valley, we use AMS radiocarbon dating, stable isotope (δ 13 C and δ 15 N) analyses, and taxonomic dietary specialization and habitat preferences to reconstruct environments and to develop a local chronology of events that we then compare with continental and regional archaeological and paleoenvironmental data. Analysis of twelve bone specimens demonstrates the presence of bison, mammoth, horse, sloth, and mastodon from 15, 000 – 13, 000 cal yr BP. The latest ages coincide with changing regional climate corresponding to the onset of the Younger Dryas. It is suggested that cooling conditions led to increased forest cover, and, along with river aggradation, reduced the area of preferred habitat for the larger bodied herbivores, which contributed to the demise of local megafauna. Archaeological evidence for megafauna–human interactions in the Pacific Northwest is scarce, limiting our ability to address the human role in causing extinction...|$|R
30|$|To further test our {{identification}} assumption, {{we follow}} Marcus (2013) in repeating our analysis using placebo regressions {{in which we}} pretend that any observed involuntary job loss takes place either (i) 1  year or (ii) 2  years earlier than it in fact did. This effectively involves replacing the measure of recent job loss {{with a measure of}} job loss in the year ahead (and separately, 2  years ahead) allowing us to investigate any trends in mental health before job loss occurs. As expected, we find that the significant mental health penalties associated with job loss discussed above disappear when we use the placebo job loss measure. Thus, our results are driven by the actual <b>timing</b> of job <b>loss</b> rather than any prior downward trajectory in the mental health of family members.|$|R
40|$|DNA {{mismatch}} repair {{is an important}} mechanism in-volved in maintaining the fidelity of genomic DNA. Defec-tive DNA {{mismatch repair}} is implicated {{in a variety of}} gastrointestinal and other tumors; however, its role in hepatocellular carcinoma (HCC) has not been assessed. Formalin-fixed, paraffin-embedded archival pathology tis-sues from 46 primary liver tumors were studied by microdis-section and microsatellite analysis of extracted DNA to assess the degree of microsatellite instability, a marker of defective mismatch repair, and to determine the extent and <b>timing</b> of allelic <b>loss</b> of two DNA mismatch repair genes, human Mut S homologue- 2 (hMSH 2) and human Mut L homologue- 1 (hMLH 1), and the tumor suppressor genes adenomatous polyposis coli gene (APC), p 53, and DPC 4. Microsatellite instability was detected in 16 of the tumor...|$|R
40|$|Abstract—Manufacturing process {{variations}} lead to {{variability in}} circuit delay and, if not accounted for, can cause excessive <b>timing</b> yield <b>loss.</b> The familiar traditional approaches to timing verification, {{such as the}} use of process corners and predefined timing margins, cannot readily handle within-die variations. Recently, statistical static timing analysis (SSTA) has been proposed as a way to deal with variability. Although many powerful techniques have been proposed, the fact that SSTA requires a significant change of methodology has delayed its wide adoption. In this paper, we propose a framework whereby the familiar concepts of corners and margins, which are generally meaningful at the transistor or cell level, are elevated to the chip level in order to handle within-die variations. This is achieved by using high-level models, such as the generic path model or the generic circuit model with different classes of paths, to represent the behavior of typical designs. These models allow us to determine “yield-specific ” margins (setup and hold margins) and virtual corners, which, if applied during standard (deterministic) timing analysis, would guarantee the desired yield. Our framework can be used at an early stage of circuit design and is consistent with traditional timing verification methodology. Index Terms—Classes of paths, early analysis, generic path, process variations, setup and hold margins, statistical timing analysis, timing yield, virtual corners. I...|$|R
40|$|Neural {{tissue is}} {{particularly}} vulnerable to metabolic stress and loss of ion homeostasis. Repetitive stress generally leads to more permanent dysfunction but the mechanisms underlying this progression are poorly understood. We investigated the effects of energetic compromise in Drosophila by targeting the Na + /K +-ATPase. Acute ouabain treatment of intact flies resulted in subsequent repetitive comas that led to death and were associated with transient loss of K + homeostasis in the brain. Heat shock pre-conditioned flies were resistant to ouabain treatment. To control the <b>timing</b> of repeated <b>loss</b> of ion homeostasis we subjected flies to repetitive anoxia while recording extracellular [K +] in the brain. We show that targeted expression of the chaperone protein Hsp 70 in glial cells delays a permanent loss of ion homeostasis associated with repetitive anoxic stress and suggest {{that this is a}} useful model for investigating molecular mechanisms of neuroprotection...|$|R
40|$|Mental {{accounting}} is {{a technique}} for asserting self-control {{in the face of}} consumption decisions, functioning as a categorization system for income and expenses. A body of evidence supports the concept that consumers are driven by perception and emotion, not rational economic thought. Mental accounting is subject to the effects of cognitive biases, leading to imperfect financial behavior. In the following paper, I present a proposal for three consecutive experiments designed to investigate the influence that advanced planning (the formation of mental budgets) and unexpected financial shocks (windfalls) can have on our use of mental accounting to regulate spending. The dependent variable is a dollar measure of how much consumers indicated they are “willing to pay” (WTP) to hypothetically purchase a typical good. The experiments share an intertemporal manipulation of a monthly budget creation task. Experiment one investigates the combined effects of positive and negative windfalls and budget creation on WTP. Experiment 2 explores boundary conditions of <b>timing</b> on <b>loss</b> aversion by manipulating the length of the time period that separates a negative windfall from the WTP task. Experiment 3 focuses on one time period, manipulating wording of a negative financial shock to focus on framing effects. The three experiments, if carried out, should reveal significant effects on WTP, suggesting that manipulations of framing and timing can lead to inconsistent spending behaviors even {{in the presence of a}} self-control tool (the mental budget) ...|$|R
40|$|The dying {{process of}} Paramecium tetraurelia cells under a cover glass without {{supporting}} pillars was described. The initiation {{of the process}} was defined by the cessation of swimming, and the termination by cell rupture. The process required 6 min on average, ranging from 1 to 11 min. The first symptom of death was {{the formation of a}} small bleb, a local swelling of the outer cell membrane. The number of blebs increased, each bleb grew, and neighboring blebs fused to form a larger bleb. By supplying water, the blebs disappeared only when their size and numbers were relatively small, indicative of a commitment point to death. Finally the outer membrane and then the inner membrane were broken, and the cytoplasmic contents flew out. Until the last moment of the cell rupture, and sometimes even after that, ciliary beating was observed somewhere locally on the cell membrane. Among the cilia, those at the cytopharynx were the first to stop beating so that food vacuole (FV) formation stopped somewhat earlier than the cellular disorganization. Cessation of the contractility of contractile vacuoles (CVs) occurred {{a little bit later on}} average than the cessation of FV formation. Anterior and posterior CVs were not related to each other in the <b>timing</b> of <b>loss</b> of contractility and in the preceding pulsating cycles. Finally, we calculated the physical pressure to burst the cell at about 950 atm and estimated the actual pressure to be at 470 ~ 2, 000 atm...|$|R
