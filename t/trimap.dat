62|12|Public
50|$|There {{also exist}} machine {{learning}} tools that can pull mattes {{with the assistance}} of a user. Often, these tools require iteration {{on the part of the}} user - an algorithm provides a result based on a training set, and the user adjusts the set until the algorithm provides the desired result. An example of this is using a manually-created coarse matte with a <b>trimap</b> segmentation, so called because it separates the image into three regions: known background, known foreground, and an unknown region. In this case, the algorithm attempts to label the unknown region based on the user's input, and the user can iterate through multiple trimaps for better results. Knockout, a plug-in tool for Adobe Photoshop, is an implementation of this process.|$|E
40|$|Image matting is {{a longstanding}} problem in {{computational}} photography. Although, {{it has been}} studied {{for more than two}} decades, yet there is a challenge of developing an automatic matting algorithm which does not require any human efforts. Most of the state-of-the-art matting algorithms require human intervention in the form of <b>trimap</b> or scribbles to generate the alpha matte form the input image. In this paper, we present a simple and efficient approach to automatically generate the <b>trimap</b> from the input image and make the whole matting process free from human-in-the-loop. We use learning based matting method to generate the matte from the automatically generated <b>trimap.</b> Experimental results demonstrate that our method produces good quality <b>trimap</b> which results into accurate matte estimation. We validate our results by replacing the automatically generated <b>trimap</b> by manually created <b>trimap</b> while using the same image matting algorithm...|$|E
40|$|This paper {{presents}} {{an approach to}} automatically extract human body region from color photos, which introduces <b>trimap</b> shape updating into iterated GrabCut image segmentation technique. It {{is based on an}} observation that human torso is relatively stable in appearance compared with various human poses formed by hands and feet, and on a fact that estimation on a small region is more accurate than on a large region if a few cues for estimation are just available. At first a human face is found by scanning a face detector across the whole target unknown image. Then a body <b>trimap,</b> an image showing potential body area, is initialized according to the found face. With this <b>trimap,</b> body torso is estimated with GrabCut image segmentation method. After that, the <b>trimap</b> is updated by dynamically growing its contour according to local image information, and new body region is estimated by applying GrabCut to the target image. With the iterated processing of <b>trimap</b> shape updating and GrabCut applying, human body region is finally extracted. The approach has been tested with 400 photo images, and the results show its usefulness. 1...|$|E
40|$|We {{propose a}} robust and fully {{automatic}} method for extracting a highly detailed transparency-preserving segmentation of a person’s head from multiple view recordings, including a background plate for each view. At first, <b>trimaps</b> containing a rough segmentation into foregorund, background and unknown image regions are extracted exploiting the visual hull of an initial foreground-background segmentation. The background plates are {{adapted to the}} lighting conditions of the recordings and the <b>trimaps</b> are used to initialize a state-of-the-art matting method adapted to a setup with precise background plates available. From the alpha matte, foreground colours are inferred for realistic rendering of the recordings onto novel backgrounds...|$|R
40|$|Fast {{foreground}} extraction is {{an important}} and challenging problem. Although GrabCut can perform well in foreground extraction, the average accuracy is not satisfactory, and more importantly, its computational cost is large. In this paper, we propose a fast interactive foreground extraction based on superpixel GrabCut and matting. Specifically, we use a superpixel method to process images {{in order to improve}} the efficiency of the GrabCut. To obtain a refined mask, we employ the Shared matting method whose <b>trimaps</b> are implemented by our constructed fast and adaptive <b>trimaps</b> (FATs). Experimental results demonstrate the proposed method is more competitive and effective in the visual sense, E-Time and MSE criterions. © 2015 IEEE...|$|R
40|$|This book, {{in order}} to generalize the two models of fuzzy {{cognitive}} maps and neutrosophic cognitive maps, has systematically invented mathematical tools like bimatrices, trimatrices, n-matrices, bigraphs, trigraphs and n-graphs and describe some of its properties. These concepts are also extended neutrosophically in this book. Using these new tools we define fuzzy cognitive bimaps, fuzzy cognitive <b>trimaps,</b> fuzzy relational bimaps and fuzzy relational <b>trimaps</b> which exploit the new notions of bimatrices, bigraphs, trimatrices and trigraphs. It is worth mentioning that these can be extended to n-array models as a simple exercise. The main advantage of these models are: 1. Comparative study of the views stage-by-stage is possible. 2. Several experts opinion can be compared not only at each stage but also the final result can easily be compared. 3. Saves time and economy. This book is organized into four chapters. The first chapter recalls the basic concepts of bimatrices and neutrosophic bimatrices. Second chapter introduces several new notions of graphs like bigraphs, trigraphs and their properties. Chapter three illustrates how these new tools {{are used in the}} construction of fuzzy cognitive bimaps, <b>trimaps</b> and n-maps and fuzzy relational bimaps, <b>trimaps</b> and n-maps. The neutrosophic analogues of chapter 3 is carried out in the fourth chapter. In this book, we have given nearly 95 examples to make the reader easily follow the definitions. We have also provided 125 figures for help in easily understanding the definition and examples. We have also given 25 real world problems as applications of Bimatrices to Fuzzy and Neutrosophic models. Comment: 273 pages, 95 examples, 125 figures, 25 real-world problems as application...|$|R
40|$|Image/Video Matting aims at {{solving the}} problem of {{accurate}} foreground estimation from a given background within still images or video sequences. The standard alpha matting method starts from a <b>trimap,</b> which separates an input image into three regions: definitely foreground, definitely background, and unknown regions. This paper presents an automatic <b>trimap</b> extraction based on an affine transformation of gradient fields {{in order to achieve}} an improved and robust Image/Video matting method. A gradient field based background and foreground segmentation technique provides a <b>trimap</b> extraction, which is robust to changing light conditions within semi-transparent objects. Our proposed background subtraction is based on affine transformed gradient projections of the input and background image and removes the background texture from a given image, preserving the texture of the foreground objects. The presented automatic <b>trimap</b> extraction method reduces the manual labor work in extracting and embedding target objects into a new background image or video sequences and might find its application within the broadcasting or movie industry...|$|E
40|$|Abstract. Foreground {{extraction}} is a {{very important}} operation in the image processing of the computers. Its purpose is to extract the area that human beings are interested in from the complicated background, which is beneficial for the subsequent operations such as background exchange, changes of the perspective effect and image mosaicing and so on. However, it is actually an ill-posed problem to determine whether a pixel belongs to the foreground. It is usually hard to acquire an accurate solution from the initial image. Therefore, the foreground extraction algorithm generally needs the user interaction. This paper has put forward a kind of rapid foreground extraction algorithm with the user interaction form of <b>Trimap.</b> On the one hand, our <b>Trimap</b> is quite simple. The users are able to understand the influence of <b>Trimap</b> on the productive resultants visually. On the other hand, with the help of <b>Trimap,</b> we are able to lessen the area that needs to be calculated in a large degree, which can rapidly finish the work of foreground extraction...|$|E
40|$|We {{present a}} new {{approach}} to the matting problem which splits the task into two steps: interactive <b>trimap</b> extraction followed by trimap-based alpha matting. By doing so we gain considerably in terms of speed and quality and are able to deal with high resolution images. This paper has three contributions: (i) a new <b>trimap</b> segmentation method using parametric max-flow; (ii) an alpha matting technique for high resolution images with a new gradient preserving prior on alpha; (iii) a database of 27 ground truth alpha mattes of still objects, which is considerably larger than previous databases and also of higher quality. The database is used to train our system and to validate that both our <b>trimap</b> extraction and our matting method improve on state-of-the-art techniques. 1...|$|E
40|$|This paper {{describes}} a new framework for video matting, {{the process of}} pulling a high-quality alpha matte and foreground from a video sequence. The framework builds upon techniques in natural image matting, optical flow computation, and background estimation. User interaction is comprised of garbage matte specification if background estimation is needed, and hand-drawn keyframe segmentations into "foreground," "background," and "unknown". The segmentations, called <b>trimaps,</b> are interpolated across the video volume using forward and backward optical flow. Competing flow estimates are combined based on information about where flow {{is likely to be}} accurate. A Bayesian matting technique uses the flowed <b>trimaps</b> to yield high-quality mattes of moving foreground elements with complex boundaries filmed by a moving camera. A novel technique for smoke matte extraction is also demonstrated...|$|R
40|$|Abstract This paper {{presents}} an automatic real-time video matting system. The proposed system {{consists of two}} novel components. In order to automatically generate <b>trimaps</b> for live videos, we advocate a Time-of-Flight (TOF) camerabased approach to video bilayer segmentation. Our algorithm combines color and depth cues in a probabilistic fusion framework. The scene depth information returned by the TOF camera is less sensitive to environment changes, which makes our method robust to illumination variation, dynamic background and camera motion. For the second step, we perform alpha matting based on the segmentation Electronic supplementary material The online {{version of this article}} (doi: 10. 1007 /s 11263 - 011 - 0471 -x) contains supplementary material, which is available to authorized users...|$|R
40|$|Image matting is {{the process}} of taking an image, {{isolating}} the foreground, and replacing the background with a new image. This can be a hard problem when the background is unknown as it is fundamentally unconstrained. We look at an existing technique for foreground-background separation called Bayesian matting and improve upon it by adding depth information acquired by a time-of-flight range scanner. We use the depth information to generate automatic <b>trimaps</b> so that the method can be used automatically for video sequences. In addition, we improved the results from the matting algorithm by incorporating the depth channel into Bayesian matting. This allows us to reduce artifacts that arise from ambiguities that occur when an object is a similar color to its background. 1...|$|R
40|$|In {{this paper}} {{we present a}} novel {{approach}} to estimate the alpha mattes of a foreground object captured by a widebaseline circular camera rig provided a single key frame <b>trimap.</b> Bayesian inference coupled with camera calibration information are used to propagate high confidence trimaps labels across the views. Recent techniques {{have been developed to}} estimate an alpha matte of an image using multiple views but they are limited to narrow baseline views with low foreground variation. The proposed wide-baseline <b>trimap</b> propagation is robust to inter-view foreground appearance changes, shadows and similarity in foreground/background appearance for cameras with opposing views enabling high quality alpha matte extraction using any state-of-the-art image matting algorithm. Index Terms — Image matting, alpha matte, <b>trimap,</b> wide-baseline, multiple views...|$|E
40|$|Object {{extraction}} is {{a critical}} operation for many content -based video applications. For these applications, a robust and precise extraction technique is required. This thesis proposes an efficient and accurate method for generating a <b>trimap</b> for video matting. We first segment the foreground using motion information and neighboring pixel coherence via graph cuts. Also, we estimate the parameters of a Gaussian Mixture Model for the foreground and background with segmented foreground and estimated static background. Next, we classify the pixels of each frame into models by performing maximum likelihood classification and generate a <b>trimap</b> which is an image consisting of three regions: foreground, background and unknown. Finally, we use the <b>trimap</b> as a guide in spectral matting for video matting. Our experimental {{results show that the}} proposed method yields accurate and natural object boundarie...|$|E
40|$|Image matting aims {{to extract}} a {{foreground}} object {{from a single}} natural image by recovering the partial transparency and corresponding color of the foreground object at each pixel in the image. The resulting transparency map is thereby denoted as alpha matte. The matting problem is severely ill-posed, and in this thesis we focus on matting approaches that utilize user interaction to make the problem tractable. There are three fundamental challenges in interactive image matting research that are addressed in this thesis: (i) Providing a fast and intuitive user interface; (ii) finding a good cost function for matting; and (iii) providing a benchmark that allows a quantitative comparison of matting results. In most previous approaches the user interacts with the algorithm by drawing an accurate <b>trimap,</b> which is a partition of the image into foreground, background and unknown regions. An accurate <b>trimap</b> is very tedious to create manually, hence we follow recent work and aim to automatically generate a <b>trimap</b> from very little user input. The novelty of our approach lies in a new cost function that describes the goodness of a <b>trimap</b> solution. Our cost function considers several image cues and incorporates four different types of priors {{that are used to}} regularize the result. We show that our method is fast and produces accurate results...|$|E
40|$|The thesis {{deals with}} an image {{processing}} problem called image matting. The problem involves detection of a foreground and background in an image with minimal user interaction using <b>trimaps.</b> Foreground detection is used in image composition. The goal of the thesis is to apply already known algorithms, in this case A Global sampling matting, in an Android application. The most important result is an intuitive application {{that can be used}} for making creative viral photos. Agile methodology is applied throughout the whole application development cycle. From the very beginning, the application is publicly available as a minimum viable product on Google play. The work&# 8217;s contribution is in optimization of the mentioned algorithm for use in mobile devices and parallelization on a GPU, together with a publicly available application...|$|R
40|$|Image matting {{plays an}} {{important}} role in image and video editing. However, the formulation of image matting is inherently ill-posed. Traditional methods usually employ interaction to deal with the image matting problem with <b>trimaps</b> and strokes, and cannot run on the mobile phone in real-time. In this paper, we propose a real-time automatic deep matting approach for mobile devices. By leveraging the densely connected blocks and the dilated convolution, a light full convolutional network is designed to predict a coarse binary mask for portrait images. And a feathering block, which is edge-preserving and matting adaptive, is further developed to learn the guided filter and transform the binary mask into alpha matte. Finally, an automatic portrait animation system based on fast deep matting is built on mobile devices, which does not need any interaction and can realize real-time matting with 15 fps. The experiments show that the proposed approach achieves comparable results with the state-of-the-art matting solvers. Comment: ACM Multimedia Conference (MM) 2017 camera-read...|$|R
40|$|In {{this work}} {{we present a}} new Markov Random Field model for image binary {{segmentation}} that computes the probability that each pixel belongs to a given class. We show that if a real valued field is computed, instead of a binary one as in graph cuts based methods, then the resultant cost function has noticeable computational and performance advantages. The proposed energy function can be efficiently minimized with standard fast linear order algorithms as Conjugate Gradient or multigrid Gauss-Seidel schemes. Moreover, our formulation accepts a good initial guess (starting point) and avoids to construct from scratch the new solution accelerating the computational process. Then we naturally implement computationally efficient multigrid algorithms. For applications with limited computational time, a good partial solution {{can be obtained by}} stopping the iterations even if the global optimum is not yet reached. We performed a meticulous comparison (with state of the art methods: Graph Cut, Random Walker and GMMF) for the interactive image segmentation (based on <b>trimaps).</b> We compare the algorithms using cross–validation procedures and a simplex decent algorithm for learning the parameter set. 1...|$|R
40|$|Given an image, digital matting {{consists}} in extracting a foreground element from the background. Standard methods are initialized with a <b>trimap,</b> a partition {{of the image}} into three regions: a definite foreground, a definite background, and a blended region where pixels are considered as a mixture of foreground and background colors. Recovering these colors {{and the proportion of}} mixture between both is an under-constrained inverse problem, sensitive to its initialization: one has to specify an accurate <b>trimap,</b> leaving undetermined as few pixels as possible. First, we propose [...] ...|$|E
40|$|The image matting {{problem is}} to extract a {{foreground}} object from a still natural image with the limited help from user. The foreground layer consists of three color layers and opacity layer. In this {{paper we propose a}} user assisted image matting workflow. Starting from a manual marking <b>trimap,</b> we perform hard segmentation and allow the user to quickly turn the segmentation result into a <b>trimap.</b> The algorithm used to apply soft matting process and allow the user to refine the result by fine-tuning the matting parameters in distinct image regions...|$|E
40|$|In this paper, a {{hierarchical}} image matting model is proposed to extract blood vessels from fundus images. More specifically, {{a hierarchical}} strategy utilizing the continuity and extendibility of retinal blood vessels is {{integrated into the}} image matting model for blood vessel segmentation. Normally the matting models require the user specified <b>trimap,</b> which separates the input image into three regions manually: the foreground, background and unknown regions. However, since creating a user specified <b>trimap</b> is a tedious and time-consuming task, region features of blood vessels are used to generate the <b>trimap</b> automatically in this paper. The proposed model has low computational complexity and outperforms many other state-ofart supervised and unsupervised methods in terms of accuracy, which achieves a vessel segmentation accuracy of 96 : 0 %, 95 : 7 % and 95 : 1 % in an average time of 10 : 72 s, 15 : 74 s and 50 : 71 s on images from three publicly available fundus image datasets DRIVE, STARE, and CHASE DB 1, respectively. Comment: 10 pages, 10 figure...|$|E
40|$|ABSTRACT. In {{this work}} {{we present a}} new Markov Random Field model for image binary {{segmentation}} that computes the probability that each pixel belongs to a given class. We show that if a real valued field is computed, instead of a binary one as in graph cuts based methods, then the resultant cost function has noticeable computational and performance advantages. The proposed energy function can be efficiently minimized with standard fast linear order algorithms as Conjugate Gradient or multigrid Gauss-Seidel schemes. Moreover, our formulation accepts a good initial guess (starting point) and avoids to construct from scratch the new solution accelerating the computational process. Then we naturally implement computationally efficient multigrid algorithms. For applications with limited computational time, a good partial solution {{can be obtained by}} stopping the iterations even if the global optimum is not yet reached. We performed a meticulous comparison (with state of the art methods: Graph Cut, Random Walker and GMMF) for the interactive image segmentation (based on <b>trimaps).</b> We compare the algorithms using cross–validation procedures and a simplex decent algorithm for learning the parameter set. Keywords:Image binary segmentation, Segmentation comparison, Interactive computer vision, Markov random fields, energy minimization, Image matting...|$|R
40|$|Single image matting, {{the task}} of {{estimating}} accurate foreground opacity from a given image, is a severely ill-posed and challenging problem. Inspired by recent advances in image co-segmentation, in this paper, we present a novel framework for a new task called co-matting, which aims to simultaneously extract alpha mattes in multiple images that contain slightly-deformed instances of the same foreground object against different backgrounds. Our system first generates <b>trimaps</b> for input images using co-segmentation, and an initial alpha matte for each image using single image matting. Each alpha matte is then locally evaluated using a novel matting confidence metric learned from a training data set. In the co-matting step, we first align the foreground object instances using appearance and geometric features, then apply a global optimization on all input images to jointly improve their alpha mattes, which allows high confidence local regions to guide their corresponding low confidence ones in other images to achieve more accurate mattes all together. Experimental results show that this co-matting framework can achieve noticeably higher quality results on an image stack than applying state-of-the-art single image matting techniques individually on each image...|$|R
40|$|This thesis {{addresses}} {{the problem of}} autonomous object segmentation. To do so the proposed segementation method uses some prior information, namely that the image to be segmented will have a low depth of field and that the object of interest will be more in focus than the background. To differentiate the object from the background scene, a multiscale wavelet based assessment is proposed. The focus assessment is used to generate a focus intensity map, and a sparse fields level set implementation of active contours is used to segment the object of interest. The initial contour is generated using a grid based technique. The method is extended to segment low depth of field video sequences with each successive initialisation for the active contours generated from the binary dilation of the previous frame's segmentation. Experimental results show good segmentations can be achieved {{with a variety of}} different images, video sequences, and objects, with no user interaction or input. The method is applied to two different areas. In the first the segmentations are used to automatically generate <b>trimaps</b> for use with matting algorithms. In the second, the method is used as part of a shape from silhouettes 3 D object reconstruction system, replacing the need for a constrained background when generating silhouettes. In addition, not using a thresholding to perform the silhouette segmentation allows for objects with dark components or areas to be segmented accurately. Some examples of 3 D models generated using silhouettes are shown...|$|R
40|$|Image matting is an {{important}} vision problem. The main stream methods for it combine sampling-based methods and propagation-based methods. In this paper, {{we deal with the}} combination with a normalized weighting parameter, which could well control the relative relationship between information from sampling and from propagation. A reasonable value range for this parameter is given based on statistics from the standard benchmark dataset. The matting is further improved by introducing semi-supervised learning iterations, which automatically refine the <b>trimap</b> without user's interaction. This is especially beneficial when the <b>trimap</b> is coarse. The experimental results on standard benchmark dataset have shown that both the normalized weighting parameter and the semi-supervised learning iteration could significantly improve the matting performance...|$|E
40|$|Figure 1 : Natural video matting. (a) We use {{a camera}} array {{to capture a}} {{collection}} of images of a scene. Here we show a single camera’s image. (b) We synthetically refocus the data and compute the variance of the refocused images (darker means lower variance). (c) From the “variance image ” we automatically compute a <b>trimap.</b> (d) We propagate the variances into the unknown region of the <b>trimap</b> and use these measurements to solve for the alpha matte. (e) We then compute the alpha multiplied foreground and composite it with a new background. We present an algorithm and a system for high-quality natural video matting using a camera array. The system uses high frequencies present in natural scenes to compute mattes by creating a synthetic aperture image that {{is focused on the}} foreground object, which reduces the variance of pixels reprojected from the foreground while increasing the variance of pixels reprojected from the background. We modify the standard matting equation to work directly with variance measurements and show how these statistics can be used to construct a <b>trimap</b> that is later upgraded to an alpha matte. The entire process is completely automatic, including an automatic method for focusing the synthetic aperture image on the foreground object and an automatic method to compute the <b>trimap</b> and the alpha matte. The proposed algorithm is very efficient and has a per-pixel running time that is linear in the number of cameras. Our current system runs at several frames per second, and we believe that it is the first system capable of computing high-quality alpha mattes at near real-time rates without the use of active illumination or special backgrounds...|$|E
40|$|In {{computer}} vision, matting is {{the process}} of accurate foreground estimation in images and videos. In this paper we presents a novel patch based approach to video matting relying on non-parametric statistics to represent image variations in appearance. This overcomes the limitation of parametric algorithms which only rely on strong colour correlation between the nearby pixels. Initially we construct a clean background by utilising the foreground object’s movement across the background. For a given frame, a <b>trimap</b> is constructed using the background and the last frame’s <b>trimap.</b> A patch-based approach is used to estimate the foreground colour for every unknown pixel and finally the alpha matte is extracted. Quantitative evaluation shows that the technique performs better, in terms of the accuracy and the required user interaction, than the current state-of-the-art parametric approaches. ...|$|E
40|$|We {{propose a}} novel image/video retexturing {{approach}} that preserves the original shading effects {{without knowing the}} underlying surface and lighting conditions. For static images, we first introduce the Poisson equation-based algorithm to simulate the texture distortion on the projected interest region of the underlying surface, while preserving the shading effect of the original image. We further work on videos by retexturing the key frame as static image and then propagating the results onto the other frames. In video retexturing, we have introduced the mesh based optimization for object tracking to avoid texture drifting, and the graph cut algorithm to effectively deal with visibility shift between frames. The graph cut algorithm is applied on a <b>trimap</b> along the boundary of the object to extract the textured part inside the <b>trimap.</b> The proposed approach is developed in image/video retexturing at nearly interactive rate, and our experimental results have showed the satisfactory performanc...|$|E
40|$|This paper {{presents}} {{a method to}} estimate alpha mattes for video sequences of the same foreground scene from wide-baseline views given sparse key-frame trimaps in a single view. A statistical inference framework is introduced for spatio-temporal propagation of high-confidence <b>trimap</b> labels between video sequences without a requirement for correspondence or camera calibration and motion estimation. Multiple view <b>trimap</b> propagation integrates appearance information between views and over time to achieve robust labelling {{in the presence of}} shadows, changes in appearance with view point and overlap between foreground and background appearance. Results demonstrate that trimaps are sufficiently accurate to allow high-quality video matting using existing single view natural image matting algorithms. Quantitative evaluation against ground-truth demonstrates that the approach achieves accurate matte estimation for camera views separated by up to 180 ◦, with the same amount of manual interaction required for conventional single view video matting...|$|E
40|$|Ship {{detection}} in static UAV aerial {{images is}} a fundamental challenge in sea target detection and precise positioning. In this paper, an improved universal background model based on Grabcut algorithm is proposed to segment foreground objects from sea automatically. First, a sea template library including images in different natural conditions is built to provide an initial template to the model. Then the background <b>trimap</b> is obtained by combing some templates matching with region growing algorithm. The output <b>trimap</b> initializes Grabcut background instead of manual intervention {{and the process of}} segmentation without iteration. The effectiveness of our proposed model is demonstrated by extensive experiments on a certain area of real UAV aerial images by an airborne Canon 5 D Mark. The proposed algorithm is not only adaptive but also with good segmentation. Furthermore, the model in this paper can be well applied in the automated processing of industrial images for related researches...|$|E
40|$|Depth map {{is widely}} adopted and {{available}} in the 3 D research area. Combining the depth map with the matting techniques is helpful to the original matte and depth image based rendering in 3 D. Herein, in this paper, a novel adaptive depth map assisted matting approach with concise integration is presented and applied to achieve favorable matting results. In this approach, the Lagrange-multiplier-free closed form solution is firstly derived to reduce the computation complexity and to increase matting accuracy. Based {{on the work of}} Levin et al. on closed form matting, an improved alpha matte is then achieved by introducing an adaptive smoothness criterion which is the function of depth map variance. Finally, the matting system is capable of working in a full automatical way by generating the <b>trimap</b> from the depth information. Simulation results demonstrate that the proposed method is able to efficiently generate an alpha matte with an roughly user specified scribbles or an automatically generated <b>trimap.</b> © 2011 IEEE...|$|E
40|$|Separating a {{foreground}} object {{from the}} background in a static image involves determining both full and partial pixel coverages, {{also known as}} extracting a matte. Previous approaches require the input image to be pre-segmented into three regions: foreground, background and unknown, which is called a <b>trimap.</b> Partial opacity values are then computed only for pixels inside the unknown region. This presegmentation based approach fails for images with large portions of semi-transparent foreground where the <b>trimap</b> is difficult to create even manually. In this paper we combine the segmentation and matting problem together and propose a unified optimization approach based on Belief Propagation. We iteratively estimate the opacity value for every pixel in the image, based on {{a small sample of}} foreground and background pixels marked by the user. Experimental results show that compared with previous approaches, our method is more efficient to extract high quality mattes for foregrounds with significant semi-transparent regions. 1...|$|E
40|$|We {{present an}} {{algorithm}} {{and a system}} for high-quality natural video matting using a camera array. The system uses high frequencies present in natural scenes to compute mattes by creating a synthetic aperture image that {{is focused on the}} foreground object, which reduces the variance of pixels reprojected from the foreground while increasing the variance of pixels reprojected from the background. We modify the standard matting equation to work directly with variance measurements and show how these statistics can be used to construct a <b>trimap</b> that is later upgraded to an alpha matte. The entire process is completely automatic, including an automatic method for focusing the synthetic aperture image on the foreground object and an automatic method to compute the <b>trimap</b> and the alpha matte. The proposed algorithm is very efficient and has a perpixel running time that is linear in the number of cameras. Our current system runs at several frames per second, and we believe that it is the first system capable of computing high-quality alpha mattes at near real-time rates without the use of active illumination or special backgrounds...|$|E
40|$|We {{propose a}} method for {{incorporating}} multiview information into color sampling methodologies for alpha mat-ting. We extend the typical <b>trimap</b> input for matting algorithms to 3 D space, enabling the association of stripes of pixels in semi-transparent regions like hair between different views without knowing or inferring their spa-tial structure. We also formulate a new cost function penalizing deviations of foreground color estimates between associated pixel stripes and its possible integration into a state-of-the-art color sampling approach. 1...|$|E
40|$|Obtaining a {{foreground}} silhouette {{across multiple}} views {{is one of}} the fundamental steps in 3 D reconstruction. In this paper we present a novel video segmentation approach, to obtain a foreground silhouette, for scenes captured by a wide-baseline camera rig given a sparse manual interaction in a single view. The algorithm is based on <b>trimap</b> propagation, a framework used in video matting. Bayesian inference coupled with camera calibration information are used to spatio-temporally propagate high confidence <b>trimap</b> labels across the multi-view video to obtain coarse silhouettes which are later refined using a matting algorithm. Recent techniques have been developed for foreground segmentation, based on image matting, in multiple views but they are limited to narrow baseline with low foreground variation. The proposed wide-baseline silhouette propagation is robust to inter-view foreground appearance changes, shadows and similarity in foreground/background appearance. The approach has demonstrated good performance in silhouette estimation for views up to 180 degree baseline (opposing views). The segmentation technique has been fully integrated in a multi-view reconstruction pipeline. The results obtained demonstrate the suitability of the technique for multi-view reconstruction with wide-baseline camera set-ups and natural background...|$|E
40|$|Copyright © 2014 Chao Xu et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Ship detection in static UAV aerial images is a fundamental challenge in sea target detection and precise positioning. In this paper, an improved universal background model based on Grabcut algorithm is proposed to segment foreground objects from sea automatically. First, a sea template library including images in different natural conditions is built to provide an initial template to the model. Then the background <b>trimap</b> is obtained by combing some templates matching with region growing algorithm. The output <b>trimap</b> initializes Grabcut background instead of manual intervention {{and the process of}} segmentation without iteration. The effectiveness of our proposedmodel is demonstrated by extensive experiments on a certain area of real UAV aerial images by an airborne Canon 5 DMark. The proposed algorithm is not only adaptive but also with good segmentation. Furthermore, the model in this paper can be well applied in the automated processing of industrial images for related researches. 1...|$|E
