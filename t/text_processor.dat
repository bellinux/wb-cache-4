59|92|Public
2500|$|Ideas that {{developed}} during discussion that are novel in XML included the algorithm for encoding detection and the encoding header, the processing instruction target, the xml:space attribute, {{and the new}} close delimiter for empty-element tags. The notion of well-formedness as opposed to validity (which enables parsing without a schema) was first formalized in XML, although it had been implemented successfully in the Electronic Book Technology [...] "Dynatext" [...] software; the software from the University of Waterloo New Oxford English Dictionary Project; the RISP LISP SGML <b>text</b> <b>processor</b> at Uniscope, Tokyo; the US Army Missile Command IADS hypertext system; Mentor Graphics Context; Interleaf and Xerox Publishing System.|$|E
5000|$|AbiWord, a <b>text</b> <b>processor</b> {{which is}} {{compatible}} with Microsoft Office ...|$|E
5000|$|... font substitutions {{defined in}} {{application}} software's (e.g. <b>text</b> <b>processor)</b> font configuration for concrete font names.|$|E
50|$|Overstriking of longer {{sections}} of text, {{such as in}} , can also be produced in many <b>text</b> <b>processors</b> as <b>text</b> markup as a special form of understriking.|$|R
40|$|We {{examine the}} line-wrap feature of <b>text</b> <b>processors</b> {{and show that}} adding {{characters}} to previously formatted lines leads to the cascading of words to subsequent lines and forms a state of self-organized criticality. We show the connection to one-dimensional random walks and diffusion problems, and we examine the predictability of catastrophic cascades. Comment: 6 pages, LaTeX with RevTeX package, 4 postscript figures appende...|$|R
40|$|In its {{theoretical}} part this bachelor thesis focuses on introducing how spelling and grammar corrections in <b>text</b> <b>processors</b> work on basic level. Brief history of <b>text</b> <b>processors</b> {{as well as}} linguistic basics needed for comprehension of the discussed problems are mentioned. In its practical part the bachelor thesis focuses on a research. Its goal is to examine {{whether there is a}} connection between using grammar and spelling correction in Microsoft Office Word 2007 and the level of grammatical expression of the youth. Another goal is to examine the hand written text conducted in the research for distribution of errors recognized by Microsoft Office Word 2007 in relation to errors not recognized by this program. A questionnaire and a dictate, which is first written in hand and then later in same form using Microsoft Office Word 2007, are used to gather the data necessary for the research. The evaluation of the research reveals some interesting results, however the hypotheses of the research are not validated...|$|R
5000|$|Reporting Subscription - Banded Reports and <b>Text</b> <b>Processor</b> Based Reporting Software for Microsoft Visual Studio Developers.|$|E
50|$|The {{strings of}} {{probable}} words are then turned into possible sentences by a <b>text</b> <b>processor.</b> This step {{is accomplished by}} using, among other tools, algorithms inspired by protein structure analysis that can identify recurring patterns.|$|E
5000|$|Writer2ePub (W2E) {{is a free}} {{extension}} for {{the various}} implementations of the Writer <b>text</b> <b>processor</b> to create EPUB-formatted e-Books [...] "from any file format that Writer can read". A text to be exported as EPUB has to be saved as OpenDocument (ODT)-formatted text document. Writer2epub is written in OpenOffice Basic. The author of Writer2ePub is Luca “Luke” Calcinai.|$|E
50|$|Writing {{direction}} is the direction glyphs {{are placed on}} the page in relation to forward progression of characters in the Unicode string. English and other languages of Latin script have left-to-right writing direction. Several major writing scripts, such as Arabic and Hebrew, have right-to-left writing direction. The Unicode specification assigns a directional type to each character to inform <b>text</b> <b>processors</b> how sequences of characters should be ordered on the page.|$|R
50|$|On Windows XP {{or later}} Windows, Input method, or IME, are also called <b>Text</b> Input <b>Processor,</b> which are {{implemented}} by the Text Services Framework API.|$|R
2500|$|This is a work-around for the {{shortcomings}} of most <b>text</b> <b>processors,</b> which are incapable of displaying the correct vowel marks for the word [...] in Koran. Because Arabic script is used to write other texts rather than Koran only, rendering [...] + [...] + [...] as the previous ligature is considered faulty: If {{one of a number}} of fonts (Noto Naskh Arabic, mry_KacstQurn, KacstOne, DejaVu Sans, Harmattan, Scheherazade, Lateef, Iranian Sans) is installed on a computer (Iranian Sans is supported by Wikimedia web-fonts), the word will appear without diacritics.|$|R
50|$|There is a potential, and, if present, {{probably}} an unconscious {{effect on the}} translated text. Different languages use different sequences for the logical elements within a sentence and a translator presented with a multiple clause sentence that is half translated {{is less likely to}} completely rebuild a sentence. Consistent empirical evidences (Martín-Mor 2011) show that translators will most likely modify the structure of a multiple clause sentence when working with a <b>text</b> <b>processor</b> rather than with a TM system.|$|E
5000|$|The {{encoding}} {{was also}} sometimes called code page 895 (CP895), for example with FoxPro, in the WordPerfect <b>text</b> <b>processor</b> {{and under the}} Arachne web browser for DOS, but IBM uses this code page number for a different encoding, CM/Group 2: 7-bit Latin SBCS: Japanese (EUC-JP JIS-Roman) or Japan 7-Bit Latin (00895), and the IANA does not recognize the number at all. The DOS code page switching file [...] for NEC Pinwriters supported the Kamenický encoding under both, code page 867 and 895 as well.|$|E
5000|$|Ideas that {{developed}} during discussion that are novel in XML included the algorithm for encoding detection and the encoding header, the processing instruction target, the xml:space attribute, {{and the new}} close delimiter for empty-element tags. The notion of well-formedness as opposed to validity (which enables parsing without a schema) was first formalized in XML, although it had been implemented successfully in the Electronic Book Technology [...] "Dynatext" [...] software; the software from the University of Waterloo New Oxford English Dictionary Project; the RISP LISP SGML <b>text</b> <b>processor</b> at Uniscope, Tokyo; the US Army Missile Command IADS hypertext system; Mentor Graphics Context; Interleaf and Xerox Publishing System.|$|E
40|$|This work {{is devoted}} to Word-to-LATEX program that {{converts}} documents written in Microsoft Word into LATEX format which is suitable for typesetting books, manuscripts, scientiffic articles, etc. The program can be customized {{so much that it}} enables to produce completely different output formats (e. g. XML). In this work I also tried to compare <b>text</b> <b>processors</b> and LATEX format and emphasise their pros and cons. The Microsoft Word object model is briefly described, its problems and limitations are also covered. Finally, the way of improving performance of applications that automate Word is suggested...|$|R
40|$|Abstract. We {{describe}} ISP RAS {{experience in}} applications of model based testing in various areas. The two different examples are considered- UniTesK test development technology aimed at software component testing and OTK tool {{intended to be}} used in test development for complex structured <b>text</b> <b>processors,</b> the main example of which is compilers. The surprising fact is that the two methods used in the tools have different prerequisites for successful applications in industrial software development. This demonstrates possibility to change those prerequisites by changing the technical aspects of the method applied. Both techniques were developed in RedVerst group of ISP RAS [1]...|$|R
40|$|Writing today, whether professional, academic, or private, {{relies heavily}} on computers. Most texts {{composed}} in the 21 st century are probably written on computers or other electronic devices, such as mobile phones. People compose <b>texts</b> in word <b>processors,</b> <b>text</b> editors, content management systems, blogs, wikis, e-mail clients, and instant messaging applications. Each of these tools supports authors i...|$|R
5000|$|An illustrative {{example of}} the {{complementary}} nature of parsing and templating is the [...] (substitute) command in the sed <b>text</b> <b>processor,</b> originating from search-and-replace in the ed text editor. Substitution commands are of the form , where [...] is a regular expression, for parsing input, and [...] is a simple template for output, either literal text, or a format string containing the characters [...] for [...] "entire match" [...] or the special escape sequences [...] through [...] for the nth sub-expression. For example, [...] replaces all occurrences of [...] "cat" [...] or [...] "dog" [...] with [...] "cats" [...] or [...] "dogs", without duplicating an existing [...] "s": [...] is the 1st (and only) sub-expression in the regexp, and [...] in the format string substitutes this into the output.|$|E
40|$|Abstract – In {{this paper}} the {{instructions}} for preparing camera ready paper for the Conference ICEST 2008 are given. The recommended, but not limited <b>text</b> <b>processor</b> is Microsoft Word 97 / 2000 /XP/ 2003. The global instructions for preparing paper with any <b>text</b> <b>processor</b> are given, too. For the LATEX users using the IEEEtran. sty is recommendable {{and it can be}} obtained from the IEEE web pag...|$|E
40|$|Emergency Department (ED) chief {{complaint}} (CC) {{data are}} {{key components of}} syndromic surveillance systems. However, {{it is difficult to}} use CC data because they are not standardized and contain varying semantic and lexical forms for the same concept. The purpose of this project was to revise a previously-developed <b>text</b> <b>processor</b> for preprocessing CC data specifically for syndromic surveillance and then evaluate it for acute respiratory illness surveillance to support decisions by public health epidemiologists. We evaluated the <b>text</b> <b>processor</b> accuracy and used the results to customize it for respiratory surveillance. We sampled 3, 699 ED records from a population-based public health surveillance system. We found equal sensitivity, specificity, and positive and negative predictive value of syndrome queries of data processed through the <b>text</b> <b>processor</b> compared to a standard keyword method on raw, unprocessed data...|$|E
40|$|Writing, whether professional, academic, or private, needs editors, input {{tools and}} display devices, and {{involves}} {{the coordination of}} cognitive, linguistic, and technical aspects. Most texts composed in the 21 st century are probably created on electronic devices; people compose <b>texts</b> in word <b>processors,</b> <b>text</b> editors, content management systems, blogs, wikis, e-mail clients, and instant messaging applications. Texts ar...|$|R
5000|$|... #Caption: Binary code {{represents}} <b>text</b> {{or computer}} <b>processor</b> instructions that create digital content.|$|R
40|$|Automatic text {{correction}} is {{an essential}} problem of today <b>text</b> <b>processors</b> and editors. Thispaper introduces a novel algorithm for automation of contextual text correction using a LinguisticHabit Graph (LHG) also introduced in this paper. A specialist internet crawler hasbeen constructed for searching through web sites {{in order to build}} a Linguistic Habit Graphafter text corpuses gathered in polish web sites. The achieved correction results on a basis ofthis algorithm using this LHG were compared with commercial programs which also enableto make text correction: Microsoft Word 2007, Open Office Writer 3. 0 and search engineGoogle. The achieved results of text correction were much better than correction made bythese commercial tools...|$|R
40|$|The {{practice}} of literate programming is not widespread because existing literate programming systems have some undesirable {{characteristics such as}} programming language and <b>text</b> <b>processor</b> dependence and lack of flexible tools for viewing and manipulation of the source file. This paper describes the literate programming system AOPS (Abstraction Oriented Programming System) which addresses both of these problems. AOPS is programming language and <b>text</b> <b>processor</b> independent literate programming system. AOPS tools include a hypertext browser, a lister {{with the ability to}} select what is presented and what is suppressed, and a filter to extract the program code from the AOPS source file. AOPS introduces the notion of a phantom abstraction that enh [...] ...|$|E
40|$|The Software Design and Documentation Language (SDDL) can be loosely {{characterized}} as a <b>text</b> <b>processor</b> with built-in knowledge of, and methods for handling the concepts of structure and abstraction which are essential for developing software and other information intensive systems. Several aspects of system descriptions to which SDDL has been applied are presented and specific SDDL methodologies developed for these applications are discussed...|$|E
40|$|Open domain {{question}} answering is slowly broadening its horizons, expanding from simple factoid questions to encompass broader {{and more complex}} queries. Recent areas of interest include scenario-based {{question answering}}, incorporating existing domain knowledge during question analysis, various types of inference, and intelligently processing subquestions. FLOOD (standing for Fluent, Linguistic, Object-Oriented, and Dynamic) provides a system within which these problems may be explored. It consists of three parts: A <b>Text</b> <b>Processor</b> which integrates existing tools to provide an end-to-end semantic parse. This begins with simple sentence breaking and tokenization and ends with semantic role filling. The <b>Text</b> <b>Processor</b> is organized as a separate module applicable to other tasks outside of FLOOD. The FLOOD Planning Platform, an environment for authoring and utilizing simple linguistic planning domains and algorithms. The platform handles routine tasks such as domain and state space management while leaving specifics up to individual reasoning modules; the primary goals of the platform are to provide a convenient and flexible interface for reasoner and domain development. A Question Answering Reasoner operating {{within the context of}} the Planning Platform. The curren...|$|E
40|$|An {{argument}} for {{the need for a}} programmable meta format: a format that introduces a new syntactic level in T& $ for document style designers. TEX has a number of characteristics that set it apart from all other <b>text</b> <b>processors.</b> Its unsurpassed quality of text setting and its capabilities for handling mathematics are some of the more visible aspects. On a deeper level, however, the extreme programmability of TEX is just as big an asset. Any layout can be automated to an arbitrary extent. (It is strange that The!l&Ybook gives almost no hint of this.) The form such automation usually takes is what is called 'generalized markup'. The perso...|$|R
40|$|Current {{software}} documentation tools (like <b>text</b> <b>processors,</b> email, documentation generators, reporting, configuration management, wikis) {{have different}} strengths {{in supporting the}} software engineering process. But one weakness they all {{have in common is}} their inability to combine the advantages of the various techniques. Integrating documentation with diverse origins would enhance the force of expression and compensate individual failings of the different techniques. In this paper, we present a new brand of documentation utilities - exemplified by the Dendrodoc-system - that overcomes current problems with documentation. By processing information at negligible cost that common tools ignore, our system represents an efficient way of improving software documentation...|$|R
5000|$|For <b>text</b> moderecommended <b>processor</b> : 200 MHz Pentium Pro or fasterminimum memory (RAM): 256 MBFor {{graphical}} moderecommended processor : 400 MHz Pentium Pro or fasterminimum memory (RAM): 640 MBrecommended memory (RAM): 1152 MBHard disk minimum {{free space}} of 15GBA DVD ROM ...|$|R
40|$|Graduation date: 1993 The {{practice}} of literate programming is not widespread because existing literate programming systems have some undesirable {{characteristics such as}} programming language and <b>text</b> <b>processor</b> dependence and lack of flexible tools for viewing and manipulation of the source file. This dissertation describes the literate programming system AOPS (Abstraction Oriented Programming System) which addresses both of these problems. AOPS is programming language and <b>text</b> <b>processor</b> independent literate programming system. AOPS tools include a hypertext browser, a lister {{with the ability to}} select what is presented and what is suppressed, and a filter to extract the program code from the AOPS source file. AOPS introduces the notion of a phantom abstraction that enhances the understandability of the literate program and when used in conjunction with the browser greatly extends the capabilities of AOPS. We also discuss how the design of AOPS supports extension of the concept of literate programming to encompass the entire software life cycle. Finally we describe an experiment which showed that literate programs contain more documentation than traditional programs...|$|E
40|$|The {{publishing}} {{of electronic}} structured documents {{is the focus}} of this bachelor's thesis. The publishing system is implemented as a web server. Documents are written by the external MS Word <b>text</b> <b>processor.</b> The document layout and structure are specified by a document template. The publishing system has a web interface based on AJAX to update published documents. The publishing system's prototype is designed to manage company documentation in the field of quality management and fulfils ISO 9000 standards...|$|E
40|$|According {{to recent}} research, nearly 95 {{percent of a}} {{corporate}} information is stored in documents. Further studies indicate that companies spent between 6 and 10 percent of their gross revenues printing and distributing documents in several ways: web and cdrom publishing, database storage and retrieval and printing. In this context documents exist in some di#erent formats, from pure ascii files to internal database or <b>text</b> <b>processor</b> formats. It is clear that document reusability and low-cost maintenance are two important issues in the near future. The majority o...|$|E
5000|$|... gwrite was an {{open source}} styled <b>text</b> word <b>processor</b> for Linux. It uses a GTK+ {{interface}} and saves files in HTML5+CSS format. Images can be embedded using base64 encoding. It is available for installation in the Ubuntu and Debian repositories.|$|R
40|$|We {{present a}} {{formally}} coherent and consistent multi-species MHC ontology which includes all human MHC alleles and serological groups. The ontology {{is part of}} StemNet a knowledge management system for hematopoietic stem cell transplantation with an integrated semantic search engine. The Owl-encoded MHC ontology contributes to the system in a threefold manner. First, it supports query formulation and query processing as well as mapping onto external terminological resources, second, it eases the interaction with the search engine when navigating through search results, and finally, it provides a formal language for text annotation, a methodological prerequisite for state-of-the-art natural language <b>text</b> <b>processors</b> which are increasingly based on machine learning methods and hence require annotated text corpora...|$|R
40|$|Abstract Tractor is {{a system}} for {{understanding}} English messages within the con-text of hard and soft information fusion for situation assessment. Tractor processes a message through <b>text</b> <b>processors</b> using standard natural language processing tech-niques, and represents the result in a formal knowledge representation language. The result is a hybrid syntactic-semantic knowledge base that is mostly syntactic. Tractor then adds relevant ontological and geographic information. Finally, it applies hand-crafted syntax-semantics mapping rules to convert the syntactic information into semantic information, although the final result is still a hybrid syntactic-semantic knowledge base. This chapter presents the various stages of Tractor’s natural lan-guage understanding process, with particular emphasis on discussions of the repre-sentation used and of the syntax-semantics mapping rules. ...|$|R
