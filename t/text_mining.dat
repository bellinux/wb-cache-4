4623|540|Public
5|$|Sociologists {{increasingly}} {{draw upon}} computationally intensive methods to analyse and model social phenomena. Using computer simulations, artificial intelligence, <b>text</b> <b>mining,</b> complex statistical methods, and new analytic approaches like {{social network analysis}} and social sequence analysis, computational sociology develops and tests theories of complex social processes through bottom-up modelling of social interactions.|$|E
5|$|There are {{numerous}} applications of matrices, both {{in mathematics and}} other sciences. Some of them merely {{take advantage of the}} compact representation of a set of numbers in a matrix. For example, in game theory and economics, the payoff matrix encodes the payoff for two players, depending on which out of a given (finite) set of alternatives the players choose. <b>Text</b> <b>mining</b> and automated thesaurus compilation makes use of document-term matrices such as tf-idf to track frequencies of certain words in several documents.|$|E
25|$|Megaputer Intelligence: {{data and}} <b>text</b> <b>mining</b> {{software}} is called PolyAnalyst.|$|E
30|$|Thus, what we {{know about}} the world consists, in large part, of {{semantic}} relations. ‘For an automatic system to grasp a text’s semantic content, it must be able to recognize and reason the relationships in texts’ [13]. Currently, due to the availability of large corpora of <b>texts,</b> <b>mining</b> relations in these texts become more and more frequent. The relational knowledge sought in this case has been of different types, mainly taxonomic knowledge, ontological knowledge, or event knowledge.|$|R
40|$|This paper {{presents}} {{a survey of}} basic concepts {{in the area of}} <b>text</b> data <b>mining</b> and some of the methods used in order to elicit useful knowledge from collections of textual data. Three different <b>text</b> data <b>mining</b> techniques (clustering/visualisation, association rules and classification models) are analysed and its exploitation possibilities within the Webocracy project are showed. Clustering and association rules discovery are well suited as supporting tools for ontology management. Classification models are used for automatic documents annotation...|$|R
40|$|This article, manuscript, or {{document}} is copyrighted by the American Psychological Association (APA). For non-commercial, {{education and research}} purposes, users may access, download, copy, display, and redistribute this article or manuscript as well as adapt, translate, or data and <b>text</b> <b>mine</b> the content contained in this document. For any such use of this document, appropriate attribution or bibliographic citation must be given. Users should not delete any copyright notices or disclaimers. For more information or to obtain permission beyond that granted here, visi...|$|R
25|$|In November 2015 Elsevier {{blocked a}} {{scientist}} from performing <b>text</b> <b>mining</b> research at scale on Elsevier papers, {{even though his}} institution already pays for access to Elsevier journal content. The data were collected via parsing of downloaded PDF and HTML files, although Elsevier claimed that the method used was screenscraping.|$|E
25|$|Natural {{language}} processing gives machines {{the ability to}} read and understand human language. A sufficiently powerful natural {{language processing}} system would enable natural language user interfaces and the acquisition of knowledge directly from human-written sources, such as newswire texts. Some straightforward applications of natural language processing include information retrieval, <b>text</b> <b>mining,</b> question answering and machine translation.|$|E
25|$|Spamming on online social {{networks}} is quite prevalent. A primary motivation to spam {{arises from the}} fact that a user advertising a brand would like others to see them and they typically publicize their brand over the social network. Detecting such spamming activity has been well studied by developing a semi-automated model to detect spams. For instance, <b>text</b> <b>mining</b> techniques are leveraged to detect regular activity of spamming which reduces the viewership and brings down the reputation (or credibility) of a public pages maintained over Facebook. In some online {{social networks}} like Twitter, users have evolved mechanisms to report spammers which has been studied and analyzed.|$|E
40|$|The {{possibilities}} for data <b>mining</b> from large <b>text</b> collections are virtually untapped. Text expresses a vast, rich range of information, but encodes this {{information in a}} form that is difficult to decipher automatically. Perhaps for this reason, there has been little work in <b>text</b> data <b>mining</b> to date, and most people who have talked about it have either conflated it with information access or have not made use of text directly to discover heretofore unknown information. In this paper I will first define data mining, information access, and corpus-based computational linguistics, and then discuss the relationship of these to <b>text</b> data <b>mining.</b> The intent behind these contrasts is to draw attention to exciting new kinds of problems for computational linguists. I describe examples of what I consider to be real <b>text</b> data <b>mining</b> efforts and briefly outline our recent ideas about how to pursue exploratory data analysis over text...|$|R
40|$|The current Ebola virus {{epidemic}} {{may provide}} some suggestions {{of how we}} can better prepare for the next pathogen outbreak. We propose several cost effective steps that could be taken that would impact the discovery and use of small molecule therapeutics including: 1. <b>text</b> <b>mine</b> the literature, 2. patent assignees and/or inventors should openly declare their relevant filings, 3. reagents and assays could be commoditized, 4. using manual curation to enhance database links, 5. engage database and curation teams, 6. consider open science approaches, 7. adapt the “box” model for shareable reference compounds, and 8. involve the physician’s perspective...|$|R
40|$|analysis to <b>text</b> {{and data}} <b>mining</b> to be {{integrated}} in various research|$|R
25|$|Rough set {{methods can}} be applied as a {{component}} of hybrid solutions in machine learning and data mining. They {{have been found to be}} particularly useful for rule induction and feature selection (semantics-preserving dimensionality reduction). Rough set-based data analysis methods have been successfully applied in bioinformatics, economics and finance, medicine, multimedia, web and <b>text</b> <b>mining,</b> signal and image processing, software engineering, robotics, and engineering (e.g. power systems and control engineering). Recently the three regions of rough sets are interpreted as regions of acceptance, rejection and deferment. This leads to three-way decision making approach with the model which can potentially lead to interesting future applications.|$|E
25|$|Information {{access is}} an area of {{research}} at the intersection of Informatics, Information Science, Information Security, Language Technology, Computer Science, and Library Science. The objectives of information access research are to automate the processing of large and unwieldy amounts of information and to simplify users' access to it. What about assigning privileges and restricting access to unauthorized users? The extent of access should be defined in the level of clearance granted for the information. Applicable technologies include information retrieval, <b>text</b> <b>mining,</b> text editing, machine translation, and text categorisation. In discussion, information access is often defined as concerning the insurance of free and closed or public access to information and is brought up in discussions on copyright, patent law, and public domain. Public libraries need resources to provide knowledge of information assurance.|$|E
25|$|The nodes of {{this network}} can {{represent}} genes, proteins, mRNAs, protein/protein complexes or cellular processes. Nodes that are depicted as lying along vertical lines {{are associated with}} the cell/environment interfaces, while the others are free-floating and can diffuse. Edges between nodes represent interactions between the nodes, that can correspond to individual molecular reactions between DNA, mRNA, miRNA, proteins or molecular processes through which the products of one gene affect those of another, though the lack of experimentally obtained information often implies that some reactions are not modeled at such a fine level of detail. These interactions can be inductive (usually represented by arrowheads or the + sign), with an increase in the concentration of one leading to an increase in the other, inhibitory (represented with filled circles, blunt arrows or the minus sign), with an increase in one leading to a decrease in the other, or dual, when depending of the circumstances the regulator can activate or inhibit the target node. The nodes can regulate themselves directly or indirectly, creating feedback loops, which form cyclic chains of dependencies in the topological network. The network structure is an abstraction of the system's molecular or chemical dynamics, describing the manifold ways in which one substance affects all the others to which it is connected. In practice, such GRNs are inferred from the biological literature on a given system and represent a distillation of the collective knowledge about a set of related biochemical reactions. To speed up the manual curation of GRNs, some recent efforts try to use <b>text</b> <b>mining,</b> curated databases, network inference from massive data, model checking and other information extraction technologies for this purpose.|$|E
40|$|Abstract: Information {{explosion}} {{has resulted}} in the need for more advanced methods for managing the information. <b>Text</b> stream <b>mining,</b> is very important as people and organizations are trying to process and understand as much of information as possible. Generalised suffix tree is a data structure which is capable of solving a number of <b>text</b> stream <b>mining</b> tasks like detecting changes in the text stream, identifying reuse of text and detecting events by identifying when the frequencies of phrases change in a statistically significant way. An efficient method with polynomial time complexity that uses suffix trees to analyse streams of data in an online setting is discussed...|$|R
50|$|The DisGeNET {{database}} integrates over 400 000 {{associations between}} > 17 000 genes and > 14 000 diseases from human to animal model expert curated databases with <b>text</b> <b>mined</b> GDAs from MEDLINE using a NLP-based approach. The highlights of DisGeNET are the data integration, standardisation and a fine-grained tracking of the provenance information. The integration is performed {{by means of}} gene and disease vocabulary mapping and by using the DisGeNET association type ontology. Furthermore, GDAs are organised according to their type and level of evidence as CURATED, PREDICTED and LITERATURE, and they are also scored based on the supporting evidence to prioritise and ease their exploration.|$|R
5000|$|Information {{technology}} research, such as predictive Chinese text input for mobile phones, automatic {{speech to}} <b>text</b> conversion, opinion <b>mining</b> ...|$|R
2500|$|Feldman, Ronen; Sanger, James (2007); The <b>Text</b> <b>Mining</b> Handbook, Cambridge University Press, ...|$|E
2500|$|Like {{many other}} {{database}} that store protein association knowledge STRING imports data from experimentally derived protein–protein interactions through literature curation. [...] Furthermore, STRING also store computationally predicted interactions from: (i) <b>text</b> <b>mining</b> of scientific texts, (ii) interactions computed from genomic features, and ...|$|E
2500|$|A {{variety of}} computational, {{mathematical}} and statistical methods {{are available and}} reported. These tools are helpful for collection, analysis, and interpretation of immunological data. They include <b>text</b> <b>mining,</b> information management, sequence analysis, analysis of molecular interactions, and mathematical models that enable advanced simulations of immune system and immunological processes.|$|E
40|$|Morphology (including word segmentation) Part {{of speech}} tagging Syntax and parsing Grammar Engineering Word sense {{disambiguation}} Lexical semantics Mathematical Linguistics Textual entailment and paraphrasing Discourse and pragmatics Knowledge acquisition and representation Noisy data analysis Machine translation Multilingual language processing Language generation Summarization Question answering Information retrieval Information extraction Topic classification and information filtering Non-topical classification (sentiment/genre analysis) Topic clustering <b>Text</b> and speech <b>mining</b> <b>Text</b> classification Evaluation (e. g., intrinsic, extrinsic, user studies...|$|R
40|$|We present {{progress}} towards automated Lecture Transcription (LT) in resource scarce environments. Our {{development has}} focused on the transcription of lectures in Afrikaans from two faculties at North-West University. A bootstrapping procedure is followed to filter and select well-aligned segments of speech. These segments are then used to train acoustic models. Initial work towards language modeling for LT in a resource-scarce environment is also presented; manual lecture transcriptions are combined with <b>text</b> <b>mined</b> from other sources such as study guides to train language models. Interpolation results indicate that study guides are a useful resource for language modeling, whereas general text (obtained from a publisher of Afrikaans books) is less useful in this context. Our findings are confirmed by the reduced word error rates (WERs) obtained from our off-line speech-recognition system for Lecture Transcription. [URL]...|$|R
40|$|New {{copyright}} {{exceptions to}} <b>text</b> and data <b>mining</b> for non-commercial research have recently {{come into effect}} and this is welcome news for UK researchers and research, argues Ross Mounce. Here he provides {{a brief overview of}} the past issues discouraging <b>text</b> and data <b>mining</b> and the what the future holds now that these exceptions have been introduced. But despite legal barriers being removed, many technical barriers still remain. Furthermore it remains to be decided what formally constitutes ‘non-commercial’ research...|$|R
5000|$|<b>Text</b> <b>mining,</b> a {{collection}} of <b>text</b> <b>mining</b> datasets with concept drift, maintained by I.Katakis. Access ...|$|E
50|$|Averbis GmbH {{provides}} text analytics and <b>text</b> <b>mining</b> {{software to}} transform unstructured text into actionable information. It {{was founded in}} 2007 by IT experts after years of relevant scientific experience {{in the field of}} <b>text</b> <b>mining</b> and multilingual information retrieval. Averbis works in the field of terminology management, natural language processing, machine learning and semantic search. Its <b>text</b> <b>mining</b> software is embedded into the <b>text</b> <b>mining</b> framework UIMA.|$|E
50|$|<b>Text</b> <b>mining</b> {{computer}} programs {{are available from}} many commercial and open source companies and sources. See List of <b>text</b> <b>mining</b> software.|$|E
40|$|We {{introduce}} a knowledge-based approach to deep knowledge discovery from real-world natural language <b>texts.</b> Data <b>mining,</b> data interpretation, and data cleaning are all incorporated in cy-cles of quality-based terminological reasoning processes [...] The methodology we propose identifies new knowledge items and assimilates {{them into a}} continuously updated domain knowl-edge base...|$|R
40|$|The work in {{my thesis}} unless {{indicated}} otherwise in the <b>text,</b> is <b>mine</b> {{and has not}} been presented for a degree study in another university. All sources of information I used to substantiate claims and arguments have been acknowledged in respect of intellectual property and copyright. The University of KwaZulu-Natal certified ethical clearance for this study...|$|R
40|$|Table is a {{very common}} {{presentation}} scheme, but few papers touch on table extraction in <b>text</b> data <b>mining.</b> This paper focuses on mining tables from large-scale HTML texts. Table filtering, recognition, interpretation, and presentation are discussed. Heuristic rules and cell similarities are employed to identify tables. The F-measure of table recognition is 86. 50 %. We also propose an algorithm to capture attribute-value relationships among table cells. Finally, more structured data is extracted and presented. Introduction Tables, which are simple and easy to use, are very common presentation scheme for writers to describe schedules, organize statistical data, summarize experimental results, and so on, in texts of different domains. Because tables provide rich information, table acquisition is useful for many applications such as document understanding, question-and-answering, text retrieval, etc. However, most of previous approaches on <b>text</b> data <b>mining</b> focus on <b>text</b> parts, and only few [...] ...|$|R
50|$|One online <b>text</b> <b>mining</b> {{application}} in the biomedical literature is PubGene that combines biomedical <b>text</b> <b>mining</b> with network visualization as an Internet service.|$|E
50|$|L. Lebart, Validation {{technique}} in <b>Text</b> <b>Mining.</b> In : Spiros Sirmakessis (ed.), <b>Text</b> <b>Mining</b> and its Application, Springer Verlag, Berlin - Heidelberg, p 169-178, 2004.|$|E
5000|$|BioCreAtIvE (A {{critical}} {{assessment of}} <b>text</b> <b>mining</b> methods in molecular biology) consists in a community-wide effort for evaluating information extraction and <b>text</b> <b>mining</b> {{developments in the}} biological domain.|$|E
40|$|<b>Text</b> <b>mined</b> hypertension, obesity, {{diabetes}} {{candidate gene}} database (T-HOD) is a database developed to collect lists of genes {{that are associated}} with three kinds of cardiovascular diseases – hypertension, obesity and diabetes, with the last disease specified into Type 1 and Type 2. T-HOD employed the state-of-art text-mining technologies, including a gene mention recognition/gene normalization system and a disease-gene relation extraction system, which can be used to affirm the association of genes with the three diseases and provide more evidence for further studies. The primary inputs of T-HOD are the three kinds of diseases, and the output is a list of disease-related genes which can be ranked based on their number of appearance, protein-protein interactions and single nucleotide polymorphisms. Currently, 837, 835, and 821 candidate genes are recorded in T-HOD for hypertension, obesity and diabetes, respectively. We believe T-HOD can help life scientists in search for more disease candidate genes in a less timeand effort-consuming manner. T-HOD is available a...|$|R
40|$|Spreadsheets {{applications}} allow data to {{be stored}} with low development overheads, but also with low data quality. Reporting on data from such sources is difficult using traditional techniques. This case study uses <b>text</b> data <b>mining</b> techniques to analyse 12 years of data from dam pump station maintenance logs stored as free text in a spreadsheet application. The goal was to classify the data as scheduled maintenance or unscheduled repair jobs. Data preparation steps required to transform the data into a format appropriate for <b>text</b> data <b>mining</b> are discussed. The data is then mined by calculating term weights to which clustering techniques are applied. Clustering identified some groups that contained relatively homogeneous types of jobs. Training a classification model to learn the cluster groups allowed those jobs to be identified in unseen data. Yet clustering did not provide a clear overall distinction between scheduled and unscheduled jobs. With some manual analysis to code a target variable for {{a subset of the}} data, classification models were trained to predict the target variable based on text features. This was achieved with a moderate level of accuracy. ...|$|R
40|$| 3) Build a {{software}} platform that will allows tools ranging from sequence analysis to <b>text</b> and data <b>mining</b> {{to be integrated}} in various research environments so as to answer specific needs of academic and industrial users. |$|R
