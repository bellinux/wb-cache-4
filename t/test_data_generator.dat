54|10000|Public
50|$|Based on the Mathematical Modelling above we {{can simply}} state the <b>Test</b> <b>Data</b> <b>Generator</b> Problem as:Given a program P and a path u, {{generate}} input x ∈ S, so that x traverses path u.|$|E
50|$|The test {{specification}} should {{be stored in}} the test repository in a text format (such as source code).Test data is sometimes generated by some <b>test</b> <b>data</b> <b>generator</b> tool.Test data {{can be stored in}} binary or text files.Test data should also be stored in the test repository together with the {{test specification}}.|$|E
50|$|Pathwise Test Data Generation is {{considered}} {{to be one of the}} best approaches to Test Data Generation. This approach does not give the generator the choice of selecting between multiple paths but just gives it one specific path for it to work on. Hence, the name Pathwise <b>Test</b> <b>Data</b> <b>Generator.</b> Thus, except for the fact that this method uses specific paths it is quite similar to Goal-Oriented test data generation. The use of specific paths leads to a better knowledge and prediction of coverage. However, this also makes it harder to generate the needed test data.|$|E
40|$|Abstract [...] Test data {{generation}} {{is basically the}} process of identifying a set of data which satisfy the criteria set for testing. Lot of research have been done by many researchers and they developed many <b>test</b> <b>data</b> <b>generators</b> like random <b>test</b> <b>data</b> <b>generators,</b> symbolic <b>test</b> <b>data</b> <b>generators</b> and dynamic <b>test</b> <b>data</b> <b>generators.</b> This paper applied the optimization study of the test case generation based on the Genetic Algorithm and generates test cases which are far more reliable. 4. [REPLACE] New population {{generation is}} replaced. 5. [TEST] If the specified condition is satisfied stop and return the solution [1]. Keywords [...] Test case generation, Genetic Algorithms, fitness functions, optimizatio...|$|R
5000|$|Pathwise <b>test</b> <b>data</b> <b>generators</b> require two inputs {{from the}} user: ...|$|R
40|$|We {{present a}} novel {{counterexample}} generator for the interactive theorem prover Isabelle {{based on a}} compiler that synthesizes <b>test</b> <b>data</b> <b>generators</b> for functional programming languages (e. g. ML, Haskell) from specifications in Isabelle. In contrast to naive type-based <b>test</b> <b>data</b> <b>generators,</b> the smart generators take the preconditions into account and only generate tests that fulfill the preconditions. The smart generators are constructed by a compiler that reformulates the preconditions as logic programs and analyzes them with an enriched mode inference. From this inference, the compiler can construct the desired generators in the functional programming language. Applying these <b>test</b> <b>data</b> <b>generators</b> reduces the number of tests significantly and enables us to find errors in specifications where naive random and exhaustive testing fail...|$|R
40|$|Rule-based {{software}} {{test data}} generation is proposed {{as an alternative}} to either path/predicate analysis or random data generation. A prototype rule-based <b>test</b> <b>data</b> <b>generator</b> for Ada programs is constructed and compared to a random <b>test</b> <b>data</b> <b>generator.</b> Four Ada procedures are used in the comparison. Approximately 2000 rule-based test cases and 100, 000 randomly generated test cases are automatically generated and executed. The success of the two methods is compared using standard coverage metrics. Simple statistical tests showing that even the primitive rule-based test data generation prototype is significantly better than random data generation are performed. This result demonstrates that rule-based test data generation is feasible and shows great promise in assisting test engineers, especially when the rule base is developed further...|$|E
40|$|Abstract—Although search-based test-data generators, like EVOSUITE, {{efficiently}} and automatically create effective JUnit test suites for Java classes, these tools are {{often difficult to}} configure. Prior work by Arcuri and Fraser revealed that the tuning of EVOSUITE with response surface methodology (RSM) yielded a configuration of the <b>test</b> <b>data</b> <b>generator</b> that did not outperform the default configuration. Following the experimental design and protocol described by Arcuri and Fraser, this paper {{presents the results of}} a study that lends further support to prior results: like RSM, the EVOSUITE configuration identified by the well-known Sequential Parameter Optimization Toolbox (SPOT) failed to significantly outperform the default settings. Although this result is negative, it furnishes further empirical evidence of the challenge associated with tuning a complex search-based <b>test</b> <b>data</b> <b>generator.</b> Moreover, the outcomes of the presented experiments also suggests that EVOSUITE’s default parameters have been set by experts in the field and are thus suitable for use in future experimental studies and industrial testing efforts. I...|$|E
40|$|Test {{effectiveness}} {{is a fundamental}} quality aspect of a test specification, which reflects its ability to demonstrate system quality levels and discover system faults. The {{effectiveness is}} tightly linked {{with the quality of}} the test data. The paper highlights specific challenges related to testing eHealth applications and emphasizes the difficulties in testing HL 7 v 3 based applications. This paper presents a new approach on generating input test data sets: a highly customizable distance-based <b>test</b> <b>data</b> <b>generator.</b> The paper highlights the importance of having organized structures of test data and shows how the proposed <b>test</b> <b>data</b> <b>generator</b> uses adaptable distances to create clusters of test data. The generator is designed to create test data in a testing language independent format and provide means of conversion to the format used by the target testing language. A general architecture of this generator is presented, and implementation guidelines are proposed. The paper also presents the conclusions drawn from validating the generator in a real scenario...|$|E
40|$|We {{present a}} {{technique}} for automatically deriving <b>test</b> <b>data</b> <b>generators</b> from a given executable predicate representing {{the set of}} values {{we are interested in}} generating. The distribution of these generators is uniform over values of a given size. To make the generation efficient, we rely on laziness of the predicate, allowing us to prune the space of values quickly. In contrast, implementing <b>test</b> <b>data</b> <b>generators</b> by hand is labour intensive and error prone. Moreover, handwritten generators often have an unpredictable distribution of values, risking that some values are arbitrarily underrepresented. We also present a variation of the technique that has better performance, but where the distribution is skewed in a limited, albeit predictable way. Experimental evaluation of the techniques shows that the automatically derived generators are much easier to define than handwritten ones, and their performance, while lower, is adequate for some realistic applications...|$|R
40|$|QuickCheck {{is a tool}} which aids the Haskell {{programmer}} {{in formulating}} and testing properties of programs Properties are described as Haskell functions and can be automati cally tested on random input {{but it is also}} possible to de ne custom <b>test</b> <b>data</b> <b>generators</b> We present a number of case studies in which the tool was successfully used and also point out some pitfalls to avoid Random testing is es pecially suitable for functional programs because properties can be stated at a ne grain When a function is built from separately tested components then random testing suces to obtain good coverage of the denition under test 1...|$|R
40|$|ABSTRACT QuickCheck {{is a tool}} which aids the Haskell {{programmer}} {{in formulating}} and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, {{but it is also}} possible to define custom <b>test</b> <b>data</b> <b>generators.</b> We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test. 1...|$|R
40|$|Abstract The Godzilla {{automatic}} <b>test</b> <b>data</b> <b>generator</b> is {{an integrated}} collection of tools that implements {{a relatively new}} test data generation method, constraint-based testing, {{that is based on}} mutation analysis. Constraint-based testing integrates mutation analysis with several other testing techniques, including statement coverage, branch coverage, domain perturbation and symbolic evaluation. Because Godzilla uses a rule-based approach to generate test data, it is easily extendible to allow new testing techniques to be integrated into the current system...|$|E
40|$|Evolutionary methods {{when used}} as a <b>test</b> <b>data</b> <b>generator</b> {{optimize}} the given input (usually called test case) according to a selected test coverage criterion encoded as a fitness function. Basically, the genetic algorithms and other Evolutionary techniques are based on pure random search. However, these algorithms adapt to the given problem. In the last decade lot of evolution based metaheuristic techniques are applied for searching software errors. This survey paper presents the work applying computational evolutionary methods in structural software testing based test data generation...|$|E
40|$|Software testing consumes half of {{the entire}} {{software}} development cost where test case generation is the most cost consuming activity in the whole process. The emergence of automatic test case generation has helped in reducing the cost eventually. Recently, model-based testing (MBT) for automatic test case generation gains interest in industry and academia due to its provision of systematic, automated, and comprehensive testing. One of the input models for MBT is state machine model which currently widely utilized to model embedded systems. Generating test cases from Unified Modeling Language (UML) state machine models has two major challenges: generating feasible paths, and generating data to satisfy the paths. The existing infeasible path detection methods are restricted to extended finite state machine (EFSM) models with integer data type only. For detecting infeasible paths that involve Object Constraints Language (OCL) constraints, new method is needed {{to cover all the}} sophisticated constructs of OCL. For test data generation, the existing search-based techniques (SBTs) have been applied to satisfy only one OCL constraint by time. In order to generate optimal data to satisfy whole constraints in the feasible path, new method with SBTs is necessary to satisfy the whole constraints at the same time of the whole path executing. This thesis presents a method for generating feasible test cases from UML state machine models with OCL constraints. One contribution of this thesis is developing an efficient technique for detecting automatically infeasible paths that contain transitions with conflicted OCL constraints. A model-driven approach was used for generating abstract test cases from the feasible paths. This model driven approach was integrated with the proposed infeasible path detection method which based on analyzing various OCL constructs and operations. The second contribution of this thesis is developing an accurate search-based <b>test</b> <b>data</b> <b>generator</b> for generating automatically optimal test data to satisfy the whole constraints in the path. In the proposed search-based <b>test</b> <b>data</b> <b>generator,</b> a whole constraints analyzer and a fitness function that evolves itself based on the error feedback were proposed. The whole constraint analyzer and the fitness function were combined with four SBTs (genetic algorithm, evolutionary algorithm, simulating annealing, and quantum genetic algorithm). Case study evaluation was conducted based on three industrial open source case studies in order to evaluate empirically the significant of the performance of the proposed method. The results were statically analyzed using t-test to show the significance of the proposed method compared to the existing methods. The results show that the proposed infeasible path detection method was efficient and detect 99 percent of the infeasible paths in the three industrial systems. The results of the proposed search-based <b>test</b> <b>data</b> <b>generator</b> show significant performance compared to the existing search-based <b>test</b> <b>data</b> <b>generator...</b>|$|E
40|$|Abstract—Developing, for example, {{a simple}} booking web service with modern tools {{can be a}} matter of a few weeks work. Testing such a system should not need to take more time than that. Automatically {{generating}} tests from specified properties of the system using the tool QuickCheck provides professional developers with the required test efficiency. But how good is the quality of these automatically generated tests? Do they cover the cases that one would have written in manual tests? The quality depends on the specified properties and <b>data</b> <b>generators</b> and so far there has not been an objective way to evaluate the quality of these QuickCheck generators. In this paper we present a method to assess the quality of QuickCheck <b>test</b> <b>data</b> <b>generators</b> by formulating requirements on them. Using this method we can give feedback to developers of such <b>data</b> <b>generators</b> in an early stage. The method supports developers in improving <b>data</b> <b>generators,</b> which may lead to an increase of the effectiveness in testing while maintaining the same efficiency. I...|$|R
40|$|Due to the {{frequent}} non-existence of an automated oracle, test cases are often evaluated manually in practice. However, {{this fact is}} rarely taken into account by automatic <b>test</b> <b>data</b> <b>generators,</b> which seek to maximise a program’s structural coverage only. The <b>test</b> <b>data</b> produced tends to be of a poor fit with the program’s operational profile. As a result, each test case takes longer for a human to check, because the scenarios that arbitrary-looking data represent require {{time and effort to}} understand. This short paper proposes methods to extracting knowledge from programmers, source code and documentation and its incorporation into the automatic <b>test</b> <b>data</b> generation process so as to inject the realism required to produce test cases that are quick and easy for a human to comprehend and check. The aim is to reduce the so-called qualitative human oracle costs associated with automatic <b>test</b> <b>data</b> generation. The potential benefits of such an approach are demonstrated with a simple case study. 1...|$|R
40|$|The actual <b>test</b> <b>data</b> {{generation}} {{is one of}} the difficult and expensive parts of applying software-testing techniques. Many of the current <b>test</b> <b>data</b> <b>generators</b> suffer from the reduction of user’s confidence in generated <b>test</b> <b>data</b> and <b>testing</b> process. This is because of focusing on developer and database administrator viewpoints regardless of users concerns and focusing on data type and structure regardless of meaning. This paper proposes a model of an intelligent <b>generator</b> for semi-actual <b>test</b> <b>data</b> with the aim of increasing users confidence in software testing. The model uses samples of real data as a resource data and a set of efficient generation techniques based on statistical methods such as permutations, combination, sampling, and statistical distributions. The selection of the suitable structure and generation technique is based on one of the intelligent soft computing techniques such as fuzzy logic, neural network, heuristic, or genetic algorithm. The generated <b>test</b> <b>data</b> is validated according to the <b>data</b> specifications then <b>tested</b> by one of the normality testing techniques to be close to the real world or environment of the testing processes. This model offers the ability of simulating real environments. Key Words : Software <b>Testing,</b> Test <b>Data</b> Generation, Semi-Actual <b>Data,</b> Intelligent <b>Generator,</b> Simulation. </p...|$|R
40|$|Testing {{of systems}} and {{applications}} {{is part of}} their development and therefore, testing data generation is very important. <b>Test</b> <b>data</b> <b>generator</b> according to a previously created template is as a tool for inserting test data to the database tables. This software allows developers or administrators to effectively test various systems that use the database storage. Data generation is carried out according to a pre - created template that defines the structure of database tables. The thesis describes the related topics of database systems and the process of the apllication implementation...|$|E
40|$|Results of {{research}} and development efforts are presented for Task 1, Phase 2 of a general project entitled, The Development of a Program Analysis Environment for Ada. A prototype of the QUEST/Ada system was developed to collect data to determine the effectiveness of the rule-based testing paradigm. The prototype consists of five parts: the <b>test</b> <b>data</b> <b>generator,</b> the parser/scanner, the test coverage analyzer, a symbolic evaluator, and a data management facility, known as the Librarian. These components are discussed at length. Also presented is an experimental design for the evaluations, an overview of the project, and a schedule for its completion...|$|E
40|$|In {{order to}} reduce the high cost of manual {{software}} testing {{and at the same time}} to increase the reliability of the testing processes researchers and practitioners have tried to automate it. One of the most important components in a testing environment is an automatic <b>test</b> <b>data</b> <b>generator</b> [...] - a system that automatically generates test data for a given program. Through the years several attempts in automatic test data generations have been made. The focus of this article is program-based generation, where the generation starts from the actual programs. Thus, techniques such as GUI-based and syntax-based test data generation are not an issue in this article...|$|E
40|$|A {{major issue}} in {{software}} testing is the automatic generation of the inputs {{to be applied to}} the programme under test. To solve this problem, a number of approaches based on search methods have been developed in the last few years, offering promising results for adequacy criteria like, for instance, branch coverage. We devise branch coverage as the satisfaction of a number of constraints. This allows to formulate the <b>test</b> <b>data</b> generation as a constrained optimisation problem or as a constraint satisfaction problem. Then, we can see that many of the generators so far have followed the same particular approach. Furthermore, this constraint-handling point of view overcomes this limitation and opens the door to new designs and search strategies that, {{to the best of our}} knowledge, have not been considered yet. As a case study, we develop <b>test</b> <b>data</b> <b>generators</b> employing different penalty objective functions or multiobjective optimisation. The results of the conducted preliminary experiments suggest these generators can improve the performance of classical approaches. 1...|$|R
40|$|International audienceLUTESS is {{a testing}} tool for {{synchronous}} software making possible to automatically build <b>test</b> <b>data</b> <b>generators.</b> The latter {{rely on a}} formal model of the program environment composed {{of a set of}} invariant properties, supposed to hold for every software execution. Additional assumptions can be used to guide the <b>test</b> <b>data</b> generation. The environment descriptions together with the assumptions correspond to a test model of the program. In this paper, we apply this modeling principle to a well known case study, the steam boiler problem which has been presented in the past. The aim of this work is to illustrate the process of building the test model and to assess the difficulty of such a process in a realistic case study. The steam boiler case study is a quite suitable problem to use, in point of both problem size and complexity, for our purposes. Taking advantage of the new features recently added in LUTESS, we show a way of defining a test model so that the testing is efficient...|$|R
40|$|In {{this paper}} we present an {{approach}} of using model-driven technologies for testing of service component interactions. We report on an industrial experiment {{with a novel}} combination of existing UML standards, i. e., the UML Testing Profile (U 2 TP), in conjunction with proprietary domain specific languages (DSLs). Many model-based testing (MBT) approaches use the UML 2 standard, but {{very few of them}} use also U 2 TP. Moreover, in practice UML coexists with DSLs which makes the overall integration not easy. We present our experiences and challenges of a U 2 TP-enabled MBT approach for a DSL for enterprise service choreographies, which describe the communication protocols between service components. The proposed workflow directly translates choreographies into UML models augmented with U 2 TP stereotypes, which are further loaded into our FOKUS!MBT tool chain. The tool provides an implementation of the U 2 TP standalone meta-model along with test case and <b>test</b> <b>data</b> <b>generators</b> to desc ribe a holistic test process within one dedicated meta-model for testing concerns...|$|R
40|$|In {{software}} testing process, test data generation represents {{an important step}} for high quality software, even for mobile devices. As proposed in previous works, a potential source for random data generation {{is represented by the}} UI layout files that are used for almost all mobile platforms (Android, iOS, Windows Phone/Mobile). This paper continues the previous work and presents a test data generation system based on Android layout files. The <b>test</b> <b>data</b> <b>generator</b> uses DSL files as input and generates test data that conform to several testing principles. The generated test data could be stored in XML files or any format required by the testing frameworks...|$|E
40|$|A {{key issue}} in {{software}} testing {{is the actual}} generation of test data from program input domain. Obviously, more accurate input domain is, more efficient test generation is. This paper presents a path-orientedautomatic random testing method based on double constraint propagation. For a given path, its domain can be reduced by splitting an input variable domain and executing a double constraint propagation algorithm. Moreover, a random <b>test</b> <b>data</b> <b>generator</b> is developed according to the reduced path domain and the test experiments are conducted {{on a number of}} programs. Experimental results show that the methodgets more accurate path domain than PRT (path-oriented random testing) approach, and random testing efficiency can thus be enhanced by using the proposed method...|$|E
40|$|International audienceWe {{introduce}} in {{this paper}} a new specification language named Praspel, for PHP Realistic Annotation and SPEcification Language. This language {{is based on the}} Design-by-Contract paradigm. Praspel clauses annotate methods of a PHP class in order to both specify their contracts, using pre- and postconditions, and assign realistic domains to the method parameters. A realistic domains describes a set of concrete, and hopefully relevant, values that can be assigned to the data of a program (class attributes and method parameters). Praspel is implemented into a unit test generator for PHP that offers a random <b>test</b> <b>data</b> <b>generator,</b> which computes test data, coupled with a runtime assertion checker, which decides whether a test passes or fails by checking the satisfaction of the contracts at run-time...|$|E
40|$|Business {{applications}} rely typically on databases {{for storing}} and processing their data (database-driven applications, or DBAPs). Testing DBAPs requires testing the application logic plus {{the interaction between}} the application logic and the database. Thus, DBAP test cases consist of input and output parameter values, the function to be tested, and an initial database state (i. e., DBAP <b>test</b> <b>data).</b> Various <b>test</b> <b>data</b> provisioning methods exist, such as manual <b>test</b> <b>data</b> design, <b>generators</b> for synthetic <b>test</b> <b>data,</b> and live-system snapshots. Many criteria and factors influence which method is optimal for a given project setting, such as costs, quality, data privacy, etc. This paper presents our methodology for guiding software development projects towards the DBAP <b>test</b> <b>data</b> provisioning method best suited for them...|$|R
40|$|Abstracr-Test data {{generation}} in program testing {{is the process}} of identifying a set of <b>test</b> <b>data</b> which satisfies given testing criterion. Most of the existing <b>test</b> <b>data</b> <b>generators</b> 161, [It], [lo], [16], [30] use symbolic evaluation to derive <b>test</b> <b>data.</b> However, in practical programs this technique frequently requires complex algebraic manipulations, espe-cially in the presence of arrays. In this paper we present an alternative approach of <b>test</b> <b>data</b> generation which is based on actual execution of the program under test, function minimization methods, and dynamic data flow analysis. Test data are developed for the program using ac-tual values of input variables. When the program is executed, the pro-gram execution flow is monitored. If during program execution an un-desirable execution flow is observed (e. g., the “actual ” path does not correspond to the selected control path) then function minimization search algorithms are used to automatically locate the values of input variables for which the selected path is traversed. In addition, dynamic data Bow analysis is used to determine those input variables responsi-ble for the undesirable program behavior, leading to significant speed-up of the search process. The approach of generating <b>test</b> <b>data</b> is then extended to programs with dynamic data structures, and a search method based on dynamic data flow analysis and backtracking is pre-sented. In the approach described in this paper, values of array in-dexes and pointers are known at each step of program execution, and this approach exploits this information to overcome difficulties of array and pointer handling; as a result, the effectiveness of <b>test</b> <b>data</b> gener-ation can be significantly improved. Zndex Terms-Automated <b>test</b> generation, dynamic <b>data</b> flow analy-sis, function minimization, software testing, symbolic evaluation. I...|$|R
40|$|QuickSpec finds {{algebraic}} {{properties of}} functional programs by testing. It is largely automatic: the user just supplies the functions to be <b>tested</b> and QuickCheck <b>data</b> <b>generators.</b> Earlier versions of QuickSpec scaled poorly; {{this paper describes}} a new design which is able to find vastly more complex laws than before. We demonstrate QuickSpec on problems which were out of reach until now, including Hughes’s pretty-printing library and Henderson’s functional geometry combinators. Categories and Subject Descriptors D. 2. 5 [Testing and Debug...|$|R
40|$|Domain {{testing is}} a {{well-known}} software testing technique. Although research tasks have been initiated in domain testing, automatic test data generation based on character string predicates {{has not yet been}} reported. This paper presents a novel approach to automatically generate ON-OFF test points for character string predicate borders associated with program paths, and describes a corresponding <b>test</b> <b>data</b> <b>generator.</b> Slices with respect to predicates on paths are constructed to calculate the current values of variables in the predicates via program slicing techniques. Each character element of variables in a character string predicate is dynamically determined in turn by function minimization so that the ON-OFF test points for the predicate border can be automatically generated. The preliminary experimental results show that this approach is promising and effective...|$|E
40|$|The Godzilla {{automatic}} <b>test</b> <b>data</b> <b>generator</b> is {{an integrated}} collection of tools that implements {{a relatively new}} test data generation method, constraint-based testing, {{that is based on}} mutation analysis. Constraint-based testing integrates mutation analysis with several other testing techniques, including statement coverage, branch coverage, domain perturbation and symbolic evaluation. Because Godzilla uses a rule-based approach to generate test data, it is easily extendible to allow new testing techniques to be integrated into the current system. This paper describes the system that has been built to implement constraint-based testing. Godzilla's design emphasizes orthogonality and modularity, allowing relatively easy extensions. Godzilla's internal structure and algorithms are described with emphasis on internal structures of the system, and the engineering problems that were solved during the implementation...|$|E
40|$|Usual {{techniques}} for automatic test data generation {{are based on}} the assumption that a complete oracle will be available during the testing process. However, there are programs for which this assumption is unreasonable. Recently, Chen et al. [3, 4] proposed to overcome this obstacle by using known relations over the input data and their unknown expected outputs to seek a subclass of faults inside the program. In this paper, we introduce an automatic testing framework able to check these so-called metamorphic relations. The framework makes use of Constraint Logic Programming techniques to find test data that violate a given metamorphic–relation. Circumstances where it can also prove that the program satisfies this relation are presented. The first experimental results we got with a prototype implementation build on the top of the <b>test</b> <b>data</b> <b>generator</b> INKA, show that this methodogy can be completely automated. 1...|$|E
40|$|This paper {{reports on}} an {{industrial}} {{study of the}} effectiveness of <b>test</b> <b>data</b> generation. In the literature on the automatic generation of <b>test</b> <b>data</b> a number of techniques stand out as having received a significant amount of interest. One area that has achieved considerable attention is the use of combinatorial techniques to construct <b>data</b> adequate <b>test</b> sets that ensure all pairs, triples etc. of input variables are included in at least one test vector. There has been some systematic evaluation of the technique as applied to unit testing and, while there are indications that the technique can be effective, very little work has been performed using industrial code. Moreover, there has been no comparison of effectiveness of the technique for unit testing compared with tests that are generated by hand. In this paper we apply random and combinatorial (AETG) techniques to a number of functions drawn from industrial code with known faults and existing unit test suites. Results indicate that for simple cases combinatorial techniques can be as effective as the human-generated test, but there are instances associated with complex code where the technique performs poorly—but no worse than randomly generated data. Categories and Subject Descriptors D. 2. 5 [Testing and Debugging]- <b>Testing</b> tools- <b>data</b> <b>generators...</b>|$|R
50|$|Intelligent Test <b>Data</b> <b>Generators</b> {{depend on}} {{sophisticated}} {{analysis of the}} code to guide the search of the <b>test</b> <b>data.</b> Intelligent Test <b>Data</b> <b>Generators</b> are essentially utilize one of the <b>test</b> <b>data</b> generation method coupled with the {{detailed analysis of the}} code. This approach may generate <b>test</b> <b>data</b> quicker than the other approaches but the analysis required for the utilization of this approach over a wide variety of programs is quite complex and requires a great deal of insight to anticipate the different situations that may arise.|$|R
40|$|PD <b>test</b> <b>data</b> {{on various}} <b>generators</b> and motors has been {{collected}} {{over the last}} 15 years using on-line partial discharge analyzers. A large PD test database has been established. The database provides an overall view of PD activity on rotating machines. Statistical analysis of the database provides a study of PD distribution with variations {{of a number of}} the parameters. This paper presents statistical analysis of a large PD database accumulated over the last 15 years. The statistical analysis shows distribution of PD levels with machine type, voltage rating, sensitivity of the PD sensor, etc. The benefits and limitations of the PD database on assessment of stator insulation condition are discussed in the paper...|$|R
