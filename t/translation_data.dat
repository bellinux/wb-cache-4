102|868|Public
5000|$|Translation memory automates {{translation}} of frequent phrases. Poedit can reuse <b>translation</b> <b>data</b> from all your PO, MO and RPM files.|$|E
50|$|The layer that {{provides}} this API {{is called the}} virtualized flash storage layer in the DFS paper. It {{is the responsibility of}} this layer to perform block allocation, wear leveling, garbage collection, crash recovery, address translation and also to make the address <b>translation</b> <b>data</b> structures persistent.|$|E
50|$|Content is {{scrubbed}} clean {{from the}} translation wizard upon exiting or refreshing the page. The software allows <b>translation</b> <b>data</b> to be deleted at the user’s discretion.Pairaphrase uses Secure Sockets Layer (SSL) encryption on its web pages where translations are entered, performed and stored. This {{also applies to}} other personal data such as payment information.|$|E
40|$|This paper {{reports on}} a case study aimed to {{investigate}} the role of visual context for stylistic differences in students' UI <b>translations.</b> <b>Data</b> from the two groups revealed stylistic differences and a tendency for a more consistent use of already conventionalized vocabulary on UI elements by the experimental group...|$|R
30|$|Moreover, asset {{management}} systems were suggested to make <b>translation</b> process <b>data</b> {{accessible to the}} scientific community.|$|R
5000|$|I18N support, {{code page}} (including UTF-8) <b>translation</b> between <b>data</b> files and SQL clients, Unicode support in Btrieve API, Japanese {{localization}} ...|$|R
50|$|ISI also {{operates}} the Metal Oxide Semiconductor Implementation Service (MOSIS), a multi-project electronic circuit wafer service that has prototyped more than 60,000 chips since 1981. MOSIS provides design tools and pools circuit designs to produce specialty and low-volume chips for corporations, universities and other research entities worldwide. The Institute also {{has given rise}} to several startup and spinoff companies in grid software, geospatial information fusion, machine <b>translation,</b> <b>data</b> integration and other technologies.|$|E
50|$|On top {{of those}} models the {{application}} model organises real applications (like the GUI model).openTMS uses a data {{source in the}} data model which organises the access to databases or {{any other kind of}} devices which allows to store (TM, terminology, even machine <b>translation)</b> <b>data.</b> Currently the following data sources are supported: TMX files, XLIFF file, SQL databases. Data sources have to implement a set of methods based on the data source interface.|$|E
50|$|The Professional Edition is a {{stand-alone}} solution which is particularly suited for localization projects of a medium to large size. It supports operations covering compound modules. As the edition is integrated with SDL Trados and SDL MultiTerm, <b>translation</b> <b>data</b> can be exported {{in order to}} use while translating relevant manuals and online help. It can also be used for data exchange with other systems. The integrated script development environment also makes it possible to change or add functions to SDL Passolo.|$|E
50|$|Some {{of these}} {{standards}} enable <b>translation</b> of <b>data</b> from unstructured (such as HTML or free-text files) to structured (such as XML or SQL).|$|R
40|$|Interest {{is rapidly}} growing in internationalized {{software}} {{that can be}} localized to various languages. This paper describes IDUX, an XML-based system designed to support the process of internationalizing data. A specific application of IDUX is to create internationalized websites, allowing the website owner to display information (such as his or her resume) in multiple languages. To support the reusability of <b>translations,</b> <b>data</b> and their <b>translations</b> are persistently stored in databases, using a novel approach to interfacing databases and XML data conformant to multiple XML schemas...|$|R
50|$|Semantic {{translation}} {{should be}} differentiated from data mapping tools that do simple one-to-one <b>translation</b> of <b>data</b> from one system to another without actually associating meaning with each data element.|$|R
5000|$|On August 1, 2008, the Washington Post {{reported}} that Department of Homeland Security policies allow federal agents to “take a traveler's laptop computer or other electronic device to an off-site location for an unspecified {{period of time}} without any suspicion of wrongdoing.” [...] Further, “officials may share copies of the laptop's contents with other agencies and private entities for language <b>translation,</b> <b>data</b> decryption or other reasons.” [...] Senator Russell Feingold called these policies “truly alarming” {{and said that he}} intends to introduce legislation soon that would require reasonable suspicion for border searches, as well as prohibit profiling on race, religion, or national origin. Meanwhile, Ryan Singel of Wired.com recommended placing one's electronics and papers “in a first class U.S. mail envelope and stamp it—or even better mail it to yourself before the trip,” [...] since ‘officers may not read or permit others to read correspondence contained in sealed letter class mail (the international equivalent of First Class) without an appropriate search warrant or consent’. However, this only applies to articles in the postal system, not to letters carried by individuals or private carriers such as DHL, UPS, or FedEx.|$|E
40|$|We {{describe}} {{a simple but}} effective method for cross-lingual syntactic transfer of dependency parsers, in the scenario where {{a large amount of}} <b>translation</b> <b>data</b> is not available. The method makes use of three steps: 1) a method for deriving cross-lingual word clusters, which can then be used in a multilingual parser; 2) a method for transferring lexical information from a target language to source language treebanks; 3) a method for integrating these steps with the density-driven annotation projection method of Rasooli and Collins (2015). Experiments show improvements over the state-of-the-art in several languages used in previous work, in a setting where the only source of <b>translation</b> <b>data</b> is the Bible, a considerably smaller corpus than the Europarl corpus used in previous work. Results using the Europarl corpus as a source of <b>translation</b> <b>data</b> show additional improvements over the results of Rasooli and Collins (2015). We conclude with results on 38 datasets from the Universal Dependencies corpora...|$|E
40|$|This paper {{provides}} an overview of state-of-the-art research in translation studies as represented in this special issue, with a special focus on corpus-based approaches that (re-) connect translation studies with other fields of corpus-based research in linguistics or which explore new types of <b>translation</b> <b>data</b> in the broadest possible sense of the term. It does so by singling out papers that illustrate different methods of data harvesting, on the one hand, particularly in areas that are currently underrepresented in the field, i. e. interpreting and subtitling, and by presenting studies that approach <b>translation</b> <b>data</b> from a perspective other than that of "translation universals"...|$|E
50|$|Translation Memory eXchange (TMX) is an XML {{specification}} for {{the exchange}} of <b>translation</b> memory <b>data</b> between computer-aided <b>translation</b> and localization tools {{with little or no}} loss of critical data.|$|R
50|$|The {{translation}} memory (TM) format of memoQ is proprietary and stored {{as a group}} of files in a folder bearing the name of the <b>translation</b> memory. External <b>data</b> can be imported in delimited text formats and Translation Memory eXchange format (TMX), and <b>translation</b> memory <b>data</b> can be exported as TMX. memoQ can also work with server-based translation memories on the memoQ Server or, using a plug-in, other external {{translation memory}} sources. memoQ Translation memories are bilingual.|$|R
50|$|The CCI {{may also}} provide other services, {{including}} security, <b>data</b> <b>translation,</b> etc.|$|R
30|$|Potential {{applications}} of our speech hiding scheme are reduction of speech storage and transmission overhead in electronic voice mail applications and audio streaming, speech <b>translation,</b> <b>data</b> communication secrecy, {{and many other}} web-based applications.|$|E
40|$|This paper {{describes}} {{the collection of}} an English-Japanese/Japanese-English simultaneous interpretation corpus. There are two main features of the corpus. The first is that professional simultaneous interpreters with different amounts of experience cooperated with the collection. By comparing data from simultaneous interpretation of each interpreter, {{it is possible to}} compare better interpretations to those that are not as good. The second is that for part of our corpus there are already <b>translation</b> <b>data</b> available. This makes it possible to compare <b>translation</b> <b>data</b> with simultaneous interpretation data. We recorded the interpretations of lectures and news, and created time-aligned transcriptions. A total of 387 k words of transcribed data were collected. The corpus will be helpful to analyze differences in interpretations styles and to construct simultaneous interpretation systems...|$|E
40|$|We {{describe}} {{a method for}} identifying systematic patterns in <b>translation</b> <b>data</b> using part-ofspeech tag sequences. We incorporate this analysis into a diagnostic tool intended for developers of machine translation systems, and demonstrate how our application {{can be used by}} developers to explore patterns in machine translation output. ...|$|E
5000|$|PDAL, an {{open source}} library for point cloud <b>data</b> <b>translation</b> and format {{abstraction}} ...|$|R
5000|$|<b>Translation</b> of {{statistical}} <b>data</b> into graphical expression, which started with William Playfair in 1768 ...|$|R
40|$|Purpose – The {{purpose of}} this paper is to address {{problems}} that exist in the context of XML to ontology translation. Existing research results dealing with XML to ontology translation do not facilitate bidirectional <b>data</b> <b>translation</b> due to the fundamental differences between XML schema and ontologies. This paper proposes a mapping representation ontology for modeling concept mappings defined between XML schema and ontology, enabling <b>data</b> <b>translation</b> without any information loss. Design/methodology/approach – A two-step compensation approach is proposed that aims to prevent the loss of data type, structural and relational information during any single trip <b>data</b> <b>translation.</b> The mapping representation ontology proposed is capable in capturing enough information to compensate the loss of information during translation, hence allowing bidirectional conversions between XML and ontology. Findings – Fundamental differences between XML schema and ontology are identified as the main reason causing the loss of information during <b>data</b> <b>translation.</b> A compensation approach that captures a sufficient amount of concept mapping information <b>data</b> <b>translation</b> is found to be successful in enabling lossless data transformation. Practical implications – Outcomes from this work allow for the seamless <b>data</b> <b>translation</b> between XML documents, it demonstrates how web applications can seamlessly communicate and exchange data with each other without the need to conform to a predefined data standard. This paper aims to enhance interoperability between distributed systems. Originality/value – This paper presents a mapping ontology that captures concept mappings defined between XML schema and ontology. Two algorithms facilitating the bidirectional XML to ontology translation are also proposed...|$|R
40|$|We {{propose a}} theory that gives formal {{semantics}} to word-level alignments defined over parallel corpora. We use our theory to introduce a linear algorithm {{that can be used}} to derive from word-aligned, parallel corpora the minimal set of syntactically motivated transformation rules that explain human <b>translation</b> <b>data.</b> ...|$|E
40|$|In {{statistical}} machine <b>translation,</b> <b>data</b> sparsity is {{a challenging}} problem espe-cially for languages with rich morphology and inconsistent orthography, such as Per-sian. We show that orthographic prepro-cessing and morphological segmentation of Persian verbs in particular improves the translation quality of Persian-English by 1. 9 BLEU points {{on a blind}} test set. ...|$|E
40|$|In {{the past}} ten to fifteen years {{considerable}} {{progress has been made}} in the field of parallel text alignment. The term parallel text itself is now well-established within the computational linguistics community. It refers to texts accompanied by their translations in one or several languages. Aligned texts have proved to be an invaluable source of <b>translation</b> <b>data</b> fo...|$|E
5000|$|<b>Data</b> remapping: The <b>translation</b> of <b>data</b> {{inside of}} the virtual directory. For instance, mapping “uid” to “samaccountname,” so a client {{application}} that only supports a standard LDAP-compliant data source is able to search an Active Directory namespace, as well.|$|R
5000|$|Monarch Health Services - Monarch is a <b>data</b> <b>translation,</b> {{interface}} {{engine for}} enterprise and system owners.|$|R
50|$|Validation Tool {{provides}} a mathematical comparison between two similar or different CAD models to ensure data integrity is maintained during a <b>translation</b> or <b>data</b> migration process. Validation Tool {{also has a}} version specifically to meet Boeing’s D6-51991 Requirements for Boeing’s suppliers.|$|R
40|$|A {{method is}} {{presented}} for incremental retraining of an SMT system, {{in which a}} local phrase table is created and incrementally updated as a file is translated and post-edited. It is shown that <b>translation</b> <b>data</b> from within the same file has higher value than other domain-specific data. In two technical domains, within-file data increases BLEU score by several full points. Furthermore, a strong recency effect is documented; nearby data within the file has greater value than more distant data. It is also shown {{that the value of}} <b>translation</b> <b>data</b> is strongly correlated with a metric defined over new occurrences of n-grams. Finally, it is argued that the incremental re-training prototype could {{serve as the basis for}} a practical system which could be interactively updated in real time in a post-editing setting. Based on the results here, such an interactive system has the potential to dramatically improve translation quality. ...|$|E
40|$|Any public {{administration}} that produces <b>translation</b> <b>data</b> {{can be a}} provider of useful reusable data to meet its own translation needs and the ones of other public organizations and private companies that work with texts of the same domain. These data can also be crucial to produce domain-tuned Machine Translation systems. The organization's management of the translation process, {{the characteristics of the}} archives of the generated resources and of the infrastructure available to support them determine the efficiency and the effectiveness with which the materials produced can be converted into reusable data. However, it is of utmost importance that the organizations themselves first become aware of the goods they are producing and, second, adapt their internal processes to become optimal providers. In this article, we propose a Maturity Model to help these organizations to achieve it by identifying the different stages of the management of <b>translation</b> <b>data</b> that determine the path to the aforementioned goal...|$|E
30|$|Finally, {{at the end}} of {{the dense}} array experiment, the {{rotation}} sensor was installed in co-location with a translation accelerometer, again in the Koutavos basin, 140  m from the first location of phase 1, at the location for the future permanent vertical array; this was operated from March 11, 2014, to July 2, 2015 (i.e., for around 16  months). This period is defined as “phase 3.” Within the available open dataset described in Perron et al. (2017), this rotation sensor location is called “ROAN.” Here, it was possible to extract 805 events with both rotation and <b>translation</b> <b>data.</b> The “Argonet” permanent vertical array has been operational since July 11, 2015, and the rotation sensor was kept on the site. Here, 29 events from the best records of the permanent array (up to July 28, 2016) were added to this dataset to complete the dataset with the strongest motions. Phase 3 allows the comparison between rotation and <b>translation</b> <b>data</b> without any upper limit in terms of strong motions, which allows analysis over a wider range of motion levels and event magnitudes.|$|E
40|$|In this paper, we {{proposed}} a <b>Data</b> <b>Translation</b> model which potentially is a major promising web service {{of the next generation}} world wide web. This technique is somehow analogy to the technique of traditional machine translation but it is far beyond what we understand about machine translation in the past and nowadays in terms of the scope and the contents. To illustrate the new concept of web services based <b>data</b> <b>translation,</b> a multilingual machine translation electronic dictionary system and its web services based model including generic services, multilingual translation services are presented. This proposed <b>data</b> <b>translation</b> model aims at achieving better web services in easiness, convenience, efficiency, and higher accuracy, scalability, self-learning, self-adapting. <br /...|$|R
50|$|Pairaphrase {{emphasizes}} secure online gisting {{and document}} <b>translation</b> for <b>data</b> security risk management. The software stores translations {{in the end}} user’s or organization’s own account for translation memory purposes and does not return translation for indexing, storing or publishing in search engines.|$|R
40|$|This paper {{introduces}} parallelization {{strategies for}} the Non-Uniform FFT (NUFFT) <b>data</b> <b>translation</b> on multicore architectures. The NUFFT {{enables the use of}} the cele-brated FFT with un-equally spaced data in numerous situ-ations in signal and image processing as well as in scientific computing. The critical extension lies at the translation of non-equally spaced or non-uniformly sampled data onto an equally spaced Cartesian grid or vice versa. The data trans-lation can be made sufficiently accurate, with the arithmetic complexity linearly proportional {{to the size of the}} data en-semble. For large NUFFTs, however, the <b>data</b> <b>translation</b> is found substantially dominant in computation time on mod-ern computers while it is expected to be dominated by the FFT. In order to match the FFT performance achieved by FFTW, data locality and parallelism in the <b>data</b> <b>translation</b> must be explored and exploited as well. We are concerned with two fundamental issues. First, the <b>data</b> <b>translation</b> can be described as a matrix-vector multiplication with a matrix of irregular sparsity. This is beyond the effective scope of the conventional tiling and parallelization schemes applied by a compiler for performance improvement on computa-tion with dense matrices. Secondly, multicore processors exist and emerge in many different configurations, and are expected to evolve further in architectural variety. This may mean the end of performance tuning on a single type of ar-chitecture. In this paper, we introduce an automation tool that takes two specifications as input, one on an application-specific <b>data</b> <b>translation</b> algorithm, the other on a target multicore processor architecture. The tool generates a par-allel code that explores the data locality and parallelism by utilizing both geometric structures in <b>data</b> <b>translation</b> and the processor-memory configurations in the target architec...|$|R
