2|46|Public
40|$|Present {{high-capacity}} GEO satellites provide throughput in {{the range}} of 70 Gb/s (Ka-Sat) up to 140 Gb/s (ViaSat- 1, EchoStar 17). In order {{to keep up with the}} quickly increasing bit rate requirements of new services and applications, future satellites must increase their capacity by an order of magnitude, thus reaching the Terabit/s <b>throughput</b> <b>class.</b> In order to achieve a Terabit/s satellite system, a multitude of issues, limitations and problems must be taken into account. The paper addresses several of these important issues, such as user link bandwidth requirement, feeder link capacity requirement, and satellite power requirements. Moreover, optical feeder links are considered...|$|E
40|$|In this paper, we {{describe}} simulation {{and evaluate the}} effect of cell update on General Packet Radio Service (GPRS). GPRS supports packet-switched services in cellular networks. We use a GPRS OPNET simulation model that implemented GPRSspecific communication protocols. The developed OPNET model supports two QoS profiles based on the mean <b>throughput</b> <b>class.</b> We validate the GPRS implementation based on the observed link throughput between base transceiver stations and the base station controller. We evaluate the effect of cell update on the end-to-end delay, time to process signaling messages, and throughput. Simulation scenarios with and without cell updates are employed to illustrate that signaling processing time and the delay as perceived by the user increase with cell update...|$|E
40|$|Abstract—We {{introduce}} an optimisation {{problem to}} maximise the <b>throughput</b> of <b>class</b> of rateless codes {{subject to a}} delay constraint for a point to point erasure packet channel with delayed feedback. We show that this problem is convex. Using the formulation for point to point communication, we extend our approach to the communication of multiple unicast flows in a network. I...|$|R
40|$|We {{consider}} the (generalized) packet switch scheduling problem, where the switch service configuration {{has to be}} dynamically chosen based on observed queue backlogs, so as to maximize the <b>throughput.</b> A <b>class</b> of recently developed `projective' scheduling algorithms, which substantially generalize the well-known maximum weight matching (MWM) algorithms for crossbar switches, are explored {{from the perspective of}} complexity. The typically huge number of possible switch configurations that the scheduler has to consider in each timeslot has been previously observed to lead to an impractical computational requirement. We introduc...|$|R
40|$|We {{investigate}} the optimal selection of minimum contention window values to achieve proportional fairness in a multirate IEEE 802. 11 e test-bed. Unlike other approaches, the proposed model {{accounts for the}} contention-based nature of 802. 11 ’s MAC layer operation and considers the case where stations can have different weights corresponding to different <b>throughput</b> <b>classes.</b> Our test-bed evaluation considers both the long-term throughput achieved by wireless stations and the short-term fairness. When all stations have the same transmission rate, optimality is achieved when a station’s throughput is proportional to its weight factor, and the optimal minimum contention windows also maximize the aggregate throughput. When stations have different transmission rates, the optimal minimum contention window for high rate stations is smaller than for low rate stations. Furthermore, we compare proportional fairness with time-based fairness, which {{can be achieved by}} adjusting packet sizes so that low and high rate stations have equal successful transmission times, or by adjusting the transmission opportunity (TXOP) limit so that high rate stations transmit multiple back-to-back packets and thus occupy the channel for the same time as low rate stations that transmit a single packet. The test-bed experiments show that when stations have different transmission rates and the same weight, proportional fairness achieves higher performance than the time-based fairness approaches, in terms of both aggregate utility and throughput...|$|R
40|$|In this paper, {{we present}} the first {{end-to-end}} fairness {{analysis of a}} network of fair servers. We argue {{that it is difficult to}} extend existing single-node fairness analysis to an end-to-end analysis of a network where each node may employ a different fair scheduling algorithm. We then present a two-step approach for end-to-end fairness analysis of heterogeneous networks. First, we define a class of scheduling algorithms, referred to as the Fair <b>Throughput</b> (FT) <b>class,</b> and prove that most known fair scheduling algorithms belong to this class. Second, we develop an analysis methodology for deriving the end-to-end fairness bounds for a network of FT servers. Our analysis is general and can be applied to heterogeneous networks where different nodes employ different scheduling algorithms from the FT class. ...|$|R
40|$|This paper {{evaluate}} {{performance of}} Optical CDMA network using 3 -D Optical Orthogonal Codes in a frame work called "time-slotted broadcast local area network". In this framework, with suitable multiple access schemes, {{a number of}} packets from different sources can be transmitted over the optical fiber in a single slot simultaneously. Performance is evaluated in term of offered load vs. <b>throughput</b> for various <b>classes</b> and it is compared with 2 -D OOCs...|$|R
50|$|In 2004, {{with the}} launch of Anik F2, the first high <b>throughput</b> satellite, a <b>class</b> of {{next-generation}} satellites providing improved capacity and bandwidth became operational. More recently, high throughput satellites such as ViaSat's ViaSat-1 satellite in 2011 and HughesNet's Jupiter in 2012 have achieved further improvements, elevating downstream data rates from 1-3 Mbit/s up to 12-15Mbit/s and beyond. Internet access services tied to these satellites are targeted largely to rural residents {{as an alternative to}} Internet service via dial-up, ADSL or classic FSSes.|$|R
40|$|Abstract In this paper, {{we present}} the first {{end-to-end}} fairness analysisof {{a network of}} fair servers. We {{argue that it is}} difficult to extend existing single-node fairness analysis to an end-to-endanalysis of a network where each node may employ a different fair scheduling algorithm. We then present a two-stepapproach for end-to-end fairness analysis of heterogeneous networks. First, we define a class of scheduling algorithms,referred to as the Fair <b>Throughput</b> (FT) <b>class,</b> and prove that most known fair scheduling algorithms belong to this class. Second, we develop an analysis methodology for deriving the end-to-end fairness bounds for a network of FT servers. Ouranalysis is general and can be applied to heterogeneous networks where different nodes employ different scheduling al-gorithms from the FT class. 1 Introduction With the commercialization of the Internet and the adventof real-time and mission-critical Internet applications, it ha...|$|R
40|$|Although many closed multiclass queuing {{networks}} have a product-form solution, evaluating their performance measures remains nontrivial {{due to the}} presence of a normalization constant. We propose the application of Monte Carlo summation {{in order to determine the}} normalization constant, throughputs, and gradients of <b>throughputs.</b> A <b>class</b> of importance-sampling functions leads to a decomposition approach, where separate single-class problems are first solved in a setup module, and then the original problem is solved by aggregating the single-class solutions in an execution model. We also consider Monte Carlo methods for evaluating performance measures based on integral representations of the normalization constant; a theory for optimal importance sampling is developed. Computational examples are given that illustrate that the Monte Carlo methods are robust over a wide range of networks and can rapidly solve networks that cannot be handled by the techniques in the existing literature...|$|R
40|$|We {{describe}} {{the design and}} implementation of the QoSbox, a configurable IP router that provides per-hop service differentiation on loss, delays and <b>throughput</b> to <b>classes</b> of traffic. The novel aspects of the QoSbox are that (1) the QoSbox does not rely on any external component (e. g., no traffic shaping and no admission control) to provide the desired service differentiation, but instead, (2) dynamically adapts packet forwarding and dropping decisions {{as a function of the}} instantaneous traffic arrivals and allows for temporary relaxation of some service objectives; also, (3) the QoSbox can enforce both absolute and proportional service differentiation on queuing delays, loss rates, and throughput at the same time. We focus on a publicly available implementation of the QoSbox in BSD-based PC-routers. We evaluate our implementation in a testbed of BSD routers over a FastEthernet network, and we sketch how the QoSbox can be implemented in high speed architectures...|$|R
40|$|A {{class of}} {{infinite}} impulse response (IIR) digital filters with a systolizable structure is proposed and its synthesis is investigated. The systolizable structure consists of pipelineable regular modules with local connections and {{is suitable for}} VLSI implementation. It is capable of achieving high performance as well as high <b>throughput.</b> This <b>class</b> of filter structure provides certain degrees of freedom {{that can be used}} to obtain some desirable properties for the filter. Techniques of evaluating the internal signal powers and the output roundoff noise of the proposed filter structure are developed. Based upon these techniques, a well-scaled IIR digital filter with minimum output roundoff noise is designed using a local optimization approach. The internal signals of all the modes of this filter are scaled to unity in the l 2 -norm sense. Compared to the Rao-Kailath (1984) orthogonal digital filter and the Gray-Markel (1973) normalized-lattice digital filter, this filter has better scaling properties and lower output roundoff noise...|$|R
40|$|We {{describe}} {{the design and}} implementation in UNIX-based PCs of the QoSbox, a configurable IP router that provides per-hop service guarantees on loss, delays and <b>throughput</b> to <b>classes</b> of traffic. There is no restriction {{on the number of}} classes or the specific service guarantees each class obtains. The novel aspects of the QoSbox are that (1) the QoSbox does not rely on any external component (e. g., no traffic shaping and no admission control) to enforce the desired service guarantees, but instead, (2) dynamically adapts packet forwarding and dropping decisions {{as a function of the}} instantaneous traffic arrivals; also, (3) the QoSbox can enforce both absolute bounds and proportional service guarantees on queueing delays, loss rates, and throughput at the same time. We evaluate the QoSbox in a testbed of PC-routers over a FastEthernet network, and show that the QoSbox is a possible solution allowing for incremental deployment to the problem of providing service differentiation in a scalable manner...|$|R
40|$|The {{throughput}} {{performance of}} the Distributed Coordination Function (DCF) of the IEEE 802. 11 MAC protocol quickly degrades {{as the number of}} contending stations increases. To solve this problem, it has been shown recently that adaptive contention window modulation based on channel idle time tracking can be used, generating near optimal throughput. In this paper, we extend the approach for the IEEE 802. 11 e network, where different QoS classes are defined. We show how to find the class-specific optimal contention window sizes that yield the maximum aggregate throughput while maintaining the target <b>throughput</b> difference between <b>classes.</b> 1...|$|R
40|$|Internet traffic {{primarily}} {{consists of}} packets from Transmission Control Protocol (TCP) flows. Based on passive, flow level TCP network measurements, our previous work {{has focused on}} using the principal component method to perform factor analysis on flow <b>class</b> <b>throughput</b> correlation matrices in order to infer which classes of TCP flows are sharing bottlenecks in the network. In this paper, we present a firstorder autoregressive model for congestion at a bottleneck to analyze the need for filtering out {{a subset of the}} collected flow measurements before analysis. We demonstrate the successful application of our statistical methods in inferring congestion sharing after filtering out small- and large-sized flow samples. 1...|$|R
40|$|One of {{the design}} {{parameters}} in closed queueing networks is Np, the number of customers of class p. It has been assumed that Np must be an integer. However, integer choices will usually not achieve the target <b>throughput</b> for each <b>class</b> simultaneously. We use Mean Value Analysis with the Schweitzer-Bard approximation and nonlinear programming to determine the value of Np needed to achieve the production targets exactly, although the values of Np may be fractional. We interpret these values to represent {{the average number of}} customers of each class in the network. We implement a control rule to achieve these averages and verify our approach through simulation...|$|R
40|$|Abstract—In this paper, {{we explore}} a novel online packet {{scheduling}} model based on vehicular network applications. The model incorporates multiple networks with non-persistent con-nectivity where we only know which networks {{are available at}} the current time. Our goal is to achieve the minimum requirement of vehicular application classes and also maximize the <b>throughput</b> of these <b>classes.</b> NS 3 simulations were performed to analyze the behavior of our scheduling model by comparing it with the standard scheduling using only LTE and WiFi networks, as well as the handover between these two networks. We observed that the proposed scheduling model had a low packet loss and low delay. I...|$|R
40|$|Abstract — One {{class of}} {{wireless}} sensor networks makes use of sensor nodes that recharge their batteries by harvesting energy from the surrounding environment. Being continuously recharged, the battery {{does not need to}} be replaced regularly and the sensor node is maintenance-free. A key module in such sensor network solutions is the data link automatic repeat request (ARQ) protocol, which must be designed to reliably deliver sensor nodes data at the minimum energy cost. With this objective in mind, two ARQ protocol classes are compared. In one class, each sensor node operates individually. In the other, the concept of cooperative communications is adopted, whereby neighboring sensor nodes help each other during the retransmission process. It is shown that the use of cooperative ARQ protocols in energy harvesting sensor networks enables sensor nodes to balance their energy consumption to match their own battery recharge rate. In turn, a balanced energy consumption-to-recharge rate ratio has the potential to improve the network <b>throughput.</b> Both <b>classes</b> of ARQ protocols are analyzed and compared. Estimated throughput gains are discussed under various network scenarios. Index Terms — Sensor networks, energy harvesting, radio co-operation, ARQ protocol, greedy algorithm. I...|$|R
40|$|Abstract—XG-PON {{requires}} an effective {{dynamic bandwidth allocation}} (DBA) mechanism for upstream traffic to support qual-ity of service for different classes of traffic. We propose X-GIANT, which extends GPON based GigaPON Access Network (GIANT) DBA, with validated optimisations to the originally proposed key parameters- service timers and assured vs non-assured ratio of medium priority traffic. We implement X-GIANT in a standard-compliant XG-PON module designed for the state-of-the-art ns- 3 simulator, tune the above key parameters and show that mean-delay and <b>throughput</b> for different <b>classes</b> of traffic obey the XG-PON requirements and respect priorities at both light and heavy upstream loads. We also show that X-GIANT shows better mean-delay performance than Efficient Bandwidth Utilisation (EBU), a recently proposed, GIANT-derived, priority-based DBA mechanism for XG-PON, for all three classes of traffic simulated. I...|$|R
40|$|Traditional Diff-Serv {{approaches}} {{have relied on}} multiple queues and scheduling mechanisms to provide trafc <b>classes</b> <b>throughput</b> guarantees at links. In this paper 1 we describe a framework to provide throughput guarantees using only a First-In-First-Out (FIFO) queue. We assume that each link can support K classes of trafc. Each link guarantees each class at least a certain xed fraction of its capacity. We rst formulate the problem of providing throughput guarantees as a multi-stage convex optimization problem. We then present a decentralized, scalable solution to this formulation in terms of congestion-controllers at the sources and adaptation algorithms at the links. A possible implementation at the routers is then presented followed by packet level simulations. We then study {{the stability of the}} proposed scheme in a general network topology. I...|$|R
40|$|We {{present an}} {{automated}} temporal partitioning and loop transformation approach for developing dynamically reconfigurable designs starting from behavior level specifications. An Integer Linear Programming (ILP) model is formulated to achieve near-optimal latency designs. We, also present a loop restructuring method to achieve maximum <b>throughput</b> for a <b>class</b> of DSP applications. This restructuring transformation is {{performed on the}} temporally partitioned behavior and results in near-optimization of throughput. We discuss efficient memory mapping and address generation techniques for the synthesis of reconfigurable designs. A Case study on the Joint Photographic Experts Group (JPEG) image compression algorithm demonstrates the effectiveness of our approach. 1 Introduction The reconfiguration capability of the SRAM FPGAs can be utilized to fit a large application onto the FPGA by partitioning the application over time into multiple segments. The division of an application into temporal seg [...] ...|$|R
40|$|We {{present an}} {{automated}} temporal partitioning tool for developing dynamically reconfigurable designs starting from behavior level specifications {{for a class}} of dsp applications. An Integer Linear Programming (ilp) model is formulated to achieve near-optimal latency designs. We, also present a loop restructuring method to achieve maximum <b>throughput</b> for a <b>class</b> of dsp applications. This restructuring transformation is performed on the temporally partitioned behavior and results in near-optimization of throughput. Case study on the Joint Photographic Experts Group (jpeg) image compression algorithm demonstrates the effectiveness of our approach. 1 Introduction fpgas have been used successfully in the rapid prototyping of designs [1, 2]. The long fabrication times associated with asic design is eliminated. But the device capacity of fpgas is far {{less than that of}} asic chips. Therefore, when synthesizing large designs on fpgas usually multi-fpga boards are used to increase device capac [...] ...|$|R
40|$|Motivated by revenue {{maximization}} in server farms with admission control, {{we investigate}} optimal scheduling in parallel processor-sharing queues. Incoming customers are distinguished in multiple classes and we define revenue as a weighted sum of <b>class</b> <b>throughputs.</b> Under these assumptions, we describe a heavy-traffic limit for the revenue maximization problem {{and study the}} asymptotic properties of the optimization model {{as the number of}} clients increases. Our main result is a simple heuristic that is able to provide tight guarantees on the optimality gap of its solutions. In the general case with M queues and R classes, we prove that our heuristic is (1 + 1 M− 1) -competitive in heavy-traffic. Experimental results indicate that the proposed heuristic is remarkably accurate, despite its negligible computational costs, both in random instances and using service rates of a web application measured on multiple cloud deployments. 1...|$|R
40|$|Multiclass Queueing {{networks}} {{have been suggested}} {{by a number of}} researchers for the performance engineering of client-server systems. A number of implementation mechanisms such as software servers, locks in transaction processing, and critical sections make the application of existing analytic methods for queueing networks difficult for the performance analysis of client-server software and systems. Moreover real systems are unlikely to meet the underlying assumptions required by the exact solution methods that are available. We present a performance bounds technique which is apt for modelling client-server systems and is based on relaxed assumptions about the stochastic behaviour of the system. Models can be solved to give upper and lower bounds on <b>throughputs</b> for different <b>classes</b> of clients. Of particular interest is the lower bound on throughput that gives a performance guarantee that is useful in the conservative design of systems. 1...|$|R
40|$|Abstract. The process {{scheduling}} aims to arrange CPU time to multiple processes for providing users with more efficient <b>throughput.</b> Except the <b>class</b> of process set by user, conventional operating systems have applied the equivalent scheduling policy to every process. Moreover, if the scheduling policy is once determined, it {{is unable to}} change without resetting the operating system which takes much time. In this paper, we propose an intelligent CPU {{process scheduling}} algorithm using fuzzy inference with user models. It classifies processes into three classes, batch, interactive and real-time processes, and models user's preferences to each process class. Finally, it assigns the priority of each process according to the class {{of the process and}} user’s preference through the fuzzy inference. The experimental result shows the proposed method can adapt to user and allow different scheduling policies to multiple users...|$|R
40|$|Such interactive, {{distributed}} multimedia applications as shared whiteboards, group editors, and simulations require reliable concurrent multicast services, i. e., the reliable {{dissemination of}} information from multiple sources to {{all the members of}} a group. Furthermore, it makes sense to offer that service on top of the increasingly available IP multicast service, which offers unreliable multicasting. This paper establishes that concurrent reliable multicasting over the Internet should be based on reliable multicast protocols based on a shared acknowledgment tree. First, we show that organizing the receivers of a reliable multicast group into an acknowledgment tree and using NAK-avoidance with periodic polling in local groups inside such a tree provides the highest maximum <b>throughput</b> among all <b>classes</b> of reliable multicast protocols proposed to date. Second, we introduce Lorax, which demonstrates the viability of implementing a reliable multicasting approach in the Internet based on ack [...] ...|$|R
40|$|A {{realistic}} quantum {{cryptographic system}} must {{function in the}} presence of noise and channel loss inevitable in any practical transmission. We examine the effects of these channel limitations on the security and <b>throughput</b> of a <b>class</b> of quantum cryptographic protocols known as four-state, or BB 84. Provable unconditional security against eavesdropping, which is the principal feature of quantum cryptography, can be achieved despite minor channel defects, albeit at a reduced transmission throughput. We present a semi-empirical relation between the fully-secure throughput and the loss and noise levels in the channel. According to this relation, an implementation of BB 84 utilizing commercially available detectors can reach throughputs as high as 10 4 - 10 5 secure bits per second over a practical channel of reasonable quality. KEYWORDS: quantum cryptography, security, channel capacity, secrecy capacity, optical networks. B. Slutsky, P. C. Sun, Y. Mazurenko, R. Rao, and Y. Fainman Page 3 [...] ...|$|R
40|$|Abstract — A key {{application}} of networked sensor systems is {{to detect and}} classify events of interest in an environment. Such applications require processing of raw data and the fusion of individual decisions. In-network processing of the sensed data {{has been shown to}} be more energy efficient than the centralized scheme that gathers all the raw data to a (powerful) base station for further processing. We formulate the problem as a special class of flow optimization problem. We propose a decentralized adaptive algorithm to maximize the <b>throughput</b> of a <b>class</b> of in-network processing applications. This algorithm is further implemented as a decentralized in-network processing protocol that adapts to any changes in link bandwidths and node processing capabilities. Simulations show that the proposed in-network processing protocol achieves upto 95 % of the optimal system throughput. We also show that path based greedy heuristics have very poor performance in the worst case. I...|$|R
40|$|Abstract — We develop {{methods to}} infer path or {{bottleneck}} sharing among TCP flow classes based on flow level measurements available from current traffic monitoring tools. Our {{premise is that}} flows that temporally overlap on congested resources will have correlated throughputs. We propose to use factor analysis to explore the correlation structure of flow <b>class</b> <b>throughputs</b> in order to hypothesize which flow classes might share congested resources. The effectiveness of this “black box” approach is studied using empirical data. We show that making such inferences based on flow level statistics is viable in practice, and can serve as an effective, novel tool for network design and configuration decisions. Our work on inferring bottleneck sharing differs significantly from previous work in that we consider flow level instead of packet level statistics, and hence may potentially influence research in that area. Possible applications of this technique include network monitoring and root cause analysis of poor performance. I...|$|R
40|$|We {{present a}} Markov chain Monte Carlo method for <b>class</b> <b>throughputs</b> in closed multiclass product-form networks. The method is as follows. For a given network, we {{construct}} a "regularized " network {{with a highly}} simplified structure that has the same steady-state distribution. We then simulate the regularized network. The method has performed reasonably well across {{a broad range of}} problems. We give a heuristic explanation of this. We prove that the regularized network "mixes in polynomial time" in some special cases. A revision of a manuscript entitled "An efficient Markov chain Monte Carlo algorithm for closed product-form networks. " Supported in part under NSF grants DMI- 9414630 and DMI- 9713730 1 Introduction 1. 1 Overview Closed multiclass product-form (CMP) queueing networks are useful as models for manufacturing and communication systems [5, 7, 20, 26, 31, 34, 46, 49]. These networks are of interest because their steady-state distributions are known explicitly up to a normali [...] ...|$|R
40|$|Event {{simulation}} and analytic modeling {{are used}} to evaluate the performance of Low Latency Queueing (LLQ), a queueing discipline available in some Internet packet switching routers for integrated services performance assurance. LLQ combines priority queueing with Class-Based Weighted Fair Queueing (CBWFQ). Priority queueing is used to ensure satisfying tight delay constraints for real-time traffic, whereas CBWFQ is used to ensure acceptable <b>throughput</b> for traffic <b>classes</b> that are less sensitive to delay. Simulations are developed both using a commercial product, OPNET Modeler, and also custom simulators that we developed. Our custom simulators model two different approaches to CBWFQ; and comparisons between the approaches and that of the commercial simulator are conducted. Our computational experiences (central processing unit [CPU] times for model execution and postprocessing) in using the simulators are described. This work is an important first step in the ability to model a proposed enhancement to LLQ which may be beneficial to Emergency Telecommunications Services. ...|$|R
40|$|In this paper, we {{consider}} a system modelled as an M/M/ 1 queue. Jobs corresponding to different classes {{are sent to}} the queue and are characterized by a delay cost per unit of time and a demand function. Our goal is to design an optimal pricing scheme for the queue, where the total charge depends on both the mean delay at the queue and arrival rate of each customer. We also assume that those two values have to be (statistically) measured, introducing errors on the total charge that might avert jobs from using the system, and then decrease demand. This model can be applied in telecommunication networks, where pricing {{can be used to}} control congestion, and the network can be characterized by a single bottleneck queue; the <b>throughput</b> of each <b>class</b> would be determined through passive measurements while the delay would be determined through active measurements. Copyright Springer Science+Business Media, LLC 2007 Pricing, Measurements, Queueing theory,...|$|R
40|$|We develop {{methods to}} infer path or {{bottleneck}} sharing among TCP flow classes based on flow level measurements available from current traffic monitoring tools. Our {{premise is that}} flows that temporally overlap on congested resources will have correlated throughputs. We propose to use factor analysis to explore the correlation structure of flow <b>class</b> <b>throughputs</b> in order to hypothesize which flow classes might share congested resources. The effectiveness of this "black box" approach is studied using empirical data. We show that making such inferences based on flow level statistics is viable in practice, and can serve as an effective, novel tool for network design and configuration decisions. Our work on inferring bottleneck sharing differs significantly from previous work in that we consider flow level instead of packet level statistics, and hence may potentially influence research in that area. Possible applications of this technique include network monitoring and root cause analysis of poor performance...|$|R
40|$|We {{analyze the}} maximum <b>throughput</b> that known <b>classes</b> of {{reliable}} multicast transport protocols can attain. A new taxonomy of reliable multicast transport protocols is introduced {{based on the}} premise that the mechanisms used to release data at the source after correct delivery should be decoupled from the mechanisms used to pace the transmission of data and to effect error recovery. Receiver-initiated protocols, which are based entirely on negative acknowledgments (naks) sent from the receivers to the sender, have been proposed to avoid the implosion of acknowledgments (acks) to the source. However, these protocols are shown to require infinite buffers in order to prevent deadlocks. Two other solutions to the ack-implosion problem are tree-based protocols and ring-based protocols. The first organize the receivers in a tree and send acks along the tree; the latter send acks to the sender along a ring of receivers. These two classes of protocols are shown to operate correctly with finit [...] ...|$|R
40|$|The {{popularity}} of wireless local area networks (WLANs) {{has resulted in}} their dense deployments around the world. While this increases capacity and coverage, the problem of increased interference can severely degrade the performance of WLANs. However, the impact of interference on throughput in dense WLANs with multiple access points (APs) has had very limited prior research. This {{is believed to be}} due to 1) the inaccurate assumption that throughput is always a monotonically decreasing function of interference and 2) the prohibitively high complexity of an accurate analytical model. In this work, firstly we provide a useful classification of commonly found interference scenarios. Secondly, we investigate the impact of interference on <b>throughput</b> for each <b>class</b> based on an approach that determines the possibility of parallel transmissions. Extensive packet-level simulations using OPNET have been performed to support the observations made. Interestingly, results have shown that in some topologies, increased interference can lead to higher throughput and vice versa...|$|R
40|$|Problem statement: WiMAX {{supports}} multiple {{types of}} traffic such as data, voice and video. Each flow requires a certain minimum bandwidth {{to achieve its}} QoS. Bandwidth allocation to traffic classes should be {{in such a way}} that fairness criteria is met with. Hence, we propose a dynamic bandwidth allocation mechanism to achieve fair and efficient allocation. Approach: We present a Generalized Stochastic Petri Net (GSPN) approach to model bandwidth allocation in Broadband Wireless Access (BWA) networks with multiple traffic classes. A dynamic weight assignment mechanism is proposed to enable fair bandwidth allocation among the competing traffic classes. Performance of the weight assignment mechanism is analytically evaluated using the GSPN model developed. Results: Results show performance improvement in terms of mean delay and normalized <b>throughput</b> of traffic <b>classes</b> compared to existing mechanisms. Simulation is carried out for different traffic rates. Analytical results are validated using simulations. Conclusion: Performance of the proposed system is evaluated in terms of mean delay and normalized system throughput. The model developed is generic and can be extended to any wireless network with multiple traffic classes...|$|R
