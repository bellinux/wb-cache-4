0|10000|Public
3000|$|DSC(ℓ,k) {{within a}} Wiener noise {{reduction}} filter. The {{determination of the}} <b>target</b> <b>values</b> is <b>controlled</b> by the fullband speaker activity detection measure [...]...|$|R
40|$|AbstractThe {{primary purpose}} of {{temperature}} control for cooling system is to ensure the system discharge temperature within target range while preventing compressor outlet temperature from overheating. A two-level subsection control method is constructed to control the compressor outlet temperature and the system discharge temperature respectively. In addition, the <b>target</b> <b>value</b> of system discharge temperature {{is divided into three}} parts. In every part, the different <b>target</b> <b>value</b> of the compressor outlet temperature is given. The methodnot only makes sure that controlling the system discharge temperature is easier to be accomplished, but also reduces cost-compensation of system. The simulation result indicates that the system discharge temperature can be regulated smoothly to <b>target</b> <b>value</b> while <b>controlling</b> the compressor outlet temperature in design value. Meanwhile,the ram air valve (RAV) and the temperature control valve (TCV) are under normal condition during all processes...|$|R
40|$|Abstract. In this paper, the LS-SVM {{model of}} woodblock {{gasification}} {{process has been}} established. The test {{results show that the}} model has better simulation and prediction effect for woodblock gasification process. On the basis of this model, the multi-objective optimization functions which is during control parameters (gasification temperature and equivalence ratio) and gas heating value and tat content is established, aiming to obtain the optimal <b>target</b> <b>value</b> of <b>control</b> parameters when the gas heating value reach maximum and lowest tar content in the process of woodblock gasification. The Pareto optimal solutions are obtained by optimization calculation. And each group data of the solutions is a compromise selection for gas heating value and percentage of tar heating value in raw material. It is more in line with practice more than a group of optimal solution...|$|R
40|$|Vitamin A (VA) {{fortification}} {{of cooking}} oil {{is considered a}} cost-effective strategy for increasing VA status, but few large-scale programs have been evaluated. We conducted representative surveys in Yaoundé and Douala, Cameroon, 2 years before and 1 year after {{the introduction of a}} mandatory national program to fortify cooking oil with VA. In each survey, 10 different households were selected within each of the same 30 clusters (n = ~ 300). Malaria infection and plasma indicators of inflammation and VA (retinol-binding protein, pRBP) status were assessed among women aged 15 – 49 years and children aged 12 – 59 months, and casual breast milk samples were collected for VA and fat measurements. Refined oil intake was measured by a food frequency questionnaire, and VA was measured in household oil samples post-fortification. Pre-fortification, low inflammation-adjusted pRBP was common among children (33 % 80 % of participants in the past week. Post-fortification, only 44 % of oil samples were fortified, but fortified samples contained VA concentrations close to the <b>target</b> <b>values.</b> <b>Controlling</b> for age, inflammation, and other covariates, {{there was no difference in}} the mean pRBP, mean breast milk VA, prevalence of low pRBP, or prevalence of low milk VA between the pre- and post-fortification surveys. The frequency of refined oil intake was not associated with VA status indicators post-fortification. In sum, after a year of cooking oil fortification with VA, we did not detect evidence of increased plasma RBP or milk VA among urban women and preschool children, possibly because less than half of the refined oil was fortified. The enforcement of norms should be strengthened, and the program should be evaluated in other regions where the prevalence of VA deficiency was greater pre-fortification...|$|R
40|$|Patients {{with type}} 2 {{diabetes}} are at high cardiovascular risk and require a global management targeting all risk factors. <b>Target</b> <b>values</b> for blood pressure have been discussed in a previous paper. The present clinical case summarizes the most important arguments concerning {{the choice of the}} <b>target</b> <b>values</b> for glucose <b>control</b> (glycated haemoglobin or HbA 1 c) and lipid management. As far as glucose control is concerned, the objective should be individually adjusted, based on the benefits/risks ratio, with a less stringent HbA 1 c level in presence of coronary heart disease and risk of severe hypoglycaemia. However, in absence of these two risks factors, the objective should be reinforced (HbA 1 c < 7 %), essentially to prevent or retard microangiopathic lesions. As far as lipid management is concerned, the most crucial goal remains LDL cholesterol lowering, with a <b>target</b> <b>value</b> < 100 mg/dL in patients at high cardiovascular risk and < 70 mg/dL in patients at very high risk, according to the recent European guidelines. Dyslipidaemia related to the metabolic syndrome (hypertriglyceridaemia, low HDL cholesterol) may also represent a therapeutic target (non-HDL cholesterol), although evidence is mostly missing in the literature. Peer reviewe...|$|R
40|$|This paper {{presents}} a multi-Model Reference Control (MRC) approach for queue-based access and congestion control procedures in communication networks. The model references (MRs) {{are used to}} address the problem of selecting the correct <b>target</b> <b>value</b> of the <b>control</b> scheme as a function of the statistical characteristics of the traffic. The target queue length is computed as a weighted sum of the outputs of the different MRs. The choice of the weight is accomplished by evaluating on-line the MRs' behavior - in terms of efficiency in the network utilization, achievable queuing delay and/or loss percentage - in response to the actual traffic feeding the system. As a case study, an access control scheme is considered and its performances are evaluated via OPNET simulations...|$|R
40|$|This paper {{deals with}} the {{application}} of algorithms inspired by Model Predictive Control to solve voltage-related power system control problems in both normal and emergency operating conditions. In {{the first part of}} the paper, we identify critical issues for a practical implementation of this methodology, and analyze how far these requirements have been met so far. In the second part, we outline a voltage control scheme that hopefully addresses the above issues. The central idea of this scheme is a static optimization to determine <b>target</b> <b>control</b> <b>values,</b> followed by a dynamic optimization to produce a feasible transition, both carried out in the closed-loop mode of Model Predictive Control. Peer reviewe...|$|R
40|$|We {{report on}} {{real-time}} control of balloon inflation inside porcine arteries. In a first step, experiments {{were done in}} a coronary artery of an excised heart. In a second step, experiments were done in a beating heart setup providing conditions very close to in vivo conditions without the complications. A programmable syringe pump was used to inflate a compliant balloon in arteries, while intravascular optical coherence tomography (IVOCT) monitoring was performed. In a feedback loop, IVOCT images were processed to provide the balloon diameter values in real-time to control the pump action {{in order to achieve}} a target diameter. In different experiments, various flow rates and target diameters were used. In the excised heart experiment, there was good convergence to target diameters resulting in a satisfactory balloon inflation control. In the beating heart experiment, there were oscillations in the diameter values due to cyclic arterial contractions. In these experiments, the control system maintained diameter averages satisfactorily close to predetermined <b>target</b> <b>values.</b> Real-time <b>control</b> of balloon inflation could not only provide a safer outcome for angioplasty procedures but could also provide additional information for diagnostics since it implicitly provides information about the artery response to the inflation process. Keywords- Angioplasty, control, optical coherence tomography (OCT), real-time systems...|$|R
40|$|A soft sensor {{approach}} is described for controlling metabolic overflow from mixed-acid fermentation and glucose overflow metabolism in a fed-batch cultivation for production of recombinant green fluorescence protein (GFP) in Escherichia coli. The hardware {{part of the}} sensor consisted of a near-infrared in situ probe that monitored the E. coli biomass and an HPLC analyzer equipped with a filtration unit that measured the overflow metabolites. The computational part of the soft sensor used basic kinetic equations and summations for estimation of specific rates and total metabolite concentrations. Two control strategies for media feeding of the fed-batch cultivation were evaluated: (1) controlling the specific rates of overflow metabolism and mixed-acid fermentation metabolites at a fixed pre-set <b>target</b> <b>values,</b> and (2) <b>controlling</b> the concentration of the sum of these metabolites at a set level. The {{results indicate that the}} latter strategy was more efficient for maintaining a high titer and low variability of the produced recombinant GFP protein. Funding Agencies|Linkoping University||</p...|$|R
40|$|This paper {{describes}} a novel error extraction approach for exploiting {{the strength of}} Levenberg-Marquardt (LM) optimization technique in intelligent control systems. Since the <b>target</b> <b>value</b> of the <b>control</b> signal is unknown, tuning of the controller parameters becomes a tedious task if the knowledge about the system and the environment is limited. The suggested methodology utilizes the sliding model control (SMC) technique. The error extraction scheme postulates the form of error on the applied control signal using the discrepancy from the prescribed reaching dynamics. The devised approach has been tested on the non-linear Duffing oscillator, which {{has been forced to}} follow a periodic orbit radically different from the natural one. The results obtained through a series of simulations have confirmed the high precision and robustness advantages without knowing the analytical details of the system under investigation. The issues of observation noise and the stability in the parametric space have approximately been addressed from the point of SMC perspective...|$|R
40|$|This paper {{considers}} a linear regression {{model with a}} one-dimensional control variable x and an m-dimensional response vector. The components of are correlated with a known covariance matrix. Based on the assumed regression model, it is of interest to obtain a suitable estimation of the corresponding <b>control</b> <b>value</b> for a given target vector on the expected responses. Due {{to the fact that}} there is more than one <b>target</b> <b>value</b> to be achieved in the multiresponse case, the m expected responses may meet their <b>target</b> <b>values</b> at different respective <b>control</b> <b>values.</b> Consideration on the performance of an estimator for the <b>control</b> <b>value</b> includes the difference of the expected response E(yi) from its corresponding <b>target</b> <b>value</b> Ti for each component and the optimal <b>value</b> of <b>control</b> point, say x 0, is defined to be the one which minimizes the weighted sum of squares of those standardized differences within the range of x. The objective of this study is to find a locally optimal design for estimating x 0, which minimizes the mean squared error of the estimator of x 0. It is shown that the optimality criterion is equivalent to a c-criterion under certain conditions and explicit solutions with dual response under linear and quadratic polynomial regressions are obtained. Calibration c-criterion Classical estimator <b>Control</b> <b>value</b> Equivalence theorem Locally optimal design Scalar optimal design...|$|R
40|$|Biological samples {{consist of}} an unknown, but large, number of {{regulated}} metabolites. It {{is of great}} interest scientifically and clinically to determine the composition and dynamics of this “metabolome”. Metabolomics is the systematic study of the metabolome and requires the development of reliable and sensitive methods. High resolution mass spectrometry is widely used, often in combination with liquid chromatography. It is essential to optimize instrumental parameters for each specific application. In this project, mass spectrometric parameters were optimized in order to detect as many compounds as possible and maximize signal intensity in dried blood spots, a sample material used in newborn screening and increasingly used in laboratory diagnostics. The following parameters were optimized on a Q Exactive Orbitrap mass spectrometer: voltage applied to the spray liquid in the ionization source (electrospray voltage), distance between the electrospray needle and the MS inlet (electrospray needle position), mass resolving power of the mass spectrometer (resolution), automatic gain <b>control</b> <b>target</b> <b>value</b> (which <b>controls</b> the number of ions to be injected into the Orbitrap), and mobile phase flow rate. The following values were chosen for each parameter: electrospray voltage 3. 5 kV, electrospray needle position C, resolution 70 000, and automatic gain <b>control</b> <b>target</b> <b>value</b> 1 000 000 ion counts. Mobile phase flow rate was increased from 150 to 300 µL/min, leading to a 50 % reduction of the initial analysis time, without compromising sensitivity. In certain cases, the optimal values derived for parameters differed unexpectedly from theoretical expectations. This {{emphasizes the importance of}} thorough parameter optimization during method development. Using a suboptimal value will decrease the number of detected compounds. This may have serious consequences, especially if compounds which are not detected are clinically relevant. The present work indicates that if extensive optimization of parameters is done during method development, diagnostic opportunities will improve...|$|R
40|$|AbstractThis paper {{considers}} a linear regression {{model with a}} one-dimensional control variable x and an m-dimensional response vector y=(y 1,…,ym). The components of y are correlated with a known covariance matrix. Based on the assumed regression model, it is of interest to obtain a suitable estimation of the corresponding <b>control</b> <b>value</b> for a given target vector T=(T 1,…,Tm) on the expected responses. Due {{to the fact that}} there is more than one <b>target</b> <b>value</b> to be achieved in the multiresponse case, the m expected responses may meet their <b>target</b> <b>values</b> at different respective <b>control</b> <b>values.</b> Consideration on the performance of an estimator for the <b>control</b> <b>value</b> includes the difference of the expected response E(yi) from its corresponding <b>target</b> <b>value</b> Ti for each component and the optimal <b>value</b> of <b>control</b> point, say x 0, is defined to be the one which minimizes the weighted sum of squares of those standardized differences within the range of x. The objective of this study is to find a locally optimal design for estimating x 0, which minimizes the mean squared error of the estimator of x 0. It is shown that the optimality criterion is equivalent to a c-criterion under certain conditions and explicit solutions with dual response under linear and quadratic polynomial regressions are obtained...|$|R
40|$|Highly active {{antiretroviral}} therapy (HAART) 1 – 3 {{has dramatically}} decreased mortality from HIV- 1 infection 4 {{and is a}} major achievement of modern medicine. However, there is no fundamental theory of HAART. Elegant models describe the dynamics of viral replication 3, 5 – 9, but a metric for the antiviral activity of drug combinations relative to a <b>target</b> <b>value</b> needed for <b>control</b> of replication is lacking. Treatment guidelines 10, 11 are based on empirical results of clinical trials in which other factors like regimen tolerability also affect outcome. Why only certain drug combinations control viral replication remains unclear. Here we quantify the intrinsic antiviral activity of antiretroviral drug combinations. We show that most single antiretrovirals exhibit previously unappreciated complex non-linear pharmacodynamics that determine their inhibitory potential at clinical concentrations. We demonstrate that neither of the major theories for drug combinations accurately predicts the combined effects of multiple antiretrovirals. However, combined effects can be understood with a novel approach that considers the degree of independence of drug effects. This analysis allows a direct comparison of the inhibitory potential of different drug combination...|$|R
40|$|Chinese Academy of Sciences KZCX 2 -XB 2 - 13 KSCX 2 -YW-N- 080;National Science Foundation for Young Scientists of China 51009126;Project for 100 Outstanding Young ScientistsA 3 -year {{experiment}} {{was conducted in}} an extremely dry and saline wasteland to investigate {{the effects of the}} drip irrigation on salt distributions and the growth of cotton under different irrigation regimes in Xinjiang, Northwest China. The experiment included five treatments in which the soil matric potential (SMP) at 20 cm depth was controlled at - 5, - 10, - 15, - 20, and - 25 kPa after cotton was established. The results indicated that a favorable low salinity zone existed in the root zone throughout the growing season when the SMP threshold was controlled below - 25 kPa. When the SMP value decreased, the electrical conductivity of the saturation paste extract (EC(e)) in the root zone after the growing season decreased as well. After the 3 -year experiment, the seed-cotton yield had reached 84 % of the average yield level for non-saline soil in the study region and the emergence rate was 78. 1 % when the SMP <b>target</b> <b>value</b> was <b>controlled</b> below - 5 kPa. The average pH of the soil decreased slightly after 3 years of cultivation. The highest irrigation water use efficiency (IWUE) values were recorded when the SMP was around - 20 kPa. After years of reclamation and utilization, the saline soil gradually changed to a moderately saline soil. The SMP of - 5 kPa at a depth of 20 cm immediately under a drip emitter can be used as an indicator for cotton drip irrigation scheduling in saline areas in Xinjiang, Northwest China...|$|R
3000|$|... are two {{auxiliary}} variables representing underachievement of the <b>target</b> <b>value</b> and overachievement of the <b>target</b> <b>value,</b> respectively (Ozcan and Toklu 2009).|$|R
30|$|Proof. In the multi-objective {{programming}} model (1), objective {{functions are}} minimized and have <b>target</b> <b>values,</b> e.g., minimize fj 0 (X) with <b>target</b> <b>value</b> Cj 0, i.e., minimize log (fj 0 (X)) with <b>target</b> <b>value</b> log (Cj 0). According to {{the method of}} goal formulation, positive deviation should be minimized.|$|R
5000|$|The values {{presented}} {{below are}} from Annex 1, Table 1, [...] "Groundwater <b>target</b> <b>values</b> and soil and groundwater intervention values". In previous {{versions of the}} Dutch Standards, <b>target</b> <b>values</b> for soil were also present. However, in the 2009 version, <b>target</b> <b>values</b> for soils have been deleted for all compounds except metals.|$|R
50|$|The bank's <b>target</b> <b>value</b> was {{the maximum}} amount of money that a team could {{accumulate}} in any one round, and if a team reached the target and banked it while already having money in the bank, the bank would be augmented to the <b>target</b> <b>value</b> instead of having the <b>target</b> <b>value</b> added to the bank.|$|R
40|$|Regional {{waters are}} being dredged once every 5 to 20 years to {{maintain}} the water discharge. The dredged material must meet certain objectives {{if it is to}} be disposed of in the adjacent soil. However, PAH levels exceed the sediment <b>target</b> <b>value</b> of 1. 0 mg sum of PAH per kg dryweight of sediment in 60 % of the ditches. In a preceeding study the present and future sediment quality has been investigated. In this study a probabilistic model was developed to investigate the effect of repeatedly distributing sediments on different categories of soil. When PAH concentration in sediment exceeds the <b>target</b> <b>value</b> up to a level of 10 mg. kg- 1 (standard above which sediments must be deposited into a depot), only farm-land on sandy soils will show no exceedance of the <b>target</b> <b>value</b> for soils (equal to the <b>target</b> <b>value</b> for sediments). The other categories, farm-land on clay, grass-land on clay and grass-land on peat, show a considerable chance of exceedance of the <b>target</b> <b>value.</b> However, when being distributed, many of the sediments in which levels of PAH above the <b>target</b> <b>value</b> were measured, will cause no exceedance of the soil <b>target</b> <b>value.</b> For sand, clay and peat ditches respectively 100 %, 63 % and 74 % of all measurements will lead to soil concentrations below the <b>target</b> <b>value</b> when being deposited on a regular basis. Decreasing atmospheric deposition will enlarge the possibility of distributing sediments without exceeding <b>target</b> <b>values,</b> especially in the case of farm-land on clay...|$|R
3000|$|F = fitted {{estimate}} for each observation, xt+ 1  = kxt (1  − xt) = logistic values, ut = mean of the <b>target</b> <b>values,</b> uj = mean of the logistic values, dst = standard deviation of <b>target</b> <b>values,</b> dsj = standard deviation of logistic values [...]...|$|R
40|$|In {{this work}} {{we discuss the}} design of a novel {{non-linear}} mapping method for visual classification based on multilayer perceptrons (MLP) and assigned class <b>target</b> <b>values.</b> In training the perceptron, one or more <b>target</b> output <b>values</b> for each class in a 2 -dimensional space are used. In other words, class membership information is interpreted visually as closeness to <b>target</b> <b>values</b> in a 2 D feature space. This mapping is obtained by training the multilayer perceptron (MLP) using class membership information, input data and judiciously chosen <b>target</b> <b>values.</b> Weights are estimated {{in such a way that}} each training feature of the corresponding class is forced to be mapped onto the corresponding 2 -dimensional <b>target</b> <b>value...</b>|$|R
5|$|Binary search {{works on}} sorted arrays. Binary search begins by {{comparing}} the middle element of the array with the <b>target</b> <b>value.</b> If the <b>target</b> <b>value</b> matches the middle element, {{its position in the}} array is returned. If the <b>target</b> <b>value</b> is less than or greater than the middle element, the search continues in the lower or upper half of the array, respectively, eliminating the other half from consideration.|$|R
40|$|Abstract: Weapon Systems Portfolio Selection (WSPS) can be {{considered}} as a multi-objective decision analysis (MODA) problem. Aiming at its challenging features because of, 1) interactions and independencies among weapon systems, 2) the uncertainty of the sample data set for assessment, and 3) the missing <b>target</b> <b>value</b> of the assessment criteria, the WSPS problem is solved form four perspectives: portfolio without the independencies or <b>target</b> <b>value,</b> portfolio with the independencies but without <b>target</b> <b>value,</b> portfolio with the independencies and <b>target</b> <b>value,</b> portfolio in a incomplete sample data with the independencies and with <b>target</b> <b>value.</b> The synergy concept is introduced to describe the independencies among systems and Grey Target (GT) and principal component analysis (PCA) method are employed in this study to deal with the missing <b>target</b> <b>value</b> and incomplete sample data set. Three hybrid multiobjective programming algorithms are proposed as GT-MOP 1, GT-MOP 2 and PCA-MOP 2 and non-dominated portfolios are generated as by sorting algorithm as a set of Pareto-optimal solutions. Finally, numerical experiments are given under four scenarios to illustrate the feasibilities and advantages of the three hybrid algorithms...|$|R
40|$|In Quality Function Deployment, {{determination}} of the <b>target</b> <b>values</b> for engineering requirements {{is the most difficult}} process. A fuzzy optimization model is presented for the {{determination of}} <b>target</b> <b>values</b> for engineering requirements in Quality Function Deployment. An inexact genetic algorithm approach was introduced to solve the model that takes the mutation along the weighted gradient direction as a genetic operator. Instead of obtaining one set of exact optimal <b>target</b> <b>values,</b> the approach can generate a family of inexact optimal <b>target</b> <b>values</b> setting within an acceptable satisfaction degree. Through an interactive approach, a design team can determine a combination of preferred solution sets from which a set of preferred <b>target</b> <b>values</b> of engineering requirements based on a specific design scenario can be obtained. An example of car door design is used to illustrate the approach. Department of Industrial and Systems Engineerin...|$|R
30|$|For any set S and S^', where S ⊂ S^', if ∀ l_i ∈ S, l_j ∈ S^'-S, l_i.s > l_j.s, {{then the}} <b>target</b> <b>value</b> of GetMaxSet(S^') is always {{smaller than the}} <b>target</b> <b>value</b> of GetMaxSet(S).|$|R
50|$|Barring a few exceptions, the <b>target</b> <b>values</b> are {{underpinned}} by {{an environmental}} risk analysis wherever possible and apply to individual substances. In most cases, <b>target</b> <b>values</b> {{for the various}} substances are related to a national background concentration that was determined for the Netherlands.|$|R
5|$|Predecessor and {{successor}} queries can {{be performed}} with rank queries. Once the rank of the <b>target</b> <b>value</b> is known, its predecessor is the element at the position given by its rank (as {{it is the largest}} element that is smaller than the <b>target</b> <b>value).</b> Its successor is the element after it (if it is present in the array) or at the next position after the predecessor (otherwise). The nearest neighbor of the <b>target</b> <b>value</b> is either its predecessor or successor, whichever is closer.|$|R
40|$|AbstractWe give a new solvability {{criterion}} for the boundary Carathéodory–Fejér problem: given a point x∈R and, a finite set of <b>target</b> <b>values,</b> {{to construct a}} function f in the Pick class such that the first few derivatives of f take on the prescribed <b>target</b> <b>values</b> at x. We also derive a linear fractional parametrization of the set of solutions of the interpolation problem with real <b>target</b> <b>values.</b> The proofs {{are based on a}} reduction method due to Julia and Nevanlinna...|$|R
5000|$|Predecessor and {{successor}} queries can {{be performed}} with rank queries. Once the rank of the <b>target</b> <b>value</b> is known, its predecessor is the element at the position given by its rank (as {{it is the largest}} element that is smaller than the <b>target</b> <b>value).</b> Its successor is the element after it (if it is present in the array) or at the next position after the predecessor (otherwise). The nearest neighbor of the <b>target</b> <b>value</b> is either its predecessor or successor, whichever is closer.|$|R
3000|$|Portal: “One of {{our team}} members is from a credit rating firm. He {{computed}} the <b>target’s</b> <b>value</b> using five different quantitative techniques. As a result, we can obtain the range of <b>target</b> <b>values</b> upon which we set initial bidding price and upper limit.” [...]...|$|R
50|$|In {{computer}} science, {{linear search}} or sequential search {{is a method}} for finding a <b>target</b> <b>value</b> within a list. It sequentially checks each element of the list for the <b>target</b> <b>value</b> until a match is found or until all the elements have been searched.|$|R
5000|$|Comparison against <b>target</b> <b>values</b> to {{determine}} a [...] "pass or fail" [...] or [...] "go/no go" [...] result. For example, with code or bar code verification, the read value is compared to the stored <b>target</b> <b>value.</b> For gauging, a measurement is compared against the proper value and tolerances. For verification of alpha-numberic codes, the OCR'd value is compared to the proper or <b>target</b> <b>value.</b> For inspection for blemishes, the measured size of the blemishes may {{be compared to the}} maximums allowed by quality standards.|$|R
40|$|Measurements of {{agreement}} {{are needed to}} assess the acceptability of a new or generic process, methodology, and formulation in areas of laboratory performance, instrument or assay validation, method comparisons, statistical process control, goodness of � t, and individual bioequivalence. In all of these areas, one needs measurements that capture {{a large proportion of}} data that are within a meaningful boundary from <b>target</b> <b>values.</b> <b>Target</b> <b>values</b> can be considered random (measured with error) or � xed (known), depending on the situation. Various meaningful measures to cope with such diverse and complex situations have become available only in the last decade. These measures often assume that the <b>target</b> <b>values</b> are random. This article reviews the literature and presents methodologies in terms of “coverage probability. ” In addition, analytical expressions are introduced for all of the aforementioned measurements when the <b>target</b> <b>values</b> are � xed and when the error structure is homogenous or heterogeneous (proportional to <b>target</b> <b>values).</b> This article compares the asymptotic power of accepting the agreement across all competing methods and discusses {{the pros and cons of}} each. Data when the <b>target</b> <b>values</b> are random or � xed are used for illustration. A SAS macro program to compute all of the proposed methods is available for download a...|$|R
30|$|Nominal-is-best {{properties}} (There is a <b>target</b> <b>value).</b>|$|R
40|$|This thesis {{describes}} {{an investigation of}} how techniques of modelling, estimation and control {{can be used to}} improve regulation of pH. A novel mathematical model of neutralization is used which explicitly accounts for two separate sources of non-linearities in pH systems: the inherent non-linearity of the pH measurement and the variable and uncertain non-linearity of the neutralization chemistry. A detailed interactive simulation package was developed. It has been used to study: 1. The application of a Bayes' non-linear estimator to a noisy pH measurement. The estimator is used in conjunction with an Extended Kalman Filter in order to generate estimates for use in combined feedforward/feedback controllers. A novel version of the Bayes' estimator is developed which successfully estimated jumping and drifting bias on the pH measurement. 2. A novel cautious stochastic control law which uses the generated estimates and allows for their uncertainty. Reduced quality of estimation forces the controller to regulate the pH at an optimally tuned <b>target</b> <b>value</b> where <b>control</b> is easier. 3. Comparisons of a variety of modern and conventional control algorithms. The modern algorithms include three self-tuners, the non-linear estimators and the cautious controller. The conventional algorithms include a PID controller, analytical linearisation of the pH measurement and the use of estimated or measured feedforward signals. Twenty-five pH control laws are simulated. The quality of regulation which can be achieved depends on what prior information is available about the neutralisation process. A strategy is proposed which matches controller structure to available information. This strategy provides guidelines to the control configurations that can be implemented as well as their relative limitations. It is shown that improvement in performance over a PID regulator is possible if one uses more complex controllers. This improvement is investigated by simulation because it varies from one process to another. It is also shown how the resulting simulation package has been used for computer aided design of pH control systems in the chemical industry. </p...|$|R
