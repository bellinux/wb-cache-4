76|10000|Public
25|$|Typically {{used with}} multiple-user {{computers}} running enterprise software. Examples are: transaction processing databases, internet infrastructure (email, webserver, e-commerce), scientific computing software, and nearline storage management software. Enterprise drives commonly operate continuously ("24/7") in demanding environments while delivering <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> without sacrificing reliability. Maximum capacity {{is not the}} primary goal, {{and as a result}} the drives are often offered in capacities that are relatively low in relation to their cost.|$|E
25|$|In 2009 (the {{most recent}} year of the evaluation), seven {{countries}} demonstrate <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> in policies for all three dimensions (overall score 15). These countries are Germany, Australia, the Netherlands, Italy, Belgium, Sweden and the US. The second best performing group (overall score 14) consists of France, Norway, South Korea, Croatia, Canada, Austria, Slovenia and Nigeria. The worst performing country in 2009 was North Korea, receiving the lowest score in all dimensions (overall score 3), followed by Somalia. For more information view the Human Trafficking Research and Measurement website.|$|E
5000|$|Carnahan's {{tenure in}} office focused on {{providing}} outstanding customer service to Missouri businesses, financial professionals, investors, voters, genealogists, researchers {{and hundreds of}} thousands of other customers. In the closeout audit at the end of her term in 2013, Republican State Auditor Thomas Schweich gave Carnahan's office <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> rating of [...] "excellent".|$|E
40|$|This chapter {{surveys the}} issues of {{collecting}} monitoring data for performance debugging of parallel programs executed in cluster environments. The main categories of monitoring tools are either clock driven or event driven, the latter including timing, counting or tracing. The paper focuses on software tracing, deemed the most general and portable event driven monitoring technique. The lack of global clock and the tracing intrusion are identified as the two major problems hindering {{the quality of the}} traced information collected by software tracers. A global time implementation by software and an approach for compensating the software tracing intrusion are then described. Performance debugging {{is an important part of}} the development cycle of parallel programs since obtaining <b>high</b> performances is <b>the</b> main goal of using cluster systems. The objective of performance measurement tools is to help programmers to get <b>the</b> <b>highest</b> <b>possible</b> <b>performances</b> from their programs on their target architecture. Performance debugging usually includes several phases...|$|R
30|$|The {{experiments}} can {{be divided}} into three parts: The first part identifies the reliable discriminative feature selection measures among those listed in the previous section. The second part examines the performance of our approach and illustrates that replacing LSSC with DBR- or BRGC-encoding scheme in our approach would achieve a much poorer performance when high entropy is imposed because of the conventional performance-entropy tradeoff of DBR- and BRGC-encoding-based discretization; The last part scrutinizes and reveals how one could attain reliable parameter estimation, i.e., Dfs, in achieving <b>the</b> <b>highest</b> <b>possible</b> discretization <b>performance.</b>|$|R
40|$|Increasingly, {{services}} need {{to interact}} with {{a wide spectrum of}} devices with varying networking capabilities. Services hosted on a messaging infrastructure need to optimally utilize and exploit the conditions that exist within the local networks. The messaging infrastructure must manage the communication between external resources, services and clients to achieve <b>the</b> <b>highest</b> <b>possible</b> system <b>performance</b> and reliability. In this paper we suggest that a transport framework needs to be incorporated into the messaging infrastructure hosting the services. We base our investigations {{in the context of the}} NaradaBrokering system...|$|R
5000|$|Typically {{used with}} multiple-user {{computers}} running enterprise software. Examples are: transaction processing databases, internet infrastructure (email, webserver, e-commerce), scientific computing software, and nearline storage management software. Enterprise drives commonly operate continuously ("24/7") in demanding environments while delivering <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> without sacrificing reliability. Maximum capacity {{is not the}} primary goal, {{and as a result}} the drives are often offered in capacities that are relatively low in relation to their cost.|$|E
50|$|In 2009 (the {{most recent}} year of the evaluation), seven {{countries}} demonstrate <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> in policies for all three dimensions (overall score 15). These countries are Germany, Australia, the Netherlands, Italy, Belgium, Sweden and the US. The second best performing group (overall score 14) consists of France, Norway, South Korea, Croatia, Canada, Austria, Slovenia and Nigeria. The worst performing country in 2009 was North Korea, receiving the lowest score in all dimensions (overall score 3), followed by Somalia. For more information view the Human Trafficking Research and Measurement website.|$|E
5000|$|Long Term Availability - Military {{programs}} {{last years}} and identical replacement hardware {{may be required}} {{over the life of}} the program. Consumer computers are often driven by the latest and greatest to realize <b>the</b> <b>highest</b> <b>possible</b> <b>performance,</b> such as required to play games. The motherboard in a consumer grade computer may have an availability measured in months instead of years or decades. In a consumer level computer, over the lifetime of the product availability, it is not unheard of for all the components such as the motherboard, drives, BIOS, video board, etc., to be different from computer to computer. That is not acceptable in a military computer for which supporting documents have been created and systems tested and approved.|$|E
30|$|To {{classify}} room types {{from the}} listing images, we manually labeled 36, 657 photos. A set of training images was first labeled by workers on Amazon Mechanical Turk and then checked by graduate and undergraduate student volunteers, who also labeled some images directly. We {{ensured that the}} training data covered images from different geographical regions. To maintain <b>the</b> <b>highest</b> <b>possible</b> classification <b>performance</b> and create a balance across image categories (instead of using a binary label of “living room” and “non-living room”) we used eight categories: living room, bedroom, kitchen, bathroom, dining room, other indoor rooms, object, and not indoor room.|$|R
50|$|Fairey, Gloster and Hawker all {{rushed to}} fulfil this need and {{competition}} was tight to attain <b>the</b> <b>highest</b> <b>performance</b> <b>possible.</b> As <b>the</b> aircraft required {{only a modest}} bomb load and with performance being paramount, the Hawker design team chose to focus its efforts on developing an aircraft similar in size to their Hurricane fighter.|$|R
40|$|Werner Schmidt (Trübbach, Switzerland, 1953) {{is one of}} {{the most}} {{interesting}} contemporary ‘green' architects, particularly experienced in straw-bale building. His accomplishments include now 20 straw-bale buildings of which 14 at least partially load-bearing. This paper extracts some essential principles from his work and explains in detail his technological solutions. This is the result of a thorough analysis, carried on during the reparation of a monograph. The success of his approach derives from many factors, among which: - Schmidt's training as a mason. In contrast with many fellow architects, his designs are rooted in practicality and feasibility. Moreover, he actively participates to the construction work. - His holistic vision of ecological building: straw bales are chosen because of the overall advantages they offer. Preferably, he adopts a modified ‘Nebraska' technique, using high-density ‘jumbo bales' forming more than 120 cm thick walls. This rather unique method assures rapidity of construction, and allows to solve a number of criticalities associated with ‘small bale' building. - Not seeking <b>the</b> <b>highest</b> <b>possible</b> <b>performances</b> lets to focus economic and technical efforts on few elements that really need to be state-of-the-art. The envelope can be built with simple techniques, while parts that need be built precisely (stairs, cooking implements, baths, etc.) can be prefabricated. Schmidt's work shows that high ecological consideration can be coupled with convincing architectural results. The quality of his buildings in terms of energy performance, living value, and beautiful form constitutes a good practice promoting new ways to ‘green' architecture...|$|R
50|$|The first {{company in}} the UK to roll out a NGN was THUS plc which started {{deployment}} back in 1999. THUS' NGN contains 10,600 km of fibre optic cable with more than 190 points of presence throughout the UK. The core optical network uses dense wavelength-division multiplexing (DWDM) technology to provide scalability to many hundreds of gigabits per second of bandwidth, in line with growth demand. On top of this, the THUS backbone network uses MPLS technology to deliver <b>the</b> <b>highest</b> <b>possible</b> <b>performance.</b> IP/MPLS-based services carry voice, video and data traffic across a converged infrastructure, potentially allowing organisations to enjoy lower infrastructure costs, as well as added flexibility and functionality. Traffic can be prioritised with Classes of Service, coupled with Service Level Agreements (SLAs) that underpin quality of service performance guarantees. The THUS NGN accommodates seven Classes of Service, four of which are currently offered on MPLS IP VPN.|$|E
5000|$|SRBs {{may also}} be {{employed}} for intra-address-space processes, where <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> is required, {{and in this case}} the necessary resources are first acquired under a TCB (usually the [...] "job step" [...] TCB), before the SRBs are SCHEDULEd (i.e., presented to the system dispatcher to compete for processor resources). It is conceivable that an address space may have but one TCB (again, the [...] "job step" [...] TCB) but tens or hundreds or even thousands of SRBs, with the SRBs performing almost all of the work in the address space and the TCB merely synchronizing the SRBs and responding to communications from the system operator. For purposes of such synchronization, the TCB will usually issue a WAITR, SVC 1, specifying a list of ECBs (one ECB per SRB, plus one for the system operator), and each SRB will indicate its completion to the TCB by using a [...] "branch entry" [...] to the POST system service (which is normally SVC 2), and specifying the ECB which is associated with its SRB, and possibly a [...] "message" [...] to the TCB. The [...] "message", should it be present, is placed in the lowest 24 bits of the ECB, and which is otherwise unused. The highest eight bits are used by the system.|$|E
40|$|Abstract—Multi-core microarchitectures {{require a}} careful balance between many {{competing}} objectives to achieve <b>the</b> <b>highest</b> <b>possible</b> <b>performance.</b> Integrated Early Analysis is {{the consideration of}} all of these factors at an early stage. Toward this goal, this work presents the first adaptive multi-granularity multi-core microarchitecture-level floorplanner that simultaneously optimizes temperature and performance, and considers memory bus length. We include simultaneous optimization at both the module-level and the core/cache-bank level. Related experiments show that our methodology is effective for optimizing multi-core architectures. ...|$|E
50|$|A common {{misconception}} is that microservers {{offer only}} low performance. This {{is caused by}} the first microservers being based on Atoms or early 32bit ARM cores. The aim of the DOME MicroDataCenter project is to deliver high performance at low cost and low power. A key characteristic of a MicroDataCenter is its packaging: very small form factor that allows short communication distances. This is based on using Microservers, eliminating all unnecessary components by integrating as much as possible from the traditional compute server into a single SoC (Server on a chip). A microserver will not deliver <b>the</b> <b>highest</b> <b>possible</b> single-thread <b>performance,</b> instead, it offers an energy optimized design point at medium-high delivered performance. In 2015, several high performance SoCs start appearing on the market, late 2016 a wider choice is available, such as Qualcomms Hydra.|$|R
40|$|GENERAL DESCRIPTION The AD 9054 A is an 8 -bit {{monolithic}} {{analog-to-digital converter}} optimized for high speed, low power, small size {{and ease of}} use. With a 200 MSPS encode rate capability and full-power analog bandwidth of 350 MHz, the component is ideal for applications requiring <b>the</b> <b>highest</b> <b>possible</b> dynamic <b>performance.</b> To minimize system cost and power dissipation, the AD 9054 A includes an internal 2. 5 V reference and track-and-hold circuit. The user provides only a 5 V power supply and an encode clock. No external reference or driver components are required for many applications. The AD 9054 A’s encode input interfaces directly to TTL, CMOS or positive-ECL logic and will operate with single-ended or differential inputs. The user may select dual-channel or singlechannel digital outputs. The dual (demultiplexed) mode interleave...|$|R
40|$|We present innovative, {{immersed}} grating based optical {{designs for}} the SMO (Spectrograph Main Optics) module of the Mid-infrared E-ELT Imager and Spectrograph, METIS. The immersed grating allows a significant reduction of SMO volume compared to conventional echelle grating designs, because the diffraction takes place in high refractive index silicon. Additionally, using novel optimization techniques and technical solutions in silicon micromachining offered by the semiconductor industry, further improvements can be achieved. We show optical architectures based on compact, double-pass Three Mirror Anastigmat (TMA) designs, which appear advantageous in terms of one or several of the following: optical performance, reduction of volume, ease of manufacturing and testing. We explore optical designs, where the emphasis is put on manufacturability and we investigate optical solutions, where {{the ultimate goal is}} <b>the</b> <b>highest</b> <b>possible</b> optical <b>performance.</b> These novel, silicon immersed grating based design concepts are applicable for future earth and space based spectrometers...|$|R
3000|$|The {{upper bound}} on the success {{probability}} of Theorem 3 represents <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> that the SAMD can achieve with no estimation errors at each detection, which is an optimistic scenario for an adversary. In reality, the actual probability of success will be {{much lower than the}} upper bound, due to estimation errors and error propagation through detections. If an adversary finds a solution of (16) via an exhaustive search, the complexity of each detection of the SAMD will be [...] O (2 ^J) with J≪N.|$|E
40|$|DOE has {{launched}} a program to make a step change in power plant to 1500 F steam, since <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> gains can be achieved in a 1500 F steam system when using a topping turbine in a back pressure steam turbine for cogeneration. A 500 -hour proof-of-concept steam generator test module was designed, fabricated, and successfully tested. It has four once-through steam generator circuits. The complete HPSS (high performance steam system) was tested above 1500 F and 1500 psig for over 102 hours at full power...|$|E
30|$|Despite our {{attempt to}} assign similar amount of system {{resources}} to each distributed processing engine {{and due to}} the fact that each one offers a handful of configuration settings regarding execution, memory allocation, and job scheduling behavior, the performance of the different implementations may differ from the optimal one. However, after performing numerous benchmarking sessions, we believe that for the current system setting, the presented configuration is fair, achieving <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> for all three engines, while maintaining the level of parallelism at 16. The configuration was performed by taking into consideration the corresponding guide of each engine.|$|E
50|$|In a {{departure}} from the design philosophy of the LS4, Rolladen-Schneider set out to design the LS7 as an uncompromised competition machine, seeking <b>the</b> <b>highest</b> <b>performance</b> <b>possible</b> with <b>the</b> technology of the time. Designer Wolf Lemke specified a highly laminar wing profile and developed a high aspect ratio wing. Carbon fibre was extensively used in the construction, along with aramid fibre, to ensure enough strength in spite of slender structural elements and increased loadings. The aileron drive bellcranks were entirely concealed within the wings, with a mere 30mm of usable height at the trailing edge.|$|R
5000|$|Those who favour {{the digital}} format {{point to the}} results of blind tests, which {{demonstrate}} <b>the</b> <b>high</b> <b>performance</b> <b>possible</b> with digital recorders. The assertion is that the 'analog sound' is more a product of analog format inaccuracies than anything else. One of the first and largest supporters of digital audio was the classical conductor Herbert von Karajan, who said that digital recording was [...] "definitely superior to any other form of recording we know". He also pioneered the unsuccessful Digital Compact Cassette and conducted the first recording ever to be commercially released on CD: Richard Strauss's Eine Alpensinfonie.|$|R
40|$|Systems and Processes Engineering Corporation (SPEC) has {{developed}} an innovative array processor architecture for computing Fourier transforms and other commonly used signal processing algorithms. This architecture is designed to extract <b>the</b> <b>highest</b> <b>possible</b> array <b>performance</b> from state-of-the-art GaAs technology. SPEC's architectural design includes a high performance RISC processor implemented in GaAs, along with a Floating Point Coprocessor and a unique Array Communications Coprocessor, also implemented in GaAs technology. Together, these data processors represent the latest in technology, both from an architectural and implementation viewpoint. SPEC has examined numerous algorithms and parallel processing architectures to determine the optimum array processor architecture. SPEC {{has developed}} an array processor architecture with integral communications ability to provide maximum node connectivity. The Array Communications Coprocessor embeds communications operations directly {{in the core of}} the processor architecture. A Floating Point Coprocessor architecture has been defined that utilizes Bit-Serial arithmetic units, operating at very high frequency, to perform floating point operations. These Bit-Serial devices reduce the device integration level and complexity to a level compatible with state-of-the-art GaAs device technology...|$|R
40|$|Abstract | The {{statistical}} analysis of traces taken from the NAS Parallel Benchmarks can tell one much about the type of network tra c that can be expected from scienti c applications run on distributed-memory parallel computers. For instance, such applications utilize a relatively few number of communication library functions, the length of their messages is widely varying, they use many more short messages than long ones, and within a single application the messages tend to follow relatively simple patterns. Information such as this {{can be used by}} hardware and software designers to optimize their systems for <b>the</b> <b>highest</b> <b>possible</b> <b>performance...</b>|$|E
40|$|Abstract ⎯ Defragmentation is a {{fundamental}} resource management service allowing Reconfigurable Computing Systems (RCSs) to efficiently utilize resources when tasks are dispatched dynamically. Only well orchestrated interactions between {{the components of the}} reconfigurable resource management system can sustain <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> level for applications running on these RCSs. While scheduling and placement have been extensively studied, defragmentation and its impact on overall system performance is still not well understood. This paper quantifies factors related to defragmentation that can affect performance in terms of level sustainement. The paper concludes by proposing an experimental approach to study this problem...|$|E
40|$|Abstract—The {{statistical}} analysis of traces taken from the NAS Parallel Benchmarks can tell one much about the type of network traffic that can be expected from scientific applications run on distributed-memory parallel computers. For instance, such applications utilize a relatively few number of communication library functions, the length of their messages is widely varying, they use many more short messages than long ones, and within a single application the messages tend to follow relatively simple patterns. Information such as this {{can be used by}} hardware and software designers to optimize their systems for <b>the</b> <b>highest</b> <b>possible</b> <b>performance...</b>|$|E
40|$|International audienceThis paper formalizes a data-flow {{component}} model specif- ically designed for building real-time interactive scientific visualization applications. The advantages sought {{in this model}} are performance, co- herence and application design assistance. The core of the article deals with the interpretation of a property and constraint based user specifica- tion to generate a concrete assembly based on our {{component model}}. To fulfill one or many coherence constraints simultaneously, the application graph is processed, particularly to find the optimal locations of filtering objects called regulators. The automatic selection and inter-connection of connectors {{in order to maintain}} the requested coherences and <b>the</b> <b>highest</b> <b>performance</b> <b>possible</b> is also part of the process...|$|R
40|$|The {{purpose of}} this study was to {{investigate}} the effects of different workloads on anaerobic power and anaerobic capacity in trained children. Wingate tests were performed on a Monark cycle ergometer by using loads of 60, 70, 80 g. kg- 1 for body mass on 47 young (21 boys, 26 girls) basketball players (age: 13. 44 ± 0. 54 years, weight: 59. 66 ± 11. 98 kg, height: 166. 81 ± 11. 16 cm). All subjects had been training regularly for at least 1. 5 year. Subjects were randomly divided into 3 groups and the three test loads were applied randomly to each group for three test sessions. The results indicate that both absolute and relative anaerobic power and capacity values were higher at 80 g. kg- 1 test load compared to the values at other test loads (60 and 70 g. kg- 1) in both gender groups. As a conclusion, although the issue of choosing optimal load setting that would elicit <b>the</b> <b>highest</b> <b>possible</b> anaerobic <b>performance</b> values for different populations is not fully resolved, using the loads of at least 80 g per kg body mass would be more appropriate in 13 – 14 years old trained children...|$|R
40|$|Abstract- This paper {{investigates the}} Digital Subscriber Line (DSL) data-rate {{increases}} {{possible with the}} Dynamic Spectrum Management (DSM) methods known as Level 3 Vectoring and Level 2 Band Preference. A suggested sequence of increasingly binder-adaptive DSM steps appears herein to assist and motivate DSL service providers and equipment vendors to progress in use of DSM. In particular, studies of bounds of spectral balancing find Band Preference as a practical method that provides <b>the</b> <b>highest</b> <b>possible</b> Level 2 <b>performance</b> in bundled or unbundled DSL environments. Investigations of vectoring begin with differential vectoring and show very high DSL data rates. These data rates increase further {{through the use of}} full-binder vectoring, leading to projections of feasible DSM vectored implementations of multi- 100 Mbps DSLs...|$|R
40|$|This {{bachelor}} thesis Creation and optimalization facebook {{campaign for}} specific e-shop is about marketing using of social network - Facebook, focusing on e-commerce Rodinnebaleni. cz. The thesis {{is divided into}} theoretical and practical part. The theoretical part is about the Internet marketing, social networks, Facebook and advertising on it. In the practical part I will deal {{with the creation of}} an advertising campaign for e-commerce rodinnebaleni. cz on Facebook. Individual results will be evaluated according to the PNO indicator. According to the results we will see how each ad set is effective. The measures for optimalization leading to <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> of the campaign gonna be established...|$|E
40|$|Abstract—Non-volatile memory {{technologies}} {{promise a}} vari-ety of advantages for memory architectures of {{next generation computing}} systems. However, these capabilities come {{at the cost of}} some inefficiencies governing the operation of these memories. The most well understood is the asymmetry of access. In order to most effectively take advantage of the benefits of these memory technologies in terms of density and reduced static power in systems while mitigating access complexity an one-size fits all method is not sufficient for all types of applications. Instead, cross-layer techniques that include the compiler, operating system, and hardware layer can extract characteristics from the application {{that can be used to}} deliver <b>the</b> <b>highest</b> <b>possible</b> <b>performance</b> while minimizing power consumption for systems using these memories...|$|E
40|$|The {{bachelor}} thesis {{provides an}} overview of selected aspects of staff care according to their application by two analyzed American firms: Google and Southwestern Company. The observed situation is compared with the practices from given area used in the Czech Republic. The main attention belongs to development, education of employees and their benefits. The thesis confirms that in the surveyed companies are benefits provided {{to a greater extent than}} is customary in the Czech Republic. The education is more intense and personalized. Both companies are focused in appreciating their employees and a good social environment, but Southwestern simultaneously supports competing in order to gain <b>the</b> <b>highest</b> <b>possible</b> <b>performance.</b> The study of given area also finds negatives of the situation in the USA and provides recommendations to both compared countries...|$|E
30|$|We {{present a}} {{practical}} solution for dynamic spectrum management (DSM) in digital subscriber line systems: the normalized-rate iterative algorithm (NRIA). Supported by a novel optimization problem formulation, the NRIA is the only DSM algorithm that jointly addresses spectrum balancing for frequency division duplexing systems and power allocation for the users sharing a common cable bundle. With a focus on being implementable rather than obtaining <b>the</b> <b>highest</b> <b>possible</b> theoretical <b>performance,</b> <b>the</b> NRIA is designed to efficiently solve the DSM optimization problem with the operators' business models in mind. This is achieved {{with the help of}} two types of parameters: the desired network asymmetry and the desired user priorities. The NRIA is a centralized DSM algorithm based on the iterative water-filling algorithm (IWFA) for finding efficient power allocations, but extends the IWFA by finding the achievable bitrates and by optimizing the bandplan. It is compared with three other DSM proposals: the IWFA, the optimal spectrum balancing algorithm (OSBA), and the bidirectional IWFA (bi-IWFA). We show that the NRIA achieves better bitrate performance than the IWFA and the bi-IWFA. It can even achieve performance almost as good as the OSBA, but with dramatically lower requirements on complexity. Additionally, the NRIA can achieve bitrate combinations that cannot be supported by any other DSM algorithm.|$|R
40|$|ARMI is a {{communication}} library {{that provides a}} framework for expressing fine-grain parallelism and mapping it to a particular machine using shared-memory and message passing library calls. The library is an advanced implementation of the RMI protocol and handles low-level details such as scheduling incoming communication and aggregating outgoing communication to coarsen parallelism when necessary. These details can be tuned for different platforms to allow user codes to achieve <b>the</b> <b>highest</b> <b>performance</b> <b>possible</b> without manual modification. ARMI is used by STAPL, our generic parallel library, to provide a portable, user transparent communication layer. We present the basic design {{as well as the}} mechanisms used in the current Pthreads/OpenMP, MPI implementations and/or a combination thereof. Performance comparisons between ARMI and explicit use of Pthreads or MPI are given on a variety of machines, including an HP V 2200, SGI Origin 3800, IBM Regatta-HPC and IBM RS 6000 SP cluster...|$|R
40|$|Abstract — A digital voltage-controlled {{oscillator}} (VCO) is described which uses frequency multiplication and division to achieve very wide bandwidth. The VCO uses current-mode logic {{and does not}} require reactive elements such as inductors, capacitors or varactors. A novel, fully symmetric exclusive-OR (XOR) circuit was developed which uses product pairs and emitter-coupled logic. To achieve <b>the</b> <b>highest</b> <b>performance</b> <b>possible,</b> <b>the</b> critical path is symmetric and special physical design techniques were developed to promote matched-capacitance. The maximum measured frequency was 13. 66 GHz. The chip occupies 1. 9 mm 1. 6 mm and dissipates 2. 45 W at a supply voltage of 6. 0 V. With a measured frequency range from 1. 25 to 13. 66 GHz, this circuit has the widest bandwidth {{reported in the literature}} for any VCO, digital or analog. Index Terms—Current-mode logic, exclusive-OR gate, hetero-structure bipolar transistors, matched-capacitance layout, phase-locked loop, quadrature frequency multiplication, ring-oscillator, variable-delay element, {{voltage-controlled oscillator}}s. I...|$|R
