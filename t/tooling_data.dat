7|8993|Public
40|$|This paper {{contains}} {{a detailed description}} of a thirteen machine COMAU FMS for a company in Torino, Italy. The monthly and daily problems {{that need to be addressed}} and the approaches that are suggested to operate this system efficiently are detailed. The trickier problems and constraints are those of tool management, especially tool loading. Detailed <b>tooling</b> <b>data</b> and their analysis are also presented. The complete spectrum of operational problems addressed range from aggregate planning to detailed scheduling, including fixture and inventory management. Breakdown situations are also addressed...|$|E
40|$|Abstract. This {{article is}} a {{detailed}} case study of a particular FMS that will be operational in 1989. It describes the daily planning and operating problems that {{will need to be}} addressed. The algorithms that will operate this system are presented. Given the daily changing production requirements, the algorithms begin with an aggregate planning feasibility check. Then planning, scheduling, inventory management, and breakdowns are addressed. The key problems in operating this system are tool management problems. Detailed <b>tooling</b> <b>data</b> and their analysis are presented in an appendix to address these problems. 1...|$|E
40|$|Information {{systems in}} today’s {{manufacturing}} enterprises are distributed. Data exchange and share {{can be performed}} by computer network systems. Enterprises are performing operations globally and e-manufacturing enterprises not only obtain online information but also organize production activities. The present manufacturing scenario demands the efficient database systems for manufacturing to perform the operations globally and to enable the e-manufacturing environment. Database systems {{are the key to}} implementing information modeling. Engineering information modeling requires database support. This paper proposes a manufacturing database system for STEP-NC data from EXPRESS entities. This manufacturing database mainly includes processing data, manufacturing data for milling and turning, <b>tooling</b> <b>data</b> for milling and turning...|$|E
40|$|<b>tools,</b> <b>data</b> {{repositories}} {{and knowledge}} resources. We {{are going to}} describe|$|R
5000|$|ISO 13399: ISO {{standard}} for cutting <b>tool</b> <b>data</b> representation and exchange ...|$|R
5000|$|The {{ability to}} monitor tool {{function}} ensures <b>tool</b> <b>data</b> integrity for {{the entirety of}} the inspection.|$|R
40|$|Over {{the past}} few years, {{manufacturing}} companies have {{had to deal with}} an increasing demand for feature-rich products at low costs. The pressures exerted on their existing manufacturing processes have lead manufacturers to investigate internet-based solutions, in order to cope with growing competition. The decentralisation phenomenon also came up as a reason to implement networked-application, which has been the starting point for internet/intranet–based systems. Today, the availability of powerful and low cost 3 D tools, database backend systems, along with web-based technologies, provides interesting opportunities to the manufacturing community, with solutions directly implementable at the core of their businesses and organisations. In this paper a web-based engineering approach is presented to developing a design support system using case-based reasoning (CBR) technology for helping in the decision-making process when choosing cutting tools. The system aims to provide on-line intelligent support for determining the most suitable configuration for turning operations, based on initial parameters and requirements for the cutting operation. The system also features a user-driven 3 D turning simulator which allows testing the chosen insert for several turning operations. The system aims to be a useful e-manufacturing tool being able to quickly and responsively provide <b>tooling</b> <b>data</b> in a highly interactive way...|$|E
40|$|The {{machine tool}} {{industry}} is highly dependent on the tooling which is needed to machine the components {{used to make the}} range of products seen in today's society. The range of tooling available to machinists is prolific and subject to continual growth. Those engineers faced with the task of process planning require advanced systems to support the decisions that need to be made for the production process to operate smoothly. The <b>tooling</b> <b>data</b> made available by these systems is a key factor in defining the efficiency with which the production processes can be carried out. This research examines the technical decision support systems made available to industrialists and highlights the scope to provide tooling engineers with up-to-date tooling performance and use data that can be used both in the planning stages as well as dealing with problems encountered during production. Specifically, this research identifies the role performed by widespread tool trials, associated with new tools or new materials, and goes on to show how the information obtained from tool trials can be collated in a structured manner and used to enhance the provision of data with which to carry out the process planning task. The goal of this research was to develop and implement a framework capable of collecting and disseminating data related to tool trials in a coherent and supportive fashion using distributed methods. This target resulted in the deployment of a system named JadeT, which is capable of receiving and analysing data from tool trials and subsequently enhancing the process planning task by basing cutting parameter selection on a combination of fundamental cutting parameter algorithms in parallel with using the approved data generated from tool trials. The JadeT system was tested via the creation of a database using actual tool trial reports, {{and the manner in which}} this data was used to provide cutting parameters was analysed. The JadeT system has been developed, deployed and evaluated. The opportunity to use data contained within tool trial reports to support process planning tasks has been identified and exploited. The testing of JadeT indicates that the system fulfils the initial goals and was able to provide suggestions for further research in this area...|$|E
40|$|With the {{globalisation}} {{and constant}} {{changes in the}} marketplace, enterprises are adapting themselves to face new challenges. Therefore, strategic corporate alliances to share knowledge, expertise and resources represent an advantage in an increasing competitive world. This has led the integration of companies, customers, suppliers and partners using networked environments. This thesis presents three novel solutions in the tooling area, developed for Seco tools Ltd, UK. These approaches implement a proposed distributed computing architecture using Internet technologies to assist geographically dispersed tooling engineers in process planning tasks. The systems are summarised as follows. TTS is a Web-based system to support engineers and technical staff in the task of providing technical advice to clients. Seco sales engineers access the system from remote machining sites and submit/retrieve/update the required <b>tooling</b> <b>data</b> located in databases at the company headquarters. The communication platform used for this system provides an effective mechanism to share information nationwide. This system implements efficient methods, such as data relaxation techniques, confidence score and importance levels of attributes, to help the user in finding the closest solutions when specific requirements are not fully matched In the database. Cluster-F has been developed to assist engineers and clients {{in the assessment of}} cutting parameters for the tooling process. In this approach the Internet acts as a vehicle to transport the data between users and the database. Cluster-F is a KD approach that makes use of clustering and fuzzy set techniques. The novel proposal In this system is the implementation of fuzzy set concepts to obtain the proximity matrix that will lead the classification of the data. Then hierarchical clustering methods are applied on these data to link the closest objects. A general KD methodology applying rough set concepts Is proposed In this research. This covers aspects of data redundancy, Identification of relevant attributes, detection of data inconsistency, and generation of knowledge rules. R-sets, the third proposed solution, has been developed using this KD methodology. This system evaluates the variables of the tooling database to analyse known and unknown relationships in the data generated after the execution of technical trials. The aim is to discover cause-effect patterns from selected attributes contained In the database. A fourth system was also developed. It is called DBManager and was conceived to administrate the systems users accounts, sales engineers’ accounts and tool trial monitoring process of the data. This supports the implementation of the proposed distributed architecture and the maintenance of the users' accounts for the access restrictions to the system running under this architecture...|$|E
5000|$|Movement {{toward an}} {{enterprise}} level approach to managing analytical <b>tools,</b> <b>data,</b> and organizational skills and capabilities ...|$|R
5000|$|DocuTie for ediscovery <b>tool,</b> <b>data</b> {{classification}} & categorization, encryption, early case assessment (ECA) {{and search}} for Enterprises and SMB organizations.|$|R
40|$|The aim of {{this thesis}} is to suggest a {{conception}} of implementation of <b>Tool</b> <b>Data</b> Management system into Tirad metal-working company. The {{first part of the}} thesis suggests a way of integration of <b>Tool</b> <b>Data</b> Management into a greater complex of implemented measures named Cybernetic Space for Production Control and Planning. Subsequent parts deal with the implementation itself. The final part lists presumptive technical and economical effects on the operation of Tirad company...|$|R
40|$|The {{explosive}} growth of Internet-based architectures is allowing an efficient {{access to information}} resources over geographically dispersed areas. This fact is exerting {{a major influence on}} current manufacturing practices. Business activities involving customers, partners, employees and suppliers are being rapidly and efficiently integrated through networked information management environments. Therefore, efforts are required to take advantage of distributed infrastructures that can satisfy information integration and collaborative work strategies in corporate environments. In this research, Internet-based distributed solutions focused on the manufacturing industry are proposed. Three different systems have been developed for the tooling sector, specifically for the company Seco Tools UK Ltd (industrial collaborator). They are summarised as follows. SELTOOL is a Web-based open tool selection system involving the analysis of technical criteria to establish appropriate selection of inserts, toolholders and cutting data for turning, threading and grooving operations. It has been oriented to world-wide Seco customers. SELTOOL provides an interactive and crossed-way of searching for tooling parameters, rather than conventional representation schemes provided by catalogues. Mechanisms were developed to filter, convert and migrate data from different formats to the database (SQL-based) used by SELTOOL. TTS (Tool Trials System) is a Web-based system developed by the author and two other researchers to support Seco sales engineers and technical staff, who would perform tooling trials in geographically dispersed machining centres and benefit from sharing data and results generated by these tests. Through TTS tooling engineers (authorised users) can submit and retrieve highly specific technical <b>tooling</b> <b>data</b> for both milling and turning operations. Moreover, it is possible for tooling engineers to avoid the execution of new tool trials knowing the results of trials carried out in physically distant places, when another engineer had previously executed these trials. The system incorporates encrypted security features suitable for restricted use on the World Wide Web. An urgent need exists for tools to make sense of raw data, extracting useful knowledge from increasingly large collections of data now being constructed and made available from networked information environments. This {{explosive growth}} in the availability of information is overwhelming the capabilities of traditional information management systems, to provide efficient ways of detecting anomalies and significant patterns in large sets of data. Inexorably, the tooling industry is generating valuable experimental data. It is a potential and unexplored sector regarding the application of knowledge capturing systems. Hence, to address this issue, a knowledge discovery system called DISKOVER was developed. DISKOVER is an integrated Java-application consisting of five data mining modules, able to be operated through the Internet. Kluster and Q-Fast are two of these modules, entirely developed by the author. Fuzzy-K has been developed by the author in collaboration with another research student in the group at Durham. The final two modules (R-Set and MQG) have been developed by another member of the Durham group. To develop Kluster, a complete clustering methodology was proposed. Kluster is a clustering application able to combine the analysis of quantitative as well as categorical data (conceptual clustering) to establish data classification processes. This module incorporates two original contributions. Specifically, consistent indicators to measure the quality of the final classification and application of optimisation methods to the final groups obtained. Kluster provides the possibility, to users, of introducing case-studies to generate cutting parameters for particular Input requirements. Fuzzy-K is an application having the advantages of hierarchical clustering, while applying fuzzy membership functions to support the generation of similarity measures. The implementation of fuzzy membership functions helped to optimise the grouping of categorical data containing missing or imprecise values. As the tooling database is accessed through the Internet, which is a relatively slow access platform, it was decided to rely on faster Information retrieval mechanisms. Q-fast is an SQL-based exploratory data analysis (EDA) application, Implemented for this purpose...|$|E
5000|$|Technical country {{capacity}} enhancing support through {{sharing of}} expertise, common approaches, analyses, methodologies, <b>tools,</b> <b>data,</b> best practices and facilitated South-South knowledge sharing.|$|R
50|$|Tool {{management}} guarantees {{efficient and}} faultless order processing. Existing knowledge is made generally available and the guidelines {{stated in the}} master data are noticed. The integration of <b>tool</b> <b>data</b> enables other applications to use the <b>tool</b> <b>data</b> which is maintained with tool management. Applications either fall back on the tool management database, or the data {{will be replaced by}} the interfaces. Especially in CNC manufacturing where several persons are involved in the production process, integration avoids faults, delays and duplicate data recording.|$|R
50|$|In {{addition}} to caGrid, the underlying infrastructure for data sharing among organizations, caBIG developed software <b>tools,</b> <b>data</b> sharing policies, and common standards and vocabularies to facilitate data sharing.|$|R
50|$|In {{addition}} to the main <b>tool</b> <b>data,</b> auxiliary data tables simplify data acquisition, using values selected from a table. Compared to manual input, this ensures more comfortable and consistent data collection.|$|R
5000|$|... 1988 EXAPT {{expands the}} {{software}} product range by {{systems for the}} <b>tool</b> <b>data</b> management (BMO) and production data management (FDO). In 1988 EXAPT trains more than 1.300 course participants including company-specific courses.|$|R
50|$|There are {{two levels}} of {{licensing}} of AQT: the Standard License, which allows most functionality, and the Extended License, which allows full use including the administration <b>tools,</b> <b>data</b> compare, and the data loader.|$|R
30|$|The {{questionnaire}} was posted on [URL] between {{the dates of}} 28 September 2014 and 1 December 2014. The {{questionnaire was}} designed online using [URL] a free survey <b>tool.</b> <b>Data</b> was downloaded from esurv.org in Excel spreadsheet form.|$|R
40|$|International audienceAdvanced sensor and {{information}} technologies have made real-time <b>tool</b> <b>data</b> readily accessible to tool and process engineers. A {{significant number of}} tool parameters (SVID’s) is collected during wafer processing and {{a large amount of}} <b>tool</b> <b>data</b> is acquired and available for fault detection and classification (FDC). Many IC makers have substantially improved the process capabilities by implementing FDC. With the real-time <b>tool</b> <b>data,</b> one can also evaluate the overall tool condition so that tool maintenance can be more effectively scheduled and the post-maintenance tool condition can be more easily qualified. However, due to the frequent change of recipes and the diversity of operations, the overall tool health is very difficult to evaluate. In this paper, we propose a recipe-independent health indicator based on the generalized moving variance. It is shown that the indicator faithfully reveals the tool condition regardless of recipe/operation changes. With the tool health indicator, possible tool faults can be identified and proper maintenance measures can be scheduled accordingly. The proposed indicator will be demonstrated and validated through the case studies of a PECVD and a PVD tool from a local fab...|$|R
5000|$|Hiren's BootCD (also {{known as}} HBCD) is a {{bootable}} CD containing {{a number of}} diagnostic programs such as partitioning agents, system performance benchmarks, disk cloning and imaging <b>tools,</b> <b>data</b> recovery <b>tools,</b> MBR tools, BIOS tools, and others for fixing various computer problems.|$|R
30|$|Silk 11 is an {{open source}} {{framework}} for integrating heterogeneous data sources. By using this <b>tool,</b> <b>data</b> publishers can establish RDF links from their data sources to other data sources on the Web. Therefore, like Apache Jenna, it also belongs to the data creation phase.|$|R
50|$|A {{simple method}} of SIT {{which can be}} {{performed}} with minimum usage of software testing <b>tools.</b> <b>Data</b> imports and exports are exchanged before the behavior of each data field within each individual layer is investigated. After the software collaboration, there are three main states of data flow.|$|R
40|$|Drinking {{water from}} the supply network {{of the city of}} Foc�ani, Vrancea county is used in food {{preparation}} and also for cleaning the production areas, equipments and working <b>tools.</b> <b>Data</b> obtained from the analysis of microbiological parameters of reference of water supply quality are presented in this pap...|$|R
40|$|This {{thesis is}} focused on {{proposal}} of production process of assembled crankshaft. It consists of choice of <b>tools,</b> <b>data</b> selection and optimisation for manufacture of individual components and for the assembly. In the assembly are also calculated important parameters for pressing components. Selected cutting conditions are experimentally verified...|$|R
50|$|Some notable {{features}} of JOSM are importing GPX files (GPS tracks), working with aerial imagery (including WMS, TMS and WMTS protocols), support for multiple cartographic projections, layers, relations editing, <b>data</b> validation <b>tools,</b> <b>data</b> filtering, offline work, presets and rendering styles. JOSM provides more than 200 keyboard shortcuts for the core functions.|$|R
5000|$|... #Caption: Achilles <b>tool</b> for <b>data</b> {{characterization}} of a healthcare dataset ...|$|R
40|$|One of the {{important}} developments in modern manufacturing industry has been the trend towards cost savings through stuff reductions whilst simultaneously improving the product quality. Traditional tool change strategies are based on very conservative estimates of tool life from past <b>tool</b> <b>data</b> and {{this leads to a}} higher tool change frequency and highe...|$|R
50|$|Since GXL is {{a general}} graph {{exchange}} format, {{it can also be}} used to interchange any graph-based data, including models between computer-aided software engineering (CASE) <b>tools,</b> <b>data</b> between graph transformation systems, or graph visualization tools. GXL includes support for hypergraphs and hierarchical graphs, and can be extended to support other types of graphs.|$|R
30|$|The IRI {{course on}} Climate Information for Public Health (CIPH) and its {{associated}} courses {{grew out of a}} recognition that there are major gaps in the knowledge, methodologies, <b>tools,</b> <b>data</b> and resources available to members of the public health community in their quest to better manage climate-related risks to improve public health outcomes. These gaps include a lack of educational and practitioner texts, <b>tools,</b> methodologies and <b>data</b> that illustrate the value of climate information to the public health sector (Connor et al. 2010).|$|R
40|$|Higher {{productivity}} and better quality in software development {{can be obtained}} by providing the programmer with a cooperative and helpful environment. Such environments must put much more emphasis on Programming-in-the-Many aspects such as: cognitive modeling, coordination, interoperability, distribution, sharing, cooperation, and communication. We propose a framework to support both Programming-in-the-Large and Programming-inthe -Many. A General Object-Based Environment (GOBE) is based on an object-oriented view of the whole environment - i. e. <b>tools,</b> <b>data,</b> people. It combines the ability to allow collaboration and sharing with an easy way to introduce new <b>tools,</b> <b>data</b> and agents. We describe the architecture and the basic component of a GOBE which is the object. Furthermore, examples are given of elegant solutions to some problems from Programmingin -the-Many and Programming-in-the-Large. 1 Introduction It has long been a well-known fact that the software industry is unable to sat [...] ...|$|R
30|$|In future work, MetaDP {{will provide}} an open API interface, so that {{researchers}} can easily integrate other bioinformatics <b>tools</b> and <b>data</b> analysis workflows with our platform. We will also integrate more metagenomic <b>data</b> analysis <b>tools,</b> <b>data</b> analysis workflows, and machine learning models, making our platform useful {{for the analysis of}} more diseases. Users can also perform custom/personalized data analysis processes according to their own requirements. The MetaDP platform can be easily used for microorganism-associated diseases, such as diabetes, obesity, and colorectal cancer, among others. We will collect more intestinal microbial sequencing data to expand disease prediction models for better disease prevention and diagnosis.|$|R
5000|$|Covert channel <b>tool</b> hides <b>data</b> in IPv6, SecurityFocus, August 11, 2006.|$|R
50|$|Developer <b>tools</b> include <b>data</b> logging, pretty-printer, profiler, {{contract}} programming, and unit tests.|$|R
5000|$|<b>Tools</b> and <b>data</b> can reside on many {{different}} systems across the network ...|$|R
