278|0|Public
2500|$|The second scheme, {{and the one}} {{implemented}} in many production-quality C++ compilers, is a <b>table-driven</b> approach. This creates static tables at compile time and link time that relate ranges of the program counter to the program state with respect to exception handling. [...] Then, if an exception is thrown, the runtime system looks up the current instruction location in the tables and determines what handlers are in play and {{what needs to be}} done. This approach minimizes executive overhead for the case where an exception is not thrown. This happens at the cost of some space, but this space can be allocated into read-only, special-purpose data sections that are not loaded or relocated until an exception is actually thrown. [...] This second approach is also superior in terms of achieving thread safety.|$|E
5000|$|... #Subtitle level 3: State-Based and <b>Table-Driven</b> Construction Techniques ...|$|E
5000|$|Reusable steps {{created in}} a table a.k.a. keyword-driven or <b>table-driven</b> testing.|$|E
5000|$|The {{design of}} those {{programs}} which rely on event-action model has been criticised, {{and it has been}} suggested that event-action model leads programmers to create error prone, difficult to extend and excessively complex application code. <b>Table-driven</b> state machines have been advocated as a viable alternative. On the other hand, <b>table-driven</b> state machines themselves suffer from significant weaknesses including [...] "state explosion" [...] phenomenon.|$|E
5000|$|... using dynamic, <b>table-driven</b> logic, {{as opposed}} to logic {{embodied}} in previously compiled programs. The use of <b>table-driven</b> logic, i.e. behavior that is heavily dictated by {{the contents of a}} database, allows programs to be simpler and more flexible. This capability is a central feature of dynamic programming languages. See also control tables for tables that are normally coded and embedded within programs as data structures (i.e. not compiled statements) but could equally be read in from a flat file, database or even retrieved from a spreadsheet.|$|E
50|$|This {{protocol}} uses a reactive approach which {{eliminates the}} need to periodically flood the network with table update messages which are required in a <b>table-driven</b> approach. In a reactive (on-demand) approach such as this, a route is established only when it is required and hence the need to find routes to all other nodes in the network {{as required by the}} <b>table-driven</b> approach is eliminated. The intermediate nodes also utilize the route cache information efficiently to reduce the control overhead. The disadvantage of this protocol is that the route maintenance mechanism does not locally repair a broken link. Stale route cache information could also result in inconsistencies during the route reconstruction phase. The connection setup delay is higher than in <b>table-driven</b> protocols. Even though the protocol performs well in static and low-mobility environments, the performance degrades rapidly with increasing mobility. Also, considerable routing overhead is involved due to the source-routing mechanism employed in DSR. This routing overhead is directly proportional to the path length.|$|E
50|$|A <b>table-driven</b> parser {{has all of}} its {{knowledge}} about the grammar encoded into unchanging data called parser tables. The parser's program code is a simple generic loop that applies unchanged to many grammars and languages. The tables may be worked out by hand for precedence methods. For LR methods, the complex tables are mechanically derived from a grammar by some parser generator tool like Bison. The parser tables are usually {{much larger than the}} grammar. In other parsers that are not <b>table-driven,</b> such as recursive descent, each language construct is parsed by a different subroutine, specialized to the syntax of that one construct.|$|E
50|$|The Object-Oriented State Machine Operating System (OOSMOS), {{written in}} C, {{promotes}} object-oriented encapsulation and implements a full <b>table-driven</b> hierarchical state machine facility. OOSMOS operates on a bare board or {{in cooperation with}} an existing operating system.|$|E
50|$|State-based {{programming}} is a programming technology using finite state machines to describe program behaviors. A <b>table-driven</b> method is a schema that uses tables {{to look up}} information rather than using logic statements (such as if and case).|$|E
50|$|Some LR parser {{generators}} create separate tailored {{program code}} for each state, {{rather than a}} parse table. These parsers can run several {{times faster than the}} generic parser loop in <b>table-driven</b> parsers. The fastest parsers use generated assembler code.|$|E
50|$|Sin, arctan, {{polynomial}} functions, or piecewise functions (such as {{the hard}} clipping function) {{are commonly used}} as waveshaping transfer functions. It is also possible to use <b>table-driven</b> functions, consisting of discrete points {{with some degree of}} interpolation or linear segments.|$|E
5000|$|If the {{algorithms}} are not pre-built {{into the}} interpreter (and therefore require additional runtime interpretation of an expression {{held in the}} table), it is known as [...] "Rule-based Rating" [...] rather than <b>table-driven</b> rating (and consequently consumes significantly more overhead).|$|E
5000|$|<b>Table-driven</b> (codeless) programming, usually {{running with}} a runtime {{framework}} and libraries. Instead of using code, the developer defines their logic by selecting an operation in a pre-defined list of memory or data table manipulation commands. In other words, instead of coding, the developer uses <b>table-driven</b> algorithm programming (see also control tables {{that can be}} used for this purpose). A good example of this type of 4GL language is PowerBuilder. These types of tools can be used for business application development usually consisting in a package allowing for both business data manipulation and reporting, therefore they come with GUI screens and report editors. They usually offer integration with lower level DLLs generated from a typical 3GL for when the need arise for more hardware/OS specific operations.|$|E
50|$|This grammar is LR(0) {{in that it}} is left-recursive (in the expr non-terminal) {{but does}} not require any lookahead. Recursive ascent is also capable of {{handling}} grammars which are LALR(1) {{in much the same way}} that <b>table-driven</b> parsers handle such cases (by pre-computing conflict resolutions based on possible lookahead).|$|E
50|$|The {{main goal}} of re2c is {{generating}} fast lexers:at least {{as fast as}} resonably optimized C lexers coded by hand.Instead of using traditional <b>table-driven</b> approach, re2cencodes the generated finite state machine directly {{in the form of}} conditional jumps and comparisons.The resulting program is faster than its <b>table-driven</b> counterpartand much easier to debug and understand.Moreover, this approach often results in smaller lexers,as re2c applies a number of optimizations such as DFA minimization and the construction of tunnel automaton.Another distinctive feature of re2c is its flexible interface:instead of assuming a fixed program template,re2c lets the programmer write most of the interface code and adapt the generated lexer to any particular environment.The main idea is that re2c should be a zero-cost abstraction for the programmer:using it should never result in a slower program than the corresponding hand-coded implementation.|$|E
50|$|Computer-aided process {{planning}} initially evolved {{as a means}} to electronically store a process plan once it was created, retrieve it, modify it for a new part and print the plan. Other capabilities were <b>table-driven</b> cost and standard estimating systems, for sales representatives to create customer quotations and estimate delivery time.|$|E
50|$|The XPL {{compiler}}, called XCOM, is a one-pass compiler using a <b>table-driven</b> parser {{and simple}} code generation techniques. Versions of XCOM exist for different machine architectures, using different hand-written code generation modules for those targets. The original target was IBM System/360, {{which is a}} proper subset of IBM System/370, IBM System/390 and IBM System z.|$|E
5000|$|... (ERror GENeration and Test):This test tool was {{developed}} to test the device support error recovery in IBM's PCP (Primary Control Program) operating system, then being developed. It used a novel and very efficient <b>table-driven</b> finite state machine (FSM) to inject simulated errors and verify that the operating system followed the detailed specifications of {{actions to be taken}} to attempt recovery.|$|E
50|$|Keyword-driven testing, {{also known}} as <b>table-driven</b> testing or action word based testing, is a {{software}} testing methodology suitable for both manual and automated testing. This method separates the documentation of test cases -including the data to use- from the prescription {{of the way the}} test cases are executed. As a result it separates the test creation process into two distinct stages: a design and development stage, and an execution stage.|$|E
50|$|A {{recursive}} ascent parser implements an LALR parser using mutually-recursive functions {{rather than}} tables. Thus, the parser is directly encoded {{in the host}} language similar to recursive descent. Direct encoding usually yields a parser which is faster than its <b>table-driven</b> equivalent {{for the same reason}} that compilation is faster than interpretation. It is also (in principle) possible to hand edit a recursive ascent parser, whereas a tabular implementation is nigh unreadable to the average human.|$|E
50|$|The {{focus of}} the project was on the {{semantics}} and machine-dependent phases of compilation, since lexical and syntactic analysis were already well understood. Each phase was formalized in a manner that permits expression in <b>table-driven</b> form. The automatic construction of the compiler then consists of deriving these tables from the semantic definitions of the language and target machine. Though this approach was largely successful for target machine description, it was less so for semantics.|$|E
50|$|In {{computer}} science, recursive ascent parsing is {{a technique}} for implementing an LALR parser which uses mutually-recursive functions rather than tables. Thus, the parser is directly encoded in the host language similar to recursive descent. Direct encoding usually yields a parser which is faster than its <b>table-driven</b> equivalent {{for the same reason}} that compilation is faster than interpretation. It is also (nominally) possible to hand edit a recursive ascent parser, whereas a tabular implementation is nigh unreadable to the average human.|$|E
50|$|One of {{the most}} {{commonly}} encountered CRC algorithms is known as CRC-32, used by (among others) Ethernet, FDDI, ZIP and other archive formats, and PNG image format. Its polynomial can be written msbit-first as 0x04C11DB7, or lsbit-first as 0xEDB88320. The W3C webpage on PNG includes an appendix with a short and simple <b>table-driven</b> implementation in C of CRC-32. You will note that the code corresponds to the lsbit-first byte-at-a-time pseudocode presented here, and the table is generated using the bit-at-a-time code.|$|E
5000|$|... : Languages which strop their {{keywords}} {{or allow}} arbitrary spaces within identifiers require a phase before parsing, which converts the input character sequence to a canonical form {{ready for the}} parser. The top-down, recursive-descent, <b>table-driven</b> parsers used in the 1960s typically read the source one character {{at a time and}} did not require a separate tokenizing phase. Atlas Autocode, and Imp (and some implementations of ALGOL and Coral 66) are examples of stropped languages which compilers would have a Line Reconstruction phase.|$|E
5000|$|BUFR {{was created}} in 1988 {{with the goal of}} {{replacing}} the WMO's dozens of character-based, position-driven meteorological codes, such as SYNOP (surface observations), TEMP (upper air soundings) and CLIMAT (monthly climatological data). BUFR was designed to be portable, compact, and universal. Any kind of data can be represented, along with its specific spatial/temporal context and any other associated metadata. In the WMO terminology, BUFR belongs to the category of <b>table-driven</b> code forms, where the meaning of data elements is determined by referring to a set of tables that are kept and maintained separately from the message itself.|$|E
50|$|Destination-Sequenced Distance-Vector Routing (DSDV) is a <b>table-driven</b> routing {{scheme for}} ad hoc mobile {{networks}} {{based on the}} Bellman-Ford algorithm. It was developed by C. Perkins and P.Bhagwat in 1994. The main contribution of the algorithm was to solve the routing loop problem. Each entry in the routing table contains a sequence number, the sequence numbers are generally even if a link is present; else, an odd number is used. The number is generated by the destination, and the emitter needs to send out the next update with this number. Routing information is distributed between nodes by sending full dumps infrequently and smaller incremental updates more frequently.|$|E
5000|$|A shift-reduce parser is a {{class of}} efficient, <b>table-driven</b> {{bottom-up}} parsing methods for computer languages and other notations formally defined by a grammar. The parsing methods most commonly used for parsing programming languages, LR parsing and its variations, are shift-reduce methods. [...] The precedence parsers used before the invention of LR parsing are also shift-reduce methods. All shift-reduce parsers have similar outward effects, in the incremental {{order in which they}} build a parse tree or call specific output actions. The outward actions of an LR parser are best understood by ignoring the arcane mathematical details of how LR parser tables are generated, and instead looking at the parser as just some generic shift-reduce method.|$|E
5000|$|Control {{tables are}} tables {{that control the}} control flow or play a major part in program control. There are no rigid rules about the {{structure}} or content of a control table - its qualifying attribute {{is its ability to}} direct control flow in some way through [...] "execution" [...] by a processor or interpreter. The design of such tables is sometimes referred to as <b>table-driven</b> design (although this typically refers to generating code automatically from external tables rather than direct run-time tables). In some cases, control tables can be specific implementations of finite-state-machine-based automata-based programming. If there are several hierarchical levels of control table they may behave in a manner equivalent to UML state machines ...|$|E
50|$|Dynamic {{source routing}} {{protocol}} (DSR) is an on-demand protocol designed {{to restrict the}} bandwidth consumed by control packets in ad hoc wireless networks by eliminating the periodic table-update messages required in the <b>table-driven</b> approach. The major difference between this and the other on-demand routing protocols {{is that it is}} beacon-less and hence does not require periodic hello packet (beacon) transmissions, which are used by a node to inform its neighbors of its presence. The basic approach of this protocol (and all other on-demand routing protocols) during the route construction phase is to establish a route by flooding RouteRequest packets in the network. The destination node, on receiving a RouteRequest packet, responds by sending a RouteReply packet back to the source, which carries the route traversed by the RouteRequest packet received.|$|E
50|$|Lexer {{performance}} is a concern, and optimizing is worthwhile, {{more so in}} stable languages where the lexer is run very often (such as C or HTML). lex/flex-generated lexers are reasonably fast, but improvements of {{two to three times}} are possible using more tuned generators. Hand-written lexers are sometimes used, but modern lexer generators produce faster lexers than most hand-coded ones. The lex/flex family of generators uses a <b>table-driven</b> approach which is much less efficient than the directly coded approach. With the latter approach the generator produces an engine that directly jumps to follow-up states via goto statements. Tools like re2c have proven to produce engines that are between two and three times faster than flex produced engines. It is in general difficult to hand-write analyzers that perform better than engines generated by these latter tools.|$|E
5000|$|The second scheme, {{and the one}} {{implemented}} in many production-quality C++ compilers, is a <b>table-driven</b> approach. This creates static tables at compile time and link time that relate ranges of the program counter to the program state with respect to exception handling. [...] Then, if an exception is thrown, the runtime system looks up the current instruction location in the tables and determines what handlers are in play and {{what needs to be}} done. This approach minimizes executive overhead for the case where an exception is not thrown. This happens at the cost of some space, but this space can be allocated into read-only, special-purpose data sections that are not loaded or relocated until an exception is actually thrown. [...] This second approach is also superior in terms of achieving thread safety.|$|E
50|$|The XCOM {{compiler}} has a hand-written lexical scanner and a mechanically-generated parser. The syntax of the compiler's {{input language}} (in this case, XPL) {{is described by}} a simplified BNF grammar. XPL's grammar analyzer tool ANALYZER or XA turns this into a set of large data tables describing all legal combinations of the syntax rules and how to discern them. This table generation step is re-done only when the language is changed. When the compiler runs, those data tables are used by a small, language-independent parsing algorithm to parse {{and respond to the}} input language. This style of <b>table-driven</b> parser is generally easier to write than an entirely hand-written recursive descent parser. XCOM uses a bottom-up parsing method, in which the compiler can delay its decision about which syntax rule it has encountered until it has seen the rightmost end of that phrase. This handles a wider range of programming languages than top-down methods, in which the compiler must guess or commit to a specific syntax rule early, when it has only seen the left end of a phrase.|$|E
5000|$|The Laboratory {{distributed}} software, {{and later}} data, at cost, thus encouraging experimentation. The Laboratory conducted correspondence courses, hosted numerous conferences, {{and worked on}} environmental planning and architectural projects with the Harvard Graduate School of Design. From 1978 to 1983, the Laboratory hosted a popular annual Harvard Computer Graphics Week. [...] Geoffrey Dutton, a Research Associate at the Laboratory from 1969 through 1984, created the first holographic thematic map, [...] "America Graph Fleeting" [...] in 1978. [...] This rotating strip of 3,000 holograms depicted an animated sequence of 3d maps showing US population growth from 1790 to 1970, generated by the Laboratory's ASPEX program. Dutton also contributed the program DOT.MAP to the Laboratory's family of distributed software (1977). [...] In 1977 James Dougenik, Duane Niemeyer, and Nicholas Chrisman developed contiguous area cartograms. [...] Bruce Donald, working at the Laboratory from 1978 to 1984, wrote BUILDER, a program for computer-aided architecture. [...] BUILDER produced plan and shaded perspectives that popularised computer-aided-design in architecture. [...] Donald also wrote the CALYPSO module for the commercial Odyssey project and worked on the GLIB/LINGUIST [...] <b>table-driven</b> language system in collaboration with Nick Chrisman and Jim Dougenik, {{which was based on}} automata theory and dynamic scoping. GLIB/LINGUIST provided an English-like user interface for Odyssey, BUILDER, and other HLCG software.|$|E
40|$|Abstract. The aim of {{this work}} {{is to provide a}} model for the dynamic {{implementation}} of finite automata for enhanced performance. Investigations have shown that hardcoded finite automata outperforms the traditional <b>table-driven</b> implementation up to some threshold. Moreover, the kind of string being recognized {{plays a major role in}} the overall processing speed of the string recognizer. Various experiments are depicted to show when the advantages of using hardcoding as basis for implementing finite automata (instead of using the classical <b>table-driven</b> approach) become manifest. The model, a dynamic algorithm that combines both hardcoding and <b>table-driven</b> is introduced...|$|E
30|$|Hybrid method: This {{method is}} a {{combination}} of the <b>table-driven</b> and demand-driven methods. An example is ZRP [20].|$|E
40|$|The paper {{describes}} the performance comparison of software implementations of CRC computation algorithms. Graphical {{results of a}} computer experiment on supercomputer cluster to determine the speed of CRC 32 software implementation were described. It is shown that a high-speed four-byte matrixdriven algorithm {{should be used in}} embedded systems and industrial data transmission systems. Research of the matrix-driven algorithms acceleration of relative <b>table-driven</b> shows that even two-bytes matrix-driven algorithm ahead of ~ 29 %, while the four-bytes - by ~ 54 %, which is a significant increasing in speed with respect to the <b>table-driven</b> algorithm...|$|E
