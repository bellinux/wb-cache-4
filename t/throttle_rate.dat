2|74|Public
40|$|A simple dynamic {{engine model}} was {{developed}} at the NASA Ames Research Center, Dryden Flight Research Facility, for use in thrust vectoring control law development and real-time aircraft simulation. The simple dynamic engine model of the F 404 -GE- 400 engine (General Electric, Lynn, Massachusetts) operates within the aircraft simulator. It was developed using tabular data generated from a complete nonlinear dynamic engine model supplied by the manufacturer. Engine dynamics were simulated using a <b>throttle</b> <b>rate</b> limiter and low-pass filter. Included is {{a description of a}} method to account for axial thrust loss resulting from thrust vectoring. In addition, the development of the simple dynamic engine model and its incorporation into the F- 18 high alpha research vehicle (HARV) thrust vectoring simulation. The simple dynamic engine model was evaluated at Mach 0. 2, 35, 000 ft altitude and at Mach 0. 7, 35, 000 ft altitude. The simple dynamic engine model is within 3 percent of the steady state response, and within 25 percent of the transient response of the complete nonlinear dynamic engine model...|$|E
40|$|The T‐ 38 Talon {{aircraft}} is used at NASA 2 ̆ 7 s (National Aeronautics and Space Administration) Johnson Space Center as a supersonic jet trainer for the astronauts, {{as well as}} a {{chase plane}} in both launches and research missions. The PEDRO (Permanent Engine Data Recording Object) system has been installed on the aircraft to record and detect engine abnormalities during flight operations. To expand PEDRO 2 ̆ 7 s data collection, PACO (Power Adjustment Capturing Object), a throttle position sensing system, has been developed. This system will provide insight to flameout analysis, allow for easier troubleshooting with afterburner lights, verify project engine feed and eliminate the need for video recording. The designed system identifies the five standard throttle positions within a 0. 5 degree precision, provides a timestamp correlated with the PEDRO system, and identifies the <b>throttle</b> <b>rate</b> of change and direction. A hazard analysis was performed on the PACO flight system and all hazards were identified and corrective actions were taken to reduce the hazard risks. This system has been through the standard NASA‐Aircraft Operations Division reviews and has been approved for flight testing. At the completion of flight testing, PACO will be installed in all PEDRO jets during their next maintenance phase...|$|E
40|$|An {{experimental}} {{investigation on}} ignition characteristics with air-throttling in an ethylene-fueled scramjet under flight Ma 6. 5 conditions was conducted. The dynamic process of air-throttling ignition was explored systematically. The influences of throttling parameters, i. e., <b>throttling</b> mass <b>rate</b> and duration, were investigated. When the <b>throttling</b> mass <b>rate</b> was 45 % of the inflow mass rate, ambient ethylene could be ignited reliably. The delay time from ignition to throttling was about 45 – 55  ms. There was a threshold of throttling duration under a certain <b>throttling</b> mass <b>rate.</b> It was shorter than 100  ms when the <b>throttling</b> mass <b>rate</b> was 45 %. While a 45 % <b>throttling</b> mass <b>rate</b> {{would make the}} shock train propagate upstream to the isolator entry in about 10 – 15  ms, four lower <b>throttling</b> mass <b>rates</b> were tested, including 30 %, 25 %, 20 %, and 10 %. All of these <b>throttling</b> mass <b>rates</b> could ignite ethylene. However, combustion performances varied with them. A higher <b>throttling</b> mass <b>rate</b> made more ethylene combust and produced higher wall pressure. Through these experiments, {{some aspects of the}} relationships between ignition, flame stabilization, combustion efficiency, and air-throttling parameters were brought to light. These results could also be a benchmark for CFD validation...|$|R
40|$|The network-on-chip (NoC) is {{a primary}} shared {{resource}} in a chip multiprocessor (CMP) system. As core counts continue to increase and applications become increasingly data-intensive, the network load will also increase, leading to more congestion in the network. This network congestion can degrade system performance if the network load is not appropriately controlled. Prior works have proposed source-throttling congestion control, which limits {{the rate at which}} new network traffic (packets) enters the NoC in order to reduce congestion and improve performance. These prior congestion control mechanisms have shortcomings that significantly limit their performance: either 1) they are not application-aware, but rather throttle all applications equally regardless of applications 2 ̆ 7 sensitivity to latency, or 2) they are not network-load-aware, throttling according to application characteristics but sometimes under- or over-throttling the cores. In this work, we propose Heterogeneous Adaptive Throttling, or HAT, a new source-throttling congestion control mechanism based on two key principles: application-aware throttling and network-load-aware <b>throttling</b> <b>rate</b> adjustment. First, we observe that only network-bandwidth-intensive applications(those which use the network most heavily) should be throttled, allowing the other latency-sensitive applications to make faster progress without as much interference. Second, we observe that the <b>throttling</b> <b>rate</b> which yields the best performance varies between workloads, a single, static, <b>throttling</b> <b>rate</b> under-throttles some workloads while over-throttling others. Hence, the throttling mechanism should observe network load dynamically and adjust its <b>throttling</b> <b>rate</b> accordingly. While some past works have also used a closed-loop control approach, none have been application-aware. HAT is the first mechanism to combine application-awareness and network-load-aware <b>throttling</b> <b>rate</b> adjustment to address congestion in a NoC. We evaluate HAT using- a wide variety of multiprogrammed workloads on several NoC-based CMP systems with 16 -, 64 -, and 144 -cores and compare its performance to two state-of-the-art congestion control mechanisms. Our evaluations show that HAT consistently provides higher system performance and fairness than prior congestion control mechanisms...|$|R
40|$|To enhance smooth {{throttle}} {{movement and}} maintain a special driving speed over various orchard road conditions, improve walking stability, we design the fuzzy controller to adjust the <b>throttle</b> open <b>rate.</b> According to the experimental data curve of <b>throttle</b> open <b>rate</b> and driving wheel speed on low-load test, speed sensor mounted on driving wheel to feedback the speed data converted to <b>throttle</b> open <b>rate.</b> Due to the picking mobile robot has no speed shift, {{it is essential to}} change the driving speed by the <b>throttle</b> open <b>rate.</b> In the end, picking mobile robot driving test verify the fuzzy controller the validity corresponding to specified values of driving wheel speed, and show that the behaviour of the picking mobile robot adapt to driving incidences, increasing the stability of the driving. Zhiyong Zhang, Dongjian He Tien-Fu Lu and Tommie. lidd...|$|R
50|$|Bandwidth {{throttling}} {{works by}} limiting (<b>throttling)</b> the <b>rate</b> {{at which a}} bandwidth intensive device (a server) accepts data. If this limit is not in place, the device can overload its processing capacity.|$|R
40|$|In Optical Burst Switched networks, each {{light path}} carry {{huge amount of}} traffic, path {{failures}} may damage the user application. Hence fault-tolerance becomes an important issue on these networks. Blocking probability is a key index of quality of service in Optical Burst Switched (OBS) network. The Erlang formula has been used extensively in the traffic engineering of optical communication to calculate the blocking probability. A combined preventive/reactive control scheme improves the condition of packet loss due to congestion in networks. The transmission delay and the <b>throttling</b> <b>rate</b> are the major parameters which affect {{the performance of the}} reactive control. High <b>throttling</b> <b>rates</b> are most efficient for fast congestion recovery, although sometimes resulting in underutilization of the link. A combined reactive/preventive congestion control mechanism is investigated in this paper with emphasis on the Leaky Bucket (LB) mechanism chosen for source traffic policing in computer networks. The fluid-flow model is used to analyze the performance of both buffered and un-buffered LBs. It is proposed that one LB is not sufficient to manage all the source traffic parameters. If tight control, fast reaction time and a small queuing delay are required then according to the analysis done, the proposed triple LB mechanism is an effective solution. According to the delayed congestion feedback information received from the network the LB parameters are dynamically changed. The preventive control policy is compared with the adaptive control scheme. The results show that even for large propagation delays, major performance improvements are possible by using an appropriate feedback policy...|$|R
40|$|The {{process of}} stall {{inception}} in axial compressors {{has been studied}} by using time and space resolved measurements. As predicted by an existing model, rotating stall is found to evolve from a pre-existing small amplitude travelling wave, which grows exponentially into a stall cell pattern. The stability of the compressor {{is equivalent to the}} stability of these pre-stall waves. One three stage and one single stage low speed compressors were investigated during the study. On both, stall transients were performed at different <b>throttle</b> <b>rates,</b> with and without inlet distortion. Each time, a period of small amplitude wave propagation is observed, with a travelling speed of approximately 30 % of rotor speed. This wave evolves into a stall cell without discontinuity in amplitude or angular position, showing that pre-stall travelling waves and stall cells are two stages of the same phenomenon. The wave was present through the whole single stage compressor, but was clearest immediately upstream of the inlet guide vanes. The damping of the small amplitude wave wa...|$|R
40|$|Abstract — Rate {{control is}} an {{automated}} defense {{to slow down}} a worm outbreak to buy time for conventional defenses to take effect. In this study, we apply the community of households model from biological epidemiology to evaluate rate control strategies. We find that <b>rate</b> <b>throttling</b> of outbound worm traffic, implemented in the network or hosts, can be effective in slowing down a new worm outbreak given sufficient coverage of hosts. An outbreak is slowed down exponentially as the fraction of protected hosts is increased. We also find that throttling both inbound and outbound traffic can be much more effective than <b>rate</b> <b>throttling</b> only outbound traffic. I...|$|R
50|$|Vehicle-to-grid (V2G) {{describes}} {{a system in}} which plug-in electric vehicles, such as electric cars (BEV) and plug-in hybrids (PHEV), communicate with the power grid to sell demand response services by either returning electricity to the grid or by <b>throttling</b> their charging <b>rate.</b>|$|R
40|$|Abstract- Resilient Packet Ring (RPR) {{is being}} devised {{as part of}} IEEE 802. 17 standard, where {{fairness}} in bandwidth allocation among ring nodes, efficiency in resource utilization, and a low computational complexity are the main requirements. Although recent efforts have improved {{the performance of the}} RPR fairness algorithms to have acceptable steady-state behavior, we demonstrate that current algorithms suffer from extreme unfairness and throughput loss in some dynamic traffic scenarios. In this paper 1, we address the bandwidth management in RPR. First, we propose a general fairness model for packet rings. Then, a new algorithm for bandwidth management in RPR called Virtual Queuing (VQ) is introduced. We study the fairness properties of VQ algorithm both analytically and with simulation results. Compared to the RPR standard fairness algorithms that suffer from a throughput loss of up to 28 % in some cases, the throughput loss with VQ is less than 2 %. Comparing to another algorithm, called Distributed Virtual-time Scheduling in Rings (DVSR), VQ has a lower computational complexity and a better performance in a dynamic traffic environment. We show that the average <b>throttled</b> <b>rate</b> of the head node in a congestion span can be up to 80 % for DVSR. With VQ, it is less than 4 % in all cases. I...|$|R
30|$|Burst errors {{refer to}} a {{contiguous}} sequence of erroneous bits, which are caused by persistent channel problems, such as prolonged interference, long fading events, handovers and disconnections often due to user mobility, and correlated packet losses are experienced. Consequently, TCP congestion control <b>throttles</b> its sending <b>rate</b> and reduces significantly its throughput.|$|R
50|$|Specific thrust has {{significant}} bearing on thrust lapse rate: the low jet velocity {{associated with a}} low specific thrust engine implies that there are large reductions in net thrust with increasing flight velocity, {{which can only be}} partially offset by <b>throttle</b> changes at <b>rated</b> conditions (e.g. maximum recommended climb rating).|$|R
50|$|If, as {{he opened}} his engine’s <b>throttle,</b> the <b>rate</b> of {{increase}} of the “chug chug” sound was {{out of sync with}} the forward progress of his locomotive, he knew his wheels were slipping. A passenger locomotive with 72 in drivers would travel 19 ft (over 6 yd) per “chug-chug”. It was therefore easy to correlate the rhythmic sound of the exhaust of a starting locomotive with the locomotive’s progress from a standing start. An engineer could thereby avoid applying too much power to a starting locomotive (by opening the steam throttle valve too much, and too quickly) and causing the wheels to slip.|$|R
40|$|Pervasive {{smart meters}} that {{continuously}} measure power usage by consumers within a smart (power) grid are providing utilities and power systems researchers with unprecedented volumes of information through streams {{that need to}} be processed and analyzed in near realtime. We introduce the use of Cloud platforms to perform scalable, latency sensitive stream processing for eEngineering applications in the smart grid domain. One unique aspect of our work is the use of adaptive <b>rate</b> control to <b>throttle</b> the <b>rate</b> of generation of power events by smart meters, which meets accuracy requirements of smart grid applications while consuming 50 % lesser bandwidth resources in the Cloud...|$|R
5000|$|A {{problem that}} webmasters have often noted with the Googlebot {{is that it}} takes up an {{enormous}} amount of bandwidth. This can cause websites to exceed their bandwidth limit and be taken down temporarily. This is especially troublesome for mirror sites which host many gigabytes of data. Google provides [...] "Webmaster Tools" [...] that allow website owners to <b>throttle</b> the crawl <b>rate.</b>|$|R
25|$|BITS {{provides}} API {{access to}} control jobs. A job can be programmatically started, stopped, paused, resumed, and queried for status. Before starting a job, a priority {{has to be}} set for it to specify when the job is processed relative to other jobs in the transfer queue. By default, all jobs are of Normal priority. Jobs can optionally be set to High, Low, or Foreground priority. Background transfers are optimized by BITS, which increases and decreases (or <b>throttles)</b> the <b>rate</b> of transfer based {{on the amount of}} idle network bandwidth that is available. If a network application begins to consume more bandwidth, BITS decreases its transfer rate to preserve the user's interactive experience, except for Foreground priority downloads.|$|R
40|$|Currently, a TCP sender {{considers}} all losses as congestion {{signals and}} reacts {{to them by}} <b>throttling</b> the sending <b>rate.</b> With Internet becoming more heterogeneous with wireless error-prone links, a TCP connection may unduly <b>throttle</b> its sending <b>rate</b> and experience a poor performance over non congested paths. A closed form expression is developed for the expected improvement of TCP throughput if TCP can differentiate congestion losses and react appropriately. Differentiated Services (Diffserv) offer a new opportunity to enable a TCP sender to identify accurately wireless losses and react appropriately. A technique based on Diffserv is proposed to accurately differentiate congestion losses from other types of losses. This technique {{is supported by a}} simple probablistic argument and evaluated through simulations. Congestion losses are identified with an accuracy of 95 %. Wireless losses are identified with an accuracy higher than 70 %. We propose TCP-Casablanca which is TCP-Newreno endowed with our discriminator. With TCP-Casablanca, an improvement of up to 150 % is observed on paths lightly congested with mild wireless error rates...|$|R
40|$|Abstract—A call {{admission}} control scheme named thinning scheme, which smoothly <b>throttles</b> the admission <b>rates</b> of calls {{according to their}} priorities and aims to provide multiple prioritized traffic with a desired quality of service, is investigated under more general conditions. Using the theory of multidimensional Markov birth-death process, analytical formulas for call blocking probabilities are derived. Index Terms—Call {{admission control}} (CAC), multimedia, blocking probability, quality of service (QoS), wireless networks, multidimensional Markov birth-death process. ...|$|R
50|$|A {{bandwidth}} intensive device, {{such as a}} server, might limit, or <b>throttle,</b> the <b>rate</b> {{at which}} it accepts data, {{in order to avoid}} overloading its processing capacity. This can be done both at the local network servers or at the ISP servers. ISPs often employ deep packet inspection (DPI), which is widely available in routers or provided by special DPI equipment. Additionally, today’s networking equipment allows ISPs to collect statistics on ﬂow sizes at line speed, which can be used to mark large ﬂows for traffic shaping. Two ISPs, Cox and Comcast, have stated that they engage in this practice, where they limit users' bandwidth by up to 99%. Today most if not all Internet Service Providers throttle their users' bandwidth, with or without the user ever even realizing it. In the specific case of Comcast, an equipment vendor called Sandvine developed the network management technology that throttled P2P file transfers.|$|R
40|$|This paper {{presents}} a rate-based controller for <b>throttling</b> available bit <b>rate</b> (ABR) input rates in high speed {{asynchronous transfer mode}} (ATM) networks with significant propagation delays. First, a Smith predictor based controller is analyzed in terms of performance and stability. Saturation issues are handled with anti-windup techniques. Performance is improved {{by means of the}} feedback of an estimate of the ABR disturbance. This reduces the average queue level, guaranteeing the shortest delays possible while keeping the channel fully occupied. Finally, sensitivity to delay estimation errors is analyzed, and the limitations of th...|$|R
5000|$|Asynchronous {{start-stop}} is {{the physical}} layer used to connect computers to modems for many dial-up Internet access applications, using a data link [...] framing protocol such as PPP to create [...] packets made {{up out of}} asynchronous serial characters. The performance loss relative to synchronous access is negligible, as most modern modems will use a private synchronous protocol to send the data between themselves, and the asynchronous links at each end are operated faster than this data link, with flow control being used to <b>throttle</b> the data <b>rate</b> to prevent overrun.|$|R
40|$|Abstract-Data burst contentions {{occur in}} optical burstswitched (OBS) {{networks}} due to one-way signaling and bufferless natu~e {{of the core}} network. A single burst loss containing multIple TCP segments can trigger drastic reactions from the corresponding TCP sources. TCP sender interprets segment loss as network congestion, resulting in <b>throttling</b> send <b>rate.</b> In this paper, we propose a new forward segment redundancy (FSR) mechanism that minimizes segment loss during burst contentions in the core and also recovers from segment loss in the forward direction using redundant segments placed in each data burst. In FSR mechanism, redundant TCP segments are added to each burst assembled at the ingress node before transmission to the destination. The segment losses due to contentions are minimized using a modified burst segmentation mechanism, and most lost segments are recovered in the forward direction using redundant segments. Using FSR, we observe significant improvement in TCP performance over OBS networks. 1 Keywords: Loss Recovery, TCP, and OBS. I...|$|R
40|$|Currently, a TCP sender {{considers}} all losses as congestion {{signals and}} reacts {{to them by}} <b>throttling</b> its sending <b>rate.</b> With Internet becoming more heterogeneous {{with more and more}} wireless error-prone links, a TCP connection may unduly <b>throttle</b> its sending <b>rate</b> and experience poor performance over paths experiencing random losses unrelated to congestion. The problem of distinguishing congestion losses from random losses is particularly hard when congestion is light: congestion losses themselves appear to be random. The key idea is to “de-randomize ” congestion losses. This paper proposes a simple biased queue management scheme that “de-randomizes ” congestion losses and enables a TCP receiver to diagnose accurately the cause of a loss and inform the TCP sender to react appropriately. Bounds on the accuracy of distinguishing wireless losses and congestion losses are analytically established and validated through simulations. Congestion losses are identified with an accuracy higher than 95 % while wireless losses are identified with an accuracy higher than 75 %. A closed form is derived for the achievable improvement by TCP endowed with a discriminator with a given accuracy. Simulations confirm this closed form. TCP-Casablanca, a TCP-Newreno endowed with the proposed discriminator at the receiver, yields through simulations an improvement of more than 100 % on paths with low levels of congestion and about 1 % random wireless packet loss rates. TCP-Ifrane, a sender-based TCP-Casablanca yields encouraging performance improvement. ...|$|R
40|$|Abstract — We {{present a}} worm {{simulator}} {{which can be}} run remotely through the web, based on the parameters supplied by the client. The core simulator program executes on the server and simulates {{the flow of the}} worm through a user-specified topology. The results of the simulation are then graphically displayed to the client. A variety of worm vectors can be simulated and various countermeasures such as <b>rate</b> <b>throttling</b> and quarantining can also be employed. The simulator uses a design that is efficient in terms of speed and memory requirements, while providing a lot of features for realistic simulations. I...|$|R
40|$|Currently {{there is}} no control for {{real-time}} traffic sources in IP networks. This {{is a serious problem}} because real-time traffic can not only congest the network but can also cause unfairness and starvation of TCP traffic. However, {{it is not possible to}} apply current solutions for Internet to the networks with high bandwidth-delay products and high bit error rates. The channel errors may result in inaccurate congestion control decisions and unnecessary <b>rate</b> <b>throttles</b> leading to severe performance degradation. This problem is amplified in the links with high bandwidth-delay products, since the link is inefficiently utilized for a very long time until the unnecessary <b>rate</b> <b>throttle</b> is recovered. In this paper, a new Rate Control Scheme, RCS, is introduced for real-time interactive applications in networks with high bandwidth-delay products and high bit error rates. RCS is based on the concept of using dummy packets to probe the availability of network resources. Dummy packets are treated as low priority packets and consequently they do not affect the throughput of actual data traffic. Therefore, RCS requires all the routers in the connection path to support some priority policy. A new algorithm is also proposed to improve the robustness of the RCS to temporal signal loss conditions. The delay-bound considerations for real-time traffic sources using RCS rate control scheme are also investigated. Simulation experiments show that in environments with high bandwidth-delay products and high bit error rates, RCS achieves high throughput performance without penalizing TCP connections...|$|R
40|$|We are {{developing}} a next-generation power manager that supports high performance within the constraints of limited power, energy, and temperature levels. To date, we have developed simulation infrastructure to model a technology-scaled version of an Alpha 21364 processor and have added three independent management techniques to the simulator model. One technique dynamically scales frequency and voltage settings. Another technique, pipeline <b>throttling,</b> restricts the <b>rate</b> of integer instruction issue. The third technique reduces leakage power in caches while retaining memory contents. We are currently using the simulation infrastructure to gauge the effect of management techniques. This report {{provides an overview of}} our research project and summarizes the current status of this work. ...|$|R
40|$|Abstract:- Pumps {{are used}} {{in a variety of}} {{important}} applications. Often, the pipe characteristic is unsatisfactory known and the selected pump has more power than needed. It will thus be throttled or the flow is throttled during operation. In such cases the pump operates under part-load flow and the inflow condition differs from the dimensioning point. In this paper results for an impeller blade designed using a single arc of a circle are presented. The pump characteristic curve shows energy transmission and losses. For the investigation of the flow in the impeller Time-resolved Particle Image Velocimetry (TR-PIV) is used. Using TR-PIV it is possible to visualise the vortices in the stall regime. The results have been obtained at different operating points. It is possible to observe different stages of the developing rotating stall. The first vortices are observed at a <b>throttled</b> flow <b>rate</b> of 50 % of the design point. They exist only in two channels of the impeller. The first rotations of the stall cell through the impeller are observed at flow rates smaller than 40 % of the design point. These velocity fields are further post-processed to analyze the possible development of the rotating stall cell...|$|R
50|$|Demand {{response}} {{is a change}} in the power consumption of an electric utility customer to better match the demand for power with the supply. Electric energy cannot be easily stored, so utilities have traditionally matched demand and supply by <b>throttling</b> the production <b>rate</b> of their power plants, taking generating units on or off line, or importing power from other utilities. There are limits to what can be achieved on the supply side, because some generating units can {{take a long time to}} come up to full power, some units may be very expensive to operate, and demand can at times be greater than the capacity of all the available power plants put together. Demand response seeks to adjust the demand for power instead of adjusting the supply.|$|R
40|$|This paper {{develops}} a protocol, Performance Adaptive UDP (henceforth PA-UDP),which aims to dynamically and autonomously maximize performance under different systems. A mathematical model and related algorithms are proposed {{to describe the}} theoretical basis behind effective buffer and CPU management. A novel delay-based <b>rate</b> <b>throttling</b> model is also demonstrated to be very accurate under diverse system latencies. Based on these models, we implemented prototype under Linux, and the experimental results demonstrate that PA-UDP outperforms other existing high-speed protocols on commodity hardware in terms of throughput, packet loss, and CPU utilization. PA-UDP is efficient not only for high-speed research networks, but also for reliable high-performance bulk data transfer over dedicated local area networks where congestion and fairness are typically not a concern...|$|R
50|$|The {{weight and}} cost of power supply and cooling systems {{generally}} depends on the maximum possible power {{that could be used}} at some instant.There are two ways to prevent a system from being permanently damaged by excessive heat.Most desktop computers design power and cooling systems around the worst-case CPU power dissipation at the maximum frequency, maximum workload, and worst-case environment.To reduce weight and cost, many laptop computers systems choose to use a much lighter, lower-cost cooling system designed around a much lower Thermal Design Power, that is somewhat above expected maximum frequency, typical workload, and typical environment.Typically such systems reduce (<b>throttle)</b> the clock <b>rate</b> when the CPU die temperature gets too hot, reducing the power dissipated to a level that the cooling system can handle.|$|R
50|$|BITS uses a queue {{to manage}} file transfers. A BITS session {{has to be}} started from an {{application}} by creating a Job. A job is a container, which has one or more files to transfer. A newly created job is empty. Files must be added, specifying both the source and destination URIs. While a download job can have any number of files, upload jobs can have only one. Properties can be set for individual files. Jobs inherit the security context of the application that creates them.BITS provides API access to control jobs. A job can be programmatically started, stopped, paused, resumed, and queried for status. Before starting a job, a priority has to be set for it to specify when the job is processed relative to other jobs in the transfer queue. By default, all jobs are of Normal priority. Jobs can optionally be set to High, Low, or Foreground priority. Background transfers are optimized by BITS, which increases and decreases (or <b>throttles)</b> the <b>rate</b> of transfer based {{on the amount of}} idle network bandwidth that is available. If a network application begins to consume more bandwidth, BITS decreases its transfer rate to preserve the user's interactive experience, except for Foreground priority downloads.|$|R
40|$|Software {{transactional}} memory (STM) enhances both ease-of-use and concurrency, and {{is considered}} one of the next-generation paradigms for parallel programming. Application programs may see hotspots where data conflicts are intensive and seriously degrade the performance. So advanced STM systems employ dynamic concurrency control techniques to curb the conflict <b>rate</b> through properly <b>throttling</b> the <b>rate</b> of spawning transactions. High-end computers may have two or more multicore processors so that data sharing among cores goes through a non-uniform cache memory hierarchy. This poses challenges to concurrency control designs as improper metadata placement and sharing will introduce scalability issues to the system. Poor thread-to-core mappings that induce excessive cache invalidation are also detrimental to the overall performance. In this paper, we share our experience in designing and implementing a new dynamic concurrency controller for Tiny STM, which helps keeping the system concurrency at a near-optimal level. By decoupling unfavourable metadata sharing, our controller design avoids costly inter-processor communications. It also features an affinity-aware thread migration technique that fine-tunes thread placements by observing inter-thread transactional conflicts. We evaluate our implementation using the STAMP benchmark suite and show that the controller can bring around 21 % average speedup over the baseline execution. © 2015 IEEE. postprin...|$|R
40|$|Abstract—In a {{dual fuel}} engine, two fuels are used simultaneously. The primary fuel is usually gaseous forms the major {{content of the}} total energy {{supplied}} to the engine. The secondary fuel, i. e., pilot fuel, is injected after compression of the primary fuel air mixture. Much of the energy release comes from the combustion of the gaseous fuel and {{a small amount of}} diesel fuel provides ignition through timed cylinder injection. In the present work, single-cylinder, compression ignition, direct injection diesel engine has been used for the investigations of exhaust emissions when the engine is operating as a dual-fuel engine using diesel as pilot fuel and Liquefied Petroleum Gas (LPG) as secondary fuel. The influence of major engine operating parameters, such as the pilot fuel quantity, intake air temperature, Exhaust Gas Recirculation (EGR), intake air <b>throttling</b> and <b>rate</b> of injection on the exhaust emissions was investigated. Diesel fuel was used as the pilot fuel, while LPG was used as the main fuel which was inducted in the intake manifold. The experimental investigations showed that the poor exhaust emissions at light loads can be improved by employing larger pilot fuel quantity, using EGR, increasing intake temperature and well adjusted rate of injection...|$|R
40|$|As {{the number}} of core {{integration}} on a single die grows, buffers consume significant energy, and occupy chip area. A bufferless deflection outing that eliminates router’s input port buffers can considerably help saving energy and chip area while providing similar performance of xisting buffered routing, especially for low-to-medium network loads. However when congestion increases, the bufferless frequently causes flits deflections, and misrouting leading to a degradation of network performance. In this paper, we propose IRT(Injection <b>Rate</b> <b>Throttling),</b> a ocal throttling mechanism that reduces deflection and misrouting for high-load bufferless networks. IRT provides injection rate control independently for each network node, allowing to reduce network congestion. Our simulation results based on a cycle-accurate simulator show that using IRT, IRT reduces average transmission latency by 8. 65 % compared to traditional bufferless routing...|$|R
40|$|Abstract—We {{address the}} problem of {{adaptive}} informationoptimal data collection in time series. Here a remote sensor or explorer agent <b>throttles</b> its sampling <b>rate</b> in order to track anomalous events while obeying constraints on time and power. This problem is challenging because the agent has limited visibility — all collected datapoints lie in the past, but its resource allocation decisions require predicting far into the future. Our solution is to continually fit a Gaussian process model to the latest data and optimize the sampling plan on line to maximize information gain. We compare the performance characteristics of stationary and nonstationary Gaussian process models. We also describe an application based on geologic analysis during planetary rover exploration. Here adaptive sampling can improve coverage of localized anomalies and potentially benefit mission science yield of long autonomous traverses. I...|$|R
