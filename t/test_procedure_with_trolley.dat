0|10000|Public
50|$|A 2012-page on a Caucho {{wiki site}} {{describes}} a <b>test</b> <b>procedure</b> <b>with</b> results showing that tested 0k (empty HTML page), 1K, 8K and 64K byte files. At every level Resin matched or exceeded nginx web server performance.|$|R
40|$|We {{consider}} {{hypothesis testing}} problems arising in e. g. {{the context of}} comparing k treatments with a control. The case of equi-correlated estimates is mainly discussed, although also unequal correlated estimates (e. g. unequal sample sizes for the treatments, when compared to a control treatment) are mentioned briefly. So called step down <b>test</b> <b>procedures</b> are compared <b>with</b> step up <b>test</b> <b>procedures,</b> <b>with</b> respect to power functions. Comparisons of rejected null hypotheses are also performed. No practical differences in performances between step up and step down <b>test</b> <b>procedures</b> could be found for finite sample sizes...|$|R
50|$|The Holm-Bonferroni method can {{be viewed}} as closed <b>testing</b> <b>procedure,</b> <b>with</b> Bonferroni method applied locally on each of the intersections of null hypotheses.As such, it {{controls}} the familywise error rate for all the k hypotheses at level α in the strong sense. Each intersection is tested using the simple Bonferroni test.|$|R
40|$|In {{this paper}} we compare {{forecasting}} performance of hypothesis <b>testing</b> <b>procedures</b> <b>with</b> a model combining algorithm called AFTER. <b>Testing</b> <b>procedures</b> {{are commonly used}} in practice to select a model based on which forecasts are made. However, besides the well-known difficulty in dealing with multiple tests, the testing approach has a potentially serious drawback: controlling the probability of Type I error can excessively favor the null, which can be problematic {{for the purpose of}} forecasting...|$|R
40|$|O 2 ̆ 7 Brien and Fleming (1979) {{proposed}} a straightforward and useful multiple <b>testing</b> <b>procedure</b> (group sequential <b>testing</b> <b>procedure)</b> for comparing two treatments {{in clinical trials}} where subject responses are dichotomous (e. g. success and failure). O 2 ̆ 7 Brien and Fleming stated that their group sequential <b>testing</b> <b>procedure</b> has the same Type I error rate and power {{as that of a}} fixed one-stage chi-square test, but gives the opportunity to terminate the trial early when one treatment is clearly performing better than the other. We studied and tested the O 2 ̆ 7 Brien and Fleming procedure specifically by correcting the originally proposed critical values. Furthermore, we updated the O’Brien Fleming Group Sequential <b>Testing</b> <b>procedure</b> to make it more flexible via three extensions. The first extension is combining the O’Brien Fleming Group Sequential <b>Testing</b> <b>procedure</b> <b>with</b> the Optimal allocation, where the idea is to allocate more patients to the better treatment after each interim analysis. The second extension is combining the O’Brien Fleming Group Sequential <b>Testing</b> <b>procedure</b> <b>with</b> the Neyman allocation which aims to minimize the variance of the difference in sample proportions. The last extension is that we can allow for different sample weights for different stages, as opposed to equal allocation for different stages. Simulation studies showed that the O’Brien Fleming Group Sequential <b>Testing</b> <b>procedure</b> is relatively robust to the added features...|$|R
40|$|In {{this article}} we {{introduce}} and evaluate <b>testing</b> <b>procedures</b> for specifying the number k of nearest neighbours in the weights matrix of spatial econometric models. The spatial J-test is used for specification search. Two <b>testing</b> <b>procedures</b> are suggested: an increasing neighbours <b>testing</b> <b>procedure</b> and a decreasing neighbours <b>testing</b> <b>procedure.</b> Simulations show that the increasing neighbours <b>testing</b> <b>procedures</b> {{can be used in}} large samples to determine k. The decreasing neighbours <b>testing</b> <b>procedure</b> is found to have low power, and is not recommended for use in practice. An empirical example involving house price data is provided to show how to use the <b>testing</b> <b>procedures</b> <b>with</b> real data. k-nearest neighbours; model specification; spatial j-test; weights matrix...|$|R
40|$|The {{purpose of}} this study is to {{introduce}} the methods of the deconvolution and to programme some of them. For the simulation, the tissue homogeneity model and the model of arterial input fiction were used. These models were engaged as the <b>test</b> <b>procedures</b> <b>with</b> the aim of verify the functionality and utility of the Wiener filter, the Lucy-Richardson algorithm and the Singular value decomposition...|$|R
40|$|Alvo and Cabilio [Alvo, M., Cabilio, P., 1995 b. Testing ordered {{alternatives}} in {{the presence}} of incomplete data. J. Amer. Statist. Assoc. 90, 1015 - 1024] extended the Page and Jonckheere tests when randomized blocks are incomplete. Here we use the step-down <b>testing</b> <b>procedure</b> of Marcus etÂ al. Â [Marcus, R., Peritz, E., Gabriel, K. R., 1976. On closed <b>testing</b> <b>procedures</b> <b>with</b> special reference to ordered analysis of variance. Biometrika 63, 655 - 660] to identify which treatments differ, and illustrate the method by an example. ...|$|R
50|$|Lau, C. A. (1996). Robustness of a unidimensional {{computerized}} <b>testing</b> mastery <b>procedure</b> <b>with</b> multidimensional <b>testing</b> data. Unpublished doctoral dissertation, University of Iowa, Iowa City IA.|$|R
40|$|In general, Wald {{tests for}} the Granger non-causality in vector autoregressive (VAR) process {{are known to}} have {{non-standard}} asymptotic properties for cointegrated systems. However, that may have standard asymptotic properties depending on the rank of the submatrix of cointegration. In this paper, we propose a procedure for conducting Granger non-causality tests that are based on discrimination of these asymptotic properties. This paper also investigate the finite sample performance of our <b>testing</b> <b>procedure,</b> and compare the <b>testing</b> <b>procedure</b> <b>with</b> conventional causality <b>tests</b> in levels VARfs. Vector autoregression, Cointegration, Granger causality, Hypothesis testing...|$|R
40|$|In {{this paper}} we {{systematically}} compare forecasting accuracy of hypothesis <b>testing</b> <b>procedures</b> <b>with</b> {{that of a}} model combining algorithm. <b>Testing</b> <b>procedures</b> are commonly used in applications to select a model, based on which forecasts are made. However, besides the well-known difficulty in dealing with multiple tests, the testing approach has a potentially serious drawback: controlling the probability of Type I error at a conventional level (e. g., 0. 05) often excessively favors the null, which can be problematic {{for the purpose of}} forecasting. In addition, as shown in this paper, <b>testing</b> <b>procedures</b> can be very unstable, which results in high variability in the forecasts. ...|$|R
40|$|We {{present a}} unifying {{approach}} to multiple <b>testing</b> <b>procedures</b> for sequential (or streaming) data by giving sufficient {{conditions for a}} sequential multiple <b>testing</b> <b>procedure</b> to control the familywise error rate (FWER), extending to the sequential domain the work of Goeman and Solari (2010) who accomplished this for fixed sample size procedures. Together we call these conditions the "rejection principle for sequential tests," which we then apply to some existing sequential multiple <b>testing</b> <b>procedures</b> to give simplified understanding of their FWER control. Next the principle is applied to derive two new sequential multiple <b>testing</b> <b>procedures</b> <b>with</b> provable FWER control, one for testing hypotheses in order and another for closed testing. Examples of these new procedures are given by applying them to a chromosome aberration data set and to finding the maximum safe dose of a treatment...|$|R
40|$|The initial {{version of}} the paper was {{circulated}} as "The Granger Non-Causality Test in Possibly Cointegrated Systems". In general, Wald tests for the Granger non-causality in vector autoregressive (VAR) process {{are known to have}} non-standard asymptotic properties for cointegrated systems. However, that may have standard asymptotic properties depending on the rank of the submatrix of cointegration. In this paper, we propose a procedure for conducting Granger non-causality tests that are based on discrimination of these asymptotic properties. This paper also investigate the finite sample performance of our <b>testing</b> <b>procedure,</b> and compare the <b>testing</b> <b>procedure</b> <b>with</b> conventional causality <b>tests</b> in levels VAR's. 21 世紀COEプログラム = 21 st-Century COE Progra...|$|R
40|$|ABSTRACT. We {{present a}} unifying {{approach}} to multiple <b>testing</b> <b>procedures</b> for sequential (or streaming) data by giving sufficient {{conditions for a}} sequential multiple <b>testing</b> <b>procedure</b> to control the familywise error rate (FWER). Together, we call these conditions a ‘rejection principle for sequential tests’, which we then apply to some existing sequential multiple <b>testing</b> <b>procedures</b> to give simplified understanding of their FWER control. Next, the principle is applied to derive two new sequential multiple <b>testing</b> <b>procedures</b> <b>with</b> provable FWER control, one for testing hypotheses in order and another for closed testing. Examples of these new procedures are given by applying them to a chromosome aberration data set and finding the maximum safe dose of a treatment. Key words: closed testing, multiple comparisons, multiple testing, sequential analysis, sequential hypothesis testing, streaming data, testing in order 1. Introduction an...|$|R
40|$|Hommel's and Hochberg's {{procedures}} for familywise error control are both derived as shortcuts {{in a closed}} <b>testing</b> <b>procedure</b> <b>with</b> the Simes local test. Hommel's shortcut is exact but takes quadratic time {{in the number of}} hypotheses. Hochberg's shortcut takes only linearithmic time, but is conservative. In this paper we present an exact shortcut in linearithmic time, combining the strengths of both procedures. The novel shortcut also applies to a robust variant of Hommel's procedure that does not require the assumption of the Simes inequality. Comment: arXiv admin note: text overlap with arXiv: 1611. 0673...|$|R
40|$|Determination {{of dynamic}} {{characteristics}} of constructions is now demanded by GOST R 53778 - 2010. It {{is a very}} important step to achieve safety of constructions. But GOST requirements do not pay attention to peculiarities of <b>test</b> <b>procedures</b> <b>with</b> unique objects. The comparative results of tests and analysis of dynamic characteristics of the constructions of Kroonstad Naval Cathedral being obtained during 2005 – 2009 are represented. It was established that some definite changes resulting in loss of spatial rigidness of the whole building occurred in condition of Cathedral constructions...|$|R
40|$|In this paper, we have {{obtained}} confidence sequences using Chow's generalization of Hájek-Rényi inequality {{and the law}} of iterated logarithm for the autoregressive parameter in a stable first order autoregressive model where innovations {{are assumed to be}} independently and identically distributed. A sequential <b>testing</b> <b>procedure</b> <b>with</b> power one has also been proposed. We have also indicated a generalization to confidence sequences for several parameters in a pth order autoregressive model. Darling-Robbins type confidence sequences Tests with power one AR(1) process AR(p) process The law of iterated logarithm Chow-Hájek-Rényi inequality...|$|R
40|$|In this paper, we {{consider}} a nonparametric <b>test</b> <b>procedure</b> for multivariate data with grouped components under the two sample problem setting. For {{the construction of}} the test statistic, we use linear rank statistics which were derived by applying the likelihood ratio principle for each component. For the null distribution of the test statistic, we apply the permutation principle for small or moderate sample sizes and derive the limiting distribution for the large sample case. Also we illustrate our <b>test</b> <b>procedure</b> <b>with</b> an example and compare <b>with</b> other <b>procedures</b> through simulation study. Finally, we discuss some additional interesting features as concluding remarks. grouped data, liner rank statistic, multivariate data, nonparametric test, permutation principle,...|$|R
40|$|This paper {{presents}} analytical, Monte Carlo, {{and empirical}} evidence linking in-sample tests of predictive content and out-of-sample forecast accuracy. Our approach {{focuses on the}} negative effect that finite-sample estimation error has on forecast accuracy {{despite the presence of}} significant population-level predictive content. Specifically, we derive simple-to-use in-sample tests that test not only whether a particular variable has predictive content but also whether this content is estimated precisely enough to improve forecast accuracy. Our tests are asymptotically non-central chi-square or non-central normal. We provide a convenient bootstrap method for computing the relevant critical values. In the Monte Carlo and empirical analysis, we compare the effectiveness of our <b>testing</b> <b>procedure</b> <b>with</b> more common <b>testing</b> <b>procedures.</b> ...|$|R
40|$|We propose 'Dunnett-type' <b>test</b> <b>procedures</b> to <b>test</b> {{for simple}} tree order {{restrictions}} on the means of "p" independent normal populations. The new tests {{are based on the}} estimation procedures that were introduced by Hwang and Peddada and later by Dunbar, Conaway and Peddada. The procedures proposed are also extended to test for 'two-sided' simple tree order restrictions. For non-normal data, nonparametric versions based on ranked data are also suggested. Using computer simulations, we compare the proposed <b>test</b> <b>procedures</b> <b>with</b> some existing <b>test</b> <b>procedures</b> in terms of size and power. Our simulation study suggests that the <b>procedures</b> compete well <b>with</b> the existing <b>procedures</b> for both one-sided and two-sided simple tree alternatives. In some instances, {{especially in the case of}} two-sided alternatives or for non-normally distributed data, the gains in power due to the procedures proposed can be substantial. Copyright 2006 Royal Statistical Society. ...|$|R
40|$|AbstractFor the {{assessment}} of vehicle safety in frontal collisions, the crash compatibility between the colliding vehicles is crucial. Compatibility compromises both the self protection and the partner protection properties of vehicles. Although compatibility has received worldwide attention for many years, no final assessment approach has been defined. Within the FIMCAR project, different frontal impact <b>test</b> <b>procedures</b> are analysed regarding their potential for future frontal impact legislation. The research activities focus on car-to-car frontal impact accidents based on accident investigations involving newer cars. Test <b>procedures</b> were developed <b>with</b> both a crash test programme and numerical simulations. The proposal from FIMCAR {{is to use a}} full width <b>test</b> <b>procedure</b> <b>with</b> deformable element and compatibility metrics in combination with the current ECE R 94 off-set procedure as a frontal impact assessment approach which also addresses compatibility...|$|R
2500|$|It {{was clear}} {{early on that}} a larger {{simulator}} was necessary for <b>testing</b> <b>procedures</b> <b>with</b> Skylab ( [...] diameter by [...] high) and other hardware in the pipeline. [...] It was also clear that its construction would require some creative financing and political maneuvering. [...] In his September 12, 1966 memo to Wernher von Braun, Kuers disclosed, [...] " [...] had apparently been told of our plans regarding the new large neutral buoyancy type simulator, {{and in response to}} his point blank questions regarding this, he was candidly shown the design blueprints by responsible ME personnel. [...] Consequently, Houston is now aware." ...|$|R
40|$|Three latex {{agglutination}} <b>test</b> <b>procedures</b> {{for detecting}} Candida antigen in human serum were compared in a retrospective study of 69 patients and 20 normal volunteers. Untreated human serum was reacted with two different latex reagents; one reagent also was reacted with serum treated with protease and heat. The <b>test</b> <b>procedure</b> <b>with</b> treated serum was best, detecting serum antigen in 17 of 21 patients (81 %) with disseminated candidiasis. Judging by autopsy-proven cases, {{there was an}} increase in positive test results in the last 2 weeks of life. When untreated sera were tested with this reagent, only 3 (14 %) of the 21 patients with disseminated candidiasis had detectable antigen in serum. A subset of these same sera was tested by a commercial latex reagent (Candida Detection System lot C 001; Ramco Laboratories, Inc., Houston, Tex.) and untreated serum. Of 18 patients with disseminated candidiasis, 5 (28 %) had at least one positive serum. Sera from patients with less severe clinical forms of candidiasis were usually negative regardless of the <b>test</b> <b>procedure</b> used. <b>With</b> one exception, sera from control patients were negative or were positive only in sera containing rheumatoid factor. Latex agglutination tests for Candida spp. in treated serum may prove to be a useful procedure for the rapid diagnosis of severe disseminated candidiasis...|$|R
40|$|The {{purpose of}} this {{research}} is two-fold. Firstly, from a practical point of view, {{the development of a new}} computer program for an adaptive <b>testing</b> <b>procedure</b> was necessitated in order to measure the verbal ability more efficiently than the other existing procedures. Secondly, an experiment was designed in order to compare the efficiency of the adaptive <b>testing</b> <b>procedure</b> <b>with</b> that of the conventional <b>testing</b> <b>procedure,</b> analyze the effects of the feedback, investigate the relationship between the verbal ability and the response time, and evaluate the stability of the repeated measurements. With regard to the first purpose, a satisfactory computer program was created. This program automatically controlls the selection of test items during the process of administering the test so that the items administered to each subject should be appropriate in their difficulties. Furthermore, with regard to the second purpose, it was conculded that the results showed the superiority of the adaptive <b>testing</b> <b>procedure</b> over the conventional one in many respects...|$|R
5000|$|Mortars {{used in this}} {{technique}} typically have a compressive strength ranging from at least 400 psi (2.8 MPa) to 1600 psi (11 MPa), when tested using ANSI <b>testing</b> <b>procedures.</b> However, <b>with</b> advancements in technology and materials, the potential strengths of the thick bed mortar system have increased.|$|R
40|$|The {{results of}} two {{different}} series of life tests carried out on vacuum switches with a self-produced axial magnetic field (in view of their use in nuclear fusion facilities) are presented. The goal was to obtain a large number (on the order of 2000) of interruptions of a unidirectional current of over 50 kA, with a recovery voltage of up to 35 kV. A first series of tests showed that the <b>test</b> <b>procedure</b> <b>with</b> an accelerated life test was not adequate; it was also apparent that the contact plate, designed for 50 Hz applications, had weak points when subjected to extended thermal contacts. Therefore, {{a new version of}} the switches, with modified contacts, was built. Both versions of the switches were tested <b>with</b> a new <b>test</b> <b>procedure,</b> and satisfactory <b>test</b> results were obtaine...|$|R
40|$|Abstract: As {{weaponry}} {{technology has}} advanced, the ballistic threat to humans has increased significantly. As {{well as the}} military, civilians who are exposed to these threats {{as part of their}} everyday work require adequate protective equipment. This increasing demand for body armour and ballistic helmets is driving the protective equipment industry to create lightweight, reliable protection adapted for specific applications and marketable {{to a wide range of}} consumers. This chapter focuses on a few theoretical aspects of head impact mechanics and related head injury criteria, considering design, manufacturing and <b>testing</b> <b>procedures,</b> <b>with</b> particular emphasis on the modern materials and tools used in the search for lightweight, cost-efficient and effective equipment...|$|R
40|$|This paper {{examines}} the dynamic behaviour of relative prices across seven Australian cities by applying panel unit root <b>test</b> <b>procedures</b> <b>with</b> structural breaks to quarterly {{consumer price index}} data for 1972 Q 1 – 2011 Q 4. We find overwhelming evidence of convergence in city relative prices. Three common structural breaks are endogenously determined at 1985, 1995, and 2007. Further, correcting for two potential biases, namely Nickell bias and time aggregation bias, we obtain half-life estimates of 2. 3 – 3. 8 quarters that are much shorter than those reported by previous research. Thus, we conclude that both structural breaks and bias corrections are important to obtain shorter half-life estimates...|$|R
40|$|This paper {{tests the}} null {{hypothesis}} of endogenous growth theories which predict cross country differences in trend growth rates against the alternative hypothesis of exogenous growth theories which predict the same trend growth rates. We use the modified <b>test</b> <b>procedure</b> <b>with</b> heterogeneous intercepts allowing different growth rates across economies. We apply the test to 17 Asian countries and NIEs with panel data. Our {{results are consistent with}} neoclassical growth theories which predict the convergence of the 17 Asian countries and NIEs, but which imply that trend growth rates are different across economies. These results support the conditional convergence of the exogenous growth model against the endogenous growth model. ...|$|R
40|$|Side impacts are {{frequent}} and can pose a hazard for children travelling at the struck side in passenger cars. Although {{the number of}} seriously injured children has decreased during the last decades, {{there is still a}} considerable risk especially for head, neck and thorax injuries. ISO/TC 22 /SC 12 /WG 1 (working group on child safety inside passenger cars) has been working on the definition of a side impact <b>test</b> <b>procedure</b> for child restraint systems for a number of years, taking into account other side impact <b>test</b> <b>procedures</b> for CRS (child restraint system) already implemented in some countries. This paper is a comprehensive summary of accident data (from USA and Europe), boundary conditions to be recognised for the definition of a side impact <b>test</b> <b>procedure</b> for CRS (crash worthiness, geometry, etc.) and current side impact <b>test</b> <b>procedures.</b> Special emphasis is given to the design specification for a suitable <b>test</b> <b>procedure</b> <b>with</b> respect to loading conditions and test severity based on full-scale test data. The paper is based on a recent ISO Technical Report, which is a comprehensive base for the future ISO <b>test</b> <b>procedure</b> development...|$|R
40|$|The closed testing {{principle}} {{provides a}} general and simple framework to con-struct powerful multiple <b>test</b> <b>procedures</b> for k elementary null hypotheses while controlling the familywise error {{rate in the}} strong sense. However, the closed testing principle has the disadvantage of leading to the evaluation of O(2 k) inter-section hypotheses. Multiple <b>test</b> <b>procedures</b> based on the closed testing principle may thus require substantial computational efforts. Consonant closed test pro-cedures for unrestricted hypotheses {{have the advantage of}} rejecting at least one elementary null hypothesis whenever the global null hypothesis is rejected and thus admit shortcuts of size k. If the elementary null hypotheses are restricted by logical constraints, the closure of common tests, such as max-t or min-p tests, may not be consonant in the usual sense. In this paper we introduce a weaker consonance property, denoted as local consonance, and show that many closed <b>test</b> <b>procedures</b> <b>with</b> restricted hypotheses satisfy this condition. We describe a general algorithm to construct related shortcuts and illustrate the results with several applications. ...|$|R
40|$|Statistical discoveries {{are often}} {{obtained}} through multiple hypothesis testing. A variety of procedures exists to evaluate multiple hypotheses, for instance the ones of Benjamini-Hochberg, Bonferroni, Holm or Sidak. We are {{particularly interested in}} multiple <b>testing</b> <b>procedures</b> <b>with</b> two desired properties: (solely) monotonic and well-behaved procedures. This article investigates to which extent the classes of (monotonic or well-behaved) multiple <b>testing</b> <b>procedures,</b> in particular the subclasses of so-called step-up and step-down procedures, are closed under basic set operations, specifically the union, intersection, difference and the complement of sets of rejected or non-rejected hypotheses. The present article proves two main results: First, taking the union or intersection of arbitrary (monotonic or well-behaved) multiple <b>testing</b> <b>procedures</b> results in new procedures which are monotonic but not well-behaved, whereas the complement or difference generally preserves neither property. Second, the two classes of (solely monotonic or well-behaved) step-up and step-down procedures are closed under taking the union or intersection, but not the complement or difference...|$|R
40|$|The {{objective}} {{of this study was}} to evaluate the residual volatiles, filler content, and resin flow <b>test</b> <b>procedures</b> for carbon-phenolic prepreg materials. The residual volatile <b>test</b> <b>procedure</b> was rewritten <b>with</b> tighter <b>procedure</b> control which was then evaluated by round robin testing by four laboratories on the same rolls of prepreg. Results indicated that the residual volatiles test was too operator and equipment dependent to be reliable, and it was recommended that the test be discontinued. The resin flow <b>test</b> <b>procedures</b> were rewritten <b>with</b> tighter <b>procedure</b> control, and it is now considered to be an acceptable test. It was recommended that the filler content determination be made prior to prepregging...|$|R
40|$|We {{advocate}} {{the use of}} absolute moment ratio statistics in conjunction with standard variance ratio statistics in order to disentangle linear dependence, non-linear dependence, and leptokurtosis in financial time series. Both statistics are computed for multiple return horizons simultaneously, {{and the results are}} presented in a comprehensive way using a graphical device. We construct a formal joint <b>testing</b> <b>procedure</b> based on bootstrapped and block-bootstrapped uniform confidence intervals. The methodology is hybrid because it combines a formal <b>testing</b> <b>procedure</b> <b>with</b> volatility curve pattern recognition based on expert opinions. An application to forex data illustrates the procedure. JEL Codes: C 14, F 31, G 14 Keywords: variance ratios; absolute returns; fat-tails; linear dependence; volatility clustering; bootstrap; forex market e#ciency; stable distributions. # We thank Jon Danelsson, Laurens de Haan, Henk Hoek, and Benne Weger for helpful comments. We also benefited from a presentat [...] ...|$|R
40|$|We {{propose a}} general and formal {{statistical}} framework for multiple tests of association between known fixed {{features of a}} genome and unknown parameters {{of the distribution of}} variable features of this genome in a population of interest. The known gene-annotation profiles, corresponding to the fixed features of the genome, may concern Gene Ontology (GO) annotation, pathway membership, regulation by particular transcription factors, nucleotide sequences, or protein sequences. The unknown gene-parameter profiles, corresponding to the variable features of the genome, may be, for example, regression coefficients relating possibly censored biological and clinical outcomes to genome-wide transcript levels, DNA copy numbers, and other covariates. A generic question of great interest in current genomic research regards the detection of associations between biological annotation metadata and genome-wide expression measures. This biological question may be translated as the test of multiple hypotheses concerning association measures between gene-annotation profiles and gene-parameter profiles. A general and rigorous formulation of the statistical inference question allows us to apply the multiple hypothesis testing methodology developed in [Multiple <b>Testing</b> <b>Procedures</b> <b>with</b> Applications to Genomics (2008) Springer, New York] and related articles, to control a broad class of Type I error rates, defined as generalized tail probabilities and expected values for arbitrary functions of the numbers of Type I errors and rejected hypotheses. The resampling-based single-step and stepwise multiple <b>testing</b> <b>procedures</b> of [Multiple <b>Testing</b> <b>Procedures</b> <b>with</b> Applications to Genomics (2008) Springer, New York] take into account the joint distribution of the test statistics and provide Type I error control in testing problems involving general data generating distributions (with arbitrary dependence structures among variables), null hypotheses, and test statistics. Comment: Published in at [URL] the IMS Collections ([URL] by the Institute of Mathematical Statistics ([URL]...|$|R
30|$|The 98 examinees {{completed}} the test individually {{in a quiet}} room on campus. After familiarizing themselves <b>with</b> the <b>testing</b> <b>procedure</b> <b>with</b> two practice items, they {{completed the}} test, followed by a demographic background survey. The test sessions were monitored by research assistant(s). As for the interviews, each of the nine examinees completed the test item by item in a quiet room on campus with the researcher. Upon completing each item, the researcher {{asked the same question}} 你为什么选这个? (Why did you select this option?) to prompt the examinees to report the rationale underlying their choices as well as their thinking processes involved in completing the test item. All verbal reports were audio recorded and later transcribed for analysis.|$|R
