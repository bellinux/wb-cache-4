505|1330|Public
2500|$|CP1/TP1: For every pair of {{concurrent}} operations [...] and [...] defined on {{the same}} state, the <b>transformation</b> <b>function</b> T satisfies CP1/TP1 property if and only if: [...] where [...] denotes the sequence of operations containing [...] followed byand where [...] denotes equivalence of the two sequences of operations. CP1/TP1 precondition: CP1/TP1 is required only if the OT system allows any two operations to be executed in different orders.|$|E
2500|$|CP2/TP2: For {{every three}} {{concurrent}} operations [...] and [...] defined {{on the same}} document state, the <b>transformation</b> <b>function</b> T satisfies CP2/TP2 property if and only if: [...] CP2/TP2 stipulates equality between two operations transformed with regard to two equivalent sequences of operations: the transformation of [...] against {{the sequence of operation}} [...] followed by [...] must give the same operation as the transformation of [...] against the sequence formed by [...] and [...] CP2/TP2 precondition: CP2/TP2 is required only if the OT systems allows two operations [...] and [...] be IT-transformed in two different document states (or contexts).|$|E
2500|$|Fractional-reserve banking allows {{banks to}} create credit {{in the form}} of bank deposits, which {{represent}} immediate liquidity to depositors. The banks also provide longer-term loans to borrowers, and act as financial intermediaries for those funds. Less liquid forms of deposit (such as time deposits) or riskier classes of financial assets (such as equities or long-term bonds) may lock up a depositor's wealth for a period of time, making it unavailable for use on demand. This [...] "borrowing short, lending long," [...] or maturity <b>transformation</b> <b>function</b> of fractional-reserve banking is a role that many economists consider to be an important function of the commercial banking system.|$|E
25|$|Application-specific {{operation}} model approach: {{which is}} to devise <b>transformation</b> <b>functions</b> for each pair of application operations. For an application with m different operations, m x m <b>transformation</b> <b>functions</b> are needed for supporting this application. In this approach, <b>transformation</b> <b>functions</b> are application-specific and cannot be reused in different applications.|$|R
40|$|Transformational {{approach}} requires to write <b>transformation</b> <b>functions</b> that ensure properties C 1 and C 2. Proving these conditions on complex typed objects {{is a serious}} bottleneck {{for the application of}} this approach. We propose to use a theorem prover to assist the development of safe <b>transformation</b> <b>functions.</b> In this paper, we present how we have designed in that way a set of safe <b>transformation</b> <b>functions</b> for an XML typed object. Keywords Theorem Prover, Transformational Approach, <b>Transformation</b> <b>Functions,</b> XML...|$|R
40|$|Operational {{transformation}} is an approach which allows to build real-time groupware tools. This approach requires correct <b>transformation</b> <b>functions.</b> Proving the correction of these <b>transformation</b> <b>functions</b> is very complex and error prone. In this paper, we show how a theorem prover can address this serious bottleneck. To validate our approach, we have verified the correctness of state-of-art <b>transformation</b> <b>functions</b> defined on Strings with surprising results. Counter-examples {{provided by the}} theorem prover have helped us to define new correct <b>transformation</b> <b>functions</b> for Strings...|$|R
2500|$|An {{alternative}} to the ROC curve is the detection error tradeoff (DET) graph, which plots the false negative rate (missed detections) vs. the false positive rate (false alarms) on non-linearly transformed x- and y-axes. The <b>transformation</b> <b>function</b> is the quantile function of the normal distribution, i.e., the inverse of the cumulative normal distribution. It is, in fact, the same transformation as zROC, below, except that the complement of the hit rate, the miss rate or false negative rate, is used. This alternative spends more graph area on the region of interest. Most of the ROC area is of little interest; one primarily cares about the region tight against the y-axis and the top left corner – which, because of using miss rate instead of its complement, the hit rate, is the lower left corner in a DET plot. Furthermore, DET graphs have the useful property of linearity and a linear threshold behavior for normal distributions. The DET plot is used extensively in the automatic speaker recognition community, where the name DET was first used. The analysis of the ROC performance in graphs with this warping of the axes was used by psychologists in perception studies halfway through the 20th century, where this was dubbed [...] "double probability paper".|$|E
5000|$|... 1935. Three great synonyms: Relation, <b>transformation,</b> <b>function.</b>|$|E
5000|$|Applying the <b>transformation</b> <b>function</b> [...] {{to each of}} {{the above}} points gives: ...|$|E
40|$|Operational {{transformation}} (OT) is {{an approach}} which allows to build real-time groupware tools. This approach requires correct <b>transformation</b> <b>functions</b> regarding two conditions called TP 1 and TP 2. Proving correctness of these <b>transformation</b> <b>functions</b> is very complex and error prone. In this paper, we show how a theorem prover can address this serious bottleneck. To validate our approach, we verifed correctness of state-of-art <b>transformation</b> <b>functions</b> de ned on strings of characters with surprising results. Counter-examples {{provided by the}} theorem prover helped us to design the tombstone <b>transformation</b> <b>functions.</b> These functions verify TP 1 and TP 2, preserve intentions and ensure multi-effect relationships...|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceOperational {{transformation}} is an approach which allows to build real-time groupware tools. This approach requires correct <b>transformation</b> <b>functions.</b> Proving the correction of these <b>transformation</b> <b>functions</b> is very complex and error prone. In this paper, we show how a theorem prover can address this serious bottleneck. To validate our approach, we have verified the correctness of state-of-art <b>transformation</b> <b>functions</b> defined on Strings with surprising results. Counter-examples {{provided by the}} theorem prover have helped us to define new correct <b>transformation</b> <b>functions</b> for Strings...|$|R
40|$|Colloque sans acte à {{diffusion}} restreinte. internationale. International audienceTransformational {{approach requires}} to write <b>transformation</b> <b>functions</b> that ensure properties C 1 and C 2. Proving these conditions on complex typed objects {{is a serious}} bottleneck {{for the application of}} this approach. We propose to use a theorem prover to assist the development of safe <b>transformation</b> <b>functions.</b> In this paper, we present how we have designed in that way a set of safe <b>transformation</b> <b>functions</b> for an XML typed object...|$|R
5000|$|If we {{consider}} [...] to be a <b>transformation</b> <b>function</b> where maps to ,then we get, ...|$|E
5000|$|The <b>transformation</b> <b>function</b> is {{responsible}} for merging two concurrent operations. It is application dependent. For example, a text editor has different operations than a whiteboard application.|$|E
5000|$|McClellan {{transform}}ations [...] {{can be used}} {{to transform}} a 1D filter design into a 2D filter design by using a <b>transformation</b> <b>function.</b> This theory allows the design of 2D adaptive filters [...] out of existing 1D prototype filters. Compared to the direct approach, this system has the advantages of a lower computational complexity and a faster convergence rate. However, in order to work properly, it needs some a priori information about the system to correctly select the <b>transformation</b> <b>function</b> parameters, making the system pre-constrained.|$|E
25|$|Generic {{operation}} model approach: {{which is}} to devise <b>transformation</b> <b>functions</b> for three primitive operations: insert, delete, and update. This approach needs an operation adaptation process to map application operations to these primitive operations. In this approach, the OT operation model is generic, so <b>transformation</b> <b>functions</b> can be reused for different applications.|$|R
2500|$|... {{assigning}} correctness responsibilities {{among the}} control algorithm and <b>transformation</b> <b>functions,</b> and ...|$|R
40|$|AbstractThis work {{presents}} two <b>transformation</b> <b>functions,</b> the α-function and the M-function, {{for finding}} better minimizers in global optimization. We prove that under some general assumptions these functions possess {{the characters of}} both tunnelling functions and filled functions. Numerical tests from some test functions show that our <b>transformation</b> <b>functions</b> are very effective in finding better minima...|$|R
50|$|Binding {{properties}} with transformations can {{be achieved}} through reducing the <b>transformation</b> <b>function</b> {{to the problem of}} binding properties, and the function can be imaginary consider as Type Conversions.|$|E
5000|$|Adaptive {{histogram}} equalization (AHE) improves on this by transforming each pixel with a <b>transformation</b> <b>function</b> {{derived from a}} neighbourhood region. It was first developed for use in aircraft cockpit displays. cited in [...] In its simplest form, each pixel is transformed based on the histogram of a square surrounding the pixel, as in the figure below. The derivation of the transformation functions from the histograms {{is exactly the same}} as for ordinary {{histogram equalization}}: The <b>transformation</b> <b>function</b> is proportional to the cumulative distribution function (CDF) of pixel values in the neighbourhood.|$|E
5000|$|This {{realization}} is {{as shown}} in the figure below.In the figure,the filters F define the <b>transformation</b> <b>function</b> and h(n) is the impulse response of the 1-D prototype filter [...]|$|E
25|$|As long {{as these}} two {{criteria}} are satisfied, the data replicas converge (with additional constraints) after all operations are executed at all sites. There {{is no need}} to enforce a total order of execution for the sake of achieving convergence. Their approach is generally to first identify and prove sufficient conditions for a few <b>transformation</b> <b>functions,</b> and then design a control procedure to ensure those sufficient conditions. This way the control procedure and <b>transformation</b> <b>functions</b> work synergistically to achieve correctness, i.e., causality and admissibility preservation. In their approach, there {{is no need to}} satisfy transformation properties such as TP2 because it does not require that the (inclusive) <b>transformation</b> <b>functions</b> work in all possible cases.|$|R
30|$|Estimation of {{the value}} of the <b>transformation</b> <b>functions</b> at all frame pixels based on the above parameters.|$|R
40|$|We {{describe}} a Markov chain Bayesian classification tool, SCS, that can perform data-driven classification of proteins and protein segments. Training data for interesting classification problems is often limited; thus, SCS uses string <b>transformation</b> <b>functions</b> {{to change the}} encoding of proteins to reduce problem perplexity and improve classification. A wrapperbased genetic algorithm is used to search the space of possible string <b>transformation</b> <b>functions</b> to find functions that improve classification...|$|R
5000|$|Another metaphor {{describes}} the state memory as an [...] "entropy pool", with input [...] "poured into" [...] the pool, and the <b>transformation</b> <b>function</b> {{referred to as}} [...] "stirring the entropy pool".|$|E
50|$|Using the Kolmogorov {{complexity}} {{gives an}} unbiased estimate (a universal prior) of the prior {{probability of a}} number. As a thought experiment an intelligent agent may be fitted with a data input device giving a series of numbers, after applying some <b>transformation</b> <b>function</b> to the raw numbers. Another agent might have the same input device with a different <b>transformation</b> <b>function.</b> The agents do not see or know about these transformation functions. Then there appears no rational basis for preferring one function over another. A universal prior insures that although two agents may have different initial probability distributions for the data input, the difference will be bounded by a constant.|$|E
50|$|Adaptive {{histogram}} equalization in its straightforward form presented above, both {{with and without}} contrast limiting, requires the computation of a different neighbourhood histogram and <b>transformation</b> <b>function</b> for each pixel in the image. This makes the method very expensive computationally.|$|E
50|$|The {{computation}} {{is carried}} out by defining filters or <b>transformation</b> <b>functions</b> that act on these time-varying streams of data.|$|R
5000|$|Google Summer of Code'2009 {{extensions}} {{to enable}} fine-grain program optimizations including polyhedral <b>transformations,</b> <b>function</b> level run-time adaptation and collective optimization ...|$|R
5000|$|Because {{matrices}} represent linear <b>transformation</b> <b>functions,</b> with matrix multiplication representing functional composition, one can immediately {{conclude that}} matrix multiplication is associative.|$|R
50|$|This is {{achieved}} by limiting the contrast enhancement of AHE. The contrast amplification {{in the vicinity of}} a given pixel value is given by the slope of the <b>transformation</b> <b>function.</b> This is proportional to the slope of the neighbourhood cumulative distribution function (CDF) and therefore to the value of the histogram at that pixel value. CLAHE limits the amplification by clipping the histogram at a predefined value before computing the CDF. This limits the slope of the CDF and therefore of the <b>transformation</b> <b>function.</b> The value at which the histogram is clipped, the so-called clip limit, depends on the normalization of the histogram and thereby {{on the size of the}} neighbourhood region. Common values limit the resulting amplification to between 3 and 4.|$|E
5000|$|When {{the image}} region {{containing}} a pixel's neighbourhood is fairly homogeneous, its histogram will be strongly peaked, and the <b>transformation</b> <b>function</b> will map {{a narrow range}} of pixel values to {{the whole range of}} the result image. This causes AHE to overamplify small amounts of noise in largely homogeneous regions of the image.|$|E
5000|$|The {{two extra}} points are {{computed}} by [...] and [...] [...] adds all the elliptic curve points {{and the two}} extra points together. Finally, the result is passed through an output <b>transformation</b> <b>function</b> f to get the hash result [...] To read more about this algorithm, see [...] "ECOH: the Elliptic Curve Only Hash".|$|E
40|$|Operation {{transformation}} {{has been}} recognized as a promising approach to intention preservation and consistency maintenance in cooperative editing systems. To deal with the complications caused {{by the fact that}} independent operations may come from different document states, we propose a pair of mutually reversible inclusion and exclusion <b>transformation</b> <b>functions,</b> which can be used to effectively include/exclude the impact of one operation into/from another operation so that the pre- /post-conditions of <b>transformation</b> <b>functions</b> can be satisfied and correct transformation results can be achieved. The technical issues and strategies in the design of inclusion and exclusion <b>transformation</b> <b>functions</b> for string-wise operations in cooperative text editing systems are discussed in detail in this paper 1 Keywords: intention preservation, cooperative editing, CSCW. 1 Introduction Cooperative editing systems allow physically dispersed people to view and edit shared textual/graphical/multimedi [...] ...|$|R
3000|$|Figure 6 {{shows that}} the <b>transformation</b> <b>functions</b> {{produced}} by the AGC for low-contrast dark images indeed fall above the line I [...]...|$|R
50|$|This {{procedure}} {{reduces the}} number of <b>transformation</b> <b>functions</b> to be computed dramatically and only imposes the small additional cost of linear interpolation.|$|R
