10000|8466|Public
25|$|For {{continuous}} random variables, <b>the</b> <b>multivariate</b> Gaussian is {{the distribution}} with maximum differential entropy.|$|E
25|$|Note {{that the}} ARMA {{model is a}} {{univariate}} model. Extensions for <b>the</b> <b>multivariate</b> case are the vector autoregression (VAR) and Vector Autoregression Moving-Average (VARMA).|$|E
25|$|The {{distribution}} can {{be expanded}} to any number of colors c of balls in the urn. <b>The</b> <b>multivariate</b> distribution is used when {{there are more than}} two colors.|$|E
5000|$|As with <b>the</b> {{symmetric}} <b>multivariate</b> Laplace distribution, <b>the</b> asymmetric <b>multivariate</b> Laplace distribution has mean , but the covariance becomes [...] [...] <b>The</b> asymmetric <b>multivariate</b> Laplace {{distribution is}} not elliptical unless , {{in which case}} the distribution reduces to <b>the</b> symmetric <b>multivariate</b> Laplace distribution with [...]|$|R
40|$|We {{propose a}} new multivariate Markov chain model for {{adding a new}} {{categorical}} data sequence. The number of the parameters in <b>the</b> new <b>multivariate</b> Markov chain model is only (3 s) less than ((s+ 1) 2) {{the number of the}} parameters in <b>the</b> former <b>multivariate</b> Markov chain model. Numerical experiments demonstrate the benefits of <b>the</b> new <b>multivariate</b> Markov chain model on saving computational resources...|$|R
5000|$|Examples include <b>the</b> {{following}} <b>multivariate</b> probability distributions: ...|$|R
25|$|No {{good way}} of calculating the {{variance}} is known. The best known method is to approximate <b>the</b> <b>multivariate</b> Wallenius distribution by a multivariate Fisher's noncentral hypergeometric distribution with the same mean, and insert the mean as calculated above in the approximate formula for the variance of the latter distribution.|$|E
25|$|There are general {{algorithms}} {{which always}} produce the complete factorization of any polynomial, in either one variable (the univariate case) or several variables (<b>the</b> <b>multivariate</b> case); see Factorization of polynomials. These algorithms are implemented {{and are available}} in most computer algebra systems. They involve advanced properties of polynomials, and are too complicated for hand-written computation. There are also a few elementary methods which are well–suited for hand-written computation, and do not always allow finding the complete factorization in degree higher than four.|$|E
25|$|New {{research}} is surfacing {{that suggests that}} ability EI measures might be measuring personality in addition to general intelligence. These studies examined <b>the</b> <b>multivariate</b> effects of personality and intelligence on EI and also corrected estimates for measurement error (which is often not done in some validation studies). For example, a study by Schulte, Ree, Carretta (2004), showed that general intelligence (measured with the Wonderlic Personnel Test), agreeableness (measured by the NEO-PI), as well as gender could reliably be used to predict the measure of EI ability.|$|E
50|$|A {{generalization}} is <b>the</b> inverse <b>multivariate</b> gamma distribution.|$|R
5000|$|<b>The</b> Rainbow <b>Multivariate</b> Equation Signature Scheme is {{a member}} of a class of multivariate {{quadratic}} equation cryptosystems called [...] "Unbalanced Oil and Vinegar Cryptosystems" [...] (UOV Cryptosystems) Bulygin, Petzoldt and Buchmann have shown a reduction of generic multivariate quadratic UOV systems to <b>the</b> NP-Hard <b>Multivariate</b> Quadratic Equation Solving problem.|$|R
5000|$|<b>The</b> omnibus <b>multivariate</b> F Test in ANOVA with {{repeated}} measures ...|$|R
25|$|Before {{data mining}} {{algorithms}} can be used, a target data set must be assembled. As data mining can only uncover patterns actually {{present in the}} data, the target data set must {{be large enough to}} contain these patterns while remaining concise enough to be mined within an acceptable time limit. A common source for data is a data mart or data warehouse. Pre-processing is essential to analyze <b>the</b> <b>multivariate</b> data sets before data mining. The target set is then cleaned. Data cleaning removes the observations containing noise and those with missing data.|$|E
25|$|A {{probability}} distribution whose sample space is {{the set of}} real numbers is called univariate, while a distribution whose sample space is a vector space is called multivariate. A univariate distribution gives the probabilities of a single random variable taking on various alternative values; a multivariate distribution (a joint {{probability distribution}}) gives the probabilities of a random vector—a list {{of two or more}} random variables—taking on various combinations of values. Important and commonly encountered univariate probability distributions include the binomial distribution, the hypergeometric distribution, and the normal distribution. <b>The</b> <b>multivariate</b> normal distribution is a commonly encountered multivariate distribution.|$|E
25|$|Principal {{component}} regression (PCR) is {{used when}} the number of predictor variables is large, or when strong correlations exist among the predictor variables. This two-stage procedure first reduces the predictor variables using principal component analysis then uses the reduced variables in an OLS regression fit. While it often works well in practice, there is no general theoretical reason that the most informative linear function of the predictor variables should lie among the dominant principal components of <b>the</b> <b>multivariate</b> distribution of the predictor variables. The partial least squares regression is the extension of the PCR method which does not suffer from the mentioned deficiency.|$|E
40|$|This article {{proposes a}} multivariate {{synthetic}} control chart for skewed populations {{based on the}} weighted standard deviation method. The proposed chart incorporates the weighted standard deviation method into <b>the</b> standard <b>multivariate</b> synthetic control chart. <b>The</b> standard <b>multivariate</b> synthetic chart consists of the Hotelling's T 2 chart and the conforming run length chart. The weighted standard deviation method adjusts the variance–covariance matrix of the quality characteristics and approximates the probability density function using several <b>multivariate</b> normal distributions. <b>The</b> proposed chart reduces to <b>the</b> standard <b>multivariate</b> synthetic chart when the underlying distribution is symmetric. In general, the simulation {{results show that the}} proposed chart performs better than <b>the</b> existing <b>multivariate</b> charts for skewed populations and the standard T 2 chart, in terms of false alarm rates as well as moderate and large mean shift detection rates based on the various degrees of skewnesses...|$|R
5000|$|Calculate {{an inverse}} {{distance}} weighted average with <b>the</b> k-nearest <b>multivariate</b> neighbors.|$|R
5000|$|A typical {{characterization}} of <b>the</b> asymmetric <b>multivariate</b> Laplace distribution has the characteristic function: ...|$|R
25|$|<b>The</b> <b>multivariate</b> {{nature of}} SA {{significantly}} complicates its quantification and measurement, {{as it is}} conceivable that a metric may only tap into one aspect of the operator's SA. Further, studies have shown that different types of SA measures do not always correlate strongly with each other (cf. Durso, Truitt, Hackworth, Crutchfield, Nikolic, Moertl, Ohrt, & Manning, 1995; Endsley, Selcon, Hardiman, & Croft, 1998; Vidulich, 2000). Accordingly, rather than rely on a single approach or metric, valid and reliable measurement of SA should utilize a battery of distinct yet related measures that complement each other (e.g., Harwood, Barnett, & Wickens, 1988). Such a multi-faced approach to SA measurement capitalizes on the strengths of each measure while minimizing the limitations inherent in each.|$|E
500|$|... discuss {{extended}} maximum spacing {{methods to}} <b>the</b> <b>multivariate</b> case. As {{there is no}} natural order for , they discuss two alternative approaches: a geometric approach based on Dirichlet cells and a probabilistic approach based on a “nearest neighbor ball” metric.|$|E
2500|$|In {{case that}} <b>the</b> <b>multivariate</b> {{distribution}} has a density , {{and this is}} available, it holds further that ...|$|E
40|$|AbstractThis paper {{deals with}} the {{determination}} of the rate of convergence to the unit of some multivariate neural network operators, namely, the Cardaliaguet-Euvrard and “squashing” operators. This is given through the multidimensional modulus of continuity of <b>the</b> involved <b>multivariate</b> function or its partial derivatives of specific order that appear in the right-hand side of <b>the</b> associated <b>multivariate</b> Jackson type inequality...|$|R
50|$|Theory {{related to}} <b>the</b> {{generalized}} <b>multivariate</b> log-gamma distribution provides a <b>multivariate</b> version of <b>the</b> Gumbel distribution.|$|R
40|$|In this article, {{we propose}} a new {{generalized}} multivariate log-gamma distribution. We consider {{the usage of}} <b>the</b> proposed <b>multivariate</b> distribution as <b>the</b> prior distribution in the Bayesian analysis. <b>The</b> generalized <b>multivariate</b> log-gamma distribution allows {{for the inclusion of}} prior knowledge on correlations between model parameters when likelihood is not {{in the form of a}} normal distribution. Use of the proposed distribution in the Bayesian analysis of log-linear models is also discussed...|$|R
2500|$|<b>The</b> <b>multivariate</b> normal {{distribution}} describes the Gaussian {{law in the}} k-dimensional Euclidean space. A vector [...] is multivariate-normally distributed if any linear combination of its components [...] has a (univariate) {{normal distribution}}. The variance of X is a k×k symmetric positive-definite matrixV. <b>The</b> <b>multivariate</b> normal distribution is a special case of the elliptical distributions. As such, its iso-density loci in the k = 2 case are ellipses {{and in the case}} of arbitrary k are ellipsoids.|$|E
2500|$|Using a non-identity {{covariance}} matrix for <b>the</b> <b>multivariate</b> normal distribution in evolution strategies {{is equivalent to}} a coordinate system transformation of the solution vectors, mainly because the sampling equation ...|$|E
2500|$|... {{such that}} [...] is {{the density of}} <b>the</b> <b>multivariate</b> normal {{distribution}} [...] Then, we have an explicit expression for the inverse of the Fisher information matrix where [...] is fixed ...|$|E
40|$|As data in {{the form}} of random {{functions}} and curves are becoming more common, so is the need for measures and estimates to capture the dependency between <b>the</b> components of <b>multivariate</b> functional data. An established method is functional canonical correlation analysis (FCCA), developed by Leurgans et al. (1993), extending <b>the</b> corresponding <b>multivariate</b> concep...|$|R
40|$|Two (narrow and wide) multivariate {{geometric}} analogues of <b>the</b> Marshall-Olkin <b>multivariate</b> exponetial distribution {{are derived}} from the following cumulative damage model. A set of devices is exposed to a common damage process. Damage occurs in discrete cycles. On each cycle the amount of damage is an independent observation on a nonnegative random variable. Damages accumulate additively. Each device has its own random breaking threshold. A device fails when the accumulated damage exceeds its threshold. Thresholds are independent of damages, and have a Marshall-Olkin <b>multivariate</b> exponential distribution. <b>The</b> joint distribution of the random numbers of cycles {{up to and including}} failure of the devices has <b>the</b> wide <b>multivariate</b> geometric distribution. It has <b>the</b> narrow <b>multivariate</b> geometric distribution if the damage variable is infinitely divisible. (Author) [URL]...|$|R
30|$|As {{a direct}} {{generalization}} of Theorem  2.19 in [25], we can formulate <b>the</b> following <b>multivariate</b> chain rule under generalized differentiability.|$|R
2500|$|The {{model of}} an urn with {{green and red}} marbles can be {{extended}} to the case where {{there are more than}} two colors of marbles. If there are Ki marbles of color i in the urn and you take n marbles at random without replacement, then the number of marbles of each color in the sample (k1,k2,...,kc) has <b>the</b> <b>multivariate</b> hypergeometric distribution. [...] This has the same relationship to the multinomial distribution that the hypergeometric distribution has to the binomial distribution—the multinomial distribution is the [...] "with-replacement" [...] distribution and <b>the</b> <b>multivariate</b> hypergeometric is the [...] "without-replacement" [...] distribution.|$|E
2500|$|... always, {{regardless}} of [...] But {{there are many}} ways for the interval of integration to expand to fill the real line, and other ways can produce different results; in other words, <b>the</b> <b>multivariate</b> limit does not always exist. We can compute ...|$|E
2500|$|Note {{that under}} this definition, the subset {{on which a}} {{function}} is defined is significant when generalizing statements from the univariate setting to <b>the</b> <b>multivariate</b> setting. For example, if [...] and , then [...] if we restrict [...] and [...] to , but not if they are defined on [...]|$|E
40|$|<b>The</b> {{study of}} <b>multivariate</b> {{distributions}} was almost exclusively restricted to <b>the</b> study of <b>multivariate</b> Normal distribution until recently. During {{the last twenty}} five years <b>the</b> study of <b>multivariate</b> discrete distributions and various ether multivariate distributions seems to have gained importance as the advancement of different fields demanded the application of distributions ether than multivariate Normal. Different multi variate distributions studied, in different situations, by the following authors could be noted {{in view of the}} remark. [ [...] . ...|$|R
5000|$|<b>The</b> {{following}} <b>multivariate</b> calibration methods {{exist for}} transforming classifier scores into class membership probabilities {{in the case}} with classes count greater than two: ...|$|R
40|$|AbstractDirichlet averages of multivariate {{functions}} are employed for a derivation of basic recurrence formulas for <b>the</b> moments of <b>multivariate</b> Dirichlet splines. An algorithm for computing <b>the</b> moments of <b>multivariate</b> simplex splines is presented. Applications to hypergeometric functions of several variables are discussed...|$|R
