8|424|Public
40|$|Software {{engineering}} endeavours {{are typically}} based on and {{governed by the}} requirements of the target software; requirements identification is therefore an integral part of software development methodologies. Similarly, engineering a software development methodology (SDM) involves the identification of {{the requirements of the}} <b>target</b> <b>methodology.</b> Methodology engineering approaches pay special attention to this issue; however, they make little use of existing methodologies as sources of insight into methodology requirements. The authors propose an iterative method for eliciting and specifying the requirements of a SDM using existing methodologies as supplementary resources. The method is performed as the analysis phase of a methodology engineering process aimed at the ultimate design and implementation of a <b>target</b> <b>methodology.</b> An initial set of requirements is first identified through analysing the characteristics of the development situation at hand and/or via delineating the general features desirable in the <b>target</b> <b>methodology.</b> These initial requirements are used as evaluation criteria; refined through iterative application to a select set of relevant methodologies. The finalised criteria highlight the qualities that the <b>target</b> <b>methodology</b> is expected to possess, and are therefore used as a basis for de. ning the final set of requirements. In an example, the authors demonstrate how the proposed elicitation process can be used for identifying the requirements of a general object-oriented SDM. Owing to its basis in knowledge gained from existing methodologies and practices, the proposed method can help methodology engineers produce a set of requirements that is not only more complete in span, but also more concrete and rigorous...|$|E
40|$|Lidar {{hard target}} {{calibration}} is discussed, emphasizing the transfer <b>target</b> <b>methodology.</b> Characteristics of example calibratrion target surfaces {{are described in}} light of four reflectance mechanisms, specular, diffuse, retroreflection, and off-specular reflectance. The ideal transfer target is one which {{can be described as}} entirely diffusely reflecting, i. e., Lambertian. Correction for retroreflection is required when using the flowers of a sulfur transfer target at CO 2 laser wavelengths. Corrections for specular and retroreflection for the integrating sphere are negligible; however, the off-specular reflectance of rough metal surfaces used in the integrating spheres is only qualitatively compared with the diffuse reflectance of flowers of sulfur...|$|E
40|$|This paper {{describes}} {{the design and}} fabrication {{of a range of}} ‘gas cell’ microtargets produced by the Target Fabrication Group in the Central Laser Facility (CLF) for academic access experiments on the Orion laser facility at the Atomic Weapons Establishment (AWE). The experiments were carried out by an academic consortium led by Imperial College London. The underlying <b>target</b> <b>methodology</b> was an evolution of a range of targets used for experiments on radiative shocks and involved the fabrication of a precision machined cell containing a number of apertures for interaction foils or diagnostic windows. The interior of the cell was gas-filled before laser irradiation. This paper details the assembly processes, thin film requirements and micro-machining processes needed to produce the targets. Also described is the implementation of a gas-fill system to produce targets that are filled to a pressure of 0. 1 – 1 bar. The paper discusses the challenges that are posed by such a target...|$|E
5000|$|Full view {{into the}} media plan, publishers, inventory, audience, <b>targeting</b> <b>methodology,</b> pricing, and other perimeters ...|$|R
50|$|In 2011, the new Village Enterprise {{model was}} launched. The new model {{included}} rigorous <b>targeting</b> <b>methodology,</b> a one-year training program, and a savings program {{in addition to}} a cash grant and mentoring.|$|R
40|$|ICE {{experienced}} a successful encounter with Comet Giacobini-Zinner on September 11, 1985. The comet-intercept trajectory, earth-return trajectory, and two cases {{of a possible}} 2014 capture trajectory are presented. Also, the essential propulsive trajectory correction maneuvers and the projected August 10, 2014 lunar swingby maneuver are discussed. The <b>targeting</b> <b>methodology</b> used for designing the trajectories is also discussed...|$|R
40|$|Background. Mutations and {{epigenetic}} aberrant signaling {{of growth}} factors pathways contribute to carcinogenesis. Recent studies reveal that non-coding RNAs are controllers of gene expression. H 19 is an imprinted gene that demonstrates maternal monoallelic expression without a protein product; although its expression is shut off in most tissues postnatally, it is reactivated during adult tissue regeneration and tumorigenesis. Moreover, H 19 is highly expressed in liver metastasis {{derived from a}} range of carcinomas. The objective {{of this study is to}} explore the role of H 19 in carcinogenesis, and to determine its identification as an anti-tumor <b>target.</b> <b>Methodology</b> / Principle Findings. By controlling oxygen pressure during tumor cell growth and H 19 expression levels, we investigated the role of H 19 expression in vitro and in vivo in hepatocellular (HCC) and bladder carcinoma. Hypoxia upregulates the level of H 19 RNA. Ablations of tumorigenicity of HCC and bladder carcinomas in vivo are seen by H 19 knockdown which also significantly abrogates anchorage-independent growth after hypoxia recovery, while ectopic H 19 expression enhances tumorigenic potential of carcinoma cells in vivo. Knocking-down H 19 message in hypoxic stress severely diminishes p 57 kip 2 induction. We identified a number of potential downstream targets of H 19 RNA, including angiogenin and FGF 18. Conclusions. H 19 RNA harbors pro-tumorigenic properties, thus the H 19 gene behaves as an oncogene and may serve as a potential new target for anti-tumor therapy...|$|E
40|$|The {{aim of this}} {{bachelor}} thesis called "Leisure {{activities for}} Panenská nursing home in Tachov" is to map the satisfaction of the house's clients with the leisure activities provided by the nursing home. This thesis comprises of two parts - theoretical and research. The theoretical part copes with the ageing problematics, {{with the needs of}} old people, their leisure time and leisure activities and certain acquisition programs. This thesis aims generally on the problematics with the focus on nursing homes, especially Panenská nursing home in Tachov. The main method is the qualitative research. The <b>target,</b> <b>methodology</b> and schedule are further described in the thesis. The used methods of qualitative research is the interviewing with semi-structured interviews. The interviews were held with the clients of Panenská nursing home in Tachov. The research data files has been chosen by the intentional quoting choice. As a secondary method, the framework data analysis technique, word-for-word transcription and the cluster-creating method has been chosen. The research has shown that the clients are satisfied with the leisure activities provided by the nursing home but they would like to introduce several new activities -handcrafting and creative writing especially. The extension of the scale of the activities would lead to the fulfilment of the needs of the clients and furthermore to more effective use of their leisure time. All the above mentioned information are possible to further use as an information source about the leisure activities in Panenská nursing home in Tachov. This bachelor thesis will be used as a feedback for the mentioned nursing home. It might help not just to improved the function of the nursing home but to greater satisfaction of its clients as well...|$|E
40|$|Improving feed {{efficiency}} is an import challenge for pig production. This study aimed at proposing molecular traits {{able to predict}} feed conversion ratio (FCR) in growing pigs. A total of 71 pigs from two divergent lines selected for residual feed intake (RFI) and fed under different conditions (ad libitum or restricted) and different diets (low fat high starch or high fat high fiber) were considered, so that {{a broad range of}} FCR data was obtained. Transcriptomics data from the loin muscle and blood were obtained using porcine microarrays. The dataset (22, 288 molecular probes per tissue and pig) was split into 70 % for machine learning methods and 30 % for cross-validation. Random forests were used to propose a reasonable set of 359 genes identified as very important predictors (VIP) of FCR. The FCR was well predicted (RMSE= 0. 16; R 2 = 0. 63) by a model combining the expression levels of 50 genes in muscle (out of the 359 VIP). These genes were involved in various biological pathways, including the response to insulin, homeostatic processes, signal transduction, regulation of cell proliferation, apoptosis, protein metabolism, and inflammatory responses. About 82 % of the muscle VIP were also expressed in the blood. The FCR was also predicted correctly (RMSE= 0. 21; R 2 = 0. 52) by using the same model of genes expressed in blood. Technical validation is in progress to evaluate the predictive potential of the model when expression levels of these genes are measured by <b>target</b> <b>methodology</b> (qPCR) in blood of the same pigs. Further tests will be performed on blood samples taken at earlier growth stages to obtain early predictors and by using different pig populations to obtain generic predictors. In conclusion, identifying molecular traits related to {{feed efficiency}} could be helpful to identify important genomic regions and new biomarkers for genetic selection. This study is part of the Feed-a-Gene project and received funding from the European Union’s H 2020 program under grant agreement no. 633531...|$|E
40|$|Energy Efficiency {{has gained}} {{concern in the}} process {{industry}} due to the high energy consumption. Process Integration using Pinch Analysis {{plays an important role}} in enhancing the sustainability and the profitability margin of industrial processes. Total Site Heat Integration (TSHI) is one of the main branches of Process Integration based on Pinch Analysis technique, which is an industrial energy conservation strategy across individual process boundary. However, the pressure drop and heat loss on the steam mains have not been well discussed in the existing TS <b>targeting</b> <b>methodologies.</b> In this paper, an extended numerical algorithm is proposed for addressing the effects of plant layout to the minimum multiple utility targets. The extended tools are able to assist the designer to perform a preliminary assessment of the retrofit options for a steam system. This enhanced methodology improves the accuracy of the existing TS <b>targeting</b> <b>methodology</b> by considering the effects of plant layout in a TS system. The proposed methodology is demonstrated with an illustrative case study...|$|R
40|$|The paper {{focuses on}} {{extending}} traditional Total Site Integration methodology {{to produce more}} meaningful utility and heat recovery targets for the process design. The traditional methodology leads to inadequate results due to inaccurate estimation of the overall Total Site heat recovery <b>targets.</b> The new <b>methodology</b> is a further development of a recently extended traditional pinch methodology. The previous extension was on the introduction of using an individual minimum temperature difference (δTmin) for different processes so that the δTmin is more representative of the specific process. Further this paper deals with stream specific δT min inside each process by setting different δT contribution (δTcont) and also using different δTcont between the process streams and the utility systems. The paper describes the further extended methodology called stream specific <b>targeting</b> <b>methodology.</b> A case study applying data from a real diary factory is used to show {{the differences between the}} traditional, process specific and stream specific total site <b>targeting</b> <b>methodologies.</b> The extended methodology gives more meaningful results {{at the end of the}} targeting with this avoiding the over or under estimated heat exchanger areas in the process design...|$|R
40|$|This paper {{reflects}} on our work in deriving <b>targeted</b> <b>methodologies</b> to develop IT applications and content in a developing world environment. This paper {{argues that a}} common thread over {{more than a decade}} of experience in building Information and Communication Technology systems has been a community centred approach. We relate this to the African philosophy of ubuntu. These approaches are wrapped into an iterative Action Research paradigm to include the communities of users directly...|$|R
40|$|The author {{analyzes}} {{the experience of}} applying the program and <b>target</b> <b>methodology</b> in practice of strategic territorial management in the Stavropol region – the region which is the catalyst of {{economic growth in the}} North Caucasus Federal District. The article’s purpose is to show that despite the favorable conditions for developing the agrarian and industrial complex, tourism, power industry extracting and processing industries in the regions of the North Caucasus, there was no success yet in improving social and economic situation. Realization of the dialectic principles of research within system and evolutionary approaches became a methodological basis of the solution of the tasks set by the author. Creative synthesis of general scientific and specific methods of research is used: subject and object, structural and functional, comparative and other types of analysis, as well as the method of expert evaluations. The investment priorities of the state program “Development of the North Caucasus Federal District for the period till 2025 ” adopted in 2014, are connected with formation of conditions for advancing development of the regional economy and creation of new jobs. The Federal Target Program “The South of Russia” is supposed to become its main tool in 2014 - 2020. The strategic tasks of this program include building social objects, increasing investment appeal of subjects of the North Caucasus Federal District and decreasing unemployment rate. The important role in development of an economic complex of the Stavropol region is played by the regional “Program of social and economic development of the Stavropol region for 2010 - 2015 ” the main objectives of which are connected with investment activity and innovative development, formation of competitive economy. However, despite active use in regional policy of program and target tools, one of the main problems constraining the accelerated development of economy of the Stavropol region, there is a deficiency of budgetary funds. Today the size of a public debt of the Stavropol region approached the limit – 42 billion rubles. Experience of 2008 - 2014 showed that program and target approach to social and economic development of subjects of the North Caucasus Federal District hardly has alternative. But dispersion of resources according to various programs and lack of coordination of efforts of public authorities can lead to violation of unity of a state policy in the North Caucasus, to inefficient use of budgetary funds, growth of corruption and other risks...|$|E
40|$|Safety {{assessment}} of {{a nuclear power plant}} (NPP) relies on a spectrum of approaches. Traditionally, deterministic analysis was extensively used to evaluate a relatively small set of so-called design-basis accidents. Initially, for these design-basis accidents, conservative calculations were performed to “envelop” the plant response and to evaluate the margin to the different acceptance limits. This corresponds largely to what is called “Option 1 ”. Later, best-estimate codes were developed first for thermal-hydraulic system analysis. These best-estimate codes have been widely adopted in safety assessments of nuclear power plants. Usage of this type of codes allows for both “Options 2 and 3 ”, depending if only conservative inputs are adopted or if a full uncertainty evaluation is being performed, i. e. “Best-Estimate Plus Uncertainty (BEPU). With the ground-breaking WASH- 1400 study performed in 1975, probabilistic safety analyses (PSA) techniques were integrated into the NPP safety assessment focusing is on “beyond design basis” sequences. Over time, this novel approach that initially met considerable criticism was continuously developed and today represents a matured analysis technology regularly applied in the framework of NPP safety assessments. Since the PSA approach does not include plant dynamics directly, support from transient analysis was necessary for identifying/verifying success criteria. Furthermore, severe accident analysis codes and further analysis tools were used to determine the course of involved sequences and its likely consequences. Typically, these support calculations were performed on a best-estimate basis (without uncertainty evaluations). It should be noted that considering the time evolution of the plant responses and its impact on success criteria could only be achieved through an (resource-intensive) iteration procedure. It is therefore no surprise that attempts {{to bridge the gap between}} the PSA and DSA approach are being pursued since quite some time. Two methods explored to bridge the gap between the PSA and DSA are the deterministic dynamic event tree approach was (DDET) and the cell-to-cell mapping technique (CCMT) [...] The theoretical basis for these approaches is given by the theory of probabilistic dynamics. While DDET techniques were successfully applied to some “real-life” problems, the situation is different for the other novel approaches with no applications to problems comparable to a NPP. It should also not be forgotten that the required computing resources necessary to deploy any of these approaches are significant. Meanwhile, computing resources are becoming or are available at the required level and support a new interest in approaches integrating/combining DSA and PSA. Combining DSA and PSA approaches found new interest in the context of the CSNI safety margin project (SMAP) and it’s follow up pilot study (SM 2 A). The motivation for this study was the general observation that plant modifications such as power up-rates lead to erosion of margin that remains largely un-quantified in the current licensing framework. SMAP proposed a framework for the evaluation of generalized safety margin that relies on the combination of DSA and PSA. Conceptually, the enveloping of sequences and parameters is abandoned: The plant simulations are performed according to the BEPU approach, and also the event tree (ET) binning is avoided as much as feasible. As such, it also allows for safety assessments according to “Option 4 ”. Furthermore, combining DSA and PSA in a consistent manner naturally leads to the application of DDET. Now, if DDET represents the ideal <b>target</b> <b>methodology</b> that unfortunately requires significant resources (both human and computational), a graded approach towards improving safety assessments is advisable: Both DSA and PSA have matured over the years and constitute state-of-the-art, but only limited experience is available with the application of the innovative combined approaches. Therefore, preserving the mature techniques and making best use of them is the ambition of Integrated Deterministic and Probabilistic Safety Assessment (IDPSA). IDPSA stands for a whole family of approaches that consider both deterministic and probabilistic aspects. The most rigorous ones are based on DDET. Combining DSA and PSA approaches found new interest in the context of the CSNI safety margin project (SMAP) and it’s follow up pilot study (SM 2 A). The most advanced DDET methods and tools which have already been used for analyzing complex realistic scenarios are the ADAPT method (Analysis of Dynamic Accident Progression Trees) developed at OSU with support from the Sandia National Laboratory (SNL), and the MCDET method (a combination of Monte Carlo simulation and the DDET approach) developed at GRS. Motivating Factors Safety is central to the design, licensing, operation, and economics of NPPs. Consequently, there are strong motivations to better understand, characterize, and manage safety and its associated “margin. ” Historically though, specific safety margin provisions have been formulated, primarily based on engineering judgment, and described by way of deterministic (or “mechanistic”) calculations. Improved understanding of both the qualitative and quantitative aspects of those safety margins is needed NPP applications such as: • Plant design changes: During the operational lifetime, a selection of plant changes are both proposed and implemented following appropriate application of regulatory and licensing processes. Further, many of these changes have both economic and safety implications. For example, NPP “stretch” and “extended” power up-rates may increase the plant production of power by as much as 20...|$|E
40|$|Depression is {{a severe}} neuropsychiatric {{disorder}} affecting approximately 10 % {{of the world}} population. Despite this, the molecular mechanisms underlying the disorder are still not understood. Novel technologies such as proteomic-based platforms are beginning to offer new insights into this devastating illness, beyond those provided by the standard <b>targeted</b> <b>methodologies.</b> Here, we will show the potential of proteome analyses {{as a tool to}} elucidate the pathophysiological mechanisms of depression as well as the discovery of potential diagnostic, therapeutic and disease course biomarkers...|$|R
50|$|As {{the brigade}} assumed {{responsibility}} {{for all of}} Diyala Province, it regained control of 1-38 Infantry and 2-23 Infantry and had attached the 2nd Squadron, 3rd Armored Cavalry Regiment and eventually the 3rd Squadron, 2nd Stryker Cavalry Regiment. In assuming a province, the brigade {{had to take a}} much greater role in transitioning Iraqi security forces and partnering with the Government of Iraq. Despite these added responsibilities, the brigade continued to keep the pressure on the enemy, replicating the same intelligence-driven <b>targeting</b> <b>methodology</b> that had proven so successful previously.|$|R
40|$|Ó The Author(s) 2009. This {{article is}} {{published}} with open access at Springerlink. com Abstract Depression is a severe neuropsychiatric disorder affecting approximately 10 % {{of the world}} population. Despite this, the molecular mechanisms underlying the disorder are still not understood. Novel technologies such as proteomic-based platforms are beginning to offer new insights into this devastating illness, beyond those provided by the standard <b>targeted</b> <b>methodologies.</b> Here, we will show the potential of proteome analyses {{as a tool to}} elucidate the pathophysiological mechanisms of depression as well as the discovery of potential diagnostic, therapeutic and disease course biomarkers...|$|R
40|$|This thesis {{describes}} {{the establishment of}} a precise gene <b>targeting</b> <b>methodology</b> in the silkworm Bombyx mori by technologies based on engineered endonucleases. Two classes of engineered endonucleases, ZFNs and full length TALENs were used for creating DSBs at specified sites in the colour marker genes (BmBlos 2 and Bmwh 3). Direct embryo microinjection of engineered nucleases mRNA were performed and let the nuclease proteins to disrupt the functions of these marker genes by creating DSBs and inducing error prone NHEJ mechanism. These experiments showed that both ZFNs and TALENs could be used for targeted gene disruption in silkworms...|$|R
40|$|To {{assess the}} {{effectiveness}} and draw {{lessons from the}} targeting strategy used in a new BRAC programme called Challenging the Frontiers of Poverty Reduction-Targeting the Ultra Poor (CFPR/TUP) that aims to experiment with {{a different type of}} approach to address extreme rural poverty. The underlying theme of both the CFPR/TUP programme and the <b>targeting</b> <b>methodology</b> used is an acknowledgement of the strength of combining different methods and approaches for greater effectiveness. This paper uses programme data emerging out of its targeting exercise to assess questions of effectiveness of the approach used. [CFPR-TUP Working Paper Series No. 2]. poverty reduction, deprivation of opportunities, poor, Bangladesh, programme data,...|$|R
40|$|IvreaArray is a {{temporary}} broadband seismic network composed of 10 station operated from July 2017 {{for a minimum of}} 1 year. It is an AlpArray Complementary Experiment (www. alparray. ethz. ch). The goal of IvreaArray is to characterize the structure and physical properties of the Earth crust and lithosphere in the area of Val Sesia, Northern Italy. In particular, the Ivrea Geophysical Body is a prime <b>target.</b> <b>Methodologies</b> will include the calculation of receiver functions, tomographic images, local earthquakes, and other seismological studies. The attached file contains the coordinates of the installed stations. The FDSN-registered network code is XK. The data will be open to the public 3 years after the data acquisition is completed...|$|R
40|$|Abstract: There {{is little}} work on <b>targeted</b> <b>methodologies</b> to develop IT {{applications}} and content in a developing world environment. This paper argues for a methodology called Socially Aware Software Engineering {{that we are}} busy formulating based on firsthand experience building Information and Communication Technology solutions. Our method {{is based on a}} classical user-centred approach from Human Computer Interaction combined with aspects of Participatory Design and cyclical software engineering practises. These approaches are wrapped into an iterative Action Research paradigm in order to directly include the community-based users of our systems. I conclude with suggestions on changing the nature of tertiary curricula in developing countries in a way that integrates this socially aware software engineering methodology...|$|R
40|$|Mesenchymal {{stem cells}} (MSCs) are {{currently}} being widely investigated both in the lab and in clinical trials for multiple disease states. The differentiation, trophic, and immunomodulatory characteristics of MSCs contribute to their therapeutic effects. Another often overlooked factor related to efficacy is the degree of engraftment. When reported, engraftment is generally low and transient in nature. MSC delivery methods should be tailored to the lesion being treated, which may be local or systemic, and customized to the mechanism of action of the MSCs, which can also be local or systemic. Engraftment efficiency is enhanced by using intra-arterial delivery instead of intravenous delivery, thus avoiding the “first-pass” accumulation of MSCs in the lung. Several <b>methodologies</b> to <b>target</b> MSCs to specific organs are being developed. These cell <b>targeting</b> <b>methodologies</b> focus on the modification of cell surface molecules through chemical, genetic, and coating techniques to promote selective adherence to particular organs or tissues. Future improvements in <b>targeting</b> and delivery <b>methodologies</b> to improve engraftment are expected to improve therapeutic results, extend the duration of efficacy, and reduce the effective (MSC) therapeutic dose...|$|R
40|$|After {{reviewing}} the basic traits of inflation targeting monetary strategy, this short paper analysis {{the nature of}} the relationship between inflation targeting and international financial crisis. Once the global financial crisis broke out, many a voice started questioning the usefulness and viability of inflation targeting strategy in this new reality. While some of the criticism has been found justifiable, required alterations are neither so huge to discard the crucial effectiveness of flexible inflation <b>targeting</b> <b>methodology</b> and turn it into something completely different, nor any of the other known monetary strategies have had built in specs that would have enabled them to fare substantially better than inflation targeting in what it partially failed us through the global financial meltdown and subsequent recession...|$|R
40|$|This article {{describes}} the details underlying the targeting of a Nicaraguan anti-poverty program, emphasising the rationale for how it was designed and implemented. It offers, by way of example, a guide for targeting in an anti-poverty program, and highlights some of the potential tradeoffs. It {{then goes on to}} present a quantitative assessment of how well the program was able to target poor households. A combination of ad hoc and statistical procedures led to targeting that was effective, with undercoverage rates of 10 per cent or below and leakage rates of 15 per cent or below. This was {{in spite of the fact}} that the <b>targeting</b> <b>methodologies</b> used were imprecise at both the household and geographic levels. Copyright © 2008 John Wiley & Sons, Ltd. ...|$|R
50|$|The {{commission}} {{ended and}} assessed {{their work in}} 2006 and unanimously agreed that a second truth commission was needed after the elections of 2006 in hopes that with a more settled political climate, the new commission would be better positioned to more effectively tackle the issues. While the commission operated for 4 years, the final report was only 84 pages long. No concrete or substantive findings were reported and only general recommendations were proposed instead. Ongoing conflicts limited {{the ability to do}} any investigations, and thus no victims, perpetrators, or witnesses were included in the reports. Limited information about procedures, tasks, <b>targets,</b> <b>methodology</b> or impact where detailed. The commission's work was relatively restricted to mediating the political struggle between the various factions involved in the conflict.|$|R
40|$|The current Italian seismic {{catalogues}} {{are generally}} considered complete, {{as regards the}} destructive seismic events which occurred from the 17 th century onwards. In fact, research performed using <b>target</b> <b>methodologies</b> still reveal earthquakes of high intensity, not yet known to the seismological tradition. This {{is the case of}} an earthquake which occurred on 14 September 1780, which caused serious damage and victims in some towns of the Tyrrhenian coast of North-eastern Sicily (I 0, = VIII MCS). The information reported in an anonymous printed account was verified in the administrative records; this allowed a reconstruction of a macroseismic outline of great interest, which may make more precise the seismic hazard assessment in an area at high environmental risk due to the presence in Milazzo of an important chemico-industrial complex...|$|R
40|$|Abstract: While {{the social}} effects of Information Technology (IT) have {{received}} much attention {{there is very}} little work on <b>targeted</b> <b>methodologies</b> to develop IT applications and content in a developing world environment. This paper describes a methodology called Socially Aware Software Engineering we are busy formulating based on firsthand experience building Information and Communication Technology solutions. Our method is based on a classical user-centred approach from Human Computer Interaction combined with aspects of Participatory Design and cyclical software engineering practises. These approaches are wrapped into an iterative Action Research paradigm in order to directly include the community-based users of our systems. We outline three cases studies based on our evolving method. The paper concludes with suggestions on changing the nature of tertiary curricula in developing countries in a way that integrates this socially aware software engineering methodology...|$|R
40|$|This paper {{compares the}} dynamic {{consistency}} of <b>targeting</b> <b>methodologies</b> that use multidimensional welfare indicators with those based on means and proxy means tests using panel data from Mexico. To make these comparisons, {{an extension of}} the Alkire and Foster (2008) dual cutoff multidimensional poverty methodology is proposed. This extension provides a relative approach to multidimensional deprivation that ranks individuals according to an aggregate of their relative position in the distribution of a set of welfare attributes or outcomes. The extension gives particular importance to deprivations that affect smaller portions of the population, as these deprivations are especially critical in defining relative multidimensional welfare. The findings, disaggregated by geographical area (urban and rural), suggest that taking into account deprivation in multiple dimensions may lead to more dynamically consistent measures of well-being and thus more dynamically consistent targeting algorithms. ...|$|R
40|$|Nearly 70 % {{of process}} {{improvement}} projects {{are failing to}} provide the expected benefits (Grant 2002). The cost of process improvement projects can be quite substantial {{and the number of}} these projects occurring within organisations continues to increase. John Thorp (1998) describes an environment in which managers are struggling to demonstrate the connection between costs and expected business benefits. This eighteen month master's research project has identified a gap in both the academic literature and the business practices of most organisations. This thesis aims to make explicit the selection of processes to improve and to provide the link between process objectives and organisational goals (Davenport 1993; Hammer and Champy 1993). Published literature, coupled with the experience of the research team, has resulted {{in the development of a}} <b>targeting</b> <b>methodology</b> for defining and ranking critical processes, and then selecting which of those critical processes to improve first. Although the research team believes that the methodology is applicable to many industries, the research was undertaken in the application hosting centre (AHC) and application service provision (ASP) industry. A focus group and follow on Delphi study was used to ensure that the processes and functional area focused upon was of importance to the participants of the research. This research project was funded by the Australian Research Council's Linkage projects and undertaken with support by REALTECH. The participants included the top three information systems outsourcing companies in Australia and another in the top ten of this industry. The study commenced with identifying critical processes in the ASP environment. This involved both a focus group session and a Delphi study. The Delphi study was followed by four action learning cycles using case studies (action, observe, reflect and revise). These action learning cycles using case studies have revealed that the methodology (which includes the steps to implement the methodology) meets the needs of organisations to identify and select 'critical' processes for improvement. It provides business and researchers with a logical and explicit method to reduce the 'squeaky wheel' and 'latest fad' approaches to process improvement projects. These prior approaches improve processes not necessarily critical for achieving organisational goals consuming limited resources for little gain. The targeting method makes the alignment of process objectives with goals by explicitly linking processes to organisational goals possible. The limitations of this research project are that it does not intend to verify the achievement of business benefit, document the change to an organisation due to its use of the <b>targeting</b> <b>methodology</b> or determine the long term benefits to an organisation using the <b>targeting</b> <b>methodology.</b> These questions might be answered in a longer and larger study as this project is limited to an eighteen month time frame. As for generalisability, the study has focused on the AHC and ASP industries, and the participants, while operating within this industry, are quite different. For the different phases of this project the participants come from in-house providers, multinational outsourcing providers, commercialised government providers, specialist niche product providers, and enterprise system suppliers...|$|R
40|$|Copyright © 2013 Thomas J. Kean et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Mesenchymal stem cells (MSCs) are currently being widely investigated both in the lab and in clinical trials for multiple disease states. The differentiation, trophic, and immunomodulatory characteristics ofMSCs contribute to their therapeutic effects. Another often overlooked factor related to efficacy is the degree of engraftment. When reported, engraftment is generally low and transient in nature. MSC delivery methods should be tailored to the lesion being treated, which may be local or systemic, and customized to themechanism of action of theMSCs, which can also be local or systemic. Engraftment efficiency is enhanced by using intra-arterial delivery instead of intravenous delivery, thus avoiding the “first-pass ” accumulation of MSCs in the lung. Several <b>methodologies</b> to <b>target</b> MSCs to specific organs are being developed. These cell <b>targeting</b> <b>methodologies</b> focus on the modification of cell surface molecules through chemical, genetic, and coating techniques to promote selective adherence to particular organs or tissues. Future improvements in <b>targeting</b> and delivery <b>methodologies</b> to improve engraftment are expected to improve therapeutic results, extend the duration of efficacy, and reduce the effective (MSC) therapeutic dose. 1...|$|R
40|$|We {{demonstrate}} proof-of-concept {{for the use}} of massively multiplexed PCR and {{next-generation sequencing}} (mmPCR-NGS) to identify both clonal and subclonal copy-number variants (CNVs) in circulating tumor DNA. This is the first report of a <b>targeted</b> <b>methodology</b> for detection of CNVs in plasma. Using an in vitro model of cell-free DNA, we show that mmPCR-NGS can accurately detect CNVs with average allelic imbalances as low as 0. 5 %, an improvement over previously reported whole-genome sequencing approaches. Our method revealed differences in the spectrum of CNVs detected in tumor tissue subsections and matching plasma samples from 11 patients with stage II breast cancer. Moreover, we showed that liquid biopsies are able to detect subclonal mutations that may be missed in tumor tissue biopsies. We anticipate that this mmPCR-NGS methodology will have broad applicability for the characterization, diagnosis, and therapeutic monitoring of CNV-enriched cancers, such as breast, ovarian, and lung cancer...|$|R
40|$|This project funded since 1986 {{serves as}} a core project for cancer {{research}} throughout MSKCC, producing key radiotracers as well as basic knowledge about thel physics of radiation decay and imaging, for nuclear medicine applications to cancer diagnosis and therapy. In recent years this research application has broadened to include experiments intended to lead to an improved understanding of cancer biology and into the discovery and testing of new cancer drugs. Advances in immune based radiotargeting {{form the basis for}} this project. Both antibody and cellular based immune targeting methods have been explored. The multi-step <b>targeting</b> <b>methodologies</b> (MST) developed by NeoRex (Seattle,Washington), have been adapted for use with positron emitting isotopes and PET allowing the quantification and optimization of targeted delivery. In addition, novel methods for radiolabeling immune T-cells with PET tracers have advanced our ability to track these cells of prolonged period of time...|$|R
40|$|The International Sun-Earth Explorer- 3 (ISEE- 3) {{was moved}} from its mission halo orbit {{upstream}} of the earth's magnetosphere on June 10, 1982. Multiple lunar swingby maneuvers were {{then used to}} shape the trajectory for extensive exploration of the distant geomagnetic tail and finally to place the spacecraft on a course that will intercept the comet Giacobini-Zinner on September 11, 1985. With this new mission objective, the spacecraft was renamed the International Cometary Explorer (ICE). A double-lunar-swingby control technique involving five passes by the moon was eventually implemented to accomplish this, {{but in the process}} of finding this solution several feasible, though less optimal, alternative trajectory sequences implementing the same procedure were discovered. This paper provides a descriptive comparison of these very different orbital profiles and serves to illustrate the utility and great flexibility of this orbital control procedure. <b>Targeting</b> <b>methodology</b> for finding constrained solutions in this space is also presented...|$|R
40|$|While {{the social}} effects of Information Technology (IT) have {{received}} much attention {{there is very}} little work on <b>targeted</b> <b>methodologies</b> to develop IT applications and content in a developing world environment. This paper describes a methodology called Socially Aware Software Engineering we are busy formulating based on firsthand experience building Information and Communication Technology solutions. Our method is based on a classical user-centred approach from Human Computer Interaction combined with aspects of Participatory Design and cyclical software engineering practises. These approaches are wrapped into an iterative Action Research paradigm in order to directly include the community-based users of our systems. We outline three cases studies based on our evolving method. The paper concludes with suggestions on changing the nature of tertiary curricula in developing countries in a way that integrates this socially aware software engineering methodology. Telkom, Cisco, Siemens, THRIP, NRFDepartment of HE and Training approved lis...|$|R
40|$|A genetic {{approach}} has been established that combines the advantages of blastocyst complementation with the experimental attributes of the developing lens for the functional analysis of genes governing cellular proliferation, terminal differentiation, and apoptosis. This lens complementation system (LCS) makes use of a mutant mouse strain, aphakia (ak), homozygotes of which fail to develop an ocular lens. We demonstrate that microinjection of wild-type embryonic stem (ES) cells into ak/ak blastocysts produces chimeras with normal ES-cell-derived lenses and that microinjection of Rb-/- ES cells generates an aberrant lens phenotype identical to that obtained through conventional gene <b>targeting</b> <b>methodology.</b> Our determination that a cell autonomous defect underlies the aphakia condition assures that lenses generated through LCS are necessarily ES-cell-derived. LCS provides for the rapid phenotypic analysis of loss-of-function mutations, circumvents the need for germ-line transmission of null alleles, and, most significantly, facilitates the study of essential genes whose inactivation is associated with early lethal phenotypes...|$|R
50|$|Counter-network {{operations}} usually {{focus on}} leadership targeting of an organization, which follows the logic that by catching the right hornet, the whole colony dies. What is often overlooked in this approach, however, {{is that if}} just a worker bee is killed, the nest is aggravated and a much bigger problem is created. While this concept provides a convenient metaphor to discuss possible <b>targeting</b> <b>methodology,</b> it seldom resembles the facts, because human networks are not directly analogous to a hornet’s nest. In other words, not every situation can be resolved by a single kill or capture of the “queen”. Activity {{is focused on the}} critical vulnerabilities of the IED System, for example, by denying the supply of components, finance, leaders, specialists and recruits and adversary exploitation and isolating the adversary from the local population. AtN/CTN seeks to 1) shape and influence IED networks, 2) disrupt their operations, and 3) undermine their financiers and supply chains.|$|R
