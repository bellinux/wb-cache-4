176|1598|Public
2500|$|The DCT {{is used in}} JPEG image compression, MJPEG, MPEG, DV, Daala, and Theora video compression. There, the {{two-dimensional}} DCT-II of [...] blocks are computed and {{the results}} are quantized and entropy coded. In this case, [...] is typically 8 and the DCT-II formula is applied to each row and column of the block. The result is an 8 × 8 <b>transform</b> <b>coefficient</b> array in which the [...] element (top-left) is the DC (zero-frequency) component and entries with increasing vertical and horizontal index values represent higher vertical and horizontal spatial frequencies.|$|E
50|$|Persistent Rice adaptation, using a Rice coding {{parameter}} derivation for entropy coding that has memory that persists across <b>transform</b> <b>coefficient</b> sub-block boundaries.|$|E
5000|$|Context-adaptive variable-length coding (CAVLC), {{which is}} a lower-complexity {{alternative}} to CABAC for the coding of quantized <b>transform</b> <b>coefficient</b> values. Although lower complexity than CABAC, CAVLC is more elaborate and more efficient than the methods typically used to code coefficients in other prior designs.|$|E
40|$|Abstract. A new {{transform}} coder for arbitrarily shaped {{regions in}} ultrasonic data is proposed. In the encoder, a block-based DCT(Discrete Cosine Transform) {{is applied to}} the resulting image block after shifting pixels within the image segment to block border and padding the mean value of the pixels to empty region. For reducing the transmission bit rate, the <b>transform</b> <b>coefficients</b> located in padded region are truncated and only the remaining <b>transform</b> <b>coefficients</b> are transmitted to the decoder. In the decoder, the <b>transform</b> <b>coefficients</b> truncated in the encoder are recovered using received <b>transform</b> <b>coefficients</b> and a block-based inverse DCT is performed...|$|R
40|$|The present {{invention}} {{provides a}} system and method for compression of image data while preserving the usable information and eliminating or reducing associated noise {{in which the}} image data includes a signal and noise. The image data is transformed using a multiscale transform technique (such as the Pyramidal Median Transform) such that the image data is represented as a plurality of <b>transform</b> <b>coefficients</b> each having a corresponding weight. From the respective weights, those <b>transform</b> <b>coefficients</b> associated with noise are determined and extracted from the original plurality of <b>transform</b> <b>coefficients.</b> The remaining <b>transform</b> <b>coefficients</b> are subsequently quantized and coded...|$|R
30|$|F(p,[*]q): Fourier <b>transforms</b> <b>coefficients</b> off f(m,[*]n).|$|R
5000|$|Spatial {{prediction}} {{from the}} edges of neighboring blocks for [...] "intra" [...] coding, rather than the [...] "DC"-only prediction found in MPEG-2 Part 2 and the <b>transform</b> <b>coefficient</b> prediction found in H.263v2 and MPEG-4 Part 2. This includes luma prediction block sizes of 16×16, 8×8, and 4×4 (of which only one type can be used within each macroblock).|$|E
5000|$|Technology {{improvements}} can {{be found}} in the designs of H.263v2 Annex I and MPEG-4 Part 2, that use frequency-domain prediction of <b>transform</b> <b>coefficient</b> values, and in H.264/MPEG-4 AVC, that use spatial prediction and adaptive transform block size techniques. There are also more sophisticated entropy coding than what was practical when the first JPEG design was developed. All of these new developments make M-JPEG an inefficient recording mechanism.|$|E
5000|$|Binarization: CABAC uses Binary Arithmetic Coding {{which means}} that only binary {{decisions}} (1 or 0) are encoded. A non-binary-valued symbol (e.g. a <b>transform</b> <b>coefficient</b> or motion vector) is [...] "binarized" [...] or converted into a binary code prior to arithmetic coding. This process {{is similar to the}} process of converting a data symbol into a variable length code but the binary code is further encoded (by the arithmetic coder) prior to transmission.|$|E
30|$|Apply {{a fusion}} rule onto the <b>transform</b> <b>coefficients.</b>|$|R
5000|$|Daala is transform-based but uses vector {{quantization}} on <b>transformed</b> <b>coefficients</b> ...|$|R
3000|$|LSF matrices. In {{contrast}} to the present study, the resulting <b>transform</b> <b>coefficients</b> are directly quantized using scalar quantization (after being normalized though). Bit allocation tables, <b>transform</b> <b>coefficients</b> mean and variance, and optimal (non-uniform) scalar quantizers are determined during a training phase applied on a training corpus of data (see Section 4.2): Bit allocation among the set of <b>transformed</b> <b>coefficients</b> is determined from their variance [32] and the quantizers are designed using the LBG algorithm [33] (see [18, 19] for details). This is done for each considered temporal size K, and for a large range of bit rates (see Section 4.4).|$|R
5000|$|The DCT {{is used in}} JPEG image compression, MJPEG, MPEG, DV, Daala, and Theora video compression. There, the {{two-dimensional}} DCT-II of [...] blocks are computed and {{the results}} are quantized and entropy coded. In this case, [...] is typically 8 and the DCT-II formula is applied to each row and column of the block. The result is an 8 × 8 <b>transform</b> <b>coefficient</b> array in which the [...] element (top-left) is the DC (zero-frequency) component and entries with increasing vertical and horizontal index values represent higher vertical and horizontal spatial frequencies.|$|E
50|$|The DCT {{is used in}} JPEG image compression, MJPEG, MPEG, DV, Daala, and Theora video compression. There, the {{two-dimensional}} DCT-II of NxN blocks are computed and {{the results}} are quantized and entropy coded. In this case, N is typically 8 and the DCT-II formula is applied to each row and column of the block. The result is an 8x8 <b>transform</b> <b>coefficient</b> array in which the: (0,0) element (top-left) is the DC (zero-frequency) component and entries with increasing vertical and horizontal index values represent higher vertical and horizontal spatial frequencies, as shown in the picture on the right.|$|E
3000|$|Since each integer <b>transform</b> <b>coefficient</b> is {{quantized}} independently by a {{quantization step}} size, minimizing the MSE {{subject to the}} constraints specified in (9) is equivalent to minimizing the distortion caused by each integer <b>transform</b> <b>coefficient.</b> In {{order to have a}} quantization that better fits to a nonuniform distribution of the integer <b>transform</b> <b>coefficient</b> over the QCS, H. 264 /AVC decoder uses the rounding control parameter [...]...|$|E
40|$|In this paper, {{we present}} a fast intra {{prediction}} method based on separating the <b>transformed</b> <b>coefficients.</b> The prediction block {{can be obtained from}} the transformed and quantized neighboring block generating minimum distor-tion for each DC and AC coefficients independently. Two prediction methods are proposed, one is full block search prediction (FBSP) and the other is edge based distance prediction (EBDP), that find the best matched <b>transformed</b> <b>coefficients</b> on additional neighboring blocks. Experimental results show that the use of <b>transform</b> <b>coefficients</b> greatly enhances the efficiency of intra prediction whilst keeping complexity low compared to H. 264 /AVC. I...|$|R
30|$|The H. 264 /AVC encoder {{performs}} intra/interpredictions to get {{the residual}} and then transforms this data into frequency domain as <b>transform</b> <b>coefficients.</b> Besides, QP relates to quantization operation and also influences residual data. Therefore, we take {{the relationship of the}} bit-rate, the number of non-zero <b>transform</b> <b>coefficients</b> (NZTC), and the QP into consideration to find the bit-rate conversion models.|$|R
40|$|We {{consider}} {{the use of}} quantized block <b>transform</b> <b>coefficients</b> to the image database retrieval problem. Based on the <b>transform</b> <b>coefficients</b> feature vectors are constructed. These feature vectors are used in histograms and combination of histograms with similarity measure for database retrieval. Experiments on public face image database show good performance of the approach in comparison with other methods. 1...|$|R
30|$|Equation (11) {{shows that}} by having {{multiple}} compressed copies, {{the size of}} the QCS for each integer <b>transform</b> <b>coefficient</b> can likely be reduced. The reduction in QCS size allows us to estimate a more accurate integer <b>transform</b> <b>coefficient</b> and thus reconstruct a video frame with a lower distortion. Ideally, we can obtain the exact integer <b>transform</b> <b>coefficient</b> if the QCS becomes a scalar, a scenario that rarely occurs. Hence, we propose in this paper to reconstruct each integer <b>transform</b> <b>coefficient</b> by using the corresponding narrow QCS and justify that by doing so the constraints in (9) can be satisfied.|$|E
40|$|Abstract—This paper {{describes}} <b>transform</b> <b>coefficient</b> coding in {{the draft}} international standard of High Efficiency Video Coding (HEVC) specification and the driving motivations behind its design. <b>Transform</b> <b>coefficient</b> coding in HEVC encompasses the scanning patterns and coding methods for the last significant coefficient, significance map, coefficient levels, and sign data. Special {{attention is paid to}} the new methods of last significant coefficient coding, multilevel significance maps, high-throughput binarization, and sign data hiding. Experimental results are provided to evaluate the performance of <b>transform</b> <b>coefficient</b> coding in HEVC. Index Terms—High Efficiency Video Coding (HEVC), high throughput entropy coder, <b>transform</b> <b>coefficient</b> coding, video coding. I...|$|E
30|$|Obtain {{the narrow}} QCS for each integer <b>transform</b> <b>coefficient</b> from the {{multiple}} copies using (11).|$|E
5000|$|The Haar <b>transform</b> <b>coefficients</b> of a n=4-point signal [...] can {{be found}} as ...|$|R
3000|$|... 2) are <b>transformed</b> <b>coefficients</b> after {{applying}} Fibonacci-Lucas transform. M is size {{of original}} image.|$|R
30|$|Our {{approach}} to {{unequal error protection}} is also based on Wyner-Ziv coding and is motivated by the SLEP approach. The overall goal of our schemes is to correct errors in each frame by protecting motion information and the <b>transform</b> <b>coefficients.</b> The primary codec is an H. 264 /AVC codec and the Wyner-Ziv codec utilizes coarse quantization and a Turbo codec. Instead of protecting everything associated with the coarsely reconstructed frames, we separately protect motion information, and <b>transform</b> <b>coefficients</b> produced by the primary H. 264 encoder. The idea being that since the loss of motion information impacts the quality of decoded video differently {{from the loss of}} <b>transform</b> <b>coefficients,</b> both should receive unequal levels of protection that are commensurate with their respective contributions {{to the quality of the}} video reconstructed by the decoder [21]. The motion information is protected via Turbo coding whereas the <b>transform</b> <b>coefficients</b> are protected via Wyner-Ziv coding. This approach is referred to as unequal error protection using Pseudo Wyner-Ziv (UEPWZ) coding.|$|R
40|$|In recent years, several {{lossless}} {{data hiding}} techniques {{have been proposed}} for images. Lossless data embedding can {{take place in the}} spatial domain or in the transform domain. They utilized characteristics of the difference image or the <b>transform</b> <b>coefficient</b> histogram and modify these values slightly to embed the data. However, after embedding message bits these steganography changed the nature of the difference image histogram or the <b>transform</b> <b>coefficient</b> histogram gradually. In this paper, we introduce two new steganalytic techniques based on the difference image histogram and the <b>transform</b> <b>coefficient</b> histogram. The algorithm can not only detect existence of secret messages in images which are embedded by above methods reliably, but also estimate the amount of hidden messages exactly...|$|E
30|$|Reconstruct each integer <b>transform</b> <b>coefficient</b> as the {{centroid}} {{of the narrow}} QCS obtained in Step 2 using (14).|$|E
3000|$|... is {{the vector}} of samples observed. θ is the <b>transform</b> <b>coefficient</b> vector of signal x under {{orthonormal}} basis ψ, i.e., [...]...|$|E
40|$|We {{explore the}} <b>transform</b> <b>coefficients</b> of various fractalbased schemes for {{statistical}} dependence and exploit correlations {{to improve the}} compression capabilities of these schemes. In most of the standard fractal-based schemes, the <b>transform</b> <b>coefficients</b> exhibit a degree of linear dependence that can be exploited by using an appropriate vector quantizer such as the LBG algorithm. Additional compression is achieved by lossless Huffman coding of the quantized coefficients...|$|R
3000|$|..., and {{the lengths}} of the parity bits packets {{containing}} the motion {{information and the}} <b>transform</b> <b>coefficients</b> are [...]...|$|R
3000|$|..., {{then the}} probabilities of the packet {{loss of the}} motion {{information}} and the <b>transform</b> <b>coefficients</b> packets are [...]...|$|R
3000|$|... }. In WZ-TC, {{a linear}} {{transform}} is first applied to X and each {{component of the}} <b>transform</b> <b>coefficient</b> vector U = T [...]...|$|E
3000|$|... be {{a random}} {{variable}} representing an integer <b>transform</b> <b>coefficient,</b> {{which can be}} either uniform (for a DC coefficient) or Laplacian/Cauchy (for an AC coefficient).|$|E
3000|$|... is {{the exact}} value of the residual's <b>transform</b> <b>coefficient</b> and such {{division}} is to combine the scaling step of transform with the subsequent quantization. The parameter [...]...|$|E
40|$|This work is {{intended}} to give some ideas to extract motion information from an image sequence. A directional energy is {{defined in terms of}} the 1 -D Hermite <b>transform</b> <b>coefficients</b> of local projections. Each projection is described by the Hermite transform resulting in a directional derivative analysis of the input at a given scale. Gaussian-derivative operators have long been used in computer vision for feature extraction and are relevant in visual system modeling. We demonstrate that the Hermite <b>transform</b> <b>coefficients</b> of local projections are readily computed as a linear mapping of the 3 -D Hermite <b>transform</b> <b>coefficients</b> through some projecting functions. The directional response is used to detect spatiotemporal patterns that are 1 -D or 2 -D. Practical consideration and experimental results are also of concern. 1...|$|R
3000|$|... blocks, {{where the}} motion {{characteristics}} of the block can be effectively predicted from the motion of its neighboring blocks, and the quantized <b>transform</b> <b>coefficients</b> of the block are all zeros. When a block is skipped, the <b>transformed</b> <b>coefficients</b> and the motion data are not transmitted, since {{the motion of the}} block is equivalent to the median of the motion vectors of the surrounding blocks. This median is known as the predicted motion vector ([...] [...]...|$|R
30|$|The Turbo decoder {{utilizes}} the received parity {{bits and}} the side information from the H. 264 /AVC decoder, to perform the iterative decoding using two BCJR-MAP decoders [27]. The error corrected information is then {{sent back to the}} H. 264 /AVC decoder to replace the error corrupted data. In this process, the decoded error-prone <b>transform</b> <b>coefficients</b> are first sent to a coarse quantizer, which {{is the same as the}} one used at the Pseudo Wyner-Ziv encoder side. The reason is that at the encoder side, in order to save data rate usage by the Wyner-Ziv coding, a coarse version of the <b>transform</b> <b>coefficients</b> is Turbo encoded. However, Only the output parity bits are transmitted to the decoder side. The video data u output from the Turbo encoder is not transmitted. Instead, the H. 264 decoded <b>transform</b> <b>coefficients</b> are used as it, together with the received parity bits of the Turbo encoded coarse-version <b>transform</b> <b>coefficients,</b> to decode the error corrected coarse version of the <b>transform</b> <b>coefficients.</b> When using the real-time transport protocol (RTP), packet loss can be inferred at the decoder easily by checking the sequence number field in the RTP headers. Wyner-Ziv decoding only performs when the decoder detects packet losses. When no packet loss happens, the H. 264 decoded <b>transform</b> <b>coefficients</b> are used for decoding the residual frames. However, when packet loss happens, the coarser version of the <b>transform</b> <b>coefficients</b> decoded by the Turbo decoder is used to limit the maximum degradation that can occur. In the parallel process, the error corrupted motion information received by the H. 264 /AVC decoder was sent directly to the corresponding Turbo decoder, together with the received corresponding parity bits, to decode the error corrected motion information. It is then sent back to the H. 264 /AVC decoder to replace the error-corrupted motion information. The reconstructed frames can be further used as the reference frames in the following decoding process. Therefore, the final version of the decoded video sequence are obtained based on the error corrected motion information and the <b>transform</b> <b>coefficients,</b> which resulted in good quality decoded frames as shown in Section 4. However, in the case of serious channel loss and/or limited available data rate for error protection, the Pseudo Wyner-Ziv coder might not have enough strength to recover all the lost video information. Also there is no fall back mechanism in use to ensure the correct turbo decoding. On this point, the UEPWZ takes the advantage of allocating different protection level on different protected video data elements depending on their overall impact on the decoded video sequence. The experiments showed that by assigning unequal data rate for protecting motion information and the <b>transform</b> <b>coefficients,</b> the rate distortion performance can be improved compared to the equal parity data rate allocation case.|$|R
