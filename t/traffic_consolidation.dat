10|3|Public
30|$|A {{considerable}} amount of investigation and research for achieving a green data center have been conducted in both academia and industry due to its great potential and benefits. Apart from the works on green/renewable resources [12 - 14], low-power hardware [15 - 18], energy-efficient network architecture [4, 19 - 23], and network virtualization techniques (VM migration and placement optimization) [24, 25], there are also many network-level proposals, which focus on <b>traffic</b> <b>consolidation.</b> The typical representatives include ElasticTree [5], and Energy-aware Routing Model [26].|$|E
40|$|In this paper, we {{estimate}} alternative specifications of the Spanish airports' cost function {{with the objective}} to provide a comparative analysis on several technological features such as output-specific marginal costs, economies of scale, and the Allen elasticities of substitution. We found evidence of significant and unexhausted scale economies as well as technological development in the Spanish airport industry. The results suggest that <b>traffic</b> <b>consolidation</b> in multi-airport {{areas such as the}} Basque Country or Catalonia will result in lower costs for the public operator. Airports' cost function Marginal costs Scale economies Translog system...|$|E
40|$|In {{this paper}} we study the {{behavior}} of a general optimization model for reducing the power consumption of core networks employing energy-aware network equipment. Specifically, we assess how the energy profiles of the devices affect the outcome of the optimization model and hence determine the general power saving policy. The computational analysis performed on several real topologies shows that the widespread <b>traffic</b> <b>consolidation</b> strategy does not always provide the best results. In fact, for devices presenting a cubic (convex in general) energy profile, the highest energy savings are achieved by spreading the traffic on the network...|$|E
40|$|The study {{outlined}} {{the volume of}} agricultural traffic and the possibilities of reducing the <b>traffic</b> by land <b>consolidation.</b> Further, the study investigated the total load caused to the village road network by agricultural traffic and the possibilities of analysing the future changes. The initial material for the study {{was obtained from the}} Finnish Land Parcel Identificatio...|$|R
5000|$|AirAsia {{planned to}} begin {{operations}} to various tier 2 and tier 3 cities with Chennai International Airport as its main operating base. According to KPMG, {{the introduction of}} AirAsia was expected to cause another price war, ultimately leading {{to an increase in}} air <b>traffic</b> and some <b>consolidation</b> in the Indian aviation sector. AirAsia initially invested an amount of 50 million and in preparation for its operations in India, it struck deals with online and offline travel agents. On 3 March 2013, the FIPB officially permitted AirAsia to rent or lease aircraft and to carry cargo on its scheduled flights. The airline then applied for permission to schedule aircraft and transport passengers, which the FIPB accepted on 6 March.|$|R
40|$|Abstract—Cluster-based storage systems {{increasingly}} use commodity communication technologies, such as Fibre Channel over Ethernet (FCoE), for accessing {{stored data}} over the network. Data is striped over multiple storage nodes, and storage traffic often shares the network with non-storage traffic. In such conditions, storage clients can experience severely degraded performance, such as TCP throughput collapse and network congestion due to competing network <b>traffic.</b> Furthermore, <b>consolidation</b> of multiple virtual machines (VMs) onto fewer physical nodes can worsen {{the performance of}} network storage systems. The root cause of this performance problem is that network traffic from multiple sources can cause transient overloads in the switch buffers. In this paper, we {{make the case that}} virtualization opens up a new set of opportunities to alleviate and solve such performance problems experienced by network storage in particular, and data center Ethernet in general. We present an architecture, called XCo, for explicit coordination of network traffic among VMs in a data center Ethernet that is inexpensive, fully transparent, currently feasible, and complementary to any switch-level hardware support. We present experimental evidence via proofof-concept implementation and evaluation to support this claim and describe the challenges and opportunities in a complete solution. I...|$|R
40|$|The paper deeply {{analyzes}} a novel network-wide {{power management}} problem, called Power-Aware Routing and Network Design with Bundled Links (PARND-BL), which {{is able to}} take into account both the relationship between the power consumption and the traffic throughput of the nodes and to power off both the chassis and even the single Physical Interface Card (PIC) composing each link. The solutions of the PARND-BL model have been analyzed by taking into account different aspects associated with the actual applicability in real network scenarios: (i) the time for obtaining the solution, (ii) the deployed network topology and the resulting topology provided by the solution, (iii) the power behavior of the network elements, (iv) the traffic load, (v) the QoS requirement, and (vi) the number of paths to route each traffic demand. Among the most interesting and novel results, our analysis shows that the strategy of minimizing the number of powered-on network elements through the <b>traffic</b> <b>consolidation</b> does not always produce power savings, and the solution of this kind of problems, in some cases, can lead to spliting a single traffic demand into a high number of paths...|$|E
40|$|Abstract—Energy {{consumption}} {{is becoming the}} Achilles ’ heel of the mobile user quality of experience partly due to undisciplined use of the cellular (3 G) transmissions by applications. The operator infrastructure is typically configured for peak performance, whereas during periods of underutilisation the handsets pay the price by staying in high energy states even if each application only uses {{a fraction of the}} maximum available bandwidth. In this paper we promote a bi-radio scenario where instead of independently using own cellular connections, several users share a single cellular link offered by one member of a coalition (a rotating aggregator). We present Watts 2 Share, an architecture for energy-aware <b>traffic</b> <b>consolidation</b> whereby group members’ data flows transmitted through a second radio (e. g., WiFi) are aggregated by the aggregator and retransmitted through the cellular link. Through careful and repeatable studies we demonstrate that this scheme saves up to 68 % of the total transmission energy in handsets compared to a pure 3 G scenario. The studies are based {{on a wide range of}} real traffic traces and real cellular operator settings, and further illustrate that this scheme reduces the overall energy by reducing the signalling overhead, as well as extending the lifetime of all handsets. Index Terms—traffic consolidation; bandwidth sharing; 3 G; WiFi; SoftAP...|$|E
40|$|Energy {{consumption}} {{is becoming the}} Achilles' heel of the mobile user quality of experience partly due to undisciplined use of the cellular (3 G) transmissions by applications. The operator infrastructure is typically configured for peak performance, whereas during periods of underutilisation the handsets pay the price by staying in high energy states even if each application only uses {{a fraction of the}} maximum available bandwidth. In this paper we promote a bi-radio scenario where instead of independently using own cellular connections, several users share a single cellular link offered by one member of a coalition (a rotating aggregator). We present Watts 2 Share, an architecture for energy-aware <b>traffic</b> <b>consolidation</b> whereby group members' data flows transmitted through a second radio (e. g., WiFi) are aggregated by the aggregator and retransmitted through the cellular link. Through careful and repeatable studies we demonstrate that this scheme saves up to 68 % of the total transmission energy in handsets compared to a pure 3 G scenario. The studies are based {{on a wide range of}} real traffic traces and real cellular operator settings, and further illustrate that this scheme reduces the overall energy by reducing the signalling overhead, as well as extending the lifetime of all handsets...|$|E
40|$|It is {{significant}} to apply load-balancing strategy {{to improve the}} performance and reliability of resource in data centers. One of the challenging scheduling problems in Cloud data centers {{is to take the}} allocation and migration of reconfigurable virtual machines (VMs) as well as the integrated features of hosting physical machines (PMs) into consideration. In the reservation model, the workload of data centers has fixed process interval characteristics. In general, load-balance scheduling is NP-hard problem as proved in many open literatures. Traditionally, for offline load balance without migration, one of the best approaches is LPT (Longest Process Time first), which is well known to have approximation ratio 4 / 3. With virtualization, reactive (post) migration of VMs after allocation is one popular way for load balance and <b>traffic</b> <b>consolidation.</b> However, reactive migration has difficulty to reach predefined load balance objectives, and may cause interruption and instability of service and other associated costs. In view of this, we propose a new paradigm, called Prepartition, it proactively sets process-time bound for each request on each PM and prepares in advance to migrate VMs to achieve the predefined balance goal. Prepartition can reduce process time by preparing VM migration in advance and therefore reduce instability and achieve better load balance as desired. We also apply the Prepartition to online (PrepartitionOn) load balance and compare it with existing online scheduling algorithms. Both theoretical and experimental results are provided. Comment: 12 pages, 11 figure...|$|E
40|$|Abstract. Power {{optimization}} {{has become}} a key challenge {{in the design of}} large-scale enterprise data centers. Existing research efforts focus mainly on computer servers to lower their energy consumption, while only few studies have tried to address the energy consumption of data center networks (DCNs), which can account for 20 % of the total energy consumption of a data center. In this paper, we propose CARPO, a correlation-aware power optimization algorithm that dynamically consolidates traffic flows onto a small set of links and switches in a DCN and then shuts down unused network devices for en-ergy savings. In sharp contrast to existing work, CARPO is designed based on a key observation from the analysis of real DCN traces that the bandwidth demands of different flows do not peak at exactly the same time. As a result, if the correlations among flows are considered in consolidation, more energy sav-ings can be achieved. In addition, CARPO integrates <b>traffic</b> <b>consolidation</b> with link rate adaptation for maximized energy savings. We implement CARPO on a hardware testbed composed of 10 virtual switches configured with a pro-duction 48 -port OpenFlow switch and 8 servers. Our empirical results with Wikipedia traces demonstrate that CARPO can save up to 46 % of network energy for a DCN, while having only negligible delay increases. CARPO also outperforms two state-of-the-art baselines by 19. 6 % and 95 % on energy sav-ings, respectively. Our simulation results with 61 flows also show the superior energy efficiency of CARPO over the baselines. 2...|$|E
40|$|Present-day {{datacenter}} networks (DCNs) {{are designed}} to achieve full bisection bandwidth {{in order to provide}} high network throughput and server agility. However, the average utilization of typical DCN infrastructure is below 10 % for significant time intervals. As a result, energy is wasted during these periods. In this thesis we analyze traffic behavior of datacenter networks using traces as well as simulated models. Based on the insight developed, we present techniques to reduce energy waste by making energy use scale linearly with load. The solutions developed are analyzed via simulations, formal analysis, and prototyping. The impact of our work is significant because the energy savings we obtain for networking infrastructure of DCNs are near optimal. A key finding of our traffic analysis is that network switch ports within the DCN are grossly under-utilized. Therefore, the first solution we study is to modify the routing within the network to force most traffic to the smallest of switches. This increases the hop count for the traffic but enables the powering off of many switch ports. The exact extent of energy savings is derived and validated using simulations. An alternative strategy we explore in this context is to replace about half the switches with fewer switches that have higher port density. This has the effect of enabling even greater <b>traffic</b> <b>consolidation,</b> thus enabling even more ports to sleep. Finally, we explore a third approach in which we begin with end-to-end traffic models and incrementally build a DCN topology that is optimized for that model. In other words, the network topology is optimized for the potential use of the datacenter. This approach makes sense because, as other researchers have observed, the traffic in a datacenter is heavily dependent on the primary use of the datacenter. A second line of research we undertake is to merge traffic in the analog domain prior to feeding it to switches. This is accomplished by use of a passive device we call a merge network. Using a merge network enables us to attain linear scaling of energy use with load regardless of datacenter traffic models. The challenge in using such a device is that layer 2 and layer 3 protocols require a one-to-one mapping of hardware addresses to IP (Internet Protocol) addresses. We overcome this problem by building a software shim layer that hides the fact that traffic is being merged. In order to validate the idea of a merge network, we build a simple mere network for gigabit optical interfaces and demonstrate correct operation at line speeds of layer 2 and layer 3 protocols. We also conducted measurements to study how traffic gets mixed in the merge network prior to being fed to the switch. We also show that the merge network uses only a fraction of a watt of power, which makes this a very attractive solution for energy efficiency. In this research we have developed solutions that enable linear scaling of energy with load in datacenter networks. The different techniques developed have been analyzed via modeling and simulations as well as prototyping. We believe that these solutions can be easily incorporated into future DCNs with little effort...|$|E

