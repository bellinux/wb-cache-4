910|0|Public
25|$|With {{the ability}} to deeply embed Informix in {{gateways}} and routers, <b>timeseries</b> support, small footprint, and low administration requirements, Informix is also targeted at Internet-of-Things solutions, {{where many of the}} data-handling requirements can be handled with gateways that embed Informix and connect sensors and devices to the internet.|$|E
2500|$|Informix <b>TimeSeries</b> is {{a unique}} feature of the {{database}} system that allows for efficient and fast manipulation of time series data, such as that generated by devices such as smart electric meters, or as found in financial trading systems with time stamped stock 'ticks'. [...] This type of data is not well suited to storage or use in the normal SQL supported style of data organization.|$|E
50|$|IBM's Informix {{which is}} an {{extensible}} Object Relational database system includes a <b>timeseries</b> data type extension which includes optimized <b>timeseries</b> storage, a <b>timeseries</b> specific function library, {{and the ability to}} map <b>timeseries</b> data to virtual tables in relational format. This gives it the ability to process standard SQL constructs such as GROUP BY and analytical functions against <b>timeseries</b> data.|$|E
5000|$|... #Caption: Atlantic Multidecadal Oscillation <b>Timeseries,</b> 1856-2013 ...|$|E
5000|$|... #Caption: Atlantic basin cyclone {{intensity}} by Accumulated cyclone energy, <b>timeseries</b> 1850-2014 ...|$|E
5000|$|... 1997 - Soliton {{develops}} TimeSquare, a <b>timeseries</b> database with an SQL-like syntax ...|$|E
5000|$|... #Caption: 3-D cutout from an x/y/t {{satellite}} image <b>timeseries</b> datacube of approx. 10,000 AVHRR images ...|$|E
5000|$|Example: “A slice {{through an}} x/y/t <b>timeseries</b> at {{position}} t=100, retrieving all available data in x and y.”A*:*,*:*,100 ...|$|E
50|$|Surface Movement: Based on <b>timeseries</b> {{acquired}} by TerraSAR-X {{over the same}} area surface displacements caused by subsurface mining, oil-/gas extraction, infrastructure construction, excavations, or underground engineering can be visualised.|$|E
50|$|Misra has {{researched}} many {{electrical engineering}} topics in signal processing algorithms, <b>timeseries</b> data, knowledge graphs, dialog, personality analytics, graph embeddings, link prediction, text classiﬁcation/generation, and crowdsourcing. He {{has also been}} a coder for the Silicon Valley TV Show.|$|E
5000|$|OceanSITES [...] {{manages a}} set of links to various sources of {{available}} ocean data, including: the Hawaiian Ocean <b>Timeseries</b> (HOT), the JAMSTEC Kuroshio Extension Observatory (JKEO), [...] Line W monitoring the North Atlantic's deep western boundary current, and others.|$|E
50|$|With {{the ability}} to deeply embed Informix in {{gateways}} and routers, <b>timeseries</b> support, small footprint, and low administration requirements, Informix is also targeted at Internet-of-Things solutions, {{where many of the}} data-handling requirements can be handled with gateways that embed Informix and connect sensors and devices to the internet.|$|E
50|$|Although {{the early}} part of his career saw close {{attention}} to technical developments in <b>timeseries</b> econometrics, Quah became heavily influenced by the approach to communicating ideas exemplified in the work of Edward Tufte, and sought similar dissemination of his research to a wider audience. He has also argued that research on economic development needs to be inextricably linked to scholarly work in International Relations.|$|E
50|$|Informix <b>TimeSeries</b> is {{a unique}} feature of the {{database}} system that allows for efficient and fast manipulation of time series data, such as that generated by devices such as smart electric meters, or as found in financial trading systems with time stamped stock 'ticks'. This type of data is not well suited to storage or use in the normal SQL supported style of data organization.|$|E
50|$|For a time {{sequence}} of color images, the array is generally four-dimensional, with the dimensions representing image X and Y coordinates, time, and RGB (or other color space) color plane. For example, the EarthServer initiative unites data centers from different continents offering 3-D x/y/t satellite image <b>timeseries</b> and 4-D x/y/z/t weather data for retrieval and server-side processing through the Open Geospatial Consortium WCPS geo datacube query language standard.|$|E
5000|$|A {{coverage}} {{is represented by}} its [...] "domain" [...] (the universe of extent) {{and a number of}} range of values representing the coverage's value at each defined location. For example, a satellite image derived from remote sensing might record varying degrees of light pollution. Aerial photography, land cover data, and digital elevation models all provide coverage data. Generally, a coverage can be multi-dimensional, such as 1-D sensor <b>timeseries,</b> 2-D satellite images, 3-D x/y/t image time series or x/y/z geo tomograms, or 4-D x/y/z/t climate and ocean data.|$|E
5000|$|It {{created a}} {{research}} division in 1961. In the early 1960s the site researched colloid chemistry, surface active phenomena, rheology of dispersions, surface chemistry, fluorescence of dyestuffs, adsorbed films on liquids, germicides, timber technology (for West Africa), and paper chromatography. Organic chemists, physical chemists and physicists worked there. In the 1960s {{the site was}} run by Unilever Research. In 1964, newly-employed scientists would be earning £1,450. New buildings in the mid-1960s meant more staff. In early 1965 the site installed a IBM System/360 (128k storage) computer at Port Sunlight, connected with time-sharing to IBM 1050 consoles at other sites; it {{claimed to be the}} first time such a computer system had been installed in the UK for industrial research. In February 1964, planning permission was applied for a site at Spital, on Port Sunlight golf course. By 1964 the site had an IBM 1620 computer. In 1965 the site formed an Operational Research Section at Port Sunlight, and their computers used PL/I and Fortran IV. In 1967 statisticians used control charts, <b>timeseries</b> analysis, multivariate analysis and stochastic processes. From early 1969 the consoles at the site were IBM 2780 with the MFT2 and HASPII operating systems. By 1969, new laboratories were built.|$|E
40|$|R topics documented: daysAgg [...] . 2 foo [...] 3 foo. na [...] 3 hoursAgg [...] 4 monthsAgg [...] . 5 <b>timeSeries</b> [...] 6 <b>timeSeries</b> 2 zoo [...] . 7 yearsAgg [...] 8 zoo 2 <b>timeSeries</b> [...] . ...|$|E
40|$|Compatible with CAJALv 1. 8 Features OCPViz An awesome {{image viewer}} New server side graph {{generation}} service Updated Documentation for Install Updated pip. frozen folder Faster Serialization New ocplib accelerations Integration with LIMS System Reorganized django settings files Bug Fixes <b>Timeseries</b> Bug Fix for CATMAID <b>Timeseries</b> Bug Fix for Window <b>Timeseries</b> Tests for CATMAID and Window Django Models Bug Fix for default servers. UI Bug Fixes for Channel and Projec...|$|E
40|$|The paper {{discusses}} {{an efficient}} feature selection approach for multivariate <b>timeseries</b> of heterogeneous sensor data within a pervasive computing scenario. An iterative filtering procedure is devised to reduce information redundancy {{measured in terms}} of <b>timeseries</b> cross-correlation. The algorithm is capable of identifying non-redundant sensor sources in an unsupervised fashion even in presence of a large proportion of noisy features. A comparative experimental analysis on real-world data from pervasive computing applications is provided, showing that the algorithm addresses major limitations of unsupervised filters in literature when dealing with sensor <b>timeseries...</b>|$|E
40|$|In {{this paper}} we offer a gentle {{introduction}} to Gaussian processes for <b>timeseries</b> data analysis. The conceptual framework of Bayesian modelling for <b>timeseries</b> data is discussed and {{the foundations of}} Bayesian non-parametric modelling presented for Gaussian processes. We discuss how domain knowledge influences design of the Gaussian process models and provide case examples to highlight the approaches...|$|E
30|$|In {{addition}} to the differences between H 12 and our implementation during summer months that are caused by vortex identification differences, there is an apparent jump in the H 12 latitude in 1992 {{near the end of}} the Nimbus- 7 TOMS data set. Moreover, at this time, there is also a jump of several degrees in the difference between our Nimbus- 7 TOMS <b>timeseries</b> and H 12 in 1992. Before this time, our <b>timeseries</b> calculated using Nimbus- 7 TOMS TCO generally agrees well with the H 12 estimates. After this time, the H 12 <b>timeseries</b> is significantly offset poleward of ours by several degrees of latitude, particularly during summer months.|$|E
40|$|Preprocessing {{workflow}} Added a workaround {{some changes}} in later versions of FSL that now return a de-meaned <b>timeseries</b> from the highpass filter. In FEAT, the mean is replaced, {{and the rest of}} the processing carries on as usual. Because I don't want to break compatability with older versions of FSL, this adds back in the mean but only if it looks like the filtered <b>timeseries</b> has been de-meaned. Note: This uses a simple heuristic, which may not be robust in all cases, so it is important to check that the signal-to-noise maps make sense if you are doing something that expects a nonzero <b>timeseries</b> mean...|$|E
40|$|The Yet Another <b>TimeSeries</b> Model (YATSM) {{algorithm}} {{is designed to}} monitor land surface phenomena, including land cover and land use change, using <b>timeseries</b> of remote sensing observations. The algorithm seeks to find distinct time periods, or time segments, within the <b>timeseries</b> by monitoring for disturbances. These time segments {{may be used to}} infer continuous periods of stable land cover, with breaks separating the segments representing ephemeral disturbances or permanent conversions in land cover or land use. "The Yet Another [...] . " part of the algorithm name is an acknowledgement of the influence a previously published <b>timeseries</b> algorithm - the Continuous Change Detection and Classification (CCDC) (Zhu and Woodcock, 2014) algorithm. While YATSM began as an extension from CCDC, it was never intended as a 1 to 1 port of CCDC and will continue to diverge in its own direction. Please cite as: Christopher E. Holden. (2015). Yet Another Time Series Model (YATSM). Zenodo. 10. 5281 /zenodo. 1712...|$|E
40|$|The {{increase}} in high-precision, high-sample-rate telemetry <b>timeseries</b> poses {{a problem for}} existing <b>timeseries</b> databases which can neither cope with the throughput demands of these streams nor provide the necessary primitives for effective analysis of them. We present a novel abstraction for telemetry <b>timeseries</b> data and a data structure for providing this abstraction: a timepartitioning version-annotated copy-on-write tree. An implementation in Go is shown to outperform existing solutions, demonstrating a throughput of 53 million inserted values per second and 119 million queried values per second on a four-node cluster. The system achieves a 2. 9 x compression ratio and satisfies statistical queries spanning a year of data in under 200 ms, as demonstrated on a year-long production deployment storing 2. 1 trillion data points. The principles and design of this database are generally applicable to a large variety of <b>timeseries</b> types and represent a significant advance {{in the development of}} technology for the Internet of Things...|$|E
30|$|To {{assess the}} impact of the {{breakpoint}} in the H 12 <b>timeseries</b> on trends, we remove its effect by subtracting the latitudinal offset at the breakpoint (i.e., the difference between the dashed lines in Fig.  3 a, at July 1992) from the latter portion of the <b>timeseries,</b> and then compute the linear trends on this “corrected” <b>timeseries</b> (Fig.  3 b). After removing the breakpoints in the H 12 <b>timeseries,</b> the trends in both hemispheres are significantly reduced (see Table  1) and the difference from our NH trend using BODSCI <b>timeseries</b> is not statistically significant (based on the confidence interval method described in Santer et al. 2000). The global tropical widening rate is reduced by more than a factor of three, from over 3 ° per decade and statistically significant to less than 1 ° per decade and not statistically significant. It is worth noting that with or without breakpoint removal, the SH trends are greater than those in the NH, in line with many previous studies suggesting the Antarctic stratospheric ozone depletion {{is one of the main}} drivers of tropical width changes and that ozone depletion has its greatest impact on the SH tropical width (Polvani et al. 2011; Waugh et al. 2015).|$|E
40|$|This stage creates {{connectivity}} matrices (one per participant/repeated condition). For block-design task fMRI, the toolbox will compute connectivity matrices {{for each}} user-specified condition after dividing up the <b>timeseries</b> by condition. In order {{to compensate for}} HDR-related delay, <b>timeseries</b> are first deconvolved (using SPM's method), allowing for division at actual onset/offset times. Detrending within each block is available. Four measures of connectivity are available: Pearson correlation...|$|E
40|$|This {{is taken}} from [SZ 04, Chap. 7]. It is the third of three {{applications}} they develop based on their review of <b>timeseries</b> techniques {{in the first four}} chapters. 1. Bursts are sudden occurrences of high values over a continuous duration of time in a <b>timeseries.</b> For example, in 1 3 5 11 12 13 0 1 if we specify thresholds for different durations, d, such a...|$|E
40|$|Context. Four open {{clusters}} {{are present}} in the Kepler field of view and <b>timeseries</b> of nearly a year in length are now available. These <b>timeseries</b> allow us to derive asteroseismic global oscillation parameters of red-giant stars in the three open clusters NGC 6791, NGC 6819 and NGC 6811. From these parameters and effective temperatures, we derive masses, radii and luminosities for the clusters as well as field red giants. status: publishe...|$|E
40|$|Abstract. Natural {{geophysical}} <b>timeseries</b> {{bear the}} signature {{of a number of}} complex, possibly inseparable, and generally unknown combination of linear, stable non-linear and chaotic processes. Quantifying the relative contribution of, in particular, the non-linear components will allow improved modelling and prediction of natural systems, or at least define some limitations on predictability. However, difficulties arise; for example, in cases where the series are naturally cyclic (e. g. water waves), it is most unclear how this cyclic behaviour impacts on the techniques commonly used to detect the nonlinear behaviour in other fields. Here a non-linear autoregressive forecasting technique which has had success in demonstrating nonlinearity in non-cyclical geophysical <b>timeseries,</b> is applied to a <b>timeseries</b> generated by videoing the waterline on a natural beach (run-up), which has som...|$|E
40|$|Numerical {{experiments}} {{using the}} general circulation model CCSM 3 {{have been performed}} for glacial climates: Last Glacial Maximum (LGM), Heinrich Stadial 1 (HS 1), Marine Isotope Stage 3 Stadial (MIS 3 -ST) and Marine Isotope Stage 3 Interstadial (MIS 3 -IST). As a reference, a control simulation for preindustrial climate (PI) has been performed. Details of the experiments are described in Merkel et al. (2010). The datasets contain <b>timeseries</b> from the last 100 years of each model simulation. For each experiment, we present: - annual mean <b>timeseries</b> of the maximum of the Atlantic Meridional Overturning Circulation between 30 °N and 80 °N and below 500 m. - monthly mean <b>timeseries</b> of sea surface temperature area-averaged over the Nino 3 -region (5 °S- 5 °N, 150 °W- 90 °W) ...|$|E
30|$|In H 06 /H 12, {{a second}} {{iterative}} process {{was added to}} this method {{to allow for a}} latitudinal dependence to exist in the regime boundaries. After computing the daily boundaries using the H 03 method, these boundaries were then used to separate tropical and midlatitude regimes in each latitude band {{and come up with a}} latitudinally varying threshold for the subtropical front. As in H 12, the daily <b>timeseries</b> have been averaged to create monthly mean <b>timeseries.</b>|$|E
40|$|Observations for passive {{microwave}} satellite sensors {{have provided}} a continuous and consistent record of sea ice extent since late 1978. Earlier records, compiled from ice charts and other sources exist, but are {{not consistent with the}} satellite record. Here, a method is presented to adjust a compilation of pre-satellite sources to remove discontinuities between the two periods and create a more consistent combined 59 -yr <b>timeseries</b> spanning 1953 &ndash; 2011. This adjusted combined <b>timeseries</b> shows more realistic behavior across the transition between the two individual <b>timeseries</b> and thus provides higher confidence in trend estimates from 1953 through 2011. The long-term <b>timeseries</b> is used to calculate linear trend estimates and compare them with trend estimates from the satellite period. The results indicate that trends through the 1960 s were largely positive (though not statistically significant) and then turned negative by the mid- 1970 s and have been consistently negative since, reaching statistical significance (at the 95 % confidence level) by the late 1980 s. The trend for September (when Arctic extent reaches its seasonal minimum) for the satellite period, 1979 &ndash; 2011 is &ndash; 12. 9 % decade&ndash; 1 , nearly double the 1953 &ndash; 2011 trend of &ndash; 6. 8 % decade&ndash; 1 (relative to the 1981 &ndash; 2010 mean). The recent decade (2002 &ndash; 2011) stands out as a period of persistent decline in ice extent. The combined 59 -yr <b>timeseries</b> puts the strong observed decline in the Arctic sea ice cover during 1979 &ndash; 2011 in a longer-term context and provides a useful resource for comparisons with historical model estimates...|$|E
40|$|This {{is taken}} from [SZ 04, Chap. 6]. It is the second of three {{applications}} they develop based on their review of <b>timeseries</b> techniques {{in the first four}} chapters. 1. “Query by humming ” is a challenging unsolved problem in <b>timeseries</b> matching. Because matches cannot be exact, dynamic time warping (DTW) is needed but this is slow, even when we use dynamic programming (see <b>timeseries.</b> pdf, Note 7). Shasha and Zhu find an approximation which excludes false negatives (failed alarm) and speeds up the matching process substantially. The problem is to match, from a database of tunes, the tune that somebody hums, maybe quite inaccurately. The melodic contour approach (a melody is represented as a sequence of u,- and d as the pitch goes up, stays the same or goes down—or maybe, more refined, as U, u,-, d and D) discriminates only very poorly among the many possible entries in the database. It also requires the identification of individual notes from the hum-query, which is a difficult problem. (The database entries can be derived from the written score, which provides the individual notes, so there is no problem there.) So Shasha and Zhu represent the hum-query as a <b>timeseries</b> of pitches, sampled regularly, say every 10 ms, without concern about individual notes. They also store the scores in the database as <b>timeseries</b> of pitches. 2. Let’s start with a database entry, “Hey Jude ” (John Lennon, Paul McCartney, 1965) From the score we can extract the following sequence of (pitch,duration) pairs (60, 4),(57, 10),(57, 2),(60, 2),(62, 2),(55, 8),(-, 4),(55, 2),(57, 2) ...|$|E
40|$|Abstract — In {{this paper}} we propose a novel family of kernels for multivariate time-series {{classification}} problems. Each <b>timeseries</b> is approximated by a linear combination of piecewise polynomial functions in a Reproducing Kernel Hilbert Space by a novel kernel interpolation technique. Using the associated kernel function a large margin classification formulation is proposed which can discriminate between two classes. The formulation leads to kernels, between two multivariate <b>timeseries,</b> which can be efficiently computed. The kernels have been successfully applied to writer independent handwritten character recognition. I...|$|E
40|$|R topics documented: sltl-package [...] . 2 filling. d [...] . 2 filling. m [...] . 3 plot. sltl [...] . 4 sltl [...] 5 summary. sltl [...] . 6 Index 7 1 2 filling. d sltl-package Time series decompoisiton using loess and {{harmonic}} regression Description Decompose daily or monthly <b>timeSeries</b> object into seasonal {{and other}} components. Loess {{is used for}} long-term components while a seasonal pattern is estimated by harmonic regression. If an unevenly-spaced <b>timeSeries</b> object is entered, missing values can be estimaed based on the seasonal adjustment algorithm...|$|E
