353|6043|Public
2500|$|... "Cowboy" [...] as an {{adjective}} for [...] "reckless" [...] {{developed in}} the 1920s. [...] "Cowboy" [...] is sometimes used today in a derogatory sense to describe someone who is reckless or ignores potential risks, irresponsible or who heedlessly handles a sensitive or dangerous <b>task.</b> <b>TIME</b> Magazine referred to President George W. Bush's foreign policy as [...] "Cowboy diplomacy", and Bush has been described in the press, particularly in Europe, as a [...] "cowboy".|$|E
50|$|When copying {{and moving}} a large {{collection}} of files between disks Webroot added 1% {{to the total}} <b>task</b> <b>time.</b> The task of zipping and unzipping {{a large group of}} files took 24% longer with Webroot installed than without it. Installing and uninstalling a number of large Windows Installer packages had an increased <b>task</b> <b>time</b> of adding 35% with the Webroot software installed.|$|E
5000|$|Estimates the {{expected}} value E(task) {{and the standard}} error SE(task) of this estimate for each <b>task</b> <b>time</b> ...|$|E
40|$|Analytic {{models can}} enable {{predictions}} about {{important aspects of}} the usability of in-vehicle information systems (IVIS) to be made at an early stage of the product development process. <b>Task</b> <b>times</b> provide a quantitative measure of user performance and are therefore important in the evaluation of IVIS usability. In this study, critical path analysis (CPA) was used to model IVIS <b>task</b> <b>times</b> in a stationary vehicle, and the technique was extended to produce predictions for slowperson and fastperson performance, as well as average user (middleperson) performance. The CPA-predicted <b>task</b> <b>times</b> were compared to <b>task</b> <b>times</b> recorded in an empirical simulator study of IVIS interaction, and the predicted times were, on average, within acceptable precision limits. This work forms the foundation for extension of the CPA model to predict IVIS <b>task</b> <b>times</b> in a moving vehicle, to reflect the demands of the dual-task driving scenario...|$|R
40|$|Consider a {{partially}} ordered set of tasks where each task has at most one immediate successor. The precedence graph for this task system is a forest. Assume that all <b>task</b> <b>times</b> are independent identically distributed exponential random variables. Then the B-schedule [2] minimizes the expected time {{to complete the task}} system on two identical processors Schedules which are optimal when <b>task</b> <b>times</b> are deterministic are not necessarily optimal when <b>task</b> <b>times</b> are stochastic if the precedence graph is not a forest or if there are more than two processors...|$|R
30|$|As can be {{seen from}} Fig.  9, the overall {{distribution}} of <b>task</b> completion <b>time</b> in three cases is consistent although the <b>task</b> completion <b>time</b> of ten subjects is slightly different. The guidance force will shorten the <b>task</b> completion <b>time</b> in both two scenarios. In the case of the virtual robot scenario, <b>task</b> completion <b>time</b> was reduced by 15.3 % at most and 8 % on average with 2  N guidance force compared with no guidance force. When 4  N guidance force was available, <b>task</b> completion <b>time</b> was shortened by 20.3 % at most and 12.7 % on average. In the ball tracking scenario, <b>task</b> completion <b>time</b> reduction was 10.77 % at most and 6.7 % on average with 2  N guidance force compared with no guidance force. When 4  N guide force was available, <b>task</b> completion <b>time</b> was shortened by 16.60 % at most and 10.6 % on average. The result indicates that the guidance force can give the operator helpful hint to improve the operation efficiency and to shorten the <b>task</b> completion <b>time.</b> Although <b>task</b> completion <b>time</b> is averagely shortened with 4  N guide force compared with 2  N guide force, further experiments should be carried out to study the optimal guidance force for different subjects and different tasks.|$|R
5000|$|Time studies {{determine}} {{the time required}} for a worker to complete each <b>task.</b> <b>Time</b> studies are often used to analyze cyclical jobs. They are considered [...] "event based" [...] studies because time measurements are triggered by the occurrence of predetermined events.|$|E
5000|$|Goldratt {{claims that}} the current method of {{generating}} <b>task</b> <b>time</b> estimates is {{the primary reason for}} increased expense of projects and their inability to finish on time. The commonly accepted principle is to add safety (aka: pad or slop) to generate a <b>task</b> <b>time</b> length that will essentially guarantee the step gets completed. He asserts that estimates for a task are based on individuals providing values that they feel will give them an 80-90% chance of completing the step, these estimates are further padded by managers above this person creating a length of time to complete a task that is excessive - as much as 200% of the actual time required. It is this excessive padding that has the opposite effect - guaranteeing the task will run full term or late. As counter intuitive as this seems, he provides examples of why this is the case. This predisposes the people on the project to consume the time estimate by: ...|$|E
5000|$|... "Cowboy" [...] as an {{adjective}} for [...] "reckless" [...] {{developed in}} the 1920s. [...] "Cowboy" [...] is sometimes used today in a derogatory sense to describe someone who is reckless or ignores potential risks, irresponsible or who heedlessly handles a sensitive or dangerous <b>task.</b> <b>TIME</b> Magazine referred to President George W. Bush's foreign policy as [...] "Cowboy diplomacy", and Bush has been described in the press, particularly in Europe, as a [...] "cowboy".|$|E
40|$|Many manual {{workstations}} {{are designed}} so that {{a specific set of}} tasks to be completed on jobs are performed at the workstation. The subset of individual tasks executed on each job may vary, and a jobs total processing time at the workstation is the sum of those individual <b>task</b> <b>times.</b> Since estimates of the mean and variance of the individual <b>task</b> <b>times</b> are used to make operational and planning decisions, data should be collected on a regular basis to ensure accurate estimates. In this research, we apply a least-squares method and maximum likelihood estimation to estimate the mean and variance of individual <b>task</b> <b>times</b> at a manual workstation from total job-processing time data. Both methods assume that the time to execute individual tasks at a workstation can be treated as independent random variables whose distributions are the same regardless of what other tasks are executed on a job. The maximum likelihood method also assumes that these times are normally distributed. Efficient computational formulas developed for the least-squares method are ideal for use with an automatic data collection system, and both methods provide good estimates of mean <b>task</b> <b>times</b> that are adequate for planning and operational decisions. ...|$|R
30|$|Video: <b>Task</b> {{completion}} <b>time.</b> <b>Task</b> completion <b>time</b> {{was defined}} as the time from the moment participants first pressed the voice activation button to the time that the same button was pressed to terminate a task, {{or in the case of}} radio tuning, the moment when the system accurately carried out the requested <b>task.</b> <b>Task</b> completion <b>time</b> reflects the average task duration across the six tasks in the IVIS condition.|$|R
3000|$|... 2 See Garcia-Mainar et al (2011), and Giannelli et al (2012) for {{a recent}} {{cross-country}} comparison of intra-household allocation of child care and domestic <b>tasks</b> <b>time.</b>|$|R
5000|$|... "Service" [...] in {{this context}} {{is not limited to the}} office or administration, but also wider service {{situations}} that are not necessarily repetitive, where <b>task</b> <b>time</b> is not applicable, and where task times may be both long and variable. Service {{in this context}} could mean anything from a hospital to a university, from an office process to a consultancy, and from a warehouse to field service maintenance. [...] "Service" [...] refers to the service concept or product service bundle, which are all the activities that provide value to the customer along a value stream.|$|E
50|$|SLIM is a decision-analytic {{approach}} to HRA which uses expert judgement to quantify Performance Shaping Factors (PSFs); factors concerning the individuals, environment or task, {{which have the}} potential to either positively or negatively affect performance e.g. available <b>task</b> <b>time.</b> Such factors are used to derive a Success Likelihood Index (SLI), a form of preference index, which is calibrated against existing data to derive a final Human Error Probability (HEP). The PSF’s which require to be considered are chosen by experts and are namely those factors which are regarded as most significant in relation to the context in question.|$|E
50|$|Benchmarking creates {{standardized}} test materials {{for a specific}} type of design. Four key characteristics are considered when establishing a benchmark: time to do the core <b>task,</b> <b>time</b> to fix errors, time to learn applications, and the functionality of the system. Once there is a benchmark, other designs can be compared to it to determine the usability of the system. Many of the common objectives of usability studies, such as trying to understand user behavior or exploring alternative designs, must be put aside. Unlike many other usability methods or types of labs studies, benchmark studies more closely resemble true experimental psychology lab studies, with greater attention to detail on methodology, study protocol and data analysis.|$|E
40|$|Traditionally, {{assembly}} lines {{are laid out}} in a straight-line configuration where a worker covers only adjacent stations. In a U-line layout, on the other hand, two or more non-adjacent stations can be physically close to each other, making it possible for a worker to cover nonadjacent stations. This added flexibility increases the decision space for U-line layouts and can result in better balanced lines. This paper examines the impact of stochastic <b>task</b> <b>times</b> on the relative performance of U-line and straight-line layouts. Several analytical and simulation results are presented, and insights are provided to explain the difference in the performance of U-line and straight-line layouts. To summarize our main results, although balanced U-line layouts are at least as productive as balanced straight-line layouts given deterministic <b>task</b> <b>times,</b> they can be less productive given stochastic <b>task</b> <b>times</b> if they are balanced deterministically using mean times. Assembly Line, U-Line, Stochastic Times, Throughput, Simulation...|$|R
40|$|International audienceThis paper {{addresses}} the balancing problem for straight assembly lines where <b>task</b> <b>times</b> {{are not known}} exactly but given by intervals of their possible values. The objective is to assign the tasks to workstations minimizing the number of workstations while respecting precedence and cycle-time constraints. An adaptable robust optimization model is proposed to hedge against the worst-case scenario for <b>task</b> <b>times.</b> To find the optimal solution(s), a breadth-first search procedure is developed and evaluated on benchmark instances. The results obtained are analysed and some practical recommendations are given...|$|R
40|$|AbstractFor {{disassembly}} sequence generation, partial disassembly {{and sequence}} dependent <b>task</b> <b>times</b> are typically not considered {{together in the}} same model. We developed a two-stage optimization program that first determines the optimal partial disassembly sequence according to reuse value only, followed by the second stage that finds the optimal partial disassembly sequence that also includes sequence dependence <b>task</b> <b>times.</b> We prove the optimality of the two-stage approach under the condition that all components with any positive reuse value must be included in the final sequence. If this condition {{does not need to be}} met, a task hedging policy is shown to be effective...|$|R
5000|$|One {{reviewer}} for The Junior Bookshelf {{offered a}} mixed review: [...] "One {{of the difficulties}} lies in accepting that apparently very ordinary children have a special destiny. This is the major obstacle to the acceptance of Narnia. Four at least of the Six who have the duty of holding back the Dark do not seem up to the <b>task.</b> <b>Time</b> switches too, although handled skilfully enough, are {{not always easy to}} swallow. Where Miss Cooper excels is in the management of setting... The writer captures the smell of the countryside... Miss Cooper shows how fine her observation is and her ability to convey its tingling reality. Perhaps, now that the Dark has been put finally to flight, she will pursue this aspect of her art." ...|$|E
50|$|However, {{there is}} one {{characteristic}} of modern quality that is universal. In the past, {{when we tried to}} improve quality, typically defined as producing fewer defective parts, we did so at the expense of increased cost, increased <b>task</b> <b>time,</b> longer cycle time, etc. We could not get fewer defective parts and lower cost and shorter cycle times, and so on. However, when modern quality techniques are applied correctly to business, engineering, manufacturing or assembly processes, all aspects of quality - customer satisfaction and fewer defects/errors and cycle time and task time/productivity and total cost, etc. - must all improve or, if one of these aspects does not improve, it must at least stay stable and not decline. Therefore, modern quality has the characteristic that it creates AND-based benefits, not OR-based benefits.|$|E
50|$|As {{the designs}} become more complex, the testing must become more formalized. Testing {{equipment}} {{will become more}} sophisticated and testing metrics become more quantitative. With a more refined prototype, designers often test effectiveness, efficiency, and subjective satisfaction, by asking the user to complete various tasks. These categories are measured by the percent that complete the task, {{how long it takes}} to complete the tasks, ratios of success to failure to complete the <b>task,</b> <b>time</b> spent on errors, the number of errors, rating scale of satisfactions, number of times user seems frustrated, etc. Additional observations of the users give designers insight on navigation difficulties, controls, conceptual models, etc. The ultimate goal of analyzing these metrics is to find/create a prototype design that users like and use to successfully perform given tasks. After conducting usability tests, it is important for a designer to record what was observed, in addition to why such behavior occurred and modify the model according to the results. Often it is quite difficult to distinguish the source of the design errors, and what the user did wrong. However, effective usability tests will not generate a solution to the problems, but provide modified design guidelines for continued testing.|$|E
40|$|Objective: This study tested {{whether the}} ease of {{learning}} to use human–machine inter-faces of in-vehicle information systems (IVIS) can be assessed at standstill. Background: Assessing the attentional demand of IVIS should include an evaluation of ease of learn-ing, because the use of IVIS at low skill levels may create safety-relevant distractions. Method: Skill acquisition in operating IVIS was quantified by fitting the power law of practice to training data sets collected in a driving study and at standstill. Participants practiced manual destination entry with two route guidance systems differing in cog-nitive demand. In Experiment 1, a sample of middle-aged participants was trained while steering routes of varying driving demands. In Experiment 2, another sample of middle-aged participants was trained at standstill. Results: In Experiment 1, dis-play glance times were less affected by driving demands than by total <b>task</b> <b>times</b> and decreased at slightly higher speed-up rates (0. 02 higher on average) than <b>task</b> <b>times</b> collected at standstill in Experiment 2. The system interface that minimized cognitive demand was operated more quickly and was easier to learn. Its system delays increased static <b>task</b> <b>times,</b> which still predicted 58 % of variance in display glance times compared with even 76 % for the second system. Conclusion: The ease of learning to use an IVIS interface and the decrease in attentional demand with training can be assessed at stand-still. Application: Fitting the power law of practice to static <b>task</b> <b>times</b> yields parameters that predict display glance times while driving, which {{makes it possible to}} compare interfaces with regard to ease of learning...|$|R
40|$|An {{experimental}} {{study was conducted}} {{to determine the effects of}} various forms of visual and force feedback on human performance for several 'peg-in-hole'-type telemanipulation tasks. Each of six human test subjects used a master/slave manipulator during two experimental sessions. In one session the subjects performed the tasks with direct vision, where subtended visual angle, force feedback, task difficulty, and the interaction of subtended visual angle and force feedback made signigicant differences in <b>task</b> completion <b>times.</b> During the other session the tasks were performed using a video monitor for visual feedback, and video frame rate, force feedback, task difficulty and the interaction of frame rate and force feedback were found to make significant differences in <b>task</b> <b>times.</b> An analysis between the direct and video viewing environments showed that apart from subtended visual angle and reduced frame rate, the video medium itself did not significantly affect <b>task</b> <b>times</b> relative to direct viewing...|$|R
30|$|Ramezani et al., in [29] {{developed}} Multi-Objective Jswarm (MO-Jswarm) scheduling algorithm {{to determine}} the optimal task distribution over the virtual machines (VMs) attempting to balance between different conflicting objectives including <b>task</b> execution <b>time,</b> <b>task</b> transferring <b>time,</b> and <b>task</b> execution cost. According to the authors the proposed algorithm {{had the ability to}} enhance the QOS and to provide a balanced trade-off between the conflicted objectives.|$|R
3000|$|Assembly <b>task</b> <b>time</b> {{of product}} batch m per station in a seru. In a seru, the <b>task</b> <b>time</b> of product type n is {{calculated}} {{by the average}} <b>task</b> <b>time</b> of workers in the seru. TC [...]...|$|E
3000|$|..., {{then the}} worker will cost more average <b>task</b> <b>time</b> than {{her or his}} <b>task</b> <b>time</b> within the {{original}} assembly line. c [...]...|$|E
3000|$|..., worker i’s average <b>task</b> <b>time</b> {{within a}} seru will be longer than {{her or his}} <b>task</b> <b>time</b> within the {{original}} assembly line.|$|E
40|$|The growing global {{competition}} compels manufacturing organizations to engage themselves in all productivity impro vement activities. In this direction, {{the consideration of}} mixed-model assembly line balancing problem and implement ing in industries play s {{a major role in}} improving organizational productivity. In this paper, the mixed model assembly line balancing problem with deterministic <b>task</b> <b>times</b> is considered. The authors made an attempt to develop a genetic algorithm for realistic design of the mixed-model assembly line balancing problem. The design is made using the ori ginnal <b>task</b> <b>times</b> of the models, which is a realistic approach. Then, it is compared with the generally perceived design of the mixed-model assembly line balancing problem.   </p...|$|R
40|$|Disassembly {{lines are}} used {{so as to}} recover both {{economic}} and ecological value residing in collected end-of-life products while meeting environmental legislation. Due {{to the nature of}} the disassembly operations, disassembly tasks exhibit higher levels of uncertainty. So as to incorporate the variability in <b>task</b> <b>times</b> while designing disassembly lines, this paper deals with the stochastic disassembly line balancing problem with the objective of minimizing the number of stations. <b>Task</b> <b>times</b> are assumed to be normally distributed random variables with known means and standard deviations. A chance-constrained piecewise-linear mixed integer programming model is proposed. The computational experiments using the cell phone problem demonstrate that the proposed model can yield on average 2 % improvements compared to a stochastic station oriented ranked positional heuristic...|$|R
40|$|International audienceDisassembly is an {{important}} aspect of end of life product treatment, as well as having products disassembled in an efficient and responsible manner. Disassembly line balancing is a technique that enables a product to be disassembled as efficiently and economically viable as possible; however, considering all possible end of life (EOL) states of a product makes disassembly line balancing very difficult. The EOL state and the possibility of multiple recovery options of a product can alter both disassembly <b>tasks</b> and <b>task</b> <b>times</b> for the disassembly of the EOL product. This paper shows how generating a joint precedence graph based on the different EOL states of a product is beneficial to achieving an optimal line balance where traditional line balancing approaches are used. We use a simple example of a pen from the literature to show how a joint disassembly precedence graph is created and a laptop example for joint precedence graph generation and balancing. We run multiple scenarios where the EOL conditions have different probabilities and compare results for the case of deterministic <b>task</b> <b>times.</b> We also consider the possibility where some disassembly <b>task</b> <b>times</b> are normally distributed and show how a stochastic joint precedence graph can be created and used in a stochastic line balancing formulation...|$|R
30|$|Average <b>task</b> <b>time</b> of seru j {{assembling}} product batch m.|$|E
3000|$|In {{the first}} half of the re-plan module C, a robot iterates to {{estimate}} the entire <b>task</b> <b>time</b> when a new delivery position is set to each position. We use part of the algorithm for the Critical Path Method [22] to estimate the entire <b>task</b> <b>time</b> for a new delivery position. The calculation cost for one estimation is O((n- 1) [...]...|$|E
40|$|Thesis (M. S.) [...] Wichita State University, College of Engineering, Dept. of Industrial and Manufacturing Engineering. In {{a single}} model manual {{assembly}} line, product flows through series of workstations {{arranged in a}} sequential manner. Each workstation has {{a finite number of}} tasks and each task has probabilistic processing time. Due to the probabilistic nature of <b>task</b> <b>time,</b> the task times can exceed the expected standard <b>task</b> <b>time</b> at some instance. If a series of tasks exceeds in a particular station, then there is a risk that the product may exceed the cycle time. As a result, a small variability in <b>task</b> <b>time</b> can lead to large delays in the delivery lead time of the product. Most of the line balancing approaches assume deterministic task times thereby ignoring the impact of <b>task</b> <b>time</b> variability on the system performance measures. The larger the variability of <b>task</b> <b>time,</b> the higher the risk associated with the station. In this paper, the impact of variability in <b>task</b> <b>time</b> is quantified in terms of risk. Risk is defined as potential loss caused when the product fails to complete within the specified station time. For line balancing, in addition to cycle time balancing, the risk should be balanced in order to improve the performance of the assembly line. In this research, a risk based assembly line balancing technique for highly variable task times is presented. The results from the case study show that the method increases the performance of the assembly line while balancing the risk of delays at each station...|$|E
30|$|The load {{balancing}} issue based on genetic algorithm {{has also been}} addressed in virtualized computing environments [11],[15],[16]. In [11] and [15], authors propose to minimize <b>task</b> execution <b>time</b> by using an objective function that minimizes the largest <b>task</b> completion <b>time</b> as defined in [11] and [8].|$|R
50|$|Ofuz is {{a contact}} management, task-management, time-tracking, and {{invoicing}} software product from SQLFusion. The software was released {{as a public}} beta on October 11, 2009. Among other features, Ofuz 0.5.8 provides the ability to manage multiple aspects of projects such as contacts, <b>tasks,</b> <b>time,</b> and invoices.|$|R
30|$|We {{propose to}} use the {{difference}} between the largest and the smallest <b>task</b> completion <b>times</b> rather than the MaxSpan value (as used in [6] and [8]) because guaranteeing a minimum TaskSpan value not only ensures a shorter <b>task</b> completion <b>time</b> but also a proper load balancing between all processors.|$|R
