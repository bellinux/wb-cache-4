15|5|Public
40|$|Abstract. Condition-based Maintenance (CBM), {{which can}} {{efficiently}} improve {{the performance of}} the deteriorating system, would be influenced by imperfect inspection in practice. Aiming at this problem, a new CBM model under imperfect inspection is presented for deteriorating system, which is described by Gamma process. The system is inspected periodically, and a preventive maintenance is performed if the degradation level exceeds a <b>threhold.</b> The inspection is imperfect, that means the measurements contain errors, and the CBM model should take these measure errors into account. The algorithm is shown to estimate the long run cost rate using Monte-Carlo method. Through numerical example, the influence of mesurement error over long run cost is analyzed. Therefore, the correctness and rationality of the model are proved...|$|E
40|$|This paper {{presents}} an exhaustive {{evaluation of the}} quality of an audio watermarking algorithm. The integration of the psychoacoustic model into the audio watermarking approach is demonstrated. The quality parameter relating the power of the watermark noise and the masking <b>threhold</b> is presented. The evaluation method is detailed {{and the quality of the}} watermarked audio tracks is evaluated with regard to different settings of the quality parameter used to adjust the power of the embedded watermarks. The subjective listener test compares the quality of the original audio track with the watermarked one. Different quality parameter settings were used in order to enable the adjustment between quality and maximum robustness according to the items to be watermarked and the target audience...|$|E
40|$|The {{objective}} of this work {{is to find the}} melodic line in MIDI files. Usually, the melodic line is stored in a single track, while the other tracks contain the accompaniment. The detection of the track that contains the melodic line can be very useful for a number of applications, such as melody matching when searching in MIDI databases. The system was developed using WEKA. First, a set of descriptors from each track of the target melody is extracted. These descriptors are the input to a random forest classifier that assigns a probability of being a melodic line to each track. The tracks with a probability under a given <b>threhold</b> are filtered out, and the one with the highest probability is selected as the melodic line of that melody. Promising results were obtained testing different MIDI databases...|$|E
40|$|A {{number of}} photonuclear {{reactions}} {{have been studied}} using the University of Saskatchewan betatron {{as a source of}} high energy x-rays. The gamma neutron <b>threholds</b> and reaction cross sections have 100 % abundance in one stable isotope. These reactions have been studied by observing the emitted neutrons with a boron trifluoride counter in a tank of paraffin. From considerations regarding the shapes of the cross sections curves near threshold, evidence has been obtained which indicates that electric quadupole and magnetic dipole absorption of photons account for {{a large part of the}} reation yield, although electric dipole absorption may account for most of the reaction at higher energies...|$|R
40|$|The constructon of the {{electronics}} module system for astrophysical investigations, the preparation on its {{base of the}} experiments for the search and detection of cosmic gamma-bursts and solar eruptions, the holding of measurements during the flight on a high-altitude balloon are {{the aim of the}} paper. As a result dependences of the minimum energy flows on characteristics of the background and <b>threholds</b> of the burst selection have been obtained. The electronics module system for astrophysical investigations, including microprocessor modules has been developed. Devices ABC and "Taurus" for the search and detection of cosmic gamma-bursts and solar eruptions with high time resolution and detection of the spectral evolution of events have been created. Measurements of background conditions during the flight on a high-altitude balloon have been held. The electronics module system created has been introduced into operation. The paper results may find their field of application in automation of scientific investigation and in astrophysical investigationsAvailable from VNTIC / VNTIC - Scientific & Technical Information Centre of RussiaSIGLERURussian Federatio...|$|R
40|$|Abstract Background MLPA {{method is}} a {{potentially}} useful semi-quantitative method to detect copy number alterations in targeted regions. In this paper, we propose {{a method for}} the normalization procedure based on a non-linear mixed-model, {{as well as a}} new approach for determining the statistical significance of altered probes based on linear mixed-model. This method establishes a threshold by using different tolerance intervals that accommodates the specific random error variability observed in each test sample. Results Through simulation studies we have shown that our proposed method outperforms two existing methods that are based on simple threshold rules or iterative regression. We have illustrated the method using a controlled MLPA assay in which targeted regions are variable in copy number in individuals suffering from different disorders such as Prader-Willi, DiGeorge or Autism showing the best performace. Conclusion Using the proposed mixed-model, we are able to determine thresholds to decide whether a region is altered. These <b>threholds</b> are specific for each individual, incorporating experimental variability, resulting in improved sensitivity and specificity as the examples with real data have revealed. </p...|$|R
40|$|We {{consider}} the newly found high mass and low magnetic field binary pulsar PSR J 1614 - 2230 {{in a model}} in which magnetars owe their strong magnetic fields to a high baryon density, magnetized core. In our magnetar model all neutron stars above a certain <b>threhold</b> mass are magnetars. This confronts us with the very basic paradox as to why this high mass star, PSR J 1614 - 2230, remains a pulsar and shows no magnetar characteristics. This is a star that has acquired its large mass by accretion from its binary companion over 5 gigayears. In this work we show that the maximum rate of energy gain from the strong interaction phase transition from this slow accretion {{does not allow for}} high enough interior temperature for ambipolar transport of the magnetic field {{to the surface of the}} star and thus the PSR J 1614 - 2230 remains latent and does not become an emergent magnetar. Comment: 5 Latex page...|$|E
40|$|This thesis {{provides}} {{an introduction to}} the fundamentals of random graph theory. The study starts introduces the two fundamental building blocks of random graph theory, namely discrete probability and graph theory. The study starts by introducing relevant concepts probability commonly used in random graph theory- these include concentration inequalities such as Chebyshev's inequality and Chernoff's inequality. Moreover we proceed by introducing central concepts in graph theory, which will underpin the later discussion. In particular we provide results such as Mycielski's construction of a family of triangle-free graphs with high chromatic number and results in Ramsey theory. Next we introduce the concept of a random graph and present two of the most famous proofs in graph theory using the theory random graphs. These include the proof {{of the fact that there}} are graphs with arbitrarily high girth and chromatic number, and a bound on the Ramsey number R(k; k). Finally we conclude by introducing the notion of a threshold function for a monotone graph property and we present proofs for the <b>threhold</b> functions of certain properties...|$|E
40|$|Abstract — This paper {{studies the}} mutual {{information}} transfer {{characteristics of a}} novel low-complexity Bayesian Multiuser Detector (MUD) proposed for employment in Space Division Multiple Access (SDMA) aided Orthogonal Frequency Division Multiplexing (OFDM) systems. The design of the Bayesian MUD advocated is based on extending the optimum single-user Bayesian design to multiuser OFDM signals modeled by a Gaussian mixture, rather than by a single Gaussian distribution, when characterizing the conditional PDF of the received signal. In {{order to reduce the}} complexity of the Bayesian MUD, we introduce an aprioriinformation threshold and then discard the lowprobability terms during the calculation of the extrinisic information generated. The achievable complexity reduction as a function of different <b>threhold</b> values is analyzed and the best tradeoff values are derived with the aid of simulation. Both non-systematic and recursive systematic convolutional codes are used for exchanging extrinsic information with the MUD for the sake of achieving a turbo-detection aided iteration gain. The convergence behavior of the proposed low-complexity Bayesian turbo MUD is investigated using EXtrinsic Information Transfer (EXIT) chart analysis and compared to that of Soft Interference Cancellation aided Minimum Mean Square Error (SIC-MMSE) MUD schemes. As expected, the simulation results show that the proposed low-complexity Bayesia...|$|E
40|$|Dynamic Glass {{patterns}} (dGPs) are {{fields of}} coherently oriented dipoles that are updated rapidly (> 5 Hz). Although {{they have no}} oriented motion energy, individual Glass patterns yield a weak percept of coherent motion, {{and in the case}} of dGPs, this effect is so prominent that subjects can confuse them for real coherent motion fields at short presentation durations (Krekelberg et al 2003, Nature 424 674 – 677). It has even been suggested that dGPs processing involves some of the neural circuitry used for motion processing. The detection thresholds for fields of coherently moving dots increase significantly when they are superimposed on incoherent motion noise. Similarly, detecting coherent Glass patterns is more difficult in the presence of superimposed incoherent dipoles. Here, we asked if Glass patterns and coherent motion interfere with each other at or before the site mediating their detection. We measured detection coherence thresholds for dGPs and coherent motion stimuli alone or in the presence of incoherent noise patterns (randomly oriented dipoles or moving dots). dGPs and coherent motion stimuli were affected very differently by different noise fields. Remarkably, coherent motion <b>threholds</b> were largely unaffected by the presence of dense, randomly oriented dipole fields while dGP thresholds were elevated by both incoherent motion and random dipoles to an equal degree. These results are consistent with our recent neuroimaging data indicating different processing networks for coherent motion and dGPs...|$|R
40|$|Locality-Sensitive Hashing (LSH) and its {{variants}} are well-known {{methods for}} solving the c-approximate NN Search problem in high-dimensional space. Traditionally, several LSH functions are concatenated {{to form a}} "static" compound hash function for building a hash table. In this paper, we propose to use a base of m single LSH functions to construct "dynamic" compound hash functions, and define a new LSH scheme called Collision Counting LSH (C 2 LSH). If the number of LSH functions under which a data object o collides with a query object q is greater than a pre-specified collision <b>threhold</b> l, then o {{can be regarded as}} a good candidate of c-approximate NN of q. This is the basic idea of C 2 LSH. Our theoretical studies show that, by appropriately choosing the size of LSH function base m and the collision threshold l, C 2 LSH can have a guarantee on query quality. Notably, the parameter m is not affected by dimensionality of data objects, which makes C 2 LSH especially good for high dimensional NN search. The experimental studies based on synthetic datasets and four real datasets have shown that C 2 LSH outperforms {{the state of the art}} method LSB-forest in high dimensional space. © 2012 ACM...|$|E
40|$|International audienceMicroRNAs (miRNAs) {{are small}} RNA {{molecules}} that bind messenger RNAs (mRNAs) to silence their expression. Understanding this regulation mechanism requires {{the study of}} the miRNA/mRNA interaction network. State of the art methods for predicting interactions lead to a high level of false positive. Roughly, the score distribution of interactions is a mix of two overlapping gaussian laws that need to be discriminated with a <b>threhold.</b> To improve the discrimination between true and false interactions, we allow to keep or discard some interaction edges that are above or below the threshold. This " process is founded on the hypothesis that the graph is formed by interaction modules represented by formal concepts, i. e. set of miRNAs having the same regulation pro le, a plausible biological structuration. Our assumption is that a network consisting only of true interactions has a simpler concept topology. It allows to discriminate between true and false interactions on the basis of concepts that can be simpli ed by edge addition or deletion. To validate our hypothesis and method, we have extracted parameters from a biological miRNA/mRNA network and use them to build random networks with xed concept topologies and true/false interaction ratio. Each repaired network can be evaluated with a score balancing the number of edge changes and the conceptual adequacy {{in the spirit of the}} minimum description length principle...|$|E
40|$|Diaprepes abbreviatus is {{an exotic}} root weevil {{occurring}} in southern US. It {{is a highly}} polyphagous species which can complete its entire life cycle on citrus and several woody ornamental plants. The lack of native egg parasitoids for this wwvil in citrus orchards has triggered efforts to evaluate condidate egg parasitoids from the Caribbean Region into Florida. The egg parasitoids Fidiobia dominica and Haeckeliania sperata are two exotic natural enemies of D. abbreviatus recently introduced in the US in a classical biological control program. The therminal requierements of both parasitoids were studied in the laboratory. The upper development <b>threhold</b> (UDT) of F. dominica was 30. 0 ºC, its maximal development rate (MDR) occurred at 27. 6 ºC, its lower development threshold (LDT) was 9. 6 ºC and its thermal constant (K) for development from egg to adult was 293. 1 DD. For H. sperata, UDT was 35. 0 ºC, MDR occurred at 31. 0 ºC, LDT was arround 15 ºC and K was 188. 1 DD. Based on these results, both species {{would be able to}} complete 17 to 18 generations annually in southern Florida. However, host availability during critical periods could severely impair the ability og these egg parasitoids to establish and successfully control D. abbreviatus in areas where winter temperatures fluctuate around 12 ºC, the LDT for this pes...|$|E
40|$|KahnemanとTverskyがリスク下での意志決定の言述モデルとして提出したプロスペクト理論は，多くの現象を説明するモデルであり，この理論が説明する現象の 1 つに確実性効果がある。本研究は，リスク下での意志決定事態にみられる確実性効果がどの程度の範囲でみられるかを 5 つの確率水準と 5 つの利得水準（金銭）を設定して検討した。その結果，確率水準では，リスクが少ない 95 ％水準においても確実な選択肢を選ぶ確実性効果がみられた。また，利得水準では少なくとも千円台の利得水準以上においてのみ確実性効果は出現し，利得水準に一定の閾値が存在することが示された。Kahneman and Tversky's {{prospect}} {{theory has}} been able to explain a variety of phenomena in guman decision making under risk. One of the most important phenomenon that prospect theory pridicts is ceatainty effect and this effect incorporated in π function of prospect theory. Present study was aimed at examine the certainty effect for different levels of risk and gain in risky option. Twenty-five dicision tasks,combined five gain levels(from 40 to 400, 000 Japanese Yen) with five risk levels(from. 75 to. 95),were used Japanese college students. Certain option always had 100 % chance and 30 yen, 300 yen,and so on. Choice Tasks were illustrated as follows:option(A) 90 % chance to win 4000 Yen,option(B) 100 % chance to win 3000 Yen. In result,certain option were chosen more than risky option in all of the tasks. On each levels of risk,proportion of the choice for certain option were increased with higher risk levels,but even at 95 % level certain option was still prefered in many subjects. This result suggests that certainty effect occurs at least up to 95 % level. On the gain levels,different effects were observed in each gain levels. There were no significant ceatainty effect in 30 and 300 Japanese Yen levels of certain option. This result suggests that certainty effect depends on gain levels {{and that there is a}} <b>threhold</b> level of gain in the certainty effect...|$|E
40|$|Multi-scale {{problems}} {{appear in}} many contexts. In this thesis, we study two dif- ferent subjects involving multi-scale problems: (i) collective dynamics, and (ii) image processing. For collective dynamics, we concentrate on flocking models, in particular, Cucker-Smale and Motsch-Tadmor systems. These models characterize the emergent behaviors of self-organized dynamics. We study flocking systems {{in three different}} scales, from microscopic agent-based models, through mesoscopic kineitc discriptions, to macroscopic fluid systems. Global existence theories are developed for all three scales, with the proof of asymptotic flocking behaviors. In the macroscopic level, a critical <b>threhold</b> phenomenon is addressed to obtain global regularity. Similar idea is implemented to other fluid systems as well, like Euler-Poisson equations. In the kinetic level, a discontinuous Galerkin method is introduced to overcome the numerical difficulty due to the precence of δ -singularity. For image processing, we apply the idea of multi-scale image representation to construct uniformly bounded solutions for div U = F. Despite {{the fact that the}} equation is simple and linear, it is suprisingly true that its bounded solution can not be constructed through a linear procedure. In particular, the Holmholtz solution is not always bounded. A hierarchical construction of the bounded solution of the equation is proposed, borrowing the idea from image processing. We also present a numerical implementation to deal with the highly nonlinear construction procedure. Solid numerical result verifies that the constructed solution is indeed uniformly bounded...|$|E
40|$|TANAKA, H. and HIGUCHI, M. Age, Exercise Perfomance, and Physiological Functkonal Capacities Abv. Exerc. Sports Physiol., Vol. 4, No. 2 pp. 51 - 56, 1998. Exercise {{performance}} {{is a research}} model that provides insight into the overall reduction in ohysiological funcuonal capacity with advancing age. Becouse confounding influences of changes in phycial activity levels, body composition, and overt disease with afe are markedly reduced or eliminated in highly-trained competitive arhletes, changes in exercise performance with increasing age can be cinsidered to be primarily the result of aging per se. Retrospective analysis of road running races have revealed that endurance running performance changes little until late 302 ̆ 7 s, then deckines modcstly until the late 502 ̆ 7 s. Thereagter the rate of decline is exponcnial with advantage age. General pattern of age-related decline in exercise perfomance appears to be similar in differnt types of endurance exercise activities including swimmig. However,. the magnitude of ovcrall reduction is smaller and {{the age at which}} exponential declines start occurs later in swimming performance compared with running performance. The exact contribution of the physiological determinants to ace-related decrease in exercise performance are unknown. It apperas, that decreases in maximal oxygen consumption and lacttate <b>threhold</b> are the two primary physiologicak dererminants of a decline in ecdurance exercise performance with advantage age. Decrease in exercise economy do not contributs importantly to the age-related decine in exercise performance. These physiological determinants of age-associated reduction in endurance perfirmance appears to be the same in men and women...|$|E
40|$|This paper {{studies the}} mutual {{information}} transfer {{characteristics of a}} novel low-complexity Bayesian Multiuser Detector (MUD) proposed for employment in Space Division Multiple Access (SDMA) aided Orthogonal Frequency Division Multiplexing (OFDM) systems. The design of the Bayesian MUD advocated is based on extending the optimum single-user Bayesian design to multiuser OFDM signals modeled by a Gaussian mixture, rather than by a single Gaussian distribution, when characterizing the conditional PDF of the received signal. In {{order to reduce the}} complexity of the Bayesian MUD, we introduce an a priori information threshold and then discard the lowprobability terms during the calculation of the extrinisic information generated. The achievable complexity reduction as a function of different <b>threhold</b> values is analyzed and the best tradeoff values are derived with the aid of simulation. Both non-systematic and recursive systematic convolutional codes are used for exchanging extrinsic information with the MUD for the sake of achieving a turbo-detection aided iteration gain. The convergence behavior of the proposed low-complexity Bayesian turbo MUD is investigated using EXtrinsic Information Transfer (EXIT) chart analysis and compared to that of Soft Interference Cancellation aided Minimum Mean Square Error (SIC-MMSE) MUD schemes. As expected, the simulation results show that the proposed low-complexity Bayesian Turbo MUD outperforms the SIC-MMSE MUDs. A substantial benefit of the proposed MUD is that it is potentially capable of supporting up to three times higher number of users than the number of receiver antennas. In this challenging multiuser scenario, the resultant channelmatrix becomes rank-deficient, resulting in a linearly non-separable detector output phasor constellation, when classic linear receivers tend to exhibit a poor performance...|$|E
40|$|The Newton {{algorithm}} is a quadratic-convergence numerical technique to calculate solution of algebraic equations. In this problem, we seek and hardware implementationof such an algorithm. Assuming a function F is monotonic in [x 1, x 2], the algorithm finds the root x ∗ of F (x) = C in [x 1, x 2] operating as follows: assuming the current {{estimate of the}} root is labeled xk ∈ [x 1, x 2], then if F (xk) ≤ th the algorithm stops(th is a <b>threhold),</b> else xk+ 1 = xk + (F (xk) −C) /F (xk). In this hardware implementation, {{we assume that the}} current estimate xk is represented with 16 bits of precision, so as the constant C. Values of F() and 1 /F are supposed to be stored in an on chip look up table with 15 ns access time. The block diagram of the hardware implementation of the {{algorithm is}} shown in figure 1. Here, L 1 -L 5 are D latches with zero delay. The delay of the 16 and 32 bits adders are respectively 5 nS and 10 ns, while the delay of the 16 x 16 multiplier is 10 nS. The L. U. T. access time is 15 ns. The input is sampled on the rising edge of a slow clock(the algorithm requires multiple cycles of the internal,fast clock to converge). Choose polarity of the latches that minimizes the clock period requird for correct operation, as well as the corresponding clock period value. 2 Problem 2 :Subthreshold inverter In this problem, we analyze robustness considerations in logic. As learnt in class,in circuit applications where extremely low energy consumption is essential and high speed operation is not required, subthrehold operation may provide a viable solution. In the following the definition of failure point of an inverter is assumed as that voltage such that for an input swing of 0 to Vdd, the output swing is limited to. 1 Vdd to. 9 Vdd. 1. Use what you know about subthreshold device modeling to develop an equation to be solved for the value of Vdd such that, when Vin = 0,Vout =. 9 Vdd. 2. Numerically solve this equation for χ...|$|E
40|$|In this thesis, {{we present}} a {{theoretical}} and experimental study on the dispersive properties of photonic structures based on microresonators. First, we develop a cavity ringdown based method who fully describe the linear properties of microcavities such as coupling regime and group delay. This homodyne method is successfully applied on a cristalline microdisk (MgF 2) and passive and active microspherical resonators to characterize various types of phenomena. In the case of doped microspherical whispering gallery modes resonators, we demonstrate selective amplification filter by combining high spectral selectivity and below <b>threhold</b> laser amplification (gain up to 20 dB at 1. 55 μm). In passive high-Q microspheres with high finesse (F > 10 ^ 5), we could observe a lift of degeneracy between counter propagating modes. This effect originates from Rayleigh scattering that couples these two modes. This phenomenom is observed in the spectral domain by a splitting of the resonance. In a second step, we study the dispersive properties of coupled-resonator architectures. The coupling of two cavities leads to a splitting of the resonance and a notable decrease in the absorption around the resonance. We experimentally show {{that it is possible}} to circumvent limitation imposed by the intrinsic losses of passive resonators using active resonators. This effect can be seen as the classical counter part of Electromagnetically Induced Transparency (EIT). Moreover, we demonstrate that Coupled-Active-Resonator-Induced Transparency is a promising alternative in optical delay line since we can dynamically adjust the delay from a few ns to tens of ns (≈ 90 ns) without any change in the transparency of the system. Furthermore, we propose and experimentally demonstrated tunable cavity-linewidth narrowing based on the strong dispersion induced by the coupling of two resonators. In the case of three resonators, we propose a coupling scheme allowing the Q-factor of a critically coupled resonator to be increased and actively modulated by using two additional coupled resonators. We experimentally validate the principle by means of a model system consisting of Er 3 +-doped fiber coupled resonators. We successfully show a growth of the Q-factor from 4 × 10 ^ 7 up to 2, 5 × 10 ^ 8. These experimental results demonstrate the means of Q-factor tailoring using active artificial photonic media. La caractérisation de résonateurs de facteurs de surtension très élevés (> 10 ^ 8) est difficilement réalisée à partir des méthodes expérimentales conventionnelles en régime stationnaire. Nous proposerons une méthode hybride spectrale/temporelle permettant la mesure du facteur de surtension global et la discrimination, de manière univoque, des facteurs Q_ 0 intrinsèque et Q_e extrinsèque du dispositif. Par cette simple mesure, nous déterminons le régime de couplage et les propriétés dispersives de micro-cavités. Dans un second temps, nous présenterons différentes architectures à base de cavités couplées actives donnant accès un à degré de liberté supplémentaire quant au contrôle de la dispersion. Nous étudierons successivement le phénomène de transparence induite pour la réalisation d'états de lumière lente puis la dispersion induite dans le cas de deux et trois cavités. Dans ce dernier cas, la modulation des pertes intrinsèques mène à un contrôle actif du facteur de qualité de la structure. La démonstration expérimentale de ce principe montre la possibilité d'ingénierie du facteur Q par l'utilisation de structures photoniques artificielles actives...|$|E

