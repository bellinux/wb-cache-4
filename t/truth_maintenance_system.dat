113|4440|Public
25|$|Knowledge Engineering Environment (KEE) used {{an object}} system called UNITS and {{integrated}} {{it with an}} inference engine and a <b>truth</b> <b>maintenance</b> <b>system</b> (ATMS).|$|E
25|$|While working (starting in 1975) as a {{research}} assistant at MIT under Gerry Sussman, Stallman published a paper (with Sussman) in 1977 on an AI <b>truth</b> <b>maintenance</b> <b>system,</b> called dependency-directed backtracking. This paper was an early work {{on the problem of}} intelligent backtracking in constraint satisfaction problems. , the technique Stallman and Sussman introduced is still the most general and powerful form of intelligent backtracking. The technique of constraint recording, wherein partial results of a search are recorded for later reuse, was also introduced in this paper.|$|E
2500|$|Non-monotonic {{reasoning}}. Non-monotonic reasoning allows {{various kinds}} of hypothetical reasoning. The system associates facts asserted with the rules and facts used to justify them and as those facts change updates the dependent knowledge as well. In rule based systems this capability {{is known as a}} <b>truth</b> <b>maintenance</b> <b>system.</b>|$|E
5000|$|G. M. Provan (1988). A {{complexity}} analysis of assumption-based <b>truth</b> <b>maintenance</b> <b>systems.</b> In B. Smith and G. Kelleher, editors, Reason <b>Maintenance</b> <b>Systems</b> and their Applications, pages 98-113. Ellis Horwood, New York.|$|R
5000|$|G. M. Provan (1990). The {{computational}} {{complexity of}} multiple-context <b>truth</b> <b>maintenance</b> <b>systems.</b> In Proceedings of the Ninth European Conference on Artificial Intelligence (ECAI'90), pages 522-527.|$|R
50|$|Systems {{specifically}} implementing {{belief revision}} are: Immortal, SATEN, and BReLS. Two systems including a belief revision feature are SNePS and Cyc. <b>Truth</b> <b>maintenance</b> <b>systems</b> {{are used in}} Artificial Intelligence to implement belief revision.|$|R
5000|$|J. Doyle. A <b>Truth</b> <b>Maintenance</b> <b>System.</b> AI. Vol. 12. No 3, pp. 251-272. 1979.|$|E
50|$|Knowledge Engineering Environment (KEE) used {{an object}} system called UNITS and {{integrated}} {{it with an}} inference engine and a <b>truth</b> <b>maintenance</b> <b>system</b> (ATMS).|$|E
50|$|KEE {{supports}} {{non-monotonic reasoning}} through {{the concepts of}} worlds. Worlds allow provide alternative slot-values of frames. Through an assumption-based <b>Truth</b> <b>maintenance</b> <b>system</b> inconsistencies can be detected and analyzed.|$|E
40|$|Finding {{the stable}} models of a {{knowledge}} base is a signicant computational problem in articial intelligence. This task {{is at the}} computational heart of <b>truth</b> <b>maintenance</b> <b>systems,</b> autoepistemic logic, and default logic. Unfortunately, it is NP-hard. In this paper we present a hierarchy of classes of knowledge bases,...|$|R
5000|$|Raymond Reiter (June 12, 1939 [...] - [...] September 16, 2002), was a Canadian {{computer}} scientist and logician. He {{was one of}} the founders of the field of non-monotonic reasoning with his work on default logic, model-based diagnosis, closed world reasoning, and <b>truth</b> <b>maintenance</b> <b>systems.</b> He also contributed to the situation calculus.|$|R
40|$|ABSTRACT. This paper {{investigates the}} problem of finding subclasses of nonmonotonic {{reasoning}} which can be implemented efficiently. The ability to “define” propositions using default assumptions about the same propositions is identified as {{a major source of}} computational complexity in nonmonotonic reasoning. If such constructs are not allowed, i. e. stratified knowledge bases are considered, a significant computational advantage is obtained. This is demonstrated by developing an iterative algorithm for propositional stratified autoepistemic theories the complexity of which is dominated by required classical reasoning. Thus efficient subclasses of stratified nonmonotonic reasoning can be obtained by further restricting the form of sentences in a knowledge base. As an example quadratic and linear time algorithms for specific subclasses of stratified autoepistemic theories are derived. The results are shown to imply efficient reasoning methods for stratified cases of default logic, logic programs, <b>truth</b> <b>maintenance</b> <b>systems,</b> and nonmonotonic modal logics. KEY WORDS: automated theorem proving, tractability, autoepistemic logic, default logic, nonmonotonic modal logics, logic programs, <b>truth</b> <b>maintenance</b> <b>systems.</b> 1...|$|R
5000|$|U. Junker and K. Konolige (1990). Computing the {{extensions}} of autoepistemic and default logics with a <b>truth</b> <b>maintenance</b> <b>system.</b> In Proceedings of the Eighth National Conference on Artificial Intelligence (AAAI'90), pages 278-283. MIT Press.|$|E
50|$|Defeasibility as corrigibility: Here, {{a person}} learns {{something}} new that annuls a prior inference. In this case, defeasible reasoning provides a constructive mechanism for belief revision, like a <b>truth</b> <b>maintenance</b> <b>system</b> as envisioned by Jon Doyle.|$|E
5000|$|A <b>truth</b> <b>maintenance</b> <b>system,</b> or TMS, is a {{knowledge}} representation method for representing both beliefs and their dependencies and an algorithm called the [...] "truth maintenance algorithm" [...] that manipulates and maintains the dependencies. The name truth maintenance {{is due to}} the ability of these systems to restore consistency.|$|E
5000|$|In a {{different}} solution to these problems, some mathematicians have devised alternate theories of logic called paraconsistent logics, which eliminate {{the principle of}} explosion. [...] These allow some contradictory statements to be proved without affecting other proofs. In artificial intelligence and models of human reasoning {{it is common for}} such logics to be used. <b>Truth</b> <b>maintenance</b> <b>systems</b> are AI models which try to capture this process.|$|R
40|$|Distributed AI {{systems are}} {{intended}} {{to fill the gap}} between classical AI and distributed computer science. Such networks of different problem solvers are required for naturally distributed problems, and for tasks which exhaust the resource of an individual node. To guarantee a certain degree of consistency in a distributed AI system, it is necessary to inspect the beliefs of both single nodes and the whole net. This task is performed by Distributed <b>Truth</b> <b>Maintenance</b> <b>Systems.</b> Based on classical TMS theories, distributed <b>truth</b> <b>maintenance</b> extends the conventional case to incorporate maintenance in DAI scenarios...|$|R
40|$|This paper {{presents}} a very high-level introduction to Belief Revision and <b>Truth</b> <b>Maintenance</b> <b>Systems,</b> including explanations of basic terminology, a brief history, and {{a comment on}} the two literatures: the TMS literature, and the AGM Belief Revision literature. More extensive surveys {{in each of the}} two literatures are cited. The paper concludes with a proposal to continue the investigation of the two traditions, and to see how they might be brought together. ...|$|R
5000|$|Non-monotonic {{reasoning}}. Non-monotonic reasoning allows {{various kinds}} of hypothetical reasoning. The system associates facts asserted with the rules and facts used to justify them and as those facts change updates the dependent knowledge as well. In rule based systems this capability {{is known as a}} <b>truth</b> <b>maintenance</b> <b>system.</b>|$|E
5000|$|A proposition-denoting term in a SNePS KB {{might or}} might not be [...] "asserted", that is, treated as true in the KB. The SNePS logic is a paraconsistent version of {{relevance}} logic, so that a contradiction does not imply anything whatsoever. Nevertheless, SNeBR, the SNePS Belief Revision subsystem, will notice any explicit contradiction and engage the user in a dialogue to repair it. SNeBR is an Assumption-Based <b>Truth</b> <b>Maintenance</b> <b>System</b> (ATMS), and removes the assertion status of any proposition whose support has been removed.|$|E
50|$|While working (starting in 1975) as a {{research}} assistant at MIT under Gerry Sussman, Stallman published a paper (with Sussman) in 1977 on an AI <b>truth</b> <b>maintenance</b> <b>system,</b> called dependency-directed backtracking. This paper was an early work {{on the problem of}} intelligent backtracking in constraint satisfaction problems. , the technique Stallman and Sussman introduced is still the most general and powerful form of intelligent backtracking. The technique of constraint recording, wherein partial results of a search are recorded for later reuse, was also introduced in this paper.|$|E
50|$|A {{different}} {{realization of}} the foundational approach to belief revision is based on explicitly declaring the dependences among beliefs. In the <b>truth</b> <b>maintenance</b> <b>systems,</b> dependence links among beliefs can be specified. In other worlds, one can explicitly declare that a given fact is believed because {{of one or more}} other facts; such a dependency is called a justification. Beliefs not having any justifications play the role of non-derived beliefs in the non-deductively closed knowledge base approach.|$|R
40|$|This brief note is {{intended}} to familiarize the non-TMS audience {{with some of the}} basic ideas surrounding classic TMS's (<b>truth</b> <b>maintenance</b> <b>systems),</b> namely the justification-based TMS and the assumption-based TMS. Topics of further interest include the relation between non-monotonic logics and TMS's, efficiency and search issues, complexity concerns, as well as the variety of TMS systems that have surfaced in the past decade or so. These include probabilistic-based TMS systems, fuzzy TMS systems, tri-valued belief systems, and so on...|$|R
40|$|We have recast {{the problem}} of <b>truth</b> <b>maintenance</b> in a setting of {{algebraic}} equations over Boolean lattices. If a method of labeling propositions to justify them according to some reasoning agent's constraints of belief happens {{to conform to the}} postulates of Boolean lattices, the labeling system can be reformulated as an algebraic equation solving <b>system.</b> All <b>truth</b> <b>maintenance</b> <b>systems</b> known to us can be so reformulated. This note summarizes our investigations into the existence and structure of solutions of these algebraic systems. Our central result is a unique factorization theorem for lattice equational systems and their solutions. Our theoretical results are interpreted to compare various styles of <b>truth</b> <b>maintenance</b> and to reveal certain computational difficulties implicit in the algebraic structure of <b>truth</b> <b>maintenance.</b> I...|$|R
50|$|A <b>truth</b> <b>maintenance</b> <b>system</b> {{maintains}} consistency between old believed {{knowledge and}} current believed {{knowledge in the}} knowledge base (KB) through revision. If the current believed statements contradict the knowledge in the KB, then the KB is updated with the new knowledge. It may happen that the same data will again be believed, and the previous knowledge will be required in the KB. If the previous data are not present, but may be required for new inference. But if the previous knowledge was in the KB, then no retracing of the same knowledge is needed. The use of TMS avoids such retracing; it keeps track of the contradictory data {{with the help of}} a dependency record. This record reflects the retractions and additions which makes the inference engine (IE) aware of its current belief set.|$|E
50|$|Many {{kinds of}} truth {{maintenance}} systems exist. Two major types are single-context and multi-context truth maintenance. In single context systems, consistency is maintained among all facts in memory (KB) and {{relates to the}} notion of consistency found in classical logic. Multi-context systems support paraconsistency by allowing consistency to be relevant to a subset of facts in memory, a context, according to the history of logical inference. This is achieved by tagging each fact or deduction with its logical history. Multi-agent truth maintenance systems perform truth maintenance across multiple memories, often located on different machines. de Kleer's assumption-based <b>truth</b> <b>maintenance</b> <b>system</b> (ATMS, 1986) was utilized in systems based upon KEE on the Lisp Machine. The first multi-agent TMS was created by Mason and Johnson. It was a multi-context system. Bridgeland and Huhns created the first single-context multi-agent system.|$|E
40|$|This paper {{presents}} a logically complete assumption based <b>truth</b> <b>maintenance</b> <b>system</b> (ATMS) {{that is part}} of a complex blast furnace computer aided piloting system [5]. This system is built on an efficient and logically complete propositional constraint solver that has been successfully used for industrial applications in computer aided design. 1 Introduction A reasoning maintenance system (RMS) is a critical part of a reasoning system, since it is responsible for assuring that the inferences made by that system are valid. The reasoning system provides the RMS with information about each inference it performs, and in return the RMS provides the reasoning system with information about the whole set of inferences. Several implementations of reasoning maintenance systems have been proposed in the past, remarkable ones being Doyle's <b>truth</b> <b>maintenance</b> <b>system</b> (TMS) [6], and De Kleer's assumption-based <b>truth</b> <b>maintenance</b> <b>system</b> (ATMS) [7]. Both of them suffer from some limitations. The [...] ...|$|E
40|$|Probabilistic Reasoning in Intelligent Systems is a {{complete}} and accessible account of the theoretical foundations and computational methods that underlie plausible reasoning under uncertainty. The author provides a coherent explication of probability as a language for reasoning with partial belief and offers a unifying perspective on other AI approaches to uncertainty, such as the Dempster-Shafer formalism, <b>truth</b> <b>maintenance</b> <b>systems,</b> and nonmonotonic logic. The author distinguishes syntactic and semantic approaches to uncertainty [...] and offers techniques, based on belief networks, that provi...|$|R
40|$|Bibliography: pages 227 - 236. This thesis {{concentrates}} on several important issues in expert system research, namely - representation of knowledge - control of reasoning - implementation of non-monotonic logics via <b>truth</b> <b>maintenance</b> <b>systems.</b> There are three parts to this thesis. PART 1 covers the background {{research in the}} above mentioned topics. PART 2 discusses the WISE system {{and the way in}} which research from PART 1 was applied to the development of the WISE shell. PART 3 considers the features of other expert system shells...|$|R
40|$|This paperpresents anewapproach for {{exploiting}} <b>Truth</b> <b>Maintenance</b> Systems(TMSs {{in which}} the inference engine can convey locality in its knowledge to the TMS. This approach is ideally suited for systems which reason about the physical world because much of knowledge is inherently local, i. e., the constraints for a particular component or process usually only interact with constraints of physically adjacent components and processes. The new TMSs operate {{with a set of}} arbitrary propositional formulae and use general Boolean Constraint Propagation(BCP) to answer queries about whether a particular literal follows from the formulae. Our TMS exploits the observation that if propositional formulae are converted to their prime implicates, then BCP is both efficient and logically complete. This observation allows the problem solver to influence the degree of completeness oftheTMS by controllinghowmany prime implicates are constructed. This control is exerted by using the locality in the original task to guide which combinations of formulae should be reduced to their prime implicates. We show that conveying locality to the TMS is an important strategy for qualitative physics problem solvers. For example, at a minimum formulae corresponding to a single component (or commonly occurring combinations) model should be compiled into prime implicates in order to minimize run-time cost. When confluence models are used, the results of using ourTMS subsume those of the qualitative reasolution rule. This approach has been implemented and tested both within Assumption-Based <b>Truth</b> <b>Maintenance</b> <b>Systems</b> and Logic-Based <b>Truth</b> <b>Maintenance</b> <b>Systems.</b> ...|$|R
40|$|Many procedurally-oriented {{problem solving}} {{systems can be}} viewed as {{performing}} a mixture of computation and deduction, with much of the computation serving to decide what deductions should be made. This results in bits and pieces of deductions being strewn throughout the program text and execution. This paper describes a problem solver subsystem called a <b>truth</b> <b>maintenance</b> <b>system</b> which collects and maintains these bits of deductions. Automatic functions of the <b>truth</b> <b>maintenance</b> <b>system</b> then use these pieces of "proofs" to consistently update a data base of program beliefs and to perform a powerful form of backtracking called dependency-directed backtracking...|$|E
40|$|To {{choose their}} actions, {{reasoning}} programs {{must be able}} to draw conclusions from limited information and subsequently revise their beliefs when discoveries invalidate previous assumptions. A <b>truth</b> <b>maintenance</b> <b>system</b> is a problem solver subsystem for performing these functions by recording and maintaining the reasons for program beliefs. These recorded reasons are useful in constructing explanations of program actions in "responsible" programs, and in guiding the course of action of a problem solver. This paper describes the structure of a <b>truth</b> <b>maintenance</b> <b>system,</b> methods for encoding control structures in patterns of reasons for beliefs, and the method of dependency-directed backtracking...|$|E
40|$|It is {{possible}} to incorporate a system which manages a knowledge base into an expert system. Because, by using this system, we can rebuild knowledge bases which have no logical contradictions with knowledge of experts and phenomena which we experience daily. However, {{it is difficult to}} build beyond systems in the machining field due to the existence of many kinds of knowledge, if we want to achieve rebuilding of the knowledge bases using current representation language. Thus, we developed a <b>truth</b> <b>maintenance</b> <b>system</b> for knowledge bases by using a new predicate-logic representation language. This paper describes how to manage knowledge bases and how to treat the functions in a <b>truth</b> <b>maintenance</b> <b>system</b> using this system when contradictions occur in the practical machining problem...|$|E
40|$|Assumption-based <b>truth</b> <b>maintenance</b> <b>systems</b> {{have become}} a {{powerful}} and widely used tool in Artificial Intelligence problem solvers. The basic ATMS is restricted to accepting only horn clause justifications. Although various generalizations have been made and proposed to allow an ATMS to handle more general clauses, they have all involved the addition of complex and difficult to integrat~’hyperresolution rules. This paper presents an alternative approach based on negated assumptions which integrates simply and cleanly into existing ATMS algorithms and which {{does not require the}} use of a hyperresolution rule to ensure label consistency. ...|$|R
40|$|Propositional {{representation}} {{services such}} as <b>truth</b> <b>maintenance</b> <b>systems</b> offer powerful support for incremental, interleaved, problem-model construction and evaluation. Probabilistic inference systems, in contrast, have lagged behind in supporting this incrementality typically demanded by problem solvers. The problem, we argue, is that the basic task of probabilistic inference is typically formulated at too large a grain-size. We show how a system built around a smaller grain-size inference task can have the desired incrementality and {{serve as the basis}} for a low-level (propositional) probabilistic representation service. Comment: Appears in Proceedings of the Ninth Conference on Uncertainty in Artificial Intelligence (UAI 1993...|$|R
5000|$|<b>Truth</b> <b>maintenance.</b> These <b>systems</b> {{record the}} {{dependencies}} in a knowledge-base {{so that when}} facts are altered, dependent knowledge can be altered accordingly. For example, if the system learns that Socrates is no longer {{known to be a}} man it will revoke the assertion that Socrates is mortal.|$|R
