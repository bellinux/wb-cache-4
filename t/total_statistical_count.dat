0|446|Public
40|$|Collecting data via a {{questionnaire}} and analyzing them while preserving respondents' privacy {{may increase the}} number of respondents and the truthfulness of their responses. It may also reduce the systematic differences between respondents and non-respondents. In this paper, we propose a privacy- preserving method for collecting and analyzing survey responses using secure multi-party computation. The method is secure under the semi-honest adversarial model. The proposed method computes a wide variety of statistics. <b>Total</b> and stratified <b>statistical</b> <b>counts</b> are computed using the secure protocols developed in this paper. Then, additional statistics, such as a contingency table, a chi-square test, an odds ratio, and logistic regression, are computed within the R statistical environment using the <b>statistical</b> <b>counts</b> as building blocks. The method was evaluated on {{a questionnaire}} data set of 3158 respondents sampled for a medical study and simulated questionnaire data sets of up to 50 000 respondents. The computation time for the statistical analyses linearly scales as the number of respondents increases. The results show that the method is efficient and scalable for practical use. It can also be used for other applications in which categorical data are collected...|$|R
5000|$|... #Subtitle level 2: Rankings {{based on}} other <b>statistical</b> <b>counts</b> ...|$|R
40|$|For wavelength-dispersive {{analysis}} of trace elements at near-background concentrations, background subtraction poses special problems because {{the background is}} complex and difficult to measure or predict with certainty. Several sources contribute. These include Compton- and Rayleigh-scattered tube continuum radiation, nondiscriminated higher-order radiation, fluorescence of instrument parts, Compton- and Rayleigh-scattered tube lines, unresolved spectral interferences, and electronic noise. Other complications include sample, source, and detector absorption edges, diffraction by the sample, limited sample thickness, and a complicated and variable geometry of the analyzed sample volume. This paper describes a Lagrange interpolation method, in which any suitable theoretical or empirical background estimate {{can be used to}} “linearize ” the data and to improve the accuracy of interpolation. The method combines the advantages of prior methods. In particular, it easily allows spectral interference corrections and calculation of <b>total</b> <b>counting</b> <b>statistical</b> errors, and it does not require background positions free from spectral interference. In principle, it also allows placing upper limits on total background-subtraction errors. In a test on SiO 2 and Fe 203 backgrounds, the method estimated background intensities accurately and outperformed a method based on empirical shape factors...|$|R
5000|$|I am {{conducting}} a <b>statistical</b> <b>count</b> of the Cepheid {{variables in the}} Great Nebula of Andromeda. ("The Absent Minded Professor" [...] as [...] "First Star I See Tonight," [...] 1954) ...|$|R
40|$|Structural {{condition}} assessment {{technology has}} gained widespread applications for providing desired solution to assess safety and serviceability of civil engineering structures. The structural reliability assessment which incorporates structural health monitoring (SHM) data {{is capable of}} providing authentic information about in-service performance of the instrumented structure and accommodating uncertainties in the measurement data. Because the peak values of the measurands which illustrate the critical condition/status of the structure are random in nature, {{it is important to}} adopt appropriate <b>statistical</b> <b>counting</b> methods to extract favorable peak values for reliability assessment. Several algorithms, such as the sampling method, the peak counting method, and the pointwise counting method, have been proposed for peak counting. In the present study, different <b>statistical</b> <b>counting</b> methods for the selection of peak data targeted for SHM-based reliability assessment of instrumented bridges are examined and compared, through the application of the above methods for the purpose of constructing peak-stress histograms and formulating probability density functions by use of long-term strain monitoring data from an instrumented bridge. Peak covering rate is defined to serve as a common basis for relating the amount of peak data and the control parameters for peak counting and helping determine the values of the control parameters in different <b>statistical</b> <b>counting</b> methods which ensure identical peak covering rate. The reliability indices obtained from the different <b>statistical</b> <b>counting</b> methods under the same amount of peak data are also compared. Department of Civil and Environmental Engineerin...|$|R
5000|$|Then, the <b>total</b> <b>statistical</b> weight , can {{be written}} as {{the sum of the}} [...] state and the RNA {{polymerase}} on promoter state: ...|$|R
40|$|In this paper, <b>statistical</b> <b>counting</b> is {{introduced}} {{in the context of}} stochastic local search. From a sample of trajectories by independent local search computations, it is shown that interesting statistical information can be actually extracted about the search space, most notably an unbiased estimate of the number of solutions. Computational results for random #SAT instances are provided...|$|R
40|$|The {{absolute}} monocyte {{count was}} determined in 100 normal individuals and in 100 {{patients with a}} variety of solid tumor malignancies. A significant elevation in the mean value for the latter group was found. Monocytosis is therefore of descriptive and diagnostic value in the evaluation of patients with solid tumor malignancy. MONOCYTOSIS occurs in a variety of conditions, most notably infectious diseases and several hematologic disorders, especially Hodgkin's disease and mono-cytic leukemia. On the other hand, its occurrence in solid tumor malignancy has received little attention. The observation that an increase in the absolute monocyte count is a frequent finding in patients with such malignancy is the basis of this report. Materials and Methods The absolute monocyte count was determined in 100 patients being observed or treated for a variety of solid tumor malignancies, excluding lymphomas. This count was compared with the absolute monocyte count deter-mined in 100 healthy adults undergoing annual routine physical examinations. The total leukocyte count was in all cases determined with a Coulter counter, whereas the differential was determined on the basis of 200 cells counted. The absolute monocyte count was found by applying the percent of monocytes in the differential to the <b>total</b> leukocyte <b>count.</b> <b>Statistical</b> comparisons were made using the Mann-Whitney two-sample rank test for nonparametric data (1). Most patients had adenocarcinoma of the breast or the gastrointestinal tract. In 68 patients monocyte counts were made before the institution of antitumor therapy, and in the remaining 32 patients counts were made while they were receiving 5 -fluorouracil or cyclophos...|$|R
40|$|Context: The {{survival}} of atraumatic restorative treatment (ART) restorations would probably increase if near total elimination of cariogenic microorganisms {{could be done}} in the process of cavity cleaning before going ahead with the restoration. Thus, use of naturally occurring disinfecting agents for achieving this goal could herald a new beginning in the field of contemporary minimum intervention dentistry. Aims: To evaluate the efficacy of hand instruments in excavating dental caries and comparatively evaluate the roles of Aloe vera and propolis as potential cavity disinfecting agents after minimally invasive hand excavation of dental caries. Settings and Designs: Experimental, in vivo intergroup split mouth, randomized clinical trial. Subjects and Methods: The study included Group I (Control), Group II (A. vera) and Group III (propolis). Ten patients with three teeth each have occlusal/occlusoproximal lesions suitable for ART were selected. Dentinal samples were collected three times from each tooth viz., preexcavation, postexcavation and postdisinfection of the cavities. These dentinal samples were subjected to microbiological analyses for <b>total</b> viable <b>count.</b> <b>Statistical</b> Analysis Used: Repeated measures of analysis of variance (ANOVA) with Bonferroni post-hoc test and one-way ANOVA with Tukey post-hoc test. Results: In all the three groups, significant amount of bacteria were left behind after hand excavation. Group II and Group III, in which cavities were treated with A. vera and propolis extracts respectively, showed a significant reduction in the bacterial counts when compared to control the group. Conclusions: Hand excavation alone does not completely eliminate bacteria, which may predispose treated teeth to secondary caries. Both propolis and A. vera extracts can be used as potential natural disinfecting agents, thereby embracing the concept of phytotherapy in minimum intervention dentistry...|$|R
40|$|We {{computed}} {{the statistical}} entropy of nonextremal 4 D and extremal 5 D Calabi-Yau black holes and found exact {{agreement with the}} Bekenstein-Hawking entropy. The computation {{is based on the}} fact that the near-horizon geometry of equivalent representations contains as a factor the Bañados-Teitelboim-Zanelli black hole and on subsequent use of Strominger’s proposal generalizing the <b>statistical</b> <b>count</b> of microstates of the BTZ black hole due to Carlip. PACS numbers: 04. 70. Dy, 11. 25. Mj Keywords: microscopic entropy, N= 2 black holes, AdS 3 geometr...|$|R
40|$|BACKGROUND: Von Willebrand disease (vWD) is an {{inherited}} hemostatic disorder {{that affects the}} hemostasis pathway. The worldwide prevalence of vWD {{is estimated to be}} 1 % of the general population but only 0. 002 % in Malaysia. AIM: Our present paper has been written to disclose the <b>statistical</b> <b>counts</b> on the number of vWD cases reported from 2011 to 2013. MATERIAL AND METHODS: This article is based on sociodemographic data, diagnoses and laboratory findings of vWD in Malaysia. A total of 92 patients were reported to have vWD in Malaysia from 2011 to 2013. RESULTS: Sociodemographic-analysis revealed that 60 % were females, 63 % were of the Malay ethnicity, 41. 3 % were in the 19 - 44 year old age group and 15. 2 % were from Sabah, with the East region having the highest registered number of vWD cases. In Malaysia, most patients are predominately affected by vWD type 1 (77. 2 %). Factor 8, von Willebrand factor: Antigen and vWF: Collagen-Binding was the strongest determinants in the laboratory profiles of vWD. CONCLUSION: This report has been done with great interest to provide an immense contribution from Malaysia, by revealing the <b>statistical</b> <b>counts</b> on vWD from 2011 - 2013...|$|R
40|$|We derive general {{formulae}} for computing {{the average}} spectrum for Bosonic or Fermionic massless emission from generic or particular sets of closed superstring quantum states, {{among the many}} occurring at a given large value of the number operator. In particular we look for states that can produce a Bosonic spectrum resembling the classical spectrum expected for peculiar cusp-like or kink-like classical configurations, and we perform a <b>statistical</b> <b>counting</b> of their average number. The results can be relevant {{in the framework of}} possible observations of the radiation emitted by cosmic strings. 1...|$|R
40|$|NUREG 1400 {{contains}} an acceptable methodology {{for determining the}} uncertainty associated with retrospective air sampling. The method is a fairly simple one in which both the systemic and random uncertainties, usually expressed as a percent error, are propagated using the square root of {{the sum of the}} squares. Historically, many people involved in air sampling have focused on the <b>statistical</b> <b>counting</b> error as the deciding factor of overall uncertainty in retrospective air sampling. This paper looks at not only the counting error but also other errors associated with the performance of retrospective air sampling...|$|R
50|$|In 2001, {{she gained}} {{national}} press attention {{when she and}} State Senator Margaret Carter (D-Portland) filed suit in U.S. District Court to force the Census Bureau to disclose its adjusted <b>statistical</b> <b>count,</b> which they suspected would reveal an undercount {{of as many as}} 43,000 Oregonians. They further estimated the cost to the State of Oregon in lost federal funding for social and educational programs over ten years at US$16 million. Judge James A. Redden ruled in favor of the disclosure, and the decision was upheld in 2002 on appeal by the Census Bureau.|$|R
40|$|In {{this paper}} we {{describe}} {{ideas about the}} string landscape, and how to relate it to the physics of the Standard Model of particle physics. First, we give a short status report about heterotic string compactifications. Then {{we focus on the}} statistics of D-brane models, on the problem of moduli stabilization, and finally on some attempts to derive a probability wave function in moduli space, which goes beyond the purely <b>statistical</b> <b>count</b> of string vacua. Comment: Contribution to the 11 th. Marcel Grossmann Meeting on General Relativity in Berlin, July 2006 }, new refs. added, typos correcte...|$|R
40|$|In 1975, D. Knuth {{proposed}} a simple statistical method for investigating search trees. We use this technique for estimating {{the number of}} solutions of CSP (Constraint Satisfaction Problem) and SAT (Boolean Satisfiability Problem) instances. We show that, depending on domain reductions, treebased estimates have a lower variance than estimates based on uniform sampling from the search space. Nevertheless, because the variance remains extremely high in the general case, a confidence interval cannot be derived but a lower bound {{of the number of}} solutions. These results are confirmed by many experiments. Keywords: <b>Statistical</b> <b>counting,</b> #P-Complete problems, Constraint satisfaction, Satisfiability. ...|$|R
40|$|In the {{diagnostic}} use of radioisotopes, one must strive to administer {{to the patient}} the smallest amount of radioactivity consistent {{with the demands of}} the study. The activity required for a satisfactory thyroid-uptake study is the activity that reduces the <b>statistical</b> <b>counting</b> uncertainty in the uptake result to an acceptable level in a reasonable counting time. Additional activity results in unnecessarily good statistics and increases the radiation dose to the patient. In general, the activity required depends on the sensitivity of the detector used, the counting times, the room background and the fraction of the tracer taken up by the thyroid. Doses of 5 â€” 2...|$|R
40|$|This work {{serves to}} {{quantify}} the instantaneous uncertainties in neutron transport simulations born from nuclear data and <b>statistical</b> <b>counting</b> uncertainties. Perturbation and adjoint theories are used to derive implicit sensitivity expressions. These expressions are transformed into forms that are convenient for construction with MCNP 6, creating the ability to perform adjoint-based uncertainty quantification with MCNP 6. These new tools are exercised on the depleted-uranium hybrid LIFE blanket, quantifying its sensitivities and uncertainties to important figures of merit. Overall, these uncertainty estimates are small (< 2 %). Having quantified the sensitivities and uncertainties, physical understanding {{of the system is}} gained and some confidence in the simulation is acquired...|$|R
30|$|SPI data {{confirms}} {{that some of}} the meteorological drought years match well with the historical records of actual droughts observed by the respondents. Thus, <b>statistical</b> <b>counts</b> of drought episodes from SPI values can be used to obtain the overall drought characteristics in the study area over time. The SPI analysis shows that extreme drought events have increased over the last 63  years, with 28.5  % of drought occurrences falling in the two decades between 1950 and 1970 in contrast to 47.9  % of drought years occurring in the study area during the last two decades between 1990 and 2012. It seems clear from the data presented and discussed here that drought is the absolute norm in Turkana territory and “good” or “normal” years are the abnormality.|$|R
40|$|This {{study was}} an attempt to {{investigate}} types of French language interference in 113 English compositions written by the Francophone secondary school students of Ntem Division, Cameroon. Analyses and explications were afforded in an attempt to verify the Igpothesis that French, the second language of the subjects, interfered with their efforts to produce correct linguistic structures in English. The analyses revealed French interference at all the levels of language design, especially in the area of linguistic specifics where there is no one-to-one correspondence between French and English structures. Results of the <b>statistical</b> <b>count</b> showed that French language interference accounted for 51 percent of all the errors analyzed in the present study. Suggestions of a general nature were also provided for remedial pedagogy. Thesis (M. A. ...|$|R
40|$|We survey {{possibilistic}} {{systems theory}} {{and place it}} in the context of Imprecise Probabilities and General Information Theory (git). In particular, we argue that possibilistic systems hold a distinct position within a broadly conceived, synthetic git. Our focus is on systems and applications which are semantically grounded by empirical measurement methods (<b>statistical</b> <b>counting),</b> rather than epistemic or subjective knowledge elicitation or assessment methods. Regarding fuzzy measures as special previsions, and evidence measures (belief and plausibility measures) as special fuzzy measures, thereby we can measure imprecise probabilities directly and empirically from set-valued frequencies (random set measurement). More specifically, measurements of random intervals yield empirical fuzzy intervals. In the random set (Dempster-Shafer) context, probability and possibility measures stand as special plausibility measures in that their "distributionality" (decomposability) maps directly to an "a [...] ...|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceThis paper {{presents}} several {{methods for}} topic detection on newspaper articles, using either a general vocabulary or topic-specific vocabularies. Specific vocabularies are determined manually or statistically. In both cases, {{we aim at}} finding the most representative words of a topic. Several methods have been experimented, {{the first one is}} based on perplexity, this method achieves a 100 % topic identification rate, on large test corpora, when the two first propositions are taken into account. Other methods are based on <b>statistical</b> <b>counts</b> and achieve 94 % of identification on smaller test corpora. The most challenge of this work is to identify topics with only few words in order to be able, during speech recognition, to determine the best adequate language model...|$|R
5000|$|Hooker was {{recruited}} by [...] with their seventeenth selection and 130th {{overall in the}} inaugural AFL Women's draft. In January 2017, she was voted into Fremantle's leadership group. She made her debut in the thirty-two point loss to the [...] at VU Whitten Oval in the opening round of the 2017 season. Despite a disappointing season on the field for Fremantle, Hooker thrived and was named in Fremantle's best players in every match for the season and led the <b>statistical</b> <b>counts</b> at the club for disposals, kicks, marks and was second in inside-50s. Her performances during the season saw her win Fremantle's inaugural fairest and best award where she finished one vote ahead of club captain, Kara Donnellan, and she was also named in the initial forty player squad for the All-Australian.|$|R
3000|$|The SPSS 17.0 {{statistical}} {{package was}} used for the <b>statistical</b> analysis. The <b>counting</b> data were expressed as percentages and analyzed by using the χ [...]...|$|R
40|$|By using {{environmental}} scanning electron microscopy, the morphological changes of Vero cells attached to and grown on the microcarrier Cytodex- 3 were observed, and their behavior of adhesion, spreading and proliferation was analyzed. The effect of exogenous fibronectin/laminin on adhesion and spreading of MCC/Vero cell was studied. The images of ESEM showed that expansion of cell growth was directed toward vacancy space. The growth curve and cell concentration change {{during the whole}} culture process {{were obtained from the}} <b>statistical</b> <b>counting</b> method based on ESEM images and the crystal violet method. The growth rate of Vero cells increases with increasing the concentration of cell inoculation, that is, the specific growth rate increases quickly with increasing the concentration of cell inoculation. When serum concentration in medium # 199 ranged from 5 % to 10 %, experimental results indicated that serum concentration is one of the important factors influencing cell growth, particularly in the cell adhesion and spreading stage. By using {{environmental scanning}} electron microscopy, the morphological changes of Vero cells attached to and grown on the microcarrier Cytodex- 3 were observed, and their behavior of adhesion, spreading and proliferation was analyzed. The effect of exogenous fibronectin/laminin on adhesion and spreading of MCC/Vero cell was studied. The images of ESEM showed that expansion of cell growth was directed toward vacancy space. The growth curve and cell concentration change during the whole culture process were obtained from the <b>statistical</b> <b>counting</b> method based on ESEM images and the crystal violet method. The growth rate of Vero cells increases with increasing the concentration of cell inoculation, that is, the specific growth rate increases quickly with increasing the concentration of cell inoculation. When serum concentration in medium # 199 ranged from 5 % to 10 %, experimental results indicated that serum concentration is one of the important factors influencing cell growth, particularly in the cell adhesion and spreading stage...|$|R
40|$|International audienceIn this article, {{we present}} a work {{undergone}} since 2005 whose goal is to integrate neologism study into a system dedicated to general lexicography for French. This platform aims at describing words and meaning sequences in a general dictionary while keeping in touch continuously with discourses : first to track new meanings and words, second to track life of meanings and words through specific <b>statistical</b> <b>counts</b> and linguistic procedures. In this framework, neologia is a core element as a dictionary must include new words and meanings {{as soon as they}} belong to usage as well as identifying out-of-usage words. This article is divided into three parts : the first one will describe the architecture of the system; the second part willl detail the macro and microstructure of the neologism dictionary; the last part will detail the procedures to keep track of neologism life that also apply to dictionay entries...|$|R
40|$|A {{synthesis}} of the observational data {{on the distribution of}} galaxies is made by expressing the <b>statistical</b> <b>counts</b> in cells of variable size in terms of the generating functional for the N-point correlation functions. A complex fractal structure is thereby derived from a simple scaling property of the correlation functions and from the finiteness of the overall density of galaxies. Bifractality occurs in two different scaling ranges. The formalism may be used to build new fractal structures for sets of points from scaling hypotheses on correlation functions. 1. INTRODUCTION The distribution of matter in the Universe is probably the oldest paradigm of fractality. In the major part of the literature devoted to this theme, which is already ancient, models of fractal structures are first constructed, then checked against observations. This short course will present a converse approach. The data about the actual distribution of galaxies in the 10 to 100 Mpc range are now rather precise and [...] ...|$|R
40|$|Abstract. A {{low carbon}} steel is austenitized and isothermally held at 680 C to form {{allotriomorphic}} ferrite and followed by a holding at lower temperature to form bainite. The morphology of allotriomorphic ferrite/bainite interfaces is studied using optical microscope. Three kinds of combination are observed: Type I: interface on one side is clear while on the other side, unclear; Type II: unclear on both sides; Type III: clear on both sides. Clear interface indicates a large difference in the orientation between the bainite and the ferrite, and unclear interface, a very small difference. The <b>statistical</b> <b>counting</b> shows that the ratio of Type I is about 80 - 82 %, and that of Type II, 7 - 8 %, and Type III, 9 - 11 %. It is observed that this ratio does not change with the austenite grain size and bainite forming temperature. And the clear and unclear side of allotriomorphic ferrite may have different influence on the nucleation rate of bainite at allotriomorhic ferrite/prior austenite interface...|$|R
40|$|This paper {{describes}} Census, {{a protocol}} for data aggregation and <b>statistical</b> <b>counting</b> in MANETs. Census operates by circulating {{a set of}} tokens in the network using biased random walks such that each node is visited {{by at least one}} token. The protocol is structure-free so as to avoid high messaging overhead for maintaining structure in the presence of node mobility. It biases the random walks of tokens so as to achieve fast cover time; the bias involves short albeit multi-hop gradients that guide the tokens towards hitherto unvisited nodes. Census thus achieves a cover time of O(N/k) and message overhead of O(Nlog(N) /k) where N is the number of nodes and k the number of tokens in the network. Notably, it enjoys scalability and robustness, which we demonstrate via simulations in networks ranging from 100 to 4000 nodes under different network densities and mobility models. Comment: 25 pages, technical report, index terms:random walk, MANET, statistical aggregation, gossip, local gradient...|$|R
40|$|Pulse shape {{analysis}} {{is an important}} background reduction and signal identification technique for next generation of 0 νββ experiments examining 76 Ge. We present {{a study of the}} systematic uncertainties in one such parametric pulse{{shape analysis}} technique for separating multi-site backgrounds from single-site signal events. We examined systematic uncertainties for events in full-energy gamma peaks (predominantly multi-site), double-escape peaks (predominantly single-site) and the Compton continuum near Qββ (which will be the dominant background for most 0 νββ searches). In short, we find <b>total</b> (<b>statistical</b> plus systematic) fractional uncertainties in the pulse shape cut survival probabilities of: 6. 6 %, 1. 5 % and 3. 8 % for double-escape, continuum and γ-ray events respectively...|$|R
40|$|Background: Nutritional {{status in}} {{relation}} to selected biochemical parameters and also nutrient intakes in the pre-eclampsia and eclampsia was assessed in 52 patients and {{compared with that of}} 52 normal pregnant (NP) women. Serum calcium, ascorbic acid and blood Hb levels in the pre-eclamptic and eclamptic patients were significantly lower than the values of NP women. By unpaired t-test demonstrated in our study, the serum calcium, ascorbic acid and blood Haemoglobin (Hb) level were highly significantly different but not correlated with each other when compared among these groups. However, <b>total</b> <b>statistical</b> analysis revealed that among all the factors studied serum calcium level, ascorbic acid level and blood Hb level have effect on nutritional status of pre-eclampsia and eclampsia...|$|R
30|$|In principle, both {{of results}} from RSS and SUT {{must be the}} same. However, this result is {{different}} from the other. SUT’s result is worse than that of RSS. Please refer to Figures  10 and 11. It is clear that the quality of designed circuits of SUT is not better than that of RSS. Because <b>statistical</b> fluctuation of <b>counts</b> in higher channels is bigger than <b>statistical</b> fluctuation of <b>counts</b> in lower channels, therefore deviations of counts in higher channels must be larger. This reason makes spectrum in higher channels bigger, it means that there is an increment for DNL.|$|R
30|$|In {{frequency}} domain feature extraction, Yadav and Kalra [4] has used spectrogram of the acoustic signal. In this technique {{they have used}} <b>total</b> nine <b>statistical</b> features like kurtosis, shape factor, crest factor, mean, median and the variance of spectrogram for classification by an ANN-based classifier.|$|R
40|$|We {{propose a}} novel {{algorithm}} for counting N indistinguishable objects, called targets, by {{a collection of}} sensors. We adopt a minimalist scenario where sensors are unaware of the (non-empty) intersections of sensing regions, and so simple addition of all sensor counts inflates estimates {{of the total number}} of targets. The multiple counting in intersections must be accounted for, but with nothing more than the sensor counts, this is clearly impossible. However, noise is typically present in the target counting of many, if not most, applications. We make the key observation that if there is a (target-dependent) noise source affecting all sensors simultaneously, then it couples those with non-empty intersections. Exploitation of this coupling allows us to extract multiple-counting statistics from stochastic correlation patterns, and hence to compute accurate estimates of N via the classical inclusion-exclusion formula. Cumulants are the correlation measures of choice. Our analysis brings out and resolves certain technicalities that arise in our <b>statistical</b> <b>counting</b> algorithm. Examples are worked out to show the potential of the new algorithm. The paper concludes with a discussion of alternative models and open problems...|$|R
40|$|As {{the result}} of {{interactions}} between visitors and a web site, an http log file contains very rich knowledge about users on-site behaviors, which, if fully exploited, can better customer services and site performance. Different {{to most of the}} existing log analysis tools which use <b>statistical</b> <b>counting</b> summaries on pages, hosts, etc., we propose a transaction model to represent users access history and a framework to adapt data mining techniques such as sequence and association rule mining to these transactions. In this framework, all transactions are extracted from the raw log file though a series of step by step data preparation phases. We discuss different methods to identify a user, and separate long convoluted sequences into semantically meaningful sessions and transactions. A new feature called interestingness is defined to model user interests in different web sections. With all the transactions being imported into an adapted cube structure with a concept hierarchy attached to each dimension of it, it is possible to carry out multi-dimensional data mining at multi-abstract levels. Using interest context rules, we demonstrate the potentially significant meaning of this system prototype...|$|R
40|$|In 1936 R. A. Fisher {{asked the}} pointed question, "Has Mendel's Work Been Rediscovered?" The query was {{intended}} to open for discussion whether someone altered the data in Gregor Mendel's classic 1866 research report on the garden pea, "Experiments in Plant-Hybridization. " Fisher concluded, reluctantly, that the <b>statistical</b> <b>counts</b> in Mendel's paper were doctored {{in order to create}} a better intuitive fit between Mendelian expected values and observed frequencies. That verdict remains the received view among statisticians, so I believe. Fisher's analysis is a tour de force of so-called "Goodness of Fit" statistical tests using c 2 to calculate significance levels, i. e., P-values. In this presentation I attempt a defense of Mendel's report, based on several themes. (1) Mendel's experiments include some important sequential design features that Fisher ignores. (2) Fisher uses particular statistical techniques of Meta-analysis for pooling outcomes from different experiments. These methods are subject to critical debate. and (3) I speculate on a small modification to Mendelian theory that offers some relief from Fisher's harsh conclusion that Mendel's data are too good to be tru...|$|R
