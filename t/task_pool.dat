23|76|Public
50|$|Muskel also {{provides}} non-functional {{features such as}} Quality of Service (QoS); security between <b>task</b> <b>pool</b> and interpreters; and resource discovery, load balancing, and fault tolerance when interfaced with Java / Jini Parallel Framework (JJPF), a distributed execution framework. Muskel {{also provides}} support for combining structured with unstructured programming and recent research has addressed extensibility.|$|E
50|$|At the {{implementation}} level, Lithium exploits macro-data flow to achieve parallelism. When the input stream receives a new parameter, the skeleton program is processed {{to obtain a}} macro-data flow graph. The nodes of the graph are macro-data flow instructions (MDFi) which represent the sequential pieces of code provided by the programmer. Tasks are used to group together several MDFi, and are consumed by idle processing elements from a <b>task</b> <b>pool.</b> When the computation of the graph is concluded, the result is placed into the output stream and thus delivered back to the user.|$|E
40|$|Task pools {{can be used}} {{to achieve}} the dynamic load bal-ancing that is {{required}} for an efficient parallel implemen-tation of irregular applications. However, the performance strongly depends on a <b>task</b> <b>pool</b> implementation that is well suited for the specific application. This paper introduces an adaptive <b>task</b> <b>pool</b> implementation that enables a step-wise transition between the common strategies of central and distributed task pools. The influence of the task size on the parallel performance is investigated and it is shown that the adaptive implementation provides the flexibility to adapt to different situations. Performance results from benchmark programs and from an irregular application for anomalous diffusion simulation are presented to demonstrate the need for an adaptive strategy. It is shown that profiling informa-tion about the overhead of the <b>task</b> <b>pool</b> implementation {{can be used to}} determine an optimal <b>task</b> <b>pool</b> strategy...|$|E
40|$|Abstract. <b>Task</b> <b>pools</b> {{have been}} shown to provide {{efficient}} load balancing for irregular applications on heterogeneous platforms. Often, distributed data struc-tures are used to store the tasks and the actual load balancing is achieved by task stealing where an idle processor accesses tasks from another processor. In this paper we extent the concept of <b>task</b> <b>pools</b> to adaptive <b>task</b> <b>pools</b> which are able to adapt the number of tasks moved between the processor to the specific execution scenario, thus reducing the overhead for task stealing significantly. We present runtime experiments for different applications on two execution platforms. ...|$|R
40|$|Since {{a static}} work {{distribution}} {{does not allow}} for satisfactory speed-ups of parallel irregular algorithms, {{there is a need for}} a dynamic distribution of work and data that can be adapted to the runtime behavior of the algorithm. <b>Task</b> <b>pools</b> are data structures which can distribute tasks dynamically to different processors where each task specifies computations to be performed and provides the data for these computations. This paper discusses the characteristics of taskbased algorithms and describes the implementation of selected types of <b>task</b> <b>pools</b> for shared-memory multiprocessors. Several <b>task</b> <b>pools</b> have been implemented in C with POSIX threads and in Java. The <b>task</b> <b>pools</b> differ in the data structures to store the tasks, the mechanism to achieve load balance, and the memory manager used to store the tasks. Runtime experiments have been performed on three different shared-memory systems using a synthetic algorithm, the hierarchical radiosity method, and a volume rendering algorithm...|$|R
30|$|For single <b>task</b> <b>pooled</b> {{in these}} {{measures}} see Autor et al. (2003, p.  1323).|$|R
40|$|Clusters of SMPs (symmetric multiprocessors) {{are popular}} {{platforms}} for parallel programming since they provide large computational power for a reasonable price. For irregular application programs with dynamically changing computation and data access behavior a flexible programming model {{is needed to}} achieve efficiency. In this paper we propose <b>Task</b> <b>Pool</b> Teams as a hybrid parallel programming environment to realize irregular algorithms on clusters of SMPs. <b>Task</b> <b>Pool</b> Teams combine task pools on single cluster nodes by an explicit message passing layer. They offer load balance together with multi-threaded, asynchronous communication. Appropriate communication protocols and <b>task</b> <b>pool</b> implementations are provided and accessible by an easy to use application programmer interface. As application examples we present a branch & bound algorithm and the hierarchical radiosity algorithm...|$|E
40|$|The {{characteristics}} of irregular algorithms make a parallel implementation difficult, especially for PC clusters or clusters of SMPs. These characteristics may include an unpredictable access behavior to dynamically changing data structures or strong irregular coupling of computations. Problems are an unknown load distribution and expensive irregular communication patterns for data accesses and redistributions. Thus the parallel implementation of irregular algorithms on distributed memory machines and clusters requires a special organizational mechanism for a dynamic load balance {{while keeping the}} communication and administration overhead low. We propose <b>task</b> <b>pool</b> teams for implementing irregular algorithms on clusters of PCs or SMPs. A <b>task</b> <b>pool</b> team combines multithreaded programming using task pools on single nodes with explicit message passing between different nodes. The dynamic load balance mechanism of task pools is generalized to a dynamic load balance scheme for all distributed nodes. We have implemented and compared several versions for <b>task</b> <b>pool</b> teams. As application example, we use the hierarchical radiosity algorithm, {{which is based on}} dynamically growing quadtree data structures annotated by varying interaction lists expressing the irregular coupling between the quadtrees. Experiments are performed on a PC cluster and a cluster of SMPs...|$|E
40|$|In {{this paper}} {{we present a}} {{distributed}} algorithm to implement a <b>task</b> <b>pool.</b> The algorithm {{can be used to}} implement a processor farm, i. e., a collection of processes that consume tasks from the <b>task</b> <b>pool</b> and possibly produce tasks into it. There are no restrictions on which process consumes which task nor on the order in which tasks are processed. The algorithm takes care of the distribution of the tasks over the processes and ensures load balancing. We derive the algorithm by transforming a sequential algorithm into a distributed one. The transformation is guided by the distribution of the data over processes. First we discuss the case of two processes, and then the general case of one or more processes...|$|E
40|$|Since {{a static}} data {{distribution}} does [...] . This paper discusses {{the characteristics of}} task-based algorithms and describes the implementation of selected types of <b>task</b> <b>pools</b> for shared-memory multiprocessors. Several <b>task</b> <b>pools</b> have been implemented in C with POSIX threads and in Java. Results of these implementations measured on three different shared-memory systems are shown for a synthetic algorithm and the parallel hierarchical radiosity method...|$|R
40|$|We {{construct}} parallel algorithms with implementations {{to solve}} the clique problem in practice and research their computing time compared with sequential algorithms. The parallel algorithms are implemented in Java using threads. Best efficiency is achieved by solving the problem of task scheduling by using <b>task</b> <b>pools.</b> 1...|$|R
40|$|Early {{experiments}} withscheduling strategieson the GRIP distributed {{graph reduction}} system indicated {{the need for}} a more responsive load balancing mechanism and highlighted the communication costs associated with superfluous global sparking [HP 92]. Since that time, the GRIP runtime system has undergone a number of changes, and the new scheduler addresses both of the above problems. Previously, load balancing was controlled by a single "Load Manager" running on one of the processing elements. The Load Manager periodically sampled the size of the global <b>task</b> <b>pools</b> and adjusted the system's sparking behavior accordingly. Experiments indicated that the Load Manager was too slow in its response to changing conditions. In the current system, load balancing has been decentralized and is now handled by the intelligent memory units [...] -the same components that maintain the global <b>task</b> <b>pools.</b> As a result, the new load balancing mechanism is much quicker to adapt to changes in system load. The origi [...] ...|$|R
40|$|We {{present a}} novel method for massively {{parallel}} hierarchical scene processing on the GPU, {{which is based}} on sequential decomposition of the given hierarchical algorithm into small functional blocks. The computation is fully managed by the GPU using a specialized <b>task</b> <b>pool</b> which facilitates synchronization and communication of processing units. We present two applications of the proposed approach: construction of the bounding volume hierarchies and collision detection based on divide-and-conquer ray tracing. The results indicate that using our approach we achieve high utilization of the GPU even for complex hierarchical problems which pose a challenge for massive parallelization...|$|E
40|$|Using the <b>task</b> <b>pool</b> {{model and}} data from 15 establishments in the Dutch {{hospitality}} industry, this study shows {{how and why}} applying handhelds affects the division of labour. These devices allow to split the waiters' jobs into separate tasks {{which tend to be}} combined into two separate "sub jobs": the "palmtopper" and the "runner". Whereas handhelds are not necessary for creating separate waiting jobs, the technology enables to create conditions under which it becomes attractive for management to opt for an increased division of labour. We show the contingent conditions and underlying mechanisms which explain why certain choices prevail...|$|E
40|$|Abstract. A {{sophisticated}} {{approach for}} the parallel execution of irreg-ular applications on parallel shared memory machines is the decompo-sition into fine-grained tasks. These tasks can be executed using a <b>task</b> <b>pool</b> which handles the scheduling {{of the tasks}} independently of the ap-plication. In this paper we present a transparent way to profile irregular applications using task pools without modifying the source code of the application. We show {{that it is possible}} to identify critical tasks which prevent scalability and to locate bottlenecks inside the application. We show that the profiling information can be used to determine a coarse estimation of the execution time for a given number of processors. ...|$|E
40|$|Abstract—Chapel {{strives to}} combine {{programmability}} {{and performance in}} an architecture-independent way. We focus on programmability, and report on our ex-periences in implementing the Unbalanced Tree Search (UTS) benchmark with user-level <b>task</b> <b>pools.</b> Our con-tributions include a discussion on how to code objects that internally contain distributed arrays, as well as suggestions for language design such as support for locale-specific and task-specific data, scalar variable-based reduction, and the omission of const. The ambition of high-productivity parallel program-ming {{has led to the}} PGAS programming model and its concretization in a number of implementations. PGAS exposes a shared memory that is split into disjoint partitions, each comprising distinct computin...|$|R
30|$|To test our hypothesis, we vary our {{method of}} <b>pooling</b> <b>tasks</b> into domains (Sect.  4) {{and compare the}} values for task change over time (Sect.  5).|$|R
40|$|Multicore {{embedded}} systems introduce new opportunities and challenges. Scaling of computational power {{is one of}} the main reasons for a transition to a multicore environment. Parallel design patterns, such as Map Reduce, <b>Task</b> Graph, Thread <b>Pool,</b> <b>Task</b> Parallelism assist to derive a parallel approach for calculating the Fast Fourier Transform. By combining these design patterns, a robust application can be obtained. The key issues for concurrent calculation of a Fast Fourier Transform are determined at a higher level avoiding low-level patch-ups. nrpages: 16 status: publishe...|$|R
40|$|Abstract—We {{present a}} fault {{tolerant}} <b>task</b> <b>pool</b> execution {{environment that is}} capable of performing fine-grain selective restart using a lightweight, distributed task completion tracking mechanism. Compared withconventionalcheckpoint/restarttechniques, this system offers a recovery penalty that is proportional to the degree of failure rather than the system size. We evaluate this system using the Self Consistent Field (SCF) kernel which forms an important component in ab initio methods for computational chemistry. Experimental results indicate that fault tolerant task pools are robust in the presence of an arbitrary number of failures and that they offer low overhead in the absence of faults. Keywords-Parallel processing, fault tolerance, task parallelism, Global Arrays, PGAS, selective recover...|$|E
40|$|We {{describe}} the solution architecture of VisRes-G, a graphical tool for visualising and steering resonance analysis in atomic collision computations. VisRes-G {{is a comprehensive}} visual tool that facilitates the graphical display, manipulation and analysis of resonance data computed over the UKL 2 G. As the user interacts with the graph a collection of computation tasks are added to a <b>task</b> <b>pool.</b> A resource-task allocation component then attempts to match the tasks with available Grid resources, controls their execution across the L 2 G and returns the results to the graphical system. A major benefit of VisRes-G is that it enables the user to focus solely on physics without having {{to be aware of}} the computational resources being used. ...|$|E
40|$|Abstract—Computer {{clusters}} with coprocessors/accelerators {{are typically}} leveraged to parallelize applications for reducing computation time. Given N parallel tasks and M processing cores, the typical {{strategy is to}} statically distribute those N tasks among M cores so that each core receives N M tasks. However, for many sophisticated applications, the processing times of N tasks may vary. In other words, some tasks will take longer time than others. The static distribution will cause the cores with light tasks {{to wait for the}} cores with the heavy tasks, resulting in an imbalance in task distribution and the nonminimal overall processing time for the application. In this work we apply dynamic task distribution. All the unfinished tasks form a <b>task</b> <b>pool.</b> Once a core finishes a task, it will request a new task from the <b>task</b> <b>pool.</b> Through this manner, all cores will be kept busy in the whole computation process. We apply two additional optimization techniques to further improve the performance of applications on clusters with Intel MIC coprocessors. First, we design hybrid implementations to distribute tasks to both the CPUs and MICs. Second, we apply multiple-level parallelism technique to realize the concurrency among the N tasks as well as the concurrency in each task. We use sparse coding as a case study to demonstrate the advantages of our approach. Sparse coding is a class of unsupervised methods for learning sets of over-complete bases to represent data efficiently. The aim of sparse coding is to find a set of basis vectors such that an input vector can be represented as a linear combination of these basis vectors. The results show that the dynamic task distribution can improve the performance by 25 % compared with the static one. Further, the hybrid mode implementation involving both the host CPUs and the MICs can outperform the basic offload mode implementation by 40 %. I...|$|E
50|$|Sweet Chariot 2 was {{released}} on January 1, 2008. This game is a complete rework of 2003's Sweet Chariot, with a new dice <b>pool</b> <b>task</b> resolution system, and all new illustrations.|$|R
40|$|Many {{compound}} properties depend {{directly on}} the dissociation constants of its acidic and basic groups. Significant effort has been invested in computational models to predict these constants. For linear regression models, compounds are often divided into chemically motivated classes, with a separate model for each class. However, sometimes too few measurements are available for a class to build a reasonable model, e. g., when investigating a new compound series. If data for related classes are available, we show that multi-task learning {{can be used to}} improve predictions by utilizing data from these other classes. We investigate performance of linear Gaussian process regression models (single <b>task,</b> <b>pooling,</b> and multitask models) in the low sample size regime, using a published data set (n = 698, mostly monoprotic, in aqueous solution) divided beforehand into 15 classes. A multi-task regression model using the intrinsic model of co-regionalization and incomplete Cholesky decomposition performed best in 85 % of all experiments. The presented approach can be applied to estimate other molecular properties where few measurements are available...|$|R
40|$|Engineering {{change orders}} (ECOs) are {{important}} drivers of development costs and lead time. This article analyzes {{the process of}} administering engineering change orders {{in the case of}} the climate control system development within a large vehicle development project. This administrative process encompasses the emergence of a change (e. g., a problem or a market-driven feature change), its management approval, and final implementation. Despite strong time pressure, this process can take several weeks, several months, and, in extreme cases, even over 1 year. Such a long lead time is especially remarkable as the actual processing time for the change typically does not exceed 2 weeks. Based on our case study, we develop an analytical framework that explains how such an extreme ratio between theoretical processing time and actual lead time is possible. The framework identifies congestion, stemming from scarce capacity coupled with processing variability, as a major lead time contributor. We outline five improvement strategies that an organization can use in order to reduce ECO lead time, namely, flexible capacity, balanced workloads, merged <b>tasks,</b> <b>pooling,</b> and reduced setups and batching...|$|R
40|$|Part 2 : Session 2 : Network and Parallel AlgorithmsInternational audienceThe {{design and}} {{analysis}} of complex systems need to determine suitable configurations for meeting requirement constraints. The Monotonic Indices Space (MIS) method is a useful approach for monotonic requirement space exploration. However, the method is highly time and memory-Consuming. Aiming {{to the problem of}} low efficiency of sequential MIS method, this paper introduces a coarse-grained parallel execution mechanism to the MIS method for accelerating the process of requirement space exploration. The <b>task</b> <b>pool</b> model is used to receive and deploy hyperboxes for work balancing. To validate our approach, the speedup is estimated by a mathematical analysis and then an experiment is conducted in a PC cluster environment. The results show that high speedup and efficiency is achieved through our approach...|$|E
40|$|We {{outline the}} design of a {{scientific}} visualization system based on a data card display invariant to provide information on the creation and processing of tasks in distributed <b>task</b> <b>pool</b> algorithms. Information aggregates over the tasks and processes are incorporated via non-classical histogram representations showing the distribution of the data within individual bins and by user-controllable tree displays. Keywords: Visualization; Interactive Visual Analysis; Distributed Task Pool; Algorithm Convergence 1 Introduction We present a new paradigm for scientific visualization which can be incorporated in parallel/ distributed code to track computational characteristics with respect to algorithm convergence and load distribution. It is our aim to provide parallel program visualization not only to the expert but also to the user who is not necessarily a parallel program expert. To this end we are re-defining the preliminary visualization tool embedded in ParInt [7], which allows for [...] ...|$|E
40|$|We {{investigate}} the parallel work redundancy {{of a class}} of adaptive algorithms, incurred from {{an increase in the}} total work required as the number of processes increases. The phenomenon is observed in adaptive integration algorithms, which are prototypical for methods that select and partition tasks from a distributed <b>task</b> <b>pool.</b> We show that, for some problems, the occurrence of this work anomaly inhibits the construction of an efficient parallel solution. For other problems {{it is important to recognize}} its influence in order to tailor the solution techniques. 1 INTRODUCTION Adaptive task partitioning is an important paradigm in numerical integration. In addition, it is used in other problem domains, such as ray tracing, function approximation, optimization, and finite element analysis (see (Kapenga and de Doncker, 1988) for a discussion). Our research indicates an adverse anomaly in the amount and pattern of work performed when implementing a distributed version of the adaptive part [...] ...|$|E
50|$|Blood Games II was {{released}} on June 26, 2007. This game is a complete rework of the earlier Blood Games, with a new dice <b>pool</b> <b>task</b> resolution system, refined magic systems, new Paths, and all new illustrations by the game's authors.|$|R
50|$|MAKNA (Majlis Kanser Nasional) or National Cancer Council Malaysia is a not-for-profit social {{enterprise}} mainly <b>tasked</b> to <b>pool</b> and utilize every effort, expertise and welfare from every faction of society to fight cancer {{and to reduce}} the pain, suffering and morbidity that the cancer patients often experience. It aims to provide curative care, preventive care, cancer research and support services to cancer patients and their families, high-risk groups {{and the general public}} in Malaysia and throughout the world.|$|R
40|$|Complexity theorists {{argue that}} an optimal {{organizational}} form {{results from the}} interactions of individual agents {{in the absence of}} an imposed management hierarchy (Anderson, 1999; Begun, 1994; Berreby, 1998; Coveney 2 ̆ 6 Highfield, 1995; Guastello, 2002). There have been few empirical studies to support this claim. This research investigated the effects of self-organization and task interdependence types on group effectiveness and member satisfaction. Results show that groups allowed to self-organize had greater member satisfaction in sequential and reciprocal task structures, shorter task completion times in sequential task structures, and lower satisfaction in <b>pooled</b> <b>task</b> structures versus comparable groups with hierarchy imposed. Hierarchy appears to inhibit the ability of members to self-organize and perform tasks in accordance with the task requirements. In the case of <b>pooled</b> <b>task</b> structures hierarchy seems to increase member satisfaction by clarifying task assignments. ...|$|R
40|$|This study designed, {{implemented}} and evaluated a learning {{content management system}} to facilitate creating both standard based and free style learning objects. The system, BULeCoMas, also enabled users to tag learning objects with usage data and tools supported with components accommodated under a Global Activity Center, are Global <b>Task</b> <b>Pool,</b> Experience Repository and Learner Record Repository. This study examined whether the experience in information technology use affect e-learning object authors’; � use of assets, � organization of assets and � embedding of instructional elements into their content authoring. The system, enabling common standards of reusable learning objects, was tested for ease of use with thirty-four novice and experienced preservice teachers. The participants found the system easy to use in general, novice and experienced information technology users were able to develop learning objects similar in size and features. The study suggests some further work for using the same system in collaborative learning object authoring...|$|E
40|$|We {{present a}} highly-scalable {{non-blocking}} producer-consumer <b>task</b> <b>pool,</b> designed {{with a special}} emphasis on lightweight synchronization and data locality. The core building block of our pool is SALSA, Scalable And Low Synchronization Algorithm for a single-consumer container with task stealing support. Each consumer operates on its own SALSA container, stealing tasks from other containers if necessary. We implement an elegant self-tuning policy for task insertion, which does not push tasks to overloaded SALSA containers, thus decreasing the likelihood of stealing. SALSA manages large chunks of tasks, which improves locality and facilitates stealing. SALSA uses a novel approach for coordination among consumers, without strong atomic operations or memory barriers in the fast path. It invokes only two CAS operations during a chunk steal. Our evaluation demonstrates that a pool built using SALSA containers scales linearly with the number Emerging computer architectures pose many new challenges for software development. First, {{as the number of}} computing elements constantly increases, the importance of scalability of parallel programs becomes paramount. Second, accessing memory has become the principal bottleneck, while multi-CPU systems ar...|$|E
30|$|The {{extensive}} {{amount of}} various empirical evidence {{as a result}} of triangulated data from different sources, different inquiry methods, and different analysis methods provides a comprehensive basis for adapting the coherence of the skills’ set, <b>task</b> <b>pool,</b> and Q matrix. As expected each single Q matrix is unique. The empirical result that a matched Q matrix model is the best proxy for describing apprentices’ underlying cognitive processes while solving each IP task confirmed the expectation that no source and no method is without limitations and that every different source and method delivers a unique contribution within the process of specifying a sounded Q matrix. Results of the Q matrix pattern matching shows that researchers, as well as experts in the field, overall rated more skills as necessary, as this could be found within the coding process of think-aloud study transcripts. With regard to empirical evaluation of these four single Q matrix models (Q-I, Q-ERC, Q-ATAC, Q-ATAS), models based on apprentices’ think-aloud studies usually show better model fit values than researchers’/experts’ Q matrix models. This underlies the special emphasis of the think-aloud method of target group respondents to understand underlying cognitive processes while solving tasks.|$|E
40|$|We {{propose a}} {{technique}} for assessing robustness of behavioral measures and treatment effects to experimenter demand effects. The {{premise is that}} by deliberately inducing demand in a structured way we can measure its influence and construct plausible bounds on demand-free behavior. We provide formal restrictions on choice that validate our method, and a Bayesian model that microfounds them. Seven pre-registered experiments with eleven canonical laboratory games and around 19, 000 participants demonstrate the technique. We also illustrate how demand sensitivity varies by <b>task,</b> participant <b>pool,</b> gender, real versus hypothetical incentives, and participant attentiveness, and provide both reduced-form and structural analyses of demand effects...|$|R
40|$|There are no widely {{accepted}} design patterns for writing distributed, concurrent, fault-tolerant code. Each programmer develops her own techniques for writing {{this type of}} complex software. The use of a common pattern for fault-tolerant programming {{has the potential to}} produce correct code more quickly and increase shared understanding between developers. We describe rules, <b>tasks,</b> and <b>pools,</b> patterns extracted from the development of RAMCloud, a fault-tolerant datacenter storage system. We illustrate their application and discuss their relationship to concurrent programming models. Our goal is to generate discussion that will ultimately lead to common techniques for fault-tolerant programming. ...|$|R
40|$|The {{papers and}} {{comments}} {{in this issue}} focus on four broad areas related to understanding and modeling choices: (1) The use of laboratory experiments to improve valuation methods; (2) The design of stated preference choice set and choice occasions; (3) Latent class models as means of identifying and accommodating preference heterogeneity; and (4) Accommodating uncertainty about the “true” model, modeling ranking and rating <b>tasks</b> and <b>pooling</b> data sources. In what follows I offer some comments on each area, and briefly discuss several unresolved issues associated with each area, closing with some comments about future research opportunities. Copyright Springer 2006 discrete choice experiments, choice models, unobserved variability,...|$|R
