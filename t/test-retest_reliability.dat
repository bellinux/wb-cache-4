6488|363|Public
5|$|One {{measure of}} an instrument's {{usefulness}} {{is to see}} how closely it agrees with another similar instrument that has been validated against information from a clinical interview by a trained clinician. In this respect, the BDI-II is positively correlated with the Hamilton Depression Rating Scale with a Pearson r of 0.71, showing good agreement. The test was also shown {{to have a high}} one-week <b>test–retest</b> <b>reliability</b> (Pearson r =0.93), suggesting that it was not overly sensitive to daily variations in mood. The test also has high internal consistency (α=.91).|$|E
25|$|The {{simplest}} {{approach is}} <b>test-retest</b> <b>reliability</b> {{over long periods}} of time, using stimuli of color names, color chips, or a computer-screen color picker providing 16.7million choices. Synesthetes consistently score around 90% on reliability of associations, even with years between tests. In contrast, non-synesthetes score just 30–40%, even with only a few weeks between tests and a warning that they would be retested.|$|E
25|$|The TMAS {{has been}} proven {{reliable}} using <b>test-retest</b> <b>reliability.</b> O’Connor, Lorr, and Stafford found there were five general factors in the scale: chronic anxiety or worry, increased physiological reactivity, sleep disturbances associated with inner strain, sense of personal inadequacy, and motor tension. This study showed that persons administered the test could be display different anxiety levels across these areas. O’Connor, Lorr, and Stafford’s realization allows patients and their doctors to better understand which dimension of anxiety needs to be addressed.|$|E
30|$|Overall, {{the psychometric}} {{properties}} of the items, subscales, and total scores support the use and continuing refinement of the GRCD in clinical trials. Item-level <b>test-retest</b> <b>reliabilities</b> were acceptable for an ObsRO instrument, as were the subscale-level <b>test-retest</b> <b>reliabilities</b> (except for the Behavior Impact subscale). The internal consistency reliabilities of the GRCD were appropriate for its intended use, and inter-item correlations were generally as expected, providing evidence for construct validity. Correlational analyses supported the construct validity of the GRCD items, subscales, and total score and hypothesis tests in support of discriminating ability were in the anticipated direction and some were statistically significant, helping to verify the validity and usefulness of the GRCD. Responsiveness statistics were large, suggesting that the GRCD is capable of detecting change, a property that will be essential in future therapeutic trials.|$|R
40|$|In this study, the short- and {{long-term}} <b>test-retest</b> <b>reliabilities</b> of tone-burst-evoked otoacoustic emissions (TBOAEs) with 12 different tone-burst stimuli (4 frequencies [1, 1. 5, 2 and 3 kHz] at 3 stimulus levels [≈ 76, ≈ 67 and ≈ 55 dB peSPL]) {{were examined in}} 30 normal hearing subjects. Click-evoked and spontaneous OAEs were recorded in parallel with TBOAEs to facilitate cross-comparisons and the generalization of results. Findings for click-evoked and spontaneous OAEs were comparable with most literature data. High reliability for TBOAEs was established for high and mid stimulus levels at all frequencies tested with reference to test-retest prevalence rate, test-retest occurrence, intra-subject test-retest difference and correlation coefficient. Derived half-octave band analysis at the frequency corresponding to the stimulus was found to reflect real TBOAE performance more reliably than broadband analysis. No significant difference between short- {{and long-term}} reliabilities was noted from all results. Similar <b>test-retest</b> <b>reliabilities</b> for high-level TBOAEs and click-evoked OAEs was obtained, suggesting that TBOAEs could potentially contribute to clinical assessment. link_to_subscribed_fulltex...|$|R
40|$|The authors {{assessed}} the <b>test-retest</b> <b>reliabilities</b> of two treatment-preference instruments recently {{applied to the}} measurement of the utilities of health states after different treatment modalities for cancer. The first instrument measures the strengths of preferences concerning a choice between a wait-and-see policy, and treatment with radiotherapy after an initial surgical breast-conserving procedure for early breast cancer. The second measures the strengths of preferences concerning a choice between two hypothetical surgical treatment outcomes in cancer of the rectum with different probabilities of expected five-year survival. Both measure {{the strength of a}} subject’s treatment preference given probabilities of treat-ment-related costs and benefits. The subjects were radiotherapy technicians (n = 20) and cancer patients (n = 20) who were interviewed in weeks 2 and 4 of radiotherapy. The <b>test-retest</b> <b>reliabilities</b> of both instruments were inconsistent and moderately high, with Spear-man’s rank correlations ranging from 0. 38 to 0. 81 and weighted kappas ranging from 0. 38 to 0. 69. To investigate whether the start of treatment with radiotherapy influenced the utilities that patients assigned to health states, the same procedure was applied in another, com-parable, group of patients with cancer (n = 20). For this group, the first assessment wa...|$|R
25|$|According to the Benton Test manual, <b>test-retest</b> <b>reliability</b> of the Benton Test is 0.85, and {{alternate}} form reliabilities {{range from}} 0.79 to 0.84. Correlation between immediate and delayed memory recall (Administration type A and D, respectively) ranges from 0.40 to 0.83, {{depending on the}} combinations of forms used. Included with the manual are standardized results for children, adolescents, and adults, though each administration method have their own standardization data. Total errors on the test {{have been shown to}} increase with age, especially after the age of 70.|$|E
25|$|Group member average {{scores of}} theory of mind abilities, {{measured}} with the Reading the Mind in the Eyes test (RME), are suggested as drivers of successful group performance. In particular, high group average {{scores on the}} RME are shown to be correlated with the collective intelligence factor c defined as a group's ability to perform {{a wide range of}} mental tasks, a group intelligence measure similar to the g factor for general individual intelligence. RME is a ToM test for adults that shows sufficient <b>test-retest</b> <b>reliability</b> and constantly differentiates control groups from individuals with functional autism or Asperger syndrome. It {{is one of the most}} widely accepted and well-validated tests for ToM abilities within adults.|$|E
25|$|The Taylor Manifest Anxiety Scale, often {{shortened}} to TMAS, {{is a test}} {{of anxiety}} as a personality trait, and was created by Janet Taylor in 1953 to identify subjects who would be useful {{in the study of}} anxiety disorders. The TMAS originally consisted of 50 true or false questions a person answers by reflecting on themselves, in order to determine their anxiety level. Janet Taylor spent her career in the field of psychology studying anxiety and gender development. Her scale has often been used to separate normal participants from those who would be considered to have pathological anxiety levels. The TMAS has been shown to have high <b>test-retest</b> <b>reliability.</b> The test is for adults but in 1956 a children's form was developed. The test was very popular for many years after its development but is now used infrequently.|$|E
40|$|The study {{investigated}} the stability of executive functioning (EF) measures {{in children and adolescents}} aged 8 - 17 years with unilateral cerebral palsy (CP). Here 44 participants with unilateral CP (mean age = 11 years, 11 months; Manual Abilities Classification Scale Level I = 6 and Level II = 37; Gross Motor Function Classification Scale Level I = 22 and Level II = 22) were randomized into the wait-list control group of a large randomized controlled trial. Participants had baseline testing with Wechsler Intelligence Scale for Children - Fourth Edition Short Form (WISC-IV-SF) and Delis-Kaplan Executive Function System (D-KEFS) subtests. Parents completed the Behavior Rating Inventory of Executive Functioning (BRIEF). Participants were re-assessed 20 +/- 2 weeks later with a shortened test battery including the D-KEFS subtests; Digit Span, Coding and Symbol Search (WISC-IV); and BRIEF. Pearson 2 ̆ 7 s <b>test-retest</b> <b>reliabilities</b> and Reliable change scores were calculated. Results indicated excellent to fair <b>test-retest</b> <b>reliabilities</b> (r = 0. 91 - 0. 74) for all measures except Digit Span Backwards (r = 0. 62), Inhibition (r = 0. 69), and Initiate (r = 0. 68). Reliable change scores applying 90...|$|R
40|$|Abstract Background A {{growing body}} of {{literature}} describes the performance of dental fear questionnaires in various countries. We describe {{the psychometric properties of}} Greek versions of the Modified Dental Anxiety Scale (MDAS) and the Dental Fear Survey (DFS) in adult Greek patients. Methods Greek versions of the MDAS and DFS were administered to two samples of adult dental patients. In the first sample, 195 patients attending one of three private practice dental offices in a large city in Greece completed the questionnaires in the waiting room before dental treatment. After treatment, their dentists (who did not know how the patients had answered the questionnaire) rated their anxiety during dental treatment. In the second sample, 41 patients attending a Greek university dental school clinic completed the questionnaire twice at two separate visits, in order to provide test-retest data. Cronbach's alpha was used to compute the internal consistencies, while Spearman's rho was used to compute the <b>test-retest</b> <b>reliabilities.</b> Construct validity was assessed by correlating the responses to the MDAS and DFS by Spearman's rho. Spearman's rho was also used to examine the criterion validities, by comparing the questionnaire responses with the dentists' ratings of anxiety. Results The internal consistencies for the MDAS were 0. 90 and 0. 92 in the two samples; for the DFS, the internal consistencies were 0. 96 in both samples. The <b>test-retest</b> <b>reliabilities</b> were 0. 94 for the MDAS and 0. 95 for the DFS. The correlation between the two questionnaires was 0. 89. The patients' responses to both questionnaires were significantly related to the dentists' ratings of their anxiety during dental treatment (both p values Conclusion The results indicate that the Greek versions of the MDAS and DFS have good internal consistencies and <b>test-retest</b> <b>reliabilities,</b> as well as good construct and criterion validities. The psychometric properties of the Greek versions of these questionnaires appear to be similar to those previously reported in other countries. </p...|$|R
40|$|This {{research}} {{assessed the}} stability of specific body image concerns among Chinese adolescents. A sample of 216 boys and 375 girls completed the Negative Physical Self Scale, a 38 -item measure of body image concerns developed specifically for use in Chinese samples. Participants returned nine months later to complete the same scale. Bivariate correlation analyses within each sex obtained good <b>test-retest</b> <b>reliabilities</b> (r=. 48 to r=. 78). Findings indicate that body image concerns of Chinese adolescents, especially those of girls, are relatively stable over a nine-month interval...|$|R
2500|$|The <b>test-retest</b> <b>reliability</b> of the MBTI {{tends to}} be low. Large numbers of people (between 39% and 76% of respondents) obtain {{different}} type classifications when retaking the indicator after only five weeks. In Fortune Magazine (May 15, 2013), an article titled [...] "Have we all been duped by the Myers-Briggs Test" [...] stated: ...|$|E
2500|$|Both {{reliability}} and validity can be assessed statistically. Consistency over repeated measures of the same test can be assessed with the Pearson correlation coefficient, and is often called <b>test-retest</b> <b>reliability.</b> [...] Similarly, [...] the equivalence of {{different versions of the}} same measure can be indexed by a Pearson correlation, and is called equivalent forms reliability or a similar term.|$|E
2500|$|Group members' social {{sensitivity}} {{was measured}} via the Reading the Mind in the Eyes Test (RME) and correlated [...]26 with c. Hereby, participants {{are asked to}} detect thinking or feeling expressed in other peoples' eyes presented on pictures and assessed in a multiple choice format. The test aims to measure peoples' theory of mind (ToM), also called 'mentalizing' or 'mind reading', which refers {{to the ability to}} attribute mental states, such as beliefs, desires or intents, to other people and in how far people understand that others have beliefs, desires, intentions or perspectives different from their own ones. RME is a ToM test for adults that shows sufficient <b>test-retest</b> <b>reliability</b> and constantly differentiates control groups from individuals with functional autism or Asperger Syndrome. It {{is one of the most}} widely accepted and well-validated tests for ToM within adults. ToM can be regarded as an associated subset of skills and abilities within the broader concept of emotional intelligence.|$|E
40|$|The BarOn Emotional Quotient Inventory (EQ-i; BarOn, 2004) {{was created}} to assess {{emotional}} intelligence (EI). In our research project we produced the Indonesian version. The EQ-i was translated from English into Bahasa Indonesia and back-translated into English. <b>Test-retest</b> <b>reliabilities</b> and internal consistencies amongst 2801 Indonesians were calculated and found quite satisfactory. The exploratory factor analyses (N= 500) and the confirmatory factor analysis (N= 750) were identified and largely consistent with the original version’s composite scales and sub scales. Our findings {{support the use of}} the Indonesian version of the EQ-i...|$|R
40|$|Recent {{research}} has highlighted several job characteristics salient to employee well-being and behavior {{for which there}} are no adequate generally applicable measures. These include timing and method control, monitoring and problem-solving demand, and production responsibility. In this article, an attempt to develop measures of these constructs provided encouraging results. Confirmatory factor analyses applied to data from 2 samples of shop-floor employees showed a consistent fit to a common 5 -factor measurement model. Scales corresponding to each of the dimensions showed satisfactory internal and <b>test–retest</b> <b>reliabilities.</b> As expected, the scales also discriminated between employees in different jobs and employees working with contrasting technologies...|$|R
40|$|Golombok and Rust 1993 a, 1993 b) to 158 Dutch {{girls and}} boys and {{concluded}} that higher prenatal exposure to polychlorinated biphenyls (PCBs) in boys was related to less masculinized play, and in girls was related to more masculinized play. They further concluded that prenatal exposure to PCBs and related compounds caused prenatal steroid hormone imbalances, leading directly to sexinappropriate play behaviors. However, this study has many flaws that preclude reaching these conclusions. The PSAI has weak psychometric properties. The <b>test–retest</b> <b>reliabilities</b> in the 0. 60 s are based on tiny samples of 15 – 18...|$|R
50|$|One-trial {{administration}} of the Purdue Pegboard Test produced <b>test-retest</b> <b>reliability</b> of 0.60 to 0.79. The three-trial administration <b>test-retest</b> <b>reliability</b> ranged from 0.82 to 0.91.|$|E
5000|$|Implicit measures, {{especially}} latency-based ones, typically {{struggle to}} achieve a satisfactory level of internal consistency and <b>test-retest</b> <b>reliability.</b> However, the IAT possess acceptable levels of both, with one review finding that internal consistency values of IAT's typically ranged from [...]7 to [...]9. In terms of <b>test-retest</b> <b>reliability,</b> the IAT has shown itself to be a relatively stable measure, however, little research has examined the <b>test-retest</b> <b>reliability</b> of the IAT with a gap in time larger than a month between administrations.|$|E
5000|$|One study {{provided}} some {{evidence for the}} <b>test-retest</b> <b>reliability</b> and predictive validity.|$|E
40|$|The present microcomputer-based {{performance}} test battery emphasizes psychometric theory and utility for repeated-measures applications during extended exposure to various environmental stressors. In the menu {{that has been}} defined at {{the current state of}} this system's development, there are more than 30 'qualified' mental tests which stabilize in less than 10 min and possess <b>test-retest</b> <b>reliabilities</b> greater than 0. 7 for a three-minute test/work period. The battery encompasses tests of cognition, information processing, psychomotor skill, memory, mood, etc. Several of the tests have demonstrated sensitivity to chemoradiotherapy, sleep loss, hypoxia, amphetamines, thermal stress, sensory deprivation, altitude, fatigue, and alcohol use. Recommendations are presented for 6 -, 12 -, and 22 -min batteries...|$|R
40|$|The {{purpose of}} this study was to {{evaluate}} the concurrent validity of two instruments: the Self-Other Profile Chart (SOPC) derived from one model of Relational Competence Theory (RCT) and the How You View Your Self (HYVYS) derived from the Elementary Pragmatic Model (EPM). These two instruments were administered together with the Brief Psychiatric Rating Inventory (BPRI) to two samples of women and men with and without psychiatric diagnoses. Scores in both instruments demonstrated statistically significant <b>test-retest</b> <b>reliabilities</b> and correlated highly with scores on the BPRI. These results tend to support the concurrent validity of both instruments and add more evidence to the theoretical significance of the models they represent...|$|R
5000|$|Implicit {{self-esteem}} In {{the article}} [...] "Stalking the perfect measure of implicit self-esteem: The blind {{men and the}} elephant revisited?", the validity and reliability of seven implicit self-esteem measures have been explored. The implicit measures {{were not correlated with}} one another. However they did correlate, but only faintly with measures of explicit self-esteem. The implicit self-esteem measurements confirmed partial reliabilities in correlation to good <b>test-retest</b> <b>reliabilities.</b> Nonetheless implicit measures were limited in their ability to calculate standard variables, for the test. Certain evidence explained that measurements of implicit self-esteem are delicate to put in context, which is further argued in later research of implicit self-esteem.|$|R
5000|$|The <b>test-retest</b> <b>reliability</b> of the NEO PI-R {{has also}} {{been found to be}} satisfactory. The <b>test-retest</b> <b>reliability</b> of an early version of the NEO after 3 months was: N = [...]87, E = [...]91, O = [...]86. The <b>test-retest</b> <b>reliability</b> for over 6 years, as {{reported}} in the NEO PI-R manual, was the following: N = [...]83, E = [...]82, O = [...]83, A = [...]63, C = [...]79. Costa and McCrae pointed out that these findings not only demonstrate good reliability of the domain scores, but also their stability (among individuals over the age of 30). Scores measured six years apart varied only marginally more than scores measured a few months apart.|$|E
50|$|Repeatability or <b>test-retest</b> <b>reliability</b> is the {{variation}} in measurements taken by a single person or instrument on the same item, under the same conditions, and {{in a short period}} of time. A less-than-perfect <b>test-retest</b> <b>reliability</b> causes test-retest variability. Such variability can be caused by, for example, intra-individual variability and intra-observer variability. A measurement may be said to be repeatable when this variation is smaller than a pre-determined acceptance criterion.|$|E
50|$|According to Sarason, the SSQ takes between {{fifteen to}} {{eighteen}} minutes to properly administer and has “good” <b>test-retest</b> <b>reliability.</b>|$|E
40|$|Objectives: To {{investigate}} (1) the intra-rater, inter-rater and <b>test-retest</b> <b>reliabilities</b> of the Figure-of-Eight Walk (F 8 W) test times; (2) its {{correlation with}} other stroke-specific impairments; and (3) the cut-off scores best discriminating patients with stroke from the healthy elderly. Design: Cross-sectional study. Setting: University-based rehabilitation centre. Participants: A {{convenience sample of}} 64 subjects: 35 subjects with chronic stroke and 29 healthy elderly. Main Outcome Measures: F 8 W test times, Fugl-Meyer Motor Assessment for the lower extremities (FMA-LE), hand-held dynamometer measurements of bilateral hip abductor and knee extensor isometric muscle strength, Five times Sit to Stand Test (FTSTST) times, 10 -Meter Walk Test (10 MWT), Timed Up and Go Test (TUGT) times, Berg Balance Scale (BBS) and Activities-specific Balance Confidence Scale (ABC) scores. Results: Excellent intra-rater, inter-rater and <b>test-retest</b> <b>reliabilities</b> (intra-class correlation coefficient (ICC) range 0. 944 - 0. 999) of F 8 W test times were found. The F 8 W test times were also {{found to be significantly}} associated with FMA-LE, BBS, FTSTST, TUG scores and 10 MWT. No significant correlation was found between F 8 W test times and either leg strength or ABC results. A F 8 W test time of 8. 2 s was found to be the most representative for discriminating between healthy elderly and stroke subjects, with a sensitivity of 100 % and a specificity of 89. 7 %. Conclusions: The F 8 W test time is a reliable measurement tool, which is able to differentiate the patients with stroke and healthy elderly subjects and correlated well with stroke-specific impairments and walking tests. The F 8 W is a reliable measurement tool for assessing the advanced walking performance of subjects with chronic stroke. Implication for RehabilitationThe F 8 W test times have excellent intra-rater, inter-rater and <b>test-retest</b> <b>reliabilities</b> in patients with chronic stroke. The F 8 W test times were also found to be significantly associated with FMA-LE, BBS, FTSTST, TUG scores and 10 MWT. A F 8 W test time of 8. 2 s was found to be the most representative for discriminating between healthy elderly and stroke subjects, with a sensitivity of 100 % and a specificity of 89. 7 %. The F 8 W test time is a reliable and valid measure in assessing the advanced walking skill in patients with stroke. Department of Rehabilitation Science...|$|R
40|$|Post mortem {{studies have}} shown volume changes of the {{hypothalamus}} in psychiatric patients. With 7 T magnetic resonance imaging this effect can now be investigated in vivo in detail. To benefit from the sub-millimeter resolution requires an improved segmentation procedure. The traditional anatomical landmarks of the hypothalamus were refined using 7 T T 1 -weighted magnetic resonance images. A detailed segmentation algorithm (unilateral hypothalamus) was developed for colour-coded, histogram-matched images, and evaluated {{in a sample of}} 10 subjects. <b>Test-retest</b> and inter-rater <b>reliabilities</b> were estimated in terms of intraclass-correlation coefficients (ICC) and Dice’s coefficient (DC). The computer-assisted segmentation algorithm ensured <b>test-retest</b> <b>reliabilities</b> of ICC ≥. 97 (DC ≥ 96. 8) and inter-rater reliabilities of ICC ≥. 94 (DC = 95. 2). There were no significant volume differences between the segmentation runs, raters, and hemispheres. The estimated volumes of the hypothalamus lie within the range of previous histological and neuroimaging results. We present a computer-assisted algorithm for the manual segmentation of the human hypothalamus using T 1 -weighted 7 T magnetic resonance imaging. Providing very high <b>test-retest</b> and inter-rater <b>reliabilities,</b> it outperforms former procedures established at 1. 5 T and 3 T magnetic resonance images and thus can serve as a gold standard for future automated procedures...|$|R
40|$|Rationale and {{objectives}} The scoring algorithm of the 12 -item Short-Form Health Survey (SF- 12) was revised {{in the second}} version (SF- 12 v 2), but information on its psychometric properties is lacking. This study determined whether the SF- 12 v 2 was a valid and equivalent substitute for the SF- 36 v 2 Health Survey (version 2) for the Chinese. Methods A total of 2410 Chinese adults in Hong Kong completed the SF- 36 Health Survey by telephone. The SF- 12 v 2 data were extracted from the SF- 36 data. Internal consistency was assessed by Cronbach's alpha, and <b>test-retest</b> <b>reliabilities</b> were evaluated by intraclass correlation. Criterion validity and equivalence were assessed using the SF- 36 v 2 scores as a gold standard. Construct validity and sensitivity were assessed by known-group comparison. Results Internal consistency and <b>test-retest</b> <b>reliabilities</b> were good (range 0. 67 - 0. 82) for all except three scales. The SF- 12 v 2 summary scores explained > 80 % of the total variances of the SF- 36 v 2 summary scores. Construct validity and sensitivity were confirmed by significantly lower SF- 12 v 2 scores in people with chronic diseases than those without. Effect size differences were less than 0. 3 and relative validities were greater than 0. 7 between SF- 12 v 2 and SF- 36 v 2 scores for different groups. Conclusion The SF- 12 v 2 was valid, reliable and sensitive for the Chinese. It is an equivalent substitute for the SF- 36 v 2 for the summary scales. link_to_OA_fulltex...|$|R
50|$|Reliability {{data for}} the CVLT-II is mostly good, ranging from 0.80-0.96 in a mixed neuro-psychiatric sample. <b>Test-retest</b> <b>reliability</b> was also adequate.|$|E
5000|$|... 1. <b>Test-retest</b> <b>reliability</b> method: {{directly}} {{assesses the}} degree to which test scores are consistent from one test administration to the next.|$|E
50|$|The DSM-5 {{field trials}} {{included}} <b>test-retest</b> <b>reliability</b> which involved different clinicians doing independent {{evaluations of the}} same patient—a common approach {{to the study of}} diagnostic reliability.|$|E
40|$|Distinct neural populations carry {{signals from}} short-wave (S) cones. We used {{individual}} differences {{to test whether}} two types of pathways, those that receive excitatory input (S+) and those that receive inhibitory input (S-), contribute independently to psychophysical performance. We also conducted a genome-wide association study (GWAS) to look for genetic correlates of the individual differences. Our psychophysical test {{was based on the}} Cambridge Color Test, but detection thresholds were measured separately for S-cone spatial increments and decrements. Our participants were 1060 healthy adults aged 16 - 40. <b>Test-retest</b> <b>reliabilities</b> for thresholds were good (ρ= 0. 64 for S-cone increments, 0. 67 for decrements and 0. 73 for the average of the two). "Regression scores," isolating variability unique to incremental or decremental sensitivity, were also reliable (ρ= 0. 53 for increments and ρ= 0. 51 for decrements). The correlation between incremental and decremental thresholds was ρ= 0. 65. No genetic markers reached genome-wide significance (p< 5 × 10 (- 7)). We identified 18 "suggestive" loci (p< 10 (- 5)). The significant <b>test-retest</b> <b>reliabilities</b> show stable individual differences in S-cone sensitivity in a normal adult population. Though a portion of the variance in sensitivity is shared between incremental and decremental sensitivity, over 26 % of the variance is stable across individuals, but unique to increments or decrements, suggesting distinct neural substrates. Some of the variability in sensitivity is likely to be genetic. We note that four of the suggestive associations found in the GWAS are with genes that are involved in glucose metabolism or have been associated with diabetes...|$|R
40|$|Objective: To {{establish}} {{the psychometric properties}} and norm of the Chinese (HK) SF- 36 version 2 Health Survey for the adult population in Hong Kong (HK) to facilitate its application and interpretation. Design: A cross-sectional random telephone survey of the general adult population. Subjects: 2410 Chinese adults randomly selected from the general Chinese adult population in Hong Kong. The {{mean age of the}} subjects was 42. 9 (S. D. 17. 3) years, 48 % were men and 38 % had one or more chronic disease. Main outcome measures: Responses to the SF- 36 v 2 Health Survey questions were extracted. Item-scale correlations, internal and <b>test-retest</b> <b>reliabilities,</b> and the factor structure of the SF- 36 v 2 Health Survey scores were analysed. The SF- 36 v 2 Health Survey scores were calculated by the standard algorithm to {{establish the}} population norm. Results: All items had 100 % scaling success indicating discriminant validity. Internal consistency and <b>test-retest</b> <b>reliabilities</b> of all scales were good (coefficients 0. 66 to 0. 89). The hypothesized two-factor structure underlying construction of the physical and mental health summary scales was confirmed. The psychometric properties of the SF- 36 v 2 Health Survey were generally better than version 1. There were significant differences in the population norms between versions 1 and 2 of the Chinese (HK) SF- 36 Health Survey, especially in the role-physical and role-emotional scales. Conclusion: The Chinese (HK) SF- 36 v 2 Health Survey is valid and reliable for measuring HRQOL of Chinese adults in Hong Kong, and population norm is now available to support the interpretation of its scores. published_or_final_versio...|$|R
40|$|Copyright © 2004 Elsevier Ltd All rights reserved. Physical {{attributes}} of local environments may influence walking. We used {{a modified version}} of the Neighbourhood Environment Walkability Scale to compare residents’ perceptions of the {{attributes of}} two neighbourhoods that differed on measures derived from Geographic Information System databases. Residents of the high-walkable neighbourhood rated relevant attributes of residential density, land-use mix (access and diversity) and street connectivity, consistently higher than did residents of the low-walkable neighbourhood. Traffic safety and safety from crime attributes did not differ. Perceived neighbourhood environment characteristics had moderate to high <b>test–retest</b> <b>reliabilities.</b> Neighbourhood environment attribute ratings may be used in population surveys and other studies. Eva Leslie, Brian Saelens, Lawrence Frank, Neville Owen, Adrian Bauman, Neil Coffee and Graeme Hugo[URL]...|$|R
