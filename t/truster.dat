88|43|Public
50|$|In June 1941, HMS Prinses Astrid {{sailed to}} Inveraray {{to join the}} fleet which {{remained}} stand-by for the Landing in the Azores (Operation <b>Truster).</b> As preparation for the operation in August 1941, the Prinses Astrid was sent to Scapa Flow for training. But due to electrical problems, the ship wasn't {{able to participate in}} Operation <b>Truster.</b> On 20 September 1941, HMS Prinses Astrid arrives in Inveraray to serve as an accommodation ship for Combined Operations Training Classes.|$|E
50|$|In social {{sciences}} and in information technology, trustor (alt. <b>truster</b> in e.g.) is an entity that trusts the other entity (the trustee). Trustor may be a social agent (such as a person or an institution) or a technical agent (such as a computer or a software application), {{acting on behalf of}} a social agent.|$|E
50|$|Fir is {{equipped}} with a dynamic positioning system that utilizes a bow thruster, stern <b>truster</b> and the ship's controllable pitch propellor to hold the ship's position and heading at the push of a button. The dynamic positioning system relies on inputs from the Differential Global Positioning System. In dynamic positioning mode the ship can be driven with a joystick from several locations on the bridge, and from a mobile ship control console.|$|E
30|$|Trust is {{modulated}} by {{features that}} affect how <b>trusters</b> judge outcomes, {{such as the}} satisfaction or violation of a commitment. First, trust assessment is subjective. <b>Trusters</b> differ in how they reward or penalize a trustee when a commitment is discharged or violated, respectively. Second, trust assessment depends on the <b>truster’s</b> memory: <b>trusters</b> with limited memory would tend to forget all but (some varying number of) recent experiences. Recent experiences {{may turn out to}} be more predictive of future experiences (that trust is about) than past experiences. Third, the effect on trust of a commitment’s outcome would be greater when the commitment is more important.|$|R
40|$|Scale and a {{modified}} version of Bieri’s grid procedure for measur-ing cognitive complexity for positive and negative social stimuli. As hypothesized, low <b>trusters</b> had significantly more differentiated cognitions for socially distant persons than high <b>trusters.</b> Contrary to hypotheses, socially close persons yielded significantly lesser complexity for high <b>trusters</b> than low <b>trusters</b> and significantly greater complexity for females than males. It was concluded that low generalized expectancies for interpersonal trust might be more adaptive and less problematical than previously contended. Bieri (1955, 1961) developed a concept of cognitive structure re-ferred to as cognitive complexity-simplicity. Derived from Kelly’s (1955) psychology of personal constructs, cognitive complexity reflects the per-son’s structuring of the social environment by means of multi-dimensional constructs. A more cognitively complex individual has available a more differentiated network of dimensions for perceiving the behavior of other...|$|R
40|$|The present {{research}} examined {{the influence of}} trust, accountability: and self-monitoring on individual decision makers' willingness to contribute in a give-some game and in an experimental public goods dilemma. Previous {{research has shown that}} trust and contributions are positively related such that high <b>trusters</b> generally contribute move than low <b>trusters.</b> The {{present research}} questions the pervasiveness of this relation by arguing that low <b>trusters</b> may increase their contributions to the same level as those of high <b>trusters,</b> but only under circumstances where their decisions are highly identifiable to their interaction partner(s). Both studies showed that strong perceptions of trust, high accountability and high self-monitoring influenced contributions positively in line with predictions, individuals low in trust contributed up to the same level as high <b>trusters</b> when accountability was high rather than loin Moreover, this interaction between trust and accountability was only: found among those classified as high self-monitors. Our results suggest that the well-known positive relation between trust and contributions may take a different form when situational cues and individual predispositions are taken into account. Copyright (C) 2001 John Wiley & Sons, Ltd. status: publishe...|$|R
50|$|Linda Schuyler, co-creator of the Degrassi {{franchise}} and CEO of Epitome Pictures, {{served as}} an executive producer with her husband, and President of Epitome Pictures, Stephen Stohn. Brendon Yorke is also credited as an executive producer again. David Lowe was the producer, and Stephanie Cohen the supervising producer. As well as playing Snake Simpson, Stephen Brogren {{also served as a}} producer, and, for the first time, directed episodes, after previously writing, producing, and directing the exclusive online series Degrassi Minis. The casting director was Stephanie Gorin, and the editor was D. Gillian <b>Truster.</b>|$|E
50|$|Some {{philosophers}} {{argue that}} trust {{is more than}} a relationship of reliance. Philosophers such as Annette Baier have made a difference between trust and reliance by saying that trust can be betrayed, whilst reliance can only be disappointed (Baier 1986, 235). Carolyn McLeod explains Baier's argument by giving the following examples: we can rely on our clock to give the time, but we do not feel betrayed when it breaks, thus, we cannot say that we trusted it; we are not trusting when we are suspicious of the other person, because this is in fact an expression of distrust (McLeod 2006). Thus, trust is different from reliance in the sense that a <b>truster</b> accepts the risk of being betrayed.|$|E
5000|$|Numerous {{allies and}} appointees turned against FDR, such as Vice President John Nance Garner, Brain <b>truster</b> Raymond Moley, Postmaster General James A. Farley and Ambassador Joseph Kennedy. Outside the {{administration}} prominent supporters who turned against FDR included journalists Walter Lippmann and Frank Kent. Newspaper publisher William Randolph Hearst {{was a major}} Roosevelt supporter in 1932, but turned his nationwide media chain against FDR starting in 1934. Historian Charles A. Beard had supported FDR in 1932 but became the leader of isolationist intellectuals who opposed his foreign policy after 1937. Roosevelt in the 1920s had been closely associated with Al Smith, the governor of New York. Roosevelt defeated Smith for the 1932 nomination, and Smith became {{the leader of the}} Liberty League of prominent businessmen opposing the New Deal. After Pearl Harbor FDR rejected the possibility of major war jobs for any of these men except Lewis Douglas and Dean Acheson. [...] Some appointees privately turned against the New Deal but kept quiet and stayed in the jobs, such as ambassador Claude Bowers.|$|E
40|$|What is the {{relationship}} between religion and trust? Using a questionnaire, we elicit data on individual religiosity. Measures of individual religiosity are then analyzed alongside behavior in an experimental trust game. Here, <b>trusters</b> are - at times - informed of their potential trustee's religiosity. We find that more religious trustees are trusted more, and such behavior is more pronounced in more religious <b>trusters.</b> More religious trustees are found to be trustworthier. Religiosity Trust Stereotype Questionnaire Experiment...|$|R
40|$|Abstract. We {{present a}} model of trust that {{integrates}} in trust definition: the <b>truster’s</b> motivation (his goal), the action that allows the trustee to reach this goal, and the trustee’s ability and intention to do this action. This model is formalized in modal logic and it {{is applied to the}} particular domain of trust on information sources. In this context trust may be derived, in particular, from <b>truster’s</b> beliefs about some trustee’s epistemic properties: sincerity, competence, vigilance, co-operativity, validity and completeness. ...|$|R
3000|$|... 〉, {{represents}} the <b>truster’s</b> bias. An interaction may yield a positive, negative, or a neutral experience. In these cases, {{the evidence is}} updated by respectively adding 〈i [...]...|$|R
50|$|Up to 1868 wills of {{immovables}} {{were not}} allowed under Scots law. The usual means of obtaining disposition of heritage after death was a trust disposition and settlement by deed de praesenti, under which the <b>truster</b> disposed the property to trustees according to the trusts of the settlement, reserving a life interest. Thus something very similar to a testamentary disposition was secured by means resembling those employed in England before the Wills Act of Henry VIII. The main disadvantage of the trust disposition {{was that it was}} liable to be overthrown by the heir, who could reduce ex capite lecti all voluntary deeds made to his prejudice within sixty days of the death of his ancestor. In 1868 the Titles to Land Consolidation Act made it competent to any owner of lands to settle the succession to the same in the event of death by testamentary or mortis causa deeds or writings. In 1871 reduction ex capite lecti was abolished. A will of immovables must be executed with the formalities of a deed and registered to give title. The disability of a woman as a witness was removed by the Titles to Land Consolidation Act. As to wills of movables, there arc several important points in which they differ from corresponding wills in England, the influence of Roman law being more marked. Males may make a will at fourteen, females at twelve. A nuncupative legacy is good to the amount of £100 Scots (£8, 6s. 8d.), and a holograph testament is good without witnesses, but it must be signed by the testator, differing in this from the old English holograph. By the Conveyancing Act 1874 such a will is presumed to have been executed on the date which it bears. Not all movables can be left, as in England. The movable property of the deceased is subject to jus relictae and legitime. See McLaren, Wills and Succession, for the law, and Judicial Styles for styles.|$|E
3000|$|Similar trust: {{the trust}} that a <b>truster</b> {{obtained}} by reasoning {{itself on the}} similarity of a trustee with other well- known trustees. A trustee is considered as a well known by a <b>truster</b> {{if there is an}} interaction between the <b>truster</b> and the trustee and the <b>truster</b> has its own experience trust about this trustee.|$|E
3000|$|Based on {{the concept}} of the {{individual}} similar trust, we can now define the similarity trust via a set of trustee agents. Let O ⊆ A be the set of all agents who have already executed at least one transaction with agent i. The similar trust of <b>truster</b> i about trustee j via all well-known trustee k∈ O of the <b>truster</b> i is then defined as follows: [...]...|$|E
40|$|Published online: 15 May 2014 We {{exploit the}} fact that {{generosity}} and trustworthiness are highly correlated and the former can thus {{be a sign of}} the latter. Subjects decide between a generous and a mean split in a dictator game. Some of them are informed from the start that afterwards they will participate in a trust game and that their choice in the dictator game may matter; others are not informed in advance. In the trust game, before <b>trusters</b> {{decide whether or not to}} trust, some trustees can reveal (or conceal) only their true choice in the dictator game, while others can say to <b>trusters,</b> truthfully or otherwise, what they chose. We find that a generous choice made naturally by uninformed trustees and reliably revealed is more effective in persuading <b>trusters</b> to trust than a generous choice that could be strategic or a lie. Moreover, we find that, when they can, mean subjects lie and go on to be untrustworthy...|$|R
30|$|Via {{nonlinear}} least-squares {{regression technique}} that uses trust region reflective algorithm [23], we estimate the <b>truster’s</b> parameters {{to minimize the}} mean absolute error (MAE) of prediction, ∑ _k= 1 ^n|α̂ ̂_̂k̂-α _k|.|$|R
40|$|In social dilemmas, {{equality}} {{is an important}} coordination rule. When {{equality is}} violated, people seek explanations. In Experiment 1, the authors assessed dispositional trust and found that especially high <b>trusters</b> were affected by the given explanation. High <b>trusters</b> reacted less negatively to external than internal explanations. Experiment 2, using a manipulation of trust in others, revealed a similar pattern across {{a wider range of}} negative emotions. In Experiment 3, the authors only induced high trust and showed that when the external explanation {{turned out to be a}} lie, emotional and retributive reactions became more negative. Moreover, attribution information did not influence reactions when participants realized that the information was dishonest. Keywords: equality; emotions; retribution; social dilemmas; trust...|$|R
3000|$|The {{basic idea}} is for each <b>truster</b> to {{maintain}} evidence 〈r,s〉 about each trustee. The initial evidence, 〈r [...]...|$|E
30|$|Similar {{trust is}} the trust that a <b>truster</b> {{obtained}} by reasoning {{itself on the}} similarity of a trustee with other well-known trustees.|$|E
3000|$|Teacy et al. [5] {{provide a}} trust model based on {{fulfilling}} or violating obligations. In their model, {{the trust of}} a <b>truster</b> (a [...]...|$|E
40|$|We {{exploit the}} fact that {{generosity}} and trustworthiness are highly correlated and the former can thus {{be a sign of}} the latter. Subjects decide between a generous and a mean split in a dictator game. Some of them are informed from the start that afterwards they will participate in a trust game and that their choice in the dictator game may matter; others are not informed in advance. In the trust game, before <b>trusters</b> {{decide whether or not to}} trust, some trustees can reveal (or conceal) only their true choice in the dictator game, while others can say to <b>trusters,</b> truthfully or otherwise, what they chose. We find that a generous choice made naturally by uninformed trustees and reliably revealed is more effective in persuading <b>trusters</b> to trust than a generous choice that could be strategic or a lie. Moreover, we find that, when they can, mean subjects lie and go on to be untrustworthy. This research was supported by the Swiss National Science Foundation, grant number 100017 _ 124877 ([URL] and the Nuffield College financial office ([URL] The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript...|$|R
40|$|Available online 28 July 2014. When {{we become}} aware that our past actions carry {{information}} about qualities that we possess or lack, which others use {{to decide how}} to deal with us, are we unconcerned, content to rely on what we have done, or do we take action to alter this information? We study this question experimentally using generosity as a sign and a signal of trustworthiness, and a trust game. Subjects play a dictator game unaware that later they will play a trust game and that their level of generosity in the dictator game will be revealed to <b>trusters,</b> with some inaccuracy, before <b>trusters</b> decide whether to trust or not. Once made aware of what follows, trustees have the option to play a second dictator game, from which their choice will be accurately conveyed to <b>trusters</b> in addition to their decision in the initial game. Consistent with ‘countersignalling theory’, those who, in the first dictator game, were either miserly or generous do not play the second dictator game, resigned or content with the information conveyed by their past actions. Those neither miserly nor generous in the first dictator game, an intermediate generous group, are likeliest to use the second dictator game; many of them for the purpose of signalling, so that they are not confused with the miserly...|$|R
6000|$|Mr. Jollie, {{who is to}} be my trustee, in {{conjunction}} with Gibson, came to see me:--a, pleasant and good-humoured man, and has high reputation {{as a man of}} business. I told him, and I will keep my word, that he would at least have no trouble by my interfering and thwarting their management, which is the not unfrequent case of <b>trusters</b> and trustees.[140] ...|$|R
3000|$|..., and E^-_t be the positive, neutral, and {{negative}} experiences inferred from the t transactions. The trust of a <b>truster</b> in the trustee {{depends on whether}} t is less than W. When t<W, the truster’s trust is 〈E^+_ti_r + λE_ti_r, E^-_ti_s + (1 -λ)E_ti_s〉; otherwise, it is 〈 r_in+ E^+_ti_r + λE_ti_r, s_in+ E^-_ti_s + (1 -λ)E_ti_s〉. When t<W we ignore the initial bias as the truster’s trust is based on recent W experiences, which simply means that the <b>truster</b> has already forgotten its initial bias.|$|E
30|$|Now, we {{can define}} the {{individual}} similar trust of a <b>truster</b> i about a trustee j via {{the similarity between}} the trustee j and another trustee l as follows.|$|E
3000|$|Experience trust: {{the trust}} that a <b>truster</b> {{obtained}} {{based on the}} history of interaction with a trustee. An interaction is called a transaction, and trust from the interaction is called transaction trust.|$|E
40|$|Interpersonal trust {{has long}} been known to {{influence}} cooperation. This study tested the hypothesis that one's degree of trust in others will influence the extent to which one reacts to the presence of fear (or the possibility of receiving no payoff for cooperative actions) in a payoff matrix. The hypothesis was formally tested with public goods games and resource dilemma games, with fear manipulated. Results support the hypothesis: when fear was present, high <b>trusters</b> cooperated more frequently than low trusters; when absent, high and low <b>trusters</b> cooperated at the same rate. The findings held across both games. However, the effects of fear within each game were not straightforward: removing fear from the resource dilemma increased low trusters' cooperation rates, but removing fear from the public goods game decreased high trusters' cooperation rates. Results imply that discussion of the role of trust in cooperation must consider whether the particular dilemma contains an element of fear...|$|R
40|$|Two studies {{examined}} {{the impact of}} online store reviews on consumer trust in online stores. Based on the warranting principle, it was proposed that consumer reviews are a more important cue for judging the trustworthiness of an online store than the overall reputation of the store (Experiment 1) or assurance seals (Experiment 2). The role of dispositional trust was also examined. In both experiments, consumer reviews turned out as the strongest predictor of trustworthiness judgments. Store reputation had no significant effect. In Experiment 1, there was a main effect of dispositional trust on perceived trustworthiness. In Experiment 2, dispositional trust moderated the effects of reviews and assurance seals. High <b>trusters</b> were more influenced by the reviews of other consumers; and only high <b>trusters</b> tended {{to be influenced by}} assurance seals. The results show that consumer reviews {{play an important role in}} consumer decision making, indicating that online consumer communities indeed empower consumers...|$|R
40|$|Trust is a {{fundamental}} concept that underpins the coherence and resilience of social systems and shapes human behavior. Despite the importance of trust as a social and psychological concept, the concept has not gained much attention from evolutionary game theorists. In this paper, an N-player trust-based social dilemma game is introduced. While the theory shows that a society with no untrustworthy individuals would yield maximum wealth to both the {{society as a whole}} and the individuals in the long run, evolutionary dynamics show this ideal situation is reached only in a special case when the initial population contains no untrustworthy individuals. When the initial population consists of even the slightest number of untrustworthy individuals, the society converges to zero <b>trusters,</b> with many untrustworthy individuals. The promotion of trust is an uneasy task, despite the fact that a combination of <b>trusters</b> and trustworthy trustees is the most rational and optimal social state. This paper presents the game and results of replicator dynamics in a hope that researchers in evolutionary games see opportunities in filling this critical gap in the literature...|$|R
30|$|The trust {{one person}} has in another varies {{depending}} on context [1, 2]. You may trust someone to water your plants while you are away but not trust that person to babysit your children. This contextualization of trust makes sense; by definition, trust requires the <b>truster</b> to make herself vulnerable, taking a risk based on her belief that the trustee will act in her best interest. If the <b>truster</b> has good information about the trustee’s plant tending skills, she {{may be willing to}} risk her greenery, but a green thumb does not imply childcare skills, so risking her children’s safety does not follow.|$|E
30|$|We {{consider}} multiagent {{system settings}} where agents {{interact with each}} other. A multiagent system is an open system consisting of autonomous and heterogeneous parties or agents. By autonomy, we mean that agents can act independently. And, by heterogeneity, we mean agents have diverse internal representations, including goals and internal policies. We consider a multiagent system to be open: agents may potentially enter such a system interact with others, and leave the system. Real-world examples of such systems arise in the corporate and military sectors where agents collaborate {{with each other in}} teams. In such systems, based on their mutual interactions, an agent as a <b>truster</b> estimates (and continually revises) its trust for another agent as a trustee. For example, in a corporate setting, an employer (<b>truster)</b> can assign a task to an employee (trustee). If the employee performs the task, the employer’s trust increases for its employee. Similarly, in the military, a commander (<b>truster)</b> can ask a subordinate (trustee) to destroy a particular target. If the subordinate success, the trust of the commander toward the subordinate presumably increases.|$|E
40|$|Abstract. Trust is a {{construct}} {{of paramount importance}} in society. Ac-cordingly, computational trust is evolving fast {{in order to allow}} trust in artificial societies. Despite the advances in this research field, most com-putational trust approaches evaluate trust by estimating the trustwor-thiness of the agents under evaluation (the trustees), without however distinguishing between the different dimensions of trustworthiness, such as ability and benevolence. In this paper, we propose different techniques to extract the ability of the trustee in the task at hand and to infer the benevolence of the trustee toward the <b>truster</b> when the trust judgment is made. Moreover, we propose to dynamically change the relative im-portance and impact of both ability and benevolence on the perceived trustworthiness of the trustee, taking into consideration the development {{of the relationship between the}} <b>truster</b> and the trustee and the disposition of the <b>truster</b> in the specific situation. Finally, we set an experimental scenario to evaluate our approach. The results obtained from these ex-periments show that the proposed techniques significantly improve the reliability of the estimation of the trustworthiness of agents...|$|E
40|$|Although {{trust and}} {{distrust}} are both crucial in online truster-trustee relationships, researchers disagree {{as to whether}} trust and distrust are distinct from each other. Given this debate, {{it is important to}} consider how distrust could be distinguished from trust. Accordingly, this paper extends the nomological network of distrust and introduces two novel antecedents never introduced in e-commerce literature: situational abnormalities and suspicion. We also propose that trust and distrust coexist in an online e-commerce relationship and can result in ambivalence when they both have high attitudinal values (represented in emotions, beliefs, or behaviours). Using a study of online consumer behaviour with 521 consumers, we largely validated our newly proposed model. We find that situational abnormalities and suspicion are separate, important novel antecedents to distrust. We also examine the effect of ambivalence on the <b>truster's</b> intentions towards the website and find a small positive effect that increases the user's intentions towards the website. Finally, we demonstrate the coexistence of trust and distrust as separate constructs, and highlight that distrust has a much larger impact on the <b>truster's</b> intentions than trust. We conclude with implications to theory and practice, along with a discussion of the limitations and future opportunities. Link_to_subscribed_fulltex...|$|R
40|$|Trust presupposes risk. Yet, {{people who}} trust others {{minimize}} risk. More precisely, {{one form of}} trust, which I shall call “strategic trust, ” manages risk. Another form of trust, which I call “moralistic ” or “generalized ” trust, discounts risk. It is this second form of trust that opens up the promise of trust to make our social and political life more cooperative and less confrontational. Moralistic trust waves away risk by doing something most economists and business people might find odd: downplaying evidence. Why should we discount risk? Generalized <b>trusters</b> don’t dismiss risk. Rather, they interpret evidence in a more positive light and are less prone to see high levels of risk than mistrusters. They look at interactions with strangers as opportunities for mutual advantage rather than as tripwires. They look at people who are different from themselves as presenting opportunities for forming new, bridging relationships. So they see immigrants and open markets as positive forces in promoting growth rather than as threats to cultural and economic hegemony. They see new technologies as ways to make life easier, rather than as perils to privacy. <b>Trusters</b> are more tolerant of minorities; {{they are more likely}} to donate to charity and to give of their time in volunteering. People with faith in others are more likely to agree on...|$|R
40|$|We use a two-person {{extensive}} form bargaining game {{to examine}} individuals? trusting and reciprocal behavior {{and how those}} relate to their scores on a trust survey. In keeping with prior research, {{we find that the}} ?self-interested? outcome is rejected by a majority of individuals. People who score high on the trust survey are both trusting and are also trustworthy, in that they reciprocate others? trust. But, people with low trust scores often exhibit trust but are not trustworthy. These ?inconsistent <b>trusters?</b> seem to be interested in exploiting the trust and trustworthiness of others in increasing their own payoff...|$|R
