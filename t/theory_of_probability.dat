554|10000|Public
5|$|Theses logicae de conversione et oppositione enunciationum, {{a public}} lecture {{delivered}} at Basel, 12 February 1686. Theses XXXI to XL {{are related to}} the <b>theory</b> <b>of</b> <b>probability.</b>|$|E
25|$|An English {{translation}} by Nathan Morrison appeared {{under the}} title Foundations of the <b>Theory</b> <b>of</b> <b>Probability</b> (Chelsea, New York) in 1950, with a second edition in 1956.|$|E
25|$|Andrey Markov {{introduced}} {{the notion of}} Markov chains (1906), which {{played an important role}} in stochastic processes theory and its applications. The modern <b>theory</b> <b>of</b> <b>probability</b> based on the measure theory was developed by Andrey Kolmogorov (1931).|$|E
50|$|Gillies, Donald (2000) Philosophical <b>Theories</b> <b>of</b> <b>Probability.</b> London: Routledge.|$|R
5000|$|S. N. Bernstein, The <b>Theory</b> <b>of</b> <b>Probabilities</b> (Russian), Moscow, Leningrad, 1946 ...|$|R
5000|$|Trent Dougherty (Jeffrey's radical probabilism, {{semantics}} for modals, <b>theories</b> <b>of</b> <b>probability)</b> ...|$|R
25|$|Together with Frank P. Ramsey and Ludwig Wittgenstein, Sraffa {{joined the}} {{so-called}} cafeteria group, an informal club that discussed Keynes's <b>theory</b> <b>of</b> <b>probability</b> and Friedrich Hayek's theory of business cycles. (Sraffa–Hayek debate) In 1939, Sraffa {{was elected to}} a fellowship at Trinity College.|$|E
25|$|Like other theories, the <b>theory</b> <b>of</b> <b>probability</b> is a {{representation}} of its concepts in formal terms—that is, in terms that can be considered separately from their meaning. These formal terms are manipulated {{by the rules of}} mathematics and logic, and any results are interpreted or translated back into the problem domain.|$|E
25|$|Beginning in 1881 and for {{the rest}} of his career, he taught at the University of Paris (the Sorbonne). He was {{initially}} appointed as the maître de conférences d'analyse (associate professor of analysis). Eventually, he held the chairs of Physical and Experimental Mechanics, Mathematical Physics and <b>Theory</b> <b>of</b> <b>Probability,</b> and Celestial Mechanics and Astronomy.|$|E
50|$|The betweenness {{problem has}} also been used to model <b>theories</b> <b>of</b> <b>probability,</b> causality, and time.|$|R
5000|$|In 1917 - [...] "Solution of some Problems in the <b>Theory</b> <b>of</b> <b>Probabilities</b> <b>of</b> Significance in Automatic Telephone Exchanges" [...] - which {{contains}} his classic formulae for call loss and waiting time.|$|R
5000|$|... "On the Use <b>of</b> the <b>Theory</b> <b>of</b> <b>Probabilities</b> in Statistics Relating to Society", 1913, J of RSS ...|$|R
25|$|The {{mathematical}} <b>theory</b> <b>of</b> <b>probability</b> {{arose from}} attempts to formulate mathematical descriptions of chance events, originally {{in the context}} of gambling, but later in connection with physics. Statistics is used to infer the underlying probability distribution of a collection of empirical observations. For the purposes of simulation, it is necessary to have a large supply of random numbers or means to generate them on demand.|$|E
25|$|The fourth {{chapter of}} this {{treatise}} includes an exposition {{of the method}} of least squares, a remarkable testimony to Laplace's command over the processes of analysis. In 1805 Legendre had published the method of least squares, making no attempt to tie it to the <b>theory</b> <b>of</b> <b>probability.</b> In 1809 Gauss had derived the normal distribution from the principle that the arithmetic mean of observations gives the most probable value for the quantity measured; then, turning this argument back upon itself, he showed that, if the errors of observation are normally distributed, the least squares estimates give the most probable values for the coefficients in regression situations. These two works seem to have spurred Laplace to complete work toward a treatise on probability he had contemplated as early as 1783.|$|E
25|$|Lyapunov {{contributed to}} several fields, {{including}} differential equations, potential theory, dynamical systems and probability theory. His main preoccupations were {{the stability of}} equilibria and the motion of mechanical systems, {{and the study of}} particles under the influence of gravity. His work in the field of mathematical physics regarded the boundary value problem of the equation of Laplace. In the theory of potential, his work from 1897 On some questions connected with Dirichlet's problem clarified several important aspects of the theory. His work in this field is in close connection with the work of Steklov. Lyapunov developed many important approximation methods. His methods, which he developed in 1899, make it possible to define the stability of sets of ordinary differential equations. He created the modern theory of the stability of a dynamic system. In the <b>theory</b> <b>of</b> <b>probability,</b> he generalised the works of Chebyshev and Markov, and proved the Central Limit Theorem under more general conditions than his predecessors. The method of characteristic functions he used for the proof later found widespread use in probability theory.|$|E
5000|$|S. Ulam (1957) Marian Smoluchowski and the <b>Theory</b> <b>of</b> <b>Probabilities</b> in Physics, American Journal of Physics, 25, 475-481 (ISSN 0002-9505).|$|R
5000|$|In 1909 - [...] "The <b>Theory</b> <b>of</b> <b>Probabilities</b> and Telephone Conversations" [...] - which {{proves that}} the Poisson {{distribution}} applies to random telephone traffic.|$|R
50|$|Andrej Rusakov holds a Master of Business Administration from Harvard Business School and MSc in Mathematics and <b>Theory</b> <b>of</b> <b>Probabilities</b> {{from the}} Mechanics & Mathematics {{department}} of the Moscow State University.|$|R
25|$|Boltzmann {{accomplished}} the feat of {{showing that the}} second law of thermodynamics is only a statistical fact. The gradual disordering of energy {{is analogous to the}} disordering of an initially ordered pack of cards under repeated shuffling, and just as the cards will finally return to their original order if shuffled a gigantic number of times, so the entire universe must some-day regain, by pure chance, the state from which it first set out. (This optimistic coda to the idea of the dying universe becomes somewhat muted when one attempts to estimate the timeline which will probably elapse before it spontaneously occurs.) The tendency for entropy increase seems to cause difficulty to beginners in thermodynamics, but is easy to understand {{from the standpoint of the}} <b>theory</b> <b>of</b> <b>probability.</b> Consider two ordinary dice, with both sixes face up. After the dice are shaken, the chance of finding these two sixes face up is small (1 in 36); thus one can say that the random motion (the agitation) of the dice, like the chaotic collisions of molecules because of thermal energy, causes the less probable state to change to one that is more probable. With millions of dice, like the millions of atoms involved in thermodynamic calculations, the probability of their all being sixes becomes so vanishingly small that the system must move to one of the more probable states. However, mathematically the odds of all the dice results not being a pair sixes is also as hard as the ones of all of them being sixes, and since statistically the data tend to balance, one in every 36 pairs of dice will tend to be a pair of sixes, and the cards -when shuffled- will sometimes present a certain temporary sequence order even if in its whole the deck was disordered.|$|E
500|$|Playing {{a central}} role in the <b>theory</b> <b>of</b> <b>probability,</b> the Wiener process is often {{considered}} the most important and studied stochastic process, [...] with connections to other stochastic processes. Its index set and state space are the non-negative numbers and real numbers, respectively, so it has both continuous index set and states space. [...] But the process can be defined more generally so its state space can be -dimensional Euclidean space. If the mean of any increment is zero, then the resulting [...] Wiener or Brownian motion process is said to have zero drift. If the mean of the increment for any two points in time is equal to the time difference [...] multiplied by some constant , which is a real number, then the resulting stochastic process is said to have drift [...]|$|E
500|$|Between 1703 and 1705, Leibniz {{corresponded with}} Jakob after {{learning}} about his discoveries in probability {{from his brother}} Johann. Leibniz managed to provide thoughtful criticisms on Bernoulli's law of large number, but failed to provide Bernoulli with de Witt's work on annuities that he so desired. From the outset, Bernoulli wished for his work to demonstrate that combinatorics and probability theory would have numerous real-world applications in all facets of society—in the line of Graunt's and de Witt's work— and {{would serve as a}} rigorous method of logical reasoning under insufficient evidence, as used in courtrooms and in moral judgements. It was also hoped that the <b>theory</b> <b>of</b> <b>probability</b> could provide comprehensive and consistent method of reasoning, where ordinary reasoning might be overwhelmed by the complexity of the situation. Thus the title Ars Conjectandi was chosen: [...] a link to the concept of ars inveniendi from scholasticism, which provided the symbolic link to pragmatism he desired and also {{as an extension of the}} prior Ars Cogitandi.|$|E
50|$|Pierre-Simon Laplace (1774) {{made the}} first attempt to deduce a rule for the {{combination}} of observations from the principles <b>of</b> the <b>theory</b> <b>of</b> <b>probabilities.</b> He represented the law <b>of</b> <b>probability</b> <b>of</b> errors by a curve and deduced a formula for the mean of three observations.|$|R
50|$|Frank Ramsey (see his {{collected}} papers, {{edited by}} D. H. Mellor) and Bruno de Finetti, developed projectivist <b>theories</b> <b>of</b> <b>probability</b> {{in the early}} twentieth century. To explain their <b>theories,</b> the concept <b>of</b> degree of belief must first be introduced.|$|R
60|$|The {{consideration}} of the latter question, and any {{consideration of}} the former beyond that already given to it, belong to what mathematicians term the doctrine of chances, or, in a phrase of greater pretension, the <b>Theory</b> <b>of</b> <b>Probabilities.</b>|$|R
2500|$|Pierre Simon de Laplace (1812) Analytical <b>Theory</b> <b>of</b> <b>Probability</b> ...|$|E
2500|$|Andrei Nikolajevich Kolmogorov (1950) Foundations of the <b>Theory</b> <b>of</b> <b>Probability</b> ...|$|E
2500|$|Ernest Nagel, Principles of the <b>theory</b> <b>of</b> <b>probability,</b> 1939, vol.1 n.6 ...|$|E
60|$|When {{approximate}} generalizations {{are joined}} by way of addition, we may deduce from the <b>theory</b> <b>of</b> <b>probabilities</b> laid down in a former chapter, in what manner each of them adds to the <b>probability</b> <b>of</b> a conclusion which has the warrant of them all.|$|R
5|$|In 1933 Andrei Kolmogorov {{published}} in German {{his book on}} the foundations <b>of</b> <b>probability</b> <b>theory</b> titled Grundbegriffe der Wahrscheinlichkeitsrechnung, where Kolmogorov used measure theory to develop an axiomatic framework for <b>probability</b> <b>theory.</b> The publication <b>of</b> this book is now widely {{considered to be the}} birth <b>of</b> modern <b>probability</b> <b>theory,</b> when the <b>theories</b> <b>of</b> <b>probability</b> and stochastic processes became parts of mathematics.|$|R
40|$|This paper (based on {{joint work}} with M. J. Schervish and J. B. Kadane) {{discusses}} some {{differences between the}} received <b>theory</b> <b>of</b> regular conditional distributions, which is the countably additive <b>theory</b> <b>of</b> conditional <b>probability,</b> and a rival <b>theory</b> <b>of</b> conditional <b>probability</b> using the <b>theory</b> <b>of</b> finitely additive <b>probability.</b> The focus <b>of</b> the paper is maximally "improper" conditional probability distributions, where the received theory requires, in effect, that P{a: P(a|a) = 0 } = 1. This work builds upon the results of Blackwell and Dubins (1975) ...|$|R
2500|$|... 1654– Blaise Pascal and Pierre de Fermat {{create the}} <b>theory</b> <b>of</b> <b>probability.</b>|$|E
2500|$|For example, [...] can be Euclidean -space [...] or some Lebesgue {{measurable}} {{subset of}} it, [...] is the σ-algebra of all Lebesgue measurable subsets of , and μ is the Lebesgue measure. In the mathematical <b>theory</b> <b>of</b> <b>probability,</b> we confine our study to a probability measure, which satisfies [...]|$|E
2500|$|The Lebesgue {{integral}} {{plays an}} important role in probability theory, in the branch of mathematics called real analysis and in many other fields in the mathematical sciences. It is named after Henri Lebesgue (1875–1941), who introduced the integral [...] It is also a pivotal part of the axiomatic <b>theory</b> <b>of</b> <b>probability.</b>|$|E
50|$|Bachelard saw how {{seemingly}} irrational theories often simply {{represented a}} drastic shift in scientific perspective. For instance, {{he claimed that}} the <b>theory</b> <b>of</b> <b>probabilities</b> was just another way of complexifying reality through a deepening of rationality (even though critics like Lord Kelvin found this theory irrational).|$|R
25|$|P. Pluch, <b>Theory</b> <b>of</b> Quantum <b>Probability,</b> PhD Thesis, University of Klagenfurt, 2006.|$|R
40|$|An {{overview}} is given, {{with new}} results, of mathematical models and algorithms for probabilistic logic, probabilistic entailment and various extensions. Analytical and numerical solutions are considered, the former leading to automated generation of theorems in the <b>theory</b> <b>of</b> <b>probabilities.</b> Ways to restore consistency and relationship with Bayesian networks are also studied. ...|$|R
