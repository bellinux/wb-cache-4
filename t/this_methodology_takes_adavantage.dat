0|10000|Public
40|$|International audienceNew β-aminocyclohexanones and β-aminocyclohexanols, with {{a primary}} amino group, have been {{obtained}} by a short and efficient sequence involving an intramolecular tandem isomerization-Mannich reaction as the key step. <b>This</b> <b>methodology</b> <b>takes</b> advantage of tert-butanesulfinyl protection of the nitrogen atom...|$|R
40|$|I {{describe}} {{a new type}} of comparative genomic database for phylogenetic profiling based on pre-calculated homologous protein groups. <b>This</b> <b>methodology</b> <b>takes</b> advantage {{of the fact that the}} proteins that are conserved in a set of organisms (in-category) that share a certain morphology, physiological function, enzyme activity, or metabolic pathway (referred to as 'trait T') may be involved in the trait T. This has been used to infe...|$|R
40|$|In {{this paper}} we discuss the case of {{defining}} a common semantic e-invoicing model for the Dutch government. We have defined a model-based methodology for developing semantic standards and have applied <b>this</b> <b>methodology</b> to the e-invoicing model. <b>This</b> <b>methodology</b> <b>takes</b> into account that multiple standards already exist, {{as is the case}} for e-invoicing with the UBL, UN/Cefact CII and SETU/hr-XML standards. After describing the methodology, the e-invoicing semantic model is briefly presented. The {{most important part of the}} paper presents lessons learnt and recommendations on defining a semantic model in an environment in which several stakeholders are present and multiple standards already exist...|$|R
40|$|The {{implementation}} of the Trans-European Network stresses {{the need for an}} evaluation of the feasibility of each TEN corridor and its parts, both from a functional, financial, socio-economic and environment perspectives. General guidelines far approaching such an issue is required. The paper aims at developing a quite general methodology to cope with all the relevant aspects concerning the {{implementation of}} a feasibility study for a transport corridor. <b>This</b> <b>methodology</b> <b>takes</b> up either theoretical or practical standpoints in order to integrate them in an integrated scheme. Moreover, some critical issues concerning the use of the generalized cost and the economies of scale are raised...|$|R
40|$|Abstract: Map {{matching}} algorithms are {{the conventional}} way to generate path observations from GPS data for route choice models. The deterministic matching may introduce extra biases to parameters of route choice models if the matching is wrong. In this paper, a new methodology is proposed to probabilistically generate path representation from GPS location {{data and the}} underlying network. <b>This</b> <b>methodology</b> <b>takes</b> advantage of both spatial and temporal relationships existing in the location data and the network. The generated result includes a set of potential true paths, along with a probability of each proposed path {{to have been the}} actual path. An algorithm is designed and applied to a simulated trip...|$|R
40|$|This paper {{describes}} a methodology {{that can be}} used for rigorously developing authentication protocols for distributed systems. It is based on the logic of authentication proposed by Lampson et al. We implemented the logic of authentication using Higher Order Logic (HOL) as the theorem prover. Based on <b>this</b> implementation, a <b>methodology</b> was developed for analyzing authentication protocols for distributed systems, and was utilized to analyze published authentication protocols. <b>This</b> <b>methodology</b> <b>took</b> into consideration the prudent engineering practices for cryptographic protocol design, proposed by Abadi and Needham. It was observed that formalizing the steps in a protocol let the aws in the design be easily noticeable. The methodology developed assists in systematically checking for known types of vulnerabilities in authentication protocols...|$|R
40|$|Optical {{communications}} {{is becoming}} an ever-increasingly important option for designers of space-to- ground communications links, whether it be for government or commercial applications. In this paper the technology being developed by NASA for use in space-to-ground optical communications is presented. Next, a program which is collecting a long term data base of atmospheric visibility statistics for optical propagation through the atmosphere will be described. Finally, a methodology for utilizing the statistics of the atmospheric data base {{in the analysis of}} space-to-ground links will be presented. <b>This</b> <b>methodology</b> <b>takes</b> into account the effects of station availability, is useful when comparing optical communications with microwave systems, and provides a rationale establishing the recommended link margin...|$|R
40|$|We {{present a}} {{methodology}} {{to reconstruct the}} radial breathing mode (RBM) region of the resonance Raman spectra of single walled carbon nanotubes (SWNTs) in isolated and aggregated states. <b>This</b> <b>methodology</b> <b>takes</b> into account the experimentally determined electron-phonon matrix elements (M(ph)) along with an energetic deviation term (Delta E). In the case of isolated SWNTs, Delta E {{was found to be}} zero, while the RBM spectral reconstruction was insensitive to variations of the electron-phonon matrix elements. On the other hand, incorpration of a non-zero Delta E value and M(ph) values corrected for diameter and chiral angle dependence through trigonal warping effects was necessary in order to obtain optimum RBM spectral reconstruction for aggregated SWNT samples. (c) 2006 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim...|$|R
40|$|We {{present a}} utility-based {{methodology}} for the valuation of early exercise contracts in incomplete markets. Incompleteness stems from nontraded assets {{on which the}} contracts are written. <b>This</b> <b>methodology</b> <b>takes</b> into account the individual’s attitude towards risk and yields nonlinear pricing rules. The early exercise indifference prices solve a quasilinear variational inequality with an obstacle term. They are also shown to satisfy an optimal stopping problem with criterion given by their European indifference price counterpart. A class of numerical schemes are developed for the variational inequalities and a general approach for solving numerically nonlinear equations arising in incomplete markets is discussed. Copyright Springer-Verlag Berlin/Heidelberg 2003 Nontraded assets, early exercise contracts, utility maximization with discretionary stopping, Hamilton-Jacobi-Bellman equations, quasilinear variational inequalities, nonlinear asset pricing,...|$|R
40|$|International audienceA {{methodology}} {{to design}} an attractive robust controller for traveling wave ultrasonic motor (TWUSM) is followed on <b>this</b> work. <b>This</b> <b>methodology</b> <b>takes</b> into account several non-linear effects, {{such as the}} friction effect, those occur in the ultrasonic motor mechanism. To achieve that, our first objective is to derive a simplified hybrid model (PSHM) that catch the main behavior of the motor during normal operation, including the stator/rotor contact interface, {{and that can be}} used to design speed and position control laws. Finally, based on this model, a Fuzzy logic controller (FLC) is designed in order to achieve robustness against several uncertainties (i. e. load torque variations, motor heating, parameters uncertainties [...] .), and a popular Shinsei USR 60 is used experimentally to validate the proposed methodology...|$|R
40|$|In {{the present}} work a methodological {{proposal}} is presented for modeling urban environmental problems. It combines Geographic Information Systems and numerical techniques {{in order to}} generate probable impact scenarios. Additionally, a specific application is presented as an example oriented to creating susceptibility maps of landslides risk scenarios in an intermediate Colombian city. More specifically, the necessity of finding transversal methods to analyze the complex urban realities is presented. Among these realities, we pick up the possibility of landslides in Andes cities and a whole methodology based on a multifactorial cause analysis is introduced. <b>This</b> <b>methodology</b> <b>takes</b> into account past experiences to propose possible futures scenarios, relying on both Geographic Information Systems to store data and on Artificial Neural Networks to classify them...|$|R
40|$|Substrate noise {{caused by}} large digital {{circuits}} will degrade {{the performance of}} analog circuits located on the same substrate. To simulate this performance degradation, {{the total amount of}} generated substrate noise must be known. Simulating substrate noise generated by large digital circuits is however not feasible with existing circuit simulators and detailed substrate models due to the long simulation times and high memory requirements. We have developed a <b>methodology</b> to simulate <b>this</b> substrate noise generation at a higher level. Not only does <b>this</b> <b>methodology</b> <b>take</b> noise coupling from switching gates into account, but also noise coupling from the power supply is included. This paper describes <b>this</b> simulation <b>methodology.</b> In the paper it is shown that the high-level simulations correspond very well with SPICE simulations and that a large gain in simulation speed is obtained. <b>This</b> high-level simulation <b>methodology</b> makes it possible to predict substrate noise generation of large digita [...] ...|$|R
40|$|Investment {{decisions}} {{in the development and}} production of new aircraft models is difficult because of the technical and market uncertainties associated with such a complex process. The accompanying risks can be mitigated through a flexible approach that incorporates several decision points at different stages of the process. Therefore, as the project evolves, management will be able to diagnose its progress, compare it to previous expectations, and decide to continue or not. In this paper, we present a methodology to evaluate flexible business strategies that is based on real options analysis (ROA) and Monte Carlo simulation. <b>This</b> <b>methodology</b> <b>takes</b> into account the flexibility that managers have to affect the success of any given project and, therefore, it provides a better estimate of project value. Numerical results are given for a representative process based on actual aircraft manufacturer’s data. I...|$|R
40|$|Fingerprint {{analysis}} {{is one of}} the most important methods used for personal identification of evidence found at a crime scene for forensic purposes. Using scanning electrochemical microscopy (SECM) imaging, researchers can visualize the ultrastructure of human fingerprints on wet porous and nonporous surfaces by combining with silver-staining or multi-metal-deposition (MMD) technology. SECM allows investigators to image chemical activities of fingerprint surfaces with an impressively high resolution, such as the third level valuable information for confirming an identification. <b>This</b> <b>methodology</b> <b>takes</b> a significant advantage of the high sensitivity of SECM towards the small variation of electrochemical reaction rates at the substrate surface. In this review, we highlight the recent breakthroughs in ultrasensitive imaging and detection of latent fingerprints with a special focus on a novel application of SECM. We will also discuss our perspectives on future research directions...|$|R
40|$|In this research, {{we present}} a {{hierarchical}} Data Envelopment Analysis (DEA) methodology for competitiveness analysis. <b>This</b> <b>methodology</b> <b>takes</b> into account the heterogeneity of the decision making units (DMUs) {{as well as the}} diversity of the comparison criteria. We propose to homogenize the DMUs by grouping them hierarchically, which permits a better identification and definition of the criteria in each specific grouping. The methodology proceeds first by the determination of the performances or relative efficiencies, which are in turn aggregated into competitiveness indices in each grouping by the superiority index of [1]; then, the overall competitiveness indices are determined additively along the hierarchical levels. We illustrate the methodology by a competitiveness analysis of several companies belonging to different sectors of activity in an economy, where are suggested ways of improvement for the non-competitive companies within their sectors and within the economy...|$|R
40|$|International audienceIn {{the present}} paper, a new {{approach}} is proposed to assess the clear-sky direct normal irradiance (DNI) in real time. This approach combines an existing empirical model, proposed by Ineichen and Perez in 2002, with a new methodology for the computation of atmospheric turbidity. <b>This</b> <b>methodology</b> <b>takes</b> {{advantage of the fact}} that changes in atmospheric turbidity are relatively small throughout the day in comparison to changes in DNI, even when the sky is free of clouds. We considered data from two experimental sites (Golden, in the USA, and Perpignan, in France) and compared the proposed approach with several combinations of empirical models and ways of computing atmospheric turbidity. A polynomial of the cosine of the solar zenith angle has also been included in the comparative study. In both sites, our approach outperforms the other approaches. It has proven to be well adapted to the real-time assessment of the clear-sky DNI, in particular when the Sun is occulted by clouds during less than eight consecutive hour...|$|R
40|$|International audienceThis paper {{deals with}} the {{systemic}} design of permanent magnet (PM) generator associated with fixed-pitch turbine for tidal energy generation. The main problem with marine current turbines systems are the maintenance requirements of the drive-train. It is known that the blade pitch system increases the complexity, cost, and the maintenance requirements of the drive-train. In offshore energy generation, the maintenance should be minimized as much as possible. For that purpose direct-drive permanent-magnet machines associated with fixed-pitch marine turbines can be an attractive solution. The main challenge with fixed-pitch blades is to ensure the power limitation of the turbine at high speed without using variable pitch system. As solution, we propose a systemic design approach of the generator {{that takes into account}} the power limitation requirement. In addition, <b>this</b> <b>methodology</b> <b>takes</b> into account the tidal site energy potential, the turbine characteristic, the control strategy, the generator specifications and the power converter constraints. The obtained results show the feasibility of our approach to satisfy the control strategy requirements...|$|R
40|$|In this paper, {{we present}} several novel {{strategies}} to improve software controlled cache utilization, {{so as to}} achieve lower power requirements for multi-media and signal processing applications. Our methodology is targeted towards embedded multi-media and DSP processors. <b>This</b> <b>methodology</b> <b>takes</b> into account many program parameters like the locality of data, size of data structures, access structures of large array variables, regularity of loop nests and the size and type of cache {{with the objective of}} improving the cache performance for lower power. We also take into account the potential overhead due to the different transformations on the instruction count and the number of execution cycles to meet the real time constraints and code size limitations. Experiments on a real life demonstrator illustrate the fact that our methodology is able to achieve significant gain in power requirements while meeting all other system constraints. 1. Introduction and Related Work Rapid progress in th [...] ...|$|R
40|$|This paper {{focuses on}} the {{multilevel}} projection method (PML) applied to numerical solution of the basic equations of fluid dynamics formulated as least-squares problems for first-order systems. The fundamental approach taken here is to pose the fluid flow equations in their first-order form, incorporate additional (usually redundant) equations where they improve {{the character of the}} formulation, and define the objective as that of minimizing the L 2 norm of the defect (or residual) of these equations. This is the basic idea behind first-order system least squares (FOSLS). The Rayleigh-Ritz variational form of PML is applied to discretize and solve the FOSLS minimization problem. This paper summarizes the basic principles and concepts of PML and FOSLS, and briefly describes some of the special forms that <b>this</b> <b>methodology</b> <b>takes</b> for convection-diffusion, Helmholtz, Cauchy-Riemann, Stokes, and hyperbolic equations. Key words: least-squares, second-order elliptic problems, finite elements, RayleighRitz, computational fluid dynamics. AMS(MOS) subject classifications: 65 F 10, 65 F 30. 1...|$|R
40|$|This paper {{proposes a}} new {{top-down}} hierarchical, mu lti-hop, secure routing protocol for the wireless sensor network, which is resilient to report fabric ation attack. The report fabrication attack tries t o generate bogus reports by compromising the sensor n odes to mislead the environment monitoring application executed by randomly deployed wireless sensor nodes. The proposed protocol relies on symmetric key mechanism which {{is appropriate for}} ra ndom deployment of wireless sensor nodes. In the proposed protocol, base station initiates the synth esis of secure hierarchical topology using top down approach. The enquiry phase of the protocol provide s assurance for the participation of all the cluste r heads in secure hierarchical topology formation. Fu rther, <b>this</b> <b>methodology</b> <b>takes</b> care of failure of he ad node or member node of a cluster. This protocol ens ures confidentiality, integrity, and authenticity o f the final report of the monitoring application. The sim ulation results demonstrate the scalability of the proposed protocol...|$|R
40|$|This paper {{deals with}} the {{systemic}} design of permanent magnet (PM) generator associated with fixed-pitch turbine for tidal energy generation. The main problem with marine current turbines systems are the maintenance requirements of the drive-train. It is known that the blade pitch system increases the complexity, cost, and the maintenance requirements of the drive-train. In offshore energy generation, the maintenance should be minimized as much as possible. For that purpose direct-drive permanent-magnet machines associated with fixed-pitch marine turbines can be an attractive solution. The main challenge with fixed-pitch blades is to ensure the power limitation of the turbine at high speed without using variable pitch system. As solution, we propose a systemic design approach of the generator {{that takes into account}} the power limitation requirement. In addition, <b>this</b> <b>methodology</b> <b>takes</b> into account the tidal site energy potential, the turbine characteristic, the control strategy, the generator specifications and the power converter constraints. The obtained results show the feasibility of our approach to satisfy the control strategy requirement...|$|R
40|$|The Simalytic^TM Modeling Technique (from Simulation/Analytic) is {{a hybrid}} {{technique}} that addresses modeling and predicting the capacity requirements of computer systems in complex enterprise-wide client/server multiple-platform applications. This technique uses a general purpose simulation tool as an underlying framework and an analytic tool to represent application response times at individual nodes. The {{bridge between the}} two techniques is a transform function that will adjust the service time for a given server depending on the load at that server. It combines both platform-centric tools (limited features but detailed platform information) and general purpose tools (rich low level features) to address today's large heterogeneous enterprises. <b>This</b> <b>methodology</b> <b>takes</b> advantage of features in the different techniques (simulation vs. analytic queuing theory) as well as features in the different tools (platform-centric vs. general purpose) by defining the interface between the simulation framework and queuing theory node models. The benefits of using a hybrid technique are discussed and results are presented to show {{the validity of the}} Simalytic technique...|$|R
40|$|The {{academic}} and professional literature addressing {{business process reengineering}} points at inter-task information flow delays (handoffs) as {{a major source of}} processing errors and excessive delays in job completion times. Many of the success stories cited in the literature call for employee-empowerment and task consolidation. It means that many benefits are accrued by consolidating tasks, rather than processing the existing task structure at a faster rate. However, there has not been any systematic methodology available to determine the optimal re-bundling of information intensive tasks. Our paper presents a new powerful methodology designed to optimally consolidate tasks {{in order to reduce the}} overall cycle time. <b>This</b> <b>methodology</b> <b>takes</b> into account the following parameters: precedence of information flows, loss of specialization, alignment of decision rights, reduction in handoffs and technology support costs. Several application examples presented here highlight the viability of our approach and illustrate the key organizational and technological tradeoffs associated with the redesign of transaction processing activities. ...|$|R
40|$|The {{optimization}} {{of chemical}} processes where the flowsheet topology is not kept fixed is a challenging discrete-continuous optimization problem. Usually, this task has been performed through equation based models. This approach presents several problems, as tedious and complicated component properties estimation or {{the handling of}} huge problems (with thousands of equations and variables). We propose a GDP approach {{as an alternative to}} the MINLP models coupled with a flowsheet program. The novelty of this approach relies on using a commercial modular process simulator where the superstructure is drawn directly on the graphical use interface of the simulator. <b>This</b> <b>methodology</b> <b>takes</b> advantage of modular process simulators (specially tailored numerical methods, reliability, and robustness) and the flexibility of the GDP formulation for the modeling and solution. The optimization tool proposed is successfully applied to the synthesis of a methanol plant where different alternatives are available for the streams, equipment and process conditions. Spanish Ministry of Science and Innovation (CTQ 2012 - 37039 -C 02 - 02) ...|$|R
40|$|Some {{companies}} are heavily reliant on {{the capabilities of}} their manufacturing technology for product competitiveness. Likewise, the capabilities of a manufacturing technology are dependent on the sourcing policy that the host company practices. This paper describes research that has explored {{a wide variety of}} US companies to understand manufacturing technology sourcing policies and how they have been formed. This research finds that there is a preference amongst the US organizations studied not to become involved with equipment manufacture, though some examples of full integration do occur. These policies are not determined by formalized decision processes, rather they are formed implicitly during technology choice. In this research, factors that influence a technology source have been identified. These drivers are then used to establish a methodology that will help practising managers to form a technology sourcing decision. <b>This</b> <b>methodology</b> <b>takes</b> into account the business demands placed on a technology, along with the characteristics of the host company's supplier base...|$|R
40|$|Within much {{contemporary}} social ontology {{there is}} a particular <b>methodology</b> at work. <b>This</b> <b>methodology</b> <b>takes</b> {{as a starting point}} two or more asocial or atomic individuals. These individuals are taken to be perfectly functional agents, though outside of all social relations. Following this, combinations of these individuals are considered, to deduce what constitutes a social group. Here I will argue that theories which rely on <b>this</b> <b>methodology</b> are always circular, so long as they purport to describe the formation of all social groups, as they must always presuppose a pre-existing collectivity. Such methodology also produces various distortions in our theories, such as voluntarism. I focus on the workings of Plural Subject Theory as laid out by Margaret Gilbert in On Social Facts. I show that the formation of a plural subject always requires communication, and that communication always requires a pre-existing collectivity. i examine the elements within Plural Subject Theory which protect gilbert from these accusations of circularity, and argue against them. I finalise by suggesting that what Plural Subject Theory, and social ontology in general, requires as a theoretical starting point is not atomic individuals and their combinations, but rather combinations of already socialised or embedded individual...|$|R
40|$|A new {{methodology}} {{is developed}} for the boring bar structural design based on the theory of optimal control. <b>This</b> <b>methodology</b> <b>takes</b> into account the effect of cutting data selection on the boring bar performance in the design stage. For establishing the design criterion, a system performance index is introduced, which {{is defined as the}} summation of norm of each harmonic component of the system transfer function at a specified frequency bandwidth. Consequently, the process of minimizing this index is equivalent to an optimal setting of the design variables of the boring bar structure through the transfer function of the boring machining system. A case study of designing a flatted boring bar structure is provided. The process of determining the flat orientation demonstrates the design criterion of keeping the stochastic part of tool vibration during machining at a possibly low level. A rotatable flatted boring bar is designed for this study. Experiments are carried out and the predicted optimal flat orientation is compared with corresponding measured roughness AA values at different orientation settings, showing good agreements...|$|R
40|$|We {{propose a}} novel method to {{reconstruct}} the hypothetical geometry of the healthy vasculature prior to intracranial aneurysm (IA) formation: a Frenet frame is calculated along the skeletonization of the arterial geometry; upstream and downstream boundaries of the aneurysmal segment are {{expressed in terms of}} the local Frenet frame basis vectors; the hypothetical healthy geometry is then reconstructed by propagating a closed curve along the skeleton using the local Frenet frames so that the upstream boundary is smoothly morphed into the downstream boundary. <b>This</b> <b>methodology</b> <b>takes</b> into account the tortuosity of the arterial vasculature and requires minimal user subjectivity. The method is applied to 22 clinical cases depicting IAs. Computational fluid dynamic simulations of the vasculature without IA are performed and the haemodynamic stimuli in the location of IA formation are examined. We observe that locally elevated wall shear stress (WSS) and gradient oscillatory number (GON) are highly correlated (20 / 22 for WSS and 19 / 22 for GON) with regions susceptible to sidewall IA formation whilst haemodynamic indices associated with the oscillation of the WSS vectors have much lower correlations...|$|R
40|$|Input to the {{language}} comprehension system frequently deviates from ideal delivery. One major type of deviation is speech disfluency: the pauses, ums, uhs, repeated words and false starts that occur throughout spontaneous speech. While {{a few studies have}} examined the effects of disfluent speech on {{the language}} comprehension system, there is relatively little understanding of the online effects of disfluent speech. In this dissertation, I use a newly rediscovered methodology known as the visual world paradigm to examine some effects of disfluent speech on syntactic parsing and reanalysis which were initially described in studies using offline tasks. <b>This</b> <b>methodology</b> <b>takes</b> advantage of a link between eye movements within a constrained visual world and the processing of spoken language. An initial study intended to demonstrate the value of this paradigm {{for the study of the}} online effects of disfluency on syntactic parsing found mixed results. Some measures showed evidence of the effects of disfluencies on parsing, but other measures showed no such effects. In addition, previously reported effects from the particular visual world used in this initia...|$|R
40|$|One of {{the recent}} {{challenges}} in wireless sensor networks is the design of efficient algorithms to monitor a set of discrete targets lying at a field. A set of active nodes must cover all the available targets {{and at the same}} time retain connectivity with the sink. Such a set can remain active un-til one active node depletes its battery. In this paper, we analyze the problem of finding the proper sensor scheduling in order to maximize the total network lifetime. We present OCCH (Optimized Connected Cover-age Heuristic) an efficient algorithm that is based on a general connected coverage <b>methodology.</b> <b>This</b> <b>methodology</b> <b>takes</b> into account the associ-ation of the sensors with the poorly covered targets that set an upper bound on the overall computed lifetime. Two solutions are presented to efficiently manage the battery life of these sensors followed by other minor improvements that prolong the network lifetime. Extensive simulation re-sults are presented that show that our solution outperforms other known algorithms found in the literature in terms of achievable network lifetime. ...|$|R
40|$|Abstract. Question Answering Systems or (QA {{systems for}} short) are {{regarded}} as {{the next generation of}} the current search engines. Instead of returning a list of relevant documents, QA systems find the direct answer to the query posed in natural language. The key difficulty in designing such systems is to perform reasoning on natural language knowledge base. The theory of Computing with Words (CW), proposed by Zadeh, offers a mathematical tool to formally represent and reason with perceptive information. CW views a proposition in natural language as imposing a soft/hard constraint on an attribute and represents it in form of a Generalized Constraint (GC). In this paper we develop a reasoning methodology for the CW-based QA systems. <b>This</b> <b>methodology</b> <b>takes,</b> as input, the knowledge base and the query in form of generalized constraints and organizes the knowledge related to the query in a new tree structure, referred to as Constraint Propagation Tree (CPT). CPT Generates a plan to find the most relevant answer to the query and allows improving the answer by establishing an information-seeking dialog with user...|$|R
40|$|In {{this paper}} we review some {{advances}} in High-κ characterization {{by means of}} capacitance measurement in the radio-frequency regime (widely known as RFCV). Firstly, we present a robust methodology for the gate impedance parameter extraction in short channel leaky devices, based on measurements from DC to the GHz range and fitting with a robust weighted algorithm. Secondly, we will present a novel RFCV technique which pushes the conventional split-CV measurement to the MHz range. This RF-split-CV is based on measuring with a 2 -port network analyzer, {{as opposed to the}} conventional technique which uses a 1 -port LCR meter. This improved technique is the basis for accurate mobility extraction as studied in the final part of the paper. <b>This</b> <b>methodology</b> <b>takes</b> parasitics fully into account: the RF-split-CV curves obtained are used for the accurate metallurgical channel length extraction. Combination of these Lmet results with conventional Ids- Vgs curves measured in the linear regime leads to the source and drain resistance calculation. After all these corrections have been performed, the mobility is finally calculated...|$|R
40|$|In {{debates about}} the {{positive}} effects of renewable and bioenergy projects the aspect of generating regional added value is discussed widely. But the real effects, generated by this regional added value stayed up to now on a non-measurable level. In order to expedite the calculation of these important figures, the author presents a field tested method for confidently arriving at useful values. <b>This</b> <b>methodology</b> <b>takes</b> into consideration the ecological, economical and social impact of a given biomass project's implementation. The model enables a comparison between the different renewable energy plants as well as between them and plants and technology of competing alternatives. Regional authorities are hereby enabled to count on a tool for confidently measuring the possible results of various bioenergy utilization technologies. With this knowledge at hand, they could then take qualified decisions towards positive effects for their region. The developed tool allows the definition of adjustable parameters, and therefore it is able to influence the regional framework regarding a more sustainable development. Regional added value Renewable energy Biomass Bioenergy Indicator Tool Sustainable development Project impact...|$|R
40|$|The aim of {{this paper}} is to {{demonstrate}} a simple methodology for performing a control benefits analysis. <b>This</b> <b>methodology</b> <b>takes</b> a global approach to determining how to improve the process. In the field of wastewater treatment this benchmark study can be a useful tool to investigate whether it is worth upgrading the process. This was proved by applying it to an industrial wastewater treatment plant in Belgium that is currently undergoing a major upgrade in its control system. This was the first application of the method to a full-scale WWTP. The results of the study show the value of performing it at the beginning of an upgrade project. Although the study does not replace the need for a more thorough analysis, it points out the areas that this analysis should focus on. The major conclusion of the paper is that the benefits study not only proves its value at the beginning of a control upgrade, it is also a useful periodical evaluation method that can redirect the project as new [...] ...|$|R
40|$|Abstract. To get a {{quantitative}} estimate of residual stresses in polycrystals from XRD measurements, a micromechanical modeling is required, except in particular cases. The {{most widely used}} method is only valid for homogeneous and isotropic samples. We present here the possibility to determine residual stresses by coupling measurements with the portable INELTM Xsolo equipment with a self-consistent polycrystalline model. <b>This</b> <b>methodology</b> may <b>take</b> into account texture and intergranular stresses induced by thermomechanical treatments. One example obtained for titanium subjected to tensile loading illustrates the methodology...|$|R
40|$|Aim {{of study}} : In <b>this</b> study, a <b>methodology</b> has been {{designed}} to assess biodiversity in the frame of the Spanish National Forest Inventory with the aim of evaluating the conservation status of Spanish forests and their future evolution. <b>This</b> <b>methodology</b> <b>takes</b> into account the different national and international initiatives together with the different types and characteristics of forests in Spain. Area of study : Álava province (Basque country, Spain). Material and methods : To analyse the contribution of each of the different indices to the biodiversity assessment, a statistical analysis using PCA multivariate techniques was performed for structure, composition and dead wood indicators. Main Results : The selected biodiversity indicators (based on field measurements) are presented along with an analysis of the results from four representative forest types in Álava by way of an example of the potential of <b>this</b> <b>methodology.</b> Research highlights : The statistical analysis revealed the important information contribution of Mingling index to the composition indicators. Regarding the structure indicators, it is remarkable the interest of using standard deviations and skewness of height and diameter as indicators. Finally it is interesting to point out the interest of assessing dead saplings since they provide additional information and their volume is a particularly useful parameter for analyzing the success of regeneration. Keywords : species richness; structural diversity; dead wood; NFI; PCA. </p...|$|R
