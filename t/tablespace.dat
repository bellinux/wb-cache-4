31|13|Public
5000|$|Oracle {{database}} management tracks its computer data storage {{with the help}} of information stored in the [...] <b>tablespace.</b> The [...] <b>tablespace</b> contains the data dictionary, indexes and clusters. A data dictionary consists of a special collection of tables that contains information about all user-objects in the database. Since version 8i, the Oracle RDBMS also supports [...] "locally managed" [...] tablespaces that store space management information in bitmaps in their own headers rather than in the [...] <b>tablespace</b> (as happens with the default [...] "dictionary-managed" [...] tablespaces). Version 10g and later introduced the [...] <b>tablespace,</b> which contains some of the tables formerly stored in the [...] <b>tablespace,</b> along with objects for other tools such as OEM, which previously required its own <b>tablespace.</b>|$|E
5000|$|Only {{objects with}} the INMEMORY {{attribute}} get populated into the In-Memory column store. The INMEMORY attribute {{can be specified}} on a <b>tablespace,</b> table, (sub)partition, or materialized view. If it is enabled at the <b>tablespace</b> level, then all tables and materialized views in the <b>tablespace</b> are enabled for In-Memory by default.|$|E
5000|$|Data {{and index}} files: These files provide the {{physical}} storage of data, which can consist of the data-dictionary data (associated with the <b>tablespace</b> SYSTEM), user data, or index data. DBAs can manage these files manually or leave their administration to Oracle itself. Note that a datafile has {{to belong to}} exactly one <b>tablespace,</b> whereas a <b>tablespace</b> can consist of multiple datafiles.|$|E
50|$|By using <b>tablespaces,</b> an {{administrator}} {{can control the}} disk layout of an installation. A common use of <b>tablespaces</b> is to optimize performance. For example, a heavily used index can be placed on a fast SSD. On the other hand, a database table which contains archived data that is rarely accessed could be stored on a less expensive but slower magnetic hard drive.|$|R
5000|$|Physical schema: {{describes}} the physical means used to store data. This {{is concerned with}} partitions, CPUs, <b>tablespaces,</b> and the like.|$|R
5000|$|Physical {{data model}} : {{describes}} the physical {{means by which}} data are stored. This is concerned with partitions, CPUs, <b>tablespaces,</b> and the like.|$|R
50|$|A DBA can impose maximum quotas on storage per user {{within each}} <b>tablespace.</b>|$|E
5000|$|By default, Oracle Ultra Search {{uses the}} [...] schema and the [...] <b>tablespace.</b>|$|E
5000|$|One or more datafiles form {{a logical}} unit of {{database}} storage called a <b>tablespace.</b>|$|E
5000|$|In Oracle version 9 databases, by default, many Oracle LDAP Table Stores use <b>tablespaces</b> {{with names}} {{beginning}} with the [...] (and occasionally [...] ) prefixes. Relevant default schemas used may include [...] (for [...] "Oracle directory server") and [...]|$|R
5000|$|In PostgreSQL, a schema holds {{all objects}} (with the {{exception}} of roles and <b>tablespaces).</b> Schemas effectively act like namespaces, allowing objects {{of the same name}} to co-exist in the same database. By default, newly created databases have a schema called [...] "public", but any additional schemas can be added, and the public schema isn't mandatory.|$|R
40|$|Objectives After {{completing}} this chapter, {{you should}} be able to: • explain how disks work (list their main parts). • evaluate disks, explain performance parameters. • explain and evaluate different RAID configurations. • create and use <b>tablespaces</b> in Oracle. • explain the storage hierarchy and compare the characteristics of different storage media. • explain how buffering (caching) works...|$|R
50|$|Oracle stores data logically in tablespaces and {{physically}} in datafiles {{associated with the}} corresponding <b>tablespace.</b>|$|E
50|$|A <b>tablespace</b> is {{a storage}} {{location}} where the actual data underlying database objects can be kept. It provides {{a layer of}} abstraction between physical and logical data, and serves to allocate storage for all DBMS managed segments. (A database segment is a database object which occupies physical space such as table data and indexes.) Once created, a <b>tablespace</b> {{can be referred to}} by name when creating database segments.|$|E
50|$|Every {{repository}} {{is stored}} in a separate database, except in case of Oracle, where every repository is a different user and <b>tablespace.</b>|$|E
50|$|The Oracle RDBMS stores data logically in {{the form}} of <b>tablespaces</b> and {{physically}} {{in the form}} of data files ("datafiles").Tablespaces can contain various types of memory segments, such as Data Segments, Index Segments, etc. Segments in turn comprise one or more extents. Extents comprise groups of contiguous data blocks. Data blocks form the basic units of data storage.|$|R
5000|$|Another kind of {{data model}} {{describes}} {{how to organize}} data using a database management system or other data management technology. It describes, for example, relational tables and columns or object-oriented classes and attributes. Such a data model is {{sometimes referred to as}} the physical data model, but in the original ANSI three schema architecture, it is called [...] "logical". In that architecture, the physical model describes the storage media (cylinders, tracks, and <b>tablespaces).</b> Ideally, this model is derived from the more conceptual data model described above. It may differ, however, to account for constraints like processing capacity and usage patterns.|$|R
50|$|MIDAWs allow ECKD channel {{programs}} {{to read and}} write to many storage locations using one channel command, which means fewer signals up and down the channel are required to transfer the same amount of data. This reduction is particularly noticeable for Extended Format data sets, accessed through Media Manager. Examples include Extended Format Sequential data sets, Extended Format VSAM data sets and certain types of DB2 <b>tablespaces.</b> While each of these data set organizations have alternatives, each has a distinct set of advantages, whether in the area of performance, space saving (through hardware-assisted data compression), or scalability (by allowing an individual data set to exceed 4 GiB).|$|R
50|$|There is no {{necessary}} {{relationship between}} schemas and tablespaces: a <b>tablespace</b> can contain objects from different schemas, and the objects {{for a single}} schema can reside in different tablespaces.|$|E
50|$|Oracle Corporation {{introduced}} Oracle ConText {{first as}} a software option, then as an Oracle data cartridge (a server-based software module) for text retrieval when it released version 8 of the Oracle database in 1997. It used the default schema CTXSYS and the default <b>tablespace</b> DRSYS.|$|E
5000|$|The Oracle {{database}} <b>tablespace</b> [...] stores OLAPSYS schema [...] {{objects and}} integrates Oracle Database OLAP Option with the Oracle Warehouse Builder (OWB). The CWMLITE name reflects {{the use of}} CWM — the Common Warehouse Metamodel, which Oracle Corporation refers to as [...] "Common Warehouse Metadata".|$|E
40|$|This paper {{describes}} a novel {{design and implementation}} of manipulating structured and unstructured data in the Oracle 8 i database over the web interface using Java Server Pages. A text recognition script is developed to automate the process of piping data from text formats into the various table fields into the Oracle 8 i database. Familiar Internet Explorer 5. 0 or above and Netscape 4. 7 or above are supported to run the web interface and perform Boolean and some other advanced search over the Oracle 8 i database. A three-tier architecture {{is used in the}} web database design. An Oracle 8 i database stores raw data in the <b>tablespaces.</b> The JSP server generates the response by querying the Oracle 8 i database and provides the web server with data in standard HTML formats. The client side tier (web browser) inputs the query and requests the response from the web server...|$|R
40|$|The first {{action that}} most {{responsible}} DBAs undertake after creating their database {{is to develop}} and implement procedures for regular database backups. In the event that some type of failure damages the database, the DBA will have the necessary information to restore normal operations and recover most or all of the data that was lost. As changes are made to the database structure [...] addition of <b>tablespaces</b> and datafiles, movement of datafiles from one disk to another, etc. [...] the backup routines must be modified accordingly. While manually keeping the backup synchronized with changes in database structure is acceptable for relatively small and static databases, use of automation to guarantee accuracy becomes desirable as the database becomes larger and modifications more frequent. Furthermore, how many DBAs are thoroughly prepared to USE their backups, should recovery be necessary? Recovery occurs infrequently, and the steps needed to implement recovery vary greatly, {{depending on the type of}} backup information available, the type of damage that occurred, and the expertise of the DBA. That expertise can be greatly enhanced by preparation, and such preparation can also serve to institutionalize that knowledge, in the event the DBA is unavailable when a failure occurs...|$|R
40|$|Oracle’s {{implementation}} of indexes {{works very well}} and is quite clever, improving on the basic designs set down decades ago. There {{seems to be an}} impression that they don’t work very well or they need constant maintenance, and that is just not true. For certain, they are not a panacea for all performance problems, as there are indeed situations where the use of indexes will actually result in poorer performance. The {{purpose of this paper is}} to help you anticipate and correctly diagnose situations where indexes are (or are not) working to the benefit of application performance, and will describe several situations where indexes are not appropriate or are ineffective. Please be aware that Oracle does not leave us stranded in bad situations. For each of the conditions where a problem can exist, Oracle usually has developed an alternative to help. What’s more, there are unambiguous methods to detect the problems so you can apply these alternatives. There are a fair number of myths about indexes in popular circulation, some of which include: • Over time, indexes tend to become “unbalanced”, requiring that they be rebuilt on a regular basis for optimal performance • Indexes supporting monotonically-ascending data values (i. e. sequences and timestamps) tend to deteriorate over time, requiring that they be rebuilt on a regular basis for optimal performance • One of the reasons for separating tables and indexes to separate <b>tablespaces</b> is to permit I/O to each to be processed i...|$|R
50|$|While it {{is common}} for tablespaces to store their data in a {{filesystem}} file, a single file must be part of a single <b>tablespace.</b> Some database management systems allow tablespaces to be configured directly over operating-system device entries, called raw devices, providing better performance by avoiding the OS filesystem overheads.|$|E
50|$|No {{standard}} defines how {{to create}} indexes, because the ISO SQL Standard does not cover physical aspects. Indexes {{are one of the}} physical parts of database conception among others like storage (<b>tablespace</b> or filegroups). RDBMS vendors all give a CREATE INDEX syntax with some specific options that depend on their software's capabilities.|$|E
50|$|Tablespaces specify {{only the}} {{database}} storage locations, not the logical database structure, or database schema. For instance, different {{objects in the}} same schema may have different underlying tablespaces. Similarly, a <b>tablespace</b> may service segments {{for more than one}} schema. Sometimes {{it can be used to}} specify schema so as to form a bond between logical and physical data.|$|E
40|$|Event log {{messages}} are currently the only genuine interface through which computer systems administrators can effectively monitor their systems and assemble a mental perception of system state. The popularisation of the Internet {{and the accompanying}} meteoric growth of business-critical systems has resulted in an overwhelming volume of event log messages, channeled through mechanisms whose designers could not have envisaged {{the scale of the}} problem. Messages regarding intrusion detection, hardware status, operating system status changes, database <b>tablespaces,</b> and so on, are being produced at the rate of many gigabytes per day for a significant computing environment. Filtering technologies {{have not been able to}} keep up. Most messages go unnoticed; no filtering whatsoever is performed on them, at least in part due to the difficulty of implementing and maintaining an effective filtering solution. The most commonly-deployed filtering alternatives rely on regular expressions to match pre-defi ned strings, with 100 % accuracy, which can then become ineffective as the code base for the software producing the messages 'drifts' away from those strings. The exactness requirement means all possible failure scenarios must be accurately anticipated and their events catered for with regular expressions, in order to make full use of this technique. Alternatives to regular expressions remain largely academic. Data mining, automated corpus construction, and neural networks, to name the highest-profi le ones, only produce probabilistic results and are either difficult or impossible to alter in any deterministic way. Policies are therefore not supported under these alternatives. This thesis explores a new architecture which utilises rich metadata in order to avoid the burden of message interpretation. The metadata itself is based on an intention to improve end-to-end communication and reduce ambiguity. A simple yet effective filtering scheme is also presented which fi lters log messages through a short and easily-customisable set of rules. With such an architecture, it is envisaged that systems administrators could signi ficantly improve their awareness of their systems while avoiding many of the false-positives and -negatives which plague today's fi ltering solutions...|$|R
50|$|Schema objects do {{not have}} a {{one-to-one}} correspondence to physical files on disk that store their information. However, Oracle databases store schema objects logically within a <b>tablespace</b> of the database. The data of each object is physically contained in {{one or more of the}} tablespace's datafiles. For some objects (such as tables, indexes, and clusters) a database administrator can specify how much disk space the Oracle RDBMS allocates for the object within the tablespace's datafiles.|$|E
50|$|Oracle {{requires}} the Oracle Advanced Security option for Oracle 10g and 11g to enable TDE. Oracle TDE addresses encryption requirements associated with {{public and private}} privacy and security mandates such as PCI and California SB 1386. Oracle Advanced Security TDE column encryption was introduced in Oracle Database 10g Release 2. Oracle Advanced Security TDE <b>tablespace</b> encryption and support for Hardware Security Modules (HSMs) were introduced with Oracle Database 11gR1. Keys for TDE {{can be stored in}} an HSM to manage keys across servers, protect keys with hardware, and introduce a separation of duties.|$|E
5000|$|The MySQL Federated storage {{engine for}} the MySQL {{relational}} {{database management system}} is a storage engine which allows a user to create a table that is a local representation of a foreign (remote) table. It utilizes the MySQL client library API as a data transport, treating the remote data source the same way other storage engines treat local data sources whether they be MYD files (MyISAM), memory (Cluster, Heap), or <b>tablespace</b> (InnoDB). Each Federated table that is defined there is one [...]frm (data definition file containing information such as the URL of the data source). The actual data can exist on a local or remote MySQL instance.|$|E
5000|$|If a {{database}} crashes, {{the recovery process}} has to apply all transactions, both uncommitted as well as committed, to the data-files on disk, using {{the information in the}} redo log files. Oracle must re-do all redo-log transactions that have both a [...] and a [...] entry (roll forward), and it must undo all transactions that have a [...] entry but no [...] entry (roll back). (Re-doing a transaction in this context simply means applying the information in the redo log files to the database; the system does not re-run the transaction itself.) The system thus re-creates committed transactions by applying the “after image” records in the redo log files to the database, and undoes incomplete transactions by using the [...] "before image" [...] records in the undo <b>tablespace.</b>|$|E
5000|$|K: Kernel KA: Kernel Access KC: Kernel Cache KCB: Kernel Cache Buffer KCBW: Kernel Cache Buffer Wait KCC: Kernel Cache Control file KCCB: Kernel Cache Control file Backup KCCCF: Kernel Cache Copy Flash {{recovery}} area KCCDC: Kernel cache Control file Copy KCP: Kernel Cache transPortable <b>tablespace</b> KCR: Kernel Cache Redo KCT: Kernel Cache insTance KD: Kernel Data KG: Kernel Generic KGL: Kernel Generic library cache KGLJ: Kernel Generic library cache Java KJ: Kernel Locking KK: Kernel Compilation KQ: Kernel Query KS: Kernel Service(s) KSB: Kernel Service Background KSM: Kernel Service Memory KSR: Kernel Service Reliable message KSU: Kernel Service User KSUSE: Kernel Service User SEssion KSUSECON: Kernel Service User SEssion CONnection KSUSEH: Kernel Service User SEssion History KT: Kernel Transaction(s) KTU: Kernel Transaction Undo KX: Kernel Execution KXS: Kernel eXecution Sql KZ: Kernel Security K2: Kernel Distributed Transactions ...|$|E
50|$|Officially {{released}} in March 2002, the Windows version of Navicat for MySQL {{became the first}} product offered to the public by PremiumSoft. Subsequently, the company released two additional versions of Navicat for MySQL on the Mac OS X and Linux operating system in June and October 2003 respectively. In November 2013, added the support of MariaDB. PremiumSoft continued to expand their Navicat series by releasing Navicat for PostgreSQL for Windows in October 2005 and then for Mac OS X in June 2006. The Linux version of Navicat for PostgreSQL would not be released until 3 years later in August 2009. In August 2008 Navicat decided to further continue their product line and branch out into the Oracle community, creating Navicat for Oracle for Windows and Mac. In August of the following year they followed up with a version for the Linux Platform. The Oracle version of Navicat supports most of the latest Oracle objects features including Directory, <b>Tablespace,</b> Synonym, Materialized View, Trigger, Sequence, and Type, etc. Navicat for SQLite was released for Windows and Mac OS X simultaneously in April 2009, and the Linux version soon followed two months later in June of the same year. In April 2010, Navicat Premium began including Navicat for SQLite starting from version 9 to expand the usability of Navicat Premium. Navicat for SQL Server was {{released in}} November 2010 for the Windows platform and Mac OS X. Also at the release, the SQL server version {{was included in the}} Premium version of Navicat. In January 2011, support for SQL Azure was added. MariaDB is currently the newest addition to the list of database Navicat supports. The new line of product, called Navicat for MariaDB, was released in November 2013 for the Windows, Mac OS X and Linux. It provides a native environment for MariaDB database management and supports the extra features like new storage engines, microsecond, virtual columns. Also at the release, the MariaDB version was included in both Navicat Premium and Navicat for MySQL.|$|E
40|$|This paper {{describes}} a prototype active <b>tablespace</b> archive {{that was created}} using standard relational database data management capabilities of IBM’s DB 2 Universal Database (UDB) and the hierarchical storage capabilities of IBM’s High Performance Storage System (HPSS). In the prototype, DB 2 UDB and HPSS are linked using the capability of UDB to use a standard UNIX/Posix file for table space {{and the ability of}} HPSS to present a standard UNIX/Posix file system interface for both disk-resident and tape-resident data through its Linux Virtual File System (VFS) feature. This integration allows the current data and the active <b>tablespace</b> archive to be accessed with one set of semantics and, through federation, would allow them {{to be seen as a}} single data source. 1...|$|E
40|$|This {{paper will}} help the reader {{configure}} a very large Oracle Server database (VLDB) for high per-formance and high availability with low maintenance. It describes decisions about database block size, RAID technology and raw devices, redo log files, <b>tablespace</b> partitioning, storage parameters, and rollback segments. This paper explores the tech-nologies and trade-off constraints associated with these issues and presents technically detailed meth-ods for optimizing a configuration within thes...|$|E
