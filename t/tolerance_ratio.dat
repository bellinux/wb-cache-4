16|59|Public
40|$|In this article, {{you will}} be exposed to a new method using both DEA and the methods of AHP, amethod that aims to {{evaluate}} the overall performance of a company involving suppliers in the production ofcertain goods. DEA method is used weightings trapezoidal fuzzy numbers. A bias <b>tolerance</b> <b>ratio</b> (BTR) isintroduced to represent a range of acceptable weights...|$|E
40|$|Abstract − In this paper, a task-specific {{measuring}} capability criterion is described, {{applicable to}} select or validate measurement systems that provide data {{to set the}} process aim, when the techniques known as “sequence of values ” or “difference chart ” are used. The criterion {{is based on the}} estimation of the “uncertainty of the process mean”, which characterizes the dispersion of the values that could reasonably be attributed to the process mean after the setting procedure. The proposed criterion is compared with the discrimination ratio and with the uncertainty per <b>tolerance</b> <b>ratio,</b> showing that the last one fails to predict the measuring capability for aim-setting operations...|$|E
40|$|Extraction of {{meaningful}} information by using artificial neural networks, where {{the focus is}} upon developing new insights for sports performance and supporting decision making, is crucial to gain success. The aim {{of this article is}} to create a theoretical framework and structurally connect the sports and multi-layer artificial neural network domains through: (a) describing sports as a complex socio-technical system; (b) identification of pre-processing subsystem for classification; (c) feature selection by using data-driven valued <b>tolerance</b> <b>ratio</b> method; (d) design predictive system model of sports performance using a backpropagation neural network. This would allow identifying, classifying, and forecasting performance levels for an enlarged data set...|$|E
40|$|Electrostatically figured {{membrane}} reflectors (EFMR) are described. Static {{and dynamic}} models were developed and verified. The models {{were used to}} develop control systems capable of stabilizing EFMR instabilities and providing EFMR disturbance rejection. Expected reflector figure diameter to surface <b>tolerance</b> <b>ratios</b> are given...|$|R
40|$|Stage-dependent {{dichlorvos}} and propoxur tolerance {{in a field}} {{population of}} the German cockroach, Blattella germanica Linnaeus (Blatodea: Blattellidae), was investigated in the laboratory using a topical application bioassay. The results showed the 6 week-old nymphs were more tolerant to dichlorvos and propoxur than the other ages tested. LD 50 values of dichlorvos and propoxur for the 6 week-old nymphs were 2. 003 µµg per insect and 5. 296 µµg per insect, respectively. <b>Tolerance</b> <b>ratios</b> of 18. 55 -fold and 4. 98 -fold for LD 50 were obtained from 6 -week-old nymphs compared to 4 week-old nymphs. The specific activity of acetylcholinesterase (AChE) from 1 week-old nymphs was the highest among all tested developmental stages of nymphs and adult males and females. The specific activity of AChE decreased significantly with increasing age. The sensitivity of AChE to dichlorvos was the highest with a ki value of 3. 12 ×× 104 mol- 1 min- 1 in the last nymphal stage of B. germanica (about 6 weeks-old). The AChE from 4 week-old nymphs was the most sensitive to propoxur, with the highest ki value being 2. 63 ×× 105 mol- 1 min- 1. These {{results indicated that the}} different developmental stages and sexes of B. germanica affected the inhibition of AChE by dichlorvos and propoxur...|$|R
40|$|The article {{describes}} issues of operational inspection reliability assurance. Reliability is the mast important property of inspection. Reliability {{is defined as}} the probability of correct decision making during the inspection. This probability depends on the measurement error and <b>tolerance</b> range <b>ratio,</b> position of acceptance limits and technological process stability. Existing approaches to measurement tolerance design, which are also used in ГОСТ 8. 051 and РД 50 - 98 - 86, do not take into consideration the influence of technological process stability on inspection reliability. Thus, these approaches are to be reconsidered. </p...|$|R
40|$|Abstract. This article {{introduces}} {{the principle of}} mathematical statistics such as R&R (Repeatability and Reproducibility), variation ratio (%P/TV), <b>tolerance</b> <b>ratio</b> (% P/T) and number of distinct category in the measurement system. The article takes infrared moisture analyser the InfraLab 710 e-Series as a measurement system and uses hierarchical nested analysis method to perform destructive experimental moisture equilibrium. Taking moisture in shredded leaves during tobacco primary process as example, we setup up three conditions of cut tobacco leaves moisture at 11 %, 15 % and 20 %, and analyse the results generated by MINITAB tools to identify the source of fluctuations, the extent and root cause in the measurement process which {{will be used to}} evaluate the measuring performance of infrared moisture meter. Then the analysis will be carried out to see if the measurement system meets the criteria of acceptable requirements, which will be a reliable tool for applications of cut tobacco leaves moisture measurement...|$|E
40|$|Image Classification {{is one of}} {{the major}} {{applications}} of Image processing to place all the related images in a separate group. In some Recognition and Identification applications, Image classification is used to reduce the size of processing dataset. In this present work, the image classification is used to perform the digital character recognition. In this work, A Soft computing technique called Art Network is been implemented through the classification process. The work is divided into two main stages named Training and Recognition process. During the Training Phase, the input imageset is processed and divided in N Classes based upon the <b>tolerance</b> <b>ratio.</b> The Eligibility criterion to specific class is decided by Feature analysis over the image. In second stage, the feature extraction over the input image is performed and based on featured value; the related class is been identified. Now one-to-one comparison is performed on that class to identify the class on which comparison is performed. The effectiveness to the work is estimated based on matching ratio...|$|E
40|$|Gauge {{repeatability}} and reproducibility {{studies are}} significant to quality improvement and quality control. The approaches are always applied {{to determine the}} capability of the measurement system. Much of the literature in this field mainly focuses on univariate and multivariate measurement systems. However, the state-of-the-art methods are not appropriate when {{the quality of a}} product is characterized by a profile. Therefore, this paper proposes a method for the measured values which can be characterized by a simple linear profile. In addition, the slopes and intercepts of these profiles often vary due to measurement error. Thus, the simple linear profile gauge studies can be considered as a two-response (slope and intercept) problem. X-values transformation is used to make the slope and intercept of each profile independent. ANOVA is utilized to estimate the variance component of measurement error and other sources of variation. Then, the criteria precision to <b>tolerance</b> <b>ratio</b> and percent R&R are introduced to assess the simple linear profile measurement system capability. Finally, the proposed approach is applied to the spring length and elasticity measurement which demonstrates how to implement the method...|$|E
40|$|The {{development}} of 3 D vertical {{integration in the}} microelectronic industry brings along significant advantages for pixelated semiconductor radiation sensors in cutting-edge scientific experiments at high luminosity particle accelerators and advanced X-ray sources. These applications set very demanding requirements {{on the performance of}} sensors and their readout electronics, in terms of pixel pitch, radiation <b>tolerance,</b> signal-to-noise <b>ratio</b> and capability of handling very high data rates. 3 D vertical integration of two or more layers with sensors and CMOS devices naturally leads the designer towards extending pixel-level processing functionalities and achieving novel structures where each layer is optimized for a specific function. This paper reviews the efforts towards the {{development of}} novel vertically integrated pixel sensors and discusses the challenges that are being tackled to qualify these devices for actual applications...|$|R
40|$|Space-time block codes {{can extend}} the optical {{signal to noise}} <b>ratio</b> <b>tolerance</b> in multiple-input multiple-output optical {{coherent}} spatial division multiplexing transmission systems with respect to single-mode transmission performance. The OSNR tolerance gain is achieved through exploiting the spatial diversity few-mode-fibers offer. An OSNR gain of 3. 2, 4. 1, 4. 9, and 6. 8 dB at the hard-decision forward error correcting limit with respect to single mode fiber back-to-back performance is shown for DP-OPSK, 8, 16, and 32 DP-QAM~ respectively...|$|R
40|$|Leaf area expansion, dry weight, {{and water}} {{relations}} of Phaseolus vulgaris L. and P. acutifolius Gray were compared during a drying cycle {{in the greenhouse}} to understand the characteristics which contribute to the superior drought tolerance of P. acutifolius. Stomates of P. acutifolius closed {{at a much higher}} water potential than those of P. vulgaris, delaying dehydration of leaf tissue. P. acutifolius had a more deeply penetrating root system, which also contributes to its drought <b>tolerance.</b> Root-shoot <b>ratios</b> did not differ between the two species either under well watered or water stressed conditions. Leaf osmotic potential was also similar in the two species, with no apparent osmotic adjustment during water stress. These results indicate that P. acutifolius postpones dehydration and suggest that sensitive stomates and a deeply penetrating root system are characteristics which, if incorporated into cultivated beans, might increase their drought tolerance...|$|R
40|$|We {{introduce}} {{a model of}} percolation induced by disorder, where an initially homogeneous network with links of equal weight is disordered {{by the introduction of}} heterogeneous weights for the links. We consider a pair of nodes i and j to be mutually reachable when the ratio α_ij of length of the optimal path between them before and after the introduction of disorder does not increase beyond a <b>tolerance</b> <b>ratio</b> τ. These conditions reflect practical limitations of reachability better than the usual percolation model, which entirely disregards path length when defining connectivity and, therefore, communication. We find that this model leads to a first order phase transition in both 2 -dimensional lattices and in Erdos-Renyi networks, {{and in the case of}} the latter, the size of the discontinuity implies that the transition is effectively catastrophic, with almost all system pairs undergoing the change from reachable to unreachable. Using the theory of optimal path lengths under disorder, we are able to predict the percolation threshold. For real networks subject to changes while in operation, this model should perform better in predicting functional limits than current percolation models. Comment: 10 pages, 3 figure...|$|E
40|$|Abstract—This paper {{presents}} several {{results on}} some costminimizing path problems in polygonal regions. For {{these types of}} problems, an approach often used to compute approximate optimal paths is to apply a discrete search algorithm to a graph Gɛ constructed from a discretization of the problem; this graph is guaranteed to contain an ɛ-good approximate optimal path, i. e., apathwithacostwithin(1 + ɛ) factor of that of an optimal path, between given source and destination points. Here, ɛ> 0 is the user-defined error <b>tolerance</b> <b>ratio.</b> We introduce a class of piecewise pseudo-Euclidean optimal path problems that includes several non-Euclidean optimal path problems previously studied and show that the BUSHWHACK algorithm, which was formerly designed for the weighted region optimal path problem, can be generalized to solve any optimal path problem of this class. We also introduce an empirical method called the adaptive discretization method that improves {{the performance of the}} approximation algorithms by placing discretization points densely only in areas that may contain optimal paths. It proceeds in multiple iterations, and in each iteration, it varies the approximation parameters and fine tunes the discretization. Index Terms—Computational geometry, mobile robots, motion planning, optimization...|$|E
40|$|This paper {{explores the}} {{differences}} in observed risk propensity among petroleum firms {{and their impact on}} firm performance. In this work, we (1) develop a decision theoretic model which measures a firm's risk propensity {{in the form of an}} "implied" utility function; (2) investigate changes in corporate risk propensity with respect to changes in firm size; and (3) examine the relationships between firms' risk propensities and alternative dimensions of economic performance, including ex post risk and return measures. We also develop a new risk propensity measure, the Risk <b>Tolerance</b> <b>Ratio</b> (RTR), which controls for firm size and allows firms to be differentiated in terms of relative risk propensity. The motivation for this work is managerial concerns regarding appropriate risk-taking behavior and the effect of risky choice on firm performance. This methodology has importance business strategy implications in that we are able to make strong inferences about causal relationships between ex ante risk-taking and performance. Our findings are compelling in that corporate risk propensity seems to matter, and that decisions about corporate risk policy have a significant impact on the petroleum firm's economic performance. risk management, decision analysis, exponential utility, business strategy, firm performance, certainty equivalents, risk tolerance...|$|E
40|$|Microfluidics is {{a growing}} {{technology}} {{in the field of}} medical diagnostics. Daktari Diagnostics is a startup located in Cambridge, MA that seeks to introduce a lab-on-a-chip device for monitoring HIV in patients. This work investigates hot embossing as a prototyping process for Daktari's microfluidic device. A hot embossing system was designed and built for the purpose of prototyping a critical feature of their microfluidic network. The machine was designed for an embossing area of 6 square inches, and was found to have a maximum positional repeatability of 43 microns. The purpose of this research was to find the capabilities of the system used for hot embossing and optimize the process for maximizing the performance. The system was validated for alignment, measurement procedure and the process control. The measuring procedure was analyzed to find the best possible metric which could serve as a response variable for the performance of the process. The 'Fill ratio' of height and width were chosen as metrics for the experimental design which had precision to <b>tolerance</b> <b>ratios</b> of 0. 44 and 0. 33 respectively. An analysis of the factors affecting the hot embossing process was carried out using experimental design and the optimal parameters were identified. The tool temperature, pressure and the holding time were the most significant in that order. The Cp for the process with respect to the height fill was found to be 4. 71 and for the width fill ratio was found to be 1. 97. Using the optimal parameters the process variation of six standard deviations was found to lie within the specification limits. Hot embossing was recommended as a possible method for rapid prototyping of the assay channel and the complete cartridge at Daktari Diagnostics. by Viren Sunil Kalsekar. Thesis: M. Eng. in Manufacturing, Massachusetts Institute of Technology, Department of Mechanical Engineering, 2013. Cataloged from PDF version of thesis. Includes bibliographical references (pages 138 - 140) ...|$|R
40|$|Chromium intake may {{increase}} insulin sensitivity, glucose <b>tolerance,</b> and the <b>ratio</b> of high density lipoprotein cholesterol to low density lipoprotein cholesterol. However, the epidemiologic {{evidence on the}} association between chromium and cardiovascular disease is very limited. To determine whether low toenail chromium concentrations were associated with risk of nonfatal myocardial infarction, the authors conducted an incident, population-based, case-control study in eight European countries and Israel in 1991 – 1992. Cases (n 684) were men with a first diagnosis of myocardial infarction recruited from the coronary units of participating hospitals. Controls (n 724...|$|R
40|$|Adaptive time-stepping methods {{based on}} the Monte Carlo Euler method for weak {{approximation}} of Itô stochastic differential equations are developed. The main result is new expansions of the computational error, with computable leading-order term in a posteriori form, based on stochastic flows and discrete dual backward problems. The expansions lead to efficient and accurate computation of error estimates. Adaptive algorithms for either stochastic time steps or deterministic time steps are described. Numerical examples illustrate when stochastic and deterministic adaptive time steps are superior to constant time steps and when adaptive stochastic steps are superior to adaptive deterministic steps. Stochastic time steps use Brownian bridges and require more work for a given number of time steps. Deterministic time steps may yield more time steps but require less work; for example, {{in the limit of}} vanishing error <b>tolerance,</b> the <b>ratio</b> of the computational error and its computable estimate tends to 1 with negligible additional work to determine the adaptive deterministic time steps...|$|R
40|$|This paper {{proposes a}} {{tolerance}} bound approach for determining sample sizes. With this new methodology {{we begin to}} think of sample size {{in the context of}} uncertainty exceeding margin. As the sample size decreases the uncertainty in the estimate of margin increases. This can be problematic when the margin is small and only a few units are available for testing. In this case there may be a true underlying positive margin to requirements but the uncertainty may be too large to conclude we have sufficient margin to those requirements {{with a high level of}} statistical confidence. Therefore, we provide a methodology for choosing a sample size large enough such that an estimated QMU uncertainty based on the tolerance bound approach will be smaller than the estimated margin (assuming there is positive margin). This ensures that the estimated tolerance bound will be within performance requirements and the <b>tolerance</b> <b>ratio</b> will be greater than one, supporting a conclusion that we have sufficient margin to the performance requirements. In addition, this paper explores the relationship between margin, uncertainty, and sample size and provides an approach and recommendations for quantifying risk when sample sizes are limited...|$|E
40|$|The {{response}} of onion tissue cultures to salinity stress was investigated. Callus initiated from aseptic seedlings {{was exposed to}} different levles of salt mixture. Fresh weight and growth value of callus inoculms were decreased as salt mixture increased in culture medium. However, dry weight and dry matter increased as salt level increased up to 4000 ppm and then decreased. Total proteins of callus enhanced as salt mixture increased in culture medium. For selection under salt stress, regenerated shoot buds derived from tolerant callus cultures {{were exposed to the}} different levels of salts mixture. The number of proliferated shoot buds and their fresh weight and growth value were depressed upon increasing of salts in medium. The best results of salt <b>tolerance</b> <b>ratio</b> were reached at 2000 ppm salts. Although protein content took similar trend of callus, it was relatively higher than in callus cultures at the same salt levels. Esterase patterns showed new band with the tolersnce lines. This band had different mobility and more intensity with the shoot bud lines exposed to 2000 ppm of salt mixture. The tolerant shoot buds were in vitro rooted and successfully adapted to free-living conditions...|$|E
40|$|The {{present study}} {{highlights}} the practical {{application of a}} Piper-based botanical insecticide for controlling insect pests {{of the home and}} garden in urban areas in eastern Canada and northeastern North America. Biopesticides, including botanicals, can offer a safe and effective alternative to conventional insecticides for controlling major insect pests within an IPM program. Secondary compounds from the Piperaceae family, specifically the abundant isobutyl amides and lignans, have shown promise for insecticidal applications. A method for extraction and HPLC-MS analysis of Piper spp. was developed in order to allow quick and accurate measure of piperamide levels in P. nigrum, P. tuberculatum, West African Guinea pepper, P. guineense Schum and Thonn, and in less recognized species from Central America. Extraction of leaf and peppercorn material with 50 : 50 ethyl acetate and water provided a greater than 80 % recovery of spiked piperine. HPLC analysis using a binary gradient of acetonitrile and water provided a clean separation of the major amide peaks between 5 and 12 min. The use of APCI-MS improved the detection limit 10 fold below the 2 -ng limit of the HPLC-DAD method. Extracts from P. nigrum, P. guineense and P. tuberculatum were tested for efficacy against insects from five orders. Among the insect pests tested, the most sensitive species were, in order of increasing lethal concentration: Eastern tent caterpillar, Malacosoma americanum F. < European pine sawfly larvae, Neodiprion sertifer Geoffroy < spindle ermine moth larvae, Yponomeuta cagnagella Hubner < Viburnum leaf beetle larvae, Pyrrhalta viburni Paykull < stripped cucumber beetle adult, Acalymma vittatum Fabrcius < Colorado potato beetle adult, Leptinotarsa decemlineata (Say) < Japanese beetle adult, Popillia japonica Newman < hairy chinch bug, Blissus leucopterus hirtus Montandon. Greenhouse trials revealed that the pepper formulations also had a repellent activity thus protecting plant leaves from: (1) herbivory by lily leaf beetles, Lilioceris lilii (Scopoli) adults and larvae, and striped cucumber beetle, Acalymma vittatum F. adults and (2) oviposition by European corn borer, Ostrina nubilalis (Hubner). When an insecticide resistant strain of potato beetle larvae was tested with the P. tuberculatum extract, there was less than a two fold <b>tolerance</b> <b>ratio</b> compared to the 22 -fold <b>tolerance</b> <b>ratio</b> to cypermethrin, a pyrethroid. An in vitro polysubstrate monoxygenase (PSMO) enzyme assay, using the substrate methoxyresorufin O-demethylation (MROD), determined that piperine, is responsible for inhibition of that specific enzyme. A subsequent toxicokinetic study determined that piperine is quickly eliminated from the exoskeleton (t 1 / 2 = 16. 5 h) and hemolymph (t 1 / 2 = 12 h) of the adult American cockroach Periplaneta americana L. after a topical application. (Abstract shortened by UMI. ...|$|E
40|$|GTE Products Corporation (Towanda) has {{developed}} a compact cross flow recuperator for high temperature industrial heat recovery applications. During {{the development of the}} ceramic recuperator, GTE interfaced with major combustion equipment manufacturers to ascertain the optimum types of combustion control that can be used with preheated air. Preheated air and its effect (increased pressure from expanded gases) on static pressure complicate the control process. Standard practices that dictate precision stoichiometric control over wide ranges of thermal inputs will be outlined. System performance with ambient air and preheated air will be discussed as will the effect of stoichiometry for each system. Mechanically linked, flow balanced, cross connected and electronic ratio controllers are to be explained. A method to perform a cost performance analysis for each system will be detailed. Basic combustion control principles and the effect of preheated air on optimization and control will be shown. Sophisticated controls are only necessary because of process load demands, and preheated air (from recuperators) allows for greater <b>tolerances</b> of <b>ratio</b> variations over controlled turndown spans...|$|R
40|$|Active Electrodes (AE), i. e. {{electrodes}} {{with built-in}} readout circuitry, {{are increasingly being}} implemented in wearable healthcare and lifestyle applications due to AE’s robustness to environmental interference. An AE locally amplifies and buffers μV-level EEG signals before driving any cabling. The low output impedance of an AE mitigates cable motion artifacts thus enabling the use of high-impedance dry electrodes for greater user comfort. However, developing a wearable EEG system, with medical grade signal quality on noise, electrode offset <b>tolerance,</b> common-mode rejection <b>ratio</b> (CMRR), input impedance and power dissipation, remains a challenging task. This paper reviews state-of-the-art bio-amplifier architectures and low-power analog circuits design techniques intended for wearable EEG acquisition, with a special focus on AE system interfaced with dry electrodes...|$|R
40|$|OBJECTIVE — The aim of {{this study}} was to {{investigate}} associations of adiponectin, leptin, C-reactive protein (CRP), interleukin (IL) - 6, and serum amyloid A (SAA), individually or in combinations, with risk of incident type 2 diabetes in a Aboriginal Canadian population. RESEARCHDESIGNANDMETHODS — Of the 606 Sandy Lake Health and Diabetes Project cohort subjects who were free of diabetes at baseline, 540 (89. 1 %) participated in 10 -year follow-up assessments. Concentrations of fasting adiponectin, leptin, CRP, IL- 6, SAA, and co-variates were measured at baseline. Fasting glucose and a 75 -g oral glucose tolerance test were obtained at baseline and follow-up to determine incident type 2 diabetes, defined as clinically diagnosed type 2 diabetes or as fasting plasma glucose 7. 0 mmol/l or 2 -h postload plasma glucose 11. 1 mmol/l at follow-up. RESULTS — Low adiponectin, high leptin, and low adiponectin-to-leptin ratio at baseline were associated with increased risk of incident type 2 diabetes after adjustment for age, sex, triglycerides, HDL cholesterol, hypertension, and impaired glucose <b>tolerance</b> (odds <b>ratio</b> 0. 63 [95 % CI 0. 48 – 0. 83], 1. 50 [1. 02 – 2. 21], and 0. 54 [0. 37 – 0. 77], respectively). When the models were additionally adjusted for waist circumference or BMI, however, only low adiponecti...|$|R
40|$|A 5 mm {{segment of}} the rat sciatic nerve was treated at 38 or 43 degrees C for 30 min using a brass thermode. This {{pretreatment}} {{was followed by a}} test heat treatment at 45 degrees C. Different intervals between the pretreatment and test treatment were studied. The effect of fractionated hyperthermia on the motor function of rat sciatic nerve was evaluated using a functional assay, the toe-spreading test. Both pretreatments led to thermal resistance of the nerve, which was maximal 24 h after the pretreatment. Thermal resistance, induced at 38 degrees C, did not show any decay over a period of 6 weeks. Thermal resistance, induced at 43 degrees C, decayed slowly, but after a 6 -week interval between priming and test heat treatment thermal resistance was still observed. As the resistance induced by a mild heat pretreatment is transient, we considered this to be thermotolerance. We accounted for the thermal resistance induced by the 38 degrees C pretreatment in the calculation of the thermal <b>tolerance</b> <b>ratio</b> (TTR) after mild heat treatment at 43 degrees C. Maximal thermal tolerance was observed 24 h after mild heat with a TTR of 3. 4 +/- 0. 6. The TTR after a 6 -week interval had declined to 1. 4 +/- 0. ...|$|E
40|$|The {{aim of this}} {{research}} is to compare various variance component estimations procedures with using signal noise ratio and error <b>tolerance</b> <b>ratio</b> which is offered with generalizabiity and Phi coefficients in non-normal distrubitions (Brennan, 2001; Kane, 1999). This research compares variance components estimations with using ANOVA and bootstrap procedures in non-normal disturbitions in one facet design G studies. Data were gathered with using two seperate procedures (a) data simulation and (b) sampling simulation. In data simulation part, it’s been simulated a non-normal dichotomous data set which fits to unidimensional personitem matrix 60 x 5 which fits to b x m design. All the simulations replicated 25 times. In sampling simulation sections datas, gathered from data simulation sections has been bootstrapped 1000 times according to the each facet. Standart errors, variance components, relative and absolute error are estimated according to the each facets with using ANOVA and bootstrap procedures. The results also show that in non-normal dichotomously scored datas best signal-noise ratio has estimated in boot b procedure, and best error-tolerance ratio has been estimated in boot m procedure. Thus, boot m procedures gives more valid estimations and boot bprocedure gives more reliable and precise estimations of universe scores in G studies rather than other procedure...|$|E
40|$|Microfluidics is {{a growing}} {{technology}} {{in the arena of}} medical diagnostics. Daktari Diagnostics is a startup located in Cambridge, MA that seeks to introduce a lab-on-a-chip device for monitoring HIV in patients. This work investigates hot embossing as a prototyping process for Daktari's microfluidic device. A hot embossing machine was designed and built for the purpose of prototyping a critical feature of their microfluidic network. The machine was designed for an embossing area of 6 square inches, and was found to have a maximum positional repeatability of 43 microns. The microfluidic feature that was prototyped is known as the assay channel. This feature is a high aspect ratio channel with a depth of 50 microns and width of 4 mm. A 10 - micron ridge is adjacent to the channel. Several measurement methods were evaluated with gage repeatability and reproducibility studies to determine the methods most capable of quantifying the quality of embossed parts. The end determination was that quality of parts should be defined by the completeness of formation of the ridge lining the channel. The height and width measurements of the ridge were used as quality metrics. The precision to <b>tolerance</b> <b>ratio</b> (P/T ratio) of the measurement method used for finding ridge height was found to be 0. 44 and the P/T ratio of the ridge width measurement method was found to be 0. 33. by Nicholas Ragosta. Thesis: M. Eng. in Manufacturing, Massachusetts Institute of Technology, Department of Mechanical Engineering, 2013. Cataloged from PDF version of thesis. Includes bibliographical references (pages 122 - 126) ...|$|E
40|$|Lymph nodes (LNs) are {{integral}} {{sites for the}} generation of immune tolerance, migration of CD 4 + T cells, and induction of Tregs. Despite the importance of LNs in regulation of inflammatory responses, the LN-specific factors that regulate T cell migration and the precise LN structural domains in which differentiation occurs remain undefined. Using intravital and fluorescent microscopy, we found that alloreactive T cells traffic distinctly into the tolerant LN and colocalize in exclusive regions with alloantigen-presenting cells, a process required for Treg induction. Extracellular matrix proteins, {{including those of the}} laminin family, formed regions within the LN that were permissive for colocalization of alloantigen-presenting cells, alloreactive T cells, and Tregs. We identified unique expression patterns of laminin proteins in high endothelial venule basement membranes and the cortical ridge that correlated with alloantigen-specific immunity or immune <b>tolerance.</b> The <b>ratio</b> of laminin α 4 to laminin α 5 was greater in domains within tolerant LNs, compared with immune LNs, and blocking laminin α 4 function or inducing laminin α 5 overexpression disrupted T cell and DC localization and transmigration through tolerant LNs. Furthermore, reducing α 4 laminin circumvented tolerance induction and induced cardiac allograft inflammation and rejection in murine models. This work identifies laminins as potential targets for immune modulation...|$|R
40|$|Forty five {{subjects}} rated soup samples varying in salt {{concentration on}} {{three types of}} ratings, intensity, hedonic and relative-to-ideal. Estimates of the most preferred concentration for individual subjects from the hedonic and relative-to-ideal ratings correlated at r = 0. 76 (P < 0. 001). The estimates were not found to differ by t-test. The slope of the relative-to-ideal function correlated with the intensity slope at r = 0. 31 (P < 0. 05) but was more {{closely associated with the}} slope of a function derived from unfolding the hedonic ratings about the break point for individual subjects. These relationships were confirmed comparing the Weber ratios derived from the intensity ratings and <b>tolerance</b> discrimination <b>ratios</b> derived from the relative-to-ideal and unfolded hedonic ratings. Group data showed good agreement between intensity and relative-to-ideal ratings, since both are linearly related to the logarithm of concentration. These results suggest that relative-to-ideal ratings provide a more informative measure of most preferred concentration similar to that derived from hedonic ratings. The slope of the relative-to-ideal function reflects, in part, how concerned the subject is about deviations from ideal rather than being simply ratings of intensity in relation to the person's ideal. © 1989 Longman Group UK Limited...|$|R
40|$|The {{choice of}} {{antimicrobial}} therapy {{for the treatment}} of bacteremia is often empirical and based on the knowledge of antibiotic susceptibility profiles of the most common bacteria causing such infections. It therefore is crucial to survey the susceptibility of bacteria causing sepsis. This study examines the susceptibility profiles of 941 gram-negative bacteria, isolated from septic patients in 10 Canadian hospitals, to 28 antimicrobial agents. Among the isolates, 30 different species were represented; Escherichia coli dominated, representing 52. 5 % of isolates. More than 50 % of all bacteria were resistant to ampicillin. Only 67 % of the E. coli isolates were susceptible to ampicillin, while 30 % of all strains were resistant to ticarcillin. Of the cephalosporins, ceftazi-dime and cefoperazonejsulbactam were the agents to which isolates were the most susceptible (90 %). Only 51 % of the E. coli strains were susceptible to cephalothin, while 91 % were still susceptible to cefazolin. A total of 93 % and 98 % ofthe strains were susceptible to aztreonam and imipenem, respectively. Aminoglycosides were highly active against most isolates, in general in the following order: netilmicin> tobramycin> gentamicin> amikacin. Tobramycin was the most active against Pseudomonas aeruginosa. Nearly all isolates were susceptible to the quino-lones. <b>Tolerance</b> (MBCjMIC <b>ratio,</b> ~ 32) was rarely observed. This survey ofthe susceptibility o...|$|R
40|$|Miniaturization {{towards the}} {{nanoscale}} {{is now the}} trend of technological developments in products and devices for mechanical, optical and electronic applications. Normally, good engineering functional components should have their form and surface tolerances less than one hundredth or even one thousandth of their feature sizes. However the structure fabricated by current nanotechnology can rarely achieve such <b>tolerance</b> <b>ratio</b> in a controllable way. Because of this, the kinematical and dynamical performances of these nano-structured mechanisms are far from ideal. Consequently, this research aims to identify the limit of micro and nano material removal under machining conditions. There are still many fundamental questions which {{need to be addressed}} in nanometric machining. Some of them are the following, name; what are the fundamental mechanisms underlying nanomachining processes? What is the limit of machining? What is the minimum depth of cut and how do you evaluate atomic surface roughness from nanomachining simulations? This study attempts to find some answers to the above questions or to point the direction towards the answers. Nanomachining has been modelled using the Molecular Dynamics (MD) method because it has proved to be an effective tool for the prediction and the analysis of these processes at the nanometre scale. Through this investigation, it is identified that the EAM potential is the most appropriate of the 3 potentials commonly used for the modelling of nanomachining of copper with diamond tool. This is because the EAM potential provides the best description of the metallic bonding in the workpiece, also, the cutting forces variation is smallest; the potential and total energies are most stable for the depth of cut considered. Therefore, the EAM potential should be used, rather than LJ and Morse potentials for the modelling of copper and other fcc metals in MD simulations of nanomachining. For potential pairs; it was observed that the tangential cutting force components are considerably affected by the interatomic potential pair used, but they are not greatly affected by whether the tool is rigid or deformable. The total energy of the system on the other hand is much lower when the tool is non rigid than when it is rigid. Various MD simulations have been carried out. Results of the investigation of the minimum depth cut (MDC) nanomachining show the nano material removal phenomena of rubbing, ploughing and cutting. In a copper material removal simulation, ploughing starts from 0. 2 0. 3 nm and the formation of chips starts to occur from the depth of cut thickness of 1. 5 nm. So it can be suggested that the extreme accuracy attainable or MDC for copper atoms workpiece, machined with extremely sharp diamond tool is around 1. 5 nm to 3 nm. The onset of plasticity for copper atom workpiece machined with extremely sharp diamond tool is around 0. 1 nm 0. 3 nm. In the investigation of the effect of various tool ends on the initiation of the phenomena of rubbing and ploughing; all the tools clearly show the phenomena of rubbing and ploughing in the depth of cut range of 0. 05 to 0. 5 nm. The tool with the pointed end has the lowest average cutting force and the tool with the flat end has the highest average cutting force. It {{is important to note that}} in nanomachining the tool with sharpest end may not necessarily cause the greatest material removal! The different tool ends may be suitable for different machining applications. On the velocity variation in nanomachining simulations, it can be concluded that the interatomic potentials readily affect the simulation results, whereas the use of rigid and non-rigid tools doesn’t show appreciable difference. Also, it was observed that the tangential and the normal cutting force components relatively increase with increase in velocity. The atomic surface roughness evaluation is affected by the choice of the interatomic potentials used for the simulation...|$|E
40|$|The {{susceptibility}} to vancomycin of nine staphylococcal strains responsible for nine episodes of peritonitis in patients on continuous ambulatory peritoneal dialysis {{was correlated with}} outcome of therapy. All strains examined had MIC values indicating sensitivity (MIC. :; 4 &mu;g/ml). Tolerance was observed in one strain of Staphylococcus aureus (MIC = 1 &mu;g/ml., MBC = 64 &mu;g/ml). Time-kill studies using three different media demonstrated this organism's reduced {{susceptibility to}} vancomycin and suggested that testmedium composition may also affect the result. The patient with the tolerant strain, required {{an extended period of}} treatment. A bacterium is said to exhibit <b>tolerance</b> when the <b>ratio</b> between the minimum bactericidal concentration (MBC) and minimum inhibitory concentration (MIC) is 32 or greater (9). Originallyobserved in a laboratory strain of Streptococcus pneumoniae (13), other workers hav...|$|R
40|$|The {{objective}} {{of the study was}} to present the architect, training system consideration and performance of Levenberg-Marquardt back propagation algorithm for manufacturing operation selection that can be associated with STEP-NC file generation. Here STEP-based product data modeling, EXPRESS representation combined with neural network algorithm using feature based design attributes such as dimension <b>ratio,</b> <b>tolerance</b> and surface finish etc. It describes the details of training algorithm steps, training data pattern and performance output of the system in association with object oriented data model in process plan data generation. It gives required criterion for extending the system for machine tools and cutting tools selection with reference to turn-mill process planning requirements. Finally summarizes on importance and methods of binding STEP representation and intelligent Computer Aided Process Planning (CAPP) system development...|$|R
40|$|A {{carrier phase}} {{estimation}} and compensation algorithm using a digital {{phase locked loop}} is proposed which exploits the common-mode impairment from the shared local oscillator at the receiver side in a few-mode fiber transmission system. We verify that the proposed algorithm is more tolerant to phase-mismatches than earlier work. The carrier phase estimation (CPE) scheme is evaluated for a 3 $,times,$ 112 Gbit/s dual polarization {{quadrature phase shift keying}} mode division multiplexed transmission over 80 km including an in-line multimode erbium doped fiber amplifier. The digital signal processing computational complexity is reduced in comparison to a traditional CPE stage. In addition, the proposed scheme is shown to perform similarly with respect to the $ 3. 8 times 10 ^{- 3 }$ forward error correcting limit optical signal to noise <b>ratio</b> <b>tolerance</b> of the traditional CPE scheme...|$|R
40|$|We {{experimentally}} {{verify the}} advantage of employing advanced coding schemes such as space-time coding and 4 dimensional modulation formats to enhance the transmission performance of a 3 -mode transmission system. The performance gain of space-time block codes for extending the optical signal-to-noise <b>ratio</b> <b>tolerance</b> in multiple-input multiple-output optical coherent spatial division multiplexing transmission systems with respect to single-mode transmission performance are evaluated. By exploiting the spatial diversity that few-mode-fibers offer, with respect to single mode fiber back-to-back performance, significant OSNR gains of 3. 2, 4. 1, 4. 9, and 6. 8 dB at the hard-decision forward error correcting limit are demonstrated for DP-QPSK 8, 16 and 32 QAM, respectively. Furthermore, by employing 4 D constellations, 6 × 28 Gbaud 128 set partitioned quadrature amplitude modulation is shown to outperform conventional 8 QAM transmission performance, whilst carrying an additional 0. 5 bit/symbol...|$|R
40|$|Liquid chromatography-tandem mass {{spectrometry}} (LC-MS/MS) {{is one of}} the most widely used techniques for identification (and quantification) of residues and contaminants across a number of different chemical domains. Although the same analytical technique is used, the parameters and criteria for identification vary depending on where in the world the analysis is performed and for what purpose (e. g. determination of pesticides, veterinary drugs, forensic toxicology, sports doping). The rationale for these differences is not clear and in most cases the criteria are essentially based on expert opinions rather than underpinned by experimental data. In the current study, the variability of the two key identification parameters, retention time and ion ratio, was assessed and compared against requirements set out in different legal and guidance documents. The study involved the analysis of 120 pesticides, representing various chemical classes, polarities, molecular weights, and detector response factors, in 21 different fruit and vegetable matrices of varying degrees of complexity. The samples were analysed non-fortified, and fortified at 10, 50 and 200 µgkg(- 1), in five laboratories using different LC-MS/MS instruments and conditions. In total, over 135, 000 extracted-ion chromatograms were manually verified to provide an extensive data set for the assessment. The experimental data do not support relative tolerances for retention time, or different <b>tolerances</b> for ion <b>ratios</b> depending on relative abundance of the two product ions measured. Retention times in today's chromatographic systems are sufficiently stable to justify an absolute tolerance of ± 0. 1 min. Ion ratios are stable as long as sufficient response is obtained for both product ions. Ion ratio deviations are typically within ± 20 % (relative), and within ± 45 % (relative) in case the response of product ions are close to the limit of detection. Ion <b>ratio</b> <b>tolerances</b> up to 50 % did not result in false positives and reduced the false negative rate for pesticides with product ions in the low S/N range t...|$|R
