1|9|Public
50|$|Handle-mounted dead man's {{switches}} {{are also}} used on many hand-held tools and lawn equipment, typically those that rotate or have blades such as saws, drills and lawn mowers. On saws for example, they incorporate a squeeze <b>throttle</b> <b>trigger</b> into the handle. If the user loses grip of the saw, the springs in the <b>throttle</b> <b>trigger</b> will push it {{back out to the}} off or idle setting, stopping the blade from spinning. Some tools go further and have a trigger guard built into the handle, similar to firearm safeties. Only when the user presses in the trigger guard first will it then release its lock on the trigger and allow the trigger to be pressed in. Typically, trigger guards can only be pressed in while the user has a firm grip of the handle.|$|E
5000|$|Most {{pneumatic}} {{die grinder}} <b>throttles</b> (also called <b>triggers)</b> feature a spring-loaded [...] "kickstand" [...] mechanism between the throttle lever {{and the body}} of the grinder. This prevents the throttle from opening (being pressed down towards {{the body of the}} grinder) without operator intervention and inhibits accidental activation. It is similar in principle to the safety catches used on many handguns.|$|R
40|$|The Fast Merging Module (FMM) {{is part of}} the <b>Trigger</b> <b>Throttling</b> System (TTS). The TTS adapts {{the trigger}} {{frequency}} to the DAQ capacity in order to avoid congestions and overflows. The states of all data sources (~ 640 in the case of CMS) are read out and merged by the FMM to obtain the status of each detector partition. The functionality and the design of the FMM are presented in this paper...|$|R
40|$|Abstract—Conventional {{front-end}} designs {{attempt to}} maximize the number of “in-flight ” instructions in the pipeline. However, branch mispredictions cause the processor to fetch useless instructions that are eventually squashed, increasing front-end energy and issue queue utilization and, thus, wasting around 30 percent of the power dissipated by a processor. Furthermore, processor design trends lead to increasing clock frequencies by lengthening the pipeline, which puts more pressure on the branch prediction engine since branches take longer to be resolved. As next-generation high-performance processors become deeply pipelined, the amount of wasted energy due to misspeculated instructions will go up. The aim of this work {{is to reduce the}} energy consumption of misspeculated instructions. We propose Selective <b>Throttling,</b> which <b>triggers</b> different power-aware techniques (fetch throttling, decode throttling, or disabling the selection logic) depending on the branch prediction confidence level. Results show that combining fetch-bandwidth reduction along with select-logic disabling provides the best performance in terms of overall energy reduction and energy-delay product improvement (14 percent and 10 percent, respectively, for a processor with a 22 -stage pipeline and 16 percent and 13 percent, respectively, for a processor with a 42 -stage pipeline). Index Terms—Control speculation, energy-aware systems, low-power design, processor architecture. æ...|$|R
40|$|Conventional {{front-end}} designs {{attempt to}} maximize the number of "in-flight" instructions in the pipeline. However, branch mispredictions cause the processor to fetch useless instructions that are eventually squashed, increasing front-end energy and issue queue utilization and, thus, wasting around 30 percent of the power dissipated by a processor. Furthermore, processor design trends lead to increasing clock frequencies by lengthening the pipeline, which puts more pressure on the branch prediction engine since branches take longer to be resolved. As next-generation high-performance processors become deeply pipelined, the amount of wasted energy due to misspeculated instructions will go up. The aim of this work {{is to reduce the}} energy consumption of misspeculated instructions. We propose selective <b>throttling,</b> which <b>triggers</b> different power-aware techniques (fetch throttling, decode throttling, or disabling the selection logic) depending on the branch prediction confidence level. Results show that combining fetch-bandwidth reduction along with select-logic disabling provides the best performance in terms of overall energy reduction and energy-delay product improvement (14 percent and 10 percent, respectively, for a processor with a 22 -stage pipeline and 16 percent and 13 percent, respectively, for a processor with a 42 -stage pipeline). Peer ReviewedPostprint (published version...|$|R
40|$|The CMS central hadron calorimeters {{will undergo}} a {{complete}} replacement of their {{data acquisition system}} electronics. The replacement is phased, with portions of the replacement starting in 2014 and continuing through LHC Long Shutdown 2 in 2018. The existing VME electronics will be replaced with a μTCA-based system. New on-detector QIE electronics cards will transmit data at 4. 8 GHz to the new μHTR cards residing in μTCA crates in the CMS electronics cavern. The μTCA crates are controlled by the AMC 13, which accepts system clock and <b>trigger</b> <b>throttling</b> control from the CMS global DAQ system. The AMC 13 distributes the clock to the μHTR and reads out data buffers from the μHTR into the CMS data acquisition system. The AMC 13 also provides the clock for in-crate GLIBs which in turn distribute the clock to the on-detector front end electronics. We report on the design, development status, and schedule of the DAQ system upgrades...|$|R
40|$|The Data Acquisition System of the Compact Muon Solenoid {{experiment}} at the Large Hadron Collider reads out event {{fragments of}} an average size of 2 kilobytes from around 650 detector front-ends {{at a rate of}} up to 100 kHz. The first stage of event-building is performed by the Super-Fragment Builder employing custom-built electronics and a Myrinet optical network. It reduces the number of fragments by one order of magnitude, thereby greatly decreasing the requirements for the subsequent event-assembly stage. By providing fast feedback from any of the front-ends to the <b>trigger,</b> the <b>Trigger</b> <b>Throttling</b> System prevents buffer overflows in the front-end electronics due to variations in the size and rate of events or due to back-pressure from the down-stream event-building and processing. This paper reports on new performance measurements and on the recent successful integration of a scaled-down setup of the described system with the trigger and with front-ends of all major sub-detectors. The on-going commissioning of the full-scale system is discussed...|$|R
40|$|With CMS {{installation}} nearing completion, {{the three}} levels of the final read-out system of the Drift Tube (DT) chambers are presented. First, are the Read Out Boards (ROB), responsible for time digitization of the signals generated by a charged particle track. Second, the Read Out Server (ROS) boards receive data from 25 ROB channels through a 240 -Mbps copper link and perform data merging for further transmission through a 800 Mbps optical link. Finally, the Detector Dependent Units (DDU) merge data from 12 ROS to build an event fragment {{and send it to}} the global CMS DAQ through an S-LINK 64 output at 320 MBps. DDUs also receive synchronization commands from the TTC system (Timing, Trigger, and Control), perform error detection on data, and send a fast feedback to the TTS (<b>Trigger</b> <b>Throttling</b> System). Functionality of these electronics has been validated in the laboratory and in several test-beams, including an exercise integrated with a fraction of the whole CMS detector and electronics that demonstrated proper operation and integration within the final CMS framework...|$|R
40|$|The L 1 Trigger Control System (TCS) is {{responsible}} to control the delivery of L 1 Trigger Accepts depending {{on the status of}} the sub-detectors readout systems and the data acquisition system. This status is derived from information provided through the <b>Trigger</b> <b>Throttling</b> System (TTS) and from the status of front-end Emulators. TCS is also responsible for generating synchronization and fast reset commands, as well as to control the delivery of test and calibration triggers. TCS uses the TTC network to distribute information to the subsystems. TCS partitioning permits groups of subdetectors main components to operate independently during setting-up, test or calibration phases. Local trigger control is foreseen for the subdetector operation in standalone mode (test beam mode) This document provides an overall description of the TCS requirements and architecture, and a detailed description o f the TCS components. The main TCS components are the Central Trigger Controller (TCS), the Local Trigger Controller (LTC), the TTCci module (CMS version of TTCvi) and the sTTS Fast Merging Module (FMM). Contact e-mail - j@cern. ch S...|$|R
40|$|The Large Hadron Collider {{delivers}} up to 32 million physics collisions per second. This rate is far {{too high}} to be processed by present-day computer farms, let alone stored on disk by the experiments for offline analysis. A fast selection of interesting events must therefore be made. In the CMS experiment this is implemented in two stages: the Level- 1 Trigger of the CMS experiment uses custom-made, fast electronics, while the experiment's high-level trigger is implemented in computer farms. The Level- 1 Global Trigger electronics has to receive signals from the subdetector systems that enter the trigger (mostly from muon detectors and calorimeters), synchronize them, determine if a pre-set trigger condition is fulfilled, check if the various subsystems are ready to accept triggers based on information from the <b>Trigger</b> <b>Throttling</b> System and on calculations of possible dead-times, and finally distribute the trigger ("Level- 1 Accept") together with timing signals to the subdetectors over the so-called "Trigger, Timing and Control" distribution tree of the experiment. These functions are fulfilled by several specialized, custom-made VME modules, {{most of which are}} housed in one crate. The overall control is exerted by the central "Trigger Control System", which is described in this paper. It consists of one main module and several ancillary boards for input and output functions. Keywords: Trigger concepts and systems (hardware and software), Digital electronic circuit...|$|R

