103|319|Public
50|$|Pitts {{believes}} that process <b>transformation</b> (<b>operations</b> and process-led transformation to drive high performance-driven execution tactics.) is the pre‐requisite to being not just great, but inspiring extraordinary growth to experiencing new possibilities through change.|$|E
50|$|A WFS {{describes}} discovery, query, or data <b>transformation</b> <b>operations.</b> The client {{generates the}} request and posts it to a web feature server using HTTP. The web feature server then executes the request. The WFS specification uses HTTP as the distributed computing platform, {{although this is}} not a hard requirement.|$|E
5000|$|Data wrangling (sometimes {{referred}} to as data munging) {{is the process of}} transforming and mapping data from one [...] "raw" [...] data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. A data wrangler describes the person who performs these <b>transformation</b> <b>operations.</b>|$|E
50|$|Various {{methods can}} be used to {{represent}} this <b>transformation</b> <b>operation,</b> such as: Euler angles, Rodrigues vectors, axis/angle (where the axis is specified as a crystallographic direction), or unit quaternions.|$|R
50|$|Superfields were {{introduced}} by Abdus Salam and J. A. Strathdee in their 1974 article Supergauge <b>Transformations.</b> <b>Operations</b> on superfields and a partial classification were presented {{a few months}} later by Sergio Ferrara, Julius Wess and Bruno Zumino in Supergauge Multiplets and Superfields.|$|R
5000|$|... #Caption: The {{full set}} of {{fundamental}} <b>transformations</b> and <b>operations</b> on 2-tangles, alongside the elementary tangles 0, ∞, ±1 and ±2.|$|R
5000|$|Permutation may {{be applied}} to smaller sets as well. However, <b>transformation</b> <b>operations</b> of such smaller sets do not {{necessarily}} result in permutation the original set. Here {{is an example of}} non-permutation of trichords, using retrogradation, inversion, and retrograde-inversion, combined in each case with transposition, as found within in the tone row (or twelve-tone series) from Anton Weberns Concerto: ...|$|E
50|$|Several {{algorithms}} {{exist to}} provide {{an efficient way to}} determine string distance and specify the minimum number of <b>transformation</b> <b>operations</b> required. Such algorithms are particularly useful for delta creation operations where something is stored as a set of differences relative to a base version. This allows several versions of a single object to be stored much more efficiently than storing them separately. This holds true even for single versions of several objects if they do not differ greatly, or anything in between. Notably, such difference algorithms are used in molecular biology to provide some measure of kinship between different kinds of organisms based on the similarities of their macromolecules (such as proteins or DNA).|$|E
40|$|Abstract: In the ETL {{process the}} {{transformation}} of data is achieved through the execution {{of a set of}} <b>transformation</b> <b>operations.</b> The realization of this process (the order in which the <b>transformation</b> <b>operations</b> must be executed) should be preceded by a specification of the transformation process at a higher level of abstraction. The specification is given through mappings representing abstract operations specific to the transformation process. These mappings are defined through weaving models and metamodels. A generated weaving metamodel (GWMM) is proposed giving the operations) and appropriate OCL constraints. Weaving models specifying the actual mappings must be in accordance with this proposed GWMM...|$|E
50|$|Technology and Training Solutions (TTS): Specializes in {{the three}} areas {{integral}} to operational <b>transformation,</b> network <b>operations,</b> applications consulting, and learning & performance.|$|R
25|$|CP-symmetry, {{often called}} just CP, {{is the product}} of two symmetries: C for charge conjugation, which {{transforms}} a particle into its antiparticle, and P for parity, which creates the mirror image of a physical system. The strong interaction and electromagnetic interaction seem to be invariant under the combined CP <b>transformation</b> <b>operation,</b> but this symmetry is slightly violated during certain types of weak decay. Historically, CP-symmetry was proposed to restore order after the discovery of parity violation in the 1950s.|$|R
40|$|In this work, a novel Multiple Valued Exclusive-Or Sum Of Products (MVESOP) {{minimization}} formulation is {{analyzed and}} an algorithm is presented that detects minimum MVESOP expressions when {{the weight of}} the function is less than eight. A heuristic MVESOP algorithm based on a novel cube <b>transformation</b> <b>operation</b> is then presented. Experimental results on MCNC benchmarks and randomly generated functions indicate that the algorithm matches or outperforms the quality {{of the state of the}} art in ESOP minimizers...|$|R
40|$|Abstract. A {{business}} process model represents the {{basic building block}} for a workflow-enabled enterprise information system. Generally, a process model evolves through numerous changes during its lifetime to meet dynamic and changing business requirements. It is essential that such changes are introduced systematically and their impact is clearly understood. Process model transformation is a suitable approach for this purpose. Applying pre-defined <b>transformation</b> <b>operations</b> can ensure that the modified process conforms to a given class of constraints specified in the original model. Using a generic process modelling language, we identify three classes of transformation principles – equivalent, imply, and subsume – to manage changes in process models. A simple algebraic notation for representing process graphs is also presented {{that can be used}} to reason about <b>transformation</b> <b>operations.</b> ...|$|E
40|$|By conbining two {{powerful}} optical computing techniques, namely, optical symbolic substitution (OSS) and polarization-encoded optical shadow-casting (POSC), morphological or shape <b>transformation</b> <b>operations</b> are demonstrated. Accordingly, erosion, dilation, opening, and closing operations are realized using both OSS and POSC schemes. These morphological operations {{are used for}} noise removal in binary images...|$|E
3000|$|In Fig.  2, “latitude” and “longitude”, the two {{properties}} in the concept Feed, correspond directly to the flat attributes of the embedded object labeled “location” in Fig.  2 a, but correspond indirectly to the flat attribute labeled “geo” in Fig.  2 b. The relationships between “latitude” and “longitude” and their indirect corresponding source attribute “geo”, though apparent, can semantically hold only if “geo” is transformed into two new source attributes, i.e., [...] "geo"→〈"latitude","longitude"〉, or vice versa. To preserve {{the structure of the}} raw data stored in the lake, we adopt two virtual <b>transformation</b> <b>operations,</b> Composition μ and Decomposition γ, to work on the schema of the raw data rather than on the data themselves. The virtual <b>transformation</b> <b>operations</b> are based on [46, 47], and they allow SemLinker to virtually map an attribute in a source schema to a property in the global ontology.|$|E
50|$|O'Mahony {{participated in}} the 2014 series of <b>Operation</b> <b>Transformation.</b>|$|R
40|$|The {{simultaneous}} replacement <b>transformation</b> <b>operation</b> ii here denned {{and studied}} w. r. t normal programs. We give applicability conditions able {{to ensure the}} correctness of the operation w. r. t. the set of logical consequences of the completed database. We consider separately the {{cases in which the}} underlying language is infinite and finite; in this latter case we also distinguish according to the kind of domain closure axioms adopted. As corollaries we obtain results for Fitting's and Kunen's semantics. We also show how simultaneous replacement can mimic other transfor-mation operations such as thinning, fattening and folding, thus producing applicability conditions for them too...|$|R
50|$|The now {{cross-media}} event <b>Operation</b> <b>Transformation</b> originated on The Gerry Ryan Show.|$|R
40|$|Schema-based program {{transformation}} [8] {{has been}} proposed as an effective technique for the optimisation of logic programs. Schemata are applied to a logic program, mapping inefficient constructs to more efficient ones. One challenging aspect of the technique is that of proving that the schemata are correct. This paper addresses the issue of correctness. We define operations for developing correct schemata by construction. The schema development operations are higher order equivalents of the classic program transformations of fold/unfold [6]. We consider a transformation schema to be correct if its application yields a target program which {{is equivalent to the}} source program under the pure Prolog semantics. The work described in this paper makes three contributions: a methodology for the development of provably correct program transformation schemata, abstraction of program <b>transformation</b> <b>operations</b> to <b>transformation</b> <b>operations</b> on schemata, and a higher-order unificatio [...] ...|$|E
40|$|Effects {{of digital}} image {{processing}} on improvement of images acquired with a fiber-optic microscope system were estimated. A raw image of cultured cells stained with a fluorescent dye was noisy and had insufficient contrast for observation of a detailed image. To improve the image quality, two series of techniques were performed. For observations of static specimens, integration of consecutive frames was effective in reducing the random noise. Histogram <b>transformation</b> <b>operations</b> improved the contrast of the integrated images, providing a clearer detailed image. For observations of moving specimens, spatial filtering for smoothing the image acquired by freezing one frame was effective in reducing random noise. The contrast of the image was also enhanced with the same histogram <b>transformation</b> <b>operations.</b> Spatial filtering {{for the purpose of}} sharpening images enhanced the partition patterns of optical fibers constituting the fiber-optic plate. They were successfully removed by two-dimensional fast Fourier transform...|$|E
40|$|The {{replacement}} transformation operation, already {{defined in}} [28], is studied wrt normal programs. We give applicability conditions able {{to ensure the}} correctness of the operation wrt Fitting's and Kunen's semantics. We show how replacement can mimic other <b>transformation</b> <b>operations</b> such as thinning, fattening and folding, thus producing applicability conditions for them too. Furthermore we characterize a transformation sequence for which the preservation of Fitting's and Kunen's semantics is ensured...|$|E
50|$|More {{sophisticated}} <b>transformations</b> include set <b>operations</b> on {{closed shapes}} (union, difference, intersection, etc.).|$|R
40|$|An {{infrared}} {{image is}} decomposed into three levels by discrete stationary wavelet transform (DSWT). Noise {{is reduced by}} wiener filter in the high resolution levels in the DSWT domain. Nonlinear gray <b>transformation</b> <b>operation</b> is used to enhance details in the low resolution levels in the DSWT domain. Enhanced infrared image is obtained by inverse DSWT. The enhanced infrared image is divided into many small blocks. The fractal dimensions of all the blocks are computed. Region of interest (ROI) is extracted by combining all the blocks, which have similar fractal dimensions. ROI is segmented by global threshold method. The man-made objects are efficiently separated from the infrared image by the proposed method. ...|$|R
5000|$|Basically, an MDA tool {{is a tool}} used to develop, interpret, compare, align, measure, verify, transform, etc. models or metamodels. In the {{following}} section [...] "model" [...] is interpreted as meaning any kind of model (e.g. a UML model) or metamodel (e.g. the CWM metamodel). In any MDA approach we have essentially two kinds of models: initial models are created manually by human agents while derived models are created automatically by programs. For example an analyst may create a UML initial model from its observation of some loose business situation while a Java model may be automatically derived from this UML model by a Model <b>transformation</b> <b>operation.</b>|$|R
40|$|Abstract—Recently, {{performance}} and monetary cost optimizations for workflows from various {{applications in the}} cloud have become a hot research topic. However, we find that most existing studies adopt ad hoc optimization strategies, which fail to capture the key optimization opportunities for different workloads and cloud offerings (e. g., virtual machines with different prices). This paper proposes ToF, a general transformation-based optimization framework for workflows in the cloud. Specifically, ToF formulates six basic workflow <b>transformation</b> <b>operations.</b> An arbitrary {{performance and}} cost optimization process can be represented as a transformation plan (i. e., a sequence of basic <b>transformation</b> <b>operations).</b> All transformations form a huge optimization space. We further develop a cost model guided planner to efficiently find the optimized transformation for a predefined goal (e. g., minimizing the monetary cost with a given performance requirement). We develop ToF on real cloud environments including Amazon EC 2 and Rackspace. Our experimental results demonstrate the effectiveness of ToF in optimizing the performance and cost in comparison with other existing approaches. Index Terms—Cloud computing, monetary cost optimizations, workflows. F...|$|E
40|$|Transformation of {{a source}} schema with its {{conforming}} data to a target schema with its conforming data {{is an important}} activity in XML as two schemas in XML can represent same real world information. Specifically in XML data integration, transformation of a source to a target is regarded as an important task. An XML source schema can often be defined with XML key which is an important integrity constraint. Thus when a source schema with keys is transformed, keys need to be transformed as they are defined on the schema. Moreover {{there is a need}} to investigate whether the transformed keys are valid and preserved. In this paper, we study how XML keys are transformed, and whether the transformed keys are valid and preserved to the target schema. Towards this problem, we firstly define XML keys and their satisfactions. We then show how the XML keys are transformed using <b>transformation</b> <b>operations.</b> Finally, we study the key preservation property of important XML transformation operators. We show that the important XML <b>transformation</b> <b>operations</b> are key preserving with necessary and sufficient conditions. ...|$|E
30|$|The Thor {{system allows}} data <b>transformation</b> <b>operations</b> to be {{performed}} either locally on each physical node or globally across all nodes. For example, a global maximum can be found by aggregating all the local maximums obtained on each node. This {{is similar to the}} MapReduce approach, however, the big advantage of ECL is that this is done naturally and {{there is no need to}} define any key-value pair or any Map or Reduce functions.|$|E
5000|$|Mathematically, the {{relation}} of degeneracy with symmetry can be clarified as follows. Let us consider a symmetry operation associated with a unitary operator [...] Under such an operation, the new Hamiltonian {{is related to the}} original Hamiltonian by a similarity transformation generated by the operator , such that , since [...] is unitary. If the Hamiltonian remains unchanged under the <b>transformation</b> <b>operation</b> , we have Now, if [...] is an energy eigenstate,where E is the corresponding energy eigenvalue.which means that [...] is also an energy eigenstate with the same eigenvalue [...] If the two states [...] and [...] are linearly independent (i.e. physically distinct), they are therefore degenerate.|$|R
50|$|The title {{refers to}} the TV series <b>Operation</b> <b>Transformation</b> and American President Donald Trump.|$|R
40|$|The {{main object}} {{of this paper}} is to present new generalizations of gamma, beta hypergeometric  and {{confluent}} hypergeometric functions. Some recurrence relations, <b>transformation</b> formulas, <b>operation</b> formulas, differentiation formulas, beta distribution and integral representations are obtained for these new generalizations. </p...|$|R
40|$|A quantum {{algorithm}} {{is a set}} of instructions for a quantum computer, however, unlike algorithms in classical computer science their results cannot be guaranteed. A quantum system can undergo two types of operation, measurement and quantum state <b>transformation,</b> <b>operations</b> themselves must be unitary (reversible). Most quantum algorithms involve a series of quantum state transformations followed by a measurement. Currently very few quantum algorithms are known and no general design methodology exists for their construction...|$|E
40|$|The {{volume of}} data being {{published}} on the Web and made available as Open Data has significantly increased {{over the last several}} years. However, data published by independent publishers are sliced and fragmented. Creating descriptive connections across datasets may considerably enrich data and extend their value. One way to standardize, describe and interconnect the information from heterogeneous data sources is to use Linked Data as a publishing technology. The majority of published open datasets is in a tabular format and the process of generating valid Linked Data from them requires powerful and flexible methods for data cleaning, preparation, and transformation. Most of the time and effort of data workers and data developers is concentrated on data cleaning aspects. In spite of the number of available platforms for tabular data cleaning and preparation, no solution is focused on the Linked Data generation. This thesis explores approaches for data cleaning and transformation {{in the context of the}} Linked Data generation and identifies their challenges. This includes reviewing typical tabular data quality issues found in the literature and practical use cases and their categorization in order to produce the requirements on designing a solution in the form of the set of data cleaning and <b>transformation</b> <b>operations.</b> Furthermore, the thesis introduces the Grafterizer software framework, developed to assist data workers and data developers in preparing and converting raw tabular data to Linked Data with simplifying and partially automating this process. The Grafterizer framework is evaluated against existing relevant tools and systems for data cleaning. The contribution of the thesis also includes extending and evaluating reference software system to implement the needed data cleaning and <b>transformation</b> <b>operations.</b> This resulted in a powerful framework for addressing typical data quality issues and a wide range of supported data cleaning and <b>transformation</b> <b>operations...</b>|$|E
3000|$|... 2001). Although PCA and LDA {{were very}} {{commonly}} used in sound signal <b>transformation</b> <b>operations,</b> they {{are not necessarily the}} best ones. In fact, for non-stationary signals, a wavelet-based time-frequency representation may be used for feature extraction. The basic idea of the discrete wavelet transform is to represent any arbitrary function f as a superposition of wavelets. Any such superposition decomposes f into different scale levels, where each level is then further decomposed with a resolution adapted to the level.|$|E
40|$|Interpolative {{reasoning}} methods is a reasoning {{technique that}} is designed to deal with reasoning in sparse rule-based systems. This paper proposed a fuzzy interpolative reasoning method by using a like - gravity - center of fuzzy sets whose shapes are trapezoidal. This method allows the conditions appearing in the antecedent part and the consequence of the rules to be represented by trapezoidal fuzzy numbers. The work steps of the presented method are first constructing a new inference rule by manipulating two given adjacent rules and next by exploiting similarity information to convert the derived inference result into the conclusion. In this process, we use scale and move rate <b>transformation</b> <b>operation</b> to support such reasoning. Department of ComputingRefereed conference pape...|$|R
40|$|We {{propose a}} novel {{technique}} of {{learning how to}} transform the source parse trees to improve the translation qualities of syntax-based translation models using synchronous context-free grammars. We transform the source tree phrasal structure into a set of simpler structures, expose such decisions to the decoding process, and find the least expensive <b>transformation</b> <b>operation</b> to better model word reordering. In particular, we integrate synchronous binarizations, verb regrouping, removal of redundant parse nodes, and incorporate a few important features such as translation boundaries. We learn the structural preferences from the data in a generative framework. The syntax-based translation system integrating the proposed techniques outperforms the best Arabic-English unconstrained system in NIST- 08 evaluations by 1. 3 absolute BLEU, which is statistically significant. ...|$|R
40|$|Radiographic image pairs {{which are}} taken {{different}} dates, {{can be easily}} compared if they are captured digitally instead of negative film form. But, image pairs must be identical in that case. Usually, second image transformed and contrast corrected pixel by pixel. <b>Transformation</b> <b>operation</b> use landmark points of images. Landmarks are typical image points like corners of bones or typical inside areas which can be seen and selected by doctors. Landmarks can also be selected automatically by a computer. This is easy and more accurate way instead of doctor’s selection. In this work, we suggest that variance of pixel densities and Mahalanobis distance can be used together for determination of landmark points. Results of our work are successful for landmark selection operation...|$|R
