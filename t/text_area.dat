127|388|Public
5|$|The {{development}} process of Epiphany was mainly focused on numerous small usability improvements. The most notable {{of them was}} the new text entry widget, which first appeared in 1.8 stable version series. The new widget supported icons inside the <b>text</b> <b>area</b> reduced the amount of screen space needed to present the information and improved GNOME integration.|$|E
5|$|The book's current {{dimensions}} are 330 by 250mm. Originally, the folios were of no standard size, {{but they were}} cropped to the current size during a 19th-century rebinding. The <b>text</b> <b>area</b> is approximately 250 by 170mm. Each text page has 16 to 18 lines of text. The manuscript is in remarkably good condition considering its great age, though many pages have suffered some damage to the delicate artwork due to rubbing. The book {{must have been the}} product of a major scriptorium over several years, yet was apparently never finished, the projected decoration of some pages appearing only in outline. It is believed that some 30 folios of the original manuscript have been lost over the centuries. Ussher counted 344 folios in 1621, but several leaves had already been lost by then. The overall estimate is based on gaps in the text and the absence of certain key illustrations.|$|E
25|$|Below {{the buttons}} {{is the main}} <b>text</b> <b>area</b> of the window. Typically, the text begins with a heading, often bold or in a larger font {{than the rest of}} the text. This heading may {{sometimes}} be in a non-scrolling region—an area of the window that does not move up or down via the scrollbar at the side of the window. Non-scrolling regions can only be used at the beginning of a topic. The Help author can control size and background color of a non-scrolling region.|$|E
50|$|In <b>text</b> <b>areas,</b> the Option key can be {{used for}} quick {{keyboard}} navigation.|$|R
50|$|The {{physician}} dictates {{the case}} into a recording device, {{which is then}} sent to a transcriptionist for entry into the EMR, usually into free <b>text</b> <b>areas.</b>|$|R
40|$|Abstract: This paper proposes an {{algorithm}} {{for detecting}} artificial text in video frames using edge information. First, an edge map is created using the Canny edge detector. Then, morphological dilation and opening {{are used in}} order to connect the vertical edges and eliminate false alarms. Bounding boxes are determined for every non-zero valued connected component, consisting the initial candidate <b>text</b> <b>areas.</b> Finally, an edge projection analysis is applied, refining the result and splitting <b>text</b> <b>areas</b> in <b>text</b> lines. The whole algorithm is applied in different resolutions to ensure text detection with size variability. Experimental results prove that the method is highly effective and efficient for artificial text detection. ...|$|R
500|$|The {{pages with}} the text have been ruled with a blind stylus or similar tool, leaving just an {{impression}} in the vellum. [...] It can be shown that this was done for each gathering with just two sets of lines, ruled on the outermost and innermost pages, requiring a very firm impression to carry the marks through to the sheets behind. [...] Impressed lines mark the vertical edges of the <b>text</b> <b>area,</b> {{and there is an}} outer pair of lines. [...] Each line of text is ruled, only as far as the inner vertical lines, and there are prick marks where the horizontal lines meet the verticals. [...] The book begins with 19 lines on a page, but at folio 42 changes to 20 lines per page, requiring the re-ruling of some pages. [...] This change was evidently a departure from the original plan, and may have been caused by a shortage of the very fine vellum, as two different sorts are used, though the change does not coincide exactly with the change in the number of lines.|$|E
2500|$|In 1997, LSI {{developers}} {{released a}} Java-based application they called [...] "NetTutor". This was an online educational interface that allowed participants and a [...] "leader" [...] to collaborate in real time. When the leader draws or places text, figures and symbols such as square-root and integral signs on a virtual whiteboard, they are simultaneously displayed on all users' screens. Other participants can [...] "raise their hands" [...] and {{be recognized by}} the leader, who can grant them access to draw or type on the whiteboard area. A secondary, instant messaging-style <b>text</b> <b>area</b> allows text-only communication. LSI leased this interface to educational partners (schools and textbook publishers, chiefly), but renamed the platform WorldWideWhiteboard in 2001 to distinguish it from its online tutoring service, which kept the name NetTutor.|$|E
2500|$|Help authors {{can also}} control the {{background}} {{color of the}} main <b>text</b> <b>area,</b> where the actual text of the topic appears. This text can be formatted and arranged in many ways. Within the text, jumps appear as green text with a single underline. [...] Single-clicking on a jump opens a different topic. [...] Some jumps may open secondary Help windows to display information. [...] Popups appear in the text as green text with a dotted underline. Single-clicking on a popup opens a small window with no menus, buttons, or scrollbars, sized to fit the text. [...] Often, popups provide short definitions of key terms or other supplemental information about the main text. The popup automatically disappears {{the next time the}} user clicks or presses a key.|$|E
40|$|This paper {{proposes a}} new method of video text {{location}} based on Adaboost. First extracting the connected domains from the video image，We get f 1 Ve C 1 aSSPS features Of text after analyZlng the <b>text</b> <b>areas.</b> Then We construct a strong classifier of Adaboost with CART(Classification And Regression Tree) using the five classes features. Finally，we send the candidate text regions into the strong classifier {{to get the}} correct <b>text</b> <b>areas.</b> The experimental results show that not only can this method achieve a good effect on the text location in the video images including the text of various fonts，sizes and colors but also realize rapidity and precision that the video text location requires...|$|R
50|$|At {{the client}} end, OS X {{defaults}} to only focusing text boxes and lists, but this setting can be overridden to allow navigation to all entries (see references). Mozilla Firefox can similarly be customized to include or exclude navigation to <b>text</b> <b>areas,</b> other form elements, and anchors.|$|R
40|$|The {{analysis}} of post-modernist metatext’s features has been reviewed in this article. The principle of mimesis’s refusal and modeling of the <b>text’s</b> <b>area,</b> game, intertextuality, irony, sense decentration {{have been viewed}} as the particular tools of the author’s opinion realization and {{the way of the}} modern literary process’s understandin...|$|R
2500|$|The {{manuscript}} has 224 medieval folios with a {{page size}} of 230 x 155mm and a typical <b>text</b> <b>area</b> of 160 x 95. The binding is modern, from 1932. The contents {{begin with a}} calendar, illustrated with {{the signs of the}} Zodiac in small roundels (ff. 4r-10v), with Scorpio as a dragon. [...] Then follow five full-page miniatures with gold grounds, showing: the Annunciation, Visitation, seated Virgin and Child, Christ in Majesty surrounded by the Evangelists' Symbols, and King David playing his harp (ff 12v-14v). [...] David faces the large Beatus initial (f 15r) that begins the text of the Latin Book of Psalms, which includes three scenes from the life of David along the stem of the [...] "B": David beheading Goliath, bringing his head to Saul, and harping, crowned as king. [...] This occupies about two thirds of the page. The usual ten English sections into which the psalms are divided are marked by smaller decorated initials, some historiated with figures. [...] These mark the start of Psalms 26 (f 38v), 38 (f 53r), 51 (f 66), 51 and 52 (f 66r and v), 68 with Jonah thrown off his ship, and riding on the whale (f 80v), 80 (f 98r), 97 (f 114r), 101 with Christ in the initial, and a kneeling monk below it with a scroll reading [...] "Lord hear my prayer" [...] (f 116), and 109 with the Trinity (f 132). [...] The initials {{at the start of the}} other psalms are in coloured ink of red, green and blue, with decoration. [...] Some of the decorative line-fillers have animal heads. [...] The psalms are followed by the Litany, with the royal saint Edward the Confessor, who rebuilt Westminster Abbey, written in gold on f 182 (as he was in the calendar at f 5), and special prayers for Edward and Saint Peter, the abbey's dedicatee.|$|E
5000|$|... #Caption: Medieval {{manuscript}} framework {{according to}} Tschichold, {{in which a}} <b>text</b> <b>area</b> proportioned near the golden ratio is constructed. [...] "Page proportion is 2:3, <b>text</b> <b>area</b> proportioned in the Golden Section." ...|$|E
5000|$|A multiple-line <b>text</b> <b>area,</b> {{the size}} of which is {{specified}} by [...] (where a col is a one-character width of text) and [...] HTML attributes. The content of this element is restricted to plain text, which appears in the <b>text</b> <b>area</b> as default text when the page is loaded.|$|E
5000|$|Fitting {{all this}} {{functionality}} in 4 KB of 2732 EPROM required {{a lot of}} effort and some sacrifices. For example, some message <b>text</b> <b>areas</b> were also used actual code (e.g. [...] "READY" [...] message) and the number of error messages was reduced to only two ("WHAT?" [...] and [...] "HOW?").|$|R
40|$|We {{present a}} {{hierarchical}} method for segmenting <b>text</b> <b>areas</b> in natural images. The method {{assumes that the}} text is written with a contrasting color on {{a more or less}} uniform background. But no assumption is made regarding the language or character set used to write the text. In particular, the text can contain simple graphics or symbols. The key feature of our approach is that we first concentrate on finding the background of the text, before testing whether there is actually text on the background. Since uniform areas are easy to find in natural images, and since <b>text</b> backgrounds define <b>areas</b> which contain "holes" (where the text is written) we thus look for uniform areas containing "holes" and label them as text backgrounds candidates. Each candidate area is then further tested for the presence of text within its convex hull. We tested our method on a database of 65 images including English and Urdu text. The method correctly segmented all the <b>text</b> <b>areas</b> in 63 of these images, and in only 4 of these were areas that do not contain text also segmented...|$|R
40|$|The {{automatic}} extraction {{and recognition}} of news captions and annotations can be of great help locating topics of interest in digital news video libraries. To achieve this goal, we present a technique, called Video OCR (Optical Character Reader), which detects, extracts, and reads <b>text</b> <b>areas</b> in digital video data. In this paper, we address problems, describe the method by which Video OCR operates, and suggest applications for its use in digital news archives. To solve two problems of character recognition for videos, low resolution characters and extremely complex backgrounds, we apply an interpolation filter, multi-frame integration and character extraction filters. Character segmentation is performed by a recognition-based segmentation method, and intermediate character recognition results are used to improve the segmentation. We also include a method for locating <b>text</b> <b>areas</b> using text-like properties {{and the use of}} a language-based postprocessing technique to increase word recogni [...] ...|$|R
50|$|A triple-click {{within a}} {{paragraph}} in the <b>text</b> <b>area</b> selects the entire paragraph.|$|E
5000|$|<b>Text</b> <b>area</b> for {{arbitrary}} SQL commands {{and storing}} these commands in command history ...|$|E
5000|$|... form controls: button (various shapes, {{including}} tab buttons), text field, <b>text</b> <b>area,</b> drop-down list, list box, checkbox, {{radio button}} ...|$|E
40|$|This master’s {{thesis is}} focused on anonymization of {{ultrasound}} data in DICOM format. Haar wavelet belonging to Daubechies wavelet family is used to detect <b>text</b> <b>areas</b> in the image. Extraction of the text from the image is done using a free tool - tesseract OCR Engine. Finally, detected text is compared to sensitive data from DICOM metadata using Levenshtein - edit distance algorithm...|$|R
40|$|Text {{detection}} {{is important}} in the retrieval of texts from digital pictures, video databases and webpages. However, it can be very challenging since the text is often embedded in a complex background. In this paper, we propose a classification-based algorithm for text detection using a sparse representation with discriminative dictionaries. First, the edges are detected by the wavelet transform and scanned into patches by a sliding window. Then, candidate <b>text</b> <b>areas</b> are obtained by applying a simple classification procedure using two learned discriminative dictionaries. Finally, the adaptive run-length smoothing algorithm and projection profile analysis are used to further refine the candidate <b>text</b> <b>areas.</b> The proposed method is evaluated on the Microsoft common test set, the ICDAR 2003 text locating set, and an image set collected from the web. Extensive experiments show that the proposed method can effectively detect texts of various sizes, fonts and colors from images and videos. (c) 2010 Elsevier B. V. All rights reserved...|$|R
40|$|Abstract. The {{automatic}} extraction {{and reading}} of news captions and annotations {{can be of}} great help locating topics of interest in digital news video archives. To achieve this goal, we present a technique, called Video OCR, which detects, extracts, and reads <b>text</b> <b>areas</b> in digital video data. In this paper, we address problems, describe the method by which Video OCR operates, and suggest applications for its use in digital news archives. To solvetwo problems of character recognition for videos, low resolution characters and extremely complex backgrounds, we apply an interpolation lter, multi-frame integration and a combination of four lters. Segmenting characters is done by a recognition-based segmentation method, and intermediate character recognition results are used to improve the segmentation. We also include a method for locating <b>text</b> <b>areas</b> using the text-like properties {{and the use of}} a language-based post-processing technique to increase word recognition rates. The overall recognition results are satisfactory for use in news indexing. Performing Video OCR on news video and combining its results with other video understanding techniques will improve the overall understanding of the news video content...|$|R
5000|$|... #Caption: Page {{spread with}} J. A. van de Graaf's {{construction}} of classical <b>text</b> <b>area</b> (print space) and margin proportions.|$|E
50|$|In {{the case}} of Nautilus, the display list was set to divide the screen into five sections. At the top was a low-resolution <b>text</b> <b>area</b> {{displaying}} the score, followed by the horizontal-scrolling map used by the Colossus, followed by another text score area, a 2-D scrolling area for the Nautilus, and finally another <b>text</b> <b>area</b> for the status at the bottom. The graphics {{for each of these}} areas would be held in a separate area in memory. The ANTIC had a single register holding the position of the smooth scrolling. In order to have different scrolling positions for the upper and lower portions of the screen, the ANTIC was instructed to cause an interrupt after the second <b>text</b> <b>area,</b> calling into the 6502 to set the scrolling register to a different position.|$|E
5000|$|The page {{proportions}} vary, {{but most}} commonly used is the 2:3 proportion. Tschichold writes [...] "For purposes of better comparison I have based his figure on a page proportion of 2:3, which Van de Graaf does not use." [...] In this canon the <b>text</b> <b>area</b> and page size are of same proportions, and {{the height of the}} <b>text</b> <b>area</b> equals the page width. This canon was popularized by Jan Tschichold in his book The Form of the Book.|$|E
40|$|Scanning two book pages at {{the same}} time helps to {{accelerate}} the scanning process {{but on the other hand}} introduces several difficulties if the user needs to have one page per image. A major difficulty is the appearance of noisy black borders around <b>text</b> <b>areas</b> as well as of noisy black stripes between the two pages. In this paper, we propose a novel algorithm for detecting the page frames on double page document images. Our aim is to split the image into the two pages as well as to remove noisy borders. First we apply a pre-processing which includes binarization, noise removal and image smoothing. Then, we detect the vertical zones of the two pages. In this stage, we introduce the vertical white run projections which have been proved efficient for detecting vertical zones of <b>text</b> <b>areas.</b> Finally, the horizontal zones of the two pages are detected based on horizontal white run projections. The experimental results on several double page document images from fifteen different books demonstrate the effectiveness of the proposed technique. 1...|$|R
40|$|In this paper, {{we present}} a trainable {{approach}} to discriminate between machine-printed and handwritten text. An integrated system able to localize <b>text</b> <b>areas</b> and split them in text-lines is used. A set of simple and easyto-compute structural characteristics that capture the differences between machine-printed and handwritten text-lines is introduced. Experiments on document images taken from IAM-DB and GRUHD databases show a remarkable performance of the proposed approach that requires minimal training data. 1...|$|R
40|$|This paper {{deals with}} the {{discrimination}} between machine-printed and handwritten text, a prerequisite for many OCR applications. An easy-to-follow approach is proposed based on an integrated system able to localize <b>text</b> <b>areas</b> and split them in text-lines. A set of simple structural characteristics that capture the differences between machine-printed and handwritten text-lines is presented and preliminary experiments on document images taken from databases of different languages and charcateristics show a remarkable performance...|$|R
50|$|TypeStuff is a Google Chrome {{extension}} {{that provides}} a persistent <b>text</b> <b>area</b> to write down notes every time a new tab is opened.|$|E
5000|$|... #Caption: Depiction of the {{proportions}} in a medieval manuscript. According to Jan Tschichold: [...] "Page proportion 2:3. Margin proportions 1:1:2:3. <b>Text</b> <b>area</b> proportioned in the Golden Section." ...|$|E
50|$|A typical {{example is}} a {{feedback}} form or comments form, which provides a <b>text</b> <b>area</b> for a user to submit his or her recommendations for improving the service.|$|E
5000|$|Draggable markers: Any marker can {{be dragged}} to the 'Get Map' <b>text</b> entry <b>area</b> {{to add that}} {{location}} to a route.|$|R
50|$|The company {{supplies}} {{two principal}} software products to its customers—Kurzweil 1000 and Kurzweil 3000. Kurzweil 1000 is a software which enables a visually impaired user {{to gain access}} to both web-based, digital or scanned print materials through its OCR and text to speech features; Kurzweil 1000 software provides easy access to most printed forms and presents them with the fields, labels, boxes, and <b>text</b> <b>areas</b> in the appropriate reading order to enable forms completion via the computer.|$|R
40|$|Extraction of <b>text</b> <b>areas</b> is a {{necessary}} first step for taking a complex document image for character recognition task. In digital libraries, such OCR'ed text facilitates access {{to the image of}} document page through keyword search. Gabor filters, known to be simulating certain characteristics of the Human Visual System (HVS), have been employed for this task by a large number of scientists, in scanned document images. Adapting such a scheme for camera based document images is a relatively new approach. Moreover, design of the appropriate filters to separate <b>text</b> <b>areas,</b> which are assumed to be rich in high frequency components, from non-text areas is a difficult task. The difficulty increases if the clutter is also rich in high frequency components. Other reported works, on separating <b>text</b> from non-text <b>areas,</b> have used geometrical/structural information like shape and size of the regions in binarized document images. In this work, we have used a combination of the above mentioned approaches for the purpose. We have used connected component analysis (CCA), in binarized images, to segment non-text areas based on the size information of the connected regions. A Gabor function based filter bank is used to separate the text and the non-text areas of comparable size. The technique is shown to work efficiently on different kinds of scanned document images, camera captured document images and sometimes on scenic images. Key Words: Gabor filter, connected component analysis, document image, multi-channel filtering...|$|R
