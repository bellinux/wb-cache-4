4723|10000|Public
5|$|Benford's law {{describes}} {{the occurrence of}} digits in many data sets, such as heights of buildings. According to Benford's law, <b>the</b> <b>probability</b> <b>that</b> <b>the</b> first decimal-digit of an item in the data sample is d (from 1 to 9) equals , regardless of the unit of measurement. Thus, about 30% of the data {{can be expected to}} have 1 as first digit, 18% start with 2, etc. Auditors examine deviations from Benford's law to detect fraudulent accounting.|$|E
5|$|The first ship of the class, Reşadiye, {{was ordered}} on 8 June 1911. Work stopped in 1912 {{following}} {{the start of}} the First Balkan War due to <b>the</b> <b>probability</b> <b>that</b> <b>the</b> Ottoman government would run out of funds. Work resumed in May 1913 following the conclusion of the conflict. The second ship, Fatih Sultan Mehmed, was ordered on 29 April 1914 in response to the Greek order for Vasilefs Konstantinos in early 1914. The British government ordered work to stop in late July 1914, {{as a result of the}} growing tensions that culminated in the outbreak of World War I on the 28th; what material that had been assembled was dismantled on the slipway in August.|$|E
5|$|The rough idea {{of these}} inapproximability results is {{to form a}} graph that {{represents}} a probabilistically checkable proof system for an NP-complete problem such as the Boolean satisfiability problem. In a probabilistically checkable proof system, a proof is represented as a sequence of bits. An instance of the satisfiability problem should have a valid proof {{if and only if}} it is satisfiable. The proof is checked by an algorithm that, after a polynomial-time computation on the input to the satisfiability problem, chooses to examine a small number of randomly chosen positions of the proof string. Depending on what values are found at that sample of bits, the checker will either accept or reject the proof, without looking at the rest of the bits. False negatives are not allowed: a valid proof must always be accepted. However, an invalid proof may sometimes mistakenly be accepted. For every invalid proof, <b>the</b> <b>probability</b> <b>that</b> <b>the</b> checker will accept it must be low.|$|E
50|$|Informally, this is {{the largest}} {{possible}} difference between <b>the</b> <b>probabilities</b> <b>that</b> <b>the</b> two <b>probability</b> distributions can assign to the same event.|$|R
40|$|Approved {{for public}} release; {{distribution}} is unlimitedThe {{behavior of the}} system hazard rate function of a two component parallel system is investigated. <b>The</b> inter-relationships between <b>the</b> <b>probabilities</b> <b>that</b> <b>the</b> components composing the system are alive and the system hazard rate is examined with special attention to certain points where there are important changes {{in the behavior of}} the hazard rate function. The behavior of the system hazard rate function is shown to depend upon the rates of change of <b>the</b> <b>probabilities</b> <b>that</b> <b>the</b> components of the system are alive. [URL] Commander, United States Nav...|$|R
25|$|In each case, {{the total}} area in red is <b>the</b> {{relative}} <b>probability</b> <b>that</b> <b>the</b> first digit is 1, {{and the total}} area in blue is <b>the</b> relative <b>probability</b> <b>that</b> <b>the</b> first digit is 8.|$|R
25|$|Instead {{we might}} ask: What is <b>the</b> <b>probability</b> <b>that</b> <b>the</b> {{bacterium}} dies between 5 hours and 5.01 hours? Let's say {{the answer is}} 0.02 (i.e., 2%). Next: What is <b>the</b> <b>probability</b> <b>that</b> <b>the</b> bacterium dies between 5 hours and 5.001 hours? The answer is probably around 0.002, since this is 1/10th of the previous interval. <b>The</b> <b>probability</b> <b>that</b> <b>the</b> bacterium dies between 5 hours and 5.0001 hours is probably about 0.0002, and so on.|$|E
25|$|Continuous {{probability}} distributions can {{be described}} in several ways. The probability density function describes the infinitesimal probability of any given value, and <b>the</b> <b>probability</b> <b>that</b> <b>the</b> outcome lies in a given interval can be computed by integrating the probability density function over that interval. On the other hand, the cumulative distribution function describes <b>the</b> <b>probability</b> <b>that</b> <b>the</b> random variable is no larger than a given value; <b>the</b> <b>probability</b> <b>that</b> <b>the</b> outcome lies in a given interval can be computed by taking the difference between the values of the cumulative distribution function at the endpoints of the interval. The cumulative distribution function is the antiderivative of the probability density function provided that the latter function exists.|$|E
25|$|First we {{consider}} the Wallenius model. <b>The</b> <b>probability</b> <b>that</b> <b>the</b> red ball is not taken in the first draw is 1000/2000 = ½. <b>The</b> <b>probability</b> <b>that</b> <b>the</b> red ball is not taken in the second draw, {{under the condition that}} it was not taken in the first draw, is 999/1999 ≈ ½. <b>The</b> <b>probability</b> <b>that</b> <b>the</b> red ball is not taken in the third draw, under the condition that it was not taken in the first two draws, is 998/1998 ≈ ½. Continuing in this way, we can calculate that the probability of not taking the red ball in n draws is approximately 2−n as long as n is small compared to N. In other words, the probability of not taking a very heavy ball in n draws falls almost exponentially with n in Wallenius’ model. The exponential function arises because the probabilities for each draw are all multiplied together.|$|E
3000|$|To {{select the}} most {{efficient}} learning method for the early fused similarities, the results of each learning methods (<b>the</b> <b>probabilities</b> <b>that</b> <b>the</b> similarities belong to the reference/cover pairs) are concatenated together to form the vector x [...]...|$|R
50|$|Consider <b>the</b> <b>probability</b> {{distributions}} shown below, {{referenced to}} a log scale.In each case, the total area in red is <b>the</b> relative <b>probability</b> <b>that</b> <b>the</b> first digit is 1, {{and the total}} area in blue is <b>the</b> relative <b>probability</b> <b>that</b> <b>the</b> first digit is 8.|$|R
50|$|Thus, {{this method}} {{estimates}} <b>that</b> <b>the</b> <b>probabilities</b> <b>that</b> <b>the</b> hypercalcemia {{is caused by}} primary hyperparathyroidism, cancer, other conditions or no disease at all are 37.3%, 6.0%, 14.9% and 41.8%, respectively, which {{may be used in}} estimating further test indications.|$|R
25|$|The {{quality of}} the issue refers to <b>the</b> <b>probability</b> <b>that</b> <b>the</b> {{bondholders}} will receive the amounts promised at the due dates. This will depend {{on a wide range}} of factors.|$|E
25|$|Any random {{variable}} {{can be described}} by its cumulative distribution function, which describes <b>the</b> <b>probability</b> <b>that</b> <b>the</b> {{random variable}} will be {{less than or equal}} to a certain value.|$|E
25|$|Since {{moving the}} wall slowly should keep a thermal {{distribution}} fixed, <b>the</b> <b>probability</b> <b>that</b> <b>the</b> light has energy E at frequency f must {{only be a}} function of E/f.|$|E
3000|$|... {{are given}} in (4). Let βk,m= Pr(Sk,m= 0) and γk,m= Pr(Sk,m= 1) <b>the</b> <b>probabilities</b> <b>that</b> <b>the</b> channel k at time m is, respectively, idle and busy. Then, we can iteratively {{calculate}} them at time m from Equation (4) as [...]...|$|R
30|$|Because we use {{empirical}} evidences we need {{to introduce}} a notion of uncertainty about <b>the</b> <b>probabilities</b> <b>that</b> <b>the</b> studies reveal. Therefore, models of subjective logic [72] could be useful for expressing things like: “The level of uncertainty about this value given by this empirical study is the following.”.|$|R
5000|$|P(E) is <b>the</b> prior <b>probability</b> <b>that</b> <b>the</b> {{evidence}} {{would be}} observed (regardless of innocence): ...|$|R
25|$|The {{standard}} {{approach is to}} test a null hypothesis against an alternative hypothesis. A critical region is the set of values of the estimator that leads to refuting the null hypothesis. The probability of type I error is therefore <b>the</b> <b>probability</b> <b>that</b> <b>the</b> estimator belongs to the critical region given that null hypothesis is true (statistical significance) and the probability of type II error is <b>the</b> <b>probability</b> <b>that</b> <b>the</b> estimator doesn't belong to the critical region given that the alternative hypothesis is true. The statistical power of a test is the probability that it correctly rejects the null hypothesis when the null hypothesis is false.|$|E
25|$|There is a {{probability}} density function f with f(5 hours) = 2 hour−1. The integral of f over any window of time (not only infinitesimal windows but also large windows) is <b>the</b> <b>probability</b> <b>that</b> <b>the</b> bacterium dies in that window.|$|E
25|$|The {{inscription}} “Judah son of Jesus” {{is ignored}} in the calculation. Since most scholars considers the historical Jesus to be childless, some people believe this inscription {{should be included in}} the calculation to reduce <b>the</b> <b>probability</b> <b>that</b> <b>the</b> tomb belongs to the Jesus family.|$|E
5000|$|... and {{its values}} are non-trivial. The factor [...] above is usually dropped (as is the {{convention}} {{in the article}} total variation distance of probability measures). Informally, {{this is the largest}} possible difference between <b>the</b> <b>probabilities</b> <b>that</b> <b>the</b> two <b>probability</b> distributions can assign to the same event. For a categorical distribution it is possible to write the total variation distance as follows ...|$|R
3000|$|Calculate <b>the</b> {{transition}} <b>probabilities</b> <b>that</b> <b>the</b> {{system will}} transfer from state n {{to the other}} states Q [...]...|$|R
50|$|<b>The</b> <b>probability,</b> P(ņχ2), <b>that</b> <b>the</b> two {{distributions}} are {{the same}} is calculated once χ2 is determined.|$|R
25|$|To {{understand}} why the two distributions are different, we may consider the following extreme example: An urn contains one red ball with the weight 1000, and a thousand white balls each with the weight 1. We want to calculate <b>the</b> <b>probability</b> <b>that</b> <b>the</b> red ball is not taken.|$|E
25|$|One {{justification}} of Occam's razor {{is a direct}} result of basic probability theory. By definition, all assumptions introduce possibilities for error; if an assumption does not improve the accuracy of a theory, its only effect is to increase <b>the</b> <b>probability</b> <b>that</b> <b>the</b> overall theory is wrong.|$|E
25|$|Such further {{consideration}} can be performed, for example, by an epidemiology-based differential diagnostic procedure, where {{potential candidate}} conditions are listed {{that may explain}} the finding, followed by calculations of how probable they are to {{have occurred in the}} first place, in turn followed by a comparison with <b>the</b> <b>probability</b> <b>that</b> <b>the</b> result would have occurred by random variability.|$|E
3000|$|<b>The</b> {{corresponding}} <b>probabilities</b> <b>that</b> <b>the</b> backoff count will be suppressed {{because of}} the collision on the medium are [...]...|$|R
5000|$|In chaos theory, the {{correlation}} integral is <b>the</b> mean <b>probability</b> <b>that</b> <b>the</b> states at two different times are close: ...|$|R
5000|$|If [...] is Boolean then [...] is <b>the</b> <b>probability</b> <b>that</b> {{flipping}} <b>the</b> 'th coordinate {{flips the}} value of the function: ...|$|R
25|$|For {{any given}} finite problem, <b>the</b> <b>probability</b> <b>that</b> <b>the</b> {{simulated}} annealing algorithm terminates {{with a global}} optimal solution approaches 1 as the annealing schedule is extended. This theoretical result, however, is not particularly helpful, since {{the time required to}} ensure a significant probability of success will usually exceed the time required for a complete search of the solution space.|$|E
25|$|The {{panspermia}} vehicles {{would be}} aimed at moving targets whose locations {{at the time of}} arrival must be predicted. This can be calculated using their measured proper motions, their distances, and the cruising speeds of the vehicles. The positional uncertainty and size of the target object then allow estimating <b>the</b> <b>probability</b> <b>that</b> <b>the</b> panspermia vehicles will arrive at their targets.|$|E
25|$|Finally, a newer {{method for}} {{determining}} the adequacy of a retirement plan is Monte Carlo simulation. This method has been gaining popularity and is now employed by many financial planners. Monte Carlo retirement calculators allow users to enter savings, income and expense information and run simulations of retirement scenarios. The simulation results show <b>the</b> <b>probability</b> <b>that</b> <b>the</b> retirement plan will be successful.|$|E
5000|$|The [...] {{gives us}} <b>the</b> <b>probability</b> <b>that</b> in <b>the</b> time {{interval}} we observe n events governed by fractional Poisson stream.|$|R
3000|$|... is a {{two-dimensional}} data structure (K×Q) containing <b>the</b> posterior <b>probabilities</b> <b>that</b> <b>the</b> observation {{in the frame}} at time t [...]...|$|R
5000|$|<b>The</b> {{conditional}} <b>probability</b> <b>that</b> <b>the</b> {{largest of}} k observations {{taken from the}} serial numbers {1,...,n}, is equal to m, is ...|$|R
