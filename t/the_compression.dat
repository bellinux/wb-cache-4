10000|10000|Public
5|$|Cockercombe tuff is a greenish-grey, hard {{pyroclastic}} rock formed by <b>the</b> <b>compression</b> of volcanic ash and is found {{almost exclusively in}} the south-eastern end of the Quantock Hills.|$|E
5|$|When the rarefication wave {{reaches the}} other (open) {{end of the}} tube, air rushes in to fill the slight vacuum. A {{little more than a}} 'neutral' amount of air enters the tube and causes a {{compression}} wave to travel back up the tube (image 4). Once <b>the</b> <b>compression</b> wave reaches the mouthpiece end of the 'tube', it is reflected again back down the pipe. However at this time, either because <b>the</b> <b>compression</b> wave 'bumped' the reed or because of the natural vibration cycle of the reed, the gap opens and another 'puff' of air is sent down the pipe.|$|E
5|$|Over twenty skulls {{have been}} found from this dinosaur. As with other lambeosaurines, the animal bore a tall, {{elaborate}} bony crest atop its skull, which contained the elongate narial passages. The narial passages extended into the crest, first into separate pockets in the sides, then into a single central chamber and onward into the respiratory system. The skull of the type specimen has no dermal impressions on it. During preservation it was compressed laterally, so now the width is about two-thirds {{what it would have}} been in real life. According to Brown, <b>the</b> <b>compression</b> also caused the nasals to shift where they pressed down on the premaxillaries. Because they were pressed on the premaxillaries, the nasals would have closed the nares. Apart from <b>the</b> <b>compression,</b> the skull appears to be normal. Contrary to what Brown assumed, the areas concerned were fully part of the praemaxillae.|$|E
40|$|<b>The</b> {{unconfined}} <b>compression</b> test {{is usually}} used for measurement of an undrained strength of cohesive soil {{because of the}} simplicity of the test technique. 　　This test，however，is　unapplicable for such specimens as cracky clay，very solid clay，and clayey soil which contains extra fractions of sand. 　　In these cases，an other strength test method such as <b>the</b> triaxial <b>compression</b> test，must be applied. 　　In this paper，results from <b>the</b> unconfined <b>compression</b> test for some cohesive soils were compared with results of <b>the</b> triaxial <b>compression</b> test on <b>the</b> same soils for the purpose of investigating the charactristics of <b>the</b> unconfined <b>compression</b> test...|$|R
40|$|<b>The</b> {{unconfined}} <b>compression</b> test is conveniently {{used for}} measuring the undrained strength　of cohesive　soil　the　to　the　simplicity　of　its　test　procedure. 　In　practice. 　a stress release occurred during sampling of undisturbed soil-which cannot be avoided. The effect of stress release on strength characteristics and deformation characteristics measured by <b>the</b> unconfined <b>compression</b> test is yet uncertain. 　　　In this paper，results from <b>the</b> unconfined <b>compression</b> test for some cohesive soils were compared with results of <b>the</b> triaxial <b>compression</b> test on　<b>the</b> same　soils {{for the purpose of}} investigating the characteristics of measured values　of <b>the</b> unconfined <b>compression</b> test...|$|R
40|$|Buckling and {{barrelling}} instabilities in <b>the</b> uniaxial <b>compressions</b> of {{an elastic}} rectangle {{have been studied}} by many authors under lubricated end conditions. However, in practice {{it is very difficult}} to realize such conditions due to friction. Here, we study <b>the</b> <b>compressions</b> of a two-dimensional nonlinearly elastic rectangle under clamped end conditions. Comment: 38 papes, 9 figure...|$|R
5|$|The {{resulting}} {{signal was}} a fast dip, corresponding to <b>the</b> <b>compression</b> of the cadmium sphere, followed by slower increase, {{corresponding to the}} decompression and following dispersal of the sphere and the lanthanum. The differences between the four traces on the oscilloscope display, each indicating the average compression {{in the direction of}} the detector, allowed the assessment of the required synchronization accuracy for the detonators.|$|E
5|$|There {{are three}} {{different}} types of eruptions. The most well-observed are magmatic eruptions, which involve the decompression of gas within magma that propels it forward. Phreatomagmatic eruptions are another type of volcanic eruption, driven by <b>the</b> <b>compression</b> of gas within magma, the direct opposite of the process powering magmatic activity. The third eruptive type is the phreatic eruption, which {{is driven by the}} superheating of steam via contact with magma; these eruptive types often exhibit no magmatic release, instead causing the granulation of existing rock.|$|E
5|$|In 1911, Pound {{introduced}} {{two other}} poets to the Eiffel Tower group: his former fiancée Hilda Doolittle (who had started signing her work H.D.) and {{her future husband}} Richard Aldington. These two were interested in exploring Greek poetic models, especially Sappho, an interest that Pound shared. <b>The</b> <b>compression</b> of expression that they achieved by following the Greek example complemented the proto-Imagist interest in Japanese poetry, and, in 1912, during a meeting {{with them in the}} British Museum tea room, Pound told H.D. and Aldington that they were Imagistes and even appended the signature H.D. Imagiste to some poems they were discussing.|$|E
2500|$|RFC 3749: [...] "Transport Layer Security Protocol <b>Compression</b> Methods", {{specifies}} <b>the</b> {{framework for}} <b>compression</b> methods and <b>the</b> DEFLATE <b>compression</b> method.|$|R
40|$|We {{show that}} if $H$ {{is a group}} of {{polynomial}} growth whose growth rate is at least quadratic then <b>the</b> $L_p$ <b>compression</b> of <b>the</b> wreath product $\Z\bwr H$ equals $\max{\frac{ 1 }{p},{ 1 / 2 }}$. We also show that <b>the</b> $L_p$ <b>compression</b> of $\Z\bwr \Z$ equals $\max{\frac{p}{ 2 p- 1 },\frac 23 }$ and <b>the</b> $L_p$ <b>compression</b> of $(\Z\bwr\Z) _ 0 $ (the zero section of $\Z\bwr \Z$, equipped with the metric induced from $\Z\bwr \Z$) equals $\max{\frac{p+ 1 }{ 2 p},\frac 34 }$. The fact that <b>the</b> Hilbert <b>compression</b> exponent of $\Z\bwr\Z$ equals $\frac 23 $ while <b>the</b> Hilbert <b>compression</b> exponent of $(\Z\bwr\Z) _ 0 $ equals $\frac 34 $ is used to show that there exists a Lipschitz function $f:(\Z\bwr\Z) _ 0 \to L_ 2 $ which cannot be extended to a Lipschitz function defined on all of $\Z\bwr \Z$...|$|R
2500|$|... (they {{actually}} {{showed that}} <b>the</b> sequence's optimal <b>compression</b> ratio over all ILFSCs is exactly its entropy rate, a quantitative measure of its deviation from normality, which is 1 exactly when the sequence is normal). Since <b>the</b> LZ <b>compression</b> algorithm compresses asymptotically {{as well as}} any ILFSC, this means that <b>the</b> LZ <b>compression</b> algorithm can compress any non-normal sequence. (Ziv Lempel 1978) ...|$|R
5|$|In 2002, CenturyLink Field {{became the}} first stadium in the NFL to install a FieldTurf {{artificial}} field. The surface is made of plastic fibers rooted {{in a mixture of}} ground rubber and sand. The field was replaced in the spring of 2008 after tests showed that compression of the sand and rubber increased the risk of player injuries. FieldTurf won the bid for the second installation over Polytan. For the replacement surface, a one-inch (two and one-half centimeters) poured rubber foundation was added to prevent <b>the</b> <b>compression</b> from reoccurring. Under the naming rights agreement, Qwest paid $500,000 for the installation and First & Goal paid the remaining amount, which was undisclosed. By 2010 the FieldTurf's quality had decreased with the blades becoming matted down. It also failed FIFA's quality testing to be ranked 2 Star. A new FieldTurf surface was laid down in 2012 and it met the requirements of a 2 Star field after testing.|$|E
5|$|Lawrence Livermore National Laboratory (LLNL) {{has been}} a leader in laser-driven {{inertial}} confinement fusion (ICF) since the initial concept was developed by LLNL employee John Nuckols in the late 1950s. The basic idea was to use a driver to compress a small pellet known as the target that contains the fusion fuel, a mix of deuterium (D) and tritium (T). If <b>the</b> <b>compression</b> reaches high enough values, fusion reactions begin to take place, releasing alpha particles and neutrons. The alphas may impact atoms in the surrounding fuel, heating them {{to the point where they}} undergo fusion as well. If the rate of alpha heating is higher than heat losses to the environment, the result is a self-sustaining chain reaction known as ignition.|$|E
5|$|Nintendo's stake {{purchase}} allowed Rare {{to expand}} significantly. The {{number of staff}} members increased from 84 to 250, and Rare moved out from their headquarters at the Manor Farmhouse. Rare also developed a CGI arcade fighting game, Killer Instinct, on their own custom-built arcade machine. Killer Instinct was set to be released for Nintendo's own 64-bit system, the Nintendo 64 in 1995, but was forced to release the game for the 16-bit SNES system, and had to downgrade the game's graphics. Killer Instinct sold 3.2 million copies, and {{was followed by a}} sequel, Killer Instinct 2. Killer Instinct Gold, the console version of Killer Instinct 2, suffered from a graphical downgrade due to <b>the</b> <b>compression</b> technology used to fit the arcade version onto the smaller Nintendo 64 cartridge.|$|E
40|$|This article {{deals with}} the use of the {{generalized}} Laguerre functions to <b>the</b> data <b>compression.</b> After <b>the</b> short introduction the definition of the generalized Laguerre polynomials and functions is given. The application of the discrete generalized Laguerre transform on <b>the</b> data <b>compression</b> is shown. It is pointed out that the discrete generalized Laguerre transform can give better results than the discrete cosine transform in the task of <b>the</b> data <b>compression.</b> <b>The</b> choice of the optimal parameter in the generalized Laguerre functions is discussed. The comparison between the optimal DLT, standard DLT, DCT and wavelet data compression with Haar and CDF basis is shown...|$|R
40|$|We {{show that}} <b>the</b> {{standard}} image <b>compression</b> algorithms are {{not suitable for}} compressing images in correlation pattern recognition since they aim at retaining image fidelity in terms of perceptual quality rather than preserving spectrally significant information for pattern recognition. New compression algorithms for pattern recognition are therefore developed, {{which are based on}} the modification of <b>the</b> standard <b>compression</b> algorithms to achieve higher compression ratio and simultaneously to enhance pattern recognition performance. This is done by emphasizing middle and high frequency components and discarding low frequency components according to a new developed distortion measure for <b>compression.</b> <b>The</b> operations of denoising, edge enhancement and compression can be integrated in the encoding process in <b>the</b> proposed <b>compression</b> algorithms. Simulation results show the effectiveness of <b>the</b> proposed <b>compression</b> algorithms...|$|R
5000|$|Lossless and lossy {{compression}} (optional): DNG support optional lossless and (since version 1.4) also lossy <b>compression.</b> <b>The</b> lossy <b>compressions</b> losses are practically indistinguishable {{in real world}} images.|$|R
5|$|Targets for NIF are {{extremely}} expensive. Each one {{consists of a}} small open ended metal cylinder with transparent double-pane windows sealing each end. In order to efficiently convert the driver laser's light to the x-rays that drive <b>the</b> <b>compression,</b> the cylinder has to be coated in gold or other heavy metals. Inside, suspended on fine plastic wires, is a hollow plastic sphere containing the fuel. In order to provide symmetrical implosion, the metal cylinder and plastic sphere have extremely high machining tolerances. The fuel, normally a gas at room temperature, is deposited inside the sphere and then cryogenically frozen until it sticks {{to the inside of}} the sphere. It is then smoothed by slowly warming it with an infrared laser to form a 100µm smooth layer on the inside of the pellet. Each target costs tens of thousands of dollars.|$|E
5|$|The {{programme}} also disproved {{claims that}} some {{deterioration in the}} quality of the gunpowder would have prevented the explosion. A portion of deliberately deteriorated gunpowder, of such low quality as to make it unusable in firearms, when placed in a heap and ignited, still managed to create a large explosion. The impact of even deteriorated gunpowder would have been magnified by its containment in wooden barrels, compensating for the quality of the contents. <b>The</b> <b>compression</b> would have created a cannon effect, with the powder first blowing up {{from the top of the}} barrel before, a millisecond later, blowing out. Calculations showed that Fawkes, who was skilled in the use of gunpowder, had deployed double the amount needed.|$|E
5|$|The {{experiment}} was suggested on 1 November 1943 by Robert Serber. The {{idea was to}} measure the spatial and temporal symmetry of explosive compression of a metal sphere. The test measured changes of absorption of gamma rays in the metal of the sphere as it underwent compression. The gamma ray source was located {{in the center of}} a metal sphere. The increase of thickness (of hollow shells) and density (of solid spheres) as <b>the</b> <b>compression</b> progressed was detected as a decrease of intensity of gamma rays outside of the sphere; the lower density explosives did not absorb gamma radiation enough to interfere with the experiment. The gamma rays had to be intense and of the right energy. Too low energy, and they would be fully absorbed in the surrounding metal; too high energy and the difference of attenuation during the implosion would be too low to be practical. The detectors had to provide high speed and large area; fast ionization chambers, then under development, were the only devices then available satisfying the requirements.|$|E
50|$|With these {{conditions}} in place, {{we find a}} collision in the MD hash function exactly when we find a collision in <b>the</b> underlying <b>compression</b> function. Therefore, <b>the</b> Merkle-Damgård construction is provably secure when <b>the</b> underlying <b>compression</b> function is secure.|$|R
5000|$|PPC, a {{division}} of Belden, holds a number of patents for connector technology and has pioneered advancements for various industries. [...] PPC’s innovations include <b>the</b> Universal <b>Compression</b> Connector, <b>the</b> wireless <b>compression</b> connector for <b>the</b> wireless industry and a locking HDMI connector.|$|R
40|$|This thesis {{deals with}} several {{lossless}} methods of image <b>compression.</b> <b>The</b> main {{goal is to}} achieve <b>the</b> best <b>compression</b> ratio for set of medical images. This paper provides brief introduction into <b>the</b> data <b>compression</b> theory. It also contains design of image compression and description of designed compression modules implementation. Also the verifi cation of suitability of designed method for medical images compression is involved...|$|R
25|$|Despite {{the fact}} that many modern ftp {{programs}} support segmented downloading, <b>the</b> <b>compression</b> via RAR, ZIP, and breaking up of files has not changed.|$|E
25|$|The next figures {{shows the}} {{spectrum}} after r-r compensation, but with truncation of <b>the</b> <b>compression</b> waveform to 1.1T, {{and the final}} compressed waveform.|$|E
25|$|If lossy data {{compression}} {{is used on}} audio or visual data, differences from the original signal will be introduced; if <b>the</b> <b>compression</b> is substantial, or lossy data is decompressed and recompressed, this may become noticeable {{in the form of}} compression artifacts. Whether these affect the perceived quality, and if so how much, depends on <b>the</b> <b>compression</b> scheme, encoder power, the characteristics of the input data, the listener’s perceptions, the listener's familiarity with artifacts, and the listening or viewing environment.|$|E
50|$|<b>The</b> Stanford <b>Compression</b> Forum (SCF) is a {{partnership}} between academic and industrial leaders {{in the fields of}} Data <b>compression.</b> <b>The</b> Forum’s mission is to facilitate research and collaborations, to expedite the transfer of academic research into technology, to supply academia with timely research problems, and to support learning and training in <b>the</b> field of <b>compression.</b>|$|R
30|$|At {{water-saturated}} condition, {{the reduction}} of MC proportionally increases with <b>the</b> increase of <b>compression</b> ratio [13]. This means <b>the</b> MC after <b>compression</b> is determined for a given compression ratio. In this study, <b>the</b> MC after <b>compression</b> for Poplar and Chinese fir were, respectively, 84.1 and 105.3 %, a critical value of MC threshold before compression: above this threshold value, <b>the</b> MC after <b>compression</b> would be reduced to similar level since <b>the</b> same <b>compression</b> ratio allows <b>the</b> similar maximum amount of water, and below this threshold <b>the</b> MC after <b>compression</b> would not reach the allowed maximum amount and therefore would be reduced. This explains <b>the</b> MC after <b>compression</b> of wood that remained constant or decreased slightly when the MC were beyond 85 and 116 % for Poplar and Chinese fir, respectively. The critical value in early report [13] was about 75 % and 120 % for a different species of Poplar (Populus tomentosa) and the same species of Chinese fir grown in different provinces.|$|R
40|$|Medical images, {{like any}} other digital data, require {{compression}} {{in order to reduce}} disk space needed for storage and time needed for transmission. <b>The</b> lossless <b>compression</b> methods of still images can shorten the file only to a very limited degree. The application of fractal compression to medical images would allow obtaining much higher <b>compression</b> ratios. While <b>the</b> fractal magnification – an inseparable feature of <b>the</b> fractal <b>compression</b> – would be very useful in presenting the reconstructed image in a highly readable form. However, like all irreversible methods, <b>the</b> fractal <b>compression</b> is connected with the problem of information loss, which is especially troublesome in the medical imaging. A very time consuming encoding process, which can last even several hours, is another bothersome drawback of <b>the</b> fractal <b>compression.</b> Based on a survey of literature and own cogitations, the author attempts to provide an adapted to the needs of medical imaging solution that will overcome the unfavorable ailments of <b>the</b> fractal <b>compression</b> methods. <b>The</b> thesis does not provide only theoretical deliberations but also gives implementation of the proposed algorithm, which is used to test the suitability of <b>the</b> fractal <b>compression</b> to medical imaging. The results of the work are more than satisfying – the fidelity of the images compressed with <b>the</b> proposed fractal <b>compression</b> method meets <b>the</b> requirements imposed on the medical images and the fractal magnification outperforms other magnification techniques...|$|R
25|$|Opera Mini {{was derived}} from the Opera web browser. Opera Mini {{requests}} web pages through Opera Software's compression proxy server. <b>The</b> <b>compression</b> server processes and compresses requested web pages before sending them to the mobile phone. <b>The</b> <b>compression</b> ratio is 90% and the transfer speed is increased by two to three times as a result. The pre-processing increases compatibility with web pages not designed for mobile phones. However, interactive sites which depend upon the device processing JavaScript do not work properly.|$|E
25|$|Free divers {{may also}} use weights to {{counteract}} buoyancy of a wetsuit. However, {{they are more}} likely to weight for neutral buoyancy at a specific depth, and their weighting must take into account not only <b>the</b> <b>compression</b> of the suit with depth, but also <b>the</b> <b>compression</b> of the air in their lungs, and the consequent loss of buoyancy. As they have no decompression obligation, they do not have to be neutrally buoyant near the surface at the end of a dive.|$|E
25|$|Early {{studies of}} the {{phenomenon}} suggested one {{solution to the problem}} was to increase <b>the</b> <b>compression</b> rate. In this approach, <b>the</b> <b>compression</b> would be started and stopped so rapidly that the bulk of the plasma would not have time to move; instead, a shock wave created by this rapid compression would be responsible for compressing the majority of the plasma. This approach became known as fast pinch. The Los Alamos team working on the Columbus linear machine designed an updated version to test this theory.|$|E
30|$|In {{the paper}} Liu et al. (2014) {{successfully}} implemented <b>the</b> CS based <b>compression</b> and <b>the</b> wavelet based <b>compression</b> procedure on <b>the</b> field {{programmable gate array}} (FPGA). The result shows that the CS based procedure achieves the better performance compared to <b>the</b> wavelet <b>compression</b> in terms of power consumption and the number of computing resources required. Furthermore, the sparse binary sensing matrix achieves <b>the</b> desired signal <b>compression,</b> but at <b>the</b> price of the higher signal reconstruction time and the higher sensing matrix construction time.|$|R
30|$|<b>The</b> {{proposed}} <b>compression</b> algorithm achieves <b>the</b> average CRs from 4 : 1 to 20 : 1 {{with average}} PRDa varies between 1.2 and 5.6 %. Since the acceptable values of PRD {{were reported to}} be less than 9 % in the literature [31], it can be emphasized that the results obtained in <b>the</b> proposed <b>compression</b> algorithm provide high CR with very low PRD levels. Furthermore, the average encoding and decoding times of <b>the</b> proposed <b>compression</b> algorithm are 0.687 and 0.318 s, respectively.|$|R
40|$|This paper further {{investigates the}} set-valued {{information}} system. First, we bring forward three tolerance relations for set-valued information systems and explore their basic properties in detail. Then <b>the</b> data <b>compression</b> is investigated for attribute reductions of set-valued information systems. Afterwards, we discuss <b>the</b> data <b>compression</b> of dynamic set-valued information systems by utilizing <b>the</b> precious <b>compression</b> of <b>the</b> original systems. Several illustrative examples are employed {{to show that}} attribute reductions of set-valued information systems can be simplified significantly by our proposed approach...|$|R
