10000|10000|Public
5|$|Hacking Invasion: A one-versus-one {{competitive}} multiplayer mode, originally {{featured in}} the first game, in which a player covertly joins another player's single-player session and steals virtual data from them. The invading player must stay hidden while stealing <b>the</b> <b>data,</b> <b>and</b> escape once successful, while the defending player must identify and kill the invading player.|$|E
5|$|JMP {{software}} is partly focused on exploratory data analysis and visualization. It {{is designed for}} users to investigate data to learn something unexpected, as opposed to confirming a hypothesis. JMP links statistical data to graphics representing them, so users can drill down or up to explore <b>the</b> <b>data</b> <b>and</b> various visual representations of it. Its primary applications are for designed experiments and analyzing statistical data from industrial processes.|$|E
5|$|Theorists {{also try}} to {{generate}} or modify models {{to take into account}} new data. In the case of an inconsistency between <b>the</b> <b>data</b> <b>and</b> model's results, the general tendency is to try to make minimal modifications to the model so that it produces results that fit the data. In some cases, a large amount of inconsistent data over time may lead to total abandonment of a model.|$|E
30|$|HY {{wrote the}} {{manuscript}} <b>and</b> participated in <b>the</b> <b>data</b> collection <b>and</b> analysis. JH assisted the surgery <b>and</b> collected <b>the</b> <b>data.</b> MC <b>and</b> IS participated in data collection. BM performed the surgery <b>and</b> participated in <b>the</b> <b>data</b> collection <b>and</b> manuscript preparation. All authors {{read and approved}} the final manuscript.|$|R
5000|$|Classes - the {{definitions}} for <b>the</b> <b>data</b> format <b>and</b> available procedures {{for a given}} type or class of object; may also contain <b>data</b> <b>and</b> procedures (known as class methods) themselves, i.e. classes contains <b>the</b> <b>data</b> members <b>and</b> member functions ...|$|R
30|$|HC {{carried out}} {{literature}} survey, <b>the</b> <b>data</b> analysis <b>and</b> drafted <b>the</b> manuscript while OB <b>and</b> AHB guided <b>data</b> collection, coordinated <b>the</b> research <b>and</b> carried out <b>the</b> <b>data</b> analysis, <b>and</b> GD collected <b>data</b> <b>and</b> carried out <b>the</b> <b>data</b> analysis. All authors {{read and approved}} the final manuscript.|$|R
5|$|Scientists {{interpreted}} that a 0.81-day {{orbit of}} a possible planet from <b>the</b> <b>data,</b> <b>and</b> followed up with observations using the CORALIE spectrograph on the Leonhard Euler Telescope at Chile's La Silla Observatory. CORALIE provided radial velocity measurements that indicated that WASP-43 was being transited by a planet that was 1.8 times Jupiter's mass, now dubbed WASP-43b. Another follow-up using the TRAPPIST telescope further defined the light curve of the body transiting WASP-43.|$|E
5|$|The season's {{activity}} was reflected with an ACE rating of approximately 165 units, the highest since 2005, and the eleventh highest value since 1944 at the time. Broadly speaking, ACE {{is a measure}} of the power of a tropical or subtropical storm multiplied by the length of time it existed. Therefore, a storm with a longer duration, such as Igor, will have high values of ACE. It is only calculated for full advisories on specific tropical and subtropical systems reaching or exceeding wind speeds of 39mph (63km/h). Accordingly, tropical depressions are not included in the count. After the storm has dissipated, typically after the end of the season, the NHC re-examines <b>the</b> <b>data</b> <b>and</b> produces a final report on each storm. These revisions can lead to a revised ACE total either upward or downward compared to the original value.|$|E
25|$|Defining {{the problem}} by {{analyzing}} <b>the</b> <b>data</b> <b>and</b> the information gathered.|$|E
30|$|VB and OP {{have worked}} on the concept and design of the given study, {{drafting}} <b>the</b> manuscript, <b>and</b> <b>data</b> collection. GY <b>and</b> YP were responsible for <b>the</b> <b>data</b> collection <b>and</b> analysis. MV helped with <b>the</b> <b>data</b> interpretation <b>and</b> a critical manuscript review. All of the authors have read and approved the final manuscript.|$|R
40|$|A {{system for}} {{encoding}} <b>and</b> decoding <b>data</b> words including an anti-analysis encoder unit for receiving an original plaintext and producing a recoded data, a data compression unit for receiving <b>the</b> recoded <b>data</b> <b>and</b> producing a compressed recoded <b>data,</b> <b>and</b> an encryption unit for receiving <b>the</b> compressed recoded <b>data</b> <b>and</b> producing an encrypted <b>data.</b> <b>The</b> recoded <b>data</b> has an increased non-correlatable data redundancy {{compared with the}} original plaintext in order to mask the statistical distribution of characters in <b>the</b> plaintext <b>data.</b> <b>The</b> system of the present invention further includes a decryption unit for receiving <b>the</b> encrypted <b>data</b> <b>and</b> producing a decrypted data, a data decompression unit for receiving <b>the</b> decrypted <b>data</b> <b>and</b> producing an uncompressed recoded <b>data,</b> <b>and</b> an anti-analysis decoder unit for receiving <b>the</b> uncompressed recoded <b>data</b> <b>and</b> producing a recovered plaintext that corresponds with the original plaintext...|$|R
50|$|<b>The</b> IEA <b>Data</b> Processing <b>and</b> Research Center (DPC) is <b>the</b> <b>data</b> {{processing}} <b>and</b> {{research department}} of IEA, located in Hamburg, Germany.|$|R
25|$|Although {{it can be}} {{convenient}} to log-bin the data, or otherwise smooth the probability density (mass) function directly, these methods introduce an implicit bias in the representation of <b>the</b> <b>data,</b> <b>and</b> thus should be avoided. The cdf, on the other hand, introduces no bias in <b>the</b> <b>data</b> <b>and</b> preserves the linear signature on doubly logarithmic axes.|$|E
25|$|PivotDiagrams {{can show}} {{aggregate}} statistical summaries for <b>the</b> <b>data</b> <b>and</b> show them.|$|E
25|$|The former {{report is}} adequate, the latter gives a more {{detailed}} explanation of <b>the</b> <b>data</b> <b>and</b> {{the reason why the}} suitcase is being checked.|$|E
30|$|KT {{collected}} <b>and</b> organized <b>the</b> field <b>data</b> <b>and</b> {{helped in}} partial <b>data</b> analysis <b>and</b> initial drafting of the manuscript. PT helped in study design, supervised <b>the</b> <b>data</b> collection, <b>and</b> assisted in <b>data</b> analysis <b>and</b> final drafting of the manuscript. Both authors {{read and approved}} the final manuscript.|$|R
30|$|TS mainly {{contributed to}} prepare the manuscript. KB contributed {{to prepare the}} manuscript. SY contributed to {{organize}} <b>the</b> patient’s <b>data</b> <b>and</b> images. CA contributed to organize <b>the</b> patient’s <b>data</b> <b>and</b> images. All authors read and approved the final manuscript.|$|R
30|$|In {{order to}} grasp the unity and dynamic of <b>the</b> {{obtained}} interview <b>data</b> <b>and</b> to show <b>the</b> <b>data’s</b> diversity <b>and</b> richness, this paper uses the combined methods of category analysis and scenario analysis.|$|R
25|$|By {{repeatedly}} scrambling <b>the</b> <b>data</b> <b>and</b> calculating transition counts, a {{null distribution}} {{can be constructed}} and a p-value computed by comparing the observed transition counts to this null distribution.|$|E
25|$|This {{attracted}} {{some interest}} in the media. However, some criticisms immediately appeared, which disputed the interpretation of <b>the</b> <b>data,</b> <b>and</b> who alluded to errors in the publication.|$|E
25|$|Snapshot {{replication}}: Snapshot replication {{publishes a}} copy of the entire database (the then-snapshot of <b>the</b> <b>data)</b> <b>and</b> replicates out to the subscribers. Further changes to the snapshot are not tracked.|$|E
30|$|In step (3), quasi-definitive {{data are}} {{generated}} from the baseline obtained in step (2) and then reviewed by a qualified observer for final validation. The quality control procedure consists of visual inspection of temporary baselines (outlier removals), checking the continuity between <b>the</b> quasi-definitive <b>data</b> <b>and</b> <b>the</b> definitive <b>data</b> of <b>the</b> previous year, checking the scalar residuals (obtained by taking the difference between <b>the</b> scalar <b>data</b> <b>and</b> <b>the</b> field modulus calculated from <b>the</b> vector <b>data),</b> <b>and</b> visual inspection of all components on different time scales.|$|R
3000|$|Now we {{consider}} a general scenario, where <b>the</b> <b>data</b> arrival <b>and</b> channel condition processes follow general distributions, and are stationary and ergodic. We assume that <b>the</b> <b>data</b> arrivals <b>and</b> transmission rates have finite mean and variance. We use r [...]...|$|R
30|$|TW was {{involved}} in <b>the</b> conception, <b>data</b> collection, analysis, manuscript writing and revision. MB and LR performed {{the main part of}} <b>the</b> <b>data</b> collection <b>and</b> were involved in <b>the</b> <b>data</b> analysis <b>and</b> revision. CT prepared the theoretical background and {{was involved}} in editing the manuscript. KF performed <b>the</b> <b>data</b> analysis <b>and</b> revision. HA {{was involved in}} all aspects of this study, including conception, data collection, <b>data</b> analysis, <b>and</b> revision. RL was involved in the conception of the study, manuscript writing, and critical revision. All authors read and approved the final manuscript.|$|R
25|$|The 1976 census was {{the largest}} {{undertaken}} to date, with 53 questions. Due to budgetary restraints, the Bureau {{was not able to}} complete normal processing of <b>the</b> <b>data</b> <b>and</b> a 50% sample was processed. There were 13,548,450 people counted.|$|E
25|$|Shapes can {{be linked}} with {{external}} data sources. Doing so, the shapes are formatted according to the data. <b>The</b> <b>data,</b> <b>and</b> hence the shapes, are updated periodically. Such shapes can also be formatted manually using the Data Graphics feature.|$|E
25|$|While Babbage's {{machines}} were mechanical and unwieldy, their basic architecture {{was similar to}} a modern computer. <b>The</b> <b>data</b> <b>and</b> program memory were separated, operation was instruction-based, the control unit could make conditional jumps, and the machine had a separate I/O unit.|$|E
40|$|A {{method and}} {{computer}} program product for synchronizing, displaying and providing access to data collected from various media. The method for processing <b>and</b> displaying <b>data</b> from a plurality of media comprises obtaining handwriting data using an electronic writing instrument, recording video <b>data,</b> synchronizing <b>the</b> video <b>data</b> <b>and</b> <b>the</b> handwriting <b>data,</b> <b>and</b> displaying in a single screen <b>the</b> video <b>data,</b> a timeline of <b>the</b> video <b>data,</b> <b>and</b> handwriting <b>data,</b> <b>the</b> timeline indexed according to discrete periods of time. The {{computer program product}} comprises instructions for recording time-stamped video <b>and</b> audio <b>data,</b> obtaining time-stamped handwriting data entries from an electronic writing instrument, synchronizing and indexing <b>the</b> video <b>and</b> audio <b>data</b> with <b>the</b> handwriting <b>data,</b> <b>and</b> displaying in a single screen, a first region comprising <b>the</b> handwriting <b>data,</b> a second region comprising <b>the</b> video <b>and</b> audio <b>data,</b> <b>and</b> a third region comprising a timeline of <b>the</b> video <b>and</b> audio <b>data.</b> Georgia Tech Research Corporatio...|$|R
30|$|LXW {{prepared}} all {{the samples}} and measured <b>the</b> SEM <b>and</b> I-V <b>data.</b> ZQZ measured <b>the</b> QE <b>data</b> <b>and</b> I-V <b>data.</b> TNZ <b>and</b> XC measured <b>the</b> reflectance <b>data</b> <b>and</b> I-V <b>data.</b> ML designed <b>the</b> experiments {{and wrote the}} manuscript. All authors read and approved the final manuscript.|$|R
30|$|<b>The</b> {{presented}} <b>data</b> mapping <b>and</b> reorganization {{creates a}} different relationship between neighboring blocks. The following cases are explaining what {{the changes are}} to address <b>the</b> needed <b>data</b> <b>and</b> how <b>the</b> addresses are generated.|$|R
25|$|In {{regression}} analysis, lack of normality in residuals simply {{indicates that}} the model postulated is inadequate in accounting for the tendency in <b>the</b> <b>data</b> <b>and</b> needs to be augmented; in other words, normality in residuals can always be achieved given a properly constructed model.|$|E
25|$|It implicitly bases the bin sizes on {{the range}} of <b>the</b> <b>data</b> <b>and</b> can perform poorly ifn<nbsp&30, {{because the number of}} bins will be small—less than seven—and {{unlikely}} to show trends in the data well. It may also perform poorly if the data are not normally distributed.|$|E
25|$|If {{data are}} {{represented}} by a statistical model specifying a particular family of probability distributions, then estimates of the median {{can be obtained by}} fitting that family of probability distributions to <b>the</b> <b>data</b> <b>and</b> calculating the theoretical median of the fitted distribution. Pareto interpolation is an application of this when the population is assumed to have a Pareto distribution.|$|E
5000|$|Execution tokens can {{be stored}} in variables. The word [...] takes an {{execution}} token from <b>the</b> <b>data</b> stack <b>and</b> performs <b>the</b> associated semantics. The word [...] (compile-comma) takes an execution token from <b>the</b> <b>data</b> stack <b>and</b> appends <b>the</b> associated semantics to the current definition.|$|R
40|$|A {{compositing}} {{process for}} selecting spatial data collected {{over a period}} of time, creating temporal <b>data</b> cubes from <b>the</b> spatial <b>data,</b> <b>and</b> processing and/or analyzing <b>the</b> <b>data</b> using temporal mapping algebra functions. In some embodiments, <b>the</b> temporal <b>data</b> cube is creating a masked cube using <b>the</b> <b>data</b> cubes, <b>and</b> computing a composite from the masked cube by using temporal mapping algebra...|$|R
40|$|AbstractThe article detailedly {{addresses}} {{the features of}} <b>the</b> petrophysical <b>data,</b> logging <b>data,</b> seismic <b>data</b> <b>and</b> geological <b>data</b> based on <b>the</b> concepts of <b>the</b> <b>data</b> mining. <b>The</b> mining ideas regarding <b>the</b> petrophysical <b>and</b> logging <b>data,</b> seismic <b>data</b> <b>and</b> geological <b>data</b> are made based on their features. The article uses different mining ways to process <b>the</b> corresponding <b>data,</b> <b>and</b> describes <b>the</b> results {{from the perspective of}} <b>the</b> functions of <b>data</b> mining. According to <b>the</b> <b>data</b> mining techniques, <b>the</b> petrophysical <b>data</b> are applied to find the relations and forecast reservoirs; <b>the</b> logging <b>data</b> will be employed to evaluate the fuzzy reservoirs and recognize the effective reservoirs in complicated geological conditions; the space mining results of the 3 D seismic data; the charts and text mining results of <b>the</b> geological <b>data.</b> <b>The</b> oil <b>and</b> natural gas <b>data</b> mining in <b>the</b> exploration adopts <b>the</b> methods of <b>data</b> analysis <b>and</b> <b>the</b> corresponding mathematical model to process <b>the</b> exploration <b>data,</b> <b>and</b> get <b>the</b> potential information. It has realized the purpose that <b>the</b> <b>data</b> guide exploration <b>and</b> given <b>the</b> concept of <b>data</b> exploration...|$|R
