0|3958|Public
40|$|We motivate, derive and {{implement}} a multilevel approach to the graph colouring problem. The resulting algorithm progressively coarsens the problem, initialises a colouring and then employs either Culberson 's iterated greedy algorithm <b>or</b> <b>tabu</b> <b>search</b> to refine the solution {{on each of the}} coarsened problems in reverse order. Tests on a large suite of problem instances indicate that for low-density graphs (up to around 30 % edge density) the multilevel paradigm can either speed up (iterated greedy) <b>or</b> even improve (<b>tabu</b> <b>search)</b> the asymptotic convergence. This augments existing evidence that, although the multilevel framework cannot be considered as a panacea for combinatorial optimisation problems, it can provide a useful addition to the combinatorial optimisation toolkit...|$|R
40|$|The Graph Colouring Problem (GCP) is a {{well known}} -hard problem with many {{theoretical}} and practical applications. In this paper we introduce a new local search algorithm based on a very large scale neighbourhood. We provide an extensive numerical comparison between this method and several other local search techniques considering also the embedding of the local search into more complex schemes like Iterated Local <b>Search</b> <b>or</b> <b>Tabu</b> <b>Search...</b>|$|R
40|$|The {{complexity}} of the irregular stock-cutting problem makes an ideal candidate for solution using search methods such as simulated annealing <b>or</b> <b>tabu</b> <b>search.</b> Although both were originally intended as generic problem solvers it is now generally accepted that they benefit from the injection of problem-specific knowledge. This paper looks {{at some of the}} ways in which such knowledge can be incorporated into a <b>tabu</b> <b>search</b> approach to the problem. Computational experience using data with a variety of characteristics is used to show how successive improvements can be obtained, culminating in a solution procedure that is more than competitive with many other generic approaches reported in the literature...|$|R
40|$|Taboo is a proscription of {{behaviour}} {{that affects}} everyday life. Tabooed topics typically include: bodies and their effluvia (sweat, snot, faeces, menstrual fluid, etc.); the organs {{and acts of}} sex, micturition and defecation; diseases, death, killing (including hunting and fishing); naming, addressing, touching, viewing persons and sacred beings, objects and places; food gathering, preparation, and consumption (Allan and Burridge 2006). When Captain James Cook (1728 – 79) and his surgeon on the Resolution William Anderson (died 1778) first encountered the term <b>taboo</b> (<b>or</b> <b>tabu)</b> in 1777 they used it to describe the behaviour of Polynesians towards things that {{were not to be}} done, entered, see...|$|R
30|$|A {{system of}} similar models {{detected}} in Step 9.1 forming a cluster can be merged using application of procedure {{defined as follows}} on a Bayesian scoring approaches. Here tasks unit steps or activities are linked or connected that leads to maximum improvement in the selected Bayesian score metric value and the path describing the changes to the graphical structure is determined from application of hill climbing, or simulated annealing <b>or</b> <b>TABU</b> <b>search</b> as described in [102] with random restarts for avoiding the solution from getting trapped in local minima.|$|R
40|$|The {{generation}} of minimal sets for faults detection in digital circuits, {{is an important}} problem in the industry. Unfortunately, {{the problem has been}} demonstrated to be NP-hard. In this report we present six heuristics capable to reduce a given sets of test-cubes to a minimal set of test-cases, with an average compression of about the 95 %. The methods that we propose, combine together personal intuitions and known heuristic methods as GRASP <b>or</b> <b>TABU</b> <b>search.</b> Even if the results obtained are not excellent, the reported experiments demonstrate the effectiveness of the proposed algorithms. 1...|$|R
40|$|We {{present a}} hybrid search {{technique}} based on metaheuristics for approximately solving the {{vehicle routing problem}} with time windows (VRPTW). The approach is two phased; a global customer clustering phase based on genetic algorithms (GAs) and a post-optimization local search technique based on <b>tabu</b> <b>search</b> (TS). We also devise a new crossover operator for the VRPTW and compare its performance with two well-known crossover operators for VRPTW and related problems. Computational experiments show that the GA is effective in setting the number of vehicles to be used while the <b>tabu</b> <b>search</b> is better suited for reducing {{the total number of}} distance traveled by the vehicles. Through our simulations, we conclude that the hybrid search technique is more suitable for the multi-objective optimization for the VRPTW than applying either the GA <b>or</b> <b>tabu</b> <b>search</b> independently...|$|R
40|$|This paper {{presents}} a new algorithm based on integrating {{the use of}} genetic algorithms and <b>tabu</b> <b>search</b> methods to solve the unit commitment problem. The proposed algorithm, which is mainly based on genetic algorithms incorporates <b>tabu</b> <b>search</b> method to generate new population members in the reproduction phase of the genetic algorithm. In the proposed algorithm, genetic algorithm solution is coded as a mix between binary and decimal representation. A fitness function is constructed from the total operating cost of the generating units without penalty terms. In the <b>tabu</b> <b>search</b> part of the algorithm, a simple short term memory procedure is used to counterthe danger of entrapment at a local optimum by preventing cycling of solutions, and the premature convergence of the genetic algorithm. A significant improvement of the proposed algorithm results, over those obtained by either genetic algorithm <b>or</b> <b>tabu</b> <b>search,</b> has been achieved. Numerical examples also showed {{the superiority of the}} proposed algorithm compared with two classical methods in the literature...|$|R
50|$|The {{resulting}} algorithms can outperform algorithms using small neighborhoods {{because the}} local improvements are larger. If neighborhood searched {{is limited to}} just one or {{a very small number}} of changes from the current solution, then it can be difficult to escape from local minima, even with additional meta-heuristic techniques such as Simulated Annealing <b>or</b> <b>Tabu</b> <b>search.</b> In large neighborhood search techniques, the possible changes from one solution to its neighbor may allow tens or hundreds of values to change, and this means that the size of the neighborhood may itself be sufficient to allow the search process to avoid or escape local minima, though additional meta-heuristic techniques can still improve performance.|$|R
40|$|Many {{recently}} developed local search procedures for job shop scheduling use interchange of operations, {{embedded in a}} simulated annealing <b>or</b> <b>tabu</b> <b>search</b> framework. We develop a new variable depth search procedure, GLS (Guided Local Search), based on an interchange scheme and using the new concept of neighborhood trees. Structural properties of the neighborhood are used to guide the search in promising directions. While this procedure competes successfully with others even as a stand-alone, a hybrid procedure that embeds GLS into a Shifting Bottleneck framework and {{takes advantage of the}} differences between the two neighborhood structures proves to be particularly efficient. We report extensive computational testing on all the problems available from the literature. Job Shop Scheduling, Local Search, Shifting Bottleneck, Neighborhood Trees...|$|R
40|$|A {{parallel}} {{version of}} the <b>tabu</b> <b>search</b> algorithm is implemented and used to optimize the solutions for a quadratic assignment problem (QAP). The instances are taken from the qaplib website ([URL] and we mainly concentrate on optimizing the instances announced by Sergio Carvalho derived from the ``Microarray Placement Problem'' ([URL] where one wants to find an arrangement of the probes (small DNA fragments) on specific locations of a microarray chip. We briefly explain combinatorics including graph theory and also the theory behind combinatorial optimization, heuristics and metaheuristcs. A description of some network optimization problems are also introduced before we apply our parallel <b>tabu</b> <b>search</b> algorithm to the quadratic assignment problem. Different approaches like Boltzmann selection procedure and random restarts are used to optimize the solutions. Through our experiments, we show that our parallel version of <b>tabu</b> <b>Search</b> do indeed manage to further optimize and even find better solutions found {{so far in the}} litterature. We try out a communication protocol based on sequentially generating graphs, where each node in the graph corresponds to a CPU <b>or</b> <b>tabu</b> <b>search</b> thread. One of the main goals is to find out if communication helps to further optimize the best known solution found so far for each instace. Validerat; 20101217 (root...|$|R
40|$|Artificial neural {{networks}} (ANN) {{are inspired by}} the structure of biological {{neural networks}} {{and their ability to}} integrate knowledge and learning. In ANN training, the objective is to minimize the error over the training set. The most popular method for training these networks is back propagation, a gradient descent technique. Other non-linear optimization methods such as conjugate directions set or conjugate gradient have also been used for this purpose. Recently, metaheuristics such as simulated annealing, genetic algorithms <b>or</b> <b>tabu</b> <b>search</b> have been also adapted to this context. There are situations in which the necessary training data are being generated in real time and an extensive training is not possible. This “on-line ” training arises in the context of optimizing a simulation. This paper presents extensive computational experiments to compare 12 “on-line ” training methods over a collection of 45 functions from the literature within a short term horizon. We propose a new method based on the <b>tabu</b> <b>search</b> methodology, which can compete in quality with the best previous approaches...|$|R
40|$|This paper {{provides}} an application oriented {{analysis of a}} multiple constraint scheduling procedure called SLSP, {{which is designed to}} batch and sequence production orders simultaneously. The Simultaneous Lotsizing and Scheduling Procedure (SLSP) is easy to implement in a Shop Floor Control System and leads to good results for finite loading problems. Dependent on the data available and the goal of production control SLSP can be used to minimize production costs or any other objective function, like minimizing the mean flow time or tardiness of the jobs. The approach is primarily based on a combination of regular dispatching rules and local search heuristics, such as Simulated Annealing, Threshold Accepting <b>or</b> <b>Tabu</b> <b>Search.</b> Additionally the procedure contains a special routine to calculate lot sizes using the Aspired Machine Time (AMT) as a control parameter. scheduling, batching, flexible routing, local search algorithms...|$|R
40|$|This article {{describes}} and compares three heuristics for {{a variant of}} the Steiner tree problem with revenues, which includes budget and hop constraints. First, a greedy method which obtains good approximations in short computational times is proposed. This initial solution is then improved by means of a destroy-and-repair method <b>or</b> a <b>tabu</b> <b>search</b> algorithm. Computational results compare the three methods in terms of accuracy and speed. (C) 2007 Elsevier B. V. All rights reserved...|$|R
40|$|An {{extension}} of the Disjunctive Model, efficiently representing Jobshop Scheduling (JS) problem, to more general Resource-Constrained Project Scheduling (RCPS) problem is proposed. The extension considers different groups of resources used by activities in different amounts limited to a constant value in every moment of the project duration. A {{solution to the problem}} is represented by a project resource flow diagram. Two kinds of project resource flow modifications [...] - serial and parallel [...] - are proposed in order to define a good neighborhood structure. This allows to efficiently apply local search techniques like Simulated Annealing <b>or</b> <b>Tabu</b> <b>Search.</b> 1 Introduction Scheduling {{has become one of the}} major concerns at the operational level of workshop management in industry, particularly when production processes are automatized. The allocation of resources over time to perform a collection of jobs [2] is also crucial in other situations like in computer science (in multiprocessors o [...] ...|$|R
40|$|Abstract. The {{resolution}} of optimization problems {{is of great}} interest nowadays and has encouraged the development of various information technology methods to attempt solving them. There are several prob-lems related to Software Engineering that can be solved by using this approach. In this paper, a new alternative based on the combination of population metaheuristics with a Tabu List {{to solve the problem}} of test cases generation when testing software is presented. This problem is of great importance for the development of software with a high compu-tational cost and which is generally hard to solve. The performance of the solution proposed has been tested on a set of varying complexity programs. The results obtained show that the method proposed allows obtaining a reduced test data set in a suitable timeframe and with a greater coverage than conventional methods such as Random Method <b>or</b> <b>Tabu</b> <b>Search...</b>|$|R
40|$|Over {{the last}} decade many metaheuristics have been applied to the flowshop {{scheduling}} problem, ranging from Simulated Annealing <b>or</b> <b>Tabu</b> <b>Search</b> to complex hybrid techniques. Some of these methods provide excellent effectiveness and efficiency {{at the expense of}} being utterly complicated. In fact, several published methods require substantial implemen-tation efforts, exploit problem specific speed-up techniques that cannot be applied to slight variations of the original problem, and often re-implementations of these methods by other researchers produce results that are quite different from the original ones. In this work we present a new iterated greedy algorithm that applies two phases iteratively, named destruc-tion, were some jobs are eliminated from the incumbent solution, and construction, where the eliminated jobs are reinserted into the sequence using the well known NEH construction £Corresponding author 1 heuristic. Optionally, a local search can be applied after the construction phase. Our iterated greedy algorithm is both very simple to implement and, as shown by experimental results, highly effective when compared to state-of-the-art methods...|$|R
40|$|There is {{no doubt}} about the need of {{optimizing}} the factor of time in today's production. Several optimization methods are in use. The optimization is often based on a single objective, e. g. the makespan. In practice, more than one time-related objectives are to be optimized. We focus on simulation based optimization of manufacturing processes. Therefore, control strategies are searched using several metaheuristic methods like Simulated Annealing, Genetic Algorithms, <b>or</b> <b>Tabu</b> <b>Search</b> and evaluated by running a simulation of the modeled manufacturing system repeatedly. Best results are proposed to be scheduled. The simulation yields in a big amount of data which is reduced to several time-related objectives like machine utilization, due date keeping, lead time, cycle time and others. Of course, these objectives have different dimensions and are contradictory in some cases. This makes the goal setting process very difficult. Several objectives have to be combined to a fitness value, which [...] ...|$|R
40|$|The daily {{management}} of an observation satellite like Spot, which consists in deciding every day what photographs will be attempted the next day, is {{of a great}} economical importance. But it is a large and difficult combinatorial optimization problem, for which efficient search methods have to be built and assessed. In this paper we describe the problem in the framework of the future Spot 5 satellite. This problem can be formulated as a Variable Valued Constraint Satisfaction Problem or as an Integer Linear Programming Problem. Within the VVCSP framework, exact methods to find an optimal solution, like Depth First Branch and Bound or Russian Dolls search and approximate methods to find a good solution, like Greedy <b>Search</b> <b>or</b> <b>Tabu</b> <b>search</b> have been developed and experimented on a set of representative problems. Comparison is also made with results obtained by running the Linear Programming environment CPLEX on the corresponding linear models. The conclusion addresses some lessons which [...] ...|$|R
40|$|Scheduling and {{timetabling}} {{problems are}} multi-constrained constraint satisfaction {{problems that have}} huge search space. These problems are NP hard. This paper investigates the use of backtracking approaches to laboratory personnel scheduling problem in which {{the objective is to}} assign tasks to employees. The main objective of this work is to search for better solutions than those obtained by authors using genetic algorithmic approach. The performance of backtracking algorithms is tested for different variable orderings, value ordering and consistency enforcement techniques. It is observed that the variable and value ordering backtracking with consistency enforcement techniques gives better results than the chronological backtracking as well as the results reported in the literature. This work indicates that the problem instance under consideration might have even better solutions which can possibly be obtained by suitably modifying the genetic algorithmic approach used earlier by authors or by using other optimization techniques such as simulated annealing <b>or</b> <b>Tabu</b> <b>search...</b>|$|R
5000|$|The {{relative}} {{simplicity of}} the algorithm makes it a popular first choice amongst optimizing algorithms. It is used widely in artificial intelligence, for reaching a goal state from a starting node. Choice of next node and starting node can be varied to give a list of related algorithms. Although more advanced algorithms such as simulated annealing <b>or</b> <b>tabu</b> <b>search</b> may give better results, in some situations hill climbing works just as well. Hill climbing can often produce a better result than other algorithms when {{the amount of time}} available to perform a search is limited, such as with real-time systems, so long as a small number of increments typically converges on a good solution (the optimal solution or a close approximation). At the other extreme, bubble sort {{can be viewed as a}} hill climbing algorithm (every adjacent element exchange decreases the number of disordered element pairs), yet this approach is far from efficient for even modest N, as the number of exchanges required grows quadratically.|$|R
40|$|In {{this paper}} a new bf {{oriented}} <b>tabu</b> <b>search</b> version is presented. It {{can be used}} to improve arbitrary existing sequential <b>or</b> parallel <b>tabu</b> <b>search</b> procedures for solving especially long-term production planning problems. As an example the Simple Assembly Line Balancing Problem 2 is considered where an efficient <b>tabu</b> <b>search</b> heuristic exists. Although this sequential procedure reach already good results the extended algorithm achieves considerable improvements even on a single processor. 1 Introduction <b>Tabu</b> <b>search</b> was developed as a heuristic strategy to overcome the problem of finding only local optima as a solution for combinatorial optimization problems. This often occurs if a local search procedure is used that only accepts a new solution if it leads to an improved cost value compared to the previous solution. Therefore the <b>tabu</b> <b>search</b> examines the whole neighbourhood of a current solution to take the best one as the next move even if the cost value deteriorates. By using a tabu list [...] ...|$|R
40|$|A typical {{irrigation}} {{scheduling problem}} {{is one of}} preparing a schedule to service a group of outlets which may be serviced simultaneously. This problem has an analogy with the classical earliness/tardiness problem in operations research. In previously published work an integer program was used to solve this problem, however such scheduling problems belong to a class of combinatorial problems known to be computationally demanding (N-P hard). This is widely reported in operations research. Hence integer programs can only be used to solve relatively small problems usually in a research environment where considerable computational resources and time can be allocated to solve a single schedule. For practical applications metaheuristics such as genetic algorithms, simulated annealing, <b>or</b> <b>tabu</b> <b>search</b> methods need to be used. However {{as reported in the}} literature, these need to be formulated carefully and tested thoroughly. This paper demonstrates the importance of robust testing of one such genetic algorithm formulated to solve the irrigation scheduling problem with simultaneous outlets serviced against an integer program formulated to solve the same problem...|$|R
40|$|Over {{the last}} decade, many metaheuristics {{have been applied}} to the flowshop {{scheduling}} problem, ranging from Simulated Annealing <b>or</b> <b>Tabu</b> <b>Search</b> to complex hybrid techniques. Some of these methods provide excellent effectiveness and efficiency {{at the expense of}} being utterly complicated. In fact, several published methods require substantial implementation efforts, exploit problem specific speed-up techniques that cannot be applied to slight variations of the original problem, and often re-implementations of these methods by other researchers produce results that are quite different from the original ones. In this work we present a new iterated greedy algorithm that applies two phases iteratively, named destruction, were some jobs are eliminated from the incumbent solution, and construction, where the eliminated jobs are reinserted into the sequence using the well known NEH construction heuristic. Optionally, a local search can be applied after the construction phase. Our iterated greedy algorithm is both very simple to implement and, as shown by experimental results, highly effective when compared to state-of-the-art methods. © 2005 Elsevier B. V. All rights reserved. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
40|$|Local Search: Incomplete {{approaches}} for solving CSPs are usually based on local search —or neighborhood search — techniques [4]: {{the idea is}} to start from an inconsistent complete assignment of values to the variables,and then gradually and iteratively repair it by changing some variable-value assignments,preferably towards better ones. One of the main problems with local search is that it may get stuck in local optima,i. e.,complete assignments that cannot be locally improved by changing one conflicting variable/value assignment,and that are not globally optimal. Therefore,local search has been combined with different meta-heuristics in order to help it escape from local optima,e. g.,simulated annealing <b>or</b> <b>tabu</b> <b>search</b> [2]. Local search has proved to be effective and efficient to solve very large CSPs. However,like complete search,it often has more difficulties in solving problems that are within the phase transition region —where the solvable probability is around 50 %. Indeed,before the phase transition region, problems are weakly constrained and have many solutions so that local search can usually easily find one. On the other side,beyond the phase transition region,problem...|$|R
40|$|EVITA, {{standing}} for Evolutionary Inventory and Transportation Algorithm, is a two-level methodology {{designed to address}} the Inventory and Transportation Problem (ITP) in retail chains. The top level uses an evolutionary algorithm to obtain delivery patterns for each shop {{on a weekly basis}} so as to minimise the inventory costs, while the bottom level solves the Vehicle Routing Problem (VRP) for every day in order to obtain the minimum transport costs associated to a particular set of patterns. The aim {{of this paper is to}} investigate whether a multiobjective approach to this problem can yield any advantage over the previously used single objective approach. The analysis performed allows us to conclude that this is not the case and that the single objective approach is in gene- ral preferable for the ITP in the case studied. A further conclusion is that it is useful to employ a classical algorithm such as Clarke & Wright's as the seed for other metaheuristics like local <b>search</b> <b>or</b> <b>tabu</b> <b>search</b> in order to provide good results for the Vehicle Routing Problem. Comment: 34 pages. Submitted to Evolutionary Computatio...|$|R
40|$|This paper {{focuses on}} the {{development}} of metaheuristic algorithms for the real-time traffic management problem of scheduling and routing trains in complex and busy railway networks. This key optimization problem can be formulated as a mixed integer linear program. However, since the problem is strongly NP-hard, heuristic algorithms are typically adopted in practice to compute good quality solutions in a short computation time. This paper presents a number of algorithmic improvements implemented in the AGLIBRARY optimization solver in order to improve the possibility of finding good quality solutions quickly. The optimization solver manages trains at the microscopic level of block sections and at a precision of seconds. The solver outcome is a detailed conflict-free train schedule, being able to avoid deadlock situations and to minimize train delays. The proposed algorithmic framework starts from a good initial solution for the train scheduling problem with fixed routes, obtained via a truncated branch-and-bound algorithm. Variable neighbourhood <b>search</b> <b>or</b> <b>tabu</b> <b>search</b> algorithms are then applied to improve the solution by re-routing some trains. The neighbourhood of a solution is characterized by the set of candidate trains to be re-routed and the available routes. Computational experiments are performed on railway networks from different countries and various sources of disturbance. The new algorithms often outperform a state-of-the-art <b>tabu</b> <b>search</b> algorithm and a commercial solver in terms of reduced computation times and/or train delays. © 2016 Elsevier Ltd...|$|R
40|$|Most {{classical}} scheduling formulations {{assume a}} fixed and known duration for each activity. In this paper, we weaken this assumption, requiring instead that each duration {{can be represented}} by an independent random variable with a known mean and variance. The best solutions are ones which have a high probability of achieving a good makespan. We first create a theoretical framework, formally showing how Monte Carlo simulation can be combined with deterministic scheduling algorithms to solve this problem. We propose an associated deterministic scheduling problem whose solution is proved, under certain conditions, to be a lower bound for the probabilistic problem. We then propose and investigate a number of techniques for solving such problems based on combinations of Monte Carlo simulation, solutions to the associated deterministic problem, and either constraint programming <b>or</b> <b>tabu</b> <b>search.</b> Our empirical results demonstrate {{that a combination of}} the use of the associated deterministic problem and Monte Carlo simulation results in algorithms that scale best both in terms of problem size and uncertainty. Further experiments point to the correlation between the quality of the deterministic solution {{and the quality of the}} probabilistic solution as a major factor responsible for this success. 1...|$|R
40|$|In this paper, an {{heuristic}} and non-linear programming based algorithm to optimally operate {{an energy}} hub plant is proposed. The energy hub plant {{described in this}} work is the test system for the European INGRID research project. The Energy Management System defines the optimal energy flows dispatch {{in order to obtain}} the energy balance and the maximum profit for the owner of the plant. The problem is highly constrained and non-linear, for this reason the methodology cannot rely on Linear Programming (LP) methods. The Energy Management System manages two energy carriers, electricity and hydrogen, interfacing three distribution networks: the electricity, the hydrogen and the methane networks. Simulations show that the buffer function of the system is as more intense as greater the efficiency of the conversion systems is, as compared to the prices variations along the day. Although heuristic search methods are well-suited for the solution of highly constrained non-linear problems, the applications carried out over the INGRID project test-bed show that improved solutions can be found applying a non-linear programming method named Generalised Reduced Gradient (GRG), to refine the solutions outputted by heuristic algorithms, such as Simulated Annealing <b>or</b> <b>Tabu</b> <b>Search...</b>|$|R
30|$|The first <b>tabu</b> <b>search</b> {{procedure}} (hereinafter called ST <b>or</b> standard <b>tabu</b> <b>search)</b> implements {{the main}} features of the TABUROUTE algorithm introduced by Gendrau et al. [11]. A solution S in ST is given by the sequence of retailers served by each route. The neighborhood of a solution S is the set of all the feasible solutions obtained by moving one of p randomly chosen retailers from its route in S to another route serving {{at least one of}} the q retailers closest to it, where p and q are two parameters of the <b>tabu</b> <b>search.</b> If a move leads to empty an existing route, the route is eliminated. An additional move consists in adding a new route to the set of routes and in assigning to it one of the p retailers. A move can lead to infeasible solutions that violate the capacity constraints of some vehicles. Infeasible solutions are penalized by a factor depending on the violation of the capacity constraints.|$|R
40|$|In this paper, {{we develop}} new {{heuristic}} {{procedures for the}} maximum diversity problem (MDP). This NPhard problem has {{a significant number of}} practical applications such as environmental balance, telecommunication services or genetic engineering. The proposed algorithm is based on the <b>tabu</b> <b>search</b> methodology and incorporates memory structures for both construction and improvement. Although proposed in seminal <b>tabu</b> <b>search</b> papers, memory-based constructions have been largely ignored and most <b>tabu</b> <b>search</b> applications restrict themselves to the local search framework. We will compare our <b>tabu</b> <b>search</b> construction with a memory-less design and with previous algorithms recently developed for this problem. This construction can be coupled with a local search procedure <b>or</b> a short-term <b>tabu</b> <b>search</b> for improved outcomes. Extensive computational experiments with medium and large instances show that the proposed procedure outperforms the best heuristics reported in the literature within short computational times...|$|R
40|$|A typical {{irrigation}} {{scheduling problem}} {{is one of}} preparing a schedule to service a group of outlets that may be serviced simultaneously. This problem has an analogy with the classical multimachine earliness/tardiness scheduling problem in operations research (OR). In previously published work, integer programming was used to solve irrigation scheduling problems; however, such scheduling problems belong to a class of combinatorial optimization problems known to be computationally demanding. This is widely reported in OR literature. Hence integer programs (IPs) can be used only to solve relatively small problems typically in a research environment where considerable computational resources and time can be allocated to solve a single schedule. For practical applications, metaheuristics such as genetic algorithms, simulated annealing, <b>or</b> <b>tabu</b> <b>search</b> methods need to be used. However, these need to be formulated carefully and tested thoroughly. The current research explores the potential of genetic algorithms to solve the simultaneous irrigation scheduling problem. For this purpose, two models are presented: the stream tube model and the time block model. These are formulated as genetic algorithms, which are then tested extensively, and the solution quality is compared with solutions from an IP. The suitability of these models for the simultaneous irrigation scheduling problem is reported. <br/...|$|R
40|$|A {{sequential}} irrigation {{scheduling problem}} {{is the problem of}} preparing a schedule to sequentially service a set of water users. This problem has an analogy with the classical single machine earliness/tardiness scheduling problem in operations research. In previously published work, integer program and heuristics were used to solve sequential irrigation scheduling problems; however, such scheduling problems belong to a class of combinatorial optimization problems known to be computationally demanding (NP-hard). This is widely reported in operations research. Hence, integer program can only be used to solve relatively small problems usually in a research environment where considerable computational resources and time can be allocated to solve a single schedule. For practical applications, metaheuristics such as genetic algorithms (GA), simulated annealing, <b>or</b> <b>tabu</b> <b>search</b> methods need to be used. These need to be formulated carefully and tested thoroughly. The current research is to explore the potential of GA to solve the sequential irrigation scheduling problems. Four GA models are presented that model four different sequential irrigation scenarios. The GA models are tested extensively for a range of problem sizes, and the solution quality is compared against solutions from integer programs and heuristics. The GA is applied to the practical engineering problem of scheduling water scheduling to 94 water users...|$|R
40|$|Today {{there are}} several formal and {{experimental}} methods for image compression, {{some of which have}} grown to be incorporated into the Joint Photographers Experts Group (JPEG) standard. Of course, many compression algorithms are still used only for experimentation mainly due to various performance issues. Lack of speed while compressing or expanding an image, poor compression rate, and poor image quality after expansion {{are a few of the}} most popular reasons for skepticism about a particular compression algorithm. This paper discusses current methods used for image compression. It also gives a detailed explanation of the discrete cosine transform (DCT), used by JPEG, and the efforts that have recently been made to optimize related algorithms. Some interesting articles regarding possible compression enhancements will be noted, and in association with these methods a new implementation of a JPEG-like image coding algorithm will be outlined. This new technique involves adapting between one and sixteen quantization tables for a specific image using either a genetic algorithm (GA) <b>or</b> <b>tabu</b> <b>search</b> (TS) approach. First, a few schemes including pixel neighborhood and Kohonen self-organizing map (SOM) algorithms will be examined to find their effectiveness at classifying blocks of edge-detected image data. Next, the GA and TS algorithms will be tested to determine their effectiveness at finding the optimum quantization table(s) for a whole image. A comparison of the techniques utilized will be thoroughly explored...|$|R
40|$|Some {{previous}} studies adopted a method statistically {{based on the}} observed traffic volumes and travel times to estimate the parameters. Others tried to find an optimal set of parameters to minimize {{the gap between the}} observed and estimated traffic volumes using, for instance, a combined optimization model with a traffic assignment model. The latter is frequently used in a large-scale network that has a capability to find a set of optimal parameter values, but its appropriateness has never been demonstrated. Thus, we developed a methodology to estimate a set of parameter values of BPR(Bureau of Public Road) function using Harmony Search (HS) method. HS was developed in early 2000, and is a global search method proven to be superior to other global search methods (e. g. Genetic Algorithm <b>or</b> <b>Tabu</b> <b>search).</b> However, it has rarely been adopted in transportation research arena yet. The HS based transportation network calibration algorithm developed in this study is tested using a grid network, and its outcomes are compared to those from incremental method (Incre) and Golden Section (GS) method. It is found that the HS algorithm outperforms Incre and GS for copying the given observed link traffic counts, and it is also pointed out that the popular optimal network calibration techniques based on an objective function of traffic volume replication are lacking the capability to find appropriate free flow travel spee...|$|R
40|$|Abstract Heuristic {{algorithms}} {{based on}} randomised allocation and deallocation of traffic demands are proposed in this paper. In contrast to traditional network design methods, {{where the problem}} has been decomposed into Topological Design, Circuit Routing and Resource Dimensioning, here were these subproblems handled simultaneously while the decomposition to traffic demands has been proposed. The proposed randomised methods can be divided into two groups. The first one is similar to Simulated Allocation [1, 2] proposed by M. Pi'oro, but instead of a single traffic demand a group of traffic demands is re-allocated at once. The second one is a model for adopting general heuristics for global optimisation, like Simulated Annealing, Threshold Accepting <b>or</b> <b>Tabu</b> <b>Search.</b> Randomised methods in general run longer than deterministic methods [3] but give better results (the quality of results depends on the running time). These algorithms can be interrupted instantly when the best result obtained so far is needed. The proposed methods are suitable for designing networks protected against any single or multiple link or node failures. Furthermore, assuming that only one network element can fail at time thrifty resource (capacity) allocation (TCA) can be incorporated into the algorithms for saving a significant amount of resources. The proposed methods are derived for transport networks like SDH and ATM, but can also be applied with minor modifications to other networks, e. g., IP and WDM. 1 Introduction In modern, particularly transport networks one of the most demanded network properties is the reliability, i. e., availability and survivability of services. The network should be designed, configured and re-configured in such a way to satisfy this demand cost effectively...|$|R
