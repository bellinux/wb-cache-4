1967|1168|Public
5|$|CT {{screening}} {{is associated}} with a high rate of falsely positive tests which may result in unneeded treatment. For each <b>true</b> <b>positive</b> scan there are about 19 falsely positives scans. Other concerns include radiation exposure and the cost of testing along with follow up. Research has not found two other available tests—sputum cytology or chest radiograph (CXR) screening tests—to have any benefit.|$|E
25|$|A ROC {{space is}} defined by FPR and TPR as x and y axes, respectively, which depicts {{relative}} trade-offs between <b>true</b> <b>positive</b> (benefits) and false positive (costs). Since TPR is equivalent to sensitivity and FPR is equal to 1 − specificity, the ROC graph is sometimes called the sensitivity vs (1 − specificity) plot. Each prediction result or instance of a confusion matrix represents {{one point in the}} ROC space.|$|E
25|$|False positives {{can also}} produce serious and counter-intuitive {{problems}} when the condition being searched for is rare, as in screening. If a test has a false positive {{rate of one}} in ten thousand, but only {{one in a million}} samples (or people) is a <b>true</b> <b>positive,</b> most of the positives detected by that test will be false. The probability that an observed positive result is a false positive may be calculated using Bayes' theorem.|$|E
2500|$|Positive posttest {{probability}} = <b>True</b> <b>positives</b> / (<b>True</b> <b>positives</b> + False positives) ...|$|R
30|$|To {{calculate}} {{recall and}} precision, we considered that <b>true</b> <b>positives</b> are instances (classes or methods) {{present in the}} code smell reference list that are also reported by the tool being assessed. False positives are instances that are not present in the reference list, but they were reported by the tool. False negatives are instances present in the reference list that were not reported by the tool. Finally, true negatives are instances that are not present in the reference list and were also not reported by the tool. Therefore, recall {{is the number of}} <b>true</b> <b>positives</b> divided by the number of instances in the reference list (<b>true</b> <b>positives</b> + false negatives), while precision in the number of <b>true</b> <b>positives</b> divided by the number of instances reported by the tool (<b>true</b> <b>positives</b> + false positives).|$|R
50|$|Typical {{alarm systems}} are {{designed}} to not miss <b>true</b> <b>positives</b> (real crime events) and to have as low of a false alarm rate as possible. In that regard, burglar alarms miss very few <b>true</b> <b>positives</b> but {{have a very high}} false alarm rate even in the controlled indoor environment. Motion detecting cameras miss some <b>true</b> <b>positives</b> but are plagued with overwhelming false alarms in an outdoor environment. Rule-based analytics reliably detect most <b>true</b> <b>positives</b> and have a low rate of false positives but cannot perform in active environments, only in empty ones. Also they are limited to the simple discrimination of whether an intruder is present or not.|$|R
25|$|A correct hit is {{termed a}} <b>True</b> <b>Positive</b> (TP), while the {{incorrect}} marking of healthy sections constitutes a False Positive (FP). The less FPs indicated, {{the higher the}} specificity is. A low specificity reduces {{the acceptance of the}} CAD system because the user has to identify all of these wrong hits. The FP-rate in lung overview examinations (CAD Chest) could be reduced to 2 per examination. In other segments (e.g. CT lung examinations) the FP-rate could be 25 or more. In CAST systems the FP rate must be extremely low (less than 1 per examination) to allow a meaningful study triage.|$|E
25|$|Let us {{consider}} a two-class prediction problem (binary classification), {{in which the}} outcomes are labeled either as positive (p) or negative (n). There are four possible outcomes from a binary classifier. If the outcome from a prediction is p and the actual value is also p, then it is called a <b>true</b> <b>positive</b> (TP); however if the actual value is n then {{it is said to}} be a false positive (FP). Conversely, a true negative (TN) has occurred when both the prediction outcome and the actual value are n, and false negative (FN) is when the prediction outcome is n while the actual value is p.|$|E
2500|$|Pretest {{probability}} = (<b>True</b> <b>positive</b> + False negative) / Total sample ...|$|E
50|$|In a {{classification}} task, the precision {{for a class}} {{is the number of}} <b>true</b> <b>positives</b> (i.e. the number of items correctly labeled as belonging to the positive class) divided {{by the total number of}} elements labeled as belonging to the positive class (i.e. the sum of <b>true</b> <b>positives</b> and false positives, which are items incorrectly labeled as belonging to the class). Recall in this context is defined as the number of <b>true</b> <b>positives</b> divided by the total number of elements that actually belong to the positive class (i.e. the sum of <b>true</b> <b>positives</b> and false negatives, which are items which were not labeled as belonging to the positive class but should have been).|$|R
30|$|Classification {{accuracy}} {{is the number}} of correct predictions made divided {{by the total number of}} predictions made, multiplied by 100 to turn it into a percentage. Precision {{is the number of}} <b>true</b> <b>positives</b> divided by the number of <b>true</b> <b>positives</b> and false positives. Recall is the number of <b>true</b> <b>positives</b> divided by the number of <b>true</b> <b>positives</b> and the number of false negatives. The F-score is the 2 × ((precision × recall)/(precision+recall)). The true-positive rate (sensitivity) and false-positive rate (specificity) vary across the different threshold and the sensitivity is inversely related with specificity. Then, the plot of sensitivity versus 1 -specificity is called receiver operating characteristic (ROC) curve and the ROC area is an effective measure of accuracy. The RMSE represents the sample standard deviation of the differences between predicted values and observed values.|$|R
5000|$|... where , , [...] and [...] are {{the number}} of <b>true</b> <b>positives,</b> false negatives, false <b>positives</b> and <b>true</b> negatives respectively.|$|R
2500|$|Suppose that a {{test for}} using a {{particular}} drug is 99% sensitive and 99% specific. That is, the test will produce 99% <b>true</b> <b>positive</b> results for drug users and 99% true negative results for non-drug users. Suppose that 0.5% of people are users of the drug. What is {{the probability that a}} randomly selected individual with a positive test is a user? ...|$|E
2500|$|The {{contingency}} table can derive several evaluation [...] "metrics" [...] (see infobox). To draw a ROC curve, only the <b>true</b> <b>positive</b> rate (TPR) and false positive rate (FPR) are needed (as functions of some classifier parameter). The TPR defines how many correct positive results occur among all positive samples available during the test. FPR, {{on the other}} hand, defines how many incorrect positive results occur among all negative samples available during the test.|$|E
2500|$|In binary classification, {{the class}} {{prediction}} for each instance is often made {{based on a}} continuous random variable , which is a [...] "score" [...] computed for the instance (e.g. estimated probability in logistic regression). Given a threshold parameter , the instance is classified as [...] "positive" [...] if , and [...] "negative" [...] otherwise. [...] follows a probability density [...] if the instance actually belongs to class [...] "positive", and [...] if otherwise. Therefore, the <b>true</b> <b>positive</b> rate is given by [...] and the false positive rate is given by [...]|$|E
40|$|In a {{wide range}} of contexts, {{including}} predator avoidance, medical decision-making and security screening, decision accuracy is fundamentally constrained by the trade-off between <b>true</b> and false <b>positives.</b> Increased <b>true</b> <b>positives</b> are possible only at the cost of increased false positives; conversely, decreased false positives are associated with decreased <b>true</b> <b>positives.</b> We use an integrated theoretical and experimental approach to show that a group of decision-makers can overcome this basic limitation. Using a mathematical model, we show that a simple quorum decision rule enables individuals in groups to simultaneously increase <b>true</b> <b>positives</b> and decrease false positives. The results from a predator-detection experiment that we performed with humans are in line with these predictions: (i) after observing the choices of the other group members, individuals both increase <b>true</b> <b>positives</b> and decrease false positives, (ii) this effect gets stronger as group size increases, (iii) individuals use a quorum threshold set between the average true- and false- positive rates of the other group members, and (iv) individuals adjust their quorum adaptively to the performance of the group. Our results have broad implications for our understanding of the ecology and evolution of group-living animals and lend themselves for applications in the human domain such as the design of improved screening methods in medical, forensic, security and business applications...|$|R
30|$|Where TP, FP and FN are the <b>true</b> <b>positives,</b> false positives {{and false}} negatives which are {{discussed}} in Sokolova and Lapalme (2009).|$|R
5000|$|Taking {{the medical}} example from above (20 <b>true</b> <b>{{positive}}s,</b> 10 false negatives, and 2030 total patients), the positive pre-test probability is calculated as: ...|$|R
2500|$|The ROC {{curve is}} created by {{plotting}} the <b>true</b> <b>positive</b> rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate {{is also known as}} sensitivity, recall or probability of detection in machine learning. The false-positive rate is also known as the fall-out or probability of false alarm and can be calculated as (1 − specificity). The ROC curve is thus the sensitivity as a function of fall-out. In general, if the probability distributions for both detection and false alarm are known, the ROC curve can be generated by plotting the cumulative distribution function (area under the probability distribution from [...] to the discrimination threshold) of the detection probability in the y-axis versus the cumulative distribution function of the false-alarm probability on the x-axis.|$|E
2500|$|On March 31, 1995, Selena {{was shot}} to death by Yolanda Saldívar, a former friend who had managed the singer's Selena Etc. boutiques. Response by the Hispanic {{community}} was comparable to the reaction of the deaths of American musicians Elvis Presley, John Lennon, and U.S. president John F. Kennedy. Newsstands were swarmed by people looking for items concerning Selena. Eight unauthorized biographies were released and six documentaries and two major companies {{were in the process of}} releasing a Selena film, all without consent from Chris Perez and the Quintanilla family. This led Abraham to produce a film based on Selena within weeks of her death, a process he found difficult since he and his family were still mourning. He believed an authorized film would [...] "put an end to all the false rumors" [...] that were circulating through the media at the time, and [...] "silence [...] from telling the wrong story." [...] He wanted [...] "the whole world to know the [...] story about [...]" [...] A.B. spoke out the family's concern about possible [...] "misinterpretation of , [...] family, and a culture" [...] by outside sources and their belief that it was imperative to release their own official film about the singer. He further said that the decision was forced upon them after learning about the unauthorized biographies and films that could have potentially misconstrue Selena's story. At the time of Abraham's decision, there were [...] "gossip and hurtful crazy things that were coming from the press" [...] about the family's plan on a film. Abraham wanted the film to immortalize Selena [...] "in a <b>true</b> <b>positive</b> and beautiful way [...] to celebrate her life [...] quiet and put to rest all [...] negative ugliness [...]" ...|$|E
5000|$|The <b>true</b> <b>positive</b> rate of a {{test for}} some disease does not tell the <b>true</b> <b>positive</b> rate {{of a group of}} people being tested. Clearly, just because a test gives 100% <b>true</b> <b>positive</b> results doesn’t mean that 100% of the people in a group will test positive. Instead, it means that the people in the group who have the disease will all (100%) test positive. To know how many people in the group have the disease, we must know the disease’s {{prevalence}}. For example, if a disease has a prevalence of 12% in some group, and a test for that disease has a <b>true</b> <b>positive</b> rate of 100%, then 12% of the people in that group will both have the disease and test positive for the disease. In other words, the rate of <b>true</b> <b>positive</b> test results in that group will be 12%. If the prevalence of a disease is 6% in some group, and my test has a <b>true</b> <b>positive</b> rate of 80%, then 80%x6%=4.8% of that group will both have the disease and test positive. In other words, the <b>true</b> <b>positive</b> rate in that group will be 4.8%. In general, the <b>true</b> <b>positive</b> rate of a disease in a group is the <b>true</b> <b>positive</b> rate of the test multiplied by the prevalence of the disease in that group. (Notice that the <b>true</b> <b>positive</b> rate by itself doesn’t say anything about the total rate of positive test results because the test might also give false positive results.) ...|$|E
5000|$|... where [...] is {{the number}} of <b>true</b> <b>positives,</b> [...] {{is the number}} of false positives, and [...] {{is the number of}} false negatives.|$|R
30|$|Here, tp is {{the number}} of <b>true</b> <b>positives</b> (foreground), fp {{is the number}} of false positives, and fn {{is the number of}} false negatives.|$|R
50|$|In a {{discipline}} in which 100 out of 1,000 hypotheses are true, studies {{with a power}} of 0.8 will find 80 and miss 20. Of the 900 incorrect hypotheses, 5% or 45 will be accepted because of type I errors. Adding the 45 false positives to the 80 <b>true</b> <b>positives</b> gives 125 positive results, or 36% specious. Dropping statistical power to 0.4, optimistic for many fields, would still produce 45 false positives but only 40 <b>true</b> <b>positives,</b> less than half.|$|R
5000|$|... 1 {{driver is}} drunk, {{and it is}} 100% certain that for that driver there is a <b>true</b> <b>positive</b> test result, so there is 1 <b>true</b> <b>positive</b> test result ...|$|E
50|$|In {{diagnostic}} testing, {{the main}} ratios used {{are the true}} column ratios - <b>True</b> <b>Positive</b> Rate and True Negative Rate - where they are known as sensitivity and specificity. In informational retrieval, the main ratios are the <b>true</b> <b>positive</b> ratios (row and column) - Positive Predictive Value and <b>True</b> <b>Positive</b> Rate - where they are known as precision and recall.|$|E
5000|$|Pretest {{probability}} = (<b>True</b> <b>positive</b> + False negative) / Total sample ...|$|E
50|$|Sensitivity is not {{the same}} as the {{precision}} or positive predictive value (ratio of <b>true</b> <b>positives</b> to combined <b>true</b> and false <b>positives),</b> which is as much a statement about the proportion of actual positives in the population being tested as it is about the test.|$|R
30|$|The {{accuracy}} of the SUVmax in the differentiation between chondroma and chondrosarcoma was evaluated, concerning the numeric value, by a ROC curve. The statistical analysis, concerning the categorical variable, was evaluated among the <b>true</b> <b>positives,</b> <b>true</b> negatives, false <b>positives</b> and false negatives values. The measure of accuracy, sensitivity, specificity, prevalence, and the predictive positive and negative were evaluated and followed in the confidence range of 95  %.|$|R
30|$|The {{use of the}} {{concepts}} {{of positive and negative}} are common in the medical and data science literature, for instance, Provost and Fawcett (2013, chap. 7). Sensitivity of a test to recognize <b>true</b> <b>positives</b> (TP/(all positives)). Specificity is the capacity to recognize true negatives (TN/(all negatives)).|$|R
5000|$|C. Seifert, P. Komisarczuk, and I. Welch, <b>True</b> <b>Positive</b> Cost Curve: A Cost-Based Evaluation Method for High-Interaction Client Honeypots, in SECURWARE, Athens, 2009.|$|E
50|$|Sensitivity or <b>True</b> <b>Positive</b> Rate (TPR), {{also known}} as recall, is the {{proportion}} of people that tested positive and are positive (<b>True</b> <b>Positive,</b> TP) {{of all the people}} that actually are positive (Condition Positive, CP = TP + FN). It {{can be seen as the}} probability that the test is positive given that the patient is sick. With higher sensitivity, fewer actual cases of disease go undetected (or, in the case of the factory quality control, fewer faulty products go to the market).|$|E
5000|$|... this {{suggests}} that a good stage must have 100% <b>true</b> <b>positive</b> and for example 40% false positive, that is accept all rectangles containing faces and erroneously mark many rectangles as potentially containing a face, to be eliminated by later stages. It {{should be noted that}} for a first stage, 100% <b>true</b> <b>positive</b> and 40% false positive still gives a lot of false negative, if only 1 in a 1000 rectangles in an image contain a face, there will still be 400 to 1 false possible faces after the first stage.|$|E
30|$|Additional {{findings}} were considered <b>true</b> <b>positives</b> when histopathological analysis of either preoperative work-up or surgical specimen has shown malignancy [invasive carcinoma or ductal {{carcinoma in situ}} (DCIS)].|$|R
50|$|Lift is {{analogous}} to information retrieval's average precision metric, if one treats the precision (fraction of the <b>positives</b> that are <b>true</b> <b>positives)</b> as the target response probability.|$|R
40|$|Abstract Background To {{assess the}} utility of {{haplotype}} association mapping (HAM) as a quantitative trait locus (QTL) discovery tool, we conducted HAM analyses for {{red blood cell count}} (RBC) and high density lipoprotein cholesterol (HDL) in mice. We then experimentally tested each HAM QTL using published crosses or new F 2 intercrosses guided by the haplotype at the HAM peaks. Results The HAM for RBC, using 33 classic inbred lines, revealed 8 QTLs; 2 of these were <b>true</b> <b>positives</b> as shown by published crosses. A HAM-guided (C 57 BL/ 6 J × CBA/J) F 2 intercross we carried out verified 2 more as <b>true</b> <b>positives</b> and 4 as false positives. The HAM for HDL, using 81 strains including recombinant inbred lines and chromosome substitution strains, detected 46 QTLs. Of these, 36 were <b>true</b> <b>positives</b> as shown by published crosses. A HAM-guided (C 57 BL/ 6 J × A/J) F 2 intercross that we carried out verified 2 more as <b>true</b> <b>positives</b> and 8 as false positives. By testing each HAM QTL for RBC and HDL, we demonstrated that 78 % of the 54 HAM peaks were <b>true</b> <b>positives</b> and 22 % were false positives. Interestingly, all false positives were in significant allelic association with one or more real QTL. Conclusion Because type I errors (false positives) can be detected experimentally, we conclude that HAM is useful for QTL detection and narrowing. We advocate the powerful and economical combined approach demonstrated here: the use of HAM for QTL discovery, followed by mitigation of the false positive problem by testing the HAM-predicted QTLs with small HAM-guided experimental crosses. </p...|$|R
