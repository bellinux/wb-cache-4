425|229|Public
5000|$|Pedro Casas, Sandrine Vaton [...] "On the use {{of random}} neural {{networks}} for <b>traffic</b> <b>matrix</b> estimation in large-scale IP networks", IWCMC 2010: 326-330, 2010.|$|E
50|$|The {{dimensioning}} process involves {{determining the}} network’s topology, routing plan, <b>traffic</b> <b>matrix,</b> and GoS requirements, and using {{this information to}} determine the maximum call handling capacity of the switches, and {{the maximum number of}} channels required between the switches. This process requires a complex model that simulates the behavior of the network equipment and routing protocols.|$|E
40|$|Absfrmt- Routing {{optimization}} {{is used to}} find a set of {{routes that}} minimizes cost (delay, utilization). Previous work has addressed this problem for {{the case of a}} known, static end-to-end <b>traffic</b> <b>matrix.</b> In the Internet, it is difficult to accurately estimate a <b>traffic</b> <b>matrix,</b> and the constantly changing nature of Internet traffic makes it costly to maintain optimal routing hy responding to traffic changes, Thus, it is of interest to maintain a set of routes that are &quot;good &quot; for B number of different possible traffic scenarios. In this paper, we explore ways to find an optimal set of routes with multiple traffic matrices to minimize expected cost. We focus, on two general approaches, source-destination muting and destination routing. In the case of source-destination routing, we extend existing methods with a single <b>traffic</b> <b>matrix</b> to solve the optimization problem with multiple traffic matrices: we extend the convex optimization solution methods for a single <b>traffic</b> <b>matrix</b> to the multiple <b>traffic</b> <b>matrix</b> case; we a h extend the gradient-based solution methods for a single <b>traffic</b> <b>matrix</b> to the multiple <b>traffic</b> <b>matrix</b> case. However, the multiple <b>traffic</b> <b>matrix</b> case requires many more control variables. In the case of destination routing, we encounter many more differences from the single <b>traffic</b> <b>matrix</b> case. The loop-free property, which is valid for the singIe <b>traffic</b> <b>matrix</b> case, is no longer valid for the multiple <b>traffic</b> <b>matrix</b> case, and it is dficult to extend existing methods for a single <b>traffic</b> <b>matrix</b> to solve the optimization prohIem with multiple traffic matrices. We show that it is NPcomplete even to determine the feasibility of multiple traffic matrices. We thus. propose and evaluate a heuristic algorithm for this case, I...|$|E
40|$|This paper {{presents}} a new publicly available dataset from GANT, the European Research and Educational Network. This dataset consists of <b>traffic</b> <b>matrices</b> built using full IGP routing information, sampled Netflow data and BGP routing information of the GANT network, one per 15 minutes interval for several months. Potential benefits of publicly available <b>traffic</b> <b>matrices</b> comprise improving {{our understanding of}} real <b>traffic</b> <b>matrices,</b> their dynamics, and to make possible the benchmarking of intradomain traffic engineering methods...|$|R
40|$|While network {{clustering}} {{is traditionally}} accomplished just {{relying on the}} topology of the network, the new traffic-aware clustering approach employs <b>traffic</b> <b>matrices</b> {{to take into account}} the intensity of the relationship between nodes. In the context of traffic-aware clustering we propose a new Evolutionary Clustering algorithm and compare it with the Spectral Filtering algorithm. We compare them using both the Modularity and the Traffic-aware Scaled Coverage metrics, and two real-world datasets, each made of 1000 <b>traffic</b> <b>matrices,</b> respectively from Abilene and Géant networks. Our experiments show that Evolutionary Clustering performs better on all <b>traffic</b> <b>matrices,</b> excepting a minor number of <b>traffic</b> <b>matrices</b> in the Abilene network when the Modularity metric is employed...|$|R
40|$|Abstract—Peer-to-Peer (P 2 P) {{applications}} {{have witnessed}} an increasing popularity in recent years, which brings new challenges to network management and traffic engineering (TE). As basic input information, P 2 P <b>traffic</b> <b>matrices</b> are of significant importance for TE. Because of the excessively {{high cost of}} direct measurement, many studies aim to model and estimate general <b>traffic</b> <b>matrices,</b> but few focus on P 2 P <b>traffic</b> <b>matrices.</b> In this paper, we propose a model to estimate P 2 P <b>traffic</b> <b>matrices</b> in operational networks. Important factors are considered, including the number of peers, the localization ratio of P 2 P traffic, and the network distance. Here, the distance can be measured with AS hop counts or geographic distance. To validate our model, we evaluate its performance using traffic traces collected from both the real P 2 P video-on-demand (VoD) and file-sharing applications. Evaluation {{results show that the}} proposed model outperforms the other two typical models for the estimation of the general <b>traffic</b> <b>matrices</b> in several metrics, including spatial and temporal estimation errors, stability in the cases of oscillating and dynamic flows, and estimation bias. To the best of our knowledge, this is the first research on P 2 P <b>traffic</b> <b>matrices</b> estimation. P 2 P <b>traffic</b> <b>matrices,</b> derived from the model, can be applied to P 2 P traffic optimization and other TE fields. Index Terms—Traffic matrix, peer-to-peer (P 2 P), traffic engineering...|$|R
40|$|The network <b>traffic</b> <b>matrix</b> {{is widely}} used in network {{operation}} and management. It is therefore of crucial importance to analyze the components {{and the structure of}} the network <b>traffic</b> <b>matrix,</b> for which several mathematical approaches such as Principal Component Analysis (PCA) were proposed. In this paper, we first argue that PCA performs poorly for analyzing <b>traffic</b> <b>matrix</b> that is polluted by large volume anomalies, and then propose a new decomposition model for the network <b>traffic</b> <b>matrix.</b> According to this model, we carry out the structural analysis by decomposing the network <b>traffic</b> <b>matrix</b> into three sub-matrices, namely, the deterministic traffic, the anomaly traffic and the noise <b>traffic</b> <b>matrix,</b> which is similar to the Robust Principal Component Analysis (RPCA) problem previously studied in [13]. Based on the Relaxed Principal Component Pursuit (Relaxed PCP) method and the Accelerated Proximal Gradient (APG) algorithm, we present an iterative approach for decomposing a <b>traffic</b> <b>matrix,</b> and demonstrate its efficiency and flexibility by experimental results. Finally, we further discuss several features of the deterministic and noise traffic. Our study develops a novel method for the problem of structural analysis of the <b>traffic</b> <b>matrix,</b> which is robust against pollution of large volume anomalies. Comment: Accepted to Elsevier Computer Network...|$|E
40|$|Abstract We {{consider}} multilayer {{traffic engineering}} (TE) strategies in IP and Optical networks. TE approach require a <b>traffic</b> <b>matrix</b> {{to compute the}} optimal topology, but it is infeasible to collect <b>traffic</b> <b>matrix</b> information for large-scale networks due the N-square problem. Hence we evaluate {{the impact of the}} <b>traffic</b> <b>matrix</b> estimation on multilayer TE. The results shows that even in the case of using the estimated <b>traffic</b> <b>matrix,</b> multilayer TE can improve the amount of traffic the network can accomodate, though the impact of estimation errors is not small. We also propose a new method to reduce the error of estima...|$|E
40|$|Abstract — A <b>traffic</b> <b>matrix</b> {{provides}} a major input to the design, {{planning and management}} of a telecommunications network. Unfortunately, computation of the <b>traffic</b> <b>matrix</b> from measurements of individual flows is extremely difficult {{due to the fact}} that the problem formulation generally leads to the need to solve an under-determined system of equations. Thus, there has been a major effort from among researchers to obtain the <b>traffic</b> <b>matrix</b> using various inference techniques. In this paper, we have studied the impact of the underlying assumptions for two methods that have shown promise in the estimation of Internet traffic demand matrices known as the Tomogravity and EM (Expectation and Maximization) methods respectively. As the Tomogravity model is a combination of the well-known gravity model and the method of least squares we have also considered the problem of obtaining a good prior <b>traffic</b> <b>matrix</b> for the least squares component of this model. We have demonstrated that the accuracy of these methods is highly dependent upon the underlying assumptions of these models, as well as the selection of an appropriate prior <b>traffic</b> <b>matrix.</b> Index Terms — <b>Traffic</b> <b>Matrix,</b> Tomogravity, EM method I...|$|E
40|$|<b>Traffic</b> <b>matrices</b> {{describe}} {{the volume of}} traffic between a set of sources and destinations within a network. These matrices are used {{in a variety of}} tasks in network planning and traffic engineering, such as the design of network topologies. <b>Traffic</b> <b>matrices</b> naturally possess complex spatiotemporal characteristics, but their proprietary nature means that little data about them is available publicly, and this situation is unlikely to change. Our goal is to develop techniques to synthesize <b>traffic</b> <b>matrices</b> for researchers who wish to test new network applications or protocols. The paucity of available data, and the desire to build a general framework for synthesis that could work in various settings requires a new look at this problem. We show how the principle of maximum entropy can be used to generate a wide variety of <b>traffic</b> <b>matrices</b> constrained by the needs of a particular task, and the available information, but otherwise avoiding hidden assumptions about the data. We demonstrate how the framework encompasses existing models and measurements, and we apply it in a simple case study to illustrate the value. Paul Tune and Matthew Rougha...|$|R
40|$|Peer-to-Peer (P 2 P) {{applications}} {{have witnessed}} an increasing popularity in recent years, which brings new challenges to network management and traffic engineering (TE). As basic input information, P 2 P <b>traffic</b> <b>matrices</b> are of significant importance for TE. Because of the excessively {{high cost of}} direct measurement. In this paper,A multipath connection model for <b>traffic</b> <b>matrices</b> in operational networks. Media files can share the peer to peer, the localization ratio of peer to peer traffic. This evaluates its performance using traffic traces collected from both the real peer to peer video-on-demand and file-sharing applications. The estimation of the general <b>traffic</b> <b>matrices</b> (TM) then used for sending the media file without traffic. Share the media file, source to destination traffic is not occur. So it give high performance and short time process...|$|R
40|$|<b>Traffic</b> <b>matrices</b> {{are used}} in many network {{engineering}} tasks, for instance optimal network design. Unfortunately, measurements of these matrices are error-prone, a problem that is exacerbated when they are extrapolated to provide the predictions used in planning. Practical network design and management should consider sensitivity to such errors, but although robust optimisation techniques exist, it seems they are rarely used, {{at least in part}} because of the difficulty in generating an ensemble of admissible <b>traffic</b> <b>matrices</b> with a controllable error level. We address this problem in our paper by presenting a fast and flexible technique of generating synthetic <b>traffic</b> <b>matrices.</b> We demonstrate the utility of the method by presenting a methodology for robust network design based on adaptation of the mean-risk analysis concept from finance. Paul Tune and Matthew Rougha...|$|R
40|$|Abstract. A <b>traffic</b> <b>matrix</b> {{represents}} the load from each ingress point to each egress point in an IP network. Although networks are engineered to tolerate some {{variation in the}} <b>traffic</b> <b>matrix,</b> large changes can lead to congested links and poor performance. The variations in the <b>traffic</b> <b>matrix</b> are caused by statistical fluctuations in the traffic entering the network and shifts in where the traffic leaves the network. For an accurate view of how the <b>traffic</b> <b>matrix</b> evolves over time, we combine fine-grained traffic measurements with a continuous view of routing, including changes in the egress points. Our approach is {{in sharp contrast to}} previous work that either inferred the <b>traffic</b> <b>matrix</b> from link-load statistics or computed it using periodic snapshots of routing tables. Analyzing seven months of data from eight vantage points in a large Internet Service Provider (ISP) network, we show that routing changes are responsible {{for the majority of the}} large traffic variations. In addition, we identify the shifts caused by internal routing changes and show that these events are responsible for the largest traffic shifts. We discuss the implications of our findings on the accuracy of previous work on <b>traffic</b> <b>matrix</b> estimation and analysis. ...|$|E
40|$|Traffic {{engineering}} and <b>traffic</b> <b>matrix</b> estimation are often treated as separate fields, even though {{one of the}} major applications for a <b>traffic</b> <b>matrix</b> is traffic engineering. In cases where a <b>traffic</b> <b>matrix</b> cannot be measured directly, it may still be estimated from indirect data (such as link measurements), but these estimates contain errors. Yet little thought has been given to the effects of inexact traffic estimates on traffic engineering. In this paper we consider how well traffic engineering works with estimated traffic matrices {{in the context of a}} specific task; namely that of optimizing network routing to minimize congestion, measured by maximum link-utilization. Our basic question is: how well is the real traffic routed if the routing is only optimized for an estimated <b>traffic</b> <b>matrix?</b> We compare against optimal routing of the real traffic using data derived from an operational tier- 1 ISP. We find that the magnitude of errors in the <b>traffic</b> <b>matrix</b> estimate is not, in itself, a good indicator of the performance of that estimate in route optimization. Likewise, the optimal algorithm for traffic engineering given knowledge of the real <b>traffic</b> <b>matrix</b> is no longer the best with only the estimated <b>traffic</b> <b>matrix</b> as input. Our main practical finding is that the combination of a known <b>traffic</b> <b>matrix</b> estimation technique and a known traffic engineering technique can get close to the optimum in avoiding congestion for the real traffic. We even demonstrate stability in the sense that routing optimized on data from one day continued to perform well on subsequent days. This stability is crucial for the practical relevance to off-line traffic engineering, as it can be performed by ISPs today...|$|E
40|$|Abstract. <b>Traffic</b> <b>matrix</b> is {{of great}} help in many network applications. However, it is very {{difficult}} to estimate the <b>traffic</b> <b>matrix</b> for a large-scale network. This is because the estimation problem from limited link measurements is highly under-constrained. We propose a simple probability model for a large-scale practical net-work. The probability model is then generalized to a general model by including random traffic data. <b>Traffic</b> <b>matrix</b> estimation is then conducted under these two models by two minimization methods. It is shown that the Normalized Root Mean Square Errors of these estimates under our model assumption are very small. For a large-scale network, the <b>traffic</b> <b>matrix</b> estimation methods also perform well. The comparison of two minimization methods shown in the simulation results complies with the analysis...|$|E
40|$|The {{estimation}} of <b>traffic</b> <b>matrices</b> in a communications network {{on the basis}} of multiperiod traffic measurements on network links is an important problem, and several solutions have been proposed when the traffic does not show dependence over time. However, extensive measurements campaigns conducted on IP networks have shown that the traffic actually exhibits long range dependence. Here a method is proposed for the {{estimation of}} <b>traffic</b> <b>matrices</b> in the case of long range dependence, and its properties are studied...|$|R
40|$|The {{estimation}} of <b>traffic</b> <b>matrices</b> in a communications network {{on the basis}} of a set of traffic measurements on the network links is a well known problem, for which a number of solutions have been proposed when the traffic does not show dependence over time, as in the case of the Poisson process. However, extensive measurements campaigns conducted on IP networks have shown that the traffic exhibits long range dependence. Here two methods are proposed for the {{estimation of}} <b>traffic</b> <b>matrices</b> in the case of long range dependence, their asymptotic properties are studied, and their relative merits are compared...|$|R
40|$|Valiant load {{balancing}} (VLB), also called two-stage {{load balancing}}, is gaining popularity as a routing scheme {{that can serve}} arbitrary <b>traffic</b> <b>matrices.</b> To date, VLB network design is well understood on a logical full-mesh topology, where VLB is optimal even when nodes or links can fail. In this paper, we address the design and capacity provisioning of arbitrary VLB network topologies. First, we introduce an algorithm to determine if VLB can serve all <b>traffic</b> <b>matrices</b> when a fixed number of arbitrary links fail, and we show {{how to find a}} mincost expansion of the network—via link upgrades or installs or both—so that it is resilient to these failures. Additionally, we propose a method to design a new VLB network under the fixed-charge network design cost model. Finally, we prove that VLB is no longer optimal on unrestricted topologies, and can require more capacity than shortest path routing to serve all <b>traffic</b> <b>matrices</b> on some topologies. These results rely on a novel theorem that characterizes the capacity VLB requires of links crossing each cut, i. e., a partition, of the network’s nodes...|$|R
40|$|International audienceAssuming {{that the}} <b>traffic</b> <b>matrix</b> {{belongs to a}} polytope, we {{describe}} a new routing paradigm where each <b>traffic</b> <b>matrix</b> is routed {{a combination of a}} number of extreme routings. This combination depends on the current <b>traffic</b> <b>matrix.</b> Multipolar routing {{can be seen as a}} generalization of both routing and robust static routing. Moreover, the time complexity of multipolar routing is under control since it depends on the number of poles (i. e. the number of extreme routings) which can be defined by the network planner...|$|E
40|$|The {{original}} publication {{is available}} at www. springerlink. comA <b>traffic</b> <b>matrix</b> represents the load from each ingress point to each egress point in an IP network. Although networks are engineered to tolerate some variation in the <b>traffic</b> <b>matrix,</b> large changes can lead to congested links and poor performance. The variations in the <b>traffic</b> <b>matrix</b> are caused by statistical fluctuations in the traffic entering the network and shifts in where the traffic leaves the network. For an accurate view of how the <b>traffic</b> <b>matrix</b> evolves over time, we combine fine-grained traffic measurements with a continuous view of routing, including changes in the egress points. Our approach is {{in sharp contrast to}} previous work that either inferred the <b>traffic</b> <b>matrix</b> from link-load statistics or computed it using periodic snapshots of routing tables. Analyzing seven months of data from eight vantage points in a large Internet Service Provider (ISP) network, we show that routing changes are responsible {{for the majority of the}} large traffic variations. In addition, we identify the shifts caused by internal routing changes and show that these events are responsible for the largest traffic shifts. We discuss the implications of our findings on the accuracy of previous work on <b>traffic</b> <b>matrix</b> estimation and analysis. Renata Teixeira, Nick Duffield, Jennifer Rexford and Matthew Rougha...|$|E
40|$|Copyright 2003 ACMTraffic {{engineering}} and <b>traffic</b> <b>matrix</b> estimation are often treated as separate fields, even though {{one of the}} major applications for a <b>traffic</b> <b>matrix</b> is traffic engineering. In cases where a <b>traffic</b> <b>matrix</b> cannot be measured directly, it may still be estimated from indirect data (such as link measurements), but these estimates contain errors. Yet little thought has been given to the effects of inexact traffic estimates on traffic engineering. In this paper we consider how well traffic engineering works with estimated traffic matrices {{in the context of a}} specific task; namely that of optimizing network routing to minimize congestion, measured by maximum link-utilization. Our basic question is: how well is the real traffic routed if the routing is only optimized for an estimated <b>traffic</b> <b>matrix?</b> We compare against optimal routing of the real traffic using data derived from an operational tier- 1 ISP. We find that the magnitude of errors in the <b>traffic</b> <b>matrix</b> estimate is not, in itself, a good indicator of the performance of that estimate in route optimization. Likewise, the optimal algorithm for traffic engineering given knowledge of the real <b>traffic</b> <b>matrix</b> is no longer the best with only the estimated <b>traffic</b> <b>matrix</b> as input. Our main practical finding is that the combination of a known <b>traffic</b> <b>matrix</b> estimation technique and a known traffic engineering technique can get close to the optimum in avoiding congestion for the real traffic. We even demonstrate stability in the sense that routing optimized on data from one day continued to perform well on subsequent days. This stability is crucial for the practical relevance to off-line traffic engineering, as it can be performed by ISPs today. Matthew Roughan, Mikkel Thorup, Yin Zhan...|$|E
40|$|Network <b>traffic</b> <b>matrices</b> are {{important}} for various network planning and management operations. Previous work for estimation of <b>traffic</b> <b>matrices</b> is based on either link load records obtained from SNMP or flow level sampled data available from Net-flow records. Sampled flow-level data provides us good approximations for <b>traffic</b> <b>matrices,</b> however, static sampling rates are not desired. People have proposed sampling solutions with dynamic sampling rates which adapt according to the changing behavior of the network. SNMP link level reports, {{on the other hand}} are computationally less extensive but do not provide optimum solutions for network traffic estimation. This work addresses the problem of measurement in a wider scope and we propose to study merging together data from multiple sources and using it effectively for network monitoring and measurement tasks. We address this problem in both time and spatial domain and intend to develop a framework for dynamically choosing monitoring points in network and blend the existing and readily information from different sources for network measurement. This information mix from multiple sources can be used for more promising and generalized anomaly detection models. We address this problem in three dimensional space of time, space and application level details...|$|R
40|$|Recently {{developed}} {{techniques have}} been very successful in accurately estimating intra-Autonomous System (AS) <b>traffic</b> <b>matrices.</b> These techniques rely on link measurements, flow measurements, or routing-related data to infer traffic demand between every pair of ingress-egress points of an AS. They also illustrate an inherent mismatch between data needed (e. g., ingress-egress demand) and data most readily available (e. g., link measurements). This mismatch is exacerbated {{when we try to}} estimate inter-AS <b>traffic</b> <b>matrices,</b> i. e., snapshots of Internet-wide traffic behavior over coarse time scale (a week or longer) between ASs. We present a method for modeling inter-AS traffic demand that relies exclusively on publicly available/obtainable measurements. We first perform extensive Internet-wide measurement experiments to infer the "business rationale" of individual ASs. We then use these business profiles to characterize individual ASs, classifying them by their "utility" into ASs providing Web hosting, residential access, and business access. We rank ASs by their utilities which drive our gravity-model based approach for generating inter-AS traffic demand. In a first attempt to validate our methodology, we test our inter-AS traffic generation method on an inferred Internet AS graph and present some preliminary findings about the resulting inter-AS <b>traffic</b> <b>matrices...</b>|$|R
40|$|International audienceWe {{consider}} {{the problem of}} partitioning of a traffic demand polytope using a hyper-plane. The polytope is divided into parts, and different routing schemes are applied while dealing with <b>traffic</b> <b>matrices</b> {{from different parts of}} the polytope. Different demands cannot share resources, and reservation vectors {{on opposite sides of the}} hyperplane have to be identical. We provide a polynomial time algorithm solving the presented problem when a traffic demand polytope is defined as a convex hull of a known set of <b>traffic</b> demand <b>matrices...</b>|$|R
40|$|Abstract—In this letter, {{we develop}} a novel {{network-wide}} traffic analysis methodology, named Stable Principal Compo-nent Pursuit with Time-Frequency Constraints (SPCP-TFC), for extracting the baseline of a <b>traffic</b> <b>matrix.</b> Following a refined <b>traffic</b> <b>matrix</b> decomposition model, we present new time-frequency constraints to extend Stable Principal Component Pursuit (SPCP), and design an efficient numerical algorithm for SPCP-TFC. At last, we evaluate the SPCP-TFC method by abundant simulations, and show it has superior performance than other traffic baseline {{methods such as}} RBL and PCA. Index Terms—baseline of <b>traffic</b> <b>matrix,</b> robust PCA, time-frequency constraint, numerical algorithm, simulation. I...|$|E
40|$|The judicious {{allocation}} of <b>traffic</b> <b>matrix</b> sources/destinations to nodes of an exemplar optical packet switching architecture, the Manhattan street network, is studied in this paper. The node placement optimisation (NPO) problem is intractable, hence simulated annealing {{is used to}} find (near) optimal solutions expeditiously. A number of non-uniform traffic patterns are considered, facilitating {{the study of the}} innate parameters of a <b>traffic</b> <b>matrix</b> that affect the optimisation results. A salient finding is that, regardless of the underlying traffic pattern, the efficacy of NPO is correlated to the coefficient of variation of the <b>traffic</b> <b>matrix...</b>|$|E
40|$|<b>Traffic</b> <b>matrix</b> is {{of great}} help in many network applications. However, it is very {{difficult}} to estimate the <b>traffic</b> <b>matrix</b> for a large-scale network. This is because the estimation problem from limited link measurements is highly under- constrained. We propose a simple probability model for a large-scale practical net- work. The probability model is then generalized to a general model by including random traffic data. <b>Traffic</b> <b>matrix</b> estimation is then conducted under these two models by two minimization methods. It is shown that the Normalized Root Mean Square Errors of these estimates under our model assumption are very small. For a large-scale network, the <b>traffic</b> <b>matrix</b> estimation methods also perform well. The comparison of two minimization methods shown in the simulation results complies with the analysis. Hui Tian, Yingpeng Sang, Hong Shen and Chunyue Zho...|$|E
40|$|In this study, {{we propose}} Renyi cross entropy to analyze <b>matrix</b> <b>traffic</b> and detect anomaly rather than other entropy metrics, such as Shannon entropy, used {{extensively}} in many earlier studies. At first, we {{introduce a new}} type of traffic termed IF-flow (internal flow) collected in router. IF-flow can make the attack traffic more conspicuous in a large number of normal traffics, which makes attacks, especially DDoS attacks, spotted more easily. Then, the analysis of Renyi cross entropy of IF-flow <b>matrix</b> <b>traffic,</b> Abilene <b>matrix</b> <b>traffic</b> confirms that <b>matrix</b> <b>traffic</b> distribution has local stability in time. This conclusion provides a guidance to accurately detect anomaly. Finally, Renyi cross entropy is used to detect DDoS attacks existed in IF-flow testing data set and Abilene testing data set. The results of detection experiments show Renyi cross entropy based method can detect DDoS attacks at the beginning with higher detection rate, lower false alarm than Shannon entropy based method...|$|R
40|$|When {{designing}} or upgrading {{a communication}} network, operators {{are faced with}} a major issue, as uncertainty on communication demands makes it difficult to correctly provision the network capacity. When a probability on <b>traffic</b> <b>matrices</b> is given, finding the cheapest capacity allocation that guarantees, within a prescribed level of confidence, that each arc can support the traffic demands peaks turns out to be, in general, a difficult non convex optimization problem belonging to the class of chance constrained problems. Drawing from some very recent results in the literature we highlight the relationships between chance constrained network design problems and robust network optimization. We then compare several different ways to build uncertainty sets upon deviation measures, comprised the recently proposed backward and forward deviation measures that capture possible asymmetries of the traffic demands distribution. We report results of a computational study aimed at comparing the performance of different models when built upon the same set of historical <b>traffic</b> <b>matrices...</b>|$|R
40|$|We {{investigate}} a network design problem under traffic uncertainty that arises when provisioning Virtual Private Networks (VPNs) : given {{a set of}} terminals that must communicate with one another, {{and a set of}} possible <b>traffic</b> <b>matrices,</b> sufficient capacity has to be reserved on the links of the large underlying public network to support all possible <b>traffic</b> <b>matrices</b> while minimizing the total reservation cost. The problem admits several versions depending on the desired topology of the reserved links, {{and the nature of the}} traffic data uncertainty. We present compact linear mixed-integer programming formulations for the problem with the classical hose traffic model and for a less conservative robust variant relying on the traffic statistics that are often available. These flow-based formulations allow us to solve optimally medium-to-large instances with commercial MIP solvers. We also propose a combined branch-and-price and cutting-plane algorithm to tackle larger instances. Computational results obtained for several classes of instances are reported and discussed. © 2006 Wiley Periodicals, Inc...|$|R
40|$|A <b>traffic</b> <b>matrix</b> {{provides}} a major input to the design, {{planning and management}} of a telecommunications network. Unfortunately, computation of the <b>traffic</b> <b>matrix</b> from measurements of individual flows is extremely difficult {{due to the fact}} that the problem formulation generally leads to the need to solve an under-determined system of equations. Thus, there has been a major effort from among researchers to obtain the <b>traffic</b> <b>matrix</b> using various inference techniques. In this paper, we have studied the impact of the underlying assumptions for two methods that have shown promise in the estimation of Internet traffic demand matrices known as the Tomogravity and EM (Expectation and Maximization) methods respectively. As the Tomogravity model is a combination of the well-known gravity model and the method of least squares we have also considered the problem of obtaining a good prior <b>traffic</b> <b>matrix</b> for the least squares component of this model. We have demonstrated that the accuracy of these methods is highly dependent upon the underlying assumptions of these models, as well as the selection of an appropriate prior <b>traffic</b> <b>matrix...</b>|$|E
40|$|A <b>traffic</b> <b>matrix</b> {{represents}} the load from each ingress point to each egress point in an IP network. Although networks are engineered to tolerate some {{variation in the}} <b>traffic</b> <b>matrix,</b> large changes can lead to congested links and poor performance. The variations in the <b>traffic</b> <b>matrix</b> are caused by statistical fluctuations in the traffic entering the network and shifts in where the traffic leaves the network. For an accurate view of how the <b>traffic</b> <b>matrix</b> evolves over time, we combine fine-grained traffic measurements with a continuous view of routing, including changes in the egress points. Our approach is {{in sharp contrast to}} previous work that either inferred the <b>traffic</b> <b>matrix</b> from link-load statistics or computed it using periodic snapshots of routing tables. Analyzing seven months of data from eight vantage points in a large Internet Service Provider (ISP) network, we show that routing changes are responsible {{for the majority of the}} large traffic variations. In addition, we identify the shifts caused by internal routing changes and show that these events are responsible for the largest traffic shifts...|$|E
40|$|Abstract — It is {{very hard}} to design a network with {{performance}} guarantees, partly because it is hard to estimate the future <b>traffic</b> <b>matrix.</b> With no knowledge of the <b>traffic</b> <b>matrix,</b> one can use the Valiant Load-balancing (VLB) architecture which can support any traffic satisfying the node capacity constraints. To interconnect N nodes of capacity r, the VLB architecture requires a logical full mesh of link capacity c = 2 r N. Uniform load-balancing can guarantee throughput, but is not necessary if the <b>traffic</b> <b>matrix</b> is known, in which case the amount of load-balancing can be reduced. In this paper we study adaptive load-balancing in two cases: when only local traffic information is known to a node, and when the network <b>traffic</b> <b>matrix</b> is known. We give linear programming formulations to maximize directly routed traffic in both cases, so as to reduce the average hop count of packets. In the case when the <b>traffic</b> <b>matrix</b> is known, we show that direct routing is not always feasible with c = 2...|$|E
40|$|Most {{research}} on <b>traffic</b> <b>matrices</b> (TM) {{has focused on}} finding models that help with inference, but not with other important tasks such as synthesis of TMs, traffic prediction, or anomaly detection. In this paper we approach the problem of a general model for <b>traffic</b> <b>matrices,</b> and argue that such a model must be sparse, i. e., have {{a small number of}} parameters in comparison {{to the size of the}} TM. A Multi-Resolution Analysis (MRA) of TMs can provide such a sparse representation. The Diffusion Wavelet (DW) transform is a good choice as a MRA tool here, because it inherently adapts to the structure of the underlying network. The paper describes our construction of the two-dimensional version of the DW transform and shows how to use it for our proposed MRA of TMs. The results obtained with operational networks confirm the sparseness of the DW-based TM analysis approach and its applicability to other TM-related tasks. Categories and Subject Descriptor...|$|R
40|$|Arguably, one of {{the most}} {{cumbersome}} tasks required to run a network simulation is the setup of a complete simulation scenario and its implementation in the target simulator. This process includes selecting a topology, provision it with all required parameters and, finally, configure traffic sources or generate <b>traffic</b> <b>matrices.</b> Many tools exist to address some of these tasks. However, most of them do not provide methods for configuring network and traffic parameters, while others only support a specific simulator. As a consequence, a user often needs to implement the desired features personally, which is both time-consuming and error-prone. To address these issues, we present the Fast Network Simulation Setup (FNSS) toolchain. It provides capabilities for parsing topologies from datasets or generating them synthetically, assign desired configuration parameters and generate <b>traffic</b> <b>matrices</b> or event schedules. It also provides APIs for a number of programming languages and network simulators to easily deploy the simulation scenario in the target simulator...|$|R
40|$|Copyright © 2008 ACMMost {{research}} on <b>traffic</b> <b>matrices</b> (TM) {{has focused on}} finding models that help with inference, but not with other important tasks such as synthesis of TMs, traffic prediction, or anomaly detection. In this paper we approach the problem of a general model for <b>traffic</b> <b>matrices,</b> and argue that such a model must be sparse, i. e., have {{a small number of}} parameters in comparison {{to the size of the}} TM. A Multi-Resolution Analysis (MRA) of TMs can provide such a sparse representation. The Diffusion Wavelet (DW) transform is a good choice as a MRA tool here, because it inherently adapts to the structure of the underlying network. The paper describes our construction of the two-dimensional version of the DW transform and shows how to use it for our proposed MRA of TMs. The results obtained with operational networks confirm the sparseness of the DW-based TM analysis approach and its applicability to other TM-related tasks. David Rincon; Matthew Roughan and Walter Willinge...|$|R
