10000|7470|Public
5|$|A back-building thunderstorm, {{commonly}} referred to as a training thunderstorm, is a thunderstorm in which new development takes place on the upwind side (usually the west or southwest side in the Northern Hemisphere), such that the storm seems to remain stationary or propagate in a backward direction. Though the storm often appears stationary on radar, or even moving upwind, this is an illusion. The storm is really a multi-cell storm with new, more vigorous cells that form on the upwind side, replacing older cells that continue to drift downwind. When this happens, catastrophic flooding is possible. In Rapid City, South Dakota, in 1972, an unusual alignment of winds at various levels of the atmosphere combined to produce a continuously <b>training</b> <b>set</b> of cells that dropped an enormous quantity of rain upon the same area, resulting in devastating flash flooding. A similar event occurred in Boscastle, England, on 16 August 2004.|$|E
5|$|Although musically precocious, Tchaikovsky {{was educated}} {{for a career}} as a civil servant. There was scant {{opportunity}} for a musical career in Russia at that time and no system of public music education. When an opportunity for such an education arose, he entered the nascent Saint Petersburg Conservatory, from which he graduated in 1865. The formal Western-oriented teaching he received there set him apart from composers of the contemporary nationalist movement embodied by the Russian composers of The Five, with whom his professional relationship was mixed. Tchaikovsky's <b>training</b> <b>set</b> him on a path to reconcile what he had learned with the native musical practices to which he had been exposed from childhood. From this reconciliation he forged a personal but unmistakably Russian style—a task that did not prove easy. The principles that governed melody, harmony and other fundamentals of Russian music ran completely counter to those that governed Western European music; this seemed to defeat the potential for using Russian music in large-scale Western composition or for forming a composite style, and it caused personal antipathies that dented Tchaikovsky's self-confidence. Russian culture exhibited a split personality, with its native and adopted elements having drifted apart increasingly since the time of Peter the Great. This resulted in uncertainty among the intelligentsia about the country's national identity—an ambiguity mirrored in Tchaikovsky's career.|$|E
5|$|Larger drugs (>500 Da) can {{provoke a}} {{neutralizing}} immune response, {{particularly if the}} drugs are administered repeatedly, or in larger doses. This limits the effectiveness of drugs based on larger peptides and proteins (which are typically larger than 6000 Da). In some cases, the drug itself is not immunogenic, but may be co-administered with an immunogenic compound, as is sometimes the case for Taxol. Computational methods {{have been developed to}} predict the immunogenicity of peptides and proteins, which are particularly useful in designing therapeutic antibodies, assessing likely virulence of mutations in viral coat particles, and validation of proposed peptide-based drug treatments. Early techniques relied mainly on the observation that hydrophilic amino acids are overrepresented in epitope regions than hydrophobic amino acids; however, more recent developments rely on machine learning techniques using databases of existing known epitopes, usually on well-studied virus proteins, as a <b>training</b> <b>set.</b> A publicly accessible database has been established for the cataloguing of epitopes from pathogens known to be recognizable by B cells. The emerging field of bioinformatics-based studies of immunogenicity is referred to as immunoinformatics. Immunoproteomics is the study of large sets of proteins (proteomics) involved in the immune response.|$|E
50|$|Over the years, three {{versions}} of rolling stock were used on this line, {{as well as}} on the through services between Nanshijiao and Beitou. Originally, the line used a large fleet of C301 <b>train</b> <b>sets.</b> In 1999, only a few C341 <b>train</b> <b>sets</b> were used. In 2007, some C371 <b>train</b> <b>sets</b> were introduced. Today, the entire fleet used on this line is the C371 <b>train</b> <b>sets</b> after the original C301 <b>train</b> <b>sets</b> were confined to the Tamsui and Xindian Lines upon the opening of Dongmen Station on September 30, 2012.|$|R
25|$|This shows Transrapid <b>train</b> <b>sets</b> {{are likely}} to cost over {{twice as much as}} ICE 3 {{conventional}} fast rail <b>train</b> <b>sets</b> at this time. However each Transrapid <b>train</b> <b>set</b> is more than twice as efficient due to their faster operating speed and acceleration according to UK Ultraspeed. In their case study only 44% as many Transrapid <b>train</b> <b>sets</b> are needed to deliver the same amount of passengers as conventional high-speed trains.|$|R
40|$|The {{passenger}} <b>train</b> <b>sets</b> is {{the carrier}} of railway passenger transport production and reasonable {{use of the}} passenger <b>train</b> <b>sets</b> {{is one of the}} key goals of railway transportation plan. In order to improve the operation efficiency of passenger <b>train</b> <b>sets,</b> optimization model of railway passenger <b>train</b> <b>sets</b> assignment have been built to minimize the non-production staying time of passenger <b>train</b> <b>sets</b> at passenger station based on established train diagram and established configuration of <b>train</b> <b>sets</b> system. On that basis, considering that the parameters of simulated Annealing Algorithm (SA) directly affect the efficiency and precision of solving, SA parameters is optimized based on nested partitions, then improved simulated annealing algorithm (ISA) is designed to solve this model. Finally, a case study has been carried out taking Zhengzhou railway station of china as an example in order to testify validity of this model and its algorithm by using calculating and comparing analysis and further solved practical problems is analyzed. The results show that the number of passenger <b>train</b> <b>sets</b> required and carriage staying time at passenger station are reduced and this model and its algorithm can be used to optimize railway passenger <b>train</b> <b>sets</b> assignment to improve efficiency of railway passenger <b>train</b> <b>sets</b> assignment...|$|R
25|$|Stacks of LSTM RNNs {{trained by}} connectionist {{temporal}} classification (CTC) can find an RNN weight matrix that maximizes {{the probability of}} the label sequences in a <b>training</b> <b>set,</b> given the corresponding input sequences. CTC achieves both alignment and recognition.|$|E
25|$|A {{probabilistic}} context free grammar {{consists of}} terminal and nonterminal variables. Each feature to be modeled has a production rule that is assigned a probability estimated from a <b>training</b> <b>set</b> of RNA structures. Production rules are recursively applied until only terminal residues are left.|$|E
25|$|A two-car set was {{converted}} from former Keihin-Tōhoku Line end cars in 2008 {{for use as}} a staff <b>training</b> <b>set</b> at JR East's Ōmiya Training Center. This replaced the former 103 series two-car set previously used there. The set is formed of KuMoHa209-76 + KuMoHa208-76, and is finished in the shōnan green/orange colour scheme.|$|E
5000|$|... 13 October 2006: Prasarana signs an {{agreement}} with a Bombardier-Hartasuma joint venture {{for the purchase of}} 22 four-car <b>train</b> <b>sets</b> for the Kelana Jaya Line with an option to purchase an additional 13 <b>train</b> <b>sets</b> for RM1.2 billion. First 22 <b>train</b> <b>sets</b> to be delivered in 2008.|$|R
40|$|With {{the rapid}} {{development}} of high-speed railway in China, {{the problem of}} motor <b>train</b> <b>set</b> assignment and maintenance scheduling {{is becoming more and}} more important for transportation organization. This paper focuses on considering the special maintenance items of motor <b>train</b> <b>set</b> and mainly meets the two maintenance cycle limits on aspects of mileage and time for each item. And then, a 0 - 1 integer programming model for motor <b>train</b> <b>set</b> assignment and maintenance scheduling is proposed, which aims at maximizing the accumulated mileage before each maintenance and minimizing the number of motor <b>train</b> <b>sets.</b> Restrictions of the model include the matching relation between motor <b>train</b> <b>sets</b> and routes as well as that between motor <b>train</b> <b>sets</b> and maintenance items and maintenance capacity of motor <b>train</b> <b>set</b> depot. A heuristic solution strategy based on particle swarm optimization is also proposed to solve the model. In the end, a case study is designed based on the background of Beijing south depot in China, and the result indicates that the model and algorithm proposed in this paper could solve the problem of motor <b>train</b> <b>set</b> assignment and maintenance scheduling effectively...|$|R
50|$|Montenegro Railways have {{received}} six class 412/416 EMU <b>train</b> <b>sets</b> {{which have been}} purchased by Yugoslav Railways for ŽTP Titograd in 1985. In 2015, there are five operational <b>train</b> <b>sets,</b> with two recently overhauled. Main depot is at Podgorica. One <b>train</b> <b>set</b> was destroyed in the Bioče disaster in 2006.|$|R
25|$|Mihalić's {{entry into}} {{athletics}} was almost coincidental. In 1940, {{one of the}} events of the Workers' Sports Games in Zagreb was a cross country race. Mihalić was nominated for the race by his football club Grafičar as he was their fastest player. Despite the fact that he entered the first foot race in his life without any training, he placed second out of approximately 200 participants, narrowly losing to an experienced athlete. This event was crucial in his decision to leave cycling and take up athletics. He joined the Concordia Zagreb athletics club and after only several months of <b>training</b> <b>set</b> his first national record in the 5000 meters, followed shortly by a national record in the 10,000 meters.|$|E
25|$|These {{can be used}} {{to output}} object {{bounding}} boxes {{in the form of a}} binary mask. They are also used for multi-scale regression to increase localization precision. DNN-based regression can learn features that capture geometric information, in addition to serving as a good classifier. They remove the requirement to explicitly model parts and their relations. This helps to broaden the variety of objects that can be learned. The model consists of multiple layers, each of which has a rectified linear unit as its activation function for non-linear transformation. Some layers are convolutional, while others are fully connected. Every convolutional layer has an additional max pooling. The network is trained to minimize L2 error for predicting the mask ranging over the entire <b>training</b> <b>set</b> containing bounding boxes represented as masks.|$|E
25|$|Applications whose goal is {{to create}} a system that generalizes well to unseen examples, face the {{possibility}} of over-training. This arises in convoluted or over-specified systems when the capacity of the network significantly exceeds the needed free parameters. Two approaches address over-training. The first is to use cross-validation and similar techniques to check for the presence of over-training and optimally select hyperparameters to minimize the generalization error. The second is to use some form of regularization. This concept emerges in a probabilistic (Bayesian) framework, where regularization can be performed by selecting a larger prior probability over simpler models; but also in statistical learning theory, where the {{goal is to}} minimize over two quantities: the 'empirical risk' and the 'structural risk', which roughly corresponds to the error over the <b>training</b> <b>set</b> and the predicted error in unseen data due to overfitting.|$|E
50|$|<b>Train</b> <b>set</b> 013/014 {{had been}} {{previously}} split and modified to serve as 3-car formations on the Xinbeitou Branch Line. When new 3-car formation C371 cars were made, <b>train</b> <b>set</b> 013/014 was subsequently re-joined and put back into normal service on Line 2. <b>Train</b> <b>set</b> 013/014 is also equipped with IGBT-VVVF inverters.|$|R
30|$|In <b>training</b> <b>sets</b> for Holiday and Oxford 5 K, we use Flickr 60 k [19] and Paris {{datasets}} [16] as vocabulary <b>training</b> <b>sets,</b> respectively.|$|R
5000|$|... #Caption: The {{original}} TOGO-built {{train of}} The Roller Coaster; this <b>train</b> <b>set</b> {{has been replaced}} with a new <b>train</b> <b>set</b> built by Premier Rides ...|$|R
2500|$|... where [...] is the {{hypothesis}} induced by learning algorithm [...] trained on <b>training</b> <b>set</b> [...] with hyperparameters [...] Instance hardness provides a continuous value for determining if an instance is an outlier instance.|$|E
2500|$|Transductive support vector {{machines}} extend SVMs in {{that they}} could also treat partially labeled data in semi-supervised learning by following the principles of transduction. Here, {{in addition to the}} <b>training</b> <b>set</b> , the learner is also given a set ...|$|E
2500|$|Pareidolia also {{arises in}} {{computer}} vision, specifically in image recognition programs, which can spuriously detect features. In {{the case of}} an artificial neural network, higher-level features correspond to more recognizable features, and enhancing these features brings out what the computer sees. These reflect the <b>training</b> <b>set</b> of images that the network has [...] "seen" [...] previously.|$|E
5|$|The three {{individual}} {{cars that}} make up a <b>train</b> <b>set</b> are distinguished by the second digit. For example, <b>train</b> <b>set</b> 3001 consists of the cars 3101, 3201, and 3301.|$|R
40|$|Optimization of railway {{passenger}} <b>train</b> <b>set</b> {{assignment is}} a complicated system engineering that is influenced by multitudinous factors. To improve the use efficiency of <b>train</b> <b>set,</b> the impact of train delay on <b>train</b> <b>set</b> assignment was analyzed, and the optimization model of railway passenger <b>train</b> <b>set</b> assignment have been built according to train delay propagation, and on that basis, optimization algorithm have also been put forward based on simulated annealing algorithm. Finally, a case study {{has been carried out}} taking four passenger stations in railway network as an example in order to testify validity, objectivity and applicability of this model by using calculating and comparing analysis. The results show that this model could improve the efficiency of railway passenger <b>train</b> <b>set</b> assignment...|$|R
50|$|The three {{individual}} {{cars that}} make up a <b>train</b> <b>set</b> are distinguished by the second digit. For example, <b>train</b> <b>set</b> 3001 consists of the cars 3101, 3201, and 3301.|$|R
2500|$|Villiers took {{very well}} to the <b>training</b> <b>set</b> by his mother: he could dance and fence well, spoke a little French, and was overall an {{excellent}} student. Bishop Godfrey Goodman declared Villiers to be [...] "the handsomest-bodied man in all of England; his limbs so well compacted, and his conversation so pleasing, and of so sweet a disposition".|$|E
2500|$|Assigning {{probability}} {{to production}} rules makes a PCFG. These probabilities are informed by observing distributions on a <b>training</b> <b>set</b> of similar composition {{to the language}} to be modeled. On most samples of broad language, probabilistic grammars where probabilities are estimated from data typically outperform hand-crafted grammars. CFGs when contrasted with PCFGs are not applicable to RNA structure prediction because while they incorporate sequence-structure relationship they lack the scoring metrics that reveal a sequence structural potential ...|$|E
2500|$|Some {{work has}} also {{examined}} outliers for nominal (or categorical) data. In {{the context of}} a set of examples (or instances) in a data set, instance hardness measures the probability that an instance will be misclassified ( [...] where [...] is the assigned class label and [...] represent the input attribute value for an instance in the <b>training</b> <b>set</b> [...] ). Ideally, instance hardness would be calculated by summing over the set of all possible hypotheses : ...|$|E
50|$|The Rock Island {{assigned}} the two Rocket <b>train</b> <b>sets</b> from the Kansas City-Minneapolis Rocket, and one <b>train</b> <b>set</b> from the Kansas City-Dallas Texas Rocket {{was transferred to}} the new Twin Star Rocket. The other Texas Rocket <b>train</b> <b>set</b> then began operating a daily round trip Rocket service between Oklahoma City and Kansas City. Another of the three-car Rocket trains operated an Oklahoma City-Dallas round trip daily.|$|R
40|$|This {{paper is}} devoted to the problem of accumulating the <b>train</b> <b>sets</b> at a sorting station. An {{analysis}} of three specific processes of accumulating the <b>train</b> <b>sets</b> has been performed taking into consideration their varieties. The calculation formulas for wagon-hours of such an accumulating according to each scheme are given. The dependence between the <b>train</b> <b>set</b> accumulation parameter and the quantity of wagons in the <b>train</b> <b>set</b> that is departing from a station has been determined. It has been also determined the influence of the above mentioned parameter on the duration of lost time of wagons at a sorting station...|$|R
30|$|Experiments were {{conducted}} on five different <b>training</b> <b>sets</b> with 50, 100, 200, 400, and 800 utterances. Additionally, a fixed set of 200 utterances, {{not included in the}} <b>training</b> <b>sets,</b> was used for testing.|$|R
2500|$|The {{final step}} of {{knowledge}} discovery from data is {{to verify that}} the patterns produced by the data mining algorithms occur in the wider data set. Not all patterns found by the data mining algorithms are necessarily valid. It is common for the data mining algorithms to find patterns in the <b>training</b> <b>set</b> which are not present in the general data set. This is called overfitting. To overcome this, the evaluation uses a test set of data on which the data mining algorithm was not trained. The learned patterns are applied to this test set, and the resulting output is compared to the desired output. For example, a data mining algorithm trying to distinguish [...] "spam" [...] from [...] "legitimate" [...] emails would be trained on a <b>training</b> <b>set</b> of sample e-mails. Once trained, the learned patterns would {{be applied to the}} test set of e-mails on which it had not been trained. The accuracy of the patterns can then be measured from how many e-mails they correctly classify. A number of statistical methods may be used to evaluate the algorithm, such as ROC curves.|$|E
2500|$|A common {{choice is}} a Gaussian kernel, {{which has a}} single {{parameter}} '. The best combination of C and [...] is often selected by a grid search with exponentially growing sequences of C and ', for example, [...] Typically, each combination of parameter choices is checked using cross validation, and the parameters with best cross-validation accuracy are picked. Alternatively, recent work in Bayesian optimization {{can be used to}} select C and ' , often requiring the evaluation of far fewer parameter combinations than grid search. The final model, which is used for testing and for classifying new data, is then trained on the whole <b>training</b> <b>set</b> using the selected parameters.|$|E
2500|$|In the Superman mythos, Byrne wrote Clark Kent {{as having}} a more {{aggressive}} and extroverted personality than previously depicted, even making him a top high-school football player. Byrne came up with explanations for how Superman's disguise works, such as the public simply does not realize {{that he has a}} secret identity since he is unmasked, that Superman would vibrate his face via his super speed in order to blur his image to photographers, and having Kent keep a weight <b>training</b> <b>set</b> around to explain how the human and presumably weaker Kent could have a frame as massive as Superman's. Byrne's Superman felt that his deepest roots were on Earth, and that his home planet of [...] "Krypton is anathema to him".|$|E
40|$|Splits of <b>train</b> <b>set</b> {{and test}} set {{given in the}} dataset. In MIT Indoor 67 {{experiment}} [6], the training size is 100 images per category. Experiment is ran on 1 split of <b>train</b> <b>set</b> and test set given in the dataset. On the 10 splits randomly generated by ourself, the classification accuracy is 69. 10 %± 1. 62 % In the Scene 15 experiment [3], the training size is 50 images per category. Experiments are ran on 10 random splits of <b>train</b> <b>set</b> and test set. In the SUN Attribute experiment [5], the training size is 150 images per attribute. The report result is average precision. The splits of <b>train</b> <b>set</b> and test set are given in the paper. In Caltech 101 and Caltech 256 experiment [1, 2], the training size is 30 images per category. The experiments are ran on 10 random splits of <b>train</b> <b>set</b> and test set. In Stanford Action 40 experiment [8], the training size is 100 images per category. Experiments are ran on 10 random splits of <b>train</b> <b>set</b> and test set. The reported result is classification accuracy...|$|R
3000|$|... (RQ 1.1) How can <b>training</b> <b>sets</b> for {{surrogate}} {{models of}} aggregated flexibilities from downstream units be sampled avoiding the distribution folding problem, which occurs with the naive approach of combining independently sampled <b>training</b> <b>sets</b> from downstream units? [...]...|$|R
5|$|The first 99 <b>train</b> <b>sets</b> were {{numbered}} 3001 to 3099. When the 100th set {{was delivered}} the numbering continued with 30100 {{and will continue}} with 30101 and so on. Many of the <b>train</b> <b>sets</b> have also been given a girls' name.|$|R
