10|10|Public
40|$|International audienceWe {{introduce}} two throughput metrics {{referred to}} as flow-and time-sampled through-puts. The former gives the <b>throughput</b> <b>statistics</b> of an arbitrary flow while the latter weights these <b>throughput</b> <b>statistics</b> by the flow durations. Under fair sharing assumptions, the latter is shown {{to coincide with the}} steady-state instantaneous throughput weighted by the number of flows, which provides a useful means to measure and estimate it. We give some generic properties satisfied by both metrics and illustrate their difference on a few examples...|$|E
40|$|Abstract: Traditional network {{management}} has {{to cope with}} the disadvantages that come along with a central management unit. In this paper we present a framework for distributed {{network management}} using a p 2 p overlay network consisting of several Distributed Network Agents. The framework provides a reliable and scalable basis for distributed test, like e. g. the identification of performance degradation in IP networks using <b>throughput</b> <b>statistics.</b> The framework is not intended to replace the central net-work manager, but rather to support it in surveying the status of the corresponding network. ...|$|E
40|$|A land mobile {{satellite}} {{demonstration system}} is described. It ulilizes the INMARSAT MARECS B 2 satellite at 26 degrees W. The system provides data transmission using a poll-response protocol with error detection and retransmission at 200 b/s rate. For most tests a 1. 8 inch monopole antenna was used, {{along with a}} satellite EIRP normally used for four voice channels. A brief summary of the results are given and the overall system consisting of three elements {{in addition to the}} satellite (the mobile unit, the base station, and the office terminal and map display) is described. <b>Throughput</b> <b>statistics</b> from one trip are summarized...|$|E
40|$|We {{compare the}} {{performance}} of different backoff functions for the multiple access protocol in an IEEE 802. 11 wireless LAN (WLAN). We provide a unified analytical model with explicit expressions for the {{mean and standard deviation}} of the access delay for generalized exponential, polynomial and linear backoff functions. Using our model, we show that linear and polynomial backoffs with appropriate parameter settings can improve upon binary exponential backoff specified in the 802. 11 WLAN standards, in terms of <b>throughput,</b> access delay <b>statistics</b> and packet drop rate...|$|R
40|$|Abstract—In this demo, we {{showcase}} DiffQ – a {{congestion control}} protocol inspired by theoretical cross-layer optimization approaches. DiffQ can support congestion control for network flows that use either single-path or opportunistic multi-path routing. Our demo {{will focus on}} the performance in single-path routing environments, where contemporary end-point congestion control algorithms like TCP face severe unfairness or even starvation. This is primarily due to the interaction of such protocols with MAC layer unfairness. We demonstrate micro (5 flows) as well as macro-evaluations (60 flows) of such cases. Our demo is conducted on WiSeNet – a 70 -node wireless mesh test-bed hosted in the computer science building at NCSU. Distributed over a 100, 000 sq ft building, {{this is one of the}} largest test-bed installations both in terms of number of nodes and coverage area, hence an ideal testing ground for such scenarios. Experimental results like <b>throughput,</b> MAC-layer <b>statistics,</b> delay, routing path flaps and network buffer overflows are recorded and displayed in real-time and enable a bird’s eye-view of the entire network status and allow us to point out various phenomenon as they happen. I...|$|R
40|$|Abstract—Today’s 802. 11 -based {{wireless}} network interface cards (WNICs) can leverage multiple transmission rates to exploit various and dynamic channel conditions. Some link adaptation schemes (LASs) {{in the literature}} {{have been shown to}} adapt well to dynamic channel conditions, thereby achieving high link throughput. However, routing protocols unaware of the underlying LAS may achieve low end-to-end throughput due to inappropriate path selection. In this paper, we propose a cross-layer routing framework called EAB which aims at discovering a high <b>throughput</b> path using <b>statistics</b> from MAC and LAS layer for a newly initiated flow. Our simulation results reveal that EAB operating on top of some efficient LASs significantly outperforms existing routing protocols in terms of the achieved throughput and the impact on existing flows. I...|$|R
40|$|Abstract—Random-early-detection (RED) {{is widely}} applied in IP network nowadays. It {{provides}} high bandwidth utilisation by dropping packets {{randomly selected from}} the queue. These dropped packets will then serve as signals that notify their transmission ends {{to slow down the}} sending rate, preventing congestion from happening. Unfortunately, RED algorithm provides little protection aggressive flows, such as flows with large packets, or congestion insensitive flows. As a result, it is easy for these flows to consume most of the bandwidth, causing bandwidth unfairness. In this paper, we propose a new algorithm, named as Power-RED, which aims to achieve bandwidth fairness. Power-RED keeps a <b>throughput</b> <b>statistics,</b> and adjusts packet drop probabilities according to power law when network tends to become congested. The simulation shows that Power-RED can guarantee fairness not only in packet numbers but also in their sizes...|$|E
40|$|In {{this paper}} {{we present a}} novel {{framework}} supporting distributed network management using a self-organizing peer-to-peer overlay network. The overlay consists of several Distributed Network Agents which can perform distributed tests and distributed monitoring for fault and performance management. In that way, the concept is able to overcome disadvantages that come along with a central management unit like scalability and reliability. The self-organization of the overlay is achieved by {{the application of a}} Distributed Hash Table (DHT) based on the Kademlia algorithm. The DHT mechanism implements a distributed index for the rapid localization of other agents or resources. The framework provides a reliable and scalable basis for distributed tests, like e. g. the identification of performance degradation in IP networks using <b>throughput</b> <b>statistics.</b> The framework is not intended to replace the central network manager, but rather to support it in testing and surveying the status of the corresponding network. ...|$|E
40|$|We {{present a}} novel {{experimental}} setup in which magnetic and optical tweezers are combined for torque and force transduction onto single filamentous molecules in a transverse configuration to allow simultaneous mechanical measurement and manipulation. Previously {{we have developed}} a super-resolution imaging module which in conjunction with advanced imaging techniques such as Blinking assisted Localisation Microscopy (BaLM) achieves localisation precision of single fluorescent dye molecules bound to DNA of ~ 30 nm along the contour of the molecule; our work here describes developments in producing a system which combines tweezing and super-resolution fluorescence imaging. The instrument also features an acousto-optic deflector that temporally divides the laser beam to form multiple traps for high <b>throughput</b> <b>statistics</b> collection. Our motivation for developing the new tool is to enable direct observation of detailed molecular topological transformation and protein binding event localisation in a stretching/twisting mechanical assay that previously could hitherto only be deduced indirectly from the end-to-end length variation of DNA. Our approach is simple and robust enough for reproduction in the lab without the requirement of precise hardware engineering, yet is capable of unveiling the elastic and dynamic properties of filamentous molecules that have been hidden using traditional tools...|$|E
40|$|Rheotaxis is {{the ability}} shared by most aquatic species to orient towards a current and swim to hold position. It is an innate and robust multi-sensory {{behavior}} that is known to involve the lateral line and visual systems. To facilitate the neuroethological study of rheotaxic behavior in larval zebrafish we developed an assay for freely swimming larvae that allows for high experimental <b>throughput,</b> large <b>statistics</b> and {{a detailed description of}} the behavior. We show that there exist a clear transition from exploration to counterflow swim, and by changing the sensory modalities accessible to the fishes (visual only, lateral line only or both) and comparing the swim patterns at different ages we characterized two different mechanisms for position holding, one mediated by the lateral line and one mediated by the visual system. We found that when both sensory modalities are accessible the lateral line dominates for triggering the transition while the visual system overshadows the lateral line for all aspect of swim patterns during the position holding phase. This suggests that at the larval stage the sensory inputs are not merged to finely tune the behavior but that one sensory modality dominates the behavioral response while redundant information pathways may be used as functional fallbacks...|$|R
40|$|A set {{of tools}} {{that allows us to}} measure and examine the effects of {{transmission}} delay and errors on the performance of TP- 4 implementations has been developed. The tools give insight into both the large- and small-scale behaviors of an implementation. These tools have been systematically applied to a commercial implementation of TP- 4. Measurements show, among other things, that a 2 -second one-way transmission delay and an effective bit-error rate of 1 error per 100, 000 bits can result in a 95 percent reduction in TP- 4 <b>throughput.</b> The detailed <b>statistics</b> give insight into why transmission delay and errors affect this implementations so significantly and support a number of 'lessons learned' that could be applied to TP- 4 implementations that operate more robustly across networks with long transmission delays and transmission errors...|$|R
40|$|This paper {{describes}} a desktop teleconferencing system running between UNIX workstations using TCP/IP and UDP/IP protocols on ethernet, 2 -Mbit/s router-connected ethernets and Fastpac-connected ethernets (10 -Mbit/s). <b>Throughput</b> and error <b>statistics</b> are presented for the networks {{along with a}} subjective assessment of audio and video quality, delay, jitter {{and the effects of}} these network artefacts on teleconferencing. We conclude {{that it is possible to}} produce an effective multimedia telecommunications system today using a single network technology. 1. INTRODUCTION Recent advances in integrated circuit design, image coding and compression, audio coding and computer architecture have made it possible to develop desktop-based teleconferencing and collaborative work systems at modest cost. Similar advances in the telecommunications industry have seen the widespread deployment of ethernet Local Area Networks (LANs), public audio/data ISDN and IEEE 802. 6 Metropolitan Area Networks (MANs). So [...] ...|$|R
40|$|Wireless {{instrumentation}} {{is rapidly}} gaining {{recognition in the}} oil and gas industry as a catalyst for optimised modularisation – a construction tactic in which the units of an LNG process train are built overseas and shipped in their entirety to site, massively reducing costs. Wireless instruments compliment this approach by removing the need to lay communication cables during the construction phase. Wireless instruments exchange information according to wireless communication protocols. These models conceptually break complex networks into simple layers and define the strict rules which coordinate message packaging, routing and transmission. WirelessHART and ISA 100. 11 a are the two main wireless communication protocols in industrial sectors, however their incompatibility alongside a split market, creates disorder for operators such as Woodside. This paper provides the engineering arguments to determine which protocol is better suited to Woodside assets, by simulating wireless sensor networks configured in either protocol. Throughput, reliability and battery life were the key performance indicators, to compare the WirelessHART’s Time Division Multiple Access channel versus ISA 100. 11 a’s Carrier Sense Multiple Access approach. Higher <b>throughput</b> <b>statistics</b> were achieved for ISA 100. 11 a, whilst WirelessHART was more efficient in power consumption. This project also looks at the requirements and limitations of wireless technology in terms of monitoring versus safety and process control...|$|E
40|$|Container flows {{have been}} booming for decades. Expectations for the 21 st century are less certain due {{to changes in}} climate and energy policy, {{increasing}} congestion and increased mobility of production factors. This paper presents a strategic model for the movement of containers {{on a global scale}} in order to analyse possible shifts in future container transport demand and the impacts of transport policies thereon. The model predicts yearly container flows over the world’s shipping routes and passing through 437 container ports around the world, based on trade information to and from all countries, taking into account more than 800 maritime container liner services. The model includes import, export and transhipment flows of containers at ports, as well as hinterland flows. The model was calibrated against observed data and is able to reproduce port <b>throughput</b> <b>statistics</b> rather accurately. The paper also introduces a scenario analysis to understand the impact of future, uncertain developments in container flows on port throughput. The scenarios include the effects of slow steaming, an increase in land based shipping costs and an increased use of large scale infrastructures such as the Trans-Siberian rail line and the opening of Arctic shipping routes. These scenarios provide an indication of the uncertainty on the expected port throughputs, with a particular focus on the port of Rotterdam in the Netherlands...|$|E
40|$|In {{order to}} {{introduce}} the benefits of Multiple-Input/Multiple-Output (MIMO) wireless solutions into the airborne environment for maximal effect, the airborne channel must be fully understood. While there have been theoretical models proposed for the airborne channel, there has been very little work toward providing a practical channel model which has been validated by actual an airborne platform. This work presents a characterization of practical performance gains of a MIMO system over a conventional SISO, in a mobile air-to-ground environment. Field measurements were collected with an airborne 4 x 4 MIMO-OFDM channel-sounding platform at altitudes, speeds and flight patterns approximating medium-endurance vehicles flying over various terrain. Ground stations placed in multiple locations (different scattering scenarios) measured channel responses in addition to actual <b>throughput</b> <b>statistics.</b> Our studies indicate that significant throughput and range gains are achievable with MIMO. We also show that depending on application requirements, these MIMO-enabled gains can be converted into considerable power savings. We also present {{a study of the}} effects of introducing MIMO-enabled signaling techniques (such as eigen beamforming and spatial multiplexing) on the total link-capacity of a system of uncoordinated, air-to-ground link-pairs deployed to a single area of operations. Captured channel measurements from the earlier real-world airborne study were inserted into our multi-link simulation environment. Trials were run under several representative aerial-deployment scenarios, revealing significant gains in link capacity. Finally, we consider the potential throughput enhancement delivered by full-duplex signaling and its limitations due to desensitization of receiver hardware by self-generated interference (SI). Existing SI cancellation solutions are prohibitive for long-range/airborne applications due to power handling limitations. They are also not easily scalable for an arbitrary number of MIMO antennas in arbitrary positions. A host-agnostic, high-power, adaptive SI canceler design is proposed and a hardware prototype is presented. Performance enhancement with an off-the-shelf host radio was demonstrated in the presence of varying SI signal profiles...|$|E
30|$|We {{have tested}} the cross-technology TDMA scheme in the CREW w-ilab.t testbed [27], {{composed}} of over 60 nodes spread in a semi-shielded environment of 22 × 66 m 2. We selected {{one pair of}} WiFi nodes, Alix 3 C 3 embedded PCs equipped with a bcm 4318 wireless interface running our custom-made WMP firmware [4], and one pair of interfering ZigBee nodes, RM 090 [28] motes running TinyOS and using the SnapMAC driver. During the experiments, the WiFi nodes executed the legacy state machine and reported <b>throughput</b> and error <b>statistics</b> to the central database. When triggered by the experiment controller, they switched to the TDMA state machine. The ZigBee nodes were programmed with two SnapMAC chains: on the receiving node, a simple chain was responsible for receiving and reporting all ZigBee packets. On the transmitting node, a TDMA chain was running that could switch between regular CSMA operation and TDMA operation as instructed by the experiment controller.|$|R
40|$|We report {{performance}} {{measurements of}} Internet connections between five Sequoia 2000 sites. <b>Throughput</b> and delay <b>statistics</b> are presented for various message sizes and for both daytime and nighttime. The highest throughput observed was 85 KB/s between UCSD and UCLA {{at night and}} the lowest was 1 KB/s between UCSD and DWR during the day. ################## For more information contact: Joseph Pasquale at pasquale@cs. ucsd. edu, 619 - 534 - 2673, 619 - 534 - 7029 (fax), or George Polyzos at polyzos@cs. ucsd. edu, 619 - 534 - 3508, 619 - 534 - 7029 (fax). 1. Introduction The Sequoia 2000 project [1] is developing computing and communications technology to support Global Change research. The goal {{is to build a}} Terabyte database of important, very large datasets to be accessible by Earth Scientists in real-time from their workstations at the Sequoia 2000 sites distributed across California. To provide acceptable performance and a testbed for communications research a new computer network interconnecting the [...] ...|$|R
40|$|In {{this paper}} we address the {{evaluation}} of speech quality through a wireless network as perceived by the user. User perceived evaluation (in addition to the usual network metrics including delay, <b>throughput,</b> packet loss <b>statistics</b> etc) is critical {{in the design of}} wireless multimedia networks where speech and video play a key role and are affected by several factors, such as network performance and encoding scheme. We use two approaches for our evaluation: small scale testbed implementation and hybrid simulation. The testbeds are implemented either by UDP (User Datagram Protocol) connection or UCLA talk connection. The hybrid simulation is event driven and is based on the Maisie parallel simulation language. It uses speech traces for inputs and plays back the speech outputs off line. There are several advantages in using the simulation tool, mainly {{from the point of view}} of scalability and new protocol feature testing. At the same time, the real life testbed provides verification of th [...] ...|$|R
40|$|On the Internet, network routers are {{typically}} implemented to provide strategic controls over the growing demands on limited and expensive bandwidth for an increasingly diverse traffic spectrum. A router {{consists of two}} major components: a set of switch fabric and multiple linecards. The functionalities of a linecard can be categorized into three parts: packet classification, statistics accounting, and packet scheduling. Packet classification includes functionalities such as routing table lookup, admission control, and deep packet inspection. Statistics accounting is implemented to store essential information such as flow statistics and network counting sketches, {{for the purpose of}} traffic monitoring and traffic management. Packet scheduling includes functionalities such as packet buffering, packet shaping, rate control, and hierarchical queue management. Sophisticated algorithms have been developed to improve the throughput and fairness on the network, however, the costs of implementing the new algorithms constantly outweigh their performance gains. This dissertation focuses on bridging the gap between advanced algorithms and their implementations in real- world network equipments by adopting a throughput- and fairness-driven design of network traffic managers which incorporate most of the functionalities of statistics accounting and packet scheduling, while providing worst- case performance guarantees for the whole router system. First, we explore parallelism to design high <b>throughput</b> <b>statistics</b> counter arrays that are robust against adversarial traffic. Second, we develop robust pipelined memory systems with worst-case performance guarantees for network processing. In our new memory systems, memory operations are finished within a fixed delay, which greatly simplifies the designs of network processors. Third, we present novel succinct priority index data structures that can be implemented for scheduling packets maintained in a large number of priority queues at line rate, which is essential in providing quality-of-service for per-flow queueing. Last, we show several reservation- based packet buffer architectures with interleaved memories that take advantage of the known packet departure times to achieve simplicity and determinism. They are scalable to growing packet storage requirements in routers to provide fine-grained per-flow queue buffering, while matching increasing line rates. All these approaches significantly improve the overall system throughput while providing better fairness, quality-of-service and worst- case performance guarantees over existing solution...|$|E
40|$|Mobile ad hoc {{networks}} (MANET) {{are very}} difficult to design in terms of scenarios specification and propagation modeling. All these aspects {{must be taken into account}} when designing MANET. For cost-effective designing, powerful and accurate simulation tools are needed. Our first contribution in this paper is to provide a global approach process (GAP) in channel modeling combining scenarios and propagation in order to have a better analysis of the physical layer, and finally to improve performances of the whole network. The GAP is implemented in an integrated simulation tool, Ad-SMPro. Moreover, channel <b>statistics,</b> <b>throughput</b> and delay are some key points to be considered when studying a mobile wireless networks. A carefully analysis of mobility effects over second order channel statistics and system performances is made based on our optimized simulation tool, Ad-SMProl. The channel is modeled by large scale fading and small scale fading including Doppler spectrum due to the double mobility of the nodes. Level Cross Rate and Average Duration of Fade are simulated as function of double mobility degree, a defined to be the ratio of the nodes' speeds. These results are compared to the theoretical predictions. We demonstrate that, in mobile ad hoc networks, flat fading channels and frequency-selective fading channels are differently affected. In addition, Bit Error rate is analysed as function of the ratio of the average bit energy to thermal noise density. Other performances (such as throughput, delay and routing traffic) are analysed and conclusions related to the proposed simulation model and the mobility effects are drawn...|$|R

