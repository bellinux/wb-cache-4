10000|5332|Public
25|$|Autonetics Division of North American Rockwell. Inc.; Minuteman D-17 Computer <b>Training</b> <b>Data.</b> Anaheim, California, 8 June 1970.|$|E
25|$|A {{version of}} SVM for {{regression}} was proposed in 1996 by Vladimir N. Vapnik, Harris Drucker, Christopher J. C. Burges, Linda Kaufman and Alexander J. Smola. This method is called support vector regression (SVR). The model produced by support vector classification (as described above) depends {{only on a}} subset of the <b>training</b> <b>data,</b> because the cost function for building the model does not care about training points that lie beyond the margin. Analogously, the model produced by SVR depends only on {{a subset of the}} <b>training</b> <b>data,</b> because the cost function for building the model ignores any <b>training</b> <b>data</b> close to the model prediction. Another SVM version known as least squares support vector machine (LS-SVM) has been proposed by Suykens and Vandewalle.|$|E
25|$|A DBN {{can be used}} to generatively pre-train a DNN {{by using}} the learned DBN weights as the initial DNN weights. Backpropagation or other discriminative {{algorithms}} can then tune these weights. This is particularly helpful when <b>training</b> <b>data</b> are limited, because poorly initialized weights can significantly hinder model performance. These pre-trained weights are in a region of the weight space that is closer to the optimal weights than were they randomly chosen. This allows for both improved modeling and faster convergence of the fine-tuning phase.|$|E
30|$|In Sect.  4, tagging {{is based}} on {{classification}} using supervised information (i.e. the train dataset) with a small dataset. From the experiment, cosine similarity computing may take time when there are many <b>train</b> <b>data.</b> Moreover, {{the selection of the}} <b>train</b> <b>data</b> is a critical task. Thus, preparing the <b>train</b> <b>data</b> may need another efficient technique such as support vector machine to determine the classifiers for the particular domain and this technique is appropriate for a large dataset.|$|R
40|$|Abstract — Discovering {{frequent}} {{episodes in}} event sequences {{is an interesting}} data mining task. In this paper, we argue that this framework is very effective for analyzing multi-neuronal spike <b>train</b> <b>data.</b> Analyzing spike <b>train</b> <b>data</b> is an important problem in neuroscience though there are no data mining approaches reported for this. Motivated by this application, we introduce different temporal constraints on the occurrences of episodes. We present algorithms for discovering frequent episodes under temporal constraints. Through simulations, we show that our method is very effective for analyzing spike <b>train</b> <b>data</b> for unearthing underlying connectivity patterns. I...|$|R
30|$|The Aurora 2.0 noisy digit {{database}} {{is widely}} used {{for the evaluation of}} noise-robust frontends [14]. Eight types of additive noises are artificially added to clean speech data with SNR levels ranging from 20 to - 5 dB. The data may be further convolved with two types of convolution noises. The multi-train recognizer is <b>trained</b> by a <b>data</b> set (called the multi-train set) consisting of clean and multi-condition noisy speech samples. The clean-train recognizer is <b>trained</b> by a <b>data</b> set (called the clean-train set) consisting of clean speech samples only. Test data in Set A are matched to the multi-condition <b>train</b> <b>data,</b> test data in Set B are not matched to the multi-condition <b>train</b> <b>data,</b> and test data in Set C are further mismatched due to convolution. Note that the proportion of the data amounts of Set A, Set B, and Set C is 2 : 2 : 1.|$|R
25|$|The {{resulting}} end-to-end system {{achieves a}} drastic {{improvement in the}} state of the art on this end-to-end task, reaching the same level of performance as the best systems operating on aligned, closely cropped images (no outside <b>training</b> <b>data).</b> It also performs well on two newer datasets, similar to LFW, but more difficult: significantly jittered (misaligned) version of LFW and SUFR-W (for example, the model’s accuracy in the LFW “unaligned & no outside data used” category is 87.55±1.41% compared to state-of-the-art APEM (adaptive probabilistic elastic matching): 81.70±1.78%).|$|E
25|$|Photonic {{implementations}} are attracting more attention, not {{the least}} {{because they do not}} require extensive cooling. Simultaneous spoken digit and speaker recognition and chaotic time-series prediction were demonstrated at data rates beyond 1 gigabyte per second in 2013. Using non-linear photonics to implement an all-optical linear classifier, a perceptron model was capable of learning the classification boundary iteratively from <b>training</b> <b>data</b> through a feedback rule. A core building block in many learning algorithms is to calculate the distance between two vectors: this was first to experimentally demonstrated up to eight dimensions using entangled qubits in a photonic quantum computer in 2015.|$|E
25|$|An {{alternative}} method of structural learning uses optimization based search. It requires a scoring function and a search strategy. A common scoring function is posterior probability {{of the structure}} given the <b>training</b> <b>data,</b> like the BIC or the BDeu. The time requirement of an exhaustive search returning a structure that maximizes the score is superexponential {{in the number of}} variables. A local search strategy makes incremental changes aimed at improving the score of the structure. A global search algorithm like Markov chain Monte Carlo can avoid getting trapped in local minima. Friedman et al. discuss using mutual information between variables and finding a structure that maximizes this. They do this by restricting the parent candidate set to k nodes and exhaustively searching therein.|$|E
50|$|In July 2016, Reply {{partnered with}} The Data Incubator in Europe (UK, Germany and Italy) to <b>train</b> <b>data</b> {{scientists}} and help companies {{move quickly to}} being data-driven.|$|R
25|$|Control data {{comes from}} two locations: Metrol, and control stations. Next <b>train</b> <b>data</b> and times are {{automatically}} updated by the train control systems, with manual overrides also possible.|$|R
30|$|Generalized filter. We {{propose to}} extend this {{filtering}} {{to the case}} where X(1) and X(2) {{are not in the}} same domain as X. This may happen for example if the test data is recorded using a different sample frequency, or if the STFT is performed with a different time-window than the <b>train</b> <b>data.</b> In such a case, D(1) and D(2) are in the domain of the <b>train</b> <b>data</b> and are X(1) and X(2), but X is in a different domain, and its coefficients correspond to different sound frequencies. As such, we cannot use Wiener filtering.|$|R
2500|$|There are {{problems}} of balance weight between infrequent grams (for example, if a proper name {{appeared in the}} <b>training</b> <b>data)</b> and frequent grams. [...] Also, items not seen in the <b>training</b> <b>data</b> {{will be given a}} probability of 0.0 without smoothing. For unseen but plausible data from a sample, one can introduce pseudocounts. [...] Pseudocounts are generally motivated on Bayesian grounds.|$|E
2500|$|If the <b>training</b> <b>data</b> are linearly separable, we {{can select}} two {{parallel}} hyperplanes that {{separate the two}} classes of data, so that {{the distance between them}} is as large as possible. The region bounded by these two hyperplanes is called the [...] "margin", and the maximum-margin hyperplane is the hyperplane that lies halfway between them. These hyperplanes can be described by the equations ...|$|E
2500|$|This idea can {{be traced}} to an {{experiment}} by Claude Shannon's work in information theory. [...] Shannon posed the question: given a sequence of letters (for example, the sequence [...] "for ex"), what is the likelihood of the next letter? [...] From <b>training</b> <b>data,</b> one can derive a probability distribution for the next letter given a history of size : [...] a = 0.4, b = 0.00001, c = 0, ....; where the probabilities of all possible [...] "next-letters" [...] sum to 1.0.|$|E
5000|$|Store {{the last}} 48 hours of safety-critical <b>train</b> <b>data.</b> This {{is to prevent}} {{over-writing}} of the crash data if the loco {{is used for the}} subsequent [...] "clean-up" [...] of the crash scene.|$|R
50|$|TCAS {{is being}} {{developed}} in India by qualified companies, manufacturing railway safety systems selected by RDSO through an Expression of Interest (EOI). These companies includes Kernex Microsystems, Medha Servo Drives Hyderabad, Invensys Bangalore, Siemens, HBL Power Systems Ltd Hyderabad and others. Indian Train Protection Systems will offer collision avoidance and also many functionalities of the European Train Control System, including prevention of Signal Passing at Danger (SPAD), Movement Authority and Control, Critical <b>Train</b> <b>Data</b> Recorder, advance in cab display of signals, advance alerts and warnings from station sections, uploading of running <b>train</b> <b>data</b> to a Central Train Management System over GSM-GPRS or other cellular networks.|$|R
40|$|Author manuscript, {{published}} in "NeuroComp/KEOpS' 12 workshop beyond the retina: from computational models to outcomes in bioengineering. Focus on architecture and dynamics sustaining information flows in the visuomotor system. (2012) " Analyzing large-scale spike <b>trains</b> <b>data</b> with spatio-temporal constraint...|$|R
2500|$|Using a {{different}} annealing technology based on {{nuclear magnetic resonance}} (NMR), a quantum Hopfield network was implemented in 2009 that mapped the input data and memorized data to Hamiltonians, allowing the use of adiabatic quantum computation. NMR technology also enables universal quantum computing, and it {{was used for the}} first experimental implementation of a quantum support vector machine to distinguish hand written number ‘6’ and ‘9’ on a liquid-state [...] quantum computer in 2015. The <b>training</b> <b>data</b> involved the pre-processing of the image which maps them to normalized 2-dimensional vectors to represent the images as the states of a qubit. The two entries of the vector are the vertical and horizontal ratio of the pixel intensity of the image. Once the vectors are defined on the feature space, the quantum support vector machine was implemented to classify the unknown input vector. The readout avoids costly quantum tomography by reading out the final state in terms of direction (up/down) of the NMR signal.|$|E
50|$|Regression {{analysis}} {{was one of}} the earliest such approaches to be developed. The data used to construct or discover a predictive relationship are called the <b>training</b> <b>data</b> set. Most approaches that search through <b>training</b> <b>data</b> for empirical relationships tend to overfit the data, meaning that they can identify apparent relationships in the <b>training</b> <b>data</b> that do not hold in general. A test set is a set of data that is independent of the <b>training</b> <b>data,</b> but that follows the same probability distribution as the <b>training</b> <b>data.</b> If a model fit to the training set also fits the test set well, minimal overfitting has taken place. A better fitting of the training set as opposed to the test set usually points to overfitting.|$|E
50|$|The {{strength}} of this method relies on the {{strength of}} the <b>training</b> <b>data</b> as well as the tuning of the modified Mumford-Shah functional. Different snakes will require different <b>training</b> <b>data</b> sets and tunings.|$|E
25|$|<b>Train</b> <b>Data</b> Management System (TDMS) which {{concentrate}} and dispatch {{the rolling}} stock information with fixed equipment. The IAGO Waveguide communications network has the capability to transmit video and is almost maintenance-free. Base stations are located within the signalling equipment room.|$|R
40|$|Neuronal {{circuits}} or cell assemblies {{carry out}} brain function through complex coordinated firing patterns [1]. Inferring topology of neuronal circuits from simultaneously recorded spike <b>train</b> <b>data</b> is a challenging problem in neuroscience. In this work {{we present a}} new class of dynamic Bayesian networks to infer polysynaptic excitatory connectivity between spiking cortical neurons [2]. The emphasis on excitatory networks allows us to learn connectivity models by exploiting fast data mining algorithms. Specifically, we show that frequent episodes help identify nodes with high mutual information relationships and can be summarized into a dynamic Bayesian network (DBN). We model the spike <b>train</b> <b>data</b> as binary random variables and learn high mutual information parent sets o...|$|R
25|$|A McKinsey Global Institute {{study found}} a {{shortage}} of 1.5 million highly <b>trained</b> <b>data</b> and AI professionals and managers {{and a number of}} private bootcamps have developed programs to meet that demand, including free programs like The Data Incubator or paid programs like General Assembly.|$|R
50|$|Suppose {{we have a}} {{model with}} one or more unknown {{parameters}}, and a data set to which the model can be fit (the <b>training</b> <b>data</b> set). The fitting process optimizes the model parameters to make the model fit the <b>training</b> <b>data</b> as well as possible. If we then take an independent sample of validation data from the same population as the <b>training</b> <b>data,</b> it will generally turn out that the model does not fit the validation data as well as it fits the <b>training</b> <b>data.</b> This is called overfitting , and is particularly likely to happen when the size of the <b>training</b> <b>data</b> set is small, or when the number of parameters in the model is large. Cross-validation is a way to predict the fit of a model to a hypothetical validation set when an explicit validation set is not available.|$|E
5000|$|The {{possibility}} of overfitting exists because the criterion used for training {{the model is}} not the same as the criterion used to judge the efficacy of a model. In particular, a model is typically trained by maximizing its performance on some set of <b>training</b> <b>data.</b> However, its efficacy is determined not by its performance on the <b>training</b> <b>data</b> but by its ability to perform well on unseen data. Overfitting occurs when a model begins to [...] "memorize" [...] <b>training</b> <b>data</b> rather than [...] "learning" [...] to generalize from a trend. As an extreme example, if the number of parameters is the same as or greater than the number of observations, a simple model or learning process can perfectly predict the <b>training</b> <b>data</b> simply by memorizing the <b>training</b> <b>data</b> in its entirety, but such a model will typically fail drastically when making predictions about new or unseen data, since the simple model has not learned to generalize at all.|$|E
50|$|The {{combination}} of 2 and 3 cannot provide full <b>training</b> <b>data</b> order which {{is needed to}} apply the full SVM algorithm. Instead, it provides {{a part of the}} ranking information of the <b>training</b> <b>data.</b> So the algorithm can be slightly revised as follows.|$|E
30|$|In this article, we {{combine the}} probability-mixing and the response-averaging model with the leaky integrate-and-fire (LIF) model, to {{describe}} neuronal behavior based on observed spike trains. This is {{cast in a}} general setting, where the stimulus S(t) is represented as an input current to the neuron. The spike <b>train</b> <b>data</b> are simulated using the LIF model, responding either to a single stimulus or to a stimulus pair. In the case of stimulus pair, both response averaging and probability mixing are used. The first goal of the paper is to estimate parameters of {{either of the two}} models from spike <b>train</b> <b>data.</b> The second goal is to test which of the two models are most likely to have generated the observed data.|$|R
30|$|The second {{objective}} is to compare variables of SCS predictive abilities of different parameters lead to mortality. Firstly, we separate our dataset to <b>trained</b> and test <b>data.</b> The <b>trained</b> <b>data</b> consists of 75 % of the dataset (167 patient records) and the test data consist of 25 % of the dataset (58 patient records). We create a logistic regression model from <b>trained</b> <b>data</b> using the patient’s status ‘dead’ as outcome, with all the variables as independent predictors. From the created model, Table 3 show the important variables for predicting deadly outcome. Oxygen saturation, prior to current illness, spent some part of daytime in bed, coma without intoxication or overdose, respiratory rate (per min) and abnormal ECG {{are the most important}} variable for predicting deadly outcome, respectively. We measure the performance of our model using the sensitivity and specificity analysis that are shown sensitivity of 86.7 % and specificity of 92.9 % for SCS predicts mortality.|$|R
40|$|Article {{begins on}} next page) The Harvard {{community}} {{has made this}} article openly available. Please share how this access benefits you. Your story matters. Citation Shimazaki, Hideaki, Shun-ichi Amari, Emery N. Brown, and SonjaGrün. 2012. State-space analysis of time-varying higher-order spike correlation for multiple neural spike <b>train</b> <b>data.</b> PLo...|$|R
50|$|In machine {{learning}}, lazy {{learning is}} a learning method in which generalization beyond the <b>training</b> <b>data</b> is delayed until a query is made to the system, as opposed to in eager learning, where the system tries to generalize the <b>training</b> <b>data</b> before receiving queries.|$|E
50|$|The usual {{reason for}} {{oversampling}} is to correct for a {{bias in the}} original dataset. One scenariowhere it is useful is when training a classifier using labelled <b>training</b> <b>data</b> from a biased source, sincelabelled <b>training</b> <b>data</b> is valuable but often comes from un-representative sources.|$|E
50|$|The bias-variance {{tradeoff}} is {{a central}} problem in supervised learning. Ideally, one wants to choose a model that both accurately captures the regularities in its <b>training</b> <b>data,</b> but also generalizes well to unseen data. Unfortunately, it is typically impossible to do both simultaneously. High-variance learning methods {{may be able to}} represent their training set well, but are at risk of overfitting to noisy or unrepresentative <b>training</b> <b>data.</b> In contrast, algorithms with high bias typically produce simpler models that don't tend to overfit, but may underfit their <b>training</b> <b>data,</b> failing to capture important regularities.|$|E
5000|$|Another {{description}} of neural spike <b>train</b> <b>data</b> uses the Ising model {{borrowed from the}} physics of magnetic spins. Because neural spike trains effectively binarized(either on or off) at small time scales (10 to 20 ms), the Ising model is able to effectively capture the present pairwise correlations, and is given by: ...|$|R
5000|$|Communication Systems Engineer: <b>trained</b> in <b>data</b> {{communications}} and computer networks ...|$|R
40|$|The web {{log data}} embed {{much of the}} user’sbrowsing {{behavior}} and the operational data generated throughInternet end user interaction may contain noise. Which affect theknowledge based decision. Handling these noisy data is a majorchallenge. ull value handling is an important noise handlingtechnique in relational data base system. In this work the issuesrelated to null value are discussed and null value handlingconcept based on <b>train</b> <b>data</b> set is applied to real MA IT webserver log. A prototype system based on Fuzzy C-meansclustering techniques with <b>trained</b> <b>data</b> set is also proposed in thiswork. The proposed method integrates advantages of fuzzysystem and also introduces a new criterion, which enhances theestimated accuracy of the approximation. The comparisonsbetween different methods for handling null values are depicted. The result shows {{the effectiveness of the}} methods empirically onrealistic web logs and explores the accuracy, coverage andperformance of the proposed Models...|$|R
