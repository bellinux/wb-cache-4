1251|10000|Public
50|$|Context {{completion}} is a {{text editor}} feature, similar to word completion, which completes words (or entire phrases) {{based on the}} current context and context of other similar words within the same document, or within some <b>training</b> <b>data</b> <b>set.</b> The main advantage of context completion {{is the ability to}} predict anticipated words more precisely and even with no initial letters. The main disadvantage is the need of a <b>training</b> <b>data</b> <b>set,</b> which is typically larger for context completion than for simpler word completion. Most common use of context completion is seen in advanced programming language editors and IDEs, where <b>training</b> <b>data</b> <b>set</b> is inherently available and context completion makes more sense to the user than broad word completion would.|$|E
50|$|The <b>training</b> <b>data</b> <b>set</b> for {{the model}} {{implementation}} utilized the potential messages and delivery mechanisms with Actors, Actions, Objects, Contexts and Indicia as a few examples.|$|E
5000|$|... i.i.d. {{queries are}} applied to a {{database}} and each query corresponds to a ranking method. The <b>training</b> <b>data</b> <b>set</b> has [...] elements. Each element contains a query and the corresponding ranking method.|$|E
40|$|Classification is a data {{analysis}} technique. The decision tree {{is one of}} the most popular classification algorithms in current use for data mining because it is more interpretable. <b>Training</b> <b>data</b> <b>sets</b> are not error free due to measurement errors in the data collection process. Traditional decision tree classifiers are constructed without considering any errors in the values of attributes of the <b>training</b> <b>data</b> <b>sets.</b> We extend such classifiers to construct effective decision trees with error corrected <b>training</b> <b>data</b> <b>sets.</b> It is possible to build decision tree classifiers with higher accuracies especially when the measurement errors in the values of the attributes of the <b>training</b> <b>data</b> <b>sets</b> are corrected appropriately before using those <b>training</b> <b>data</b> <b>sets</b> in decision tree learning. Error corrected <b>data</b> <b>sets</b> can be used not only in decision tre...|$|R
30|$|Architecture and {{training}} of ANN with appropriate <b>training</b> <b>data</b> <b>sets.</b>|$|R
30|$|Bagging (Breiman 1996) {{which is}} also known as {{bootstrap}} aggregation involves training multiple models with <b>training</b> <b>sets</b> of <b>data</b> randomly drawn with replacement from the base <b>training</b> <b>data</b> <b>sets.</b> The <b>training</b> <b>data</b> <b>sets</b> for the base models are called bootstraps. Hence, bagging involves training different models with different samples and usually predictions are obtained by averaging the results of the different base models for a regression problem.|$|R
50|$|As {{the size}} of <b>training</b> <b>data</b> <b>set</b> {{approaches}} infinity, the one nearest neighbour classifier guarantees an error rate of no worse than twice the Bayes error rate (the minimum achievable error rate given {{the distribution of the}} data).|$|E
5000|$|Suppose [...] is {{the element}} of a <b>training</b> <b>data</b> <b>set,</b> where [...] is the feature vector and [...] is the label (which classifies the {{category}} of [...] ). A typical SVM classifier for such data set {{can be defined as}} the solution of the following optimization problem.|$|E
50|$|Suppose {{we have a}} {{model with}} one or more unknown {{parameters}}, and a data set to which the model can be fit (the <b>training</b> <b>data</b> <b>set).</b> The fitting process optimizes the model parameters to make the model fit the training data as well as possible. If we then take an independent sample of validation data from the same population as the training data, it will generally turn out that the model does not fit the validation data as well as it fits the training data. This is called overfitting , and is particularly likely to happen when the size of the <b>training</b> <b>data</b> <b>set</b> is small, or when the number of parameters in the model is large. Cross-validation is a way to predict the fit of a model to a hypothetical validation set when an explicit validation set is not available.|$|E
50|$|The {{strength}} of this method relies on the {{strength of}} the <b>training</b> <b>data</b> as well as the tuning of the modified Mumford-Shah functional. Different snakes will require different <b>training</b> <b>data</b> <b>sets</b> and tunings.|$|R
40|$|The {{quality and}} size of the <b>training</b> <b>data</b> <b>sets</b> is a {{critical}} stage on the ability of the artificial neural networks to generalize the characteristics of the training examples. Several approaches are focused to form <b>training</b> <b>data</b> <b>sets</b> by identification of border examples or core examples with the aim to improve the accuracy of network classification and generalization. However, a refinement of <b>data</b> <b>sets</b> by the elimination of outliers examples may increase the accuracy too. In this paper, we analyze the use of different editing schemes based on nearest neighbor rule on the most popular neural networks architectures...|$|R
3000|$|... {{simulated}} <b>training</b> <b>data</b> <b>sets</b> of {{the required}} sample size from the probability model in each case, and employing sample means and sample variances to approximate the performance metrics in Section 4.|$|R
5000|$|A machine {{learning}} algorithm, {{also known as}} a learning map , maps a <b>training</b> <b>data</b> <b>set,</b> which is a set of labeled examples , onto a function [...] from [...] to , where [...] and [...] are in the same space of the training examples. The functions [...] are selected from a hypothesis space of functions called [...]|$|E
5000|$|... k q-flat {{algorithm}} can be {{used for}} classification. Suppose there are total of m classes. For each class, k flats are trained a priori via <b>training</b> <b>data</b> <b>set.</b> When a new data comes, find the flat that is closest to the new data. Then the new data is associate to class of the closest flat.|$|E
50|$|This layer {{contains}} one neuron {{for each}} {{case in the}} <b>training</b> <b>data</b> <b>set.</b> It stores {{the values of the}} predictor variables for the case along with the target value. A hidden neuron computes the Euclidean distance of the test case from the neuron’s center point and then applies the radial basis function kernel function using the sigma values.|$|E
40|$|We {{describe}} two methodologies {{for obtaining}} segmented regression estimators from massive <b>training</b> <b>data</b> <b>sets.</b> The first methodology, called Linear Regression Tree (LRT), {{is used for}} continuous response variables, and the second and complementary methodology, called Naive Bayes Tree (NBT), is used for categorical response variables. These are implemented in the IBM ProbE TM (Probabilistic Estimation) data mining engine, which is an object-oriented framework for building classes of segmented predictive models from massive <b>training</b> <b>data</b> <b>sets.</b> Based on this methodology, an application called ATM-SE TM for direct-mail targeted marketing has been developed jointly with Fingerhut Business Intelligence [1]) ...|$|R
40|$|International audienceBig data {{processing}} {{is the new}} challenge for analytical, machine learning techniques. Many efforts are needed to scale both classic, advanced methods to the {{the mass of the}} provided data. Evolutionary learning algorithms (EAL) are robust, effective methods in solving a wide variety of complex learning problems. This paper discusses how to tune the active sampling techniques for EAL to deal with very large <b>training</b> <b>data</b> <b>sets.</b> It introduces the key decisions needed to design an effective active sampling strategy, review the main techniques used with evolutionary algorithms. Then, we discuss how they could be adapted to learn from big <b>training</b> <b>data</b> <b>sets,</b> present some research directions in this domain...|$|R
40|$|Artificial neural {{networks}} (ANNs) provide {{a quick and}} flexible means of developing flood flow simulation models. An important criterion for the wider applicability of the ANNs {{is the ability to}} generalise the events outside the range of <b>training</b> <b>data</b> <b>sets.</b> With respect to flood flow simulation, the ability to extrapolate beyond the range of calibrated <b>data</b> <b>sets</b> is of crucial importance. This study explores methods for improving generalisation of the ANNs using three different flood events <b>data</b> <b>sets</b> from the Neckar River in Germany. An ANN-based model is formulated to simulate flows at certain locations in the river reach, based on the flows at upstream locations. Network <b>training</b> <b>data</b> <b>sets</b> consist of time series of flows from observation stations. Simulated flows from a one-dimensional hydrodynamic numerical model are integrated for network training and validation, at a river section where no measurements are available. Network structures with different activation functions are considered for improving generalisation. The training algorithm involved backpropagation with the Levenberg-Marquardt approximation. The ability of the trained networks to extrapolate is assessed using flow data beyond the range of the <b>training</b> <b>data</b> <b>sets.</b> The results {{of this study indicate that}} the ANN in a suitable configuration can extend forecasting capability to a certain extent beyond the range of calibrated <b>data</b> <b>sets...</b>|$|R
5000|$|The {{excess risk}} of a general {{classifier}} [...] (possibly depending on some training data) is defined as Thus this non-negative quantity is important for assessing the performance of different classification techniques. A classifier {{is said to be}} consistent if the excess risk converges to zero as the size of the <b>training</b> <b>data</b> <b>set</b> tends to infinity.|$|E
5000|$|Suppose the <b>training</b> <b>data</b> <b>set</b> is , with , , where [...] indexes task, and [...] Let [...] In {{this setting}} {{there is a}} {{consistent}} input and output space and the same loss function [...] for each task: [...] This results in the regularized machine learning problem: where [...] is a vector valued reproducing kernel Hilbert space with functions [...] having components [...]|$|E
50|$|Soft {{independent}} modelling {{by class}} analogy (SIMCA) is a statistical method for supervised classification of data. The method requires a <b>training</b> <b>data</b> <b>set</b> consisting of samples (or objects) {{with a set}} of attributes and their class membership. The term soft refers to the fact the classifier can identify samples as belonging to multiple classes and not necessarily producing a classification of samples into non-overlapping classes.|$|E
5000|$|Exceeding {{available}} room FLOSS GIS/Remote sensing/Environmental applications have a {{large amount}} of sample, demonstration and <b>training</b> <b>data</b> <b>sets.</b> Installing all the data could easily result too large amount of data that cannot be burnt to a CD or DVD. Therefore, some <b>data</b> <b>sets</b> might be excluded from the media.|$|R
30|$|The reduced {{data are}} then {{normalized}} using the min–max operator (Eq.  3) to lie between 0 and 1. The final <b>training</b> <b>data</b> <b>sets</b> used for learning the classification/estimation models are created using the normalized {{data for the}} VDP and VH classes.|$|R
30|$|Two <b>training</b> <b>data</b> <b>sets</b> TDS for “snow” and “rain” were {{composed}} of 2, 500 geotagged tweets. One consisted of geotagged tweets that included “snow” as a keyword that were posted on February 8. The other consisted of geotagged tweets that included “rain” as a keyword that were posted on June 4. In these two <b>train</b> <b>data</b> <b>sets,</b> the geotagged tweets in the TDS were labeled manually. The number of geotagged tweets in the “positive” class, which means including topic “snow”, and the “negative” class was 1648 and 852, respectively. Moreover, {{the number of}} geotagged tweets in the “positive” class, which means including the topic “rain”, and the “negative” class was 897 and 1603, respectively.|$|R
5000|$|... 3. M-Step: The {{established}} {{relevance of}} a given feature set to a labeling scheme is now used to compute the a priori estimate {{of a given}} label {{in the second part}} of the algorithm. Since the actual number of total labels is unknown (from a <b>training</b> <b>data</b> <b>set),</b> a hidden estimate of the number of labels given by the user is utilized in computations.|$|E
50|$|Line {{completion}} {{is a type}} {{of context}} completion, first introduced by Juraj Simlovic in TED Notepad, in July 2006. The context in line completion is the current line, while current document poses as <b>training</b> <b>data</b> <b>set.</b> When user begins a line which starts with a frequently used phrase, the editor automatically completes it, up to the position where similar lines differ, or proposes a list of common continuations.|$|E
50|$|In {{data mining}} tools (for multivariate {{statistics}} and machine learning), the depending variable is assigned {{a role as}} target variable (or in some tools as label attribute), while a dependent variable may be assigned a role as regular variable. Known values for the target variable are provided for the <b>training</b> <b>data</b> <b>set</b> and test data set, but should be predicted for other data. The target variable is used in supervised learning algorithms but not in non-supervised learning.|$|E
40|$|In {{order to}} utilize remote sensed images effectively, {{a lot of}} image {{classification}} methods are suggested for many years. But the accuracy of traditional methods based on pixel-based classification is not high in general. And, in case of supervised classification, users should select <b>training</b> <b>data</b> <b>sets</b> within the image that {{are representative of the}} land-cover classes of interest. But users feel inconvenience to extract <b>training</b> <b>data</b> <b>sets</b> for image classification. In this paper, object oriented classification of Landsat images using feature database is studied in consideration of user’s convenience and classification accuracy. Object oriented image classification, currently a new classification concept, allows the integration of a spectral value, shape and texture and creates image objects. According to classification classes, objects statistics such as mean value, standard deviation, tasselled cap transformation and band ratio component were constructed as feature database. The feature of seven classes (Rural, Forest, Grass, Agriculture, Wetland, Barren, Water) was constructed in this study, it will be served in a network to user for image classification <b>training</b> <b>data</b> <b>sets.</b> Proposed method will be higher classification accuracy than that of traditional pixel-based supervised classification and gives convenient environment to users. 1...|$|R
40|$|Abstract — Spatial AdaBoost {{proposed}} by Nishii and Eguchi (TGRS 2005) is a contextual supervised classifier of land-cover categories of geostatistical data. It shows an ex-cellent performance {{similar to that}} of the MRF-based classi-fier with much less computational cost. In this paper, we ex-tend the method to the setup with multi spatio-temporal im-ages. We take classification functions by the averages of log posterior probabilities derived by respective <b>training</b> <b>data</b> <b>sets.</b> The functions are sequentially combined by minimizing the empirical exponential risk calculated over samples in all the <b>training</b> <b>data</b> <b>sets.</b> Thus, we obtain a classifier based on a convex combination of the functions. The proposed method is applied to artificial data, and it shows performance {{similar to that of}} Spatial AdaBoost based on much larger <b>training</b> <b>data.</b> I...|$|R
30|$|The {{features}} or weights W_ 2 of RBM 2 {{are then}} used to linearly transform both the testing and <b>training</b> <b>data</b> <b>sets</b> before being used by classifier. The principle of restricted Boltzmann machine and softmax regression-based classifier is explained in sections (A) and (C).|$|R
50|$|The use of {{different}} model parameters and different corpus sizes can greatly affect {{the quality of}} a word2vec model. Accuracy can be improved in a number of ways, including the choice of model architecture (CBOW or Skip-Gram), increasing the <b>training</b> <b>data</b> <b>set,</b> increasing the number of vector dimensions, and increasing the window size of words considered by the algorithm. Each of these improvements comes with the cost of increased computational complexity and therefore increased model generation time.|$|E
50|$|The goal of {{supervised}} learning (more specifically classification) {{is to learn}} a decision rule that can categorize data instances into pre-defined classes. The k-nearest neighbor rule assumes a <b>training</b> <b>data</b> <b>set</b> of labeled instances (i.e. the classes are known). It classifies a new data instance with the class obtained from the majority vote of the k closest (labeled) training instances. Closeness is measured with a pre-defined metric. Large margin nearest neighbors is an algorithm that learns this global (pseudo-)metric in a supervised fashion to improve the classification accuracy of the k-nearest neighbor rule.|$|E
5000|$|... where s is {{the step}} index, t an index into the {{training}} sample, u is {{the index of}} the BMU for D(t), α(s) is a monotonically decreasing learning coefficient and D(t) is the input vector; Θ(u, v, s) is the neighborhood function which gives {{the distance between the}} neuron u and the neuron v in step s. Depending on the implementations, t can scan the <b>training</b> <b>data</b> <b>set</b> systematically (t is 0, 1, 2...T-1, then repeat, T being the training sample's size), be randomly drawn from the data set (bootstrap sampling), or implement some other sampling method (such as jackknifing).|$|E
40|$|Abstract — Classification {{is one of}} {{the most}} {{important}} techniques in data mining. Decision tree is the most important classification technique in machine learning and data mining. Decision tree classifiers are constructed using <b>training</b> dada <b>sets.</b> <b>Training</b> <b>data</b> <b>sets</b> contain numerical (or continuous) and categorical (or discrete) attributes. Measurement errors are common in any data collection process, particularly when training datasets contain numerical (or continuous) attributes. So, values of numerical attributes contain measurement errors in many <b>training</b> <b>data</b> <b>sets.</b> We extend certain (or traditional or classical) decision tree building algorithms to handle values of numerical attributes containing measurement errors. We have discovered that the accuracy of a certain (or classical or traditional) decision tree classifiers can be much improved if the measurement errors in the values of numerical attributes in the <b>training</b> <b>data</b> <b>sets</b> are properly handled (or controlled or modeled or corrected) appropriately. The present study proposes a new algorithm for decision tree classifier construction. This new algorithm is named as Accurate Decision Tree (ADT) classifier construction. ADT classifiers are more accurate than certain (or traditional or classical) decision tree classifiers. ADT proves to be more effective regarding classification accuracy when compared with Certain Decision Tree (CDT) classifiers. The performance of thes...|$|R
30|$|After all labeled <b>training</b> <b>data,</b> i.e. <b>sets</b> IS- 20, IS- 50, IS- 100 and IS- 250, {{have been}} {{transformed}} into activation vectors for each dictionary learned from each unlabeled <b>data</b> <b>set,</b> we obtained in total 64 (4 labeled <b>data</b> <b>sets</b> × 4 dictionary sizes × 4 unlabeled <b>data</b> <b>sets)</b> labeled <b>training</b> <b>data</b> <b>sets.</b> Then, using the LIBSVM tool, we learned 64 SVM classifiers each consisting of 6 SVMs trained in one-versus-all mode. The SVM input vectors were linearly scaled to fit the [0, 1] range. For the sparse coding method, this significantly reduces vectors sparsity, but it is tolerable since our goal is not the sparse representation itself. Linear kernel was used as distance measure and the SVMs were trained to produce probabilistic outputs.|$|R
5000|$|More formally, {{given some}} <b>training</b> <b>data</b> , a <b>set</b> of n {{points of the}} form ...|$|R
