527|3706|Public
25|$|Note: All data in {{the table}} above are {{seasonally}} adjusted, except for the Northern Territory and the Australian Capital Territory, which are <b>trend</b> <b>data.</b>|$|E
25|$|Locky is {{reported}} to have been sent to about a half-million users on February 16, 2016, and for the period immediately after the attackers increased their distribution to millions of users. Despite the newer version, Google <b>Trend</b> <b>data</b> indicates that infections have dropped off around June 2016.|$|E
2500|$|Since 1991-92, most market-makers in Europe have {{employed}} binomial models to evaluate convertibles. Models were available from INSEAD, <b>Trend</b> <b>Data</b> of Canada, Bloomberg LP and from home-developed models, amongst others. [...] These models needed an input of credit spread, volatility for pricing (historic volatility often used), and the risk-free rate of return. The binomial calculation assumes {{there is a}} bell-shaped probability distribution to future share prices, and the higher the volatility, the flatter is the bell-shape. Where there are issuer calls and investor puts, these will affect the expected residual period of optionality, at different share price levels. The binomial value is a weighted expected value, (1) taking readings from all the different nodes of a lattice expanding out from current prices and (2) taking account of varying periods of expected residual optionality at different share price levels. See Lattice model (finance)#Hybrid Securities. The three biggest areas of subjectivity are (1) the rate of volatility used, for volatility is not constant, and (2) {{whether or not to}} incorporate into the model a cost of stock borrow, for hedge funds and market-makers. The third important factor is (3) the dividend status of the equity delivered, if the bond is called, as the issuer may time the calling of the bond to minimise the dividend cost to the issuer.|$|E
30|$|The steps towards {{examining}} {{the possibility of}} forecasting said diseases using Google <b>Trends</b> <b>data</b> are as follows: First, we {{provide an overview of}} the online interest variations on each of these diseases for the respective examined periods. Next, we visualize the geographical distribution of the online interest in each disease for all states for each individual year from 2004 to 2017. Following, we calculate the Pearson correlations between Google <b>Trends</b> <b>data</b> and the respective CDC data on each disease’s cases. Finally, we estimate linear regressions for the examined diseases at both national and state level, in order to examine the possibility of forecasting said diseases using Google <b>Trends</b> <b>data.</b>|$|R
50|$|A few {{unofficial}} Google Trends API tools {{have been}} released, {{along with a}} wiki detailing them and simple access to Google <b>Trends</b> <b>data.</b>|$|R
5000|$|While {{no public}} numbers {{measuring}} the install-base of these operating systems are available, Google <b>Trends</b> <b>data</b> on {{a handful of}} them indicate their relative popularity: ...|$|R
50|$|<b>Trend</b> <b>data</b> {{indicates}} {{decrease in}} tractor and child related injuries.|$|E
5000|$|Record <b>trend</b> <b>data</b> {{at regular}} {{intervals}} in veterinary vital signs monitoring.|$|E
5000|$|... <b>trend</b> <b>data</b> on {{agricultural}} scientist numbers and total investments in agricultural {{research by the}} government, higher education, and nonprofit sectors of developing countries; and ...|$|E
30|$|For the US, {{statistically}} significant correlation was observed between Hepatitis cases and Google <b>Trends</b> <b>data</b> (r[*]=[*] 0.9583, p[*]<[*] 0.01). For Hepatitis A, {{statistically significant}} correlations were observed between Google {{data in the}} US (r[*]=[*] 0.9045, p[*]<[*] 0.01); the same for Hepatitis B (r[*]=[*] 0.8922, p[*]<[*] 0.01). On the other hand, for Hepatitis C cases, no correlation was observed with Google <b>Trends</b> <b>data</b> (r[*]=[*]−[*] 0.3089, p[*]>[*] 0.1), indicating that the latter does not contribute significantly to the high correlation between all Hepatitis cases and Google data.|$|R
40|$|In this paper, {{we propose}} a new {{augmented}} Dickey–Fuller-type test for unit roots {{which accounts for}} two structural breaks. We consider two different specifications: (a) two breaks {{in the level of}} a <b>trending</b> <b>data</b> series and (b) two breaks in the level and slope of a <b>trending</b> <b>data</b> series. The breaks whose time of occurrence is assumed to be unknown are modeled as innovational outliers and thus take effect gradually. Using Monte Carlo simulations, we showthat our proposed test has correct size, stable power, and identifies the structural breaks accurately. <br /...|$|R
50|$|A {{public affairs}} team works to {{influence}} Government both in Westminster and the devolved institutions. There {{is also a}} Citizens Advice All-Party Parliamentary Group that provides a forum for Members of Parliament {{who are interested in}} the work of Citizens Advice. Citizens Advice produces constituency data that can be used by Parliamentarians to improve how they complete their own case work. Advice <b>Trends</b> <b>data</b> is published at a national and local level. Consumer Advice <b>Trends</b> <b>data</b> is also published as is data for Wales alone and data on the performance of energy suppliers and the postal service.|$|R
50|$|Profile of GMAT Candidates. The annual {{publication}} {{released in}} November offers five- and 10-year <b>trend</b> <b>data</b> on average scores and GMAT volume by demographic breakdowns.|$|E
50|$|Mobistat, {{a web-based}} {{reporting}} and mapping tool, measures mobile network performance.Mobistat {{is used to}} compile, analyze, and <b>trend</b> <b>data</b> for multiple years’ worth of network testing across geographical markets and by region.|$|E
50|$|Loggly is {{headquartered}} in San Francisco, California. The company had 25 employees and 5,000 customers in October 2014. Loggly records log data from any device and reports it in a real-time management platform with <b>trend</b> <b>data.</b>|$|E
50|$|Furthermore, it {{was shown}} by Tobias Preis et al. {{that there is a}} {{correlation}} between Google <b>Trends</b> <b>data</b> of company names and transaction volumes of the corresponding stocks on a weekly time scale.|$|R
50|$|The Shinken WebUI is the builtin Web {{interface}} {{that provides}} near real time status information, configuration, interaction, a dashboard to visualize <b>trending</b> <b>data</b> from Graphite databases and the visualization of dependency tree graphs.|$|R
40|$|Recently, {{studies have}} used search query volume (SQV) data to {{forecast}} a given process of interest. However, Google <b>Trends</b> SQV <b>data</b> {{comes from a}} periodic sample of queries. As a result, Google <b>Trends</b> <b>data</b> is different every week. We propose a Dynamic Linear Model that treats SQV data as a representation of an unobservable process. We apply our model to forecast the number of hotel nonresident registrations in Puerto Rico using SQV data downloaded in 11 different occasions. The model provides better inference on the association {{between the number of}} hotel nonresident registrations and SQV than using Google <b>Trends</b> <b>data</b> retrieved only on one occasion. Furthermore, our model results in more realistic prediction intervals of forecasts. However, compared to simpler models we only find evidence of better performance for our model when making forecasts on a horizon of over 6 months...|$|R
5000|$|ACA 411: Tracking Health Reform in California is an {{interactive}} tool that provides baseline and <b>trend</b> <b>data</b> for selected measures {{to examine how}} the ACA is changing insurance coverage, access to health care, and affordability in California.|$|E
5000|$|The National Education Longitudinal Study of 1998 (NELS:88), {{which began}} with an 8th grade cohort in 1988, {{providing}} <b>trend</b> <b>data</b> about critical transitions experienced by young people as they develop, attend school, and embark on their careers ...|$|E
50|$|Locky is {{reported}} to have been sent to about a half-million users on February 16, 2016, and for the period immediately after the attackers increased their distribution to millions of users. Despite the newer version, Google <b>Trend</b> <b>data</b> indicates that infections have dropped off around June 2016.|$|E
40|$|Purpose: Previous {{studies have}} showed that Google Trends of influenza-related search data were highly {{correlated}} with conventional influenza-like illness (ILI) surveillance data. A timely and effectively surveillance method for influenza monitoring and early alert is essential for Taiwan, where only conventional surveillance is currently available. The {{purpose of this study}} was to evaluate the feasibility of using Google Trends for influenza surveillance in Taiwan. Method: This study investigated the correlation between 208 weeks of ILI and virologic influenza surveillance <b>data</b> and Google <b>Trends</b> <b>data</b> for influenza-related search terms (H 1 N 1, fever, sore throat, cough, flu, influenza A, type A influenza, influenza B and cold) in Taiwan from Jan 3 rd 2010 to Dec 28 th 2013. Pearson correlation coefficients and lag correlations of maximal 2 weeks were calculated. Results: In terms of the correlation between Google <b>Trends</b> <b>data</b> and ILI surveillance data in Taiwan during the study period, the search term flu showed the strongest correlation with both outpatient and emergency room ILI visit rate (r = 0. 82 and r= 0. 70, p< 0. 001). Except for fever and sore throat, the correlation coefficients between Google <b>Trends</b> <b>data</b> and ILI surveillance data for all keywords were statistically significant (r= 0. 16, p= 0. 02 to 0. 82, p< 0. 001). When compared with virologic surveillance rate, Google Trends for influenza B had the highest correlation in 2012 (r= 0. 91, p< 0. 001). In addition, Google <b>Trends</b> <b>data</b> for all keywords had strong correlations with the outpatient and emergency room ILI visit data in 2011, and the correlation coefficients ranged from 0. 25 to 0. 90 (p< 0. 001). The lag correlation analysis indicated that most of keywords had the maximum correlation coefficients at a lag time of 0 weeks. Conclusion: The strong correlations between Google <b>Trends</b> <b>data</b> and CDC ILI surveillance data in Taiwan suggested that Google <b>Trends</b> <b>data</b> fitted well with the conventional ILI surveillance data. The correlation between ILI surveillance <b>data</b> and Google <b>Trends</b> <b>data</b> was higher than that between Google Trends and virologic surveillance data. The lag time correlation analysis did not indicate a significant preceding for most of search terms in Google Trends than CDC surveillance data, which suggested that Google Trends for the search terms used in this study did not show an advantage on the monitoring of influenza outbreak when compared with the conventional surveillance data in Taiwan. In summary, this study found that Google Trends in traditional Chinese could be applied as a complementary tool for influenza surveillance in Taiwan, especially for the ILI surveillance. Further study should develop more representative keywords and predictive model to estimate influenza activities as well as assist in detecting early alert of influenza outbreaks. published_or_final_versionPublic HealthMasterMaster of Public Healt...|$|R
40|$|Stock {{prediction}} models using {{search query}} data {{is a modern}} phenomena and arelatively unexplored subject which potentially yields improvements to currentlyestablished prediction algorithms. This thesis will strive to improve an autoregressiveprediction model by analyzing concurrent search query data to conclude whether ornot taking such data into account will improve the prediction model. Multiplealternatives for sources of search query data has been analyzed and Google Trendswas concluded as the most suitable candidate. The thesis found no strong indicatorthat amplifying the autoregressive algorithm with Google <b>Trends</b> <b>data</b> would producebetter stock predictions. There remains to be found an elegant solution to improvingprediction models using Google <b>Trends</b> <b>data...</b>|$|R
50|$|Before {{considering}} <b>trends</b> in real <b>data,</b> it {{is useful}} to understand <b>trends</b> in random <b>data.</b>|$|R
5000|$|Thingbuzz {{searches}} for things or products {{that people are}} talking about or recommending on Twitter, and presents the data {{in a way that is}} consumable and searchable. Thingbuzz also shows crowdsourced emerging <b>trend</b> <b>data,</b> measured by the number of tweets, the credibility ranking of tweeters and time.|$|E
50|$|DPI allows ISPs {{to gather}} {{statistical}} information about use patterns by user group. For instance, {{it might be}} of interest whether users with a 2 Mbit connection use the network in a dissimilar manner to users with a 5 Mbit connection. Access to <b>trend</b> <b>data</b> also helps network planning.|$|E
5000|$|An air data {{computer}} (ADC) is {{an essential}} avionics component found in modern glass cockpits. This computer, rather than individual instruments, can determine the calibrated airspeed, Mach number, altitude, and altitude <b>trend</b> <b>data</b> from an aircraft's pitot-static system. [...] In some very high speed aircraft such as the Space Shuttle, equivalent airspeed is calculated instead of calibrated airspeed.|$|E
50|$|Mobile Development Series:A semi-annual {{survey of}} over 400 {{developers}} worldwide who are {{actively engaged in}} mobile development. This series was started in 2003 and contains both <b>trending</b> <b>data</b> and dynamic content current to the flux and change in mobile development.|$|R
40|$|The U. S. Geological Survey (USGS) {{has begun}} the {{development}} of operational, 30 -m resolution annual thematic land cover data {{to meet the needs}} of a variety of land cover data users. The Continuous Change Detection and Classification (CCDC) algorithm is being evaluated as the likely methodology following early trials. Data for training and testing of CCDC thematic maps have been provided by the USGS Land Cover Trends (LC Trends) project, which offers sample-based, manually classified thematic land cover data at 2755 probabilistically located sample blocks across the conterminous United States. These samples represent a high quality, well distributed source of data to train the Random Forest classifier invoked by CCDC. We evaluated the suitability of LC <b>Trends</b> <b>data</b> to train the classifier by assessing the agreement of annual land cover maps output from CCDC with output from the LC Trends project within 14 Landsat path/row locations across the conterminous United States. We used a small subset of circa 2000 data from the LC Trends project to train the classifier, reserving the remaining <b>Trends</b> <b>data</b> from 2000, and incorporating LC <b>Trends</b> <b>data</b> from 1992, to evaluate measures of agreement across time, space, and thematic classes, and to characterize disagreement. Overall agreement ranged from 75 % to 98 % across the path/rows, and results were largely consistent across time. Land cover types that were well represented in the training data tended to have higher rates of agreement between LC Trends and CCDC outputs. Characteristics of disagreement are being used to improve the use of LC <b>Trends</b> <b>data</b> as a continued source of training information for operational production of annual land cover maps...|$|R
40|$|Abstract {{copyright}} UK Data Service {{and data}} collection copyright owner. A quarterly survey of house sales in Bedfordshire to monitor <b>trends.</b> <b>Data</b> are collected on the property (location, price, age, type, size); on the vendor (destination); and on the purchaser (age, origin, workplace and reason for move...|$|R
50|$|Due {{to lack of}} {{research}} and rarity of sightings/capture, population <b>trend</b> <b>data</b> for the Coeur d'Alene salamander are spotty at best. Small sites are thought to exist where the species is abundant and capable of observation, but without an implemented monitoring program, few data are available with which to evaluate population trends. This lack of information puts the Coeur d'Alene salamander on both Idaho and Montana's Species of Special Concern lists.|$|E
50|$|The {{achievement}} gap, {{as reported}} in <b>trend</b> <b>data</b> collected by the National Assessment of Educational Progress (NAEP), has become a focal point of education reform efforts {{by a number of}} nonprofit organizations and advocacy groups. Attempts to minimize the achievement gap by improving equality of access to educational opportunities have been numerous but fragmented, such as affirmative action, multicultural education, finance equalization, and interventions to improve school testing, teacher quality and accountability.|$|E
50|$|In {{the context}} of a pulse oximeter, an episodic scanner could be {{implemented}} to send anevent report to the manager on every heart beat. A periodic scanner could be implementedto send an event report containing <b>trend</b> <b>data</b> every five seconds, say. As with the otherobjects, the data contained within the scanner event reports are specified in theconfiguration phase - the agent has considerable flexibility in defining the data it will send,yet any configuration will be intelligible to the manager.|$|E
40|$|This study {{introduces}} a monthly coincident indicator for consumption in Germany based on Google <b>Trends</b> <b>data</b> on web search activity. In real-time nowcasting experiments the indicator outperforms common survey-based indicators in predicting consumption. Unlike those indicators, it provides predictive information beyond that already captured in other macroeconomic variables...|$|R
30|$|Nevertheless, {{there are}} some caveats to Google Trends. Because only a sample of {{searches}} is used and searches for which there are insufficient observations are excluded, Google <b>Trends</b> <b>data</b> could be affected by sample bias (in small samples, only random draws with enough observations are shown) (Kearney and Levine 2015). A second issue is sampling variability (problematic for standard error calculations when data are treated as fixed rather than random variables). To addresses these issues, the authors repeat their searches on Google Trends several times and calculate {{the average of the}} indices (to reduce the sampling variability). Another shortcoming of Google <b>Trends</b> <b>data</b> is that demographic information is not available. As temporal and geographic variations are sources of variation that labour economists typically rely on, the above issues are important to account for.|$|R
40|$|This paper {{proposes a}} test of the rank of the {{submatrix}} of b, where b is a cointe-grating matrix+ In addition, the submatrix of b 4, an orthogonal complement to b, is investigated+ We construct the test statistic by using the eigenvalues of the qua-dratic form of the submatrix+ We show that the test statistic has a limiting chi-square distribution when data are nontrending, whereas for <b>trending</b> <b>data</b> we have to consider a conservative test or other testing procedure that requires the pretest {{of the structure of the}} matrix+ Finite sample simulations show that, although the simulation settings are limited, the proposed test works well for nontrending data, whereas we have to carefully use the test for <b>trending</b> <b>data</b> because it may become too conservative in some cases+ 1...|$|R
