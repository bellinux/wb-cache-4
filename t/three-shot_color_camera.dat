0|1124|Public
30|$|Most DR systems use <b>color</b> <b>cameras</b> only. We {{introduce}} DR {{methods that}} use special sensors, such as RGB-D (<b>color</b> <b>camera</b> and rangefinder), and medical instruments, such as endoscopy, ultrasound, and X-ray.|$|R
50|$|Sophisticated <b>color</b> <b>cameras</b> {{with high}} <b>color</b> {{resolution}} {{are capable of}} detecting millions of colors to better distinguish more subtle color defects. Trichromatic <b>color</b> <b>cameras</b> (also called three-channel cameras) divide light into three bands, which can include red, green and/or blue within the visible spectrum as well as IR and UV.|$|R
5000|$|Underwater cameras (2): 480 TVL <b>Color</b> <b>Camera</b> and low-light camera.|$|R
50|$|In {{the twentieth}} century {{we have a new}} {{generation}} of <b>cameras,</b> <b>color</b> <b>cameras,</b> digital cameras, high definition cameras, the same advances came to video and cinema.|$|R
2500|$|Built-in <b>color</b> <b>camera,</b> to {{the right}} of the display, VGA {{resolution}} (640×480) ...|$|R
5000|$|... #Caption: TK-41 <b>color</b> <b>camera</b> {{on the set}} of Major Astro, c. 1964.|$|R
5000|$|... #Caption: William Van Doren Kelley and his invention, the Prizma <b>color</b> <b>camera.</b>|$|R
5000|$|VGA <b>color</b> <b>camera</b> in the {{forehead}} for image recognition, and video recording ...|$|R
2500|$|File:RCA <b>Color</b> Broadcast <b>Camera</b> TK-41C - 2.jpg|1954 RCA TK-41C dolly-mounted <b>color</b> {{broadcast}} <b>camera</b> ...|$|R
5000|$|HDC-500 High Definition <b>Color</b> <b>Camera</b> (3 CCD, world's first CCD-based HD video camera) ...|$|R
40|$|Abstract — This work proposes two {{particle}} filter-based visual trackers — one using output {{images from}} a <b>color</b> <b>camera</b> {{and the other}} using images from a time-of-flight range imaging sensor. These proposed trackers were compared {{in order to identify}} the advantages and drawbacks of utilizing output images from the <b>color</b> <b>camera</b> as opposed to output from the time-of-flight range imaging sensor for the most efficient visual tracking. This paper is also unique in its novel mixture of efficient methods to produce two stable and reliable human trackers using the two cameras. Index Terms — visual tracking, <b>color</b> <b>camera,</b> time-of-flight sensor, illumination invariant, particle filter I...|$|R
5000|$|... #Caption: Apollo 14 EVA frame {{demonstrates}} the [...] "blooming" [...] issue with <b>Color</b> <b>Camera.</b>|$|R
5000|$|... #Subtitle level 5: Fusion of 3D lidar and <b>color</b> <b>camera</b> for {{multiple}} object detection and tracking ...|$|R
25|$|Raw sensor streams: Access to {{low-level}} streams {{from the}} depth sensor, <b>color</b> <b>camera</b> sensor, and four-element microphone array.|$|R
50|$|For {{the first}} nine months of NTSC color in 1953-1954, CBS {{continued}} to use its field-sequential <b>color</b> television <b>cameras,</b> with the field rate and signal adapted for NTSC standards, until RCA delivered its first production model of an NTSC <b>color</b> <b>camera</b> in time for the 1954-55 season.|$|R
5000|$|... #Caption: A 1912 color {{photograph}} of Sergei Mikhailovich Prokudin-Gorskii, who documented the Russian Empire with a <b>color</b> <b>camera</b> from 1909 to 1915.|$|R
5000|$|... but {{researchers}} have found methods to adapt them to <b>color</b> <b>camera</b> images. Recently, the use of super-resolution for 3D data has also been shown.|$|R
40|$|In this paper, {{we propose}} an {{approach}} for generating free viewpoint videos based on multiple depth and <b>color</b> <b>cameras</b> to resolve issues encountered with traditional <b>color</b> <b>cameras</b> techniques. Our system {{is based on}} consumer products such as Kinect that does not provide satisfying quality in terms of resolution and noise. Our contribution is then to propose a full pipeline for enhancing the depth maps and finally {{improving the quality of}} the novel viewpoint generated. Index Terms — Free-viewpoint video, depth camera, up-sampling, noise reduction, FT...|$|R
50|$|Outcome Budget 2016-17 of Department of Space {{mentions}} that development of space grade <b>color</b> <b>camera</b> and image storage unit for SRE-2 would be undertaken during year 2016-17.|$|R
5000|$|... #Caption: Stan Lebar, {{the project}} manager for Westinghouse's Apollo Television Cameras, shows the Field-Sequential <b>Color</b> <b>Camera</b> {{on the left and}} the Monochrome Lunar Surface Camera on the right.|$|R
40|$|A novel {{technique}} {{that uses a}} single <b>color</b> <b>camera</b> to capture high-resolution three-dimensional (3 -D) geometry and the perfectly aligned color texture simultaneously is discussed. A projector projects three phase-shifted black-and-white fringe patterns onto the object, and a <b>color</b> <b>camera</b> captures the fringe images reflected by the object. From these three fringe images, both 3 -D shape and the color texture are obtained. Moreover, since only three fringe images are required, this proposed technique permits real-time 3 -D shape measurement. Experiments are presented to demonstrate {{the success of this}} technique...|$|R
40|$|We {{present a}} {{quantitative}} phase microscopy method that uses a Bayer mosaic <b>color</b> <b>camera</b> to simultaneously acquire off-axis interferograms in transmission mode at two distinct wavelengths. Wrapped phase information is processed using a two-wavelength algorithm to extend {{the range of the}} optical path delay measurements that can be detected using a single temporal acquisition. We experimentally demonstrate this technique by acquiring the phase profiles of optically clear microstructures without 2 pi ambiguities. In addition, the phase noise contribution arising from spectral channel crosstalk on the <b>color</b> <b>camera</b> is quantified...|$|R
40|$|This work proposes two {{particle}} filter-based visual trackers — one using output {{images from}} a <b>color</b> <b>camera</b> {{and the other}} using images from a time-of-flight range imaging sensor. These proposed trackers were compared {{in order to identify}} the advantages and drawbacks of utilizing output images from the <b>color</b> <b>camera</b> as opposed to output from the time-of-flight range imaging sensor for the most efficient visual tracking. This paper is also unique in its novel mixture of efficient methods to produce two stable and reliable human trackers using the two cameras. </p...|$|R
40|$|Lateral {{chromatic}} aberration (CA) of <b>color</b> <b>cameras</b> has great {{effects on the}} imaging quality. This paper presents a novel method to full-field calibrate lateral CA between color channels by using unwrapped phase data. Closed circle sinusoidal fringe patterns having the optimum three-fringe numbers are generated and displayed on a liquid crystal screen consecutively through red, green and blue channels. These closed fringe patterns are captured by a <b>color</b> <b>camera.</b> The wrapped phase and unwrapped phase of each pixel can be calculated by using four-step phase shifting algorithm and optimum three-fringe number method, respectively. The pixel deviations produced by lateral CA are computed by comparing the obtained absolute phase data between red, blue, and green channels in polar coordinate system and calibration is accomplished in Cartesian coordinate system. Lateral CA between color channels of the <b>color</b> <b>camera</b> can be compensated by using the calibrated data. Simulated and experimental results show {{the validity of the}} proposed calibration and compensation method...|$|R
50|$|Special Operations TALON (SOTAL): Does {{not have}} the robotic arm {{manipulator}} but carries day/night <b>color</b> <b>cameras</b> and listening devices; lighter due {{to the absence of}} the arm, for reconnaissance missions.|$|R
5000|$|Yakov Borisovich Rozval - {{the author}} of many {{outstanding}} inventions, including the first Soviet broadcasting <b>color</b> <b>camera</b> {{as well as many}} others. A total of about 50 inventions and patents. Including: ...|$|R
50|$|The {{system was}} {{composed}} of the <b>Color</b> Television <b>Camera</b> (CTV) and the Television Control Unit (TCU). These were connected to the Lunar Communications Relay Unit (LCRU) when mounted on the Lunar Roving Vehicle (LRV). Like the Westinghouse <b>Color</b> <b>Camera,</b> it used the field-sequential color system, and used the same ground-station signal processing and color decoding techniques to produce a broadcast NTSC color video signal.|$|R
40|$|The {{need for}} {{autonomous}} navigation and intelligent control of unmanned sea surface vehicles requires a mechanically robust sensing architecture that is watertight, durable, and insensitive to vibration and shock loading. The sensing system developed here comprises four {{black and white}} cameras and a single <b>color</b> <b>camera.</b> The cameras are rigidly mounted to a camera bar that can be reconfigured to mount multiple vehicles, and act as both navigational cameras and application cameras. The cameras are housed in watertight casings to protect them and their electronics from moisture and wave splashes. Two of {{the black and white}} cameras are positioned to provide lateral vision. They are angled away {{from the front of the}} vehicle at horizontal angles to provide ideal fields of view for mapping and autonomous navigation. The other two black and white cameras are positioned at an angle into the <b>color</b> <b>camera's</b> field of view to support vehicle applications. These two cameras provide an overlap, as well as a backup to the front <b>camera.</b> The <b>color</b> <b>camera</b> is positioned directly in the middle of the bar, aimed straight ahead. This system is applicable to any sea-going vehicle, both on Earth and in space...|$|R
40|$|Time-of-Flight matrix sensors {{currently}} available {{allow for the}} acquisition of range maps at video rate but usually have a limited resolution. At the same time high resolution <b>color</b> <b>cameras</b> are widely available. This makes highly desirable methods {{that are able to}} exploit the combined use of ToF sensors and <b>color</b> <b>cameras</b> to obtain high resolution range maps. This work presents a novel interpolation technique that exploits side information from a standard <b>color</b> <b>camera</b> to increase the resolution of range maps. A segmented version of the high resolution color image is used in order to identify the main objects in the scene, while a novel surface prediction scheme is used to interpolate the available depth samples. Critical issues like the joint calibration of the two devices and the unreliability of the acquired data have also been taken into account with ad- hoc solutions. The performance of the proposed scheme has been verified with both synthetic and real-world data and experimental results have shown how the proposed method allows to obtain a more accurate interpolation with sharper edges if compared with standard approaches...|$|R
40|$|With the {{development}} of optoelectronic technologies, <b>color</b> <b>cameras</b> have been widely exploited in space remote sensing, earth observations from space, environmental monitoring, urban construction, and many other fields. Currently, most commercial <b>color</b> <b>cameras</b> use a single charge coupled device (CCD) or complementary metal-oxide-semiconductor (CMOS) sensor that has a Bayer color filter array (CFA) on its pixel surface to obtain red (R), green (G), or blue (B) samples. As a way of evaluating imaging quality, modulation transfer function (MTF) can provide a comprehensive and objective metric for camera imaging performance. In the conventional knife-edge method for <b>color</b> <b>camera</b> MTF measurement, a linear uniform sampling of the edge spread function (ESF) must be completed before a fast Fourier transform (FFT) can be applied. As the sampling rate becomes large, the number of pixel points on the line which {{is parallel to the}} knife-edge become less. So taking average of the pixel points to obtain ESF can be strongly affected by the noise of sensor. Therefore it is necessary to balance the influences of sampling rate and sensor noise on the MTF measurement, and the recommended sampling rate is 4 - 6. When the tilt angle of knife-edge has an error, the non-uniform sampling ESF can be obtained by the slanted knife-edge method. This leads to a variation in the results of the camera MTF on a spatial frequency scale and early cut-off. The best MTF results of camera can be obtained by rotating knife-edge, calculating MTF power under different tilt angles of knife-edge, and finding the maximum MTF power. And we propose an algorithm for Bayer filter <b>color</b> <b>camera</b> MTF measurement. The algorithm processing includes extracting R, G, B colors of knife-edge images; projection; differential operation; Hanning window filtration; FFT; correction; weighting combination of R, G, B colors MTF; MTF power calculation; optimal tilt angle of knife-edge estimation. To verify the accuracy of the proposed method, the weighting response factors of R, G, B colors are calibrated and an experimental setup for <b>color</b> <b>camera</b> MTF measurement is established. The knife-edge target is rotated in angle steps of 0. 02 degrees, and the MTF results are calculated under different tilt angles of knife-edge within +/- 0. 1 degrees. surrounding the estimate position by the proposed algorithm. The maximum differences of MTF results between the proposed method and fringe target method are 0. 061 (Nyquist frequency f(c)) and 0. 043 (f(c) / 2), respectively. The results show that by searching the optimal tilt angle of knife-edge, the effect of non-uniform sampling on MTF result of <b>color</b> <b>camera</b> can be eliminated. Compared with the conventional method, the proposed method is superior for the measurement of the super-sampled MTF of <b>color</b> <b>camera.</b> Meanwhile, this method can also be applied to MTF measurements of radiographic systems, such as X-ray imaging system and other systems. </p...|$|R
50|$|TADS {{contains}} a thermographic {{camera and a}} monochrome daylight television camera. With the improvements planned with M-TADS in the block III level AH-64D, the monochrome TV-camera is planned to be replaced with a full <b>color</b> <b>camera.</b>|$|R
500|$|This was {{the first}} mission to {{broadcast}} extensive color television coverage from the lunar surface, using the Westinghouse Lunar <b>Color</b> <b>Camera.</b> (The same <b>color</b> <b>camera</b> model was used on Apollo 12 and provided about 30 minutes of color telecasting before it was inadvertently pointed at the Sun, ending its usefulness.) While on the Moon, Shepard used a Wilson six-iron head attached to a lunar sample scoop handle to drive golf balls. Despite thick gloves and a stiff spacesuit, which forced him to swing the club with one hand, Shepard struck two golf balls, driving the second, as he jokingly put it, [...] "miles and miles and miles".|$|R
25|$|Ichikawa {{hoped to}} make the film in <b>color,</b> but <b>color</b> <b>cameras</b> were too big, and thus costly, to be moved to Burma. Much of the film was shot in Yasui, Hakone and the Izu Peninsula in Japan.|$|R
40|$|International audienceThe {{combination}} of range sensors with <b>color</b> <b>cameras</b> {{can be very}} useful for robot navigation, semantic perception, manipulation, and telepresence. Several methods of combining range- and color-data have been investigated and successfully used in various robotic applications. Most of these systems suffer from the problems of noise in the range-data and resolution mismatch between the range sensor and the <b>color</b> <b>cameras,</b> since the resolution of current range sensors is {{much less than the}} resolution of <b>color</b> <b>cameras.</b> High-resolution depth maps can be obtained using stereo matching, but this often fails to construct accurate depth maps of weakly/repetitively textured scenes, or if the scene exhibits complex self-occlusions. Range sensors provide coarse depth information regardless of presence/absence of texture. The use of a calibrated system, composed of a time-of-flight (TOF) camera and of a stereoscopic camera pair, allows data fusion thus overcoming the weaknesses of both individual sensors. We propose a novel TOF-stereo fusion method based on an efficient seed-growing algorithm which uses the TOF data projected onto the stereo image pair as an initial set of correspondences. These initial ''seeds'' are then propagated based on a Bayesian model which combines an image similarity score with rough depth priors computed from the low-resolution range data. The overall result is a dense and accurate depth map at the resolution of the <b>color</b> <b>cameras</b> at hand. We show that the proposed algorithm outperforms 2 D image-based stereo algorithms and that the results are of higher resolution than off-the-shelf color-range sensors, e. g., Kinect. Moreover, the algorithm potentially exhibits real-time performance on a single CPU...|$|R
50|$|KMED-TV {{bought the}} first <b>color</b> <b>cameras</b> in Southern Oregon in 1968, {{a year of}} many firsts for the station. That year also saw the area's first live remote broadcast, the first {{television}} editorials and the first use of live microwave technology.|$|R
5000|$|Colorplexer (a {{portmanteau}} of [...] "color" [...] and [...] "multiplexer") was the RCA {{trade name}} for its complex electronic device which encoded discrete red, {{green and blue}} 3-color images, as from a <b>color</b> <b>camera,</b> into a composite monochrome-compatible color information stream.|$|R
