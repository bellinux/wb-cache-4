33|25|Public
25|$|Google Maps {{began as}} a C++ desktop program {{designed}} by Lars and Jens Eilstrup Rasmussen at Where 2 Technologies. In October 2004, the company was acquired by Google, which converted it into a web application. After additional acquisitions of a geospatial data visualization company and a realtime <b>traffic</b> <b>analyzer,</b> Google Maps was launched in February 2005. The service's front end utilizes JavaScript, XML, and Ajax. Google Maps offers an API that allows maps to be embedded on third-party websites, and offers a locator for urban businesses and other organizations in numerous countries around the world. Google Map Maker allowed users to collaboratively expand and update the service's mapping worldwide but was discontinued from March, 2017. However crowdsourced contributions to Google Maps are not ending as the company announced those features will be transferred to Google's Local Guides programme.|$|E
50|$|Features {{which set}} ControlNet {{apart from other}} fieldbuses include the {{built-in}} support for fully redundant cables {{and the fact that}} communication on ControlNet can be strictly scheduled and highly deterministic. Due to the unique physical layer, common network sniffers such as Wireshark cannot be used to sniff ControlNet packets. Rockwell Automation provides ControlNet <b>Traffic</b> <b>Analyzer</b> software to sniff and analyze ControlNet packets.|$|E
50|$|According {{to former}} and current US {{government}} officials, {{there are more}} than a dozen major US based Internet switching stations where this kind of filtering takes place, which is not only near the sites where the main undersea Internet cables enter the US. An actual example of a facility where NSA taps Internet backbone cables is Room 641A in the San Francisco switching station of AT&T, which was revealed in 2006. One of the devices used to filter the Internet traffic is the Semantic <b>Traffic</b> <b>Analyzer</b> or STA 6400 made by Boeing subsidiary Narus.|$|E
40|$|Hardware aided time {{stamping}} of Ethernet frames {{is used to}} implement a two way time transfer. The method is capable to either operate actively by initiating or relaying frames, or passively by utilization the traffic on, preferably, optical links. Time stability of unfiltered measurements taken on local links is about 3. 5 ns @ 1 s TDEV, reaching below 1 ns for time intervals of about 100 s. The presented method is specific to a family of commercial <b>traffic</b> <b>analyzers,</b> but can be generalized for any similar capable hardware...|$|R
40|$|Abstract—Anonymous MANET routing {{relies on}} {{techniques}} such as re-encryption on each hop to hide end-to-end commu-nication relations. However, passive signal detectors and <b>traffic</b> <b>analyzers</b> can still retrieve sensitive information from PHY and MAC layers to derive end-to-end communication relations through statistical traffic analysis. In this paper, we propose a Statistical Traffic pAttern discoveRy System (STARS) based on eigen analysis which can greatly improve the accuracy to derive traffic patterns in MANETs. STARS intends {{to find out the}} sources and destinations of captured packets and to discover the end-to-end communication relations. The proposed approach is purely passive. It does not require analyzers to be actively involved in MANET transmissions and to possess encryption keys to decrypt traffic. We present theoretical models as well as extensive simulations to demonstrate our solutions. I...|$|R
40|$|Abstract: Various {{powerful}} instruments {{exist today}} to evaluate information {{quality in the}} web context. They can be categorized into five types of tools, namely performance monitoring systems, site <b>analyzers,</b> <b>traffic</b> <b>analyzers,</b> web mining tools and survey tools (to generate opinion-based user feedback). The combined use of these tools can enable an organization to measure the multiple dimensions of information quality in the Internet or Intranet context. This however requires a clear methodology {{that is based on}} systematic sequential steps and on an information quality framework that outlines relevant measurement criteria. In this paper we show which information quality criteria can be measured with the help of these tools and we provide an overview on {{the most important of these}} instruments. We present the IQM-methodology to match information quality criteria with adequate measurement tools...|$|R
50|$|Google Maps {{began as}} a C++ desktop program {{designed}} by Lars and Jens Eilstrup Rasmussen at Where 2 Technologies. In October 2004, the company was acquired by Google, which converted it into a web application. After additional acquisitions of a geospatial data visualization company and a realtime <b>traffic</b> <b>analyzer,</b> Google Maps was launched in February 2005. The service's front end utilizes JavaScript, XML, and Ajax. Google Maps offers an API that allows maps to be embedded on third-party websites, and offers a locator for urban businesses and other organizations in numerous countries around the world. Google Map Maker allowed users to collaboratively expand and update the service's mapping worldwide but was discontinued from March, 2017. However crowdsourced contributions to Google Maps are not ending as the company announced those features will be transferred to Google's Local Guides programme.|$|E
5000|$|The National Security Agency (NSA), with {{cooperation}} from AT&T Inc., has used Deep Packet Inspection technology to make internet traffic surveillance, sorting, and forwarding more intelligent. The DPI {{is used to}} find which packets are carrying e-mail or a Voice over Internet Protocol (VoIP) telephone call.Traffic associated with AT&T’s Common Backbone was [...] "split" [...] between two fibers, dividing the signal so that 50 percent of the signal strength went to each output fiber. One of the output fibers was diverted to a secure room; the other carried communications on to AT&T’s switching equipment. The secure room contained Narus traffic analyzers and logic servers; Narus states that such devices are capable of real-time data collection (recording data for consideration) and capture at 10 gigabits per second. Certain traffic was selected and sent over a dedicated line to a [...] "central location" [...] for analysis. According to an affdavit by expert witness J. Scott Marcus, a former senior advisor for Internet Technology at the US Federal Communications Commission, the diverted traffic [...] "represented all, or substantially all, of AT&T’s peering traffic in the San Francisco Bay area", and thus, [...] "the designers of the ... configuration made no attempt, in terms of location or position of the fiber split, to exclude data sources [...] primarily of domestic data".Narus's Semantic <b>Traffic</b> <b>Analyzer</b> software, which runs on IBM or Dell Linux servers using DPI technology, sorts through IP traffic at 10Gbit/s to pick out specific messages based on a targeted e-mail address, IP address or, {{in the case of}} VoIP, telephone number. President George W. Bush and Attorney General Alberto R. Gonzales have asserted that they believe the president has the authority to order secret intercepts of telephone and e-mail exchanges between people inside the United States and their contacts abroad without obtaining a FISA warrant.|$|E
40|$|The Measurement-based Admission Control is used {{to achieve}} the {{required}} Quality of Service. The Measurement- based Admission Control mechanism provides significant functionality for integrated service guaranties. This paper presents {{the model of the}} <b>traffic</b> <b>analyzer</b> for real-time applications. It consists of two cross-dependent sub-modules: traffic measurement and traffic estimator. The model presented in the paper is characterized by low system overheads for real-time traffic parameters estimation...|$|E
40|$|The article {{presents}} {{a comparison of}} three devices and two methods {{that are used to}} count traffic flow. All measurements were carried out at a roundabout in Ostrava, where the following devices were used: Viacount II, Icoms TSM-SA, and Nu-Metrics NC- 200 <b>traffic</b> <b>analyzers.</b> The methods of manual counting of vehicles and of counting vehicles based on video footage were used. The article also provides a comparison of the results obtained, namely in terms of traffic intensity, and of the measurements of the length and speed of vehicles. Further, we evaluate the results and explore the deviations from reality and the reasons why they occur. The article concludes with the recommended procedure designed to eliminate the identified problems, in order to ensure the most accurate results, with no significant deviations...|$|R
40|$|Current Internet e-mail {{facilities}} {{are built on}} the foundation of standard rules and protocols, which usually allow {{a considerable amount of}} "freedom" to their designers. Each of these standards has been defined based on a number of vendor specific implementations, in order to provide common inter-working procedures for cross-vendor communication. Thus, a lot of optional and redundant information is being exchanged during e-mail sessions, which is available to implement versatile covert channel mechanisms. The work exploits this possibility by presenting a simple but effective steganographic schema {{that can be used to}} deploy robust secret communication through e-mail. This schema can offer unidirectional asynchronous one-to-one or one-to-many covert channel facilities that are able to bypass the most sophisticated firewalls and <b>traffic</b> <b>analyzers.</b> Its implementation neither affects the involved transport protocols nor causes any perceivable performance degradation or data loss to the end-users. Â© 2011 IEEE...|$|R
40|$|International {{audience}} While {{the ultimate}} goal of kernel-level network stacks is to manage individual packets at line rate, the goal of user-level network monitoring applications is instead to match packets with the flow they belong to, and take actions accordingly. With current improvements in Network Interface Cards hardware and network software stacks, traffic monitors and <b>traffic</b> <b>analyzers</b> are fed with multi-Gbps streams of packets [...] which de facto pushes bottlenecks from kernel-level networking stack up to user-level applications. In this paper, we argue that flow management is a crucial module for any user-application that needs to process traffic at multiple Gbps, and we study the performance impact of different design choices of the flow management module by adopting a trace-driven emulation approach. While our results do not show a single ''best'' system settings under all circumstances, they highlight several tradeoffs, in terms of, e. g., the kind of structure, its size, and the computational complexity, that may affect system performance in a non-trivial way. We further make our software tools available to the scientific community to promote sharing of best practices</p...|$|R
40|$|This paper {{describes}} {{a pair of}} systems {{which can be used}} to obtain realistic traffic samples in a Sector/TMA from a given real traffic database. Those are a <b>traffic</b> <b>analyzer</b> and a traffic pattern generator. These two systems allow the ATM engineer to both gain insight on the traffic structure of the area under analysis and to obtain statistically significant samples for the evaluation of operational concepts and procedure changes, perform analysis of ATM performance under traffic changes, [...] ...|$|E
40|$|In this paper, a {{modeling}} and simulation framework is proposed for generating data for training and testing intrusion detection systems. The framework can develop models of web usage from web server logs in a data driven fashion and the actual traffic is generated by employing the web browser installed on the host. Additionally, we employed an intrusion detection system as a <b>traffic</b> <b>analyzer</b> to validate the synthetic data that the framework generated and compared it against the standard intrusion detection system benchmark data, namely KDD 99 datasets...|$|E
40|$|This {{bachelor}} work {{deals with}} the representation of captured network traffic in XML and storing within a database system Oracle by using XML schema. The beginning explains the basics of computer networks, network management and network protocols that are captured. Followed by chapters on network <b>traffic</b> <b>analyzer,</b> NetPDL format used to describe intercepted traffic, a chapter devoted to the foundation of relational database systems and the foundation of Oracle database system. At {{the end of the}} bachelor work there are chapters dealing with the created XML schemas, implementation of the program, program tools and the description how to use the program...|$|E
40|$|This {{document}} {{describes a}} set of heuristics for distinguishing IPsec ESP-NULL (Encapsulating Security Payload without encryption) packets from encrypted ESP packets. These heuristics {{can be used on}} intermediate devices, like <b>traffic</b> <b>analyzers,</b> and deep-inspection engines, to quickly decide whether or not a given packet flow is encrypted, i. e., whether or not it can be inspected. Use of these heuristics does not require any changes made on existing IPsec hosts that are compliant with RFC 4303. Status of This Memo This document is not an Internet Standards Track specification; it is published for informational purposes. This document {{is a product of the}} Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by the Internet Engineering Steering Group (IESG). Not all documents approved by the IESG are a candidate for any level of Internet Standard; see Section 2 of RFC 5741. Information about the current status of this document, any errata, and how to provide feedback on it may be obtained a...|$|R
40|$|While the {{ultimate}} goal of kernel-level network stacks is to manage individual packets at line rate, the goal of user-level network monitoring applications is instead to match packets with the flow they belong to, and take actions accordingly. With current improvements in Network Interface Cards hardware and network software stacks, traffic monitors and <b>traffic</b> <b>analyzers</b> are fed with multi-Gbps streams of packets - which de facto pushes bottlenecks from kernel-level networking stack up to user-level applications. In this paper, we argue that flow management is a crucial module for any user-application that needs to process traffic at multiple Gbps, and we study the performance impact of different design choices of the flow management module by adopting a trace-driven emulation approach. While our results do not show a single "best" system settings under all circumstances, they highlight several tradeoffs, in terms of, e. g., the kind of structure, its size, and the computational complexity, that may affect system performance in a non-trivial way. We further make our software tools available to the scientific community to promote sharing of best practices...|$|R
40|$|Part 1 : Tools and Lessons Learned from Passive MeasurementInternational audienceWhile the {{ultimate}} goal of kernel-level network stacks is to manage individual packets at line rate, the goal of user-level network monitoring applications is instead to match packets with the flow they belong to, and take actions accordingly. With current improvements in Network Interface Cards hardware and network software stacks, traffic monitors and <b>traffic</b> <b>analyzers</b> are fed with multi-Gbps streams of packets – which de facto pushes bottlenecks from kernel-level networking stack up to user-level applications. In this paper, we argue that flow management is a crucial module for any user-application that needs to process traffic at multiple Gbps, and we study the performance impact of different design choices of the flow management module by adopting a trace-driven emulation approach. While our results do not show a single “best” system settings under all circumstances, they highlight several tradeoffs, in terms of, e. g., the kind of structure, its size, and the computational complexity, that may affect system performance in a non-trivial way. We further make our software tools available to the scientific community to promote sharing of best practices...|$|R
40|$|Internet {{technology}} has been used increasingly to enhance the global competitiveness of various industries through the widespread applications of cost effective electronic commerce (EC). In this paper, we focus on information infrastructure, flow coordination, and EC front-end for supply chain management. Three main modules are proposed to conjoin various business organizations and to strengthen business competence, namely (1) an efficient web page and catalogue generator; (2) a hybrid search engine specifically for product, merchandise, equipment, and other enabling technologies; and (3) a <b>traffic</b> <b>analyzer</b> of profile management to improve the information layering and organization. We also present an example of EC deployment and impact studies for textile industry Index Terms Internet, electronic commerce, Supply chain management. I...|$|E
40|$|Abstract. In {{order to}} solve the {{difficult}} problem of the transmission-type smoke meter response time, which needs to be settled urgently, response time testers have been developed, according to China's metrological verification regulation JJG 976 - 2010 《 Calibration procedures of transmission-type smoke meter 》. The tester integrated several communication protocols of transmission-type smoke meter manufacturers, takes measurements at every 20 ms, draws absorptance N curves in real time and displays the final response time in man-machine interface. The measuring range of the tester is (600 ~ 2000) ms, and the error is ± 20 ms. It is very convenient, fast, and accurate to verify for transmission–type smoke meter and <b>traffic</b> <b>analyzer...</b>|$|E
40|$|The NetCOPE {{platform}} {{is used for}} rapid developement of hardware accelerated network applications on the family of COMBO cards. An essential part of this {{platform is}} output network module which helps designers to implement Data Link Layer of the OSI reference model, especially the MAC sublayer. This bachelor&# 8217;s thesis focuses on design, implemen- tation and verification of such a module operating at speed 100 Gb/s. Furthemore, an appli- cation on the NetCOPE platform was created. It is designed for transmitting short samples of network traffic stored in QDR static memory. Transmission is controlled by precise ti- mestamps. The whole system was deployed on a COMBO card and verified by a network <b>traffic</b> <b>analyzer...</b>|$|E
40|$|As {{dependence}} on the World Wide Web continues to grow, so does the need for businesses to have quantitative measures of the client perceived response times of their Web services. We present ksniffer, a kernel-based traffic monitor capable of determining pageview response times as perceived by remote clients, in real-time at gigabit traffic rates. ksniffer is based on novel, online mechanisms that take a “look once, then drop ” approach to packet analysis to reconstruct TCP connections and learn client pageview activity. These mechanisms are designed to operate accurately with live network traffic even {{in the presence of}} packet loss and delay, and can be efficiently implemented in kernel space. This enables ksniffer to perform analysis that exceeds the functionality of current <b>traffic</b> <b>analyzers</b> while doing so at high bandwidth rates. ksniffer requires only to passively monitor network traffic and can be integrated with systems that perform server management to achieve specified response time goals. Our experimental results demonstrate that ksniffer can run on an inexpensive, commodity, Linux-based PC and provide online pageview response time measurements, across a wide range of operating conditions, that are within five percent of the response times measured at the client by detailed instrumentation. ...|$|R
40|$|System administrators employ network monitors, such as <b>traffic</b> <b>analyzers,</b> network {{intrusion}} prevention systems, and firewalls, {{to protect}} the network’s hosts from remote adver-saries. The problem is that vulnerabilities are caused pri-marily by errors in the host software and/or configuration, but modern hosts are too complex for system administra-tors to understand, limiting monitoring to known attacks. Researchers have proposed automated methods to compute network monitor placements, but these methods also fail to model attack paths within hosts and/or fail to scale beyond tens of hosts. In this paper, we propose a method to compute network monitor placements that leverages commonality in available access control policies across hosts to compute net-work monitor placement for large-scale systems. We intro-duce an equivalence property, called flow equivalence, which reduces {{the size of the}} placement problem to be propor-tional to the number of unique host configurations. This process enables us to solve mediation placement problems for thousands of hosts with access control policies contain-ing of thousands of rules in seconds (less than 125 for a network of 9500 hosts). Our method enables administrators to place network monitors in large-scale networks automati-cally, leveraging the actual host configuration, to detect and prevent network-borne threats...|$|R
40|$|We {{show how}} to build cheap and large CAMs, or CLAMs, using flash memory. These CLAMs are {{targeted}} at an emerging class of networking applications that require massive indexes running into a hundred GB or more, with items been inserted, updated {{and looked up at}} a rapid rate. Examples of such applications include WAN optimizers, data de-duplication, network monitoring, and <b>traffic</b> <b>analyzers.</b> For such applications, using DRAM-based indexes is quite expensive, while on-disk approaches are too slow. In contrast, our flash memory based CLAMs cost nearly the same as using existing on-disk approaches but offer orders of magnitude better performance. While flash memory inherently offers efficient random reads required for fast lookups, it does not support efficient small random writes required for inserts and updates. To address this, we design an efficient data-structure called BufferHash that significantly lowers the amortized cost of all write operations. Our design of BufferHash also incorporates efficient and flexible eviction policies. We build CLAMs using BufferHash on SSDs and disks. We find that the SSD-based CLAMs can offer average insert and lookup latencies of 0. 02 ms and 0. 06 ms (for 40 % lookup success rates), respectively. We show that using such a CLAM in a WAN optimization application can offer 3 X better throughput improvement than current designs...|$|R
40|$|The {{main goal}} of this master's thesis is to apprise of {{principles}} of Cisco One Platform Kit based on software defined networks and with monitoring techniques in that type of networks. The focus is concentrated on monitoring the quality of Voice over IP communication. Next part of this thesis is a proposal {{and implementation of the}} extensible monitoring environment OneMon on the Cisco One Platform Kit. It is possible to extend OneMon environment using specific analyzers to monitor various types of network traffic. The part of this master's thesis is also implementation of VoIP <b>traffic</b> <b>analyzer</b> for SIP and RTP protocols. This analyzer provides information about phone calls and their quality in a monitored segment of a computer network...|$|E
40|$|The main {{advantage}} of software defined networking (SDN) {{is that it}} allows intelligent control and management of networking though programmability in real time. It enables efficient utilization of network resources through traffic engineering, and offers potential attack defense methods when abnormalities arise. However, previous studies have only identified individual solutions for respective problems, instead of finding a more global solution in real time that is capable of addressing multiple situations in network status. To cover diverse network conditions, this paper presents a comprehensive reactive system for simultaneously monitoring failures, anomalies, and attacks for high availability and reliability. We design three main modules in the SDN controller for a robust and agile defense (RAD) system against network anomalies: a <b>traffic</b> <b>analyzer,</b> a traffic engineer, and a rule manager. RAD provides reactive flow rule generation to control traffic while detecting network failures, anomalies, high traffic volume (elephant flows), and attacks. The <b>traffic</b> <b>analyzer</b> identifies elephant flows, traffic anomalies, and attacks based on attack signatures and network monitoring. The traffic engineer module measures network utilization and delay {{in order to determine the}} best path for multi-dimensional routing and load balancing under any circumstances. Finally, the rule manager generates and installs a flow rule for the selected best path to control traffic. We implement the proposed RAD system based on Floodlight, an open source project for the SDN controller. We evaluate our system using simulation with and without the aforementioned RAD modules. Experimental results show that our approach is both practical and feasible, and can successfully augment an existing SDN controller in terms of agility, robustness, and efficiency, even in the face of link failures, attacks, and elephant flows...|$|E
40|$|This thesis {{deals with}} {{wormhole}} attack discovery in mobile wireless ad hoc networks. Two separate approaches to wormhole attack discovery are developed in this thesis. One approach [...] based on protocol-breaking [...] allows detection of wormholes that disrupt network operations by dropping network packets. Another [...] a novel frequency-based analysis of periodic network messages [...] detects wormholes {{that do not}} drop traffic. The developed wormhole attack discovery techniques are local, do not rely on specialized hardware or clock synchronization, and do not require modification to existing ad hoc network routing protocols. In addition, tools that are necessary for ad hoc network attack research are created. Network <b>traffic</b> <b>analyzer</b> modules applicable to ad hoc network research are developed and tested. Also, a realistic implementation of a wormhole attack in the NS- 2 network simulator is created...|$|E
40|$|AbstractCurrent Internet e-mail {{facilities}} are built onto {{the foundation of}} standard rules and protocols, which usually allow {{a considerable amount of}} “freedom” to their designers. Each of these standards has been defined based on a number of vendor specific implementations, in order to provide common inter-working procedures for cross-vendor communication. Thus, a lot of optional and redundant information is being exchanged during e-mail sessions, which is available to implement versatile covert channel mechanisms. This work exploits this possibility by presenting a simple but effective steganographic scheme {{that can be used to}} deploy robust secret communication through spam e-mails. This scheme can offer unidirectional asynchronous one-to-one or one-to-many covert channel facilities that are able to bypass the most sophisticated firewalls and <b>traffic</b> <b>analyzers.</b> Its implementation neither affects the involved transport protocols nor causes any perceivable performance degradation or data loss to the end-users. The proposed scheme allows one to manage possible filtering/loss of the e-mails being the vehicle of the secret information. A novel retransmission method based on the Raptor codes has been adopted. The use of Raptor codes is key to correctly and efficiently manage the difficulty or impossibility to retransmit e-mails in the case of a unidirectional secret communication starting from one sender and directed to many recipients. In order to evaluate the performance characteristics of the proposed scheme, an empirical estimation of the covert channel bandwidth has been performed...|$|R
5000|$|Once {{the data}} are captured, they can be {{displayed}} several ways, from the simple (showing waveforms or state listings) to the complex (showing decoded Ethernet protocol <b>traffic).</b> Some <b>analyzers</b> can also operate in a [...] "compare" [...] mode, where they compare each captured data set to a previously recorded data set, and halt capture or visually notify the operator when this data set is either matched or not. This is useful for long-term empirical testing. Recent analyzers can even be set to email {{a copy of the}} test data to the engineer on a successful trigger.|$|R
40|$|Within the VoIP {{networks}} environment, {{there are}} three protocols that {{solve the problem of}} voice packet signaling, known as “highlight protocols”: H 323, SIP and IAX. Particularly, this document focuses on a specific difference between SIP and IAX: the bandwidth usage, which is an essential parameter in order to design and optimize a VoIP network for an organization. One of the most important factors to consider when building VoIP networks is proper planning capacity. About planning capacity, bandwidth calculation is an important factor to consider when designing and troubleshooting packet voice networks for good voice quality. This paper presents important explanations about the bandwidth utilization over VoIP networks; this includes some theoretical foundations and bandwidth calculation on a per-flow basis for a VoIP trunk, in which different voice codecs are enabled (specifically G. 711 and GSM) together with VoIP protocols such as SIP and IAX. Voice over IP (VoIP) is applied. These calculations are compared against the results obtained from <b>traffic</b> <b>analyzers</b> over a physical Ethernet trunk between two Asterisk servers into a specific LAN, simulating two different branches of an organization. Both the analysis of the results obtained and the conclusions from this work are useful when calculating the maximum number of simultaneous calls or the minimum capacity of a data link that is necessary for a particular number of voice conversations, taking into account the audio codecs used and the signaling and data flow protocols...|$|R
40|$|Abstract — Traffic {{measurement}} {{represents an}} indispensable and valuable {{tool for the}} analysis of nowadays telecommunication networks. Moreover, it is desirable for traffic measurement and analysis to be both continuous and persistent, since only these joint requirements allow to track important changes on the traffic pattern. On the other hand, transmission links bandwidth keep improving, at a seemingly inexorable rate: therefore, the analysis of the traffic is becoming more complex than ever. This paper focuses on the description and the benchmarking of a network <b>traffic</b> <b>analyzer,</b> called Tstat, able to process real-time traffic further providing i) several advanced measurement indexes of transport layer protocols and ii) ever-lasting monitoring capabilities. Particularly, our aim is to assess what kind of links, and under which load, can be continuously and persistently monitored without compromising the complexity of the traffic analysis that has to be performed. I...|$|E
40|$|Abstract — In this Paper The {{location}} {{privacy of}} end nodes {{remains to be}} solved even when identification anonymity issues are addressed in the wireless routing protocol. Location privacy attacks can be performed by tracing either route discovery messages or data packets in order to discover the message’s origin or destination venue. In this work we propose a protocol to provide receiver location privacy in mobile ad hoc networks. In general, anonymity is achieved by hiding the entity of interest {{among a number of}} similar entities, the anonymity set, so that it is not obvious to outsiders which anonymity set member is the real entity. The main contribution {{of this paper is to}} perform the routing in a way that the location of the destination node cannot be discovered by the adversary. This protocol supports receiver location privacy even against a global <b>traffic</b> <b>analyzer.</b> We use both, privacy analysis and simulation, to study the anonymity and routing performance for the proposed approach...|$|E
40|$|Nowadays, {{e-community}} business, {{web servers}} and organizations, mainly suffered by Denial of Service (DoS) attacks. DoS {{is a common}} attack causes significant problems in business operations and 65 % organizations are suffering over the Internet. This type of attack is created by sending a high rate malicious traffic towards the server and block genuine users using desired network sources and services. In this way this attack consumes the network resources and services which results into degrades the availability of desired services to the valid users. This paper proposes the intrusion detection mechanism for DoS detection such as Local Area Network Denial (LAND), which classified into the Network <b>Traffic</b> <b>Analyzer,</b> Traffic Features Identification and Extraction, IP spoofing based attack detection and Intruder Information. This system efficiently detects DoS LAND based on IP spoofing. This system analyzes the network resources consumed by an attacker. The system is implemented and tested using open source tools. The experimental result shows that, the proposed system produces better performance in comparison with state-of-art existing system and result into {{a low level of}} memory and CPU usage...|$|E
40|$|Abstract: This paper {{describes}} {{a novel approach}} to traffic capture and analysis in high speed networks. A format for the representation of captured packets that (i) limits the amount of data stored and (ii) enables efficient processing is defined. Then, data mining techniques widely studied and deployed for extracting relevant information from extremely large data bases, are applied {{as a means to}} effectively process the significant amount of captured data. The paper provides a first evaluation of the proposed approach in terms of its ability of extracting relevant information and its computational complexity. Such evaluation is based on the first experiments run on the prototypal implementation of the proposed approach within the <b>Analyzer</b> <b>traffic</b> capturing and analysis tool. I...|$|R
40|$|Abstract-In {{performance}} testing of ATM switches and network of switches {{a variety of}} connection configurations is needed. In most of the cases, these configurations require one <b>traffic</b> generator and/or <b>analyzer</b> for each switch port. Since this equipment is rather expensive, it is desirable to define scalable configurations {{that can be used}} with a limited number of generators. In this paper we present a methodology for the implementation of scalable connection configurations. The methodology is simple and offers a general solution to generate scalable connection configurations. Several examples of scalable configurations illustrate the methodology. The application of this methodology helps users to repeat easily performance tests under the same traffic load conditions. I...|$|R
40|$|In {{performance}} testing of ATM switches and network of switches {{a variety of}} connection configurations is needed. In most of the cases, these configurations require one <b>traffic</b> generator and/or <b>analyzer</b> for each switch port. Since this equipment is rather expensive, it is desirable to define scalable configurations {{that can be used}} with a limited number of generators. In this paper we present a methodology for the implementation of scalable connection configurations. The methodology is simple and offers a general solution to generate scalable connection configurations. Several examples of scalable configurations illustrate the methodology. The application of this methodology helps users to repeat easily performance tests under the same traffic load conditions. Arjan Durresi, Raj Jain, Gojko Babic, Bruce Northcot...|$|R
