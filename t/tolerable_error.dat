118|104|Public
25|$|For 35mm motion pictures, {{the image}} {{area on the}} film is roughly 22mm by 16mm. The limit of <b>tolerable</b> <b>error</b> was {{traditionally}} set at 0.05mm (0.002in) diameter, while for 16mmfilm, where the size is about half as large, the tolerance is stricter, 0.025mm (0.001in). More modern practice for 35mm productions set the circle of confusion limit at 0.025mm (0.001in).|$|E
2500|$|ASTM E122 Standard Practice for Calculating Sample Size to Estimate, With a Specified <b>Tolerable</b> <b>Error,</b> the Average for Characteristic of a Lot or Process ...|$|E
5000|$|ATI {{claimed that}} the support of DirectX 10.1 can bring {{improved}} performance and processing efficiency with reduced rounding error (0.5 ULP compared with average error 1.0 ULP as <b>tolerable</b> <b>error),</b> better image details and quality, global illumination (a technique used in animated films, and more improvements to consumer gaming systems therefore giving more realistic gaming experience. [...] ) ...|$|E
5000|$|... {{none of the}} {{packages}} marked have a negative error greater than twice the <b>tolerable</b> negative <b>error</b> (since no such package may bear the estimated sign).|$|R
30|$|Evaluation of quality: Methods to {{evaluate}} quality {{is discussed in}} Section  4.1. The approach for performance evaluation is to first study the impacts of device calibration and network conditions on quality, then examine how poor quality reduces the application performance [42]. Two effective methods are proposed {{to evaluate}} the impact of quality on performance: ① Benchmarking that tests an application multiple times with numerous erroneous datasets in contrast to those with no known errors, and ② Standardization that documents, for each application, the level of <b>tolerable</b> <b>errors.</b>|$|R
40|$|Details of the {{resonance}} theory used in {{the code}} GYMEA are described and compared with exact solutions for resonance's in Th 232, U 235, and Pu 240. The relative merits of two methods for including background cross sections are evaluated, by an exhaustive study of the reaction rates across the resonance's. It {{was found that the}} analytical procedure for calculating resonance reaction rates leads to <b>tolerable</b> <b>errors</b> in reactor physics calculations. The resonance adjusted calculations emerged as the most accurate method for computing the fine structure of the reaction rates across a resonance...|$|R
50|$|For 35 mm motion pictures, {{the image}} {{area on the}} film is roughly 22 mm by 16 mm. The limit of <b>tolerable</b> <b>error</b> was {{traditionally}} set at 0.05 mm (0.002 in) diameter, while for 16 mm film, where the size is about half as large, the tolerance is stricter, 0.025 mm (0.001 in). More modern practice for 35 mm productions set the circle of confusion limit at 0.025 mm (0.001 in).|$|E
50|$|The {{tolerable}} negative {{error is}} related to the nominal quantity and varies between 9% on packages nominally 50 g or 50 ml or less, to 1.5% on packages nominally 1 kg or 1 L or more. The <b>tolerable</b> <b>error</b> decreases as nominal quantity increases, and is done by alternating intervals where there is a percentage error and intervals where there is a fixed error (and thus over those intervals the percentage error decreases).|$|E
50|$|In fixed-rate mode, the sync rate is {{predefined}} by {{the operator}} and the DSL modem chooses a bits-per-bin allocation that yields an approximately equal error rate in each bin. In variable-rate mode, the bits-per-bin are chosen to maximize the sync rate, subject to a <b>tolerable</b> <b>error</b> risk. These choices can either be conservative, where the modem chooses to allocate fewer bits per bin than it possibly could, a choice which makes for a slower connection, or less conservative in which more bits per bin are chosen in which case {{there is a greater}} risk case of error should future signal-to-noise ratios deteriorate {{to the point where the}} bits-per-bin allocations chosen are too high to cope with the greater noise present. This conservatism, involving a choice of using fewer bits per bin as a safeguard against future noise increases, is reported as the signal-to-noise ratio margin or SNR margin.|$|E
40|$|Soft-error {{detection}} in FPGAs typically requires replication, {{doubling the}} required area. We propose an approach which distinguishes between <b>tolerable</b> <b>errors</b> in data-flow, such-as arithmetic, and intolerable errors in control-flow, such as branches and their data-dependencies. This approach is demonstrated {{in a new}} high-level synthesis compiler pass called StitchUp, which precisely identifies the control critical parts of the design, then automatically replicates only that part. We applied StitchUp to the CHStone benchmark suite and performed exhaustive hardware fault injection in each case, finding that all control-flow errors were detected while only requiring 1 % circuit area overhead in the best case...|$|R
5000|$|... the {{proportion}} of packages having a negative error greater than the <b>tolerable</b> negative <b>error</b> shall be sufficiently small for batches of packages {{to satisfy the requirements}} of the official reference test as specified in legislation; ...|$|R
50|$|When {{using the}} table, {{the values of}} the <b>tolerable</b> {{negative}} <b>errors</b> shown as percentages in the table, calculated in units of weight or volume, shall be rounded up to the nearest 0.1 g or 0.1 ml.|$|R
40|$|We {{investigate}} the error tolerance of quantum cryptographic protocols using $d$-level systems. In particular, {{we focus on}} prepare-and-measure schemes that use two mutually unbiased bases and a key-distillation procedure with two-way classical communication. For arbitrary quantum channels, we obtain a sufficient condition for secret-key distillation which, {{in the case of}} isotropic quantum channels, yields an analytic expression for the maximally <b>tolerable</b> <b>error</b> rate of the cryptographic protocols under consideration. The difference between the <b>tolerable</b> <b>error</b> rate and its theoretical upper bound tends slowly to zero for sufficiently large dimensions of the information carriers. Comment: 10 pages, 1 figur...|$|E
40|$|Abstract. For {{reducing}} the communication overhead of data aggregation, authors proposed a probabilistic transmitting-based data aggregation scheme for wireless sensor network. Due to {{limited number of}} nodes in the cluster and aggregation error is unavoidable; nodes adopt the probabilistic transmitting to lower the communication overhead with <b>tolerable</b> <b>error.</b> In order to prevent the influence of big noise, Dixon criterion was adopted to eliminate the gross error in the small sample. Experiment shows the proposed scheme reduces the inner-cluster transmissions and lowers the communication overhead effectively with <b>tolerable</b> <b>error.</b> The aggregation error of probabilistic transmitting and all nodes transmitting are {{at the same level}} and both are acceptable for wireless sensor networks...|$|E
3000|$|... a[*]The {{achievable}} rate regions will be implicitly {{assumed to}} correspond to a certain constant <b>tolerable</b> <b>error</b> probability respecting which {{it is possible to}} transmit a finite number of bits with a finite amount of energy per bit.|$|E
40|$|A new visual servoing {{technique}} {{consisting of}} generating circular-like trajectories is proposed {{which does not}} require either geometrical models of the object or points depth. For calibrated camera, the object is kept {{in the field of}} view and global stability is achieved. Then, necessary and sufficient conditions are provided for establishing <b>tolerable</b> <b>errors</b> on the estimates of the intrinsic and extrinsic parameters in order to guarantee robust field of view and robust local stability. Simulation results show that the translational trajectories obtained in presence of large displacements are significantly shorter than those produced by one of the best existing methods, in both cases of correct and bad calibration. Very satisfactory results are obtained also in presence of small displacements. link_to_subscribed_fulltex...|$|R
40|$|A single-chip microprocessor-compatible 128 -b {{correlator}} {{is designed}} and implemented in a 3 -μm M 2 CMOS process. Full-custom design techniques {{are applied to}} achieve the best tradeoff among chip size, speed, and power consumption. The chip is placed in a microprocessor-based portable data terminal using HF radio communication. It {{marks the beginning of}} a synchronous data stream received from the very noisy channel by detecing the synchronization (sync) word. The sync word can be detected for either inverted or noninverted input data streams. Two chips can be cascaded to make a 256 -b correlator. The chip is fully programmable by a microprocessor to set the number of <b>tolerable</b> <b>errors</b> in detection and to select the bits of the 128 -b (or 256 -b) data stream {{to be used in the}} correlation...|$|R
40|$|The {{degree of}} {{controllability}} {{of a large}} space structure is found by a four step procedure: (1) finding the minimum control energy for driving the system from a given initial state to the origin in the prescribed time; (2) finding the region of initial state which can be driven to the origin with constrained control energy and time using optimal control strategy; (3) scaling the axes so that a unit displacement in every direction is equally important to control; and (4) finding the linear measurement of the weighted "volume" of the ellipsoid in the equicontrol space. For observability, the error covariance must be reduced toward zero using measurements optimally, and the criterion must be standardized by the magnitude of <b>tolerable</b> <b>errors.</b> The results obtained using these methods are applied to the vibration modes of a free-free beam...|$|R
40|$|We {{consider}} {{the task of}} interactive communication {{in the presence of}} adversarial errors and present tight bounds on the tolerable error-rates {{in a number of different}} settings. Most significantly, we explore adaptive interactive communication where the communicating parties decide who should speak next based on the history of the interaction. Braverman and Rao [STOC' 11] show that non-adaptively one can code for any constant error rate below 1 / 4 but not more. They asked whether this bound could be improved using adaptivity. We answer this open question in the affirmative (with a slightly different collection of resources) : Our adaptive coding scheme tolerates any error rate below 2 / 7 and we show that tolerating a higher error rate is impossible. We also show that in the setting of Franklin et al. [CRYPTO' 13], where parties share randomness not known to the adversary, adaptivity increases the <b>tolerable</b> <b>error</b> rate from 1 / 2 to 2 / 3. For list-decodable interactive communications, where each party outputs a constant size list of possible outcomes, the tight <b>tolerable</b> <b>error</b> rate is 1 / 2. Our negative results hold even if the communication and computation are unbounded, whereas for our positive results communication and computation are polynomially bounded. Most prior work considered coding schemes with linear amount of communication, while allowing unbounded computations. We argue that studying <b>tolerable</b> <b>error</b> rates in this relaxed context helps to identify a setting's intrinsic optimal error rate. We set forward a strong working hypothesis which stipulates that for any setting the maximum <b>tolerable</b> <b>error</b> rate is independent of many computational and communication complexity measures. We believe this hypothesis to be a powerful guideline for the design of simple, natural, and efficient coding schemes and for understanding the (im) possibilities of coding for interactive communications...|$|E
40|$|In this work, speech {{signals are}} modeled {{by means of}} the {{so-called}} pre-defined "signature functions". The pre-defined signature functions are generated using the statistical properties of the speech signals. It has been exhibited that, with a few basic signature functions, any speech signal can be generated within a <b>tolerable</b> <b>error.</b> Publisher's Versio...|$|E
40|$|The quantum key {{distribution}} protocol without public announcement of bases {{is equipped with a}} two-way classical communication symmetric entanglement purification protocol. This modified {{key distribution}} protocol is unconditionally secure and has a higher <b>tolerable</b> <b>error</b> rate of 20 %, which is higher than previous scheme without public announcement of bases. Comment: 5 pages. To appear in Physical Review...|$|E
40|$|We train autoencoders by Flat Minimum Search (FMS), a regularizer {{algorithm}} {{for finding}} low-complexity networks describable by few bits of information. As a by-product, this encourages nonlinear independent component analysis (ICA) and sparse codes of the input data. Flat minima are regions in weight space where (a) there is <b>tolerable</b> small <b>error</b> and (b) you can perturb the weights without greatly affecting the network's output. Hence the weights {{may be given}} with low precision: few bits of information are required to describe the corresponding "simple" or low complexity-network. Low network complexity is generally associated with high generalization performance. To simplify the algorithm for finding flat minima, we do not consider maximal connected regions but focus on so-called "boxes" within regions: for each weight vector w leading to <b>tolerable</b> small <b>error,</b> its box Mw in weight space is a W -dimensional hypercuboid with center w, where W {{is the number of}} weights. For simplicity, e [...] ...|$|R
40|$|Abstract. It {{is shown}} that the holes of the objects in an input image with a CT-CNN [1] or a DT-CNN [2] may be {{obtained}} in a single transient using just one linear parameter configuration. A set of local rules is given that describe how a CNN with a linear configuration may extract the hole of the objects of an input image in a single transient. The parameter configuration for DT-CNNs or for CT-CNNs is obtained as the solution of a single linear programming problem, including robustness as an objective. The tolerances to multiplicative and additive errors caused by circuit inaccuracies for the linear hole-extraction configurations proposed have been deduced. These <b>tolerable</b> <b>errors</b> have been corroborated by simulations. The tolerance to errors and {{the speed of the}} CT-CNN linear configuration proposed for hole extraction are compared with those of the CT-CNN nonlinear configuration found in the bibliography [3]. Key Words: cellular neural networks, hole extraction, tolerance to errors, linear programming problem 1...|$|R
40|$|Least Squares Curve Fitting program, AKLSQF, {{easily and}} {{efficiently}} computes polynomial providing least-squares best fit to uniformly spaced data. Enables user to specify <b>tolerable</b> least-squares <b>error</b> in fit or degree of polynomial. AKLSQF returns polynomial and actual least-squares-fit error incurred in operation. Data supplied to routine either by direct keyboard entry or via file. Written for an IBM PC X/AT or compatible using Microsoft's Quick Basic compiler...|$|R
40|$|We {{prove that}} BB 84 {{protocol}} with random privacy amplification is secure {{with a higher}} key rate than Mayers' estimate with the same error rate. Consequently, the <b>tolerable</b> <b>error</b> rate of this protocol is increased from 7. 5 % to 11 %. We also extend this method {{to the case of}} estimating error rates separately in each basis, which enables us to securely share a longer key...|$|E
40|$|To {{solve the}} {{problems}} inherent in working with sequential decision processes, it is proposed to (1) utilize concepts of dominance through bounding in the decision processes (DP) formalism {{to reduce the amount}} of computing required. This advocates the marrying of DP recursion and Branch-and-Bound methodology; and (2) relax the requirement of strict optimality in the search over the state space, and be content with a <b>tolerable</b> <b>error...</b>|$|E
40|$|We {{prove that}} BB 84 {{protocol}} with random privacy amplification is secure {{with a higher}} key rate than Mayers ’ estimate with the same error rate. Consequently, the <b>tolerable</b> <b>error</b> rate of this protocol is increased from 7. 5 % to 11 %. We also extend this method {{to the case of}} estimating error rates separately in each basis, which enables us to securely share a longer key. ...|$|E
40|$|Abstract—Data rate, <b>tolerable</b> bit <b>error</b> rate or frame {{error rate}} and range & {{coverage}} {{are the key}} performance requirement of a communication link. In this paper performance of MFSK link is analyzed in terms of bit error rate, number of errors and total number of data processed. In the communication link model proposed, which is implemented using MATLAB block set, an improvement in BER is observed. Different parameters which effects and enables to keep BER low in M-ary communication system are also identified...|$|R
30|$|The above {{mathematical}} modeling is {{the training}} representation of our proposed predictor. We train the MLP with the slot(s) state and idle time slot(s) history. The {{training of the}} proposed predictor is done by changing the weights according to (7) {{with the aim of}} minimizing the mean square error, i.e., E in (6). We have repeated the above weight updating procedure until the threshold in terms of the required mean square error is achieved, where the threshold mean square <b>error</b> is the <b>tolerable</b> prediction <b>error.</b>|$|R
40|$|Abstract - We discuss specific, recent {{advances}} {{in the analysis of}} an experiment to test the Equivalence Principle (EP) in free fall. A differential accelerometer detector with two proof masses of different materials free falls inside an evacuated capsule previously released from a stratospheric balloon. The detector spins slowly about its horizontal axis during the fall. An EP violation signal (if present) will manifest itself at the rotational frequency of the detector. The detector operates in a quiet environment as it slowly moves with respect to the co-moving capsule. There are, however, gravitational and dynamical noise contributions that need to be evaluated in order to define key requirements for this experiment. Specifically, higher-order mass moments of the capsule contribute errors to the differential acceleration output with components at the spin frequency which need to be minimized. The dynamics of the free falling detector (in its present design) has been simulated in order to estimate the <b>tolerable</b> <b>errors</b> at release which, in turn, define the release mechanism requirements. Moreover, the study of the higher-order mass moments for a worst-case position of the detector package relative to the cryostat has led to the definition of requirements on the shape and size of the proof masses...|$|R
30|$|Reliable space telecommanding is of {{fundamental}} importance as {{the success of}} a mission may be compromised because of an error corrupting a TC message. This imposes strict constraints on the maximum <b>tolerable</b> <b>error</b> rates. In particular, the codeword error rate (CER) is defined as the ratio of the number of decoding failures to the total number of received codewords. Requirements are often specified in terms of average CER, and a typical value is CER ≤ 10 − 5.|$|E
40|$|The {{concept of}} {{asymptotic}} correctability of Bell-diagonal quantum states is generalised to elementary quantum systems of higher dimensions. Based on these results basic properties of quantum state purification protocols are investigated which {{are capable of}} purifying tensor products of Bell-diagonal states and {{which are based on}} $B$-steps of the Gottesman-Lo-type with the subsequent application of a Calderbank-Shor-Steane quantum code. Consequences for maximum <b>tolerable</b> <b>error</b> rates of quantum cryptographic protocols are discussed. Comment: submitted to J. Phys. ...|$|E
40|$|This paper {{shows that}} the BB 84 {{protocol}} with random privacy amplification is secure with a higher key rate than Mayers ’ estimate with the same error rate. Consequently, the <b>tolerable</b> <b>error</b> rate of this protocol is increased from 7. 5 % to 11 %. We also extend this method {{to the case of}} estimating error rates separately in each basis, which enables us to securely share a longer key. Index Terms—Quantum key distribution, BB 84, random privacy amplification, security analysis...|$|E
40|$|The first aim of any visual-servoing {{strategy}} is to avoid features being lost {{from the field of}} view and that the desired location may not be reached. However, avoiding both these system failures turns out to be very difficult, especially when the initial and desired locations are distant. Moreover, the methods that succeed in presence of large camera displacements often produce a long translational trajectory that may not be allowed by the robot workspace and/or joint limits. In this paper, a new strategy for dealing with such problems is proposed, which consists of generating circular-like trajectories that may satisfy the task requirements more naturally than other solutions. Knowledge of geometrical models of the object or points depth is not required. It is shown that system failures are avoided for a calibrated camera. Moreover, necessary and sufficient conditions are provided for establishing <b>tolerable</b> <b>errors</b> on the estimates of the intrinsic and extrinsic parameters, in order to guarantee a robust field of view and robust local asymptotic stability. Several simulation results show that the translational trajectories obtained in presence of large displacements are significantly shorter than those produced by the existing methods, in cases of both correct and bad camera calibration. Very satisfactory results are achieved also in presence of small displacements. © 2004 IEEE. link_to_subscribed_fulltex...|$|R
40|$|Detection of {{activity}} {{is a key}} capability for microphone arrays. An array system should tell when a source of interest is present and evaluate the usability of the computed spatial estimates. This work proposes activity features that are computed from spatial data only, using time delays and direction of arrival. The features are validated with a loudspeaker experiment. Results show that the features are effective: <b>tolerable</b> detection <b>errors</b> are achievable with simple detection methods. In addition, direction of arrival estimation error is reduced down to one third when unreliable estimates are discarded. 1...|$|R
40|$|An {{investigation}} {{has been made}} of point return of a vehicle with a lift-to-drag ratio of 1 / 2, returning from a lunar mission. It was found that the available longitudinal and lateral range allowed considerable tolerances in entry conditions for a point return. Longitudinal range capability for a vehicle that was allowed to skip to an altitude not exceeding 400 miles was about 3 - 1 / 2 times greater than the range capability of a vehicle that was restricted to remain in the atmosphere after entry. Longitudinal range is very sensitive to changes in both velocity and flight-path angle {{at the bottom of the}} first pull-out and at exit. An investigation showed that after a skip a vehicle could be placed in a circular orbit for a relatively modest weight penalty. A skip maneuver was found to have no effect on lateral range when the roll was initiated at a velocity near satellite speed after the vehicle had re-entered the atmosphere. However, when the roll was initiated at the earliest possible time along the undershoot boundary, lateral range was increased by a factor of about 2 - 1 / 2. The <b>tolerable</b> <b>errors</b> in time of arrival and in inclination of the orbital plane at point of entry were greater for the skip trajectory than for the no-skip trajectory...|$|R
