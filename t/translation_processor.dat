1|8|Public
50|$|On January 19, 2000, Transmeta held {{a launch}} event at Villa Montalvo in Saratoga, California and {{announced}} {{to the world that}} it had been working on an x86 compatible dynamic binary <b>translation</b> <b>processor</b> named Crusoe. It also released an 18-page whitepaper describing the technology.|$|E
40|$|This paper {{presents}} BOA (Binary-translation Optimized Architecture), {{a processor}} designed to achieve high frequency by using software dynamic binary <b>translation.</b> <b>Processors</b> for software binary translation are very conducive to high frequency {{because they can}} assume a simple hardware design. Binary translation eliminates the binary compatibility problem faced by other processors, while dynamic recompilation enables re-optimization of critical program code sections and {{eliminates the need for}} dynamic scheduling hardware. In this work we examine the implications of binary <b>translation</b> on <b>processor</b> architecture and software translation and how we support a very high frequency PowerPC implementation via dynamic binary translation. The design of processors with clock speeds of 1 GHz or more has been a topic of considerable research in both industry and academia. Binary translation presents an interesting alternative for processor design as it enables good performance on simple processor designs. <b>Processors</b> for binary <b>translation</b> achieve maximum performance by enabling high frequency processors while still exploiting available parallelism in the code. The effect of both of these optimizations is to minimiz...|$|R
50|$|Along {{with the}} <b>translation</b> to {{different}} <b>processors,</b> the KRoC team have modified the compiler significantly, creating a compiler {{for what has}} become known as occam v2.5, and now as occam-pi.|$|R
40|$|Presented is an 8 -issue tree-VLIW {{processor}} {{designed for}} efficient support of dynamic binary <b>translation.</b> This <b>processor</b> confronts two primary {{problems faced by}} VLIW architectures: binary compatibility and branch performance. Binary compatibility with existing architectures is achieved through dynamic binary translation which translates and schedules PowerPC instructions {{to take advantage of}} the available instruction level parallelism. Efficient branch performance is achieved through tree instructions that support multi-way path and branch selection within a single VLIW instruction. The processor architecture is described, along with design details of the branch unit, pipeline, register file and memory hierarchy, for a 0. 25 micron standard-cell design. Performance simulation...|$|R
40|$|International audienceBugs or inefficiencies {{appearing}} in MPSoC platforms {{can have a}} very broad range of sources. However, due to the huge number of possible execution interleavings, reproducing the conditions of occurrence of a given error/performance issue is very difficult. One {{solution to this problem}} consists of tracing an execution for later analysis. This paper details the challenges and issues behind the production of a "well formed" trace in a transaction accurate virtual prototyping environment that uses dynamic binary <b>translation</b> as <b>processor</b> simulation technology. We propose a solution which requires modification of the dynamic compilation process, but stays non-intrusive, and demonstrate its feasibility on several examples...|$|R
50|$|If the {{inequality}} is false, {{the processor}} generates a general protection (GP) fault. Otherwise, address <b>translation</b> continues. The <b>processor</b> then takes the 32-bit or 16-bit offset and compares {{it against the}} segment limit specified in the segment descriptor. If it is larger, a GP fault is generated. Otherwise, the processor adds the 24-bit segment base, specified in descriptor, to the offset, creating a linear physical address.|$|R
50|$|In {{order to}} make this <b>translation</b> more efficient, <b>processor</b> vendors {{implemented}} technologies commonly called SLAT. By treating each guest-physical address as a host-virtual address, a slight extension of the hardware used to walk a non-virtualized page table (now the guest page table) can walk the host page table. With multilevel page tables the host page table can be viewed conceptually as nested within the guest page table. A hardware page table walker can treat the additional translation layer almost like adding levels to the page table.|$|R
40|$|Trends in {{computer}} engineering place renewed emphasis on increasing parallelism and heterogeneity. The rise of parallelism adds an additional {{dimension to the}} challenge of portability, as different processors support different notions of parallelism, whether vector parallelism executing in a few threads on multicore CPUs or large-scale thread hierarchies on GPUs. Thus, software experiences obstacles to portability and efficient execution beyond differences in instruction sets; rather, the underlying execution models of radically different architectures may not be compatible. Dynamic compilation applied to data-parallel heterogeneous architectures presents an abstraction layer decoupling program representations from optimized binaries, thus enabling portability without encumbering performance. This dissertation proposes several techniques that extend dynamic compilation to data-parallel execution models. These contributions include: - characterization of data-parallel workloads - machine-independent application metrics - framework for performance modeling and prediction - execution model <b>translation</b> for vector <b>processors</b> - region-based compilation and scheduling We evaluate these claims via the development of a novel dynamic compilation framework, GPU Ocelot, with which we execute real-world workloads from GPU computing. This enables the execution of GPU computing workloads to run efficiently on multicore CPUs, GPUs, and a functional simulator. We show data-parallel workloads exhibit performance scaling, take advantage of vector instruction set extensions, and effectively exploit data locality via scheduling which attempts to maximize control locality. PhDCommittee Chair: Yalamanchili, Sudha; Committee Member: Lanterman, Aaron; Committee Member: Pande, Santosh; Committee Member: Richards, Mark; Committee Member: Shamma, Jef...|$|R
40|$|Many-core {{processors}} {{offer new}} levels of on-chip performance by {{capitalizing on the}} increasing rate of device integration. Harnessing the full performance potential of these processors requires that hardware designers not only exploit the advantages, but also consider the problems introduced by the new architectures. Such challenges arise from both the processor's increased structural complexity and the reliability issues of the silicon substrate. In this thesis, we address these challenges in a framework that targets correct execution and performance on three coordinates: 1) tolerating permanent faults, 2) facilitating static and dynamic verification through precise specifications, and 3) designing scalable coherence protocols. First, we propose CCA, a new design paradigm for increasing the processor's lifetime performance {{in the presence of}} permanent faults in cores. CCA chips rely on a reconfiguration mechanism that allows cores to replace faulty components with fault-free structures borrowed from neighboring cores. In contrast with existing solutions for handling hard faults that simply shut down cores, CCA aims to maximize the utilization of defect-free resources and increase the availability of on-chip cores. We implement three-core and four-core CCA chips and demonstrate that they offer a cumulative lifetime performance improvement of up to 65 % for industry-representative utilization periods. In addition, we show that CCA benefits systems that employ modular redundancy to guarantee correct execution by increasing their availability. Second, we target the correctness of the address <b>translation</b> system. Current <b>processors</b> often exhibit design bugs in their translation systems, and we believe one cause for these faults is a lack of precise specifications describing the interactions between address translation {{and the rest of the}} memory system, especially memory consistency. We address this aspect by introducing a framework for specifying translation-aware consistency models. As part of this framework, we identify the critical role played by address translation in supporting correct memory consistency implementations. Consequently, we propose a set of invariants that characterizes address translation. Based on these invariants, we develop DVAT, a dynamic verification mechanism for address translation. We demonstrate that DVAT is efficient in detecting translation-related faults, including several that mimic design bugs reported in processor errata. By checking the correctness of the address translation system, DVAT supports dynamic verification of translation-aware memory consistency. Finally, we address the scalability of translation coherence protocols. Current software-based solutions for maintaining translation coherence adversely impact performance and do not scale. We propose UNITD, a hardware coherence protocol that supports scalable performance and architectural decoupling. UNITD integrates translation coherence within the regular cache coherence protocol, such that TLBs participate in the cache coherence protocol similar to instruction or data caches. We evaluate snooping and directory UNITD coherence protocols on processors with up to 16 cores and demonstrate that UNITD reduces the performance penalty of translation coherence to almost zero. Dissertatio...|$|R

