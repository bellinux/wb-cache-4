8|19|Public
40|$|The {{growing number}} of glacier margin lakes that have {{developed}} due to glacier retreat have caused an increase of dangerous glacier lake outburst floods (GLOFs) in several regions over the last decade. This normally causes a flood wave downstream the glacier. Typically, such an event takes few to several hours. GLOF scenarios may be a significant hazard to life, property, nature and infrastructure in the affected areas. A GLOF is usually characterized by a progressive water level drop. By observing the water level of the lake, an imminent GLOF-event can be identified. Common gauging systems are often not suitable for the measurement task, {{as they may be}} affected by ice fall or landslides in the lake basin. Therefore, in our pilot study, the water level is observed by processing images of a <b>terrestrial</b> <b>camera</b> system observing a glacier margin lake. The paper presents the basic principle of an automatic single-camera-based GLOF early warning system. Challenges and approaches to solve them are discussed. First, results from processed image sequences are presented to show the feasibility of the concept. Water level changes can be determined at decimetre precision...|$|E
40|$|Abramov glacier, {{located in}} the Pamir Alay, Kyrgyzstan, is a {{reference}} glacier within the Global Terrestrial Network for Glaciers. Long-term glaciological measurements exist from 1968 to 1998 and a mass-balance monitoring programme was re-established in 2011. In this study we re-analyse existing mass-balance data and use a spatially distributed mass-balance model to provide continuous seasonal time series of glacier mass balance covering the period 1968 – 2014. The model is calibrated to seasonal mass-balance surveys and then applied to the period with no measurements. Validation and recalibration is carried out using snowline observations derived from satellite imagery and, after 2011, also from automatic <b>terrestrial</b> <b>camera</b> images. We combine direct measurements, remote observations and modelling. The results are compared to geodetic glacier volume change {{over the past decade}} and to a ground-penetrating radar survey in the accumulation zone resolving several layers of accumulation. Previously published geodetic mass budget estimates for Abramov glacier suggest a close-to-zero mass balance for the past decade, which contradicts our results. We find a low plausibility for equilibrium conditions over the past 15 years. Instead, we suggest that the glacier's sensitivity to increased summer air temperature is decisive for the substantial mass loss during the past decade...|$|E
40|$|ABSTRACT: This article {{presents}} (comparatively) the methodology {{for creating a}} 3 D model of the urban area, based on terrestrial laser scanner, traditional technologies of terrestrial photogrammetry and aerial images. We are reviewing the data sources, their preliminary processing to be brought in a common system and the software used for this purpose. The case study presents the comparative results obtained using the methods listed above. To obtain the 3 D models with terrestrial laser scanner systems have been used the dates achieved with ScanStation 2. To obtain the 3 D model drawn by traditional photogrammetric methods using the UMK <b>terrestrial</b> <b>camera,</b> have been used auxiliary dates from topographic measurements with GPS systems and total stations {{as well as the}} current topographic plans. For the 3 D model creation based on the dates taken with aerial digital cameras, were used the aerial images, taken with the ADS 40 photogrammetric aerial camera. The comparative study between the three methods was accomplished by analyzing the object space representation fidelity, the precision of the 3 D models obtained by comparison of the distances, areas and volumes, comparing the execution time and execution costs. The {{article presents}} the conclusions, {{the advantages and disadvantages of}} the three technologies based on the criteria listed above...|$|E
30|$|During {{the past}} years, {{increasing}} traffic {{appears to be}} one of the major problems in urban and sub-urban areas [1]. Traffic congestion and jams are one of the main reasons for immensely increasing transportation costs due to the wasted time and extra fuel. Conventional stationary ground measurement systems such as inductive loops, radar sensors or <b>terrestrial</b> <b>cameras</b> are able to deliver precise traffic data punctually with high temporal resolution, but their spatial distribution is still limited to selected motorways or main roads.|$|R
5000|$|Surveying <b>terrestrial</b> mammals with <b>camera</b> traps in the Lancandon {{indigenous}} people reserve of Metzabok and in Palenque National Park, Mexico.|$|R
40|$|This paper {{presents}} the design, implementation and demonstration {{results from the}} ongoing ESA ARTES project “SFEDONA”. The SFEDONA project deals with a complete end-to-end fire detection and alerting application which employs state-of-the-art satellite and wireless communications air interfaces as well as advanced technologies in fire detection, alerting and propagation estimation based on <b>terrestrial</b> optical <b>cameras,</b> weather meteorological stations and environmenta...|$|R
40|$|The rate of {{detection}} of meteoroid {{impacts on the}} moon by the lunar seismic network shows a characteristic diurnal variation. Assuming that these meteoroids have a flux and a preimpact orbital distribution {{similar to that of}} fireballs observed by <b>terrestrial</b> <b>camera</b> networks, one can compute the expected diurnal variation for a given set of parameters that describe the seismic wave generation and transmission on the moon. An iterative process to match the theoretical variation with the observed one has led us to the following results: (1) the majority of the detected impact events occur within a closer range of the network than was believed earlier. This results in higher meteoroid flux estimates from lunar seismic data that agree with the terrestrially measured flux. (2) For meteoroid masses smaller than 1000 g, seismic amplitude is approximately proportional to the one-fifth power of the impact speed; for larger masses it is approximately proportional to the eight-fifth power, provided that the terrestrial meteor data used for analysis are not biased. (3) Seismic efficiency of meteoroids smaller than 1000 g is significantly less than that of large meteoroids. (4) Using orbits of fireballs that represent meteorites, we predict that the share of meteorites among the detected impacts is approximately 15 percent assuming that seismic efficiency of the high-density meteorites is {{the same as that of}} average meteoroids. A greatly increased seismic efficiency for these high-density objects is not likely...|$|E
40|$|This paper {{presents}} a comprehensive method for {{the determination of}} glacier surface motion vector fields at high spatial and temporal resolution. These vector fields {{can be derived from}} monocular <b>terrestrial</b> <b>camera</b> image sequences and are a valuable data source for glaciological analysis of the motion behaviour of glaciers. The measurement concepts for the acquisition of image sequences are presented, and an automated monoscopic image sequence processing chain is developed. Motion vector fields can be derived with high precision by applying automatic subpixel-accuracy image matching techniques on grey value patterns in the image sequences. Well-established matching techniques have been adapted to the special characteristics of the glacier data in order to achieve high reliability in automatic image sequence processing, including the handling of moving shadows as well as motion effects induced by small instabilities in the camera set-up. Suitable geo-referencing techniques were developed to transform image measurements into a reference coordinate system. The result of monoscopic image sequence analysis is a dense raster of glacier surface point trajectories for each image sequence. Each translation vector component in these trajectories can be determined with an accuracy of a few centimetres for points at a distance of several kilometres from the camera. Extensive practical validation experiments have shown that motion vector and trajectory fields derived from monocular image sequences can be used for the determination of high-resolution velocity fields of glaciers, including the analysis of tidal effects on glacier movement, the investigation of a glacier's motion behaviour during calving events, the determination of the position and migration of the grounding line and the detection of subglacial channels during glacier lake outburst floods...|$|E
40|$|During {{the last}} decades photogrammetric {{computer}} vision systems have been well established in scientific and commercial applications. Especially the increasing affordability of unmanned aerial vehicles (UAVs) in conjunction with automated multi-view processing pipelines have resulted in an easy way of acquiring spatial data and creating realistic and accurate 3 D models. With the use of multicopter UAVs, {{it is possible to}} record highly overlapping images from almost <b>terrestrial</b> <b>camera</b> positions to oblique and nadir aerial images due to the ability to navigate slowly, hover and capture images at nearly any possible position. Multi-copter UAVs thus are bridging the gap between terrestrial and traditional aerial image acquisition and are therefore ideally suited to enable easy and safe data collection and inspection tasks in complex or hazardous environments. In this paper we present a fully automated processing pipeline for precise, metric and geo-accurate 3 D reconstructions of complex geometries using various imaging platforms. Our workflow allows for georeferencing of UAV imagery based on GPS-measurements of camera stations from an on-board GPS receiver as well as tie and control point information. Ground control points (GCPs) are integrated directly in the bundle adjustment to refine the georegistration and correct for systematic distortions of the image block. We discuss our approach based on three different case studies for applications in mining and archaeology and present several accuracy related analyses investigating georegistration, camera network configuration and ground sampling distance. Our approach is furthermore suited for seamlessly matching and integrating images from different view points and cameras (aerial and terrestrial as well as inside views) into one single reconstruction. Together with aerial images from a UAV, we are able to enrich 3 D models by combining terrestrial images as well inside views of an object by joint image processing to generate highly detailed, accurate and complete reconstructions...|$|E
40|$|Recent new {{developments}} in the electronics have leaded to the manufacturing of new high-resolution digital sensors (up to 39 mega pixel) for <b>terrestrial</b> <b>cameras.</b> These technological innovations, together with new processing algorithms of image matching, allow to obtain image-based surface models in an almost automatic way with an accuracy and a detail level that can be surely compared with the one achievable with active sensors. With this in mind, we present {{new developments}} in terrestrial 3 D surface reconstruction and object modeling using digital images, reporting some tests conducted using low cost digital cameras and commercial or in-house software. The tests were conducted selecting different kinds of objects (low relief, statue, buildings, small heritage find, etc.), with different camera configurations and different image resolutions. Different image matching procedures are analyzed, comparing area-based, feature-based or an integration of both. A critical examination of the results is presented, with particular attention to the daily archaeological or heritage documentation purpose...|$|R
40|$|Deviations of {{positions}} of pixels on charge-coupled-device (CCD) image detector from nominal rectangular grid pattern measured by method in which coherent-light interference fringes used as reference pattern. Conceived {{for use in}} determining pixel-position errors in astrometric cameras flown aboard spacecraft. Also applied to determination of similar errors in (and calibration of) <b>terrestrial</b> CCD <b>cameras</b> used as position sensors; for example, position-measuring cameras that are parts of robotic systems...|$|R
50|$|Another {{major factor}} in whether {{this is the best}} {{technique}} to use in the specific research is which type of species one is attempting to observe with the camera. Species such as small-bodied birds and insects may be too small to trigger the camera. Reptiles and amphibians {{will not be able to}} trip the infrared or heat differential-based sensors, however, methods have been developed to detect these species by utilizing a reflector based sensor system. However, for most medium and large-bodied <b>terrestrial</b> species <b>camera</b> traps have proven to be a successful tool for study.|$|R
40|$|The {{growing number}} of glacial margin lakes that have {{developed}} due to glacier retreat, have caused an increase of dangerous Glacial Lake Outburst Floods (GLOFs) in several regions over the last decade. A GLOF can occur when {{the water from the}} lake finds a path underneath the bottom of the glacier and the lake is draining rapidly. This causes normally a flood wave downstream the glacier. Typically such an event takes about 24 hours. GLOF scenarios may be a significant hazard to life, property, nature and infrastructure in the affected areas. Together with our partner institute CECS (Valdivia, Chile), a project was initiated on a pilot study for an early warning system for GLOF events in the Northern Patagonian Icefield. A GLOF is normally characterized by a progressive water level drop. By observing the water level of the lake, an imminent GLOF-event can be identified. Common gauging systems are not suitable for the measurement task, as they may be affected by ice fall or landslides in the lake basin. Therefore, in our pilot study the water level is observed by processing images of a <b>terrestrial</b> <b>camera</b> system. The paper presents the basic principle of a single-camera based GLOF early warning system. Challenges and approaches to solve them are discussed. First results from processed image sequences are presented to show the feasibility of the concept. Water level changes can be determined at decimetre precision. In the first stage of the project, the waterline was measured manually in the images. A promising approach for reliable automation of this task is the use of a camera, which is sensitive for near infrared. The difference in the reflection of water, ice, and rock in this wavelength is more better than in RGB. This will be discussed in the outlook in deep...|$|E
40|$|Provides {{a general}} {{view of the}} {{different}} applications of photogrammetric measurements or images for the documentation and conservation of cultural heritage. The author discusses the principles of perspective and stereoscopy (natural and artificial) that lie behind photogrammetric measurements. The different kinds of instruments used for these measurements are also described and illustrated in the article. The instrumentation ranges from simple photogrammetric <b>cameras,</b> to <b>terrestrial</b> photogrammetric <b>cameras</b> as well as metric and semi-metric cameras. The article also discusses the procedures and instrumentation used in the post-processing phase of the information...|$|R
30|$|A {{society that}} relies on {{individual}} mobility day to day requires sufficient methods for traffic monitoring and guidance. Especially daily commuters want to know travel times for their way to work. Moreover, relief forces are interested in precise travel times for their routing in case of emergencies, mass events, and disasters. However, precise travel time prediction on road networks {{is one of the}} most important concerns and challenges in modern transportation and traffic sciences. In order to determine traffic flow on different road types automatically, several approaches are possible. In general, traffic monitoring is mainly based on data from conventional stationary ground measurement systems such as inductive loops, radar sensors or <b>terrestrial</b> <b>cameras.</b> All ground measurement systems embedded in road infrastructure deliver precise traffic data punctually with high temporal resolution, but their spatial distribution is still limited to selected motorways and main roads. The low spatial resolution of these systems makes area-wide traffic monitoring difficult. New approaches collect data by means of mobile measurement units which flow with the traffic. The so called floating car data (FCD, [4, 17]) obtained from taxicabs can deliver useful traffic information within cities, but they are only available in few big cities today. Furthermore, the traffic information available from this source depends on the routes taxicabs drive, but taxi drivers tend to avoid busy roads during rush hours. Hence, only few or no data will be available on roads burdened with commuter traffic. In order to contribute to area-wide traffic monitoring by remote sensing, several projects, based on airborne optical and SAR sensors as well as SAR satellite sensors are currently running at DLR or have already been concluded. In Reinartz et al. [16] the general suitability of image time series from airborne cameras for traffic monitoring was shown. Tests with several camera systems and various airborne platforms, as well as the development of an airborne traffic monitoring system and thematic image processing software for traffic parameters were performed within the projects “LUMOS” and “Eye in the Sky” [3, 8].|$|R
40|$|Digital <b>terrestrial</b> {{panoramic}} <b>cameras</b> {{are providing}} a new device for taking high-resolution images. The produced images {{have been used}} widely for purely imaging purposes such as an indoor and landscape imaging, cultural heritage recording, tourism advertising and image-based rendering. Due to the high information content of those images {{they may also be}} used as an efficient means for 3 Dobject reconstruction. Therefore the need arises to establish a sensor model and investigate the potential of the system in terms of accuracy. With a well-defined sensor model we have additional powerful sensors for image recording and efficient 3 D object modeling. In this paper we present the result of physical measurements of tumbling for the SpheroCam. A method for tumbling error modeling of panoramic cameras is introduced and we will show how it can be used in bundle adjustment with additional parameters. Then we report the result of modeling and accuracy testing using a 3 D testfield and compare it with the case when tumbling is not being modeled for EYESCAN and SpheroCam. The results indicate subpixel accuracy for both systems. 1...|$|R
40|$|Context. There is an {{increasing}} reliance {{on the use of}} camera-trap technologies for surveys of medium to large <b>terrestrial</b> mammals. <b>Camera</b> trapping may, however, also have significant applications for broad-scale surveys of small mammals. Aims. The present study aims to compare results from camera-trapping surveys to those of the more traditional live trapping techniques. Specifically, it aims to test the effectiveness of the techniques for detecting species, and the cost effectiveness of both approaches. Methods. Surveys were conducted across 36 sites in the Grampians National Park, Victoria, Australia, between April and July 2009. At each site, independent surveys were conducted for small mammals by using a combination of Elliot and cage trapping, then camera trapping. Results for the two different approaches were compared for both their ability to generate small-mammal presence data and their cost effectiveness. Key results. Camera-trapping surveys of 36 sites in the Grampians National Park compared favourably with those of live trapping surveys. Similar species were detected across the sites, and camera trapping was a considerably more cost effective than live trapping. Conclusions. Camera-trapping surveys of small terrestrial mammals may provide a new and cost-effective technique for surveying terrestrial small mammals. This is particularly the case when presence data are the main requirement of the survey, with no requirement to capture and tag animals. Implications. Given the cost-effective nature of camera trapping, there is potential to use this approach to increase the level of replication and spatial coverage of small-mammal surveys. Improving the replication and spatial coverage of studies has the potential to significantly increase the scope of research questions that can be asked, thus providing the potential to improve wildlife management. <br /...|$|R
40|$|Calving is the {{mechanical}} loss of icebergs from tidewater glaciers, responsible for 70 % {{of the annual}} transfer of mass from the cryosphere to the ocean (van der Veen 1998 a, 2002). To be able to correctly predict future global sea level changes {{it is important to}} understand calving processes and incorporate them into the models. The aim of this thesis is to investigate surface velocities, front positions and calving rates of a fast flowing tidewater glacier in Svalbard using an automatic oblique <b>terrestrial</b> time-lapse <b>camera.</b> The camera took pictures every 30 min from May 1 st to September 16 th 2014 resulting in 6600 images. The project forms part of the ConocoPhillips-Lundin Northern Area Program project CRIOS (Calving Rates and Impact on Sea Level) program whose overall aim is to develop better calving-process models. Mean velocities of Kronebreen increased from 3 m/day in May and reached a peak in mid-July of 5. 3 m/day, with a velocity pattern showing increasing velocities towards the front and the centreline. Velocity results were filtered, sensitivity tested, averaged both spatially and temporally and fit well with previous results. Results suggest that velocity has a forcing from air temperature and rain events due to water inputs in the glacier system. Mean front positions showed a total retreat of 320 m, and calving rates reached a peak in early August of 11 m/day. Different parts of the front showed different styles of retreat, and therefore calving styles. Inter-meltwater-plume areas were dominated by infrequent large calving events, and plume areas were dominated by continuous calving. Mean calving rates may be atmospherically controlled, but internal dynamics, melt-water plumes and fjord temperatures may also play a role. The high resolution both spatially and temporally gained using this method makes it possible to investigate the nature of calving and the evolution of surface velocity patterns in more detail than satellite derived results. These data are required for improving the understanding of calving dynamics to develop sea level rise models...|$|R
40|$|Multi-spectral sensor {{systems that}} record {{spatially}} and temporally registered image video {{have a variety}} of applications depending on the spectral band employed and the number of colors available. The colors can be selected to highlight physically meaningful portions of the image, and the resulting imagery can be used to decode relevant phenomenology. For example, the images can be in spectral bands that identify materials that are intrinsic to the target while uncommon in the backgound, providing an anomaly detection cue. These multi-spectral video sensor engines can also be employed in conjunction with conventional fore-optics such as astronomical telescopes or microscopes to exploit useful phenomenology at dissimilar scales. Here we explore the relevance of multi-spectral video in a space application. This effort coupled a <b>terrestrial</b> multispectral video <b>camera</b> to an astronomical telescope. Data from a variety of objects in Low Earth Orbit (LEO) were collected and analyzed both temporally, using light curves, and spectrally, using principal component analysis (PCA). We find the spectral information is correlated with temporal information, and that the spectral analysis adds the most value when the light curve period is long. The value of spectral-temporal signatures, where the signature is the difference in either the harmonics or phase of the spectral light curves, is investigated with inconclusive results...|$|R
40|$|Remote sensing using <b>terrestrial</b> optical CCD <b>cameras</b> is {{a useful}} data-collection method for {{geophysical}} measurement in the near-shore zone, where in situ measurement is difficult and time consuming. In particular, optical video sensing of the variability in the visible spectrum from the sea surface due to the near-shore incident wave field is becoming an established method for distal measurement of near-shore sub-tidal morphology. We report {{on the use of}} a low-mounted shore-normal camera for gathering data on cross-shore dissipative characteristics of a dynamic, open beach. Data is analysed for the purposes of classifying three of Wright and Shorts’ intermediate classes of morphological beach state, as determined by expert raters. Although these beach states are usually thought of as being distinctive in terms of their longshore bar variability, theory predicts that differences should also be observed in cross-shore dissipative characteristics. Three methods of generating features from statistical features from the archived optical data are described and compared, in terms of their ability to discriminate between the beach states. The best performance was obtained using an pixel intensity percentile representation (which does not assume a Gaussian intensity distribution), which classified 85 % of the 284 cases correctly. Class centre moment profiles for each beach state were constructed, and results indicate that cross-shore wave dissipation becomes more disorganized as linear bars devolve into more complex transverse structures...|$|R
40|$|In {{the physics}} of the upper {{atmosphere}} the solar extreme ultraviolet (EUV) radiation plays a dominant role controlling most of the thermospheric/ionospheric (T/I) processes. Since {{this part of the}} solar spectrum is absorbed in the thermosphere, platforms to measure the EUV fluxes became only available with the development of rockets reaching altitude levels exceeding 80 km. With the availability of V 2 rockets used in space research, recording of EUV spectra started in 1946 using photographic films. The development of pointing devices to accurately orient the spectrographs toward the sun initiated intense activities in solarterrestrial research. The application of photoelectric recording technology enabled the scientists placing EUV spectrometers aboard satellites observing qualitatively strong variability of the solar EUV irradiance on short-, medium-, and long-term scales. However, as more measurements were performed more radiometric EUV data diverged due to the inherent degradation of the EUV instruments with time. Also, continuous recording of the EUV energy input to the T/I system was not achieved. It is only {{at the end of the}} last century that there was progress made in solving the serious problem of degradation enabling to monitore solar EUV fluxes with sufficient radiometric accuracy. The data sets available allow composing the data available to the first set of EUV data covering a period of 11 years for the first time. Based on the sophisticated instrumentation verified in space, future EUV measurements of the solar spectral irradiance (SSI) are promising accuracy levels of about 5 % and less. With added low-cost equipment, real-time measurements will allow providing data needed in ionospheric modeling, e. g., for correcting propagation delays of navigation signals from space to earth. Adding EUV airglow and auroral emission monitoring by airglow cameras, the impact of space weather on the terrestrial T/I system can be studied with a spectral <b>terrestrial</b> irradiance <b>camera</b> (STI-Cam) and also be used investigating real-time space weather effects and deriving more detailed correction procedures for the evaluation of Global Navigation Satellite System (GNSS) signals. Progress in physics goes with achieving higher accuracy in measurements. This review historically guides the reader on the ways of exploring the impact of the variable solar radiation in the extreme ultraviolet spectral region on our upper atmosphere in the altitude regime from 80 to 1000 km...|$|R
40|$|National audienceSurface {{displacement}} field of landslides {{is a key}} parameter to access to their geometries and mechanical properties. Surface displacements can be calculated using remote-sensing methods such as interferometry for radar data and image correlation for optical data. These methods have been elaborated this last decade and successfully applied on sensors (radar, <b>cameras,</b> <b>terrestrial</b> 3 D laser scanner imaging) either attached to space or aerial platforms such as satellites, planes, and unmanned radio-controlled platforms (drones and helicopters) or settled at fixed positions emplaced {{in the front of}} landslides. This paper reviews the techniques of image analysis (interferometry and optical data correlation) to measure displacements and examines the performance of each type of platforms. Examples of applications of these techniques in French South Alps are shown. Depending on the landslide characteristics (exposure conditions, size, velocity) as well as the goal of the study (operational or scientific purpose), one or a combination of several techniques and data (characterized by several resolution, accuracy, covered surface, revisiting time) have to be used. Radar satellite data processed with differential interferometric or PS methods are mainly suitable for scientific purposes due to various application limitations in mountainous area. Optical satellite and aerial images can be used for scientific studies at fairly high resolution but are strongly dependant on atmospheric conditions. Platforms and sensors such as drone, fixed camera, fixed radar and Lidar have the advantage of high adaptability. They can be used to obtain very high resolution and precise 3 D data (of centimetric accuracy) suitable for both scientific and operational purposes...|$|R
40|$|In {{order to}} study the seismic {{vulnerability}} of the buildings, one necessary data is the knowledge of façade size and the dimension/position of the windows/doors and other structural discontinuities. To well obtain such information {{for a lot of}} buildings in an urban area, this paper suggests a photogrammetric surveying by the integrated use of Mobile Mapping Systems (MMS) techniques and CCD images. As usual for current architectural photogrammetry, by a CCD <b>camera,</b> <b>terrestrial</b> images are acquired in the best geometrical shot conditions. The 2 D-surveying of building façades is then performed by the well-known digital image-rectification procedure. But at this time, the coordinates of the required control points are measured by a low-cost simplified MMS and not, as usual, by topographic methods. Therefore, for this application, we employ a MMS as well as a “ 3 D-point sower”, namely to only measure with the best efficiency the 3 D-coordinates of stacks of control points. From these East, North and Height coordinates, to compute the 2 D-coordinates ones, with respect each single front, is very easy. By using a simplified MMS, original “pseudo-dynamic” analytical models have been proposed and tested during last years. Thanks to these algorithms, it is possible to recursively solve two classical MMS problems as well as the external orientation of its CCD and the homologous point research by image matching. First interesting results of the application of this method on the historical center of Vittorio Veneto (Italy), test-site for a national research project on seismic risk, are finally explained...|$|R
40|$|Ice {{plays an}} {{important}} role in hydraulic processes of rivers in cold regions such as Canada. The formation, progression, recession and breakup of river ice cover known as river ice processes affect river hydraulics, sediment transport characteristics as well as river morphology. Ice jamming and break up are responsible of winter flash floods, river bed modification and bank scour. River ice cover monitoring using <b>terrestrial</b> images from <b>cameras</b> installed on the shores can help monitor and understand river ice processes. In this study, the benefits of terrestrial monitoring of river ice using a camera installed on the shore are evaluated. A time-lapse camera system was installed during three consecutive winters at two locations on the shores of the Lower Nelson River, in Northern Manitoba and programmed to take an image of the river ice cover approximatively every hour. An image analysis algorithm was then developed to automatically extract quantitative characteristics of the river ice cover from the captured images. The developed algorithm consists of four main steps: preprocessing, image registration, georectification and river ice detection. The contributions of this thesis include the development of a novel approach for performing georectification while accounting for a fluctuating water surface elevation, and the use of categorization approach and a locally adaptive image thresholding technique for target detection. The developed algorithm was able to detect and quantify important river ice cover characteristics such as the area covered by ice, border ice progression and ablation rate, and river ice break up processes with an acceptable accuracy...|$|R
40|$|Computing {{relative}} or absolute range (egocentric distance) is difficult because, of course, neither is specified in any direct {{way by the}} 2 D retinal image. If, however, there was a relationship between range and luminance or color, perhaps it could be exploited to yield fast, initial estimates of range from the retinal image per se. We studied the statistical dependence between range (and disparity) contrast and luminance contrast across random point-pairs in natural scenes, and found that changes in range and luminance are highly dependent. We collected high resolution range maps of natural scenes co-registered with luminance (RGB) images using a Riegl <b>terrestrial</b> scanner, co-mounted <b>camera,</b> and in-house software. Various alternative preprocessing stages were used to simulate {{the early stages of}} visual processing (e. g. foveation). Our basic approach was to randomly sample pairs of points in the scenes to determine if the change in range or luminance or both exceeded some criterion. We then 1) compared the conditional density of range edges given luminance edges to the (unconditioned) density of range edges and 2) compared the joint distribution of range and luminance contrast to the product of their marginal distributions. We found a robust statistical dependence between range and luminance. Additionally, we computed difference surface maps (between the joint distributions and product-of-marginals predicted by independence). These difference surfaces reveal which regions of luminance and range change exhibit the strongest statistical dependencies. The statistical dependence between luminance and range allows the construction of models where one can assign a probability of occurrence of a range edge given a luminance edge at a particular point in a scene. In principle, such a mechanism could also be used by biological visual system to serve as priors when reconstructing the 3 D environment from 2 D image data...|$|R

