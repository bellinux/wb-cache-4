0|10|Public
30|$|Test samples: SOGOU Chinese <b>Thesaurus,</b> the <b>test</b> {{samples are}} taken from the thesaurus.|$|R
40|$|In {{this paper}} {{we present a}} method for extracting bilingual terminologies from {{comparable}} corpora. In our approach we treat bilingual term extraction as a classification problem. For classification we use an SVM binary classifier and training data taken from the EUROVOC <b>thesaurus.</b> We <b>test</b> our approach on a held-out test set from EUROVOC and perform precision, recall and f-measure evaluations for 20 European language pairs. The performance of our classifier reaches the 100 % precision level for many language pairs. We also perform manual evaluation on bilingual terms extracted from English-German term-tagged comparable corpora. The results of this manual evaluation showed 60 - 83 % of the term pairs generated are exact translations and over 90 % exact or partial translations. ...|$|R
40|$|The Visual Thesaurus {{is a new}} query {{approach}} when no starting {{image is}} available. It is a concise representation of all similar regions in a panel of visual patches; the user arranges the visual patches according to his mental target image. The construction of the Visual Thesaurus needs a reliable region description and a clustering algorithm that reflects the variety of the database. In this paper, we develop a new region description schema based on Harris color points of interest. We also evaluate the relevance of several multi-dimensional matching metrics when measuring the similarity between regions described by variable signature dimensions. We outline the need of clustering {{to speed up the}} computation process as well. Moreover, we adopted the relational clustering algorithm to categorize regions according to Harris points of interest features. Generated clusters are represented by prototypes that compose the ”page zero ” of the Visual <b>Thesaurus.</b> We <b>tested</b> our approach on generic database, the relevance of obtained clusters is evaluated subjectively. Index Terms — Image region analysis, Pattern matching, Image texture analysis, Image classification, Pattern clusterin...|$|R
40|$|We {{study the}} h Hirsch index {{as a local}} node {{centrality}} measure for complex networks in general. The h index is compared with the Degree centrality (a local measure), the Betweenness and Eigenvector centralities (two non-local measures) {{in the case of}} a biological network (Yeast interaction protein-protein network) and a linguistic network (Moby <b>Thesaurus</b> II) as <b>test</b> environments. In both networks, the Hirsch index has poor correlation with Betweenness centrality but correlates well with Eigenvector centrality, specially for the more important nodes that are relevant for ranking purposes, say in Search Machine Optimization. In the thesaurus network, the h index seems even to outperform the Eigenvector centrality measure as evaluated by simple linguistic criteria. Comment: 8 pages, 4 figures, typos and references corrected, table I correcte...|$|R
40|$|This {{study is}} part of our broader {{research}} focusing on conceptual query expansion. Our goal is to examine whether current structures of Knowledge Organisation Systems (KOSs) reflect users’ perception of knowledge representation in order to verify under which circumstances the KOSs can ameliorate the query expansion process. For our study we focused on non-expert users using a relational KOS, namely the EUROVOC <b>thesaurus.</b> To <b>test</b> our hypotheses we proceeded with an empirical study during which the participants had to conduct specific searches in the Evonymos Ecological Library database. Our metrics showed that only 15. 0 % of the submitted terms were unique and that the search terms mainly contained one or two words. Furthermore, 60. 5 % of the submitted terms were matched to Thesaurus’ terms. We conclude that for conceptual query expansion using a thesaurus the polysemy of words is a serious obstacle, which is hard to deal with because of the limited search words used for each query. This is because the limited search words do not serve for safe conceptual matching both among the search terms and between the search terms and terms from the hierarchy of the Thesaurus. Future research will try to answer whether this problem is solved with the synchronous use of multiple KOSs during the query expansion or with conceptual query clustering techniques...|$|R
40|$|Primarily {{based on}} the report "Chronology of Selected Literature, Reports, Policy Instruments, and signigicant Events Affecting Federal Scientific and Technical Information (STI) in the United States", no. 11 of the NASA/DoD Aerospace Knowledge Diffusion {{research}} project of Thomas Pinelli, and the OTA report "Helping America compete. The role of Federal Scientific and Technical Information", the paper pays attention {{to the history of}} COSATI, CENDI, NTIS, DTIC and NASA, <b>TEST</b> <b>Thesaurus</b> and COSATI Subject Categories. Further attention is being given to Subject Categories for STI (reports, journal articles, translations, books and databases) in general and to the many Subject Categories that have grown from the old COSATI scheme. Because standardization of Subject Categories might be a useful method to facilitate and promote access to internaional STI, attention is given to the CENDI RDP, the NATO Thesaurus and NTIS Subject Catergories. Includes: Conference preprint, Pratt student commentaryXAInternationa...|$|R
40|$|A user-interactive {{rule-based}} {{computer program}} {{was developed for}} the purpose of mapping and merging multiple hierarchical thesauri. The program DynaSaurI (Dynamic <b>Thesaurus</b> Integration) was <b>tested</b> on subsets of two medical thesauruses, the Systemized Nomenclature of Medicine (SNOMED) and the Medical Subject Headings (MeSH). Each theasurus is treated as a knowledge base, containing information both in the terms and in the various types of relationships between terms. DynaSaurI uses combinations of string matching and tree browsing to propose a ranked array of related MeSH terms for each SNOMED term presented. A medical expert selected the closest match from the array of terms proposed by DynaSaurI and entered the appropriate type of relationship between the terms. The information acquired from the expert was then used to refine DynaSaurI's mapping rules. With DynaSaurI, all 84 SNOMED concepts were successfully merged with and mapped to MeSH Main Headings; 74 (88 %) were mapped by the initial DynaSaurI pass, and the remainder by incorporating the user's responses. All merging utilized the relationship descriptions (e. g., “is narrower than”) provided by the on-line interaction with the medical expert...|$|R
40|$|The {{purpose of}} this work was to {{investigate}} how ISO standard based thesauri can be reused by means of semantic web technology. Besides the proposal of a conversion method, the goal was also to investigate if {{it is possible to}} define a thesaurus meta model using RDF(S) /OWL in a way that generic reasoners are able to deliver the desired thesaurus services, for thesauri of realistic size as there is not much information available about this topic in literature. Focus was on the practical usefullness of the resulting thesaurus system and therefore a thesaurus of 15000 terms has been converted. The <b>thesaurus</b> services were <b>tested</b> using two OWL reasoners and two RDF reasoners. But both tested RDF(S) reasoners, CWM and Sesame, could deliver the desired thesaurus services also when a complete thesaurus of about 150. 000 terms was loaded. A consequence of this approach is that some ‘knowledge’ of the thesaurus model which can only be described with OWL, must be hard coded in the application interfacing to the RDF(S) reasoner...|$|R
40|$|Thesauri are {{important}} tools for many Natural Language Processing applications. Roget's Thesaurus is particularly useful. It is {{of high quality}} {{and has been in}} development for over a century and a half. Yet its applications have been limited, largely because the only publicly available edition dates from 1911. This thesis proposes and tests methods of automatically updating the vocabulary of the 1911 Roget’s Thesaurus. I use the Thesaurus as a source of training data in order to learn from Roget’s for the purpose of updating Roget’s. The lexicon is updated in two stages. First, I develop a measure of semantic relatedness that enhances existing distributional techniques. I improve existing methods by using known sets of synonyms from Roget’s to train a distributional measure to better identify near synonyms. Second, I use the new measure of semantic relatedness to find where in Roget’s to place a new word. Existing words from Roget’s are used as training data to tune the parameters of three methods of inserting words. Over 5000 new words and word-senses were added using this process. I conduct two kinds of evaluation on the updated Thesaurus. One is on the procedure for updating Roget’s. This is accomplished by removing some words from the <b>Thesaurus</b> and <b>testing</b> my system's ability to reinsert them in the correct location. Human evaluation of the newly added words is also performed. Annotators must determine whether a newly added word is in the correct location. They found that in most cases the new words were almost indistinguishable from those already existing in Roget's Thesaurus. The second kind of evaluation is to establish the usefulness of the updated Roget’s Thesaurus on actual Natural Language Processing applications. These applications include determining semantic relatedness between word pairs or sentence pairs, identifying the best synonym from a set of candidates, solving SAT-style analogy problems, pseudo-word-sense disambiguation, and sentence ranking for text summarization. The updated Thesaurus consistently performed at least as well or better the original Thesaurus on all these applications...|$|R
40|$|The goal is {{to study}} {{thesaurus}} as an instrument to define the classification of economic sciences, to adapt their classification to the increased information flow, to increase accuracy of allocation of information resources with consideration of the users’ needs, to suggest making alterations in the classification of economic sciences made by the Institute of Scientific Information for Social Sciences of the Russian Academy of Sciences (INION RAN) in 2001. The authors see the classification of economic sciences {{as a product of}} social communications theory – a differentiated aspect of social research. Modern science is subdivided into various aspects with varied subjects and methods. The latter overlap and form a hierarchy of concepts in science within the same research subject. The authors stress the importance of information retrieval systems for developing scientific knowledge. Information retrieval systems can immediately deliver data from different areas of science to the user who can then integrate the information and obtain a vivid picture of the research subject. Search engines and rubricators are becoming increasingly important as {{there is a tendency to}} isolated thinking with many Internet users. The authors have devised a certain approach to using the thesaurus as the means of sciences classification and as a hyper language of science. The suggested methodological approach to structuring terms and notions via <b>thesaurus</b> have been <b>tested</b> at Syktyvkar State University and Syktyvkar branch of Saint-Petersburg Economic University. Methods : deduction, induction, analysis, synthesis, abstraction technique, classification. Results : there have been defined stages and main sections of the information-retrieval thesaurus of the hyperlanguage of economic science on the basis of existing classification systems of scientific knowledge. Scope of application of results : library services, information technology, education. DOI:  [URL] </p...|$|R

