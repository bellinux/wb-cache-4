0|10000|Public
50|$|Firefox Focus is a privacy-focused browser from Mozilla, {{available}} for the Apple iPhone, iPad, iPod <b>touch</b> <b>mobile</b> <b>devices</b> and Android smartphone and tablet devices. It {{is also known as}} Firefox Klar in German-speaking context {{in order to avoid the}} ambiguity with the German news magazine FOCUS.|$|R
50|$|Originally {{produced}} in Adobe Flash, {{the game was}} re-released in 2016 as a native HTML5 game, with support for <b>touch</b> and <b>mobile</b> <b>devices.</b>|$|R
50|$|Firefox for iOS is a browser from Mozilla, for the Apple iPhone, iPad and iPod <b>Touch</b> <b>mobile</b> <b>devices.</b> It is {{the first}} Firefox branded browser {{not to use the}} Gecko layout engine as is used in Firefox for desktop and mobile. Due to iOS {{security}} restrictions chosen by Apple (specifically the inability to set writable pages executable, which is essential for just-in-time compilation), Firefox has to use the built-in iOS WebKit-based rendering framework instead of Gecko. Firefox for iOS supports Firefox Sync and is able to sync Firefox's browsing history, bookmarks, and recent tabs.|$|R
30|$|In {{the final}} interview, {{we asked the}} {{participants}} whether {{they would like to}} change the colors of the app icons on their own <b>mobile</b> <b>touch</b> <b>devices</b> and how they would feel about color coding of apps, in order to represent certain categories {{with the help of a}} common color. Participants who did not own a <b>mobile</b> <b>touch</b> <b>device</b> were excluded from this analysis, leading to a sample of N[*]=[*] 34. Regarding the first question, 41 % of the participants indicated that they would like to manipulate the colors of the apps on their <b>mobile</b> <b>touch</b> <b>device,</b> while 9 % were indecisive, and 50 % were opposed to the idea. The latter group mostly attributed its opposition to familiarization with current app icon or brand colors and to a lack of interest in the personalization of colors. Regarding the second question, participants showed a more positive reaction. Of the participants, 65 % indicated that they would like a color-coded system on their <b>mobile</b> <b>touch</b> <b>device</b> in which apps of the same categories (e.g. games) share the same color. However, only half of these participants would like to pick the colors of these categories themselves.|$|R
50|$|Taptu was {{a social}} media and {{technology}} company that built platforms, tools and applications that enabled content on <b>touch</b> screen <b>mobile</b> <b>devices,</b> including phones running iOS and Android. Taptu was a privately held company that was founded in Cambridge in 2007 and was funded by DFJ Esprit and Sofinnova. The company was based in Cambridge and Denver, Colorado.|$|R
30|$|Even though Study 2 {{approximated}} to {{a realistic}} use of <b>mobile</b> <b>touch</b> <b>devices,</b> {{it was still}} conducted under controlled laboratory conditions and shares similar limitations.|$|R
40|$|International audienceWall-sized {{displays}} {{can support}} data visualization and collaboration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It {{consists of an}} interface running on <b>touch</b> <b>mobile</b> <b>devices</b> for input, a communication protocol between devices and the wall, and a library that implements the protocol and handles synchronization, locking and input conflicts. The library presents the input as an event loop with callback functions. Each <b>touch</b> <b>mobile</b> has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can control simple cursors on the wall application, or specific content (objects or groups of them). The types of associated widgets are decided by the wall application, making the mobile interface customizable by the wall application it connects to...|$|R
40|$|Wall-sized {{displays}} {{can support}} data visualization and collab-oration, but making them interactive is challenging. Smarties allows wall application developers to easily add interactive support to their collaborative applications. It {{consists of an}} interface running on <b>touch</b> <b>mobile</b> <b>devices</b> for input, a commu-nication protocol between devices and the wall, and a library that implements the protocol and handles synchronization, locking and input conflicts. The library presents the input as an event loop with callback functions. Each <b>touch</b> <b>mobile</b> has multiple cursor controllers, each associated with keyboards, widgets and clipboards. These controllers can be assigned to specific tasks, are persistent in nature, and can be shared by multiple collaborating users for sharing work. They can con-trol simple cursors on the wall application, or specific content (objects or groups of them). The types of associated wid-gets are decided by the wall application, making the mobile interface customizable by the wall application it connects to. Author Keywords input toolkit; wall display; hand-held touch devices; cscw; multi-cursors. ACM Classification Keyword...|$|R
30|$|In sum, in an applied visual search {{paradigm}} on <b>mobile</b> <b>touch</b> <b>devices,</b> {{the efficiency}} of the search can be understood as an objective indicator of the usability. The efficiency, on the other hand, is also perceived by the user, which influences the perception of the intuitiveness and of the instrumental qualities of the device. Due {{to the fact that the}} present paper aims to optimize search screens on a <b>mobile</b> <b>touch</b> <b>device,</b> an increased efficiency should be reflected in a better UX and increased intuitiveness.|$|R
40|$|Abstract — This paper {{presents}} a design and evaluation {{process in the}} early design phase towards a three dimensional user interface on a <b>touch</b> screen <b>mobile</b> <b>device</b> with service multitasking use cases. Our Service Fusion concept is an outcome of this iterative concept design and evaluation process. In this paper, we present briefly four 3 D user interface concepts, evaluated with users and experts. Two of these concepts are also implemented on a <b>touch</b> screen <b>mobile</b> <b>device.</b> We also present user experience findings and how they have supported our early phase design process. The Service Fusion demonstration of 3 D multitasking shows multiple services running in a 3 D city model, which allows users to purchase movie tickets, listen to music and find local bars and stores by drag and drop gestural controls. Evaluation findings indicate that {{people are interested in}} service multitasking and dragging and dropping interaction model in 3 D user interfaces in the tablet device context. However, the 3 D space context will affect how important and useful users perceive services to them. Keywords- 3 D UI; concept design; user experience; <b>touch</b> screen <b>mobile</b> device; tablet. I...|$|R
30|$|For affective {{interaction}} {{to happen}} on <b>mobile</b> <b>touch</b> screen <b>devices,</b> we therefore require an emotion recognition technique that {{does not depend on}} expensive computations or need any extra setup. The method we propose relies on users’ touch interaction behaviour (finger strokes) to detect the emotional state of mind. It does not require additional sensors or wires to record the finger strokes. Also, the computations are much less compared to the existing methods. Hence, the proposed approach is expected to be more suitable for <b>mobile</b> <b>touch</b> input <b>devices.</b>|$|R
40|$|How can {{institutions}} of higher education harness the didactic potential of the near-ubiquity of <b>touch</b> enabled <b>mobile</b> <b>devices</b> amongst a 21 st century student population? This paper describes the goals, method and results of a two-year educational development project conducted at University of Leuven Association, Belgium (2013 - 2015). The project sets forth to (a) chart the didactic affordances of <b>touch</b> enabled <b>mobile</b> <b>devices</b> for higher education, (b) develop a user-friendly interface to direct teachers and students towards affordances that meet their particular teaching or learning needs and c) design a step-by-step trajectory to help policy makers and ICT personnel manoeuvre the complexities of implementing a didactic change that raises a host of technological, financial and logistic questions. First, a theoretical, didactic framework was established. Puentedura’s SAMR-model [1], which prominently figures the use of a functional task in the upper two, ‘transformative’ layers of its application model, led towards the development of a framework of technology-mediated, task-based teaching and learning [2]. Then, through literature and a series of task-driven pilot projects in diverse disciplines and educational settings, it was researched which of Cope and Kalantzis’ ‘seven affordances’ [3] could be realized through <b>touch</b> enabled <b>mobile</b> <b>devices.</b> As a result, an extensive matrix of didactic affordances was assembled, which forms the backbone of an interactive, multiplatform website and app for students, lecturers and professors. Users can browse the interface for specific touch enabled didactic approaches and applications, which are categorized according to didactic need and educational setting. Using search filters, users are led to a relevant one-page brief that describes a particular didactic affordance by means of an example, concluding with an annotated selection of suitable apps. As the TPACK model demonstrates, however, even if a didactic scenario successfully integrates technological, pedagogic and content knowledge, it will only take root in an environment that meets several contextual requirements (infrastructure, finance, vision, support, management…) [4]. Therefore, an implementation trajectory for policy makers and ICT personnel was developed alongside the didactic path aimed at student and teachers. The trajectory, which is modelled onto Kotter’s eightstep change management approach, guides institutions through the complex process of integrating the didactic use of <b>touch</b> enabled <b>mobile</b> <b>devices</b> into their culture and organizational structures [5]. This paper aims to offer inspiration and tools for {{institutions of}} teaching and learning that wish {{to make the most of}} the touch enabled technologies that students (and teachers) carry with them into higher education. status: publishe...|$|R
40|$|Full of {{explained}} {{code and}} enriched with screenshots, {{this book is}} the practical way to take your Sencha Touch skills to the next level. If you want to gain practical knowledge for using the Sencha <b>Touch</b> <b>mobile</b> web application framework, and you are familiar with HTML and CSS, then this book is for you. It is assumed that {{you know how to}} use touchscreens, <b>touch</b> events, and <b>mobile</b> <b>devices</b> such as Apple iOS and Google Android...|$|R
30|$|Although basic {{research}} results were confirmed for a <b>mobile</b> <b>touch</b> <b>device</b> setting, a major limitation {{is that the}} visual search on <b>mobile</b> <b>touch</b> <b>devices</b> was not adequately replicated. In real life, users mentally visualize the app icon and its features before a search. The location and color of icons are learned and memorized through the interaction with the device. In Study 1, these two dimensions were excluded by randomization in order to focus on effects of similarity grouping. The impact of spatial learning and memory, {{the preparation of the}} search by learned colors, as well as the interplay of these complex cognitive processes are further addressed in the general discussion.|$|R
30|$|Our {{goal was}} to {{increase}} the efficiency of app selection on <b>mobile</b> <b>touch</b> <b>devices</b> by using an organization scheme of app icons based on color. More precisely, we investigated whether basic findings from the visual search paradigm also hold for a more complex search situation on app icons and how users experience the colored icon, which presumably helps to improve their search. In order to realize the first step of transfer, an artificial visual search with real app icons on a <b>mobile</b> <b>touch</b> <b>device</b> was conducted in Study 1, aiming to replicate effects of TDS as well as DDS. Reaction times were analyzed depending on of set size and target presence. In Study 2, the effect of the TDS and DDS was replicated and its impact on UX and intuitiveness was investigated. Additionally, further aspects of the transformation of basic research to the applied setting of app search on <b>mobile</b> <b>touch</b> <b>devices,</b> such as response format (touching the target) and swiping, were realized. Finally, other important impacts, such as crowding (Pelli & Tillman, 2008) or guidance by memory (e.g. Chun & Jiang, 1998; Geyer, Zehetleitner, & Müller, 2010) were discussed as directions for future work.|$|R
500|$|Since {{its initial}} release for the Nokia N900 {{multimedia}} Internet device, and Apple's iPhone and iPod <b>Touch</b> <b>mobile</b> digital <b>devices,</b> Rovio has released versions of Angry Birds for additional devices. [...] An iPad-exclusive version, Angry Birds HD, released with the iPad <b>mobile</b> digital <b>device</b> in April 2010. In August 2010, Angry Birds was {{made available to}} the Palm Pre phone running Palm's webOS operating system through its App Catalog online store. Symbian^3 phones received a version of the game in October 2010, which initially includes only the [...] "Poached Eggs" [...] and [...] "Mighty Hoax" [...] episodes. Angry Birds works on Kindle Fire and Kindle Fire HD.|$|R
40|$|In {{the last}} decade, we have {{observed}} an increased proliferation of <b>mobile</b> <b>touch</b> <b>devices.</b> These devices {{are often used}} for browsing content. But how can we enrich the user interaction to allow for content production and complex design tasks on the devices? This thesis presents CrowdDesign Touch, an authoring environment that combines both design-by-example and crowdsourcing to allow complex design tasks to be carried on <b>mobile</b> <b>touch</b> <b>devices.</b> CrowdDesign Touch builds on {{the foundation of a}} previous project: CrowdDesign. This pro-ject extends the concept of designing with the crowd to new domains to become a general framework of a mobile authoring environment. Our approach is designed to support authors in composing prototypes of slideshow presentations, mobile applications and mobile web-sites. The thesis presents the design and implementation of several prototypes along with exper-iments that explore the potential of combining design-by-example with crowdsourcing for complex design tasks that are otherwise too difficult to be carried out on a <b>mobile</b> <b>device...</b>|$|R
30|$|In sum, we {{know from}} applied {{research}} that guidance by simple features (e.g. color) and similarity grouping modulates the efficiency of visual search. Notwithstanding the evidence that color highlighting and similarity grouping are important factors of app arrangement on <b>mobile</b> <b>touch</b> <b>devices,</b> a systematic transfer of fundamental visual search results to this applied setting has not been done yet. A validation of results from visual search paradigms in the applied context of <b>mobile</b> <b>touch</b> <b>devices</b> might significantly contribute {{to the design of}} more efficient interfaces. Here, we also aim to test how users feel about applications modifying their search behavior. This aim is based on the user-centered design approach, which emphasizes the importance of including the user in the process of designing technology (ISO 9241 – 210, 2010; Norman & Draper, 1986).|$|R
50|$|Earbits is a commercial-free music {{streaming}} service & music marketing platform that {{was founded in}} 2010. The streaming service is available to consumers as a website in addition to clients for the iPhone, iPod <b>Touch</b> & Android <b>mobile</b> <b>devices.</b> The music marketing platform is available to independent artists, labels and concert promoters who can bid for their songs to be played. Earbits currently has 550 labels, 10,000 artists and 100,000 songs in its library.|$|R
5000|$|The Zune HD was a {{portable}} media {{player in the}} Zune product family released on September 15, 2009 by Microsoft. It was a direct competitor with Apple's iPod <b>touch</b> series of <b>mobile</b> <b>devices.</b> It was initially released in 16 and 32 GB capacities. [...] A 64 GB version was released on April 9, 2010. It has a touchscreen interface for navigation and included Wi-Fi for synchronization, access to the Zune Marketplace and Web browsing.|$|R
40|$|ABSTRACT We present DooDB, a doodle {{database}} containing {{data from}} 100 users captured with a <b>touch</b> screen-enabled <b>mobile</b> <b>device</b> under realistic conditions following a systematic protocol. The database contains two corpora: 1) doodles and 2) pseudo-signatures, which are simplified finger-drawn {{versions of the}} handwritten signature. The dataset includes genuine samples and forgeries, produced under worst-case conditions, where attackers have visual access to the drawing process. Statistical and qualitative analyzes of the data are presented, comparing doodles and pseudo-signatures to handwritten signatures. Time variability, learning curves, and discriminative power of different features are also studied. Verification performance against forgeries is analyzed using state-of-the-art algorithms and benchmark results are provided. INDEX TERMS Graphical password, doodle verification, pseudo-signature. I...|$|R
30|$|We see {{all around}} us various devices that are {{operated}} by touch. The popularity of <b>mobile</b> <b>touch</b> screen <b>devices</b> have seen significant rise in recent years, mainly due to the availability of affordable smart phones and tabs. According {{to a survey by}} the Federation of Indian Chambers of Commerce and Industry (FICCI) and KPMG International 1, 59 million people were using smart phones till 2013 in India and it is expected to reach 265 million by 2016. The statistics is in fact reflective of a global trend. Since these devices are being used by the masses, usability and consequently the HCI issues are very important for these devices. As we have already noted before, emotion influence usability. Therefore, it is necessary to work in the direction of affective <b>touch</b> interaction for <b>mobile</b> <b>touch</b> screen <b>devices.</b> In this article, we present the first step towards achieving the objective; namely, detect emotion for touch screen users.|$|R
50|$|The latest major stable SproutCore {{release is}} 1.8, {{released}} on March 7, 2012, with many bug fixes, several new features, and documentation updates. Release 1.6 {{was largely a}} bugfix release, building on the previous 1.5 release. SproutCore 1.5 contained significant updates to view layers, added a new CSS parser that builds off of SCSS, WAI-ARIA support, modular loading, and additional features. The previous major release, SproutCore 1.4, included <b>touch</b> support for <b>mobile</b> <b>devices,</b> released on September 20, 2010.|$|R
30|$|On <b>mobile</b> <b>touch</b> <b>devices,</b> {{efficiency}} {{refers to}} quick access to apps {{with a minimum}} of resources spent on the search. However, the increasing number of available apps forces users into a complex and inefficient visual search task. The complex search dynamic arises from factors such as the available screen size of <b>mobile</b> <b>devices,</b> similarity of app icons, the need to swipe through several smartphone pages, diverse use-environments (e.g. on a train, while walking), differing goals and use cases leading to altering target apps, and the need for complex motoric responses (e.g. touch displays with little or no haptic feedback). The search for an app icon is even further complicated because phone manufacturers often implement the possibility to adjust (“individualize”) the spatial icon array. Even though personalization can allow quicker access to certain apps, most phone manufacturers limit the degrees of freedom offered to arrange app icons and personalized arrangements can be altered by updates. Hence, human-centered app icon design faces the challenge of facilitating the complex visual search task on <b>mobile</b> <b>touch</b> <b>devices.</b> Our goal was to transfer knowledge from basic research on visual search to the field of human–computer interaction and app icon design, with the aim of providing <b>mobile</b> <b>touch</b> <b>device</b> users with a fluent experience when searching for an app. We first examined visual search efficiency for app icon selection by similarity grouping with universally applicable colored icons (Study 1). Visual search efficiency was then further investigated with regard to the appeal of these colored icons and their effect on the perception of the interaction qualities in terms of UX (Study 2). Three theoretical areas were considered: basic research regarding visual search; applied research dealing with visual search of icons; and the impact of (search) efficiency on UX.|$|R
30|$|<b>Mobile</b> <b>touch</b> <b>devices</b> {{have become}} an {{important}} part of daily life. “There’s an app for that” has become a common phrase, showing how ubiquitous apps have become. While the growing number of apps offers users a wide range of possibilities, it also challenges them to find the desired app from all the others installed on the <b>mobile</b> <b>device</b> within a reasonable amount of time. Focusing on this challenge, we explored in two studies how users can be supported in their visual search for a specific icon by attentional guidance based on universally applicable colors.|$|R
30|$|Users of <b>mobile</b> <b>touch</b> <b>devices</b> {{are often}} {{confronted with a}} great number of apps, {{challenging}} an efficient access to single applications. Especially when looking for infrequently used apps, users have to perform a visual search. We address this problem in two studies by applying knowledge about visual search efficiency to app icons on <b>mobile</b> <b>touch</b> <b>devices.</b> We aimed to transfer findings of similarity grouping for complex stimuli to a more applied setting and to investigate the effect of search efficiency on user experience. In Study 1 (N[*]=[*] 18), we varied set size and target presence as well as visual similarity between icons by color manipulation. Results indicated a highly efficient search when the target was easy to discriminate from the distractors and a less efficient search with increasing similarity. These results were replicated in a second, more realistic use case (N[*]=[*] 36). Regarding user experience, Study 2 showed that perceived usability and intuitiveness increased with search efficiency but that the overall liking also depended on the visual variety of the design. Moreover, although participants showed a general interest in a system supporting their search, most participants had concerns about data privacy with such a system. In conclusion, the results indicate that concepts and findings from basic attention research serve as fruitful heuristics for searches in more realistic (applied) settings. Furthermore, results showed that similarity manipulation with color works without controlling for other icon characteristics (e.g. luminance, shade). The findings might offer a new approach when designing for smooth interaction with <b>mobile</b> <b>touch</b> <b>devices.</b>|$|R
40|$|The use {{of paper}} tickets {{is still one}} of the most popular methods of verifying tickets at the events. Because of {{increased}} number of <b>mobile</b> <b>devices</b> with network access and built-in NFC technology there are new methods emerging for verifying tickets. The thesis presents a solution to validate tickets with mobile application for Android devices. To perform tests a web application was implemented that enables organizers to create public events, performances or tour of museums/galleries. Visitors are able to view events on the web application and buy tickets for events. After the visitors collect tickets using mobile application, they can used them to gain entry by <b>touching</b> their <b>mobile</b> <b>device</b> NFC with another NFC device provided by event organiser. Main focus of this thesis is to develop a system that can verify tickets, without accessing the server for each request and thus reduce the time needed to verify the individual tickets...|$|R
30|$|When users look {{at their}} <b>mobile</b> <b>touch</b> <b>device</b> to open an app, they first {{have to find the}} right icon. We {{investigate}} whether searches can be supported by colored app icons and how users feel about such a support system. It is known that search efficiency can be manipulated by similarity grouping. However, these results are mainly based on simple stimuli and a yes/no answer format. App icons are more complex because they have many different visual features and users have to tap the icon to start the app after navigating between different screens of the <b>mobile</b> <b>device.</b> This paper aims to transfer basic knowledge from visual search for these complex stimuli by applying the theoretical foundation of visual search in the context of <b>mobile</b> <b>touch</b> <b>devices.</b> This includes not only similarity grouping, effects of set size, and target presence, but also motoric processes. Additionally, we aim to connect search efficiency with user experience (UX). The results give a first insight into how icons can be designed to allow grouping, which can be used in further research regarding spatial learning processes, semantic categorization of apps, and individual preferences of app organization. The results indicate how important the overall design of <b>mobile</b> <b>device</b> screens is for UX. Moreover, a color grouping scheme might be a way to further empower designers to develop devices that match the user’s hedonistic and pragmatic needs.|$|R
40|$|We {{present a}} novel sketch-based route {{planning}} technique, {{that supports the}} collaborative work {{of a group of}} people navigating through a virtual environments using <b>mobile</b> <b>devices.</b> With our new approach, route planning tasks, like creating camera animation paths, can be generated very efficient, while working on large screens with complex data. Our interaction technique lets the user explore the distributed environment in a two stage process. During the first stage, the user draws the preferred navigation path directly onto a <b>touch</b> sensitive <b>mobile</b> <b>device,</b> that presents the data as a “World in Miniature”. Afterward, during a second stage, the user can define areas of interest by performing additional sketches, like drawing points, lines or circles, to easily define the camera orientation during the animation. Based on the sketched input, the system creates automatically the optimal animation path and camera orientation, so that disturbing occlusions are avoided and all areas of interest are in view...|$|R
40|$|Abstract. <b>Touch</b> screen <b>mobile</b> <b>devices</b> {{are highly}} {{flexible}} and customizable, allowing designers to create inclusive user interfaces that are accessible {{to a broader}} user population. However, the knowledge to provide this new generation of user interfaces {{is yet to be}} uncovered. Our goal is to thoroughly study <b>mobile</b> <b>touch</b> interfaces, thus providing the tools for informed design. We present an evaluation performed with 15 tetraplegic and 18 able-bodied people that allowed us to identify their main similarities and differences within a set of interaction techniques (Tapping, Crossing, and Directional Gesturing) and parameterizations. Results show that despite the expected error rate disparity, there are clear resemblances, thus enabling the development of inclusive touch interfaces. Tapping, a traditional interaction technique, was among the most effective for both target populations, along with Crossing. The main difference concerns Directional Gesturing that in spite of its unconstrained nature shows to be inaccurate for motor impaired users...|$|R
40|$|The availability, and popularity, {{of touch}} screen tablets is {{drastically}} increasing with over 30 % of internet users now owning one. However {{the lack of}} bimanual interaction in touch screen tablets is presenting product designers with serious challenges. Several {{attempts have been made}} to facilitate bimanual interaction in such products but results are not comparable to that of their non-mobile cousins, e. g. laptops. This paper presents the finding of a group collaboration aimed at prototyping a <b>mobile</b> <b>touch</b> screen <b>device</b> which supports bimanual interaction during internet browser navigation through rear mounted inputs. The researchers found it problematic to add basic bimanual interactions for internet browser navigation to the rear of a prototype <b>mobile</b> <b>touch</b> screen <b>device</b> due to issues regarding grip type, finger movement and hand position. This paper concludes that in order to achieve bimanual interaction researchers need to return to basics and consider how to free the hand and fingers from current constraints...|$|R
40|$|International audienceThis paper {{describes}} keylogging counter-measures for virtual keyboards, {{widely used}} to authenticate in various applications and contexts, such as online banking services or <b>touch</b> screen <b>mobile</b> <b>devices.</b> Due to this massive use {{and to the}} malware landscape, {{the security of a}} virtual keyboard at authentication time is fundamental. Our work is based upon several human vision properties like motion perception, visual as simulation and visual interpolation. We, first, generate a frame filled with noise and then we manipulate this noise {{in order to make a}} user see shapes, e. g. letters or digits. The recognition of these shapes by a malware would require high analysis capabilities to automatize. This way, we achieved to make a human-readable virtual keyboard resilient to a large scope of screenshot-based keylogging methods...|$|R
40|$|This paper studies {{continuous}} authentication for <b>touch</b> interface based <b>mobile</b> <b>devices.</b> A Hidden Markov Model (HMM) based behavioral template training {{approach is}} presented, {{which does not}} require training data from other subjects other than {{the owner of the}} mobile. The stroke patterns of a user are modeled using a continuous left-right HMM. The approach models the horizontal and vertical scrolling patterns of a user since these are the basic and mostly used interactions on a <b>mobile</b> <b>device.</b> The effectiveness of the proposed method is evaluated through extensive experiments using the Toucha-lytics database which comprises of touch data over time. The results show that the performance of the proposed approach is better than the state-of-the-art method...|$|R
40|$|This paper {{describes}} our mobile spatial interaction (MSI) prototype Touch 2 Query which {{presents the}} idea of using the <b>touch</b> screen on <b>mobile</b> <b>devices</b> to assist in performing ad-hoc spatial queries. This approach differs from conventional mobile LBS applications where the query shape (search space) is limited to either a bounding box or radius. Instead, we provide functionality that allows users to interactively draw any desired query shape overlaid on an area of interest directly on a <b>mobile</b> <b>device</b> with their finger by combining vector primitives such as circles, polygons, polylines, and points. With the help of location and orientation aware <b>mobile</b> <b>devices,</b> <b>mobile</b> maps, and real-time distance and area measurements, Touch 2 Query gives the users freedom to perform customised spatial queries on objects/areas of interest while realising a better contextual understanding of their spatial environment at the same time...|$|R
30|$|Study 2 {{incorporated}} {{a more realistic}} scenario by expanding the search space over two screens connected by a swipe. Also Study 2 showed that guiding attention by color similarity enhanced the search efficiency. In addition, the results of Study 2 indicated that these searches on connected screens are even more sensible to bad icon design (high TDS) than single screen searches. In sum, knowledge of basic visual search was successfully transferred to the visual search of <b>mobile</b> <b>touch</b> <b>devices.</b>|$|R
40|$|This {{case study}} {{responds}} to the current trends in ICT. <b>Mobile</b> <b>Touch</b> iPads can provide very good assistance to disabled seniors. The intuitive tablet environment, {{the possibility of the}} formation environment and its portability, has a very positive effect on the use of particular communication. For comparison, using a conventional PC/notebook, word processor, keyboard and computer mouse compared to the iPad and selected applications. The results of this case study show that the use of <b>mobile</b> <b>touch</b> <b>devices</b> iPad for seniors with mental retardation is a great benefit. These devices do not require high demands on graphomotorics like a standard PC devices...|$|R
