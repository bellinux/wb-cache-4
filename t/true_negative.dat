583|469|Public
25|$|Let us {{consider}} a two-class prediction problem (binary classification), {{in which the}} outcomes are labeled either as positive (p) or negative (n). There are four possible outcomes from a binary classifier. If the outcome from a prediction is p and the actual value is also p, then it is called a true positive (TP); however if the actual value is n then {{it is said to}} be a false positive (FP). Conversely, a <b>true</b> <b>negative</b> (TN) has occurred when both the prediction outcome and the actual value are n, and false negative (FN) is when the prediction outcome is n while the actual value is p.|$|E
500|$|Khonsari was a {{child in}} Iran {{at the time of}} the Revolution, and left the country shortly after it ended. Khonsari {{developed}} the game with the intention of making players understand the moral ambiguity of the situation, due to the different beliefs in Iran, and to [...] "feel the passion and the elation of being in the revolution". When the initial game concept was conceived, the location of Iran had not been decided; the development team was attracted to the idea of a game set during a revolution, ultimately settling on the Iranian Revolution. When representing the concept of a revolution, the development team wished to demonstrate the multiple definitions of the term. Khonsari stated that they [...] "wanted to embrace that spirit of revolution, but we also show the trajectory of a revolution", regarding the <b>true</b> <b>negative</b> and complicated results of real revolutions.|$|E
2500|$|Suppose that a {{test for}} using a {{particular}} drug is 99% sensitive and 99% specific. That is, the test will produce 99% true positive results for drug users and 99% <b>true</b> <b>negative</b> results for non-drug users. Suppose that 0.5% of people are users of the drug. What is {{the probability that a}} randomly selected individual with a positive test is a user? ...|$|E
5000|$|... where , , [...] and [...] are {{the number}} of <b>true</b> positives, false <b>negatives,</b> false positives and <b>true</b> <b>negatives</b> respectively.|$|R
2500|$|Negative posttest {{probability}} = False negatives / (False <b>negatives</b> + <b>True</b> <b>negatives)</b> ...|$|R
50|$|In {{information}} retrieval, {{the positive}} predictive value is called precision, and sensitivity is called recall. Unlike the Specificity vs Sensitivity tradeoff, these measures are both independent {{of the number of}} <b>true</b> <b>negatives,</b> which is generally unknown and much larger than the actual numbers of relevant and retrieved documents. This assumption of very large numbers of <b>true</b> <b>negatives</b> versus positives is rare in other applications.|$|R
50|$|Recall in {{this context}} is also {{referred}} to as the true positive rate or sensitivity, and precision is also referred to as positive predictive value (PPV); other related measures used in classification include <b>true</b> <b>negative</b> rate and accuracy. <b>True</b> <b>negative</b> rate is also called specificity.|$|E
50|$|Specificity (SPC) or <b>True</b> <b>Negative</b> Rate (TNR) is the {{proportion}} of people that tested negative and are negative (<b>True</b> <b>Negative,</b> TN) {{of all the people}} that actually are negative (Condition Negative, CN = TN + FP). As with sensitivity, it can be looked at as the probability that the test result is negative given that the patient is not sick. With higher specificity, fewer healthy people are labeled as sick (or, in the factory case, fewer good products are discarded).|$|E
50|$|Various kits have a 93-95% {{sensitivity}} (true positive rate). For hospitalized patients, {{one study}} found the specificity to be about 50% (<b>true</b> <b>negative</b> rate) in the diagnosis of thrombotic disease.|$|E
5000|$|... where FP is {{the number}} of false positives, TN {{is the number}} of <b>true</b> <b>negatives</b> and N=FP+TN is the total number of negatives.|$|R
40|$|After the {{publication}} of 1, we were alerted to an error in our data. The error was an one-off miscalculation in the extraction of position information for our set of <b>true</b> <b>negatives.</b> Our data set should have used randomly selected non-edited cytosines (C) as <b>true</b> <b>negatives,</b> but the data generation phase resulted {{in a set of}} nucleotides that were each one nucleotide downstream of known, unedited cytosines. The consequences of this error are reflected in changes to our results, although the general conclusions presented in our original publication remain largely unchanged. </p...|$|R
3000|$|False {{positive}} rate {{is given}} {{by the total number}} of false positives over the total number of <b>true</b> <b>negatives</b> and false positives. It can be expressed mathematically as [...]...|$|R
50|$|Specificity (also {{called the}} <b>true</b> <b>negative</b> rate) {{measures}} {{the proportion of}} negatives that are correctly identified as such (i.e., the percentage of healthy people who are correctly identified as not having the condition).|$|E
50|$|In {{addition}} to overall accuracy, investigators frequently report {{sensitivity and specificity}} (True Positive Rate: TPR and <b>True</b> <b>Negative</b> Rate: TNR, respectively) meaning True Positive Rate (TPR) and <b>True</b> <b>Negative</b> Rate (TNR) respectively. Similarly, investigators sometimes report the False Positive Rate (FPR) {{as well as the}} False Negative Rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The Total Operating Characteristic (TOC) is an effective method to express a model’s diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used Receiver operating characteristic (ROC) and ROC’s associated Area Under the Curve (AUC).|$|E
50|$|Suppose {{that when}} the {{screening}} test is applied to a person not having the disease, there is a 1% chance of getting a false positive result (and hence 99% chance of getting a <b>true</b> <b>negative</b> result), i.e.|$|E
30|$|There were 83 true positives (TP), 44 false positives (FP), 9 false negatives (FN) and 528 <b>true</b> <b>negatives</b> (TN) when {{considering}} the sample of 664 mammographies in the categories 0, 4 and 5.|$|R
30|$|This article, is {{concerned}} about choosing an appropriate significance threshold after we have ordered the hypotheses based on their p-values without knowing or estimating {{the total number of}} true positives or total number of <b>true</b> <b>negatives.</b>|$|R
30|$|As Barsim (Barsim & Yang, 2018) points out, the F 1 -score {{does not}} account for the <b>true</b> <b>negatives</b> and they propose to use Matthews Correlation Coefficient (MCC). An energy-based pendant of MCC can be derived analogously.|$|R
5000|$|... (While this {{is often}} {{described}} as [...] "negative feedback", as it reduces gain, raises input impedance, and reduces distortion, it predates the invention of negative feedback and does not reduce output impedance or increase bandwidth, as <b>true</b> <b>negative</b> feedback would do.) ...|$|E
5000|$|As Ada {{supports}} <b>true</b> <b>negative</b> indices as in [...] {{it places}} no special meaning on negative indices. In the example above the term [...] would slice the [...] from 31 BC to 30 AD (since {{there was no}} year zero, the year number 0 actually refers to 1 BC).|$|E
5000|$|Suppose a {{drug test}} is 99% {{sensitive}} and 99% specific. That is, the test will produce 99% true positive results for drug users and 99% <b>true</b> <b>negative</b> results for non-drug users. Suppose that 0.5% of people are users of the drug. What is {{the probability that a}} randomly selected individual with a positive test is a user? ...|$|E
40|$|False negatives are {{recorded}} in every chemical detection system, but when animals {{are used as}} a scent detector, some false negatives can arise {{as a result of}} a failure in the link between detection and the trained alert response, or a failure of the handler to identify the positive alert. A false negative response can be critical in certain scenarios, such as searching for a live person or detecting explosives. In this study, we investigated whether the nature of sniffing behavior in trained detection dogs during a controlled scent-detection task differs in response to <b>true</b> positives, <b>true</b> <b>negatives,</b> false positives, and false negatives. A total of 200 videos of 10 working detection dogs were pseudorandomly selected and analyzed frame by frame to quantify sniffing duration and the number of sniffing episodes recorded in a Go/No-Go single scent-detection task using an eight-choice test apparatus. We found that the sniffing duration of <b>true</b> <b>negatives</b> is significantly shorter than false <b>negatives,</b> <b>true</b> positives, and false positives. Furthermore, dogs only ever performed one sniffing episode towards <b>true</b> <b>negatives,</b> but two sniffing episodes commonly occurred in the other situations. These results demonstrate how the nature of sniffing can be used to more effectively assess odor detection by dogs used as biological detection devices...|$|R
3000|$|... where true positives (σ) are the {{correctly}} classified positive cases, <b>true</b> <b>negatives</b> (η) are the correctly classified negative cases, false positives (Ψ) are the incorrectly classified positive cases, {{and false}} negatives (Φ) are the incorrectly classified negative cases.|$|R
40|$|Adults read a prose {{passage and}} responded to {{questions}} based on it which were either true or false and were phrased either affirmatively or negatively. <b>True</b> <b>negatives</b> yielded most errors, fol-lowed in order by false <b>negatives,</b> <b>true</b> affirmatives, and false affirma-tives. The discrepancy from the ordering Wason (1961) found for binary propositions and the implications for construction of true-false examinations are discussed. EDUCATIONAL AND PSYCHOLOGICAL MEASUREMEN...|$|R
50|$|In {{diagnostic}} testing, {{the main}} ratios used {{are the true}} column ratios - True Positive Rate and <b>True</b> <b>Negative</b> Rate - where they are known as sensitivity and specificity. In informational retrieval, the main ratios are the true positive ratios (row and column) - Positive Predictive Value and True Positive Rate - where they are known as precision and recall.|$|E
50|$|The column ratios are True Positive Rate (TPR, aka Sensitivity or recall), with {{complement}} the False Negative Rate (FNR); and <b>True</b> <b>Negative</b> Rate (TNR, aka Specificity, SPC), with complement False Positive Rate (FPR). These are {{the proportion of}} the population with the condition (resp., without the condition) for which the test is correct (or, complementarily, for which the test is incorrect); these are independent of prevalence.|$|E
50|$|If {{the array}} {{abstraction}} {{does not support}} <b>true</b> <b>negative</b> indices (as for example the arrays of Ada and Pascal do), then negative indices for the bounds of the slice for a given dimension are sometimes used to specify an offset {{from the end of}} the array in that dimension. In 1-based schemes, -1 generally would indicate the second-to-last item, while in a 0-based system, it would mean the very last item.|$|E
50|$|The F-score is {{also used}} in machine learning. Note, however, that the F-{{measures}} do not take the <b>true</b> <b>negatives</b> into account, and that measures such as the Matthews correlation coefficient, Informedness or Cohen's kappa may be preferable to assess {{the performance of a}} binary classifier.|$|R
30|$|The {{use of the}} {{concepts}} {{of positive and negative}} are common in the medical and data science literature, for instance, Provost and Fawcett (2013, chap. 7). Sensitivity of a test to recognize true positives (TP/(all positives)). Specificity is the capacity to recognize <b>true</b> <b>negatives</b> (TN/(all negatives)).|$|R
30|$|If, {{as often}} happens when the gold {{standard}} test is surgical, {{a significant proportion of}} patients do not have a laparoscopy to confirm {{the presence or absence of}} endometriosis, the <b>true</b> <b>negatives</b> in the MRI, TVS and TRS will be overestimated and the false negatives will be underestimated.|$|R
50|$|Note, however, {{that the}} F-scores {{do not take}} the <b>true</b> <b>negative</b> rate into account, and that {{measures}} such as the Phi coefficient, Matthews correlation coefficient, Informedness or Cohen's kappa may be preferable to assess {{the performance of a}} binary classifier. As a correlation coefficient, the Matthews correlation coefficient is the geometric mean of the regression coefficients of the problem and its dual. The component regression coefficients of the Matthews correlation coefficient are markedness (deltap) and informedness (deltap').|$|E
5000|$|... {{all types}} of medical test results can be true {{positive}} or false positive and <b>true</b> <b>negative</b> or false negative...these categories are hugely dependent on the prevalence of the disease being tested for; and, for example, a false positive test result is more likely when the prevalence of the disease being tested for is very low (such as a lab test for cold-weather influenza being done in June in South Carolina, USA. and giving a [...] "positive" [...] result).|$|E
50|$|The {{positive}} and negative predictive values (PPV and NPV respectively) are the proportions of {{positive and}} negative results in statistics and diagnostic tests that are true positive and <b>true</b> <b>negative</b> results, respectively. The PPV and NPV describe the performance of a diagnostic test or other statistical measure. A high result can be interpreted as indicating the accuracy of such a statistic. The PPV and NPV are not intrinsic to the test; they depend also on the prevalence. The PPV can be derived using Bayes' theorem.|$|E
30|$|In {{order to}} assess the {{performance}} of the two models we randomly split the training sample in two different sub-samples: the first one (90 % of the observations) is used to estimate the models using boosting, the second one (10 % of the observations) is used for the out-of-sample assessment of the classification performance. We repeat the operation 1000 times (drawing different sub-samples) and we evaluate the performance based on average results. Since the number of <b>true</b> <b>negatives</b> (ads that are not duplicates and are identified as such) is much larger than the number of true positives, using the classic accuracy rate can be misleading. For this reason we consider measures of classification performance that do not rely on the number of <b>true</b> <b>negatives,</b> namely: precision, recall and F-measure.|$|R
30|$|Ultrasound {{findings}} on all lung fields were tabulated as {{positive or negative}} for PTXs and compared to the subsequent upright CXR report as the reference standard. Dichotomous {{data were analyzed using}} Stata version 12.0 (Stata Corp., College Station, TX, USA) by calculating rates of <b>true</b> positives, <b>true</b> <b>negatives,</b> sensitivity, and specificity.|$|R
30|$|Truth {{was derived}} from tissue {{sampling}} and histopathology reports for cases with positive assessments on MRI and/or CESM. Tissue sampling should be completed in maximum 4  weeks after the last study imaging procedure. Cases with negative assessments (BI-RADS ≤  2) on both MRI and CESM were considered as <b>true</b> <b>negatives</b> and needn’t require histopathology.|$|R
