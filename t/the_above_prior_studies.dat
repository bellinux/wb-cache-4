0|10000|Public
40|$|We {{investigate}} experimentally how children’s increasingly flexible use {{of reference}} frames enables accurate search for hidden objects. Children watch {{as an object}} is rolled down a ramp, behind a panel of doors, and stops at a barrier visible <b>above</b> <b>the</b> doors. <b>Prior</b> <b>studies</b> have found that 3 -year-olds can accurately retrieve the object but that 2 -year-olds fail to do so. We gave 2 - and 2. 5 -year-olds a strong reference frame by increasing the relative salience and stability of the barrier. We found that 2. 5 -year-olds could successfully locate the hidden object. This work {{highlights the importance of}} the task structure in creating performance differences during transitional phases in cognitive development...|$|R
40|$|The {{purpose of}} this study is (1) to {{investigate}} the current body of knowledge encompassing two related topics: (a) to what extent can we reliably predict the change in people's attitudes in response to an abrupt change in noise exposure, and (b) after the change, is there a decay in the abrupt-change effect whereby people's attitudes slowly shift from their initial reaction to a steady-state value? and (2) to provide recommendations for any future work that may be needed. The literature search located 23 studies relating to one or both of <b>the</b> <b>above</b> topics. These <b>prior</b> <b>studies</b> shed considerable light on the current ability to predict initial reaction and decay effects. The literature makes one point very clear: Great care in both experimental design and data analysis is necessary to produce credible, convincing findings, both in the reanalysis of existing data and for planning future data acquisition and analysis studies. New airport studies must be designed to minimize nuisance variables and avoid past design features that may have introduced sufficient unexplained variance to mask sought after effects. Additionally, the study must be designed to tie in with previous investigations by incorporating similar survey questions and techniques...|$|R
5000|$|Using <b>the</b> <b>above</b> <b>prior</b> and likelihood, <b>the</b> {{posterior}} distribution {{can be expressed}} as: ...|$|R
50|$|To {{show that}} <b>the</b> <b>above</b> <b>prior</b> {{distribution}} is a conjugate prior, we can derive the posterior.|$|R
5000|$|Note that <b>the</b> <b>above</b> {{analysis}} requires <b>prior</b> {{knowledge of}} [...] and [...]|$|R
30|$|To {{the best}} of our knowledge, no {{previous}} work has been presented concerning the degree to which changes in topology data due to cyber attacks influence LMP calculation in real-time power markets. In particular, as the physical and economic risks from topology data attacks become increasingly threatening as mentioned in <b>the</b> <b>above</b> <b>prior</b> work, an analysis tool is required for system operators to accurately and quickly evaluate such risks from a cybersecurity perspective. We aim to develop a framework that is a computationally efficient closed-form application, with which system operators can rapidly predict and quantify the impact of topology data attack on LMP.|$|R
30|$|To {{check for}} a {{possible}} effect of a particle size on the magnitude of coal softening, the work was also performed with a finer coal powder (− 200 mesh) prepared by using the same procedure as <b>the</b> <b>above.</b> <b>Prior</b> to sieving, <b>the</b> samples were further ground with agate mortar and pestle and thoroughly homogenized; > 95 % of the finer powder was re-claimed. In the control measurements, we used a higher-precision pressure-relief valve, for better pressure stability during the heating. A reproducibility check was also performed using − 20  + 45 -mesh (U.S. Sieve Series) samples of the same Argonne Premium Pocahontas No. 3 Coal.|$|R
40|$|In {{this paper}} {{distinct}} prior distributions are derived in a Bayesian inference of the two-parameters Gamma distribution. Noniformative priors, such as Jeffreys, reference, MDIP, Tibshirani and an innovative prior {{based on the}} copula approach are investigated. We show that the maximal data information prior provides in an improper posterior density and that the different choices of the parameter of interest lead to different reference priors in this case. Based on the simulated data sets, the Bayesian estimates and credible intervals for the unknown parameters are computed {{and the performance of}} the prior distributions are evaluated. The Bayesian analysis is conducted using the Markov Chain Monte Carlo (MCMC) methods to generate samples from the posterior distributions under <b>the</b> <b>above</b> <b>priors...</b>|$|R
5000|$|Advertising Age 2006 Special Report ranks Merkle 38 in World’s Top 50 Marketing Organizations, {{moving it}} 9 {{positions}} <b>above</b> <b>the</b> <b>prior</b> year's position.|$|R
40|$|In this paper, the two-parameter Marshall-Olkin Extended Weibull (MOEW) {{model is}} {{considered}} to analyze the software reliability data. The Markov Chain Monte Carlo (MCMC) method is used to compute the Bayes estimates of the model parameters. In this paper, {{it is assumed that}} the parameters have non-informative set of priors and they are independently distributed. Under <b>the</b> <b>above</b> <b>priors,</b> we use Gibbs algorithm in OpenBUGS to generate MCMC samples from the posterior density function. Based on the generated samples, we can compute the Bayes estimates of the unknown parameters and also can construct highest posterior density credible intervals. We also compute the maximum likelihood estimate and associated confidence intervals to compare the performances of the Bayes estimators with the classical estimators. One data analysis is performed for illustrative purposes...|$|R
5000|$|The {{budget for}} 2009-10 was $49.9 million. [...] The {{increase}} {{in fiscal year}} 2009 was a voter approved 9.9% <b>above</b> <b>the</b> <b>prior</b> year. The percentage increase was <b>above</b> <b>the</b> state average. This amount was exceeded by $750,000.|$|R
40|$|By {{noting that}} a Rasch or two {{parameter}} logistic (2 PL) item {{belongs to the}} exponential family of random variables and that the probability density function (pdf) of the correct response (X= 1) and the incorrect response (X= 0) are symmetric {{with respect to the}} vertical line at the item location, it is shown that the conjugate prior for ability is proportional to [I(theta)) superscript alpha where I(theta) is the item information and alpha is a positive constant. When <b>the</b> <b>above</b> <b>prior</b> is applied to a three parameter logistic (3 PL) item, the requirement that item selection rules are bound to the traditional formula for correction for random guessing implies that the constant alpha must be 1. Thus, maximum information selection rules for 3 PL items are the only rules that are consistent with a Bayesian analysis based on the family of conjugate priors and {{with the use of the}} correction-for-guessing formula. (Contains 16 references.) (Author/SLD) Reproductions supplied by EDRS are the best that can be made from the original document...|$|R
40|$|In [2] two {{carrier phase}} based models for {{integrity}} monitoring are developed, called there the j-step {{model and the}} prior information model. The former uses single dierence measurements of several consecutive epochs, while the latter combines the single dierence measurements of the current epoch and estimates of integer ambiguities and their error covariances of the previous epoch obtained from the positioning algorithm of van Graas and Lee [16]. This paper presents ecient and numerically reliable integrity methods and simulation results based on <b>the</b> <b>above</b> two models and a third model presented in [10], {{which is the same}} as <b>the</b> <b>above</b> <b>prior</b> information model but double dierence measurements are used. The maximum residual test statistics are used in all these methods. Our simulation results show that for ramp error rates not smaller than 0 : 1 m=s, all three methods perform very well for fault detection and identication, and for a small ramp rate such as 0 : 01 m=s, both single and double dierence prior information methods gives less missed detection rates than the j-step method. Our simulations also show the prior information methods give (much) smaller horizontal protection levels than the j-step method. These methods can also detect single or multiple cycle slips and identify a single cycle slip. ...|$|R
40|$|Abstract. In our {{previous}} study, task segmentation {{was done by}} mnSOM, using prior information that winner modules corresponding to subsequences {{in the same class}} share the same label. Since this prior informatiom is not available in real situation, segmenta-tion thus obtained should be regarded as the upper bound for the performance, not as a candidate for performance comparison. Present paper proposes to do task segmentation by applying various clustering methods to the resulting mnSOM, without using <b>the</b> <b>above</b> <b>prior</b> information. Firstly, we use the conventional hierarchical clustering. It assumes that the distances between any pair of modules are provided with precision, {{but this is not the}} case in mnSOM. Secondly, we used a clustering method based on only the distance between spatially adjacent modules with modification by their temporal contiguity. In the robotic field 1, the segmentation performance by the hierarchical clustering is very close to the upper bound for novel data. In the robotic field 2, the segmentation performance by clustering with the spatio-temporal contiguity is very close to the upper bound for novel data. Therefore, the proposed methods demonstrated their effectiveness in segmentation...|$|R
40|$|In our {{previous}} study, task segmentation {{was done by}} mnSOM, using prior information that winner modules corresponding to subsequences {{in the same class}} share the same label. Since this prior informatiom is not available in real situation, segmentation thus obtained should be regarded as the upper bound for the performance, not as a candidate for performance comparison. Present paper proposes to do task segmentation by applying various clustering methods to the resulting mnSOM, without using <b>the</b> <b>above</b> <b>prior</b> information. Firstly, we use the conventional hierarchical clustering. It assumes that the distances between any pair of modules are provided with precision, {{but this is not the}} case in mnSOM. Secondly, we used a clustering method based on only the distance between spatially adjacent modules with modification by their temporal contiguity. In the robotic field 1, the segmentation performance by the hierarchical clustering is very close to the upper bound for novel data. In the robotic field 2, the segmentation performance by clustering with the spatio-temporal contiguity is very close to the upper bound for novel data. Therefore, the proposed methods demonstrated their effectiveness in segmentation. Keywords: mnSOM, Task segmentation, Clustering, Mobile robot, Temporal contiguity, Spatio-temporal contiguit...|$|R
50|$|Although {{the source}} code of older {{versions}} {{is available for}} modification, due to <b>the</b> <b>above</b> 3.6 and <b>prior</b> license restrictions, it was not open source or free software according to the OSI or the FSF definition of the term. This was a problem as source code exchange with the greater FOSS ecosystem was impossible due to License incompatibility with copyleft licenses.|$|R
40|$|When {{information}} on multiple genotypes evaluated in multiple environments is recorded, a multi-environment single trait model for assessing genotype × environment interaction (G × E) is usually employed. Comprehensive models that simultaneously {{take into account}} the correlated traits and trait × genotype × environment interaction (T × G × E) are lacking. In this research, we propose a Bayesian model for analyzing multiple traits and multiple environments for whole-genome prediction (WGP) model. For this model, we used Half-t priors on each standard deviation term and uniform priors on each correlation of the covariance matrix. These priors were not informative and led to posterior inferences that were insensitive to the choice of hyper-parameters. We also developed a computationally efficient Markov Chain Monte Carlo (MCMC) under <b>the</b> <b>above</b> <b>priors,</b> which allowed us to obtain all required full conditional distributions of the parameters leading to an exact Gibbs sampling for the posterior distribution. We used two real data sets to implement and evaluate the proposed Bayesian method and found that when the correlation between traits was high (> 0. 5), the proposed model (with unstructured variance–covariance) improved prediction accuracy compared to the model with diagonal and standard variance–covariance structures. The R-software package Bayesian Multi-Trait and Multi-Environment (BMTME) offers optimized C++ routines to efficiently perform the analyses...|$|R
40|$|In {{the field}} of state of charge (SOC) estimation, the Kalman filter has been widely used for many years, {{although}} its performance strongly depends on {{the accuracy of the}} battery model as well as the noise covariance. The Kalman gain determines the confidence coefficient of the battery model by adjusting the weight of open circuit voltage (OCV) correction, and has a strong correlation with the measurement noise covariance (R). In this paper, the online identification method is applied to acquire the real model parameters under different operation conditions. A criterion based on the OCV error is proposed to evaluate the reliability of online parameters. Besides, the equivalent circuit model produces an intrinsic model error which is dependent on the load current, and the property that a high battery current or a large current change induces a large model error can be observed. Based on <b>the</b> <b>above</b> <b>prior</b> knowledge, a fuzzy model is established to compensate the model error through updating R. Combining the positive strategy (i. e., online identification) and negative strategy (i. e., fuzzy model), a more reliable and robust SOC estimation algorithm is proposed. The experiment results verify the proposed reliability criterion and SOC estimation method under various conditions for LiFePO 4 batteries...|$|R
5000|$|As a more {{contentious}} example, Jaynes {{published an}} argument (Jaynes 1968) based on Lie groups thatsuggests that the prior representing complete uncertainty about a probability {{should be the}} Haldane prior p&minus;1(1 &minus; p)&minus;1. The example Jaynes gives is of finding a chemical in a lab and asking whether it will dissolve in water in repeated experiments. The Haldane prior gives {{by far the most}} weight to [...] and , indicating that the sample will either dissolve every time or never dissolve, with equal probability. However, if one has observed samples of the chemical to dissolve in one experiment and not to dissolve in another experiment then this prior is updated to the uniform distribution on the interval 1. This is obtained by applying Bayes' theorem to the data set consisting of one observation of dissolving and one of not dissolving, using <b>the</b> <b>above</b> <b>prior.</b> <b>The</b> Haldane prior is an improper prior distribution (meaning that it does not integrate to 1) that puts 100% of the probability content at either p = 0 or at p = 1 if a finite number of observations have given the same result. Harold Jeffreys devised a systematic way for designing uninformative proper priors for e.g., Jeffreys prior p&minus;1/2(1 &minus; p)&minus;1/2 for the Bernoulli random variable.|$|R
40|$|We study quantum key {{distribution}} with standard weak coherent states and show, rather counter-intuitively, that the detection events originated from vacua can contribute to secure key generation rate, over and <b>above</b> <b>the</b> best <b>prior</b> art result. Our proof {{is based on a}} communication complexity/quantum memory argument. ...|$|R
40|$|BACKGROUND Low {{success rates}} in the New Zealand Diploma in Engineering - Civil (NZDE) in 2011 were a cause for concern. The average success rate of the eight {{compulsory}} courses {{in the first year}} of study in the NZDE was low at 44 %. From the records of student applications, about 30 % of the domestic students had not met the entry criteria of NCEA Level 2. This study examines the performance of those students along with domestic students who met the academic entry criteria and special admission students aged 20 and <b>above</b> with <b>prior</b> <b>study</b> or relevant work experience. PURPOSE The purpose of this study is firstly to find out if the admission of students who did not meet the entry criteria significantly affected the success rate of certain courses in NZDE. Secondly, to determine if the present National Certificate of Education Achievement (NCEA) Level 2 entry requirement an adequate entry criterion for NZDE programme to produce quality graduates as Engineering Technicians. Finally, to evaluate if <b>prior</b> <b>study</b> and work experience have effect on the students’ success rate. DESIGN/METHODOLOGY Three categories of domestic students were identified and their success rates in courses through the NZDE analysed. They are: (A) students meeting entry criteria, (B) students not meeting entry criteria, and (C) special admission students aged 20 and <b>above</b> with <b>prior</b> <b>study</b> or relevant work experience. These three categories of students were analysed over three years to establish their average semester success rates and first attempt success rates for eight Year One compulsory courses RESULTS The study found that the success rate of Category A and C students consistently higher than the success rate of Category B students. Both Category A and B students showed a similar increase in success rate with time but the success rate of Category C students was hovering within a narrow range although they have the highest success rate among the three categories of students in the beginning. CONCLUSIONS The findings confirm the effect of students’ high school academic results on their first year university academic performance. However, the longitudinal study found that the students who stayed on the course continued to improve academically irrespective of their academic performances at the beginning of their study. The study also showed that <b>prior</b> <b>study</b> and work experience have a positive impact on the students’ performance in general...|$|R
5000|$|... #Caption: In <b>the</b> diagram <b>above</b> {{hyperventilation}} <b>prior</b> to <b>the</b> dive has artificially depressed CO2 levels (partial pressures) without {{elevating the}} O2 level. This pre-dive state {{is likely to}} result in shallow water blackout. The O2 level drops into the diver's blackout zone before the CO2can rise enough to force the diver to resurface to breathe. The dive length is extended but the diver may not survive.|$|R
30|$|There {{was some}} {{previous}} work that considered observer design for fractional-order nonlinear systems, for example, in [36, 43 – 49]. It {{should be pointed}} out that in <b>the</b> <b>above</b> literature <b>the</b> <b>prior</b> knowledge of the system model should be known in advance. However, in this work, compared with <b>the</b> <b>above</b> results, our method has a very high robustness, which can be seen in the following subsection (the system models suffer from time-varying parameters as well as system uncertainties).|$|R
5000|$|This {{standard}} {{provides the}} primary functionality of the VESA BIOS Extensions. It allows applications {{to determine the}} capabilities of the graphics card and provides the ability to set the display modes that are found. VBE 2.0 adds some new features <b>above</b> <b>the</b> <b>prior</b> VBE 1.2 standard including linear framebuffer access and protected mode banking. Some of the VBE Core 2.0 features include: ...|$|R
40|$|The {{progressive}} Type-II hybrid censoring scheme {{introduced by}} Kundu and Joarder (Computational Statistics and Data Analysis, 2509 - 2528, 2006), has received some {{attention in the}} last few years. One major drawback of this censoring scheme is that very few observations (even no observation at all) may be observed {{at the end of the}} experiment. To overcome this problem, Cho, Sun and Lee (Statistical Methodology, 23, 18 - 34, 2015) recently introduced generalized progressive censoring which ensures to get a pre specified number of failures. In this paper we analyze generalized progressive censored data in presence of competing risks. For brevity we have considered only two competing causes of failures, and it is assumed that the lifetime of the competing causes follow one parameter exponential distributions with different scale parameters. We obtain the maximum likelihood estimators of the unknown parameters and also provide their exact distributions. Based on the exact distributions of the maximum likelihood estimators exact confidence intervals can be obtained. Asymptotic and bootstrap confidence intervals are also provided for comparison purposes. We further consider the Bayesian analysis of the unknown parameters under a very flexible Beta-Gamma prior. We provide the Bayes estimates and the associated credible intervals of the unknown parameters based on <b>the</b> <b>above</b> <b>priors.</b> We present extensive simulation results to see the effectiveness of the proposed method and finally one real data set is analyzed for illustrative purpose...|$|R
50|$|Lewis was a keen {{supporter}} of the National Library of Wales, located in Aberystwyth. In 1909 he became a Vice President of the Library. In 1925, while walking in <b>the</b> hills <b>above</b> <b>the</b> town <b>prior</b> to {{a meeting of the}} Library's council, Lewis suffered a fall down a quarry which left him paralyzed {{for the rest of his}} life. Although elected President of the Library in 1926, this was a largely honorific appointment.|$|R
3000|$|<b>The</b> <b>above</b> {{synthesis}} of <b>prior</b> research on social influence {{benefits and costs}} highlights that sent interlocks are especially effective as means for affecting other firms as they allow contact {{with all of the}} other company’s board members and, thus, offer much room to exert influence. Regarding their costs, influence attempts of a partner firm directed at the focal firm seem to be indirect at best and, thus, are unlikely to carry much weight. Thus, we suggest: [...]...|$|R
50|$|A free {{cash flow}} of €302 million results after {{deducting}} investments in fixed assets from the net cash flow, which is €368 million <b>above</b> <b>the</b> <b>prior</b> year. Net payments amounting to €159 million {{were made in the}} current fiscal year for the acquisition of interests in affiliated companies of Luvata’s Rolled Products Division. Taking interest payments and received dividends into account, there is a cash outflow of €257 million from investing activities.|$|R
40|$|This paper investigates novel {{methods for}} {{incorporating}} syntactic information in probabilistic latent variable models of lexical choice and contextual similarity. The resulting models capture {{the effects of}} context on the interpretation of a word and in particular {{its effect on the}} appropriateness of replacing that word with a potentially related one. Evaluating our techniques on two datasets, we report performance <b>above</b> <b>the</b> <b>prior</b> state of the art for estimating sentence similarity and ranking lexical substitutes. ...|$|R
50|$|The Tumwater Falls {{created an}} impassable barrier to salmon until 1952, when a fish ladder {{was built by}} the Washington Department of Fisheries (now the Washington State Department of Fish and Wildlife), to provide salmon access to the newly {{constructed}} fish hatchery located immediately <b>above</b> <b>the</b> falls. <b>Prior</b> to the 1952 hatchery operations, <b>the</b> Deschutes river <b>above</b> <b>the</b> Tumwater Falls was a river system free {{of the influence of}} migrating and spawning salmon, an unusual ecological occurrence in the riparian systems of Puget Sound.|$|R
5000|$|The home WAP site is {{the cell}} phone {{equivalent}} of the main Primatech Paper website; however, the Careers section prompts a participant for their name and cell phone number, whereas the main website prompts for <b>the</b> code mentioned <b>above.</b> <b>Prior</b> to <b>the</b> episode on February 12, 2007 (Run!) when a user submitted their information, they would be redirected to a new WAP page which read [...] "Trying to crack into this thing. Give me about a week. I'll {{let you know what}} to do." [...] After the 19th, the site reads: [...] "Plan A has gone into effect. Let's get together to observe. Go to www.samantha48616e61.com at 9:00 PM on Monday, 2/26/07." ...|$|R
5000|$|From <b>the</b> <b>above</b> {{expressions}} {{it follows}} that for s/n = 1/2) all <b>the</b> <b>above</b> three <b>prior</b> probabilities result in the identical location for the posterior probability mean = mode = 1/2. For s/n < 1/2, {{the mean of the}} posterior probabilities, using the following priors, are such that: mean for Bayes prior > mean for Jeffreys prior > mean for Haldane prior. For s/n > 1/2 the order of these inequalities is reversed such that the Haldane prior probability results in the largest posterior mean. The Haldane prior probability Beta(0,0) results in a posterior probability density with mean (the expected value for the probability of success in the [...] "next" [...] trial) identical to the ratio s/n of the number of successes to the total number of trials. Therefore, the Haldane prior results in a posterior probability with expected value in the next trial equal to the maximum likelihood. The Bayes prior probability Beta(1,1) results in a posterior probability density with mode identical to the ratio s/n (the maximum likelihood).|$|R
40|$|The main {{objective}} {{of the current study}} is to handle the identification problem of autoregressive processes from the Bayesian point of view. Two Bayesian identification approaches are considered. They are referred to as the direct and the indirect approaches. The two approaches are employed to solve the Bayesian identification problem of autoregressive processes using three well known priors. These priors are the G prior, the Natural-Conjugate prior and Jeffrey's prior. The theoretical derivations related to the two Bayesian identification approaches are conducted using <b>the</b> <b>above</b> mentioned <b>priors.</b> Moreover, <b>the</b> performance of the two techniques, using each of the three priors, is investigated via comprehensive simulation studies. Simulation results show that the two techniques are adequate to solve the identification problem of autoregressive processes. The increase in the time series length leads to better performance for each technique. The use of different priors doesn't affect the previous results. </p...|$|R
25|$|Chernobyl thyroid cancer {{incidence}} rates did {{not begin}} to increase <b>above</b> <b>the</b> <b>prior</b> baseline value of about 0.7 cases per 100,000 people per year until 1989 to 1991, 3–5 years after the incident in both adolescent and child age groups. The rate reached its highest point so far, of about 11 cases per 100,000 in {{the decade of the}} 2000s, approximately 14 years after the accident. From 1989 to 2005, an excess of 4,000 children and adolescent cases of thyroid cancer were observed. Nine of these had died as of 2005, a 99% survival rate.|$|R
6000|$|... [779] [Byron {{loved to}} make fact and fancy walk together, but, here, his memory played him false, or his art kept him true. The Black Friar walked and {{walks in the}} Guests' Refectory (or Banqueting Hall, or [...] "Gallery" [...] of this stanza), which adjoins the Prior's Parlour, but the room where Byron slept (in a four-post bed-a coronet, at each corner, atop) is on <b>the</b> floor <b>above</b> <b>the</b> <b>Prior's</b> Parlour, and can only be {{approached}} by a spiral staircase. Both rooms look west, and command {{a view of the}} [...] "lake's billow" [...] and the [...] "cascade." [...] Moreover, the Guests' Refectory was never hung with [...] "old pictures." [...] It would seem that Don Juan (perhaps Byron on an emergency) slept in the Prior's Parlour, and that in the visionary Newstead the pictures forsook the Grand Drawing-Room for the Hall. Hence the scene! El Libertado steps out of the Gothic Chamber [...] "forth" [...] into the [...] "gallery," [...] and lo! [...] "a monk in cowl and beads." [...] But, Quien sabe? The Psalmist's caution with regard to princes is not inapplicable to poets.] ...|$|R
3000|$|For {{the basic}} {{logistic}} regression model (10), we used very flat N(0, 100) priors for the β parameters. Bayesian estimates using these priors {{are very similar}} to standard ML estimates of the same logistic regression model. 15 For the full logistic MESE model, we used the same priors on the β’s in 10, and for τ in 9 we again used an inverse-Gamma(1, 1) prior and we assume flat N(0, 100) priors on each α coefficient. In order to set the scale of θ, we mean-centered each of the covariates in (9). In line with our discussion <b>above,</b> <b>the</b> <b>prior</b> on [...]...|$|R
