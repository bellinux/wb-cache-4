1|10000|Public
5000|$|Test case: A {{test case}} {{normally}} {{consists of a}} unique identifier, requirement references from a design specification, preconditions, events, {{a series of steps}} (also known as actions) to follow, input, output, expected result, and actual result. Clinically defined, a test case is an input and an expected result. This can be as terse as 'for condition x your derived result is y', although normally test cases describe in more detail the input scenario and what results might be expected. It can occasionally be a series of steps (but often steps are contained in a separate test procedure that can be exercised against multiple test cases, as a matter of economy) but with one expected result or expected outcome. The optional fields are a <b>test</b> <b>case</b> <b>ID,</b> test step, or order of execution number, related requirement(s), depth, test category, author, and check boxes for whether the test is automatable and has been automated. Larger test cases may also contain prerequisite states or steps, and descriptions. A test case should also contain a place for the actual result. These steps can be stored in a word processor document, spreadsheet, database, or other common repository. In a database system, you may also be able to see past test results, who generated the results, and what system configuration was used to generate those results. These past results would usually be stored in a separate table.|$|E
30|$|The testing {{plan should}} define scope, testing {{procedure}} and its acceptance criteria. The process and <b>testing</b> <b>cases</b> should have personnel, {{hardware and software}} specification, test data source and schedule. Furthermore, the attributes for <b>testing</b> <b>cases</b> should have <b>id,</b> name, testing target, relevance with other functions, priority, and testing scenario, expected results. Lastly, the <b>test</b> <b>cases</b> should include integration and acceptance <b>testing</b> <b>cases.</b> The <b>testing</b> results should be noted for pass/fail/incomplete after verification and validation. It was designed to meet CMMI PI process area.|$|R
5000|$|Those who {{disagree}} with our holding will likely mark it {{as the product of}} an [...] If so, they will have erred as this is manifestly not an activist Court. Rather, this case came to us {{as the result of the}} activism of an ill-informed faction on a school board, aided by a national public interest law firm eager to find a constitutional <b>test</b> <b>case</b> on <b>ID,</b> who in combination drove the Board to adopt an imprudent and ultimately unconstitutional policy. The breathtaking inanity of the Board's decision is evident when considered against the factual backdrop which has now been fully revealed through this trial. The students, parents, and teachers of the Dover Area School District deserved better than to be dragged into this legal maelstrom, with its resulting utter waste of monetary and personal resources.|$|R
40|$|Abstract. Event logs are {{invaluable}} {{sources of}} knowledge about the actual ex-ecution of processes. A large number of techniques to mine, check conformance and analyze performance have been developed based on logs. All these tech-niques require at least <b>case</b> <b>ID,</b> activity ID and the timestamp to be in the log. If one of those is missing, these techniques cannot be applied. Real life logs are rarely originating from a centrally orchestrated process execution. Thus, <b>case</b> <b>ID</b> might be missing, known as unlabeled log. This requires a manual preprocessing of the log to assign <b>case</b> <b>ID</b> to events in the log. In this paper, we propose a new approach to deduce <b>case</b> <b>ID</b> for the unlabeled event log depending on the knowledge about the process model. We provide set of labeled logs instead of a single labeled log with different rankings. We evaluate our prototypical implementation against similar approaches...|$|R
50|$|The <b>test</b> <b>case</b> {{design and}} {{construction}} features {{can be used to}} define the overall design for each <b>test</b> <b>case.</b> Each <b>test</b> <b>case</b> includes a rich text editor with background information about the <b>test</b> <b>case.</b> A <b>test</b> <b>case</b> can include links to development items and requirements. A <b>test</b> <b>case</b> can be associated with other test artifacts, such as test plans, test scripts, and <b>test</b> <b>case</b> execution records. In additions, <b>test</b> <b>cases</b> can be combined into test suites.|$|R
30|$|AVFs select <b>test</b> <b>cases</b> {{using this}} {{software}} relation information. Specifically, AVFs select corresponding function group <b>test</b> <b>cases,</b> corresponding software group <b>test</b> <b>cases,</b> and corresponding software <b>test</b> <b>cases</b> respectively for each installed software.|$|R
40|$|Given some <b>test</b> <b>case,</b> {{a program}} fails. Which {{circumstances}} of the <b>test</b> <b>case</b> {{are responsible for the}} particular failure? The Delta Debugging algorithm generalizes and simplifies some failing <b>test</b> <b>case</b> to a minimal <b>test</b> <b>case</b> that still produces the failure; it also isolates the difference between a passing and a failing <b>test</b> <b>case...</b>|$|R
40|$|Abstract: Generally, <b>test</b> <b>cases</b> {{derived from}} a formal model can not be {{directly}} fed into implementations under test (IUT), because model based test generation techniques produce abstract <b>test</b> <b>cases.</b> In order to run an abstract <b>test</b> <b>case</b> against an IUT the ab-stract <b>test</b> <b>case</b> either has to be transformed to a concrete <b>test</b> <b>case</b> or an execution of the abstract <b>test</b> <b>case</b> is needed. In this {{paper we propose a}} rule based test execution frame-work, which allows the execution of abstract <b>test</b> <b>cases.</b> Furthermore, we present first results from testing a so called SIP Registrar by executing abstract <b>test</b> <b>cases</b> derived with the TGV tool from a formal specification. ...|$|R
30|$|In the results, 15 <b>test</b> <b>cases</b> were {{executed}} for each user virtual machine, and total of 180 <b>test</b> <b>cases</b> {{were executed}} automatically. Only 25 <b>test</b> <b>cases</b> were prepared by service providers, but our proposed idea of software group and function group abstraction {{was able to}} effectively select <b>test</b> <b>cases</b> based on user environments. Although, automatic <b>test</b> <b>cases</b> preparations of Jenkins took about three {{times the amount of}} work of normal manual <b>test</b> <b>cases</b> executions [2], but it was more effective than executing each user and each software <b>test</b> <b>case</b> manually.|$|R
40|$|How to {{effectively}} generate <b>test</b> <b>cases</b> {{is the key}} to software testing. In our previous research, we applied the program dynamic invariant as feedback to guide <b>test</b> <b>case</b> generation, and that can reduce the redundancy and improve the coverage effectively. However, the repeated extraction of program dynamic invariants significantly increased the burden of <b>test</b> <b>case</b> generation. To address this issue, we present a novel technique that automatically converts program dynamic invariant into assertion and then make use of the assertion to direct the process of <b>test</b> <b>case</b> generation. If the new <b>test</b> <b>case</b> does not violate the assertion (that means the new <b>test</b> <b>case</b> will change the program invariant), then the new case is a valid <b>test</b> <b>case,</b> otherwise it is a redundant invalid <b>test</b> <b>case.</b> This method can avoid the repetition of extracting the same program invariant. Our experimental results indicate that, while not reducing the quality of the generated <b>test</b> <b>cases,</b> the assertion-directed method can greatly reduce the time cost of <b>test</b> <b>case</b> generation. © 2012 IEEE. Wuhan University of TechnologyHow {{to effectively}} generate <b>test</b> <b>cases</b> {{is the key to}} software testing. In our previous research, we applied the program dynamic invariant as feedback to guide <b>test</b> <b>case</b> generation, and that can reduce the redundancy and improve the coverage effectively. However, the repeated extraction of program dynamic invariants significantly increased the burden of <b>test</b> <b>case</b> generation. To address this issue, we present a novel technique that automatically converts program dynamic invariant into assertion and then make use of the assertion to direct the process of <b>test</b> <b>case</b> generation. If the new <b>test</b> <b>case</b> does not violate the assertion (that means the new <b>test</b> <b>case</b> will change the program invariant), then the new case is a valid <b>test</b> <b>case,</b> otherwise it is a redundant invalid <b>test</b> <b>case.</b> This method can avoid the repetition of extracting the same program invariant. Our experimental results indicate that, while not reducing the quality of the generated <b>test</b> <b>cases,</b> the assertion-directed method can greatly reduce the time cost of <b>test</b> <b>case</b> generation. © 2012 IEEE...|$|R
40|$|Abstract—Generation and {{prioritization}} of <b>test</b> <b>cases</b> {{is one of}} {{the major}} issue in software testing. Maximum number of faults are identified through <b>test</b> <b>cases</b> only. Clients confidence can be gained through software testing. This paper firstly generates <b>test</b> <b>cases</b> using decision coverage metrics which gave redundant set of set cases. So, in in order to generate optimized set of <b>test</b> <b>cases,</b> genetic algorithm is used so that we can generate maximum number of faults with the minimum number of <b>test</b> <b>cases.</b> After generating the optimized set of <b>test</b> <b>cases</b> we proposed a technique to prioritize those <b>test</b> <b>cases</b> to indicate the order with which <b>test</b> <b>case</b> may be addressed which is known as prioritization of <b>test</b> <b>cases</b> using proposed algorithm which gave results in less time by consuming less resources...|$|R
40|$|In the {{research}} on automatic generation of <b>testing</b> <b>cases,</b> there are different execution paths under drivers of different <b>testing</b> <b>cases.</b> The probability of these paths being executed is also different. For paths which are easy to be executed, more redundant <b>testing</b> <b>case</b> tend to be generated; But only fewer <b>testing</b> <b>cases</b> are generated for the control paths which are hard to be executed. Genetic algorithm {{can be used to}} instruct the automatic generation of <b>testing</b> <b>cases.</b> For the former paths, it can restrict the generation of these kinds of <b>testing</b> <b>cases.</b> On the contrary, the algorithm will encourage the generation of such <b>testing</b> <b>cases</b> as much as possible. So based on the study on the technology of path-oriented <b>testing</b> <b>case</b> automatic generation, the genetic algorithm is adopted to construct the process of automatic generation. According to the triggering path during the dynamic execution of program, the generated <b>testing</b> <b>cases</b> are separated into different equivalence class. The number of <b>testing</b> <b>case</b> is adjusted dynamicly by the fitness corresponding to the paths. The method can create a certain number of <b>testing</b> <b>cases</b> for each execution path to ensure the sufficiency. It also reduces redundant <b>testing</b> <b>cases</b> so it is an effective method for automatic generation of <b>testing</b> <b>cases...</b>|$|R
50|$|Prioritize the <b>test</b> <b>cases</b> {{so as to}} {{increase}} a test suite's rate of fault detection. Test case prioritization techniques schedule <b>test</b> <b>cases</b> so that the <b>test</b> <b>cases</b> that are higher in priority are executed before the <b>test</b> <b>cases</b> that have a lesser priority.|$|R
40|$|One of the {{important}} tasks during software testing is the generation of <b>test</b> <b>cases.</b> Unfortunately, existing approaches to <b>test</b> <b>case</b> generation often have problems limiting their use. A problem of dynamic <b>test</b> <b>case</b> generation approaches, for instance, is {{that a large number}} of iterations can be necessary to obtain <b>test</b> <b>cases.</b> This article introduces a formal framework for the application of the well-known search strategy of binary search in path-oriented <b>test</b> <b>case</b> generation and explains the binary search-based <b>test</b> <b>case</b> generation (BINTEST) algorithm...|$|R
50|$|Search-based {{software}} engineering {{has been applied}} to software testing, including automatic generation of <b>test</b> <b>cases</b> (<b>test</b> data), <b>test</b> <b>case</b> minimization and <b>test</b> <b>case</b> prioritization. Regression <b>testing</b> has also received some attention.|$|R
30|$|We use an {{existing}} tool, Jenkins, to execute <b>test</b> <b>cases</b> {{selected from the}} <b>test</b> <b>case</b> DB. Jenkins is installed on a server in which AVFs also work. The AVFs request Jenkins to execute extracted <b>test</b> <b>cases,</b> and then Jenkins executes <b>test</b> <b>cases</b> and gathers results.|$|R
30|$|Regression testing {{prioritization}} - <b>test</b> <b>case</b> prioritization techniques execute after a set {{of changes}} in the SUT. Therefore, <b>test</b> <b>case</b> prioritization can use information gathered in previous runs of existing <b>test</b> <b>cases</b> to help the action of prioritize the <b>test</b> <b>cases</b> for subsequent runs.|$|R
30|$|Service {{providers}} prepare {{these data}} and <b>test</b> <b>cases</b> in the <b>test</b> <b>case</b> DB before patch verifications. Next, we explain {{the procedure for}} selecting <b>test</b> <b>cases</b> for each user environment using software relation data and <b>test</b> <b>case</b> attribute data when a new patch is released.|$|R
40|$|Metamorphic Testing (MT) aims to {{alleviate}} the oracle problem. In MT, testers define metamorphic relations (MRs) which are used to generate new <b>test</b> <b>cases</b> (referred to as follow-up <b>test</b> <b>cases)</b> from the available <b>test</b> <b>cases</b> (referred to as source <b>test</b> <b>cases).</b> Both source and follow-up <b>test</b> <b>cases</b> are executed and their outputs are verified against the relevant MRs, of which any violation implies that the software under test is faulty. So far, the research {{on the effectiveness of}} MT has been focused on the selection of better MRs (that is, MRs that {{are more likely to be}} violated). In addition to MR selection, the source and follow-up <b>test</b> <b>cases</b> may also affect the effectiveness of MT. Since follow-up <b>test</b> <b>cases</b> are defined by the source <b>test</b> <b>cases</b> and MRs, selection of source <b>test</b> <b>cases</b> will then affect the effectiveness of MT. However, in existing MT studies, random testing is commonly adopted as the <b>test</b> <b>case</b> selection strategy for source <b>test</b> <b>cases.</b> This study aims to investigate the impact of source <b>test</b> <b>cases</b> on the effectiveness of MT. Since Adaptive Random Testing (ART) has been developed as an enhancement to Random Testing (RT), this study will focus on comparing the performance of RT and ART as source <b>test</b> <b>case</b> selection strategies on the effectiveness of MT. Experiment results show that ART outperforms RT on enhancing the effectiveness of MT...|$|R
40|$|Software {{testing is}} a process of ratifying the {{functionality}} of software. It is one of the crucial area which consumes more time and high cost. The time spent on testing is mainly concerned with testing large number of <b>test</b> <b>cases,</b> which are unreliable. Our goal is {{to reduce the number of}} <b>test</b> <b>cases</b> and to give reliable <b>test</b> <b>cases.</b> To extract reliable <b>test</b> <b>cases</b> from large number of <b>test</b> <b>cases,</b> clustering algorithm is used which is a data mining approach to reduce the number of <b>test</b> <b>cases...</b>|$|R
40|$|This paper {{proposed}} an improved algorithm to automatically generate <b>test</b> <b>cases</b> directly from UML activity diagram using an activity graph. This algorithm has been implemented as a prototype using UML activity diagrams as inputs to generate <b>test</b> <b>cases.</b> These generated <b>test</b> <b>cases</b> are generated automatically are compared to <b>test</b> <b>cases</b> that are generated manually {{in order to}} evaluate the algorithm’s usability and reliability. The result shows that the <b>test</b> <b>cases</b> generated by the developed <b>test</b> <b>case</b> generator program {{are the same as}} the one manually derived...|$|R
40|$|This paper {{presents}} automatic <b>test</b> <b>case</b> generation technique. Multi population {{genetic algorithm}} {{is used to}} generate <b>test</b> <b>cases.</b> Fitness function {{is based on the}} multiple condition decision coverage criteria. MATLAB Gatool is used for implementing the <b>test</b> <b>case</b> generation algorithm. It generates efficient and effective <b>test</b> <b>cases.</b> Test cases are optimized using multi population genetic algorithm. MCDC coverage is used as coverage criteria. Automatic <b>test</b> <b>cases</b> generation reduce the testing effort, time and cost...|$|R
40|$|The {{techniques}} of <b>test</b> <b>case</b> prioritization schedule the execution order of <b>test</b> <b>cases</b> to attain re-spective target, such as enhanced level of forecasting the fault. The {{requirement of the}} prioritiza-tion {{can be viewed as}} the en-route for deriving an order of relation on a given set of <b>test</b> <b>cases</b> which results from regression testing. Alteration of programs between the versions can cause more <b>test</b> <b>cases</b> which may respond differently to following versions of software. In this, a fixed approach to prioritizing <b>test</b> <b>cases</b> avoids the preceding drawbacks. The JUnit <b>test</b> <b>case</b> prioritiza-tion techniques operating in the absence of coverage information, differs from existing dynamic coverage-based <b>test</b> <b>case</b> prioritization techniques. Further, the prioritization <b>test</b> <b>cases</b> relying on coverage information were projected from fixed structures relatively other than gathered instru-mentation and execution...|$|R
40|$|Many {{different}} {{techniques have}} been proposed {{to address the problem}} of automated <b>test</b> <b>case</b> generation, varying in a range of properties and resulting in very different <b>test</b> <b>cases.</b> In this paper we investigate the effects of the <b>test</b> <b>case</b> length on resulting test suites: Intuitively, longer <b>test</b> <b>cases</b> should serve to find more difficult faults but will reduce the number of <b>test</b> <b>cases</b> necessary to achieve the test objectives. On the other hand longer <b>test</b> <b>cases</b> have disadvantages such as higher computational costs and they are more difficult to interpret manually. Consequently, should one aim to generate many short <b>test</b> <b>cases</b> or fewer but longer <b>test</b> <b>cases?</b> We present the results of a set of experiments performed in a scenario of specification based testing for reactive systems. As expected, a long <b>test</b> <b>case</b> can achieve higher coverage and fault detecting capability than a short one, while giving preference to longer <b>test</b> <b>cases</b> in general can help reduce the size of test suites but can also have the opposite effect, for example, if minimization is applied. 1...|$|R
40|$|Unit {{testing of}} {{software}} requires {{the construction of}} large amounts of supporting software. Test drivers and stubs are needed to isolate the unit under test from other units, and <b>test</b> <b>cases</b> specifications need to be translated into compilable code. Constructing test software is as time-consuming and as fault-prone as any other software, and sometimes more so. To support testers there are tools that can automatically generate test code from <b>test</b> <b>case</b> specifications {{that are similar to}} the <b>test</b> <b>case</b> specification. These tools include a <b>test</b> <b>case</b> definition language, in which the <b>test</b> <b>cases</b> are stated, and a test script generator, that generates compilable code from the <b>test</b> <b>case</b> de nitions. Even so, testers often have to resort to writing source code for <b>test</b> <b>cases</b> requiring features unavailable in the <b>test</b> <b>case</b> definition language. To learn more about how a better <b>test</b> <b>case</b> definition language could be constructed, we have designed and implemented a test script generator and a <b>test</b> <b>case</b> definition language. This paper gives an overview of some of our experiences and some of our ideas for future work...|$|R
40|$|Test suite {{augmentation}} {{techniques are}} used in regression testing to identify code elements affected by changes and to generate <b>test</b> <b>cases</b> to cover those elements. Our preliminary work suggests that several factors influence the cost and effectiveness of test suite augmentation techniques. These include {{the order in which}} affected elements are considered while generating <b>test</b> <b>cases,</b> the manner in which existing regression <b>test</b> <b>cases</b> and newly generated <b>test</b> <b>cases</b> are used, and the algorithm used to generate <b>test</b> <b>cases.</b> In this work, we present the results of an empirical study examining these factors, considering two <b>test</b> <b>case</b> generation algorithms (concolic and genetic). The results of our experiment show that the primary factor affecting augmentation is the <b>test</b> <b>case</b> generation algorithm utilized; this affects both cost and effectiveness. The manner in which existing and newly generated <b>test</b> <b>cases</b> are utilized also has a substantial effect on efficiency but a lesser effect on effectiveness. The order in which affected elements are considered turns out to have relatively few effects when using concolic <b>test</b> <b>case</b> generation, but more substantial effects when using genetic <b>test</b> <b>case</b> generation...|$|R
40|$|Abstract — For <b>testing</b> software, <b>test</b> <b>case</b> {{generation}} {{is the most}} important part. The automation of specification based <b>test</b> <b>case</b> generation needs formal or semi formal specification. As a semiformal modeling, UML is widely used to describe analysis and design specification by both academia and industry. Thus UML models become the sources of <b>test</b> <b>case</b> generation naturally. This paper proposes a method to generate <b>test</b> <b>cases</b> from UML activity diagrams. We have proposed conditioned slicing as a general slicing framework for <b>test</b> <b>case</b> generation from activity diagrams. Our method first builds a flow dependence graph from an ordinary UML activity diagram and then applies conditioned slicing on a predicate node of the graph, to generate <b>test</b> <b>cases.</b> It minimizes the number of <b>test</b> <b>cases</b> generated while deriving all practically useful <b>test</b> <b>cases.</b> The effectiveness of a <b>test</b> <b>case</b> is based on how well the test covers and exercises the modeled behaviors. Our proposed method satisfies high path coverage criterion...|$|R
40|$|AbstractRegression testing {{ensures that}} changes {{made in the}} fixes or any {{enhancement}} changes do not impact the previously working functionality. Whenever software is modified, a set of <b>test</b> <b>cases</b> are run to assure that changes don’t affect {{the other parts of}} the software. Hence all existing <b>test</b> <b>cases</b> need to be tested as well as new <b>test</b> <b>cases</b> need to be created. It is nonviable to re-execute every <b>test</b> <b>case</b> for a given software, because if there are more number of <b>test</b> <b>cases</b> to be <b>tested,</b> the more effort and time is required. This problem can be solved by prioritizing <b>test</b> <b>cases.</b> Test case prioritization techniques reorder the priority of a <b>test</b> <b>case</b> in an attempt to ensure that maximum faults are uncovered by the high prioritized <b>test</b> <b>cases.</b> In this paper we propose an optimized <b>test</b> <b>case</b> prioritization technique using Ant Colony Optimization (ACO) to reduce the cost, effort and time taken to perform regression testing and also uncover maximum faults...|$|R
50|$|Effective {{layout of}} a <b>test</b> <b>case</b> ensures all {{required}} actions are completed, improves the readability of the <b>test</b> <b>case,</b> and smooths {{the flow of}} execution. Consistent structure helps in building a self-documenting <b>test</b> <b>case.</b> A commonly applied structure for <b>test</b> <b>cases</b> has (1) setup, (2) execution, (3) validation, and (4) cleanup.|$|R
40|$|Unified Modeling Language (UML) {{is widely}} applied and {{emerging}} in software testing area. One of the UML model is sequence diagram. Current researcher required {{a few of}} software in order to generate <b>test</b> <b>cases.</b> This software is {{needed in order to}} draw the sequence diagram, translate the diagram and generate the <b>test</b> <b>cases.</b> Test cases contain input and expected output of certain scenario in the system. However, the current <b>test</b> <b>case</b> generator did not provide complete <b>test</b> <b>cases</b> and only cover a few types of messages which affect the effectiveness of <b>test</b> <b>cases.</b> This research proposed a meta-model to extract information from UML sequence model and a Test Case Generator (TCG) Algorithm to generate <b>test</b> <b>cases.</b> The meta-model and algorithm can improve existing <b>test</b> <b>case</b> generator approach, which only one software is needed to use in order to translate sequence diagram. Test cases generated will then be evaluated message sequence path coverage which adequate testing criteria and thus increased the effectiveness of <b>test</b> <b>cases.</b> The findings showed that the proposed algorithm improved the effectiveness of <b>test</b> <b>cases</b> in term of message path coverage which also improved the whole <b>test</b> <b>case</b> generator approach...|$|R
3000|$|... gen {{currently}} generated new <b>test</b> <b>cases</b> {{against the}} whole history of previously generated <b>test</b> <b>cases,</b> fuzzing speed decays constantly with increasing duration of the fuzzing campaign. Therefore, we define an upper bound k_max∈N of total <b>test</b> <b>cases</b> that we keep for quality evaluation of new <b>test</b> <b>cases.</b> Small values of k [...]...|$|R
40|$|International audienceFinding {{and fixing}} bugs are {{time-consuming}} activities in software development. Spectrum-based fault localization aims {{to identify the}} faulty position in source code based on the execution trace of <b>test</b> <b>cases.</b> Failing <b>test</b> <b>cases</b> and their assertions form test oracles for the failing behavior of the system under analysis. In this paper, we propose a novel concept of spectrum driven <b>test</b> <b>case</b> purification for improving fault localization. The goal of <b>test</b> <b>case</b> purification is to separate existing <b>test</b> <b>cases</b> into small fractions (called purified <b>test</b> <b>cases)</b> and to enhance the test oracles to further localize faults. Combining with an original fault localization technique (e. g., Tarantula), <b>test</b> <b>case</b> purification results in better ranking the program statements. Our experiments on 1800 faults in six open-source Java programs show that <b>test</b> <b>case</b> purification can effectively improve existing fault localization techniques...|$|R
40|$|This paper {{presents}} {{a method to}} generate, analyse and represent <b>test</b> <b>cases</b> from protocol specification. The language of temporal ordering specification (LOTOS) is mapped into an extended finite state machine (EFSM). Test cases are generated from EFSM. The generated <b>test</b> <b>cases</b> are modelled as a dependence graph. Predicate slices are used to identify infeasible <b>test</b> <b>cases</b> that must be eliminated. Redundant assignments and predicates in all the feasible <b>test</b> <b>cases</b> are removed by reducing the <b>test</b> <b>case</b> dependence graph. The reduced <b>test</b> <b>case</b> dependence graph is adapted for a local single-layer (LS) architecture. The reduced <b>test</b> <b>cases</b> for the LS architecture are enhanced to represent the tester's behaviour. The dynamic behaviour of the <b>test</b> <b>cases</b> is represented {{in the form of}} control graphs by inverting the events, assigning verdicts to the events in the enhanced dependence graph. © 1995...|$|R
40|$|During the {{execution}} of a test plan, a test manager may decide to drop a <b>test</b> <b>case</b> if its result can be inferred from already executed <b>test</b> <b>cases.</b> We show {{that it is possible}} to automatically generate a test plan to exploit the potential to justifiably drop a <b>test</b> <b>case</b> and thus reduce the number of <b>test</b> <b>cases.</b> Our approach uses Boolean formulas to model the mutual dependencies between test results. The algorithm to generate a test plan comes with the formal guarantee of optimality with regards to the inference of the result of a <b>test</b> <b>case</b> from already executed <b>test</b> <b>cases...</b>|$|R
40|$|While {{performing}} regression testing, {{an appropriate}} choice for <b>test</b> <b>case</b> ordering allows the tester to early discover faults in source code. To this end, <b>test</b> <b>case</b> prioritization techniques can be used. Several existing <b>test</b> <b>case</b> prioritization techniques {{leave out the}} execution cost of <b>test</b> <b>cases</b> and exploit a single objective function (e. g., code or requirements coverage). In this paper, we present a multi-objective <b>test</b> <b>case</b> prioritization technique that determines the ordering of <b>test</b> <b>cases</b> that maximize the number of discovered faults that are both technical and business critical. In other words, our new technique aims at both early discovering faults and reducing the execution cost of <b>test</b> <b>cases.</b> To this end, we automatically recover links among software artifacts (i. e., requirements specifications, <b>test</b> <b>cases,</b> and source code) and apply a metric-based approach to automatically identify critical and fault-prone portions of software artifacts, thus becoming able to give them more importance during <b>test</b> <b>case</b> prioritization. We experimentally evaluated our technique on 21 Java applications. The obtained results support our hypotheses on efficiency and effectiveness of our new technique and {{on the use of}} automatic artifacts analysis and weighting in <b>test</b> <b>case</b> prioritization...|$|R
30|$|We have {{implemented}} AVFs GUI/API interfaces of verification start and <b>test</b> <b>case</b> registration. By releasing GUI to users, users can register their application-specific <b>test</b> <b>cases.</b> A user registers a <b>test</b> <b>case</b> and its attribute data to a <b>test</b> <b>case</b> DB via GUI. Registered <b>test</b> <b>cases</b> {{need to be}} invoked by Jenkins. And registered attribute data need to have information of for which tenant and for which virtual machines. For user registrations, we add two additional columns of exclusive tenant ID and virtual machine <b>ID</b> to a <b>test</b> <b>case</b> table. By setting exclusive tenant ID, registered test is only used on the specified tenant. By setting virtual machine ID, AVFs can distinguish which virtual machine in the tenant is tested by the <b>test</b> <b>case.</b>|$|R
