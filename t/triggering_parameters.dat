16|132|Public
40|$|This paper {{presents}} low velocity impact {{response of}} functionally graded pretwisted conical shells. The modi&# 64257;ed Hertzian contact law {{which accounts for}} permanent indentation is utilized to compute the contact force and other impact parameter. The time dependent equations are solved by Newmark's time integration scheme. An eight noded isoparametric quadratic element is employed in the present &# 64257;nite element formulation. A parametric study is carried out to investigate the effects of <b>triggering</b> <b>parameters</b> like initial velocity of impactor, twist angle, oblique impact angle, location of impact for Stainless Steel-Nickel functionally graded conical shell subjected to low velocity impact...|$|E
40|$|AbstractThe low {{velocity}} impact {{response of}} torsion stiff composite pretwisted conical shells is {{portrayed in the}} present study. The formulation is based on Mindlin's theory incorporating rotary inertia and effects of transverse shear deformation. An eight noded isoparametric plate bending element is employed to satisfy the compatibility of deformation and equilibrium of resultant forces and moments at the delamination crack front. A multipoint constraint algorithm is incorporated which leads to unsymmetric stiffness matrices. The modiﬁed Hertzian contact law is employed to simulate the contact force and the time dependent equations are solved by Newmark's time integration algorithm. Parametric studies are conducted with respect to <b>triggering</b> <b>parameters</b> like twist angle, target displacement, initial velocity of striker considering low velocity centrally impacted spherical mass...|$|E
40|$|AbstractUsing a {{visualization}} {{engine to}} analyze power meter generated data about energy consumption {{of a building}} can provide immediate and informative feedback for energy conservation research. This paper proposed a platform, real-time replay system (RTRS), to provide such a visualized and interactive environment through the Unity 3 d game engine. RTRS combines two data sources: Revit, a building information model (BIM) tool, and WiFi power socket sensors into Unity 3 d and replays electricity usage events. RTRS users can easily change the scene or jump to the given time frame identified as a wasteful operation, and the system will display potential energy conservation suggestions. In addition, RTRS users can set up event <b>triggering</b> <b>parameters</b> or query conditions against the sensor database inside RTRS. In overall, RTRS can provide an intuitive and easy-to-use platform for managing electricity usage data of a building, reducing the time and efforts for looking up information at the raw data level...|$|E
3000|$|... [...]), {{referred}} as the system's <b>triggering</b> <b>parameter,</b> determines the system's degree of preemption. Large {{values for the}} system's <b>triggering</b> <b>parameter</b> will make the scheduling policy react in a more preemptive way to real-time users' short-term throughput performance deviations, and therefore the achieved probabilities of not satisfying their short-term QoS requirements values will decrease.|$|R
3000|$|... [...]. We {{consider}} saturated NRT users requesting {{best effort}} NRT services, aiming at maximizing the achieved actual downlink throughput. The system's <b>triggering</b> <b>parameter</b> is [...]...|$|R
40|$|The {{mapping of}} soil {{movement}} was examined by comparing {{an extension of}} the deterministic Soil Stability Index Mapping (SINMAP) method, and an overlay method with <b>trigger</b> <b>parameters</b> of soil movement. The SINMAP model used soil parameters {{in the form of the}} cohesion value (c), internal friction angle (φ), and hydraulic conductivity (ks) for the prediction of soil movement based on the factor of safety (FS), while the indirect method used a literature review and field observations. The weightings of soil movement <b>trigger</b> <b>parameters</b> in assessments were based on natural physical aspects: (1) slope inclination = 30 %; (2) rock weathering = 15 %; (3) geological structure = 20 %; (4) rainfall = 15 %; (5) groundwater potential = 7 %; (6) seismicity = 3 %; and (7) vegetation = 10 %. The research area was located in the Buleleng district, in particular in the ancient mountain area of Buyan-Tamblingan, in the Sukasada sub-district. The hazard mapping gave a high and very high hazard scale. The SINMAP model gave a validation accuracy of 14. 29 %, while the overlay method with seven <b>trigger</b> <b>parameters</b> produced an accuracy of 71. 43 %. Based on the analysis of the very high and high hazard class and the validation of the landslide occurrence points, the deterministic method using soil parameters and water absorption gave a much lower accuracy than the overlay method with a study of soil motion <b>trigger</b> <b>parameters...</b>|$|R
40|$|Rockfall is a {{major problem}} in high hill slopes and rocky mountainous regions and {{construction}} of highways at these rockfall prone areas often require stable slopes. The causes of rockfall are presence of discontinuities, high angle cut slopes, heavy rainfall, and unplanned slope geometry etc. Slope geometry {{is one of the most}} <b>triggering</b> <b>parameters</b> for rockfall, when there are variations in slope angle along the profile of slope. The Present study involves rockfall hazard assessment of road cut slopes for 15 km distance starting from Mahabaleshwar town along State Highway- 72 (SH- 72). The vertical to subvertical cut slopes are prone to instability due to unfavorable orientation of discontinuities in slope face of weathered and altered basaltic rockmass. The predominant type of instability has been found as wedge type failure involving medium to large size blocks. In order to investigate the existing stability conditions, analyses were carried out at two locations under different slope conditions. The kinematic analysis was performed using stereographic projection method. Roc k Fall 4. 0 numerical simulator software was used to calculate the maximum bounce heights, total kinetic energies and translational velocities of the falling rockmass blocks, and a comparative analysis is presented with increasing the mass of blocks and height of the slope. The result of numerical analysis shows that varying slope angle geometry creates more problems as compared to the mass of blocks in the scenario of rockfall. </p...|$|E
40|$|The entire dissertation/thesis text is {{included}} in the research. pdf file; the official abstract appears in the short. pdf file (which also appears in the research. pdf); a non-technical general description, or public abstract, appears in the public. pdf file. Title from title screen of research. pdf file viewed on (January 11, 2007) Includes bibliographical references. Thesis (M. S.) University of Missouri-Columbia 2005. Dissertations, Academic [...] University of Missouri [...] Columbia [...] Electrical engineering. A model of a spark gap used as a shorting switch in a Blumlein pulse power system has been developed. The model is separated into a pre-breakdown kinetic model and a post-breakdown fluid model. The kinetic model is used to simulate streamer formation, and the fluid model is used to simulate the behavior of the conducting arc. Intrinsic switch parameters that were varied in the kinetic model included electric field, gas pressure and gas type. Laser <b>triggering</b> <b>parameters</b> varied included spot shape, spot area, and laser power. Parameters varied in the fluid model were the initial arc radius, arc conductivity, and gas density. Initial arc radius and conductivity for the fluid model are found from the end result of the kinetic model. The goal was to evaluate parameters to discover their effects on the resistive fall time of the switch. Increasing the initial arc radius and conductivity were a large factor in decreasing the resistive fall time. Increasing the electric field and reorienting the laser trigger spot to a linear beam transverse to the electric field were significant factors in increasing the initial arc radius...|$|E
40|$|This work {{focuses on}} the design of {{handover}} algorithms that will improve the handover decision making process {{and at the same time}} provide the flexibility to change performance indicators when the need arises. It will incorporate the training capability derived from the artificial neural networks to tune the fuzzy logic controller to achieve at least a near-optimal output. With this adaptive capability, the algorithms can minimise the need for human intervention during initial deployment, optimisation and maintenance of network elements. The main contributions of this thesis are summarised as follows: firstly, a new handover triggering scheme is designed which incorporates fuzzy logic with adaptive capabilities to improve and optimise the handover decision process, followed by comparative performance analysis between the conventional and the new adaptive fuzzy logic handover decision algorithms in homogeneous networks. The adaptive fuzzy logic controller (FLC) will also be applied in LTE's mobility management scenarios where it will contribute to a larger framework envisioned by SONs to reduce OPEX. This is followed by comparative performance studies of the new algorithms with the existing LTE's handover algorithms. Secondly, the selection of eNBs in the SON’s automatic neighbour relation (ANR) function has been improved with a design of an additional function called the neighbour sorting function (NSF). It will sort and rank the possible eNBs to handover based on the QoS requirements. Finally, the adaptive nature of the algorithms can also be applied to optimise the existing LTE's handover <b>triggering</b> <b>parameters</b> such as time-to-trigger (TTT) and handover margin (HOM) ...|$|E
40|$|The event-triggered H∞ {{control design}} is {{investigated}} for networked control systems with uncertainties and transmission delays. A novel event-triggering scheme is proposed, which has some advantages over traditional ones with a continuous detector. Considering {{the effect of}} the transmission delay, a delay system model for the analysis is firstly constructed. Then, based on the model and Lyapunov functional method, criteria for the stability with an H∞ norm bound and criteria for the co-design of both the feedback gain and the <b>trigger</b> <b>parameters</b> are derived. In order to solve the feedback gain and the <b>trigger</b> <b>parameters,</b> the linear matrix inequality technique is employed. From the simulation example, it can be concluded that the proposed event-triggering scheme is superior to some other event-triggering schemes in some existing literature...|$|R
40|$|A Time Encoding Machine {{consisting}} of a feedback loop containing an adder, an integrator and a Schmitt trigger encodes amplitude information into a time sequence. We demonstrate how to construct a Time Decoding Machine that perfectly recovers the amplitude information from the time sequence and is <b>trigger</b> <b>parameter</b> insensitive...|$|R
40|$|An event-triggered {{scheme is}} adopted {{and applied to}} the design of a {{centralized}} wide-area H∞ damping controller (WAHDC) of interconnected power systems with external disturbance. Firstly, based on the linearized multimachine system model, the centralized WAHDC with event-triggered scheme design problem is described as time-delay feedback control problem. Then by using Lyapunov functional method and Jensen inequality technique, criteria for stability with an H∞ norm bound and for design of the feedback controller are derived. The linear matrix inequality (LMI) is employed to solve the feedback gain. Finally, case studies are carried out based on two-area four-machine power system. Simulations indicate that the proposed WAHDC with event-triggered scheme can damp the interarea oscillation effectively when the external disturbance is bounded and significantly reduce the number of measured states released to WAHDC. Relationships between event <b>trigger</b> <b>parameter</b> σ and dynamic performance, σ and network utilization, σ and time delay, and σ and disturbance rejection level are investigated and results obtained can be used to choose an appropriate event <b>trigger</b> <b>parameter...</b>|$|R
40|$|This {{research}} {{was carried out}} due to the occurrence of mass movement in Kalitlaga Village Pagentan Sub-District Banjarnegara District, {{which was one of}} most dangerous area to mass movement in Province Central Java. Such movement resulted in damaged houses and road. This {{research was}} conducted to recognize and identify the direction and type of mass movement, to identify the <b>triggering</b> <b>parameters</b> and the cause of mass movement in order to provide an appropriate disaster mitigation recommendation and prevention method, as well as to introduce low cost early warning system based on community which enabled the community to prepare and operate the system in lessening the disaster risks. Secondary and primary data used in this research were derived from field investigation and study. The method of the study is analyzing the results of field study. To obtain the percentage of people understanding on disaster mitigation, landslide, and early warning system, interviews were conducted and the interviews outputs were processed using the SPSS software. Result shows that the landslide is predominantly northeastern ward and slump type of movement. To the number of leaky water pipe and infiltrations into the ground induce the mass movement. This movement is due to geological factors such as geomorphology factor and existence of clay stone as well as high rainfall factor. The community low understanding on disaster mitigation represents the reason to install simple and cheap early warning system community based disaster mitigation. Such mitigation is easier to apply than technology based mitigation. It is also more suitable prior to a disaster. Community participation and also support from government are the key efficacy of disaster mitigation...|$|E
40|$|This {{paper is}} a {{presentation}} of landslide monitoring, early warning and remediation methods recommended for the Polish Carpathians. Instrumentation included standard and automatic on-line measurements with the real-time transfer of data to an Internet web server. The research was funded through EU Innovative Economy Programme and also by the SOPO Landslide Counteraction Project. The landslides investigated were characterized by relatively low rates of the displacements. These ranged from a few millimetres to several centimetres per year. Colluviums of clayey flysch deposits were of a soil-rock type with a very high plasticity and moisture content. The instrumentation consisted of 23 standard inclinometers set to depths of 5 - 21 m. The starting point of monitoring measurements was in January 2006. These were performed every 1 - 2 months over the period of 8 years. The measurements taken detected displacements from several millimetres to 40 cm set at a depth of 1 - 17 m. The modern, on-line monitoring and early warning system was installed in May 2010. The system is {{the first of its kind}} in Poland and only one of several such real-time systems in the world. The installation was working with the Local Road Authority in Gorlice. It contained three automatic field stations for investigation of landslide parameters to depths of 12 - 16 m and weather station. In-place tilt transducers and innovative 3 D continuous inclinometer systems with sensors located every 0. 5 m were used. It has the possibility of measuring a much greater range of movements compared to standard systems. The conventional and real-time data obtained provided a better recognition of the <b>triggering</b> <b>parameters</b> and the control of geohazard stabilizations. The monitoring methods chosen supplemented by numerical modelling could lead to more reliable forecasting of such landslides and could thus provide better control and landslide remediation possibilities also to stabilization works which prevent landslides...|$|E
40|$|The {{base of the}} Faro contouritic drift (IODP Site U 1386) on the {{northern}} margin of the Gulf of Cádiz (Algarve margin) is characterized by two sequences of frequent gravity deposits with different ages and compositions. Among these gravity deposits, several relatively thick debrites (up to 12 m) have been observed and studied in detail. Sedimentological analyses have been performed and because of non-turbulent behavior of debris flows, detailed micropaleontological studies could be realized. Planktonic foraminifera thus allowed establishing a detailed biostratigraphy of these deposits. Benthic foraminifer and ostracod assemblageswere {{used to evaluate the}} origin of the sediment composing these debris flows and estimate their run-out distance. These debrites are dated fromEarly Pliocene and early Pleistocene, andwere deposited in amesobathyal environment. They comprise silty mud clasts and matrixes with sand content up to 34 %. The Early Pliocene debrites are bioclast-rich whereas the Early Pleistocene debrite is enriched in terrigenous particles. The data indicates that these debrites were triggered on the continental shelf and traveled less than 100 km, eroding the seafloor all along their path for the Early Pliocene debrites and only the first part of their path for the early Pleistocene debrite. Matrixes originate fromfailure areaswhereas eroded sediments along the flow pathway are incorporated into the flow as clasts. High abundance of shelf fauna during the Early Pliocene and great supply of terrigenous particles from rivers during the early Pleistocene in the south-western Iberian margin have favored gravity flows fromthe continental shelf to the slope. The contouritic paleo-moat of the Faro drift has been a determining channeling feature for gravity flows along the Algarve margin during the early Pleistocene, testifying of the strong interaction between MOW circulation and down-slope processes. Tectonic and diapiric activities were significant during Early Pliocene and early Pleistocene on the Algarve margin and could have been <b>triggering</b> <b>parameters</b> of failures related to these debris flows...|$|E
40|$|This {{paper is}} {{concerned}} with the state-feedback controller design for stochastic networked control systems (NCSs) with random actuator failures and transmission delays. Firstly, an event-triggered scheme is introduced to optimize the performance of the stochastic NCSs. Secondly, stochastic NCSs under event-triggered scheme are modeled as stochastic time-delay systems. Thirdly, some less conservative delay-dependent stability criteria in terms of linear matrix inequalities for the codesign of both the controller gain and the <b>trigger</b> <b>parameters</b> are obtained by using delay-decomposition technique and convex combination approach. Finally, a numerical example is provided to show the less sampled data transmission and less conservatism of the proposed theory...|$|R
40|$|This note is {{concerned}} with event-triggered H∞ controller design for networked control systems. A novel event-triggering scheme is proposed, which has some advantages over some existing schemes. A delay system model for the analysis is firstly constructed by investigating {{the effect of the}} network transmission delay. Then, based on this model, criteria for stability with an H∞ norm bound and criteria for co-designing both the feedback gain and the <b>trigger</b> <b>parameters</b> are derived. These criteria are formulated in terms of linear matrix inequalities. Simulation results have shown that the proposed event-triggering scheme is superior to some existing event-triggering schemes in the literature...|$|R
40|$|The {{landslide}} that is {{the subject}} of this paper occurred inPrahova County. The present work was carried out to study the spatialinfluence of geological and morphological factors upon landslideoccurrence on a local scale by using geotechnical and geophysical methods in order to determine local <b>trigger</b> <b>parameters.</b> The input data for the slopestability analysis were collected from topographic investigations, geological mapping. In addition, soil geotechnical parameters were collated from a series of in situ tests. A geophysical survey was applied by using vertical electrical soundings in order to detect the existence and continuity of a potential sliding surface...|$|R
40|$|The {{identification}} of snow avalanche release areas {{is a very}} difficult task. The release mechanism of snow avalanches depends on many different terrain, meteorological, snowpack and <b>triggering</b> <b>parameters</b> and their interactions, which are very difficult to assess. In many alpine regions such as the Indian Himalaya, nearly no information on avalanche release areas exists mainly due to the very rough and poorly accessible terrain, the vast size of the region and the lack of avalanche records. However avalanche release information is urgently required for numerical simulation of avalanche events to plan mitigation measures, for hazard mapping and to secure important roads. The Rohtang tunnel access road near Manali, Himachal Pradesh, India, is such an example. By far the most reliable way to identify avalanche release areas is using historic avalanche records and field investigations accomplished by avalanche experts in the formation zones. But both methods are not feasible for this area due to the rough terrain, its vast extent and lack of time. Therefore, we develop an operational, easy-to-use automated potential release area (PRA) detection tool in Python/ArcGIS which uses high spatial resolution digital elevation models (DEMs) and forest cover information derived from airborne remote sensing instruments as input. Such instruments can acquire spatially continuous data even over inaccessible terrain and cover large areas. We validate our tool using a database of historic avalanches acquired over 56 yr in the neighborhood of Davos, Switzerland, and apply this method for the avalanche tracks along the Rohtang tunnel access road. This tool, used by avalanche experts, delivers valuable input to identify focus areas for more-detailed investigations on avalanche release areas in remote regions such as the Indian Himalaya and is a precondition for large-scale avalanche hazard mapping...|$|E
40|$|International audienceThe {{base of the}} Faro contouritic drift (IODP Site U 1386) on the {{northern}} margin of the Gulf of Cádiz (Algarve margin) is characterized by two sequences of frequent gravity deposits with different ages and compositions. Among these gravity deposits, several relatively thick debrites (up to 12 m) have been observed and studied in detail. Sedimentological analyses have been performed and because of non-turbulent behavior of debris flows, detailed micropaleontological studies could be realized. Planktonic foraminifera thus allowed establishing a detailed biostratigraphy of these deposits. Benthic foraminifer and ostracod assemblages were {{used to evaluate the}} origin of the sediment composing these debris flows and estimate their run-out distance. These debrites are dated from Early Pliocene and early Pleistocene, and were deposited in a mesobathyal environment. They comprise silty mud clasts and matrixes with sand content up to 34 %. The Early Pliocene debrites are bioclast-rich whereas the Early Pleistocene debrite is enriched in terrigenous particles. The data indicates that these debrites were triggered on the continental shelf and traveled less than 100 km, eroding the seafloor all along their path for the Early Pliocene debrites and only the first part of their path for the early Pleistocene debrite. Matrixes originate from failure areas whereas eroded sediments along the flow pathway are incorporated into the flow as clasts. High abundance of shelf fauna during the Early Pliocene and great supply of terrigenous particles from rivers during the early Pleistocene in the south-western Iberian margin have favored gravity flows from the continental shelf to the slope. The contouritic paleo-moat of the Faro drift has been a determining channeling feature for gravity flows along the Algarve margin during the early Pleistocene, testifying of the strong interaction between MOW circulation and down-slope processes. Tectonic and diapiric activities were significant during Early Pliocene and early Pleistocene on the Algarve margin and could have been <b>triggering</b> <b>parameters</b> of failures related to these debris flows...|$|E
40|$|International Telemetering Conference Proceedings / October 20 - 23, 2003 / Riviera Hotel and Convention Center, Las Vegas, NevadaThe US Army Aberdeen Test Center (ATC) is acquiring, transferring, and databasing data {{during all}} phases of {{automotive}} testing using networked data acquisition devices. The devices are small ruggedized computer-based systems programmed with specific data acquisition tasks and then networked together with other devices in order to share information within a test item or vehicle. One of the devices is also networked to a ground-station for monitor, control and data transfer {{of any of the}} devices on the net. Application of these devices has varied from single vehicle tests in a single geographical location up to a 100 -vehicle nationwide test. Each device has a primary task such as acquiring data from vehicular data busses (MIL-STD- 1553, SAE J 1708 bus, SAE J 1939 bus, RS- 422 serial bus, etc.), GPS (time and position), analog sensors and video with audio. Each device has programmable options, maintained in a configuration file, that define the specific recording methods, real-time algorithms to be performed, data rates, and <b>triggering</b> <b>parameters.</b> The programmability of the system and bi-directional communications allow the configuration file to be modified remotely after the system is fielded. The primary data storage media of each device is onboard solid-state flash disk; therefore, a continuous communication link is not critical to data gathering. Data are gathered, quality checked and loaded into a database for analysis. The configuration file, {{as an integral part of}} the database, ensures configuration identity and management. A web based graphical user interface provides preprogrammed query options for viewing, summarizing, graphing, and consolidating data. The database can also be queried for more detailed analyses. The architecture for this network approach to field data acquisition was under the Aberdeen Test Center program Versatile Information System Integrated On-Line (VISION). This paper will describe how the merging of data acquisition systems to network communications and information management tools provides a powerful resource for system engineers, analysts, evaluators and acquisition personnel...|$|E
3000|$|... 0 as {{described}} above, we can generate action potential pulses using the standard Hodgkin - Huxley {{model for a}} large variety of critical sodium <b>trigger</b> shaping <b>parameters.</b> We label these with a N [...]...|$|R
40|$|The {{effect of}} varying BATSE <b>trigger</b> <b>parameters</b> on the modeled BATSE {{detection}} rate is investigated numerically. Quantitative estimates are obtained of the systematic effects {{generated by the}} complex interplay of trigger times, variations in the signal-to-noise ratio for burst detection {{as well as the}} time scale over which backgrounds are determined, and the number of required detections above threshold. It is found, in particular that employing a third detection, at a reduced signal-to-noise ratio, to resolve a burst does not increase the detection rate. It is also shown that the BATSE detection rate is insensitive to variations in the time scale over which the background is determined...|$|R
40|$|<b>Triggers</b> for <b>parameter</b> setting may be ambiguous. Strategies {{for dealing}} with {{ambiguity}} include guessing, parallel processing, and waiting for unambiguous input. The Trigger Learning Algorithm of Gibson and Wexler (1994) is a guessing system. Gibson and Wexler show that under some reasonable assumptions it may never attain the target grammar. I propose instead a deterministic device that waits for unambiguous <b>triggers</b> to set <b>parameters.</b> This learner {{must be able to}} detect parametric ambiguity. This is not possible on the classical conception of triggers as sentences that flip parameter switches. It is possible if a <b>trigger</b> (and the <b>parameter</b> value it <b>triggers)</b> is a piece of tree structure, perhaps a single feature, made available by Universal Grammar, and adopted into the learner’s grammar if input sentences cannot be parsed without it...|$|R
40|$|Abstract: This {{paper is}} a {{presentation}} of landslide monitoring, early warning and remediation methods recommended for the Polish Carpathians. Instrumentation included standard and automatic on-line measurements with the real-time transfer of data to an Internet web server. The research was funded through EU Innovative Economy Programme and also by the SOPO Land-slide Counteraction Project. The landslides investigated were characterized by relatively low rates of the displacements. These ranged from a few millimetres to several centimetres per year. Colluviums of clayey flysch deposits were of a soil-rock type with a very high plasticity and moisture content. The instrumentation consisted of 23 standard inclinometers set to depths of 5 – 21 m. The starting point of monitoring measurements was in January 2006. These were performed every 1 – 2 months over the period of 8 years. The measurements taken detected displacements from several millimetres to 40 cm set at a depth of 1 – 17 m. The modern, on-line monitoring and early warning system was installed in May 2010. The system is {{the first of its kind}} in Poland and only one of several such real-time systems in the world. The installation was working with the Local Road Authority in Gorlice. It contained three automatic field stations for investigation of landslide parameters to depths of 12 – 16 m and weather station. In-place tilt transducers and innovative 3 D continuous inclinometer systems with sensors located every 0. 5 m were used. It has the possibility of measuring a much greater range of movements compared to standard systems. The conventional and real-time data obtained provided a better recognition of the <b>triggering</b> <b>parameters</b> and the control of geohaz-ard stabilizations. The monitoring methods chosen supplemented by numerical modelling could lead to more reliable fore-casting of such landslides and could thus provide better control and landslide remediation possibilities also to stabilization works which prevent landslides. Key words: monitoring systems, geotechnical engineering landslide investigation...|$|E
40|$|A thesis {{submitted}} to the University of Bedfordshire in partial ful lment of the requirements for the degree of Doctor of PhilosophyFemtocell is a small cellular base station used by operators to extend indoor service coverage and enhance overall network performance. In Long Term Evolution (LTE), femtocell works under macrocell coverage and combines with the macrocell to constitute the two-tier network. Compared to the traditional single-tier network, the two-tier scenario creates many new challenges, which lead to the 3 rd Generation Partnership Project (3 GPP) implementing an automation technology called Self-Organising Network (SON) {{in order to achieve}} lower cost and enhanced network performance. This thesis focuses on the inbound and outbound handovers (handover between femtocell and macrocell); in detail, it provides suitable solutions for the intensity of femtocell handover prediction, Physical Cell Identity (PCI) allocation and handover triggering parameter optimisation. Moreover, those solutions are implemented in the structure of SON. In order to e ciently manage radio resource allocation, this research investigates the conventional UE-based prediction model and proposes a cell-based prediction model to predict the intensity of a femtocell's handover, which overcomes the drawbacks of the conventional models in the two-tier scenario. Then, the predictor is used in the proposed dynamic group PCI allocation approach in order {{to solve the problem of}} PCI allocation for the femtocells. In addition, based on SON, this approach is implemented in the structure of a centralised Automated Con guration of Physical Cell Identity (ACPCI). It overcomes the drawbacks of the conventional method by reducing inbound handover failure of Cell Global Identity (CGI). This thesis also tackles optimisation of the handover <b>triggering</b> <b>parameters</b> to minimise handover failure. A dynamic hysteresis-adjusting approach for each User Equipment (UE) is proposed, using received average Reference Signal-Signal to Interference plus Noise Ratio (RS-SINR) of the UE as a criterion. Furthermore, based on SON, this approach is implemented in the structure of hybrid Mobility Robustness Optimisation (MRO). It is able to off er the unique optimised hysteresis value to the individual UE in the network. In order to evaluate the performance of the proposed approach against existing methods, a System Level Simulation (SLS) tool, provided by the Centre for Wireless Network Design (CWiND) research group, is utilised, which models the structure of two-tier communication of LTE femtocell-based networks...|$|E
30|$|The {{regulated}} utilization {{values are}} {{calculated from the}} raw CPU usage monitor values recorded at the specified frequency for the entered period, using (1). This provides relatively stable monitor values that can reflect the overall resource utilization changes of the monitor period, compared with the raw real-time monitor data. Then, in order to mitigate the optimization delays, OCSO IaaS optimization adopts a dynamic adjusted threshold algorithm that uses variable green boundary limits and violation thresholds. Basically, the amount of dynamic scaling adjustment is controlled according to two aspects: I) whether an optimization is a continued or intermittent scaling; II) how much the regulated utilization monitor values exceed the green limits (i.e., within, by or over 10 %). In this way, whenever an optimization occurs, the successor’s green boundary limit and threshold values are evolved, using (2.1), (2.3), (3.1) and (3.3). More specifically, depending on whether its successor could {{keep up with the}} workload for the incoming period of monitor cycle, two sets of <b>triggering</b> <b>parameters</b> are used: in case of a continuous optimization, the respected up/down limit is lowered/raised for a certain amount depending on the utilization data recorded during the current monitor period (using (2.1)/(3.1)), whereas the respected threshold value is lowered (using (2.3)/(3.3)); in case of intermittent optimization or no optimization, the evolved parameters are restored to the initial user specified values. Additionally, whenever an up/down limit is changed, the other limit must be validated (using the relevant PGR). This is to ensure that the gap between the up and down limits is always appropriate for later optimizations, regardless of the volumes of workload. Without this validation and the mandatory supplement updates, as the gap becomes too large or too small, the optimizations would either miss the optimal timing or be triggered too early. The validation updates stay the same as they are in TARGO, using (2.2) and (3.2). The above complete rule evolution process creates a dynamic green boundary and respected thresholds specifically for every new VM successor considering its size as well as the current workload volume. In this way, the system would act more proactively while responding to extremely altered workloads. By doing so, OCSO IaaS optimization overcomes TARGO’s lagging limitations by upsizing VMs quicker while facing dramatically/continuously increasing workloads and downsizing VMs earlier in case of rapidly/constantly descending workloads.|$|E
40|$|A radial {{multichannel}} pseudopark switch seems advantageous {{for switching}} currents exceeding 100 kA. A single common hollow cathode guarantees same tigger conditions for all channels. The electron beams emitted {{out of the}} hollow cathode of this switch are analyzed by means of Faraday-cups by varying the circuit {{as well as the}} <b>trigger</b> <b>parameters.</b> In addition to the cup measuremnts, the discharge is observed using a CCD camera. It is found that each channel of the Switch must receive a respective beam, before the restistance of the switch turns low, if the discharge current is to run through that channel. In addition, most of the varied parameters do not influence the electron beam...|$|R
40|$|We {{report on}} the {{fabrication}} of nanocontacts by indentation of an ultrathin insulating photoresist layer deposited on various types of conductive structures. A modified atomic force microscope (AFM) designed for local resistance measurements {{is used as a}} nanoindenter. The nanoindentation is performed while measuring continuously the resistance between the conductive tip of the AFM and the conductive layer, which is used as the <b>trigger</b> <b>parameter</b> to stop the indentation. This allows a very accurate control of the indentation process, The indented hole is subsequently filled by a metal to create a contact on the underlying layer. We show that nanocontacts; in the range of 1 to 10 nm(2) can be created with this technique...|$|R
40|$|This paper {{introduces}} a novel event-triggered scheme into networked control systems {{which is used}} to determine when to transmit the newly sampled state information to the controller. Considering the effect of the network transmission delay and probabilistic actuator fault with different failure rates, a new actuator fault model is proposed under this event-triggered scheme. Then, criteria for the exponential mean square stability (EMSS) and criteria for codesigning both the feedback and the <b>trigger</b> <b>parameters</b> are derived by using Lyapunov functional method. These criteria are obtained in the form of linear matrix inequalities. A simulation example is employed to show that our event-triggered scheme can lead to a larger release period than some existing ones...|$|R
40|$|Restricted until 24 July 2009. Recently quantum phase {{transitions}} {{have attracted}} {{the interest of}} both theorists and experimentalists in condensed matter physics. Quantum magnets provide a perfect playground for studying these phase transitions since they can be triggered by many control parameters such as frustration, lattice dimerization, and magnetic field. Most previous {{studies have focused on}} the magnetic properties in pure systems. In these systems, responses to the <b>triggering</b> <b>parameters</b> are found to be uniform, leading to homogeneous phases. However little progress has been made so far on the phase transitions and properties in disordered quantum magnets because they are more complicated systems, and few theoretical tools can be applied.; In this thesis we use the stochastic series expansion quantum Monte Carlo method to study quantum phase transitions in disordered magnets. We find that disordered magnets can behave quite differently from pure systems. The system inhomogeneity can strongly affect phase transitions by changing their universality class. We also find order-disorder transitions are often accompanied by the appearance of novel quantum disordered phases, in which magnetic properties behave highly nontrivial, even singular.; In this thesis two examples are studied in great detail. The first one is the phase diagram of an inhomogeneous, bond-diluted two-dimensional antiferromagnet near the percolation threshold. We show that the magnetic transition can be tuned by the inhomogeneity of the dilution from a classical percolation to a quantum phase transition. Interestingly the quantum transition still takes the nature of a renormalized percolative transition, with continuously varying critical exponents. A gapless quantum disordered phase with no magnetic long-range order but geometric percolation is found. The low-temperature uniform susceptibility diverges as a non-universal power-law of the temperature in this phase, indicating that this is a quantum Griffiths phase. In the second example, we study field-induced quantum phase transitions in two-dimensional site-diluted coupled dimers. We find that an extremely small field drives the order-bydisordered phase into a quantum disordered disordered-free-moment phase. The agnetization curve in this phase shows a series of pseudo-plateaus, which {{can be explained by the}} highly inhomogeneous field response of the free moments. A spin-boson mapping reveals that the disordered-free-moment phase can be understood as a low-field Bose glass phase, and hence the associated phase transition is a realization of a twodimensional Bose-glass-to-disordered-free-moment transition. This is confirmed by the entire phase diagram and the study of the scaling behavior of correlation length, order parameter, and spin stiffness in the critical regime...|$|E
40|$|Abstract. System {{behaviors}} {{specify the}} major functions of domain specific Web Information Systems (WIS). Traditional techniques can not satisfy various requirements or manage innumerous data while developing WIS behaviors. People {{appeal to a}} smart tool for implementing the WIS behaviors. This article makes the following contributions: (1) Proposes the concept of domain ontology and behavior ontology to describe the contents and operations of WIS; (2) Extends traditional ECA model to characterize the <b>triggers,</b> <b>parameters,</b> actions as well as validations of WIS behaviors; (3) Analyses the relationships between domain ontology and behavior ontology with rule sets; (4) Implements a tool named WISE Builder with four algorithms to help users building behavior ontology with domain ontology; (5) Shows the feasibility of this technique in a real application case...|$|R
40|$|The Gamma Ray Large Area Space Telescope (GLAST), {{currently}} set {{for launch}} {{in the first}} quarter of 2007, will consist of two instruments, the GLAST Burst Monitor (GBM) and the Large Area Telescope (LAT). One of the goals of the GBM is to identify and locate gamma-ray bursts using on-board software. The GLAST observatory can then be re-oriented to allow observations by the LAT. A Bayesian analysis will be used to distinguish gamma-ray bursts from other triggering events, such as solar flares, magnetospheric particle precipitation, soft gamma repeaters (SGRs), and Cygnus X- 1 flaring. The <b>trigger</b> <b>parameters</b> used in the analysis are the burst celestial coordinates, angle from the Earth's horizon, spectral hardness, and the spacecraft geomagnetic latitude. The algorithm will be described and the results of testing will be presented...|$|R
40|$|Abstract. The {{landslide}} that is {{the subject}} of this paper occurred in the central part of Romania, in Prahova County, located near the Prahova Valley, in hillside area, frequently affected by this kind of major hazard. The geological phenomenon occurred in the area is an old event and it was reactivated starting with 2010. The inappropriate geological and geotechnical conditions characteristic of the area and also the lack of a drainage system were conducted to landslide reactivation during a period of intense rainfall. The present work was carried out to study the spatial influence of geological and morphological factors upon landslide occurrence on a local scale by using geotechnical and geophysical methods in order to determine local <b>trigger</b> <b>parameters.</b> The complex studies were conducted in finding the most feasible technical and economical option for the efficient emergency management of landslide hazard...|$|R
40|$|One of {{the core}} types of {{analysis}} performed in naturalistic driving studies (NDS) is event based analysis (EBA). EBA considers surrogate events, called safety critical events (SCE), for crashes, since actual crashes are rare. In order to find potential safety critical events, constant parameter thresholds have been commonly used (Simons-Morton et al., 2011). A key challenge of NDS is determining whether these SCEs are safety-relevant requiring time-consuming and expensive manual video coding. In order to lower the time needed for manual coding, a new approach of identifying SCE is presented on the data of the UDRIVE NDS. In this approach, SCE triggers are defined based on the likelihood of certain events countering the inherited high number of false-alarms of constant thresholds (Simons-Morton et al., 2011). The approach provides a functional relationship between the threshold parameters (e. g. longitudinal acceleration and situational parameters such as speed). This function {{is based on the}} joint probability density distribution (JPDD) of the involved <b>trigger</b> <b>parameters.</b> The first step is to estimate the JPDD from a representative sample. Because the linearly binned kernel density estimate approach (Wand, 1994) is computationally fast and allows for estimating two dimensional distributions, it was used for estimating the JPDD (Deng, 2011). The trigger function is computed as the percentile line of the estimated JPDD by computing the cumulative probability function. This curve represents a dynamically changing threshold of <b>trigger</b> <b>parameters</b> depending on a chosen set of situational parameters such as velocity. This approach allows for determining events occurring with a specific probability. A polynomial fit can help determining an easy-to-implement representation of the trigger function. This approach has two advantages: Specific values of a constant trigger threshold {{do not need to be}} chosen, but instead values are the result of a general parameter setting. Furthermore, it provides a dynamically changing threshold for different scenarios, such as a lower threshold on longitudinal deceleration values for driving on a highway (higher speed levels) compared to urban driving (lower speed levels). We expect that this framework closes the gap between discrete forms of SCE triggers and helps to lower the number of false-alarm detections and therefore relieves the burden of manual inspection...|$|R
40|$|Submicron-sized extra-cellular vesicles {{generated}} by budding from the external cell membranes, microparticles (MPs) are important actors in transfusion {{as well as}} in other medical specialties. After briefly positioning their role in the characterization of labile blood products, this technically oriented chapter aims to review practical points that need to be considered when trying to use flow cytometry for the analysis, characterization and absolute counting of MP subsets. Subjects of active discussions relative to instrumentation will include the choice of the <b>trigger</b> <b>parameter,</b> possible standardization approaches requiring instrument quality-control, origin and control of non-specific background and of coincidence artifacts, choice of the type of electronic signals, optimal sheath fluid and sample speed. Questions related to reagents will cover target antigens and receptors, multi-color reagents, negative controls, enumeration of MPs and limiting artifacts due to unexpected (micro-) coagulation of plasma samples. Newly detected problems are generating innovative solutions and flow cytometry will continue to remain the technology of choice for the analysis of MPs, in the domain of transfusion {{as well as in}} many diverse specialties...|$|R
