1|546|Public
40|$|We present PianoText, a {{text entry}} method based on a piano {{keyboard}} with an optimized mapping between notes and chords of music to letters of the English language. PianoText exemplies the idea of transferring musical expertise to a text entry task by computationally searching for mappings between frequent motor patterns while considering their n-gram frequency distributions and respecting constraints aecting the playability of music. In the Interactivity session, audience members with piano skills can <b>transcribe</b> <b>text</b> with PianoText, and a trained pianist will show that it allows him to generate text at speeds close to that of professional QWERTY-typists...|$|E
5000|$|... http://lincoln.lib.niu.edu/cgi-bin/amarch/getdoc.pl?/var/lib/philologic/databases/amarch/.17512 Thomas Hickey Court-martial (<b>transcribed</b> <b>text)</b> ...|$|R
5000|$|... 1. The {{two classes}} Correct and Incorrect Not Fixed {{comprise}} {{all of the}} characters in <b>transcribed</b> <b>text.</b> 2. Fixes (F) keystrokes are easy to identify, and include keystrokes such as backspace, delete, cursor movements, and modifier keys. 3. Incorrect Fixed (IF) keystrokes are found in the input stream, but not the <b>transcribed</b> <b>text,</b> and are not editing keys.|$|R
2500|$|... The Political Science Quarterly, vol. III, no. 3, 1898, <b>transcribed</b> <b>text,</b> Sons of DeWitt Colony Texas Website ...|$|R
50|$|Devéria {{spent his}} last days {{traveling}} in Egypt, making drawings and <b>transcribing</b> <b>texts.</b> He died in 1857.|$|R
5000|$|Audiosear.ch is {{a company}} which {{develops}} technology for indexing and retrieving <b>transcribed</b> <b>text</b> from audio recordings. Audio content is indexed and searchable.|$|R
5000|$|He {{mastered}} Latin. He {{had great}} interest in manuscripts and literary texts. He himself personally <b>transcribed</b> <b>text</b> of Cicero, his Somnium Scipionis ...|$|R
5000|$|With {{the minimum}} string {{distance}} error, errors that are corrected {{do not appear}} in the <b>transcribed</b> <b>text.</b> The following example will show you why this is an important class of errors to consider: ...|$|R
40|$|The aim of {{this thesis}} {{is to create a}} web-based {{annotation}} editor, which displays the audio waveform alongside the <b>transcribed</b> <b>text.</b> A waveform viewer library was developed, which uses HTML 5 canvas elements for rendering. The library allows scrolling and zooming of the waveform. Annotations are directly marked in the audio and the position of the <b>transcribed</b> <b>text</b> is synchronised with their location. The end goal is to replace an existing editor with the one being created. Therefore, a usability test was conducted to compare the two. The time needed to learn to use the application and to transcribe a short recording was reduced by 20 %. The waveform viewer library was released under an open-source license...|$|R
40|$|We {{describe}} and identify shortcomings in two statistics recently introduced to measure accuracy in text entry evaluations: the minimum string distance (MSD) error rate and keystrokes per character (KSPC). To overcome the weaknesses, a new framework for error analysis is developed and demonstrated. It combines {{the analysis of}} the presented text, input stream (keystrokes), and <b>transcribed</b> <b>text.</b> New statistics include a unified total error rate, combining two constituent error rates: the corrected error rate (errors committed but corrected) and the not corrected error rate (errors left in the <b>transcribed</b> <b>text).</b> The framework includes other measures including error correction efficiency, participant conscientiousness, utilised bandwidth, and wasted bandwidth. A text entry study demonstrating the new methodology is described...|$|R
5000|$|... in {{the above}} example, the {{incorrect}} character ('x') was deleted with a backspace ('<-'). Since these errors do {{not appear in the}} <b>transcribed</b> <b>text,</b> the MSD error rate is 0%. This is why there is the key strokes per character (KSPC) statistic.|$|R
40|$|Event {{materials}} from the BU Libraries Open Access Month 2017 Transcribe-a-thon for BU Recipe Boxes. Materials include the promotional image, user instructions, administrative instructions, json output of steps used in OpenRefine to clean exported data, and template for creating styled Word document of <b>transcribed</b> <b>text...</b>|$|R
5000|$|... #Caption: Harald's runestone, side A.See <b>transcribed</b> runic <b>text.</b>|$|R
5000|$|The Florentine {{bookseller}} Vespasiano da Bisticci recalled {{later in}} the century that Poggio had been a very fine calligrapher of lettera antica and di had <b>transcribed</b> <b>texts</b> to support himself— presumably, as Martin Davies points out— {{before he went to}} Rome in 1403 to begin his career in the papal curia.|$|R
5000|$|A {{study by}} Hayes and Chenoweth [...] {{looks at the}} role of articulatory {{suppression}} in working memory. The articulatory suppression condition group asked participants to repeat the word “tap” aloud to a metronome while they <b>transcribed</b> <b>text.</b> The control group had to tap their foot to the metronome as they <b>transcribed</b> the <b>text.</b> The {{results of the study}} indicated, that participants who were under articulatory suppression condition had a significant reduction in typing rate and significant {{increase in the number of}} uncorrected errors. In summary, this study shows how articulatory suppression interfered with verbal working memory.|$|R
2500|$|The slash (as a [...] "virgule") {{offset by}} spaces {{to either side}} is used to mark line breaks when <b>transcribing</b> <b>text</b> from a {{multi-line}} format into a single-line one. It is particularly common in quoting poetry, song lyrics, and dramatic scripts, formats where omitting the line breaks risks losing meaningful context. For example, when quoting Hamlet's soliloquy ...|$|R
40|$|This paper {{introduces}} {{standards used}} for <b>transcribing</b> <b>texts</b> of the Arabic Learner Corpus (ALC) from the hand-written sheets into an electronic format. It describes the transcription process which {{was performed by}} three transcribers, and the measurement conducted for keeping consistency in transcription. The paper concludes {{with a description of}} the corpus file produced based on the electronic format...|$|R
5000|$|The slash (as a [...] "virgule") {{offset by}} spaces {{to either side}} is used to mark line breaks when <b>transcribing</b> <b>text</b> from a {{multi-line}} format into a single-line one. It is particularly common in quoting poetry, song lyrics, and dramatic scripts, formats where omitting the line breaks risks losing meaningful context. For example, when quoting Hamlet's soliloquy ...|$|R
40|$|Spoken Document Retrieval (SDR) is a {{promising}} technology for enhancing {{the utility of}} spoken materials. After the spoken documents have been transcribed by using a Large Vocabulary Continuous Speech Recognition (LVCSR) decoder, a text-based ad hoc retrieval method can be applied directly to the transcribed documents. However, recognition errors will significantly degrade the retrieval perfor-mance. To address this problem, we have previously proposed a method that aimed {{to fill the gap}} between automatically <b>transcribed</b> <b>text</b> and correctly <b>transcribed</b> <b>text</b> by using a statistical translation technique. In this paper, we extend the method by (1) using neighboring context to index the target passage, and (2) applying a language modeling approach for document retrieval. Our experimental evaluation shows that context information can improve retrieval performance, and that the language modeling approach is effective in incorporating context information into the proposed SDR method, which uses a translation model. 1...|$|R
25|$|Barthel (1958) did not <b>transcribe</b> this <b>text,</b> {{though he}} later {{accepted}} it as authentic.|$|R
40|$|We {{describe}} {{a technique to}} analyse character-level errors in evaluations of text entry methods. Using an algorithm for sequence comparisons, we generate the set of optimal alignments between the presented and <b>transcribed</b> <b>text.</b> Percharacter errors, categorized as insertions, substitutions, or deletions, are obtained by analysing the alignments and applying a weighting factor. A detailed example using a real data set is given...|$|R
5000|$|The {{original}} version of OHMS synchronized <b>transcribed</b> <b>text</b> with time code in the audio/video, {{as well as}} providing a user map/viewer that connected search results of a transcript to the corresponding moments in the audio or video.OHMS designer Doug Boyd writes [...] "OHMS inexpensively and efficiently encodes transcripts of interviews and then connects the transcripts to the corresponding moments in the audio or video interview. [...] ".|$|R
40|$|We {{demonstrate}} that a generative model for object shapes can achieve {{state of the}} art results on challenging scene text recognition tasks, and with orders of magnitude fewer training images than required for competing discriminative methods. In addition to <b>transcribing</b> <b>text</b> from challenging images, our method performs fine-grained instance segmentation of characters. We show that our model is more robust to both affine transformations and non-affine deformations compared to previous approaches...|$|R
40|$|Here is {{presented}} a phonetic source model whose parameters, estimated from phonetically <b>transcribed</b> <b>texts,</b> reflect the non-stationary phoneme conditional probability which is proper {{of a given}} language. Such a model will give a priori knowledges about the allowed phonetic sequences probabilities for a very large vocabulary speech recognizer, where the lexical access is made after phonetic decoding. After {{a discussion about the}} probability estimation method, model features and performances are given...|$|R
50|$|Born in Sassoferrato (near Fano), Marche, {{he studied}} with Vittorino da Feltre in Mantua in 1443, then in Ferrara with Guarino. He also {{studied at the}} University of Padua. At the age of {{eighteen}} he {{spent some time in}} the household of the Englishman William Grey, later Lord High Treasurer, who was travelling in Italy and was a student of Guarino. He <b>transcribed</b> <b>texts</b> for Grey and accompanied him to Rome when he moved there.|$|R
40|$|The Speech Transcription Analysis Tool (STAT) is an {{open source}} tool for {{aligning}} and comparing two phonetically <b>transcribed</b> <b>texts</b> of human speech. The output analysis is a parameterized set of phonological differences. These differences are based upon a selectable set of binary phonetic features such as [voice], [continuant], [high], etc. STAT was initially designed to provide sets of phonological speech patterns in the comparisons of various English accents found in the Speech Accent Archiv...|$|R
30|$|The {{techniques}} {{developed for}} sentiment analysis needs {{to focus on}} the type of supporting application as they have different content style. Microblogging (twitter) and <b>transcribed</b> <b>text</b> is unstructured having more noise and therefore, lexicon-based techniques do not perform well (Katz et al. 2015). Similarly depending upon the nature of platform structural information can also be incorporated e.g. likes, share, retweets, hashtags etc. Ofek (2014) showed drop in accuracy when twitter data was used instead of Wall street journal content, even after including emoticons and hashtags (Ofek 2014). Machine learning techniques are more supportive to accommodate structural information e.g. meta-data as non-textual features (Katz et al. 2015). ML techniques depend on the feature set to which proximity and context based features can also be added. <b>Transcribed</b> <b>text</b> is used in Takeuchi and Yamaguchi (2014) and Cailliau and Cavet (2013) introducing new type of textual content. It also contain terms like “Emm” and “Aah” etc. that doesn’t have any meaning but are used while speaking. Similarly sentences are left incomplete and grammar is ignored. This opens new avenues to these techniques to deal with this type of content.|$|R
50|$|It uses 'web sources, {{electronic}} mailing lists, newsgroups, news feeds, and audio-video data.'. The audio-video {{is automatically}} <b>transcribed</b> into <b>text</b> by the ViTAP system.|$|R
40|$|This volume, in Spanish, {{is another}} welcome example of Weich-­‐Shahak’s {{continuing}} work documenting, disseminating and providing accurate information about Judeo-­‐Spanish song. Over eighty Moroccan Judeo-­‐Spanish romances are fully <b>transcribed</b> (<b>text</b> and music) and annotated, with both textual and musical variants indicated. The selections {{are taken from}} Weich-­‐Shahak’s 1976 -­‐ 1994 fieldwork in Israel, deposited at the National Sound Archives (NSA) of the Jewish National and University Library at the Hebrew University in Jerusalem; each item is identified with its NSA catalogue number...|$|R
50|$|Menotec was an {{infrastructure}} project {{funded by the}} Norwegian Research Council (2010-2012) {{with the aim of}} transcribing and annotating a corpus of Old Norwegian <b>texts.</b> The <b>transcribed</b> <b>texts</b> have been (and will be) published in the Medieval Nordic Text Archive, while the annotated texts have been published in the treebank of the PROIEL project, as well as being made accessible through the INESS portal. The funding for the project lasted for the three years 2010-2012, but the project work continues within new contexts.|$|R
40|$|International audienceThe GREYCmachine {{translation}} (MT) {{system is}} a slight evolution of the ALEPH machine translation system that participated in the IWLST 2005 campaign. It is a pure examplebased MT system that exploits proportional analogies. The training data used for this campaign were limited on purpose to the sole data provided by the organizers. However, the training data were expanded {{with the results of}} sub-sentential alignments. The system participated in the two classical tasks of translation of manually <b>transcribed</b> <b>texts</b> from Japanese to English and Arabic to English...|$|R
50|$|The {{manuscript}} {{was found}} in Antinoopolis (El-Sheikh Ibada) in Egypt. It was examined by Giovanni Mercati (1953) and Mario Naldini (1965). Mercati <b>transcribed</b> the <b>text</b> of the codex.|$|R
40|$|Abstract. The Polish text corpus was {{analysed}} to {{find information}} about phoneme statistics. We were {{especially interested in}} triphones as they are commonly used in many speech processing applications like HTK speech recogniser. An attempt to create the full list of triphones for Polish language is presented. A vast amount of phonetically <b>transcribed</b> <b>text</b> was analysed to obtain the frequency of triphone occurrences. A distibution of frequency of triphones occuring and other phenomena are presented. The standard phonetic alphabet for Polish and methods of providing phonetic transcriptions are described...|$|R
40|$|We analyze {{grammatical}} {{features of}} Macao Pidgin Portuguese (MPP) in a recently <b>transcribed</b> <b>text,</b> 澳門番語雜字全本 Collection of Assorted phrases in Macao Pidgin. The features discussed include pronouns, copulas, prepositions, TMA, complementation and serial verb constructions. Some features, notably the locative copula {{and use of}} pronouns, are shared with Chinese Pidgin English (CPE). Object marking with com resembles other Asian contact varieties of Portuguese. This work not only adds greatly to our knowledge of this poorly attested pidgin but also provides new evidence for the role MPP played in the genesis of CPE...|$|R
40|$|The Polish text corpus was {{analysed}} to {{find information}} about phoneme statistics. We were {{especially interested in}} triphones as they are commonly used in many speech processing applications like HTK speech recogniser. An attempt to create the full list of triphones for Polish language is presented. A vast amount of phonetically <b>transcribed</b> <b>text</b> was analysed to obtain the frequency of triphone occurrences. A distibution of frequency of triphones occuring and other phenomena are presented. The standard phonetic alphabet for Polish and methods of providing phonetic transcriptions are described. 1...|$|R
40|$|The GREYC machine {{translation}} (MT) {{system is a}} slight evolution of the ALEPH {{machine translation}} system that participated in the IWLST 2005 campaign. It is a pure examplebased MT system that exploits proportional analogies. The training data used for this campaign were limited on purpose to the sole data provided by the organizers. However, the training data were expanded {{with the results of}} sub-sentential alignments. The system participated in the two classical tasks of translation of manually <b>transcribed</b> <b>texts</b> from Japanese to English and Arabic to English. 1...|$|R
