98|43|Public
5000|$|Many-to-many model: In {{this model}} {{a pool of}} user threads is mapped to a pool of kernel threads. All system calls from a user <b>thread</b> <b>pool</b> are handled by the threads in their {{corresponding}} kernel <b>thread</b> <b>pool</b> ...|$|E
5000|$|Thread pools : A typical, {{general-purpose}} <b>thread</b> <b>pool</b> class {{might have}} a public addTask (...) method that adds a work item to an internal queue of tasks waiting to be done. It maintains a pool of threads that execute commands from the queue. The items in the queue are command objects. Typically these objects implement a common interface such as java.lang.Runnable that allows the <b>thread</b> <b>pool</b> to execute the command even though the <b>thread</b> <b>pool</b> class itself was written without any knowledge of the specific tasks for which it would be used.|$|E
5000|$|... {{implements}} spinlock, mutex, event, semaphore, {{thread and}} <b>thread</b> <b>pool</b> ...|$|E
50|$|Special {{cases of}} pools are {{connection}} <b>pools,</b> <b>thread</b> <b>pools,</b> and memory pools.|$|R
40|$|Abstract. <b>Thread</b> <b>pools</b> {{are often}} used as a pattern to {{increase}} the throughput and responsiveness of software systems. Implementations of <b>thread</b> <b>pools</b> may differ considerably from each other, which urges the need to analyze these differences in a formal manner. We use an object-oriented paradigm to model different <b>thread</b> <b>pools</b> {{in the context of}} the ASK system, an industrial communication platform. We use be-havioral interfaces, high-level behavioral specifications for the objects, as a starting-point for analysis. Based on these behavioral interfaces, func-tional aspects are modeled in Creol, a high-level modeling language for concurrent objects. It can be used to simulate the behaviors of the ASK system for debugging, testing, and formal verification. Based on the Creol model, we have constructed a real-time model of the ASK system in Up-paal. The real-time model has been used to check the schedulability of the <b>thread</b> <b>pools</b> with respect to the behavioral interfaces. ...|$|R
5000|$|<b>Thread</b> <b>pools</b> {{reduce the}} cost of {{spawning}} a new thread by reusing a limited number of threads.|$|R
5000|$|Support {{of various}} {{concurrency}} models: cooperative (single thread), <b>thread</b> <b>pool,</b> prefork ...|$|E
50|$|Typically, a <b>thread</b> <b>pool</b> executes on {{a single}} computer. However, thread pools are conceptually related to server farms in which a master process, which might be a <b>thread</b> <b>pool</b> itself, {{distributes}} tasks to worker processes on different computers, {{in order to increase}} the overall throughput. Embarrassingly parallel problems are highly amenable to this approach.|$|E
5000|$|... javax/enterprise/concurrent: This package {{provides}} the interfaces for interacting directly with Java EE's platform default managed <b>thread</b> <b>pool.</b> A higher-level executor service {{working on this}} same <b>thread</b> <b>pool</b> can be used optionally. The same interfaces {{can be used for}} user-defined managed thread pools, but this relies on vendor specific configuration and is not covered by the Java EE specification.|$|E
5000|$|Concurrent testing: run {{tests in}} {{arbitrarily}} big <b>thread</b> <b>pools</b> with various policies available (all methods {{in their own}} thread, one thread per test class, etc.), and test whether the code is multithread safe.|$|R
25|$|<b>Thread</b> <b>Pools</b> {{have been}} {{upgraded}} to support multiple pools per process, {{as well as}} to reduce performance overhead using thread recycling. It also includes Cleanup Groups that allow cleanup of pending thread-pool requests on process shutdown.|$|R
50|$|Further {{high-level}} threading facilities such as <b>thread</b> <b>pools</b> {{have been}} remanded {{to a future}} C++ technical report. They {{are not part of}} C++11, but their eventual implementation is expected to be built entirely on top of the thread library features.|$|R
5000|$|Support for {{multi-core}} architectures: all processing is multithreaded using a <b>thread</b> <b>pool</b> pattern.|$|E
5000|$|Executor {{interface}} decouples task execution from execution method; <b>thread</b> <b>pool</b> is {{a special}} executor ...|$|E
5000|$|... #Caption: A sample <b>thread</b> <b>pool</b> (green boxes) with waiting tasks (blue) and {{completed}} tasks (yellow) ...|$|E
40|$|A diploma thesis {{presenting}} a hardware-oriented parallelization of the C++ Standard Template Library. Strategies like <b>thread</b> <b>pooling</b> and <b>thread</b> affinity {{are used to}} enable speedups already for small input sizes and to best exploit the underlying hardware. Comparisons with existing approaches are used for evaluations...|$|R
40|$|The use of {{multithreading}} {{can enhance}} {{the performance of a}} software system. However, its excessive use can degrade the performance. For example, a thread-per-job approach might lead to a large amount of threads with increased associated overheads. In this paper we explore the use of the Parallelism Viewpoint to support one possible strategy {{to reduce the number of}} threads, namely finding candidate threads that can be replaced by <b>thread</b> <b>pooling.</b> <b>Thread</b> <b>pooling</b> reduces the large number of threads by reusing threads from an existing pool. As an example we analyze the threads of a precision critical parallelism-intensive electron microscope software system. Results show that the viewpoint provides a profound insight into the threading structure of the system, which helps in reducing the number of threads in a cost-effective way. And, the total time gain along with such reduction is encouraging. status: publishe...|$|R
40|$|The {{algorithms}} {{and execution}} policies {{specified by the}} Parallelism TS are designed to permit implementation on the broadest range of platforms. In addition to preemptive <b>thread</b> <b>pools</b> common on some platforms, implementations of these algorithms may {{want to take advantage}} of a number of mechanisms for parallel execution, including cooperative fibers, GPU threads, and SIMD vector units, among others. A suitabl...|$|R
5000|$|... 9.0: March 2013. Clients handled via <b>thread</b> <b>pool</b> {{instead of}} {{creating}} threads on the fly.|$|E
50|$|Tibero uses {{multiple}} working processes, {{and each}} working process uses multiple threads. The number of processes and threads can be changed. User requests are {{handled by the}} <b>thread</b> <b>pool,</b> but removes the overhead of the dispatcher, which handles input/output processing. The memory usage and number of OS processes can be reduced by using the <b>thread</b> <b>pool.</b> The number of simultaneous processes can be changed.|$|E
50|$|Execution of {{parallel}} tasks in Node.js is handled by a <b>thread</b> <b>pool.</b> The main thread call functions post tasks to the shared task queue that threads in the <b>thread</b> <b>pool</b> pull and execute. Inherently non-blocking system functions like networking translates to kernel-side non-blocking sockets, while inherently blocking system functions like file I/O {{run in a}} blocking way on its own thread. When a thread in the <b>thread</b> <b>pool</b> completes a task, it informs the main thread of this that in turn wakes up and execute the registered callback. Since callbacks are handled in serial on the main thread, long lasting computations and other CPU-bound tasks will freeze the entire event-loop until completion.|$|E
40|$|The current {{version of}} Java (J 2 SE 5. 0) {{provides}} {{a high level of}} support for concurreny in comparison to previous versions. For example, programmers using J 2 SE 5. 0 can now achieve synchronization between concurrent threads using explicit locks, semaphores, barriers, latches, or exchangers. Furthermore, built-in concurrent data structures such as hash maps and queues, built-in <b>thread</b> <b>pools,</b> and atomic variables are all at the programmer's disposal. We ar...|$|R
5000|$|Java {{supports}} <b>thread</b> <b>pooling</b> via [...] {{and other}} related classes. The executor service has {{a certain number of}} [...] "basic" [...] threads that are never discarded. If all threads are busy, the service allocates the allowed number of extra threads that are later discarded if not used for the certain expiration time. If no more threads are allowed, the tasks can be placed in the queue. Finally, if this queue may get too long, it can be configured to suspend the requesting thread.|$|R
40|$|Commercial {{off-the-shelf}} (COTS) middleware increasingly offers {{not only}} functional support for standard interfaces, {{but also the}} ability to optimize their resource consumption patterns. For example, a Real-time CORBA object request broker (ORB) permits application developers to configure server <b>thread</b> <b>pooling</b> policies. This flexibility {{makes it possible to}} use standard functional interfaces in applications where they were not applicable previously. However, the non-standard nature of the optimization mechanisms [...] -i. e., the "knobs and dials" [...] -against the very product-independence that standardized COTS interfaces are intended to provide...|$|R
5000|$|... #Caption: A sample <b>thread</b> <b>pool</b> (green boxes) with a queue (FIFO) {{of waiting}} tasks (blue) and a queue of {{completed}} tasks (yellow) ...|$|E
5000|$|Grand Central Dispatch (GCD) is a {{technology}} developed by Apple Inc. to optimize application support for systems with multi-core processors and other symmetric multiprocessing systems. It is an implementation of task parallelism {{based on the}} <b>thread</b> <b>pool</b> pattern. The fundamental idea is to move {{the management of the}} <b>thread</b> <b>pool</b> {{out of the hands of}} the developer, and closer to the operating system. The developer injects [...] "work packages" [...] into the pool oblivious of the pool's architecture. This model improves simplicity, portability and performance.|$|E
5000|$|... #Caption: A sample <b>thread</b> <b>pool</b> (green boxes) with task queues {{of waiting}} tasks (blue) and {{completed}} tasks (yellow), {{in the sense}} of task as [...] "unit of work".|$|E
40|$|In {{this paper}} we {{introduce}} a real-time {{extension of the}} concurrent object modeling language Creol {{which is based on}} duration statements indicating best and worst case execution times and deadlines. We show how to analyze schedulability of an abstraction of real-time concurrent objects in terms of timed automata. Further, we introduce techniques for testing the conformance between these behavioral abstractions and the executable semantics of Real-Time Creol in Real-Time Maude. As a case study we model and analyze the schedulability of <b>thread</b> <b>pools</b> in an industrial communication platform...|$|R
50|$|Another {{paradigm}} of thread usage {{is that of}} <b>thread</b> <b>pools</b> where a set number of threads are created at startup that then wait for a task to be assigned. When a new task arrives, it wakes up, completes the task {{and goes back to}} waiting. This avoids the relatively expensive thread creation and destruction functions for every task performed and takes thread management out of the application developer’s hand and leaves it to a library or the operating system that is better suited to optimize thread management. For example, frameworks like Grand Central Dispatch and Threading Building Blocks.|$|R
40|$|Modern {{programming}} languages like C # or Java are {{executed in}} a managed runtime and offer support for concurrency {{at a high}} level of abstraction. However, high-level parallel abstractions (e. g., <b>thread</b> <b>pools)</b> can merely be provided as a library since the underlying runtime (including the dynamic compiler) is aware of only a small set of low-level parallel abstractions. In this paper we discuss alternative abstractions of concurrency in the source language, the runtime, and the dynamic compiler. The abstractions enable a dynamic optimizing compiler to perform new code transformations that can adapt the granularity of parallel tasks according to the system resources. The presented optimizations allow the runtime to tune the execution of parallel code fully automatically. ...|$|R
50|$|On 29 February 2012, Oracle Corporation {{released}} GlassFish 3.1.2. This release includes {{bug fixes}} and new features including administration console enhancements, transaction recovery from a database and new <b>thread</b> <b>pool</b> properties.|$|E
50|$|The {{size of a}} <b>thread</b> <b>pool</b> is {{the number}} of threads kept in reserve for {{executing}} tasks. It is usually a tunable parameter of the application, adjusted to optimize program performance.|$|E
50|$|In {{computer}} programming, a <b>thread</b> <b>pool</b> is {{a software}} design pattern for achieving concurrency of execution {{in a computer}} program. Often also called a replicated workers or worker-crew model, a <b>thread</b> <b>pool</b> maintains multiple threads waiting for tasks to be allocated for concurrent execution by the supervising program. By maintaining a pool of threads, the model increases performance and avoids latency in execution due to frequent creation and destruction of threads for short-lived tasks. The number of available threads is tuned to the computing resources available to the program, such as parallel processors, cores, memory, and network sockets.|$|E
40|$|Over {{the past}} few years, {{mainstream}} computing has shifted from isolated personal comput-ers to networks of computational devices. As a result the client-server programming model has become increasingly important. These servers often have very strong performance and reliability criteria. We did an empirical study of different server architectures, developed a novel thread-per-connection to event-driven transformation, and developed a performance model to predict server performance under various server architectures. We considered four different server architectures: a thread-per-connection architecture built on a kernel-level thread implementation, a thread-per-connection architecture built on a user-level thread implementation, an automatically generated event-driven architecture, and a <b>thread</b> <b>pooled</b> architecture. Our empirical study consisted of evaluating the different server architectures across a suite of benchmarks consisting of an echo server with different traffic patterns, a time server,...|$|R
40|$|Commercial {{off-the-shelf}} (COTS) middleware increasingly offers distributed real-time and embedded (DRE) applications {{functional support}} for standard interfaces, {{along with the}} ability to optimize application resource utilization. For example, a Real-time CORBA object request broker (ORB) permits DRE application developers to configure server <b>thread</b> <b>pooling</b> policies. This flexibility makes it possible to use standard functional interfaces in applications where they were not applicable previously. However, the nonstandard nature of the optimization mechanisms [...] i. e., the "knobs and dials" [...] acts against the very product-independence that standardized COTS interfaces are intended to provide. This paper presents an architectural pattern called Quality Connector, which is a meta-programming technique that enables applications to specify the QoS they require from their infrastructure, and then manages the operations that optimize the middleware to implement those QoS requirements...|$|R
40|$|Java programmers {{are faced}} with {{numerous}} choices in man-aging concurrent execution on multicore platforms. These choices often have different trade-offs (e. g., performance, scalability, and correctness guarantees). This paper analyzes an additional dimension, energy consumption. It presents an empirical study aiming to illuminate the relationship be-tween the choices and settings of thread management con-structs and energy consumption. We consider three impor-tant thread management constructs in concurrent program-ming: explicit thread creation, fixed-size <b>thread</b> <b>pooling,</b> and work stealing. We further {{shed light on the}} energy/perfor-mance trade-off of three “tuning knobs ” of these constructs: the number of threads, the task division strategy, and the characteristics of processed data. Through an extensive ex-perimental space exploration over real-world Java programs, we produce a list of findings about the energy behaviors of concurrent programs, which are not always obvious. The study serves as a first step toward improving energy effi-ciency of concurrent programs on parallel architectures...|$|R
