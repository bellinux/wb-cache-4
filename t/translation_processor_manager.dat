0|38|Public
50|$|The Helios nucleus is {{composed}} of the kernel, libraries, loader service and the <b>processor</b> <b>manager</b> service.|$|R
50|$|The {{remaining}} {{components of the}} nucleus are the loader and <b>processor</b> <b>manager</b> servers. Once the kernel is loaded, these processes are bootstrapped, and they integrate the newly running node into the Helios network.|$|R
50|$|On January 19, 2000, Transmeta held {{a launch}} event at Villa Montalvo in Saratoga, California and {{announced}} {{to the world that}} it had been working on an x86 compatible dynamic binary <b>translation</b> <b>processor</b> named Crusoe. It also released an 18-page whitepaper describing the technology.|$|R
50|$|Key servers in Helios are the {{previously}} mentioned loader, <b>processor</b> <b>manager</b> and network server, {{together with the}} session manager, the window server and the file server. Others include the keyboard, mouse, RS232 and Centronics servers (built into the host I/O server), the null server (like Unix's /dev/null), and the logger server (like Unix's syslog).|$|R
5000|$|The Rmpi uses manager/workers {{parallelism}} {{where one}} main <b>processor</b> (<b>manager)</b> servers as {{the control of}} all other processors (workers). The manager/workers parallelism introduced around early 2000 is particularly efficient for large tasks in small clusters, for example, bootstrap method and Monte Carlo simulation in applied statistics since i.i.d. assumption is commonly used in most statistical analysis. In particular, task pull parallelism has better performance for Rmpi in heterogeneous computing environments.|$|R
5000|$|System Command <b>Processor,</b> a <b>Manager</b> {{to which}} {{commands}} {{defined by a}} server's host system, can be sent for execution.|$|R
40|$|This paper {{presents}} BOA (Binary-translation Optimized Architecture), {{a processor}} designed to achieve high frequency by using software dynamic binary <b>translation.</b> <b>Processors</b> for software binary translation are very conducive to high frequency {{because they can}} assume a simple hardware design. Binary translation eliminates the binary compatibility problem faced by other processors, while dynamic recompilation enables re-optimization of critical program code sections and {{eliminates the need for}} dynamic scheduling hardware. In this work we examine the implications of binary <b>translation</b> on <b>processor</b> architecture and software translation and how we support a very high frequency PowerPC implementation via dynamic binary translation. The design of processors with clock speeds of 1 GHz or more has been a topic of considerable research in both industry and academia. Binary translation presents an interesting alternative for processor design as it enables good performance on simple processor designs. <b>Processors</b> for binary <b>translation</b> achieve maximum performance by enabling high frequency processors while still exploiting available parallelism in the code. The effect of both of these optimizations is to minimiz...|$|R
5000|$|The first {{recorded}} {{use of the}} term in print was 1987, in PC Week 8 Sept. 107/2. [...] "Everybody has only one killer application. The secretary has a word <b>processor.</b> The <b>manager</b> has a spreadsheet." ...|$|R
50|$|Logical Partitions, LPARs, a {{standard}} function on ES/9000 processors, are a feature whereby IBM's <b>Processor</b> Resource/Systems <b>Manager</b> (PR/SM), allows different operating systems to run concurrently in separate logical partitions (LPARs), {{with a high}} degree of isolation.|$|R
40|$|The Local Query <b>Processors</b> <b>Manager</b> (LOP Manager) {{provides}} back-up {{support for}} information retrieval in the Composite Information System / Tool Kit (CIS/TK). The LQP Manager reroutes queries to alternate databases when the currently selected database becomes inaccessible. The mechanism used {{to achieve this}} rerouting groups together all the databases in the system with the same local schema. Alternate databases are selected from the same group as the that of the current database. Status tables as used to help {{keep track of the}} status of all the LOPs in the system. The LOP Manager also provides a downloading facility to incrementally download data from remote databases into local databases...|$|R
50|$|In {{mainframe}} computing a PR/SM (<b>Processor</b> Resource/System <b>Manager)</b> is a type-1 Hypervisor (a {{virtual machine}} monitor) that allows multiple logical partitions to share physical {{resources such as}} CPUs, I/O channels and direct access storage devices (DASD). It is integrated with all IBM System z machines.|$|R
40|$|Abstract: We {{introduce}} {{a novel approach}} that allows heterogeneous applications run together on a shared hosting plat-form, dynamically sharing the platform’s resources. The proposed approach has been validated by a proof-of-concept prototype which uses a global <b>processor</b> <b>manager</b> to distribute the platform’s processors among two (or more) heterogeneous applications, i. e. a Tomcat application server and a Globus grid middleware. Our evaluation demonstrates the benefit of including bidirectional communication between applications and the OS for efficiently managing the resources and preventing the degradation of an applications performance, especially when the hosting platform is fully overloaded. For the sake of simplicity, we have modified the applications so that they communicate with the resource manager, although other techniques {{can be applied to}} avoid these modifications. Running different applications in a shared platform and being able to assign priorities between them provides important benefits. ...|$|R
50|$|Along {{with the}} <b>translation</b> to {{different}} <b>processors,</b> the KRoC team have modified the compiler significantly, creating a compiler {{for what has}} become known as occam v2.5, and now as occam-pi.|$|R
50|$|The {{image to}} the right {{is an example of}} a {{compositional}} structure diagram. It contains the agents Order <b>Processor,</b> Supplier <b>Manager,</b> Supplier, Online Shop and an unnamed human agent. Agents are represented by rectangles. The dots and the shadow of the agent Supplier indicate that this agent has multiple instances, i.e. the Supplier Manager communicates with one or many suppliers. The so-called human agent represents a user interacting with the system.|$|R
50|$|Agents {{communicate}} via channels. The {{direction of}} information flow is either indicated by arrows (not {{shown in the}} picture), by a request-response-symbol (e.g. between Supplier Manager and Supplier) or omitted (e.g. between Order <b>Processor</b> and Supplier <b>Manager).</b>|$|R
40|$|Heterogeneous MultiProcessor System on Chips (MPSoCs) are viable {{implementation}} platforms for multimedia. However, optimisation of such platforms for performance, area footprint {{and energy}} consumption is a challenge. This thesis explores {{the paradigm of}} pipelined MPSoCs, and introduces design-time and run-time optimisations, {{in the form of}} an optimisation framework. This is the first time a framework has been proposed for optimisation of both the area footprint and energy consumption of a pipelined MPSoC. In a pipelined MPSoC, processors are organised into pipeline stages and are connected through First In First Out (FIFO) buffers. Application Specific Instruction set Processors (ASIPs) are used so that their customisation can be exploited to optimise the area footprint of a pipelined MPSoC. Each processor has a number of configurations, which are made up of differing custom instructions and cache configurations, and thus enable performance-area trade-off. This thesis proposes analytical models and estimation methods to aid quick design space exploration of pipelined MPSoCs, when there are billions of design points. Three analytical models are proposed to estimate the execution time, latency and throughput of a pipelined MPSoC, and two estimation methods are proposed to reduce the number of slow, full-system, cycle-accurate simulations. Researchers have used absolute accuracy and graphical fidelity to evaluate estimation models. Since there does not exist any metric to quantify fidelity, this thesis also proposes fidelity metrics to enable evaluation of estimation models in terms of not only the absolute accuracy, but also the fidelity. For design space exploration, two algorithms are proposed to select one configuration per processor so as to minimise the area footprint of a pipelined MPSoC under a latency or a throughput constraint. Experiments with a number of pipelined MPSoCs, executing JPEG encoder, JPEG decoder, MP 3 encoder and H. 264 encoder applications, showed that the analytical models and the estimation methods had a maximum absolute error of 18. 67 % and a minimum fidelity of 0. 88. The proposed analytical models and estimation methods resulted in simulation times of only several hours for design spaces containing up to 10 ^ 18 design points. The proposed exploration algorithms explored such large design spaces for Pareto fronts in less than seven minutes. Next, this thesis proposes a novel adaptive pipelined MPSoC architecture, where idle processors are transitioned into low-power states at run-time to reduce energy consumption. Two run-time managers are proposed for the adaptive pipelined MPSoC. Firstly, a run-time <b>processor</b> <b>manager</b> is proposed to manage the idle processors by either clock-gating or power-gating them. Secondly, a run-time power manager is proposed to select the most beneficial low-power state for an idle processor. Experiments with an H. 264 video encoder, designed for HD 720 p at 30 fps, showed that the <b>processor</b> <b>manager</b> provided an energy reduction of up to 34 % and 39 % when clock-gating and power-gating was used respectively with a minimum throughput of 28. 75 fps (which is within the specifications), compared to a pipelined MPSoC without run-time adaptability. Compared to the use of only the <b>processor</b> <b>manager,</b> the power manager reduced up to a further 40 % energy consumption with only an additional 0. 5 % degradation of the throughput. Lastly, this thesis proposes multi-mode pipelined MPSoCs, where multiple pipelined MPSoCs designed separately are merged into a single pipelined MPSoC with modes. A multi-mode pipelined MPSoC enables further reduction of the area footprint by sharing the processors and FIFO buffers. Three merging heuristics are proposed to find the maximal overlap between the individual pipelined MPSoCs, where the optimality of the heuristics is traded-off with their running times. The results indicated significant area footprint reduction &# 150; up to 62 % processor area, 57 % FIFO area and 59 % processor/FIFO ports &# 150; when compared to individual pipelined MPSoCs...|$|R
40|$|Most modern {{processors}} offer hardware {{support for}} monitoring performance events {{related to the}} interaction of applications with specific subunits of the processor [4, 7, 8, 9, 10]. The insight attained from performance monitoring counters is useful for both application programmers and processor manufacturers. Programmers typically employ them as {{a powerful tool for}} post-mortem analysis, identification and resolution of performance bottlenecks in their applications. Processor manufacturers, on the other hand, can collect valuable information on the performance of their products while the latter are used in production environments. This knowledge is then exploited during the design phase of future products. Our project, MOHCA (MOnitoring of Hardware for Continuous Adaptation) exploits performance monitoring counters in a different way. The counters are used for online monitoring of hardware events. The information collected is fed back to OS scheduling policies, providing them with awareness of the dynamically changing characteristics of the execution environment and allowing them to continuously adapt to these characteristics and reach more educated scheduling decisions. The scheduling policies have been implemented {{in the context of a}} <b>processor</b> <b>manager,</b> i. e. a server process which applies kernel-level schedulin...|$|R
50|$|Mega-Em — {{advanced}} emulation {{software that}} required {{at least a}} 386 <b>processor</b> and EMM <b>manager</b> with DPMI/VCPI support. Mega-Em emulated the 8-bit Sound Blaster circuitry for sound effects and the Roland MT-32/LAPC-I or Roland Sound Canvas/MPU-401 for music. It supported UltraMID TSR functionality.|$|R
5000|$|A {{manager is}} a self-identifying entity that {{provides}} an {{environment for the}} storage and processing of objects. A manager is encapsulated by the operations defined by its class. Together, a set of managers implements the overall processing environment of a DDM client or server. Manager entities at this level were inspired by the System Objects of the System/38 operating system. [...] The Managers defined by DDM include: Dictionary, Supervisor, Agent, Directory, File(s), Access Method(s), Relational Database, SQL Application Manager, Queue, Lock Manager, Security Manager, Recovery <b>Manager,</b> System Command <b>Processor,</b> Communication <b>Manager(s).</b>|$|R
50|$|When IBM {{introduced}} System/370 Extended Architecture on the 3081, {{customers were}} faced {{with the need to}} run a production MVS/370 system while testing MVS/XA on the same machine. IBM's solution was VM/XA Migration Aid, which used the new Start Interpretive Execution (SIE) instruction to run the virtual machine. SIE automatically handled some privileged instructions and returned to CP for cases that it couldn't handle. The <b>Processor</b> Resource/System <b>Manager</b> (PR/SM) of the later 3090 also used SIE.There were several VM/XA products before it was eventually supplanted by VM/ESA and z/VM.|$|R
40|$|Presented is an 8 -issue tree-VLIW {{processor}} {{designed for}} efficient support of dynamic binary <b>translation.</b> This <b>processor</b> confronts two primary {{problems faced by}} VLIW architectures: binary compatibility and branch performance. Binary compatibility with existing architectures is achieved through dynamic binary translation which translates and schedules PowerPC instructions {{to take advantage of}} the available instruction level parallelism. Efficient branch performance is achieved through tree instructions that support multi-way path and branch selection within a single VLIW instruction. The processor architecture is described, along with design details of the branch unit, pipeline, register file and memory hierarchy, for a 0. 25 micron standard-cell design. Performance simulation...|$|R
40|$|International audienceBugs or inefficiencies {{appearing}} in MPSoC platforms {{can have a}} very broad range of sources. However, due to the huge number of possible execution interleavings, reproducing the conditions of occurrence of a given error/performance issue is very difficult. One {{solution to this problem}} consists of tracing an execution for later analysis. This paper details the challenges and issues behind the production of a "well formed" trace in a transaction accurate virtual prototyping environment that uses dynamic binary <b>translation</b> as <b>processor</b> simulation technology. We propose a solution which requires modification of the dynamic compilation process, but stays non-intrusive, and demonstrate its feasibility on several examples...|$|R
50|$|Mailing labels {{identify}} the addressee, the sender {{and any other}} information which {{may be useful in}} transit. Many software packages such as word <b>processor</b> and contact <b>manager</b> programs produce standardized mailing labels from a data set that comply with postal standards. These labels may also include routing barcodes and special handling requirements to expedite delivery.|$|R
50|$|If the {{inequality}} is false, {{the processor}} generates a general protection (GP) fault. Otherwise, address <b>translation</b> continues. The <b>processor</b> then takes the 32-bit or 16-bit offset and compares {{it against the}} segment limit specified in the segment descriptor. If it is larger, a GP fault is generated. Otherwise, the processor adds the 24-bit segment base, specified in descriptor, to the offset, creating a linear physical address.|$|R
50|$|In {{order to}} make this <b>translation</b> more efficient, <b>processor</b> vendors {{implemented}} technologies commonly called SLAT. By treating each guest-physical address as a host-virtual address, a slight extension of the hardware used to walk a non-virtualized page table (now the guest page table) can walk the host page table. With multilevel page tables the host page table can be viewed conceptually as nested within the guest page table. A hardware page table walker can treat the additional translation layer almost like adding levels to the page table.|$|R
50|$|On 386 and {{subsequent}} <b>processors,</b> memory <b>managers</b> like QEMM might move {{the bulk of}} the code for a driver or TSR into extended memory {{and replace it with a}} small fingerhold that was capable of accessing the extended-memory-resident code. They might analyze memory usage to detect drivers that required more RAM during startup than they did subsequently, and recover and reuse the memory that was no longer needed after startup. They might even remap areas of memory normally used for memory-mapped I/O. Many of these tricks involved assumptions about the functioning of drivers and other components. In effect, memory managers might reverse-engineer and modify other vendors' code on the fly. As might be expected, such tricks did not always work. Therefore, memory managers also incorporated very elaborate systems of configurable options, and provisions for recovery should a selected option render the PC unbootable (a frequent occurrence).|$|R
40|$|This paper {{focuses on}} the {{determinants}} and effects of the participation of cattle producers in the supermarket channel, export processor channel, and traditional auction channel. It begins with {{the analysis of the}} market channels using qualitative data from 50 interviews of retailers, <b>processors,</b> auction market <b>managers,</b> and other key informants in Costa Rica and Nicaragua, two widely differing cases. It then analyzes patterns and supplies of producers by channel using farm level data (from the authors' survey of farmers in 2004) from 300 farms in the two countries. Industrial Organization, Livestock Production/Industries,...|$|R
40|$|When {{multiple}} ows including {{continuous media}} streams are simultaneously sent from a computer, allocation {{and management of}} both processor capacity and network bandwidth need tobeconsidered. We propose aframework of Quality of Service (QoS) management inside a sending host that controls execution of sending threads in consideration of utilization of processor capacity and network bandwidth. To distinguish from ows which require only best-e ort service, we call a ow which requires a speci c rate of service ow. " To guarantee QoS of such reserved ow both in processor- and network-intensive cases in a sending host, processor capacity reserve is allocated such {{that the rate of}} each reserved ow is attained and nonconforming data are policed before they are transmitted. <b>Processor</b> Capacity <b>Manager</b> and the network device driver exchange information in a cooperative manner to support the rate adaptive allocation of processor capacity reserve. In this paper, we describe design and implementation of our framework on RT-Mach. The results of performance evaluations demonstrate that our scheme performs well for full-duplex Ethernet...|$|R
2500|$|Supervisor mode {{is used by}} the kernel for {{low level}} tasks that need {{unrestricted}} access to hardware, such as controlling how memory is accessed, and communicating with devices such as disk drives and video display devices. User mode, in contrast, is used for almost everything else. Application programs, such as word <b>processors</b> and database <b>managers,</b> operate within user mode, and can only access machine resources by turning control over to the kernel, a process which causes a switch to supervisor mode. [...] Typically, the transfer of control to the kernel is achieved by executing a software interrupt instruction, such as the Motorola 68000 TRAP instruction. [...] The software interrupt causes the microprocessor to switch from user mode to supervisor mode and begin executing code that allows the kernel to take control.|$|R
40|$|This study {{established}} {{a conceptual framework}} for capturing the probabilistic nature of travel times {{with the use of}} existing traffic simulation models. The framework features three components: scenario manager, traffic simulation models, and trajectory <b>processor.</b> The scenario <b>manager</b> captures exogenous sources of variation in travel times through external scenarios consistent with real-world roadway disruptions. The traffic simulation models then produce individual vehicle trajectories for input scenarios while further introducing randomness that stems from endogenous sources of variation. Finally, the trajectory processor constructs distributions of travel time either for each scenario or for multiple scenarios to allow users to investigate scenario-specific impact on variability in travel times and overall system reliability. Within this framework, the paper discusses methodologies for performing scenario-based reliability analysis that focuses on (a) approaches to obtaining distributions of travel times from scenario-specific outputs and (b) issues and practices associated with designing and generating input scenarios. The proposed scenario-based approach was applied to a real-world network to show detailed procedures, analysis results, and their implications...|$|R
40|$|We examine {{implementations}} of {{a parallel}} {{branch and bound}} algorithm for coloring graphs on the Connection Machine CM- 5. Using the LogP model of parallel computation, an asynchronous model aiming to capture the communication costs {{of a family of}} architectures including the CM- 5, we examine three load balancing strategies: busy processors sending work randomly to other processors (Random); idle processors polling other processors for work (Polling); and matching busy processors with idle <b>processors</b> using a <b>manager</b> (MatchMaker). This is the first use of LogP for analyzing problems with unstructured communication patterns. The analysis divides the computation into three phases: start-up phases during which one or a few processors have work and need to distribute it quickly to all the other processors; busy phases during which there is plenty of work for all processors; and sparse phases during which the amount of work is limited. The analysis uses LogP to find ratios of time spent on comm [...] ...|$|R
40|$|Published in Journal of Aerospace Computing, Information, and Communication, Vol. 1, Issue 12, December 2004. This paper {{describes}} the design, development, {{and testing of}} Unmanned Aerial Vehicles (UAV) with highly automated search capabilities. Here, systems are able to respond on their own {{in the presence of}} considerable uncertainty utilizing an image <b>processor,</b> tracker/mapper, mission <b>manager,</b> and trajectory generation; and are used to complete a realistic benchmark reconnaissance mission. Subsequent to the selection of the search area, all functions are automated and human operator assistance is not required. The applications of these capabilities include reduction of operator workload in operational UAV systems, new UAV or guided-munition missions conducted without the assistance or availability of human operators, or the enhancement/augmentation of human search capabilities. The resulting system was able to search the 15 -building village automatically with speed comparable to a human operator searching on foot or with a conventional remotely piloted vehicle. It was successful in 6 of 7 actual flights over the McKenna Military Operations in Urban Terrain test site over two different days and a variety of lighting conditions and choice of desired building...|$|R
40|$|Illegal, {{unregulated}} and unreported (IUU) fishing {{refers to}} fishing activities {{that do not}} comply with national, regional, or international fisheries conservation or management legislation or measures. IUU fishing is complex and affects many stakeholders from the individual artisanal fisher in national waters, to fishing fleets in Exclusive Economic Zones (EEZ) and the High Seas, to fish <b>processor</b> and fisheries <b>managers</b> in developed and developing countries. Illegal fishing occurs in every ocean in the world, resulting {{in the loss of}} individual jobs and income, depletion of existing fish stocks, damage to the marine environment, and loss of state revenue. It affects activities both at sea and onshore, such as shipment, transportation, landing, importation and exportation, sale, and distribution of fish products. IUU fishing also has the potential {{to reduce the amount of}} fish available to subsistence fishers and communities who rely on fish as their staple diet. For example in Sierra Leone, fish provides approximately 65 % of the protein source consumed by the under-nourished population. Thus people's livelihoods and food security may be seriously threatened by the possibility of losing access to this food source as result of IUU fishing...|$|R
40|$|International audienceThe {{architecture}} of classic productivity software are {{moving from a}} traditional desktop-based software to a client server architecture hosted in the Cloud. In this context, web browsers behave as application containers that allow users to access a variety of Cloud-based applications and services, such as IDEs, Word <b>processors,</b> Music Collection <b>Managers,</b> etc. As a result, {{a significant part of}} these software run in the browser and accesses remote services. A lesson learned from development framework used in distributed applications is the success of pluggable architecture pattern as a core architecture concept, i. e., a Software Architecture that promotes the use of Pluggable Module to dynamically plug. Following this trend, this paper discusses the main challenges to create a component-based platform supporting the development of dynamically adaptable single web page applications. This paper also presents an approach called KevoreeJS based on models@runtime to control browser as component platform which address some of these challenges. We validate this work by presenting the design of a dashboard for sensor based system and highlighting the capacity of KevoreeJS to dynamically choose the placement of code on the server or client side and how KevoreeJS can be used to dynamically install or remove running components...|$|R
40|$|Trends in {{computer}} engineering place renewed emphasis on increasing parallelism and heterogeneity. The rise of parallelism adds an additional {{dimension to the}} challenge of portability, as different processors support different notions of parallelism, whether vector parallelism executing in a few threads on multicore CPUs or large-scale thread hierarchies on GPUs. Thus, software experiences obstacles to portability and efficient execution beyond differences in instruction sets; rather, the underlying execution models of radically different architectures may not be compatible. Dynamic compilation applied to data-parallel heterogeneous architectures presents an abstraction layer decoupling program representations from optimized binaries, thus enabling portability without encumbering performance. This dissertation proposes several techniques that extend dynamic compilation to data-parallel execution models. These contributions include: - characterization of data-parallel workloads - machine-independent application metrics - framework for performance modeling and prediction - execution model <b>translation</b> for vector <b>processors</b> - region-based compilation and scheduling We evaluate these claims via the development of a novel dynamic compilation framework, GPU Ocelot, with which we execute real-world workloads from GPU computing. This enables the execution of GPU computing workloads to run efficiently on multicore CPUs, GPUs, and a functional simulator. We show data-parallel workloads exhibit performance scaling, take advantage of vector instruction set extensions, and effectively exploit data locality via scheduling which attempts to maximize control locality. PhDCommittee Chair: Yalamanchili, Sudha; Committee Member: Lanterman, Aaron; Committee Member: Pande, Santosh; Committee Member: Richards, Mark; Committee Member: Shamma, Jef...|$|R
40|$|Emergency {{and routine}} {{management}} of animal bodies and (or) remains {{is a significant}} challenge and a major responsibility for the sustainability of agricultural, recreational, and natural animal systems. Strategies are critical {{in order to protect}} not only animal and human physical health, but more broadly, holistic health, which involves economic, social, and environmental components. In our times, we face the large-scale realities of biological pathogens, toxicological contaminants, radiological contamination, and natural disasters. Likewise important is the daily management of animal deaths and byproduct accumulation under normal and natural production. Research is necessary in developing effective response plans, as are the deliberative interactions among international, national, state, provincial, and local governments, public institutions, non-governmental organizations and the private sector. The 4 th International Symposium on Managing Animal Mortality and Health Risk and the resulting Symposium Proceedings enable animal emergency responders, planners, educators, researchers, animal caretakers, livestock producers, food animal <b>processors,</b> food systems <b>managers,</b> and researchers to more effectively manage mass mortality events, animal disease outbreaks, and (or) food contamination events, should they occur. Experts from around the world have contributed new knowledge from lessons learned during these experiences, from demonstrations of depopulation, disposal, and decontamination technologies, from simulating a disease outbreak on an international border, and from recent, related research. The impact of this event will be further extended with the post-symposium release of the Compendium of Related Materials and White Paper. Partnering among the individuals planning the 4 th International Symposium on Managing Animal Mortality and Health Risk, the U. S. Department of Homeland Security’s Science & Technology Directorate and the National Center for Foreign Animal Disease and Zoonotic Disease contributed to compilation of these resources and was greatly appreciated. In the future, this and broader working relationships will benefit the local, regional, national and international communities by capturing synergisms and efficiently using resources in research, education and policy-making efforts. Michigan State University was pleased to be the host institution for the 4 th International Symposium on Managing Animal Mortality and Health Risk. Homeland Security, FAZD Center, Cornell University, University of Maine Cooperative Extension, University of Michiga...|$|R
