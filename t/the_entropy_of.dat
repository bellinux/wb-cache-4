5421|10000|Public
5|$|Because each {{configuration}} {{has only}} a bounded number of predecessors, the evolution of Rule 90 preserves <b>the</b> <b>entropy</b> <b>of</b> any configuration. In particular, if an infinite initial configuration is selected by choosing the state of each cell independently at random, {{with each of the}} two states being equally likely to be selected, then each subsequent configuration can be described by exactly the same probability distribution.|$|E
5|$|Alternatively, if {{the density}} in the {{universe}} were equal to or below the critical density, the expansion would slow down but never stop. Star formation would cease with the consumption of interstellar gas in each galaxy; stars would burn out, leaving white dwarfs, neutron stars, and black holes. Very gradually, collisions between these would result in mass accumulating into larger and larger black holes. The average temperature of the universe would asymptotically approach absolute zero—a Big Freeze. Moreover, if the proton were unstable, then baryonic matter would disappear, leaving only radiation and black holes. Eventually, black holes would evaporate by emitting Hawking radiation. <b>The</b> <b>entropy</b> <b>of</b> the universe would increase {{to the point where}} no organized form of energy could be extracted from it, a scenario known as heat death.|$|E
5|$|Living organisms must {{obey the}} laws of thermodynamics, which {{describe}} the transfer of heat and work. The second law of thermodynamics states that in any closed system, the amount of entropy (disorder) cannot decrease. Although living organisms' amazing complexity appears to contradict this law, life is possible as all organisms are open systems that exchange matter and energy with their surroundings. Thus living systems are not in equilibrium, but instead are dissipative systems that maintain their state of high complexity by causing a larger increase in <b>the</b> <b>entropy</b> <b>of</b> their environments. The metabolism of a cell achieves this by coupling the spontaneous processes of catabolism to the non-spontaneous processes of anabolism. In thermodynamic terms, metabolism maintains order by creating disorder.|$|E
3000|$|... [...]. The {{position}} and momentum information <b>entropies</b> <b>of</b> D-dimensional quantum systems with central potentials, {{such as the}} isotropic harmonic oscillator and the hydrogen atom, depend on <b>the</b> <b>entropies</b> <b>of</b> <b>the</b> (hyper)spherical harmonics (see [2]). In turn, these entropies are expressed in terms <b>of</b> <b>the</b> <b>entropies</b> <b>of</b> <b>the</b> Gegenbauer (ultraspherical) polynomials [...]...|$|R
30|$|<b>The</b> {{information}} <b>entropy</b> <b>of</b> Fig.  3 is calculated. The {{results show}} that <b>the</b> information <b>entropy</b> <b>of</b> <b>the</b> original image is 3.05, <b>the</b> information <b>entropy</b> <b>of</b> <b>the</b> decrypted graph is 3.07, and <b>the</b> information <b>entropy</b> <b>of</b> <b>the</b> encrypted graph is 7.88. It {{can be seen from}} <b>the</b> results <b>of</b> information <b>entropy</b> that before and after encryption. <b>The</b> image information <b>entropy</b> is basically unchanged, but <b>the</b> information <b>entropy</b> <b>of</b> <b>the</b> encrypted image becomes 7.88, indicating that the encrypted image is close to a random signal and has good confidentiality.|$|R
5000|$|Whatever {{changes to}} dS and dSR occur in <b>the</b> <b>entropies</b> <b>of</b> <b>the</b> {{sub-system}} and the surroundings individually, {{according to the}} Second Law <b>the</b> <b>entropy</b> Stot <b>of</b> <b>the</b> isolated total system must not decrease: ...|$|R
5|$|Even more remarkably, {{there is}} a general set of laws known as black hole mechanics, which is {{analogous}} to the laws of thermodynamics. For instance, by the second law of black hole mechanics, the area of the event horizon of a general black hole will never decrease with time, analogous to <b>the</b> <b>entropy</b> <b>of</b> a thermodynamic system. This limits the energy that can be extracted by classical means from a rotating black hole (e.g. by the Penrose process). There is strong evidence that the laws of black hole mechanics are, in fact, a subset of the laws of thermodynamics, and that the black hole area is proportional to its entropy. This leads to a modification of the original laws of black hole mechanics: for instance, as the second law of black hole mechanics becomes part of the second law of thermodynamics, it is possible for black hole area to decrease—as long as other processes ensure that, overall, entropy increases. As thermodynamical objects with non-zero temperature, black holes should emit thermal radiation. Semi-classical calculations indicate that indeed they do, with the surface gravity playing the role of temperature in Planck's law. This radiation is known as Hawking radiation (cf. the quantum theory section, below).|$|E
25|$|It {{follows from}} the second law of {{thermodynamics}} that <b>the</b> <b>entropy</b> <b>of</b> {{a system that is}} not isolated may decrease. An air conditioner, for example, may cool the air in a room, thus reducing <b>the</b> <b>entropy</b> <b>of</b> the air of that system. The heat expelled from the room (the system), which the air conditioner transports and discharges to the outside air, always makes a bigger contribution to <b>the</b> <b>entropy</b> <b>of</b> the environment than the decrease of <b>the</b> <b>entropy</b> <b>of</b> the air of that system. Thus, the total of entropy of the room plus <b>the</b> <b>entropy</b> <b>of</b> the environment increases, in agreement with the second law of thermodynamics.|$|E
25|$|This last {{functional}} relationship characterizes <b>the</b> <b>entropy</b> <b>of</b> {{a system with}} sub-systems. It demands that <b>the</b> <b>entropy</b> <b>of</b> a system can be calculated from the entropies of its sub-systems if the interactions between the sub-systems are known.|$|E
40|$|The Hod {{conjecture}} {{proposes that}} the asymptotic quasinormal frequencies determine <b>the</b> <b>entropy</b> quantum <b>of</b> a black hole. Considering the Maggiore modification of this conjecture we calculate <b>the</b> <b>entropy</b> spectra <b>of</b> general, single horizon, asymptotically flat black holes in two-dimensional dilaton gravity. We also compute <b>the</b> <b>entropy</b> quanta <b>of</b> <b>the</b> two-dimensional Witten and AdS(2) black holes. Using {{the results for}} <b>the</b> <b>entropy</b> quanta <b>of</b> these two-dimensional black holes we discuss whether the produced values are generic. Finally we extend the results on <b>the</b> <b>entropy</b> spectra <b>of</b> other black holes. Comment: 13 page...|$|R
5000|$|As in the {{discrete}} case <b>the</b> joint differential <b>entropy</b> <b>of</b> a set {{of random}} variables is smaller or equal than <b>the</b> sum <b>of</b> <b>the</b> <b>entropies</b> <b>of</b> <b>the</b> individual random variables: ...|$|R
40|$|AbstractIn [G. T. Seidler, <b>The</b> topological <b>entropy</b> <b>of</b> homeomorphisms on {{one-dimensional}} continua, Proc. Amer. Math. Soc. 108 (1990) 1025 – 1030], G. T. Seidler {{proved that}} <b>the</b> topological <b>entropy</b> <b>of</b> every homeomorphism {{on a regular}} curve is zero. Also, in [H. Kato, Topological <b>entropy</b> <b>of</b> monotone maps and confluent maps on regular curves, Topology Proc. 28 (2) (2004) 587 – 593] <b>the</b> topological <b>entropy</b> <b>of</b> confluent maps on regular curves was investigated. In particular, it was proved that <b>the</b> topological <b>entropy</b> <b>of</b> every monotone map on any regular curve is zero. In this paper, furthermore we investigate <b>the</b> topological <b>entropy</b> <b>of</b> more general maps on regular curves. We evaluate <b>the</b> topological <b>entropy</b> <b>of</b> maps f on regular curves X {{in terms of the}} growth of the number of components of f−n(y)  (y∈X) ...|$|R
25|$|Thorne has {{investigated}} the quantum statistical mechanical origin of <b>the</b> <b>entropy</b> <b>of</b> {{a black hole}}. With his postdoc Wojciech Zurek, he showed that <b>the</b> <b>entropy</b> <b>of</b> a black hole is the logarithm {{of the number of}} ways that the hole could have been made.|$|E
25|$|The {{implication}} is that <b>the</b> <b>entropy</b> <b>of</b> a perfect crystal simply approaches a constant value.|$|E
25|$|It can {{be shown}} that for the output of Markov {{information}} sources, Kolmogorov complexity is related to <b>the</b> <b>entropy</b> <b>of</b> the information source. More precisely, the Kolmogorov complexity of the output of a Markov information source, normalized by {{the length of the}} output, converges almost surely (as the length of the output goes to infinity) to <b>the</b> <b>entropy</b> <b>of</b> the source.|$|E
40|$|In this paper, {{the fault}} {{detection}} in uncertain multivariate nonlinear non-Gaussian stochastic systems is further investigated. Entropy is introduced {{to characterize the}} stochastic behavior of the detection errors, and <b>the</b> <b>entropy</b> optimization principle is established for the fault detection problem. The principle is to maximize <b>the</b> <b>entropies</b> <b>of</b> <b>the</b> stochastic detection errors {{in the presence of}} faults and to minimize <b>the</b> <b>entropies</b> <b>of</b> <b>the</b> detection errors in the presence of disturbances. In order to calculate <b>the</b> <b>entropies,</b> <b>the</b> formulations <b>of</b> the joint probability density functions (JPDFs) of the stochastic errors are presented in terms of the known JPDFs of both the disturbances and the faults. By using the novel performance indexes and the formulations for <b>the</b> <b>entropies</b> <b>of</b> <b>the</b> detection errors, new fault detection design methods are provided for the considered multivariate nonlinear non-Gaussian plants. Finally, a simulation example is given to illustrate the efficiency of the proposed fault detection algorithm...|$|R
5000|$|... where H‡i are the enthalpies of {{activation}} and S‡i are <b>the</b> <b>entropies</b> <b>of</b> activation.|$|R
5000|$|... where [...] is <b>the</b> joint <b>entropy</b> <b>of</b> <b>the</b> {{variable}} set [...] and [...] is <b>the</b> conditional <b>entropy</b> <b>of</b> variable , given <b>the</b> rest.|$|R
25|$|Sackur–Tetrode entropy – <b>the</b> <b>entropy</b> <b>of</b> a {{monatomic}} classical {{ideal gas}} determined via quantum considerations.|$|E
25|$|In {{classical}} thermodynamics <b>the</b> <b>entropy</b> <b>of</b> {{the reference}} state {{can be put}} equal to zero at any convenient temperature and pressure. For example, for pure substances, one can take <b>the</b> <b>entropy</b> <b>of</b> the solid at the melting point at 1bar equal to zero. From a more fundamental point of view, the third law of thermodynamics {{suggests that there is}} a preference to take S = 0 at T = 0 (absolute zero) for perfectly ordered materials such as crystals.|$|E
25|$|Third law of thermodynamics: As {{a system}} {{approaches}} absolute zero, all processes cease and <b>the</b> <b>entropy</b> <b>of</b> the system approaches a minimum value.|$|E
40|$|This report {{proves that}} <b>the</b> {{differential}} <b>entropy</b> <b>of</b> particle mixtures {{is equal to}} -∞ unlike the wrong claim in the literature that is equal to <b>the</b> discrete <b>entropy</b> <b>of</b> particle weights. It then gives an upper bound for <b>the</b> differential <b>entropy</b> <b>of</b> <b>the</b> Gaussian mixtures {{which can be used}} in practical applications...|$|R
50|$|<b>The</b> joint <b>entropy</b> <b>of</b> {{a set of}} {{variables}} is {{greater than or equal}} to all <b>of</b> <b>the</b> individual <b>entropies</b> <b>of</b> <b>the</b> variables in the set.|$|R
40|$|AbstractWe prove {{a number}} of identities {{relating}} <b>the</b> sofic <b>entropy</b> <b>of</b> a certain class of non-expansive algebraic dynamical systems, <b>the</b> sofic <b>entropy</b> <b>of</b> <b>the</b> Wired Spanning Forest and <b>the</b> tree <b>entropy</b> <b>of</b> Cayley graphs of residually finite groups. We also show that homoclinic points and periodic points in harmonic models are dense under general conditions...|$|R
25|$|Lieb, E.H., Yngvason, J. (2003). <b>The</b> <b>Entropy</b> <b>of</b> Classical Thermodynamics, Chapter 8 of Entropy, Greven, A., Keller, G., Warnecke (editors) (2003).|$|E
25|$|In this section, <b>the</b> <b>entropy</b> <b>of</b> a {{mixed state}} is {{discussed}} {{as well as}} how it {{can be viewed as a}} measure of quantum entanglement.|$|E
25|$|In this description, as used by Gibbs, ε {{refers to}} the {{internal}} energy of the body, η refers to <b>the</b> <b>entropy</b> <b>of</b> the body, and ν is {{the volume of the}} body.|$|E
5000|$|... where [...] is <b>the</b> {{differential}} <b>entropy</b> <b>of</b> <b>the</b> Gaussian density {{with the}} same mean and variance as [...] and [...] is <b>the</b> differential <b>entropy</b> <b>of</b> : ...|$|R
30|$|In the following, {{we define}} <b>the</b> logical <b>entropy</b> <b>of</b> a {{dynamical}} system (Ω,S,μ,T). We will begin by defining <b>the</b> logical <b>entropy</b> <b>of</b> a measure preserving transformation T {{relative to a}} partition α. Later we shall remove the dependence on α to obtain <b>the</b> logical <b>entropy</b> <b>of</b> a dynamical system (Ω,S,μ,T). We first need the following standard analytic lemma.|$|R
40|$|We prove {{a number}} of identities {{relating}} <b>the</b> sofic <b>entropy</b> <b>of</b> a certain class of non-expansive algebraic dynamical systems, <b>the</b> sofic <b>entropy</b> <b>of</b> <b>the</b> Wired Spanning Forest and <b>the</b> tree <b>entropy</b> <b>of</b> Cayley graphs of residually finite groups. We also show that homoclinic points and periodic points in harmonic models are dense under general conditions. Comment: Comments welcome...|$|R
25|$|So entropy is an {{adiabatic}} invariant. The Nlog(N) term {{makes the}} entropy additive, so <b>the</b> <b>entropy</b> <b>of</b> two volumes of gas {{is the sum}} of the entropies of each one.|$|E
25|$|In Boltzmann's 1896 Lectures on Gas Theory, {{he showed}} that this {{expression}} gives {{a measure of}} entropy for systems of atoms and molecules in the gas phase, thus providing a measure for <b>the</b> <b>entropy</b> <b>of</b> classical thermodynamics.|$|E
25|$|When the {{expectation}} value is added over all modes in a cavity, this is Wien's distribution, and it describes the thermodynamic {{distribution of energy}} in a classical gas of photons. Wien's Law implicitly assumes that light is statistically composed of packets that change energy and frequency in the same way. <b>The</b> <b>entropy</b> <b>of</b> a Wien gas scales as the volume to the power N, where N {{is the number of}} packets. This led Einstein to suggest that light is composed of localizable particles with energy proportional to the frequency. Then <b>the</b> <b>entropy</b> <b>of</b> the Wien gas can be given a statistical interpretation as the number of possible positions that the photons can be in.|$|E
5000|$|It {{is easily}} {{shown that the}} {{efficiency}} [...] is maximum when the entire cyclic process is a reversible process. This means <b>the</b> total <b>entropy</b> <b>of</b> <b>the</b> net system (<b>the</b> <b>entropies</b> <b>of</b> <b>the</b> hot furnace, the [...] "working fluid" [...] of the Heat engine, and the cold sink) remains constant when the [...] "working fluid" [...] completes one cycle and returns to its original state. (In the general case, <b>the</b> total <b>entropy</b> <b>of</b> this combined system would increase in a general irreversible process).|$|R
40|$|It {{is pointed}} out that <b>the</b> <b>entropies</b> <b>of</b> structure, {{information}} and <b>the</b> effectiveness <b>entropy</b> between knowledge and organization structure are main <b>entropy</b> sources <b>of</b> supply chain network in this paper. Firstly, establish <b>entropy</b> model <b>of</b> fractal supply chain network organization structure. Secondly, fractal knowledge management network outside independently organization structure is set up. Moreover, knowledge and organization structure to have the whole similarity, and its entropy model is established. Furthermore, <b>the</b> effectiveness <b>entropy</b> model is builded. Finally, <b>the</b> <b>entropies</b> <b>of</b> structure, information and <b>the</b> effectiveness <b>entropy</b> are summed to research. And the model shows that fractal structure has prominent effect <b>of</b> dropping <b>entropy...</b>|$|R
3000|$|In the following, we {{will define}} <b>the</b> logical <b>entropy</b> <b>of</b> a {{dynamical}} system (A, μ, U [...]). First, we define <b>the</b> logical <b>entropy</b> <b>of</b> U {{relative to a}} partition X in (A, · [...]). Then we remove the dependence on X to get <b>the</b> logical <b>entropy</b> <b>of</b> a dynamical system (A, μ, U [...]). We will need the following proposition.|$|R
