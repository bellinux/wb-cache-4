34|0|Public
50|$|LM was {{to follow}} {{the path of a}} wire mounted onto a board with her right index finger. The test was {{performed}} under purely tactile (blindfolded), purely visual (glass over the board), or <b>tactile-visual</b> condition. The patient performed best in the purely tactile condition and very poorly in the visual condition. She did not benefit from the visual information in the <b>tactile-visual</b> condition either. The patient reported that the difficulty was between her finger and her eyes. She could not follow her finger with her eyes if she moved her finger too fast.|$|E
5000|$|Vocal-auditory channel.Refers to {{the idea}} that speaking/hearing is the mode humans use for {{language}}. When Hockett first defined this feature, it did not take sign language into account, which reflects the ideology of orality that was prevalent during the time [...] This feature has since been modified to include other channels of language, such as <b>tactile-visual</b> or chemical-olfactory.|$|E
40|$|Positron {{emission}} tomography in three-dimensional acquisition mode {{was used to}} identify the neural populations involved in <b>tactile–visual</b> cross-modal transfer of shape. Eight young male volunteers went through three runs of three different matching conditions: tactile–tactile (TT), <b>tactile–visual</b> (TV), and visual– visual (VV), and a motor control condition. Fifteen spherical ellipsoids were used as stimuli. By subtracting the different matching conditions and calcu-lating the intersections of statistically significant activations, we could identify cortical functional fields involved {{in the formation of}} visual and tactile representation of the objects alone and those involved in cross-modal transfer of the shapes of the objects. Fields engaged in representation of visual shape, revealed in VV–control, TV–control and TV–TT, were found bilaterally in th...|$|E
40|$|The {{majority}} of studies investigating interactions between vision and touch have typically explored single events, presenting one object at a time. The present study investigates how <b>tactile-visual</b> interactions affect competition between multiple visual objects in more dynamic cluttered environments. Participants {{searched for a}} horizontal or vertical line segment among distractor line segments of various orientations, all continuously changing color. Search times and search slopes were substantially reduced when the target color change {{was accompanied by a}} tactile signal. These benefits were observed even though the tactile signal was uninformative about the location, orientation, or color of the visual target. We conclude that <b>tactile-visual</b> synchrony guides attention in multiple object environments by increasing the saliency of the visual event. © 2008 Elsevier Ireland Ltd. All rights reserved...|$|E
40|$|The lateral-occipital <b>tactile-visual</b> area (LOtv) is {{activated}} when objects are recognized by vision or touch. We report {{here that the}} LOtv is also activated in sighted and blind humans who recognize objects by extracting shape information from visual-to-auditory sensory substitution soundscapes. Recognizing objects by their typical sounds or learning to associate specific soundscapes with specific objects do not activate this region. This suggests that LOtv {{is driven by the}} presence of shape information...|$|E
40|$|Cross-modal {{perception}} in <b>tactile-visual</b> modalities {{has been studied}} in the normal population. Developmental theories have suggested that cross-modal associations are naturally biased, and are stronger in children. This study aimed to test <b>tactile-visual</b> cross-modal interactions in adults and children and to see whether these interactions influence word naming. Forty-five adults and 39 pre-school children participated in two experiments. In experiment 1, participants either touched or looked at three pairs of 3 D objects - a round vs. angular object, a soft vs. hard object and a rough vs. smooth object. For each shape, they made object-luminance associations by placing objects in a black or white box. No {{differences were found between}} whether participants touched or looked at the objects. Strong preferences were found in adults to place the round, smooth and soft objects in the white box, but contrary to predictions and developmental theories, this was not found in children. Learned experience is proposed as an explanation to support these findings. Experiment 2 was a replication of Maurer, Pathman and Mondloch’s (2006) study on the ‘bouba/kiki’ paradigm, in which children were shown two 2 D shapes (one rounded and one angular) and asked which was called ‘bouba’. They found preferences to name the rounded shape ‘bouba’, and hypothesised that children were making cross-modal associations between sound and shape. We replicated Maurer et al. ’s study excluding their approach of drawing attention to the experimenter’s mouth as they said the nonsense words. Contrary to Maurer et al., we found that children showed no preferences to match ‘bouba’ to the rounded shape, suggesting that Maurer et al. ’s study reflected visual-visual uni-sensory mapping. This study has shown that <b>tactile-visual</b> cross-modality occurs in the normal population, and suggests that preferences in cross-modal associations may be stronger in adults than in children as a result of learning...|$|E
40|$|This paper {{presents}} the results of an evaluation of the weathering of different basaltic lithotypes (dense basalts, vesicular-amygdaloidal basalts, and basaltic breccias) from four basaltic flows of the Serra Geral Formation of the Itaipu Dam region. Samples were classified according to their degree of weathering based on analysis with a 200 X digital microscope and were subjected to pH, electrical conductivity, and point-load strength tests. The results show that pH and electrical conductivity values are effective for the evaluation of weathering, especially when <b>tactile-visual</b> classification does not provide an accurate evaluation of the rock's different degrees of weathering...|$|E
40|$|ABSTRACT—Multisensory {{integration}} in humans {{is thought to}} be essentially a brain phenomenon, but theories are si-lent as to the possible involvement of the peripheral ner-vous system. We provide evidence that this approach is insufficient. We report novel tactile-auditory and <b>tactile-visual</b> interactions in humans, demonstrating that a fa-cilitating sound or visual stimulus that is exactly syn-chronous with an excitatory tactile signal presented at the lower leg increases the peripheral representation of that excitatory signal. These results demonstrate that during multisensory integration, the brain not only continuously binds information obtained from the senses, but also acts directly on that information by modulating activity at pe-ripheral levels. We also discuss a theoretical framework to explain this novel interaction...|$|E
40|$|Sensory {{substitution}} devices (SSDs) systematically turn visual dimensions into {{patterns of}} tactile or auditory stimulation. After training, a user {{of these devices}} learns to translate these audio or tactile sensations back into a mental visual picture. Most previous SSDs translate greyscale images using intuitive cross-sensory mappings to help users learn the devices. However more recent SSDs have started to incorporate additional colour dimensions such as saturation and hue. Chapter two examines how previous SSDs have translated the complexities of colour into hearing or touch. The chapter explores if colour is useful for SSD users, how SSD and veridical colour perception differ and how optimal cross-sensory mappings might be considered. After long-term training, some blind users of SSDs report visual sensations from tactile or auditory stimulation. A related phenomena is that of synaesthesia, a condition where stimulation of one modality (i. e. touch) produces an automatic, consistent and vivid sensation in another modality (i. e. vision). <b>Tactile-visual</b> synaesthesia is an extremely rare variant that can shed light on how the <b>tactile-visual</b> system is altered when touch can elicit visual sensations. Chapter three reports a series of investigations on the tactile discrimination abilities and phenomenology of tactile-vision synaesthetes, alongside questionnaire data from synaesthetes unavailable for testing. Chapter four introduces a new SSD to test if the presentation of colour information in sensory substitution affects object and colour discrimination. Chapter five presents experiments on intuitive auditory-colour mappings across {{a wide variety of}} sounds. These findings are used to predict the reported colour hallucinations resulting from LSD use while listening to these sounds. Chapter six uses a new sensory substitution device designed to test the utility of these intuitive sound-colour links for visual processing. These findings are discussed with reference to how cross-sensory links, LSD and synaesthesia can inform optimal SSD design for visual processing...|$|E
40|$|Abstract We {{investigated}} crossmodal {{links between}} vision and touch for moving objects. In experiment 1, observers discriminated visual targets presented randomly {{at one of}} five locations on their forearm. Tactile pulses simulating motion along the forearm preceded visual targets. At short <b>tactile-visual</b> ISIs, discriminations were more rapid when the final tactile pulse and visual target were at the same location. At longer ISIs, discriminations were more rapid when the visual target was offset in the motion direction and were slower for offsets opposite to the motion direction. In experiment 2, speeded tactile discriminations at one of three random locations on the forearm were preceded by a visually simulated approaching object. Discriminations were more rapid when the object approached {{the location of the}} tactile stimulation and discrimination performance was dependent on the approaching object’s time to contact. These results demonstrate dynamic links in the spatial mapping between vision and touch...|$|E
40|$|According to {{proponents of}} the {{sensorimotor}} contingency theory of perception (Hurley 2 ̆ 6 Noë 2003, Noë 2004, O’Regan 2011), active control of camera movement {{is necessary for the}} emergence of distal attribution in <b>tactile-visual</b> sensory substitution (TVSS) because it enables the subject to acquire knowledge of the way stimulation in the substituting modality varies as a function of self-initiated, bodily action. This chapter, by contrast, approaches distal attribution as a solution to a causal inference problem faced by the subject’s perceptual systems. Given all of the available endogenous and exogenous evidence available to those systems, what is the most probable source of stimulation in the substituting modality? From this perspective, active control over the camera’s movements matters for rather different reasons. Most importantly, it generates proprioceptive and efference-copy based information about the camera’s body-relative position necessary {{to make use of the}} spatial cues present in the stimulation that the subject receives for purposes of egocentric object localization...|$|E
40|$|International audienceThis paper {{introduces}} the recently developed TexiCare device that aims at preventing pressure ulcers {{for people with}} spinal cord injury. This embedded device is aimed to be mounted on the user wheelchair. Its sensor is 100 % textile and allows the measurement of pressures at the interface between the cushion and the buttocks. It is comfortable, washable and low cost. It is connected to a cigarette-box sized unit that (i) measures the pressures in real time, (ii) estimates the risk for internal over-strains, and (iii) alerts the wheelchair user whenever necessary. The alert method {{has been defined as}} a result of a utility/usability/acceptability study conducted with representative end users. It is based on a <b>tactile-visual</b> feedback (via a watch or a smartphone for example) : the tactile modality is used to discreetly alarm the person while the visual modality conveys an informative message. In order to evaluate the usability of the TexiCare device, a paraplegic volunteer equipped his wheelchair at home during a six months period. Interestingly, the first results revealed bad habits such as an inadequate posture when watching TV, rare relief maneuvers, and the occurrence of abnormal high pressures...|$|E
40|$|Abstract: In <b>tactile-visual</b> sensory {{substitution}} (TVSS), {{images from}} {{a video camera}} are converted into patterns of vibrotactile stimulation that visually impaired subjects can use to perform tasks ordinarily guided by seeing. A main finding in early experiments conducted by Paul Bach-y-Rita and colleagues is that subjects equipped with a TVSS device engaged in distal attribution – attributed {{the cause of the}} stimulations they received to objects in the external, threedimensional scene – only when they had active control over how the camera moved. Subjects who received visual input passively experienced only a changing pattern of tactile stimulation. Why was this the case? According to proponents of the sensorimotor contingency theory, active control of the camera is necessary for the emergence of distal attribution because it enables the subject to acquire knowledge of the laws of sensorimotor contingency that govern use of the TVSS device. This chapter, by contrast, approaches distal attribution as a solution to a causal inference problem faced by the subject’s perceptual systems. Given all of the available endogenous and exogenous evidence available to those systems, what is the most probable source of stimulation in the substituting modality? From this perspective, active control over the camera’s movement...|$|E
40|$|In the {{well-known}} visual bias of auditory location (alias the ventriloquist effect), auditory and visual events presented in separate locations appear closer together, provided the presentations are synchronized. Here, {{we consider the}} possibility of the converse phenomenon: crossmodal attraction on the time dimension conditional on spatial proximity. Participants judged the order of occurrence of sound bursts and light flashes, respectively, separated in time by varying stimulus onset asynchronies (SOAs) and delivered either in the same or in different locations. Presentation was organized using randomly mixed psychophysical staircases, by which the SOA was reduced progressively until a point of uncertainty was reached. This point was reached at longer SOAs with the sounds in the same frontal location as the flashes than in different places, showing that apparent temporal separation is effectively longer in the first condition. Together with a similar one obtained recently in a case of <b>tactile-visual</b> discrepancy, this result supports a view in which timing and spatial layout of the inputs play to some extent inter-changeable roles in the pairing operation at the base of crossmodal interaction. © 2003 Elsevier Science B. V. All rights reserved. SCOPUS: cp. jinfo:eu-repo/semantics/publishe...|$|E
40|$|Our {{previous}} studies on scalp-recorded event-related potentials (ERPs) showed that somatosensory N 140 evoked by a tactile vibration in working memory tasks was enhanced when human subjects expected a coming visual stimulus {{that had been}} paired with the tactile stimulus. The results suggested that such enhancement represented the cortical activities involved in <b>tactile-visual</b> crossmodal association. In the present study, we further hypothesized that the enhancement represented the neural activities in somatosensory and frontal cortices in the crossmodal association. By applying independent component analysis (ICA) to the ERP data, we found independent components (ICs) located in the medial prefrontal cortex (around the anterior cingulate cortex, ACC) and the primary somatosensory cortex (SI). The activity represented by the IC in SI cortex showed enhancement in expectation of the visual stimulus. Such differential activity thus suggested the participation of SI cortex in the task-related crossmodal association. Further, the coherence analysis and the Granger causality spectral analysis of the ICs showed that SI cortex appeared to cooperate with ACC in attention and perception of the tactile stimulus in crossmodal association. The results of our study support with new evidence an important idea in cortical neurophysiology: higher cognitive operations develop from the modality-specific sensory cortices (in the present study, SI cortex) that are involved i...|$|E
40|$|Visual-tactile {{carry-over}} {{effects of}} global/local processing (attention to the whole, versus the details) {{have been reported}} under active touch conditions. We investigated whether carry-over effects of global/local processing also occur for passive touch and whether global/local processing has differential effects on affective and discriminative aspects of touch. Participants completed two tactile tasks involving pleasantness rating and discrimination {{of a set of}} tactile vibrations before and after completing a version of the Navon task that encouraged a focus on the global (n = 30), local (n = 30), or both (n = 30) features of a series of visual stimuli. In line with previous research suggesting a link between global processing and positive emotion, global processing increased pleasantness ratings of high (but not low) frequency tactile vibrations. Local processing did not improve the ability to discriminate between vibrations of different frequencies, however. There was some evidence of a <b>tactile-visual</b> carry-over effect; prior local processing of tactile vibrations reduced global precedence during the Navon task in the control group. We have shown carry-over effects of global versus local processing on passive touch perception. These findings provide further evidence suggesting that a common perceptual mechanism determines processing level across modalities and show {{for the first time that}} prior global processing affects the pleasantness of touch...|$|E
40|$|There have {{recently}} been considerable advances {{in our understanding of}} the neuronal mechanisms underlying multitasking, but the role of multimodal integration for this faculty has remained rather unclear. We examined this issue by comparing different modality combinations in a multitasking (stop-change) paradigm. In-depth neurophysiological analyses of event-related potentials (ERPs) were conducted to complement the obtained behavioral data. Specifically, we applied signal decomposition using second order blind identification (SOBI) to the multi-subject ERP data and source localization. We found that both general multimodal information integration and modality-specific aspects (potentially related to task difficulty) modulate behavioral performance and associated neurophysiological correlates. Simultaneous multimodal input generally increased early attentional processing of visual stimuli (i. e. P 1 and N 1 amplitudes) as well as measures of cognitive effort and conflict (i. e. central P 3 amplitudes). Yet, <b>tactile-visual</b> input caused larger impairments in multitasking than audio-visual input. General aspects of multimodal information integration modulated the activity in the premotor cortex (BA 6) as well as different visual association areas concerned with the integration of visual information with input from other modalities (BA 19, BA 21, BA 37). On top of this, differences in the specific combination of modalities also affected performance and measures of conflict/effort originating in prefrontal regions (BA 6) ...|$|E
40|$|The {{ability for}} {{touchscreen}} controls {{to move from}} two physical dimensions to three dimensions may soon be possible. Though solutions exist for enhanced tactile touchscreen interaction using vibrotactile devices, no definitive commercial solution yet exists for providing real, physical shape to the virtual buttons on a touchscreen display. Of the many next steps in interface technology, this paper concentrates on the path leading to tangible, dynamic, touchscreen surfaces. An experiment was performed that explores the usage differences between a flat surface touchscreen and one augmented with raised surface controls. The results were mixed. The combination of <b>tactile-visual</b> modalities had {{a negative effect on}} task completion time when visual attention was focused on a single task (single target task time increased by 8 % and the serial target task time increased by 6 %). On the other hand, the dual modality had a positive effect on error rate when visual attention was divided between two tasks (the serial target error rate decreased by 50 %). In addition to the experiment, this study also investigated the feasibility of creating a dynamic, three dimensional, tangible touchscreen. A new interface solution may be possible by inverting the traditional touchscreen architecture and integrating emerging technologies such as organic light emitting diode (OLED) displays and electrorheological fluid based tactile pins...|$|E
40|$|<b>Tactile-visual</b> {{links in}} spatial {{attention}} were examined by presenting spatially nonpredictive tactile cues {{to the left}} or right hand, shortly prior to visual targets in the left or right hemifield. To examine the spatial coordinates of any crossmodal links, different postures were examined. The hands were either uncrossed, or crossed so that the left hand lay in the right visual field and vice versa. Visual judgments were better on the side where the stimulated hand lay, though this effect was somewhat smaller with longer intervals between cue and target, and with crossed hands. Event-related brain potentials (ERPs) showed a similar pattern. Larger amplitude occipital N 1 components were obtained for visual events on the same side as the preceding tactile cue, at ipsilateral electrode sites. Negativities in the Nd 2 interval at midline and lateral central sites, and in the Nd 1 interval at electrode Pz, were also enhanced for the cued side. As in the psychophysical results, ERP cueing effects during the crossed posture were determined by the side of space in which the stimulated hand lay, not by the anatomical side of the initial hemispheric projection for the tactile cue. These results demonstrate that crossmodal links in spatial attention can influence sensory brain responses as early as the N 1, and that these links operate in a spatial frame-of-reference that can remap between the modalities across changes in posture...|$|E
40|$|Processing {{of a given}} {{target is}} {{facilitated}} when it is defined within the same (e. g., visual–visual), compared to a different (e. g., <b>tactile–visual),</b> perceptual modality as on the previous trial [Spence, C., Nicholls, M., & Driver, J. The cost of expecting events in the wrong sensory modality. Perception & Psychophysics, 63, 330 – 336, 2001]. The present {{study was designed to}} identify electrocortical (EEG) correlates underlying this “modality shift effect. ” Participants had to discriminate (via foot pedal responses) the modality of the target stimulus, visual versus tactile (Experiment 1), or respond based on the target-defining features (Experiment 2). Thus, modality changes were associated with response changes in Experiment 1, but dissociated in Experiment 2. Both experiments confirmed previous behavioral findings with slower discrimination times for modality change, relative to repetition, trials. Independently of the target-defining modality, spatial stimulus characteristics, and the motor response, this effect was mirrored by enhanced amplitudes of the anterior N 1 component. These findings are explained in terms of a generalized “modality-weighting” account, which extends the “dimension-weighting” account proposed by Found and Müller [Searching for unknown feature targets on more than one dimension: Investigating a “dimension-weighting” account. Perception & Psychophysics, 58, 88 – 101, 1996] for the visual modality. On this account, the anterior N 1 enhancement is assumed to reflect the detection of a modality change and initiation of the readjustment of attentional weight-setting from the old to the new target-defining modality in order to optimize target detection...|$|E
40|$|The last 50 {{years or}} so has seen great {{optimism}} concerning the potential of sensory substitution and augmentation devices to enhance {{the lives of those}} with (or even those without) some form of sensory loss (in practice, this has typically meant those who are blind or suffering from low vision). One commonly discussed solution for those individuals who are blind has been to use one of a range of <b>tactile-visual</b> sensory substitution systems that represent objects captured by a camera as outline images on the skin surface in real-time (what Loomis, Klatzky and Giudice, 2012, term general-purpose sensory substitution devices). However, despite the fact that touch, like vision, initially codes information spatiotopically, I would like to argue that a number of fundamental perceptual, attentional, and cognitive limitations constraining the processing of tactile information mean that the skin surface is unlikely ever to provide such general-purpose sensory substitution capabilities. At present, there is little evidence to suggest that the extensive cortical plasticity that has been demonstrated in those who have lost (or never had) a sense can do much to overcome the limitations associated with trying to perceive high rates of spatiotemporally varying information presented via the skin surface (no matter whether that surface be the back, stomach, forehead, or tongue). Instead, the use of the skin will likely be restricted to various special-purpose devices that enable specific activities such as navigation, the control of locomotion, pattern perception, etc...|$|E
40|$|Adaptive {{behavior}} {{relies on}} the integration of perceptual and motor processes. In this study, we aimed at characterizing the cerebral processes underlying perceptuo-motor interactions evoked during prehension movements in healthy humans, as measured by means of functional magnetic resonance imaging. We manipulated the viewing conditions (binocular or monocular) during planning of a prehension movement, while parametrically varying the slant of the grasped object. This design manipulates the relative relevance and availability of different depth cues necessary for accurate planning of the prehension movement, biasing visual information processing toward either the dorsal visual stream (binocular vision) or the ventral visual stream (monocular vision). Two critical nodes of the dorsomedial visuomotor stream [V 6 A (anterior visual area 6) and PMd (dorsal premotor cortex) ] increased their activity with increasing object slant, regardless of viewing conditions. In contrast, areas in both the dorsolateral visuomotor stream [anterior intraparietal area (AIP) and ventral premotor cortex (PMv) ] and in the ventral visual stream [lateral-occipital <b>tactile-visual</b> area (LOtv) ] showed differential slant-related responses, with activity increasing when monocular viewing conditions and increasing slant required the processing of pictorial depth cues. These conditions also increased the functional coupling of AIP with both LOtv and PMv. These findings {{support the view that}} the dorsomedial stream is automatically involved in processing visuospatial parameters for grasping, regardless of viewing conditions or object characteristics. In contrast, the dorsolateral stream appears to adapt motor behavior to the current conditions by integrating perceptual information processed in the ventral stream into the prehension plan...|$|E
40|$|Abstract Objective To {{evaluate}} {{the influence of}} caries-affected dentin on bond strength of a universal one-step and a multi-step etch-and-rinse adhesive system. Material and method Enamel of 60 third human molars with and without caries was removed to expose dentin. The teeth {{were randomly assigned to}} six groups: Single Bond Universal (3 M ESPE, St. Paul, MN, USA) in etch-and-rinse and in self-etch mode and Prime & Bond NT (Dentsply Co, Konstanz, Germany), all on sound and caries-affected dentin. Smear layer of the 30 sound dentin specimens was standardized by polishing with 600 -grit SiC paper under water cooling. Residual infected dentin of the 30 caries-affected specimens was removed with a number 4 CA carbide bur until no caries smooth tissue was detectable by <b>tactile-visual</b> inspection. Cylinders of a light cured composite resin (Filtek Z 350 XT, 3 M ESPE) were built up using starch tubes and microshear test was performed until failure. The data was analyzed by one-way ANOVA and Tukey’s post hoc test. Result Significant differences in microshear bond strength (μSBS) were observed for the caries-affected groups, but not for sound dentin. The μSBS of Single Bond Universal were not influenced by the application protocol on sound dentin, however they were lower in the caries-affected group with both application protocols. The μSBS for Prime & Bond NT was not influenced by the dentin conditions. Conclusion Caries-affected dentin decrease in bond strength of Single Bond Universal in comparison to sound dentin. The bond strength of Prime & Bond NT was not altered by substrate conditions...|$|E
40|$|Change {{blindness}} is {{the name}} given to people's inability to detect changes introduced between two consecutively-presented scenes when they are separated by a distractor that masks the transients that are typically associated with change. Change blindness has been reported within vision, audition, and touch, but has never before been investigated when successive patterns are presented to different sensory modalities. In the study reported here, we investigated change detection performance when the two to-be-compared stimulus patterns were presented in the same sensory modality (i. e., both visual or both tactile) and when one stimulus pattern was tactile while the other was presented visually or vice versa. The two to-be-compared patterns were presented consecutively, separated by an empty interval, or else separated by a masked interval. In the latter case, the masked interval could either be tactile or visual. The first experiment investigated visual-tactile and <b>tactile-visual</b> change detection performance. The results showed that {{in the absence of}} masking, participants detected changes in position accurately, {{despite the fact that the}} two to-be-compared displays were presented in different sensory modalities. Furthermore, when a mask was presented between the two to-be-compared displays, crossmodal change blindness was elicited no matter whether the mask was visual or tactile. The results of two further experiments showed that performance was better overall in the unimodal (visual or tactile) conditions than in the crossmodal conditions. These results suggest that certain of the processes underlying change blindness are multisensory in nature. We discuss these findings in relation to recent claims regarding the crossmodal nature of spatial attention...|$|E
40|$|Time {{perception}} is not precise. Signals encoded in different sensory modalities that arrive within about an 80 millisecond time window {{tend to be}} perceived as synchronous, whereas signals arriving outside this window typically seem asynchronous. However, the relative timings that seem synchronous are subject to change, a phenomenon called temporal recalibration. Currently, it is thought that temporal recalibration is indicative of changes in the speed at which information is encoded in the brain. This thesis explores another possibility: that temporal recalibration results from adopting flexible criteria for deciding what constitutes synchrony. Critical predictions for the latter hypothesis are that conflicting criteria can be maintained for different combinations of sensory signals, and that the criteria adopted for one combination of signals need not impact a novel combination. Two experiments were conducted to test these proposals. Participants adapted to alternating trains of bi-modal signal combinations (i. e., audio-visual and visual-tactile) with the audio and tactile signals offset from visual signals in opposite directions (if audio signals led, tactile signals lagged, or vice versa). Subsequently participants were presented with different combinations of cross modal tests (audio-visual, <b>tactile-visual,</b> or audio-tactile) at a range of offsets, and asked if the test signals seemed synchronous. Results showed that synchrony perception shifted in opposite directions for the two adapted combinations of cross modal signal, and that this had no impact for the non-adapted combination. These findings suggest that temporal recalibration is not induced by slowing or speeding sensory analyses, but by adopting flexible criteria for different combinations of sensory signal...|$|E
40|$|We {{investigated}} {{the effects of}} seen and unseen within-hemifield posture changes on crossmodal visual-tactile links in covert spatial attention. In all experiments, a spatially nonpredictive tactile cue {{was presented to the}} left or the right hand, with the two hands placed symmetrically across the midline. Shortly after a tactile cue, a visual target appeared at one of two eccentricities within either of the hemifields. For half of the trial blocks, the hands were aligned with the inner visual target locations, and for the remainder, the hands were aligned with the outer target locations. In Experiments 1 and 2, the inner and outer eccentricities were 17. 5 o and 52. 5 o, respectively. In Experiment 1, the arms were completely covered, and visual up-down judgments were better when on the same side as the preceding tactile cue. Cueing effects were not significantly affected by hand or target alignment. In Experiment 2, the arms were in view, and now some target responses were affected by cue alignment: Cueing for outer targets was only significant when the hands were aligned with them. In Experiment 3, we tested whether any unseen posture changes could alter the cueing effects, by widely separating the inner and outer target eccentricities (now 10 o and 86 o). In this case, hand alignment did affect some of the cueing effects: Cueing for outer targets was now only significant when the hands were in the outer position. Although these results confirm that proprioception can, in some cases, influence <b>tactile-visual</b> links in exogenous spatial attention, they also show that spatial precision is severely limited, especially when posture is unseen. © 2014 Psychonomic Society, Inc...|$|E
40|$|ABSTRACT: Hippocampal place fields show {{remapping}} between {{environments that}} contain sufficiently different contextual features, {{a phenomenon that}} may reflect a mechanism for episodic memory formation. Previous {{studies have shown that}} place fields remap to changes in the configuration of visual landmarks in an environment. Other experiments have demonstrated that remapping can occur with experience, even when the visual features of an environment remain stable. A special case of remapping may be trajectory coding, the tendency for hippocampal neurons to exhibit different firing rates depending upon recently visited or upcoming spatial locations. To further delineate the conditions under which different task features elicit remapping, we recorded from place cells in dorsal CA 1 of hippocampus while rats switched between tasks that differed in memory demand and task structure; continuous spatial alternation (CA), delayed spatial alternation (DA), and <b>tactile-visual</b> conditional discrimination (CD). Individual hippocampal neurons and populations of simultaneously recorded neurons showed coherent remapping between CA and CD. However, task remapping was rarely seen between DA and CD. Analysis of individual units revealed that even though the population retained a coherent representation of task structure across the DA and CD tasks, the majority of individual neurons consistently remapped at some point during recording sessions. In contrast with previous studies, trajectory coding on the stem of the T-maze was virtually absent during all of the tasks, suggesting that experience with multiple tasks in the same environment reduces the likelihood that hippocampal neurons will represent distinct trajectories. Trajectory coding was, however, observed during the delay period of DA. Whether place fields change in response to task or trial type or remain stable within the same environment may depend on which aspects of the context are most salient or relevant to behavior. VC 2012 Wiley Periodicals, Inc...|$|E
40|$|This {{document}} is copyrighted by the American Psychological Association {{or one of}} its allied publishers. This article is intended solely for the personal use of the individual user and {{is not to be}} disseminated broadly. Working memory depends on communication between the hippocampus and the prefrontal cortex (PFC); however, the neural circuitry that mediates interactions between these brain areas has not been well characterized. Two candidate structures are the thalamic reuniens (RE) and rhomboid (Rh) nuclei, which are reciprocally connected with both the hippocampus and PFC. These known anatomical connections suggest that RE/Rh may be involved in mediating hippocampal-prefrontal communication, and therefore may be critical for working memory processing. To test the hypothesis that RE/Rh are necessary for working memory, we trained separate groups of rats to perform 1 of 2 tasks in a T-maze. The first task was a working memory-dependent conditional discrimination (CDWM) task, and the second task was a nonworking memory-dependent conditional discrimination (CD) task. These tasks took place in the same maze, featured the same number of trials, and utilized the same cue (a <b>tactile-visual</b> maze insert). After rats had learned either task, RE/Rh were transiently inactivated with the GABA A receptor agonist muscimol, and performance was assessed. RE/Rh inactivation caused performance deficits on the CDWM task, but not the CD task. This result suggests that RE/Rh are a necessary component of working memory task performance, which is also thought to depend on the hippocampal-prefrontal circuit. RE/Rh inactivation did not cause a performance deficit on the CD task, suggesting that RE/Rh have dissociable contributions to working memory-dependent and nonworking memory-dependent tasks, independently of the known contributions of these 2 thalamic nuclei to the sensorimotor and attention-related aspects of other memory tasks...|$|E
40|$|Neuroplasticity is a {{mechanism}} whereby the brain changes its configuration and function through experience. Short-term learning (i. e. minutes to hours) {{is associated with}} early phases of neuroplasticity whereby the cortical responses increase to common stimuli, and underlies long-term learning (i. e. days to weeks). Tactile sensation is an important sense, therefore if it became compromised it would be valuable to {{have an understanding of}} the neural mechanisms that underlie tactile short-term learning, and other means to promote learning, such as the introduction of a second modality. Having more knowledge in the area of somatosensory learning could then provide the means leading to long-term learning and potential recovery of function after brain injury such as stroke. The focus of this thesis was to research the role of visual information on short-term somatosensory learning, and to understand the electrophysiological mechanisms that are associated with this modulation of learning within a single testing session. The methodology consisted of learning Morse code tactile patterns corresponding to English letters, and was broken up into two experiments. The objective of the first experiment was to determine the functional benefit to performance of the temporal and spatial coupling of tactile and visual stimuli, and the second experiment was used to determine the electrophysiological mechanisms associated with the modulation of somatosensory processing by visual stimulation. Given that there is a quantifiable measurement of learning, we hypothesized that <b>tactile-visual</b> cross-modal coupling will increase the learning outcome and provide functional benefit. It has been shown (Eimer et al., 2001) that presenting a visual stimulus within the same spatial site as the corresponding tactile stimulus will enhance the measurable components, and better the behavioural performance (Ohara et al., 2006). The current results demonstrated that visual-tactile cross-modal association can {{have a positive effect on}} learning over a short period of time, and that presenting a visual stimulus prior to a tactile stimulus may be beneficial to performance during the early stages of learning. Also, the results from the second experiment demonstrated an elevated and prolonged tactile P 100, and a noticeably absent N 140 component when tactile information was presented before visual information. Further research, extending from this thesis, is needed to advance understanding of the performance and electrophysiological outcomes of visual-tactile cross-modal associations. The findings of this study give insight into the performance and electrophysiological effects involved with short-term somatosensory learning, specifically how the manipulation of a visual stimulus, both spatially and temporally, can affect tactile learning as indicated through behavioural performance, and affect the electrophysiological mechanisms involved with somatosensory processing...|$|E
40|$|A presente dissertação insere-se nos estudos de ensino de desenho no âmbito da invisualidade e apresenta uma proposta de procedimentos elaborados a partir de um conjunto de desenhos realizados por crianças standards. Para tanto, partiu-se do pressuposto de que crianças cegas constroem esquemas gráficos após um aprendizado e exercícios de elementos de desenho, ou seja, de linhas e figuras geométricas básicas, e que podem com isto, alcançar resultados semelhantes aos desenhos de crianças standards. Sendo assim, no contexto desta proposta, os elementos de desenho serão usados para construir o componente de desenho, que por sua vez, vai construir o esquema gráfico do objeto como um todo. Para o embasamento teórico, abordou-se os aspectos comunicacionais do desenho, bem como o processo da representação gráfica na infância, a partir de estudos de B. Darras, S. G. Coutinho e M. L. B. Duarte. Ao que se refere à invisualidade, foram estudadas as metodologias de L. Bardisa, M. L. B. Duarte e F. J. de Lima, sendo que as duas primeiras tratam do ensino do desenho para crianças cegas, e a última do reconhecimento de figuras bidimensionais tangíveis. Os dados levantados na pesquisa de campo, realizada com quatro alunos cegos, apresentaram resultados que corroboram no sentido de revelar que o uso de imagens tátil-visuais, objetos naturais e maquetes tridimensionais contribuem como mediadores no processo de ensino e aprendizagem nessa área. O estudo realizado em oito sessões individuais de desenho demonstrou que os alunos passaram a construir esquemas gráficos semelhantes aos realizados por crianças standards, sugerindo uma possível aplicabilidade do métodoThe current {{dissertation}} {{is inserted}} in drawing s teaching {{studies in the}} non visuality scope and presents a proposal of procedures elaborated {{from a group of}} drawings done by standard kids. For that, it started from the presuppose that blind children build graphic schemes after an education and drawing s elements exercises, it means, lines and basic geometrical figures, and with that they may reach similar results to standard kids drawings. Thereby, in this proposal s context, the drawings elements will be used to build the component of drawing, which will build the graphic scheme of the object as a whole. To the theoretical base, it was approached the communicational aspects of the drawing, as well as the process of graphical representation in childhood, from the studies of B. Darras, S. G. Coutinho and M. L. B. Duarte. What refers to non visuality, L. Bardisa, M. L. B. Duarte and F. J. de Lima s methodologies were studied, and the first two ones talk about the teaching of the drawing to blind children, and the last one talks about the recognizing of tangible bi-dimensional figures. The data raised in this field research, performed with four blind students, presented results that helped in the sense of revealing that the use of images <b>tactile-visual,</b> natural objects and tri-dimensional scale models contributed as mediators in the process of education and learning in this context. The study performed in eight individual drawing sessions showed that the students started to build graphic schemes similar to the ones done by standard children, suggesting a possible applicability of the metho...|$|E
40|$|This thesis {{examines}} {{some aspects}} of visual and tactile perception in young mongol and normal children of similar mental ages. In Chapter 1 the mongol person is introduced {{as a member of}} a discrete group which is well defined clinically and which is characterised by several chromosome aberrations. It is seen that the mongol can be identified at birth on the basis of clinical characteristics and his condition can be confirmed by chromosome analysis. Mongols therefore provide the research worker with the opportunity to study the very early development of a relatively homogeneous group of mentally handicapped children. In the remainder of Chapter 1 the development of the mongol is considered. Four aspects of his development are examined: intellectual ability, motor ability-, verbal ability and perceptual ability. It is argued that the areas of visual and tactile perception provide the most exciting prospects for research with the young mongol, since the visual abilities of the adult mongol seem to be similar to those of persons of the same mental age, whereas his tactile abilities seem to be deficient. Therefore in Chapter 2 the development of visual and tactile abilities of normal children and the ways in which these are studied in the young normal child are reviewed. It is seen that the normal child is able to perceive and remember many features of visually and tactually presented patterns from an early age. Chapter 3 describes the subject populations of mongol and normal children who took part in the experiments. It is demonstrated that the sample of mongol children was fairly representative of the mongol population in terms of birth weight, parental ages, birth order and number and age of siblings, although, the effects of maternal age and birth order were smaller than reported in other studies. It is proposed that these differences could be accounted for by the observed shift towards earlier childbearing ages in the general population. The first experiment (Experiment 1) is described in Chapter 4. Normal and mongol children were matched for mental age, sex and social class, and their visual exploration and memory of simple two dimensional patterns were compared. There was little difference in the way in which the mongol and normal children responded visually to two such patterns. Both groups showed less visual interest when the two patterns were identical compared with when they were of different shapes and colours. In a similar way, the children's interest decreased when one pair of patterns was presented repeatedly and increased following a change in either the positions of the two different patterns or the shape and colour of the two identical patterns. It was also found that the older mongol and normal children made more eye movements than the younger children did. This experiment therefore established a baseline for the study of visual perception in young mongol children. In Chapter 5 (Experiment 2) the finding often reported in the literature that the adult mongol has a tactile deficit was investigated in the young mongol. For procedural reasons a direct test of the ability of the young mongol child to distinguish between three dimensional objects by touch alone was not possible. Instead two <b>tactile-visual</b> cross-modal tasks and two visual within-modal tasks using a pair of ellipsoids and a pair of cubes were employed. The mongol children were matched with normal children for mental age, sex and social class. There were two age groups with mean mental ages of about 12 and 17 months. The mongol children performed at chance level on both <b>tactile-visual</b> cross-modal tasks whilst the normals performed above chance level with at least one pair of objects. The older mongols performed above chance level on the visual within- modal task with the ellipsoids: therefore their failure on the cross-modal task with this pair is due either to a tactile deficit or to a failure to integrate tactile and visual information. The chance level performance of the younger mongols on the within-modal tasks could account for their poor performance on the cross- modal tasks. This second experiment demonstrated that the young mongol child may have some form of tactile deficit and also showed that his ability to distinguish visually between three dimensional objects is inferior to that of the normal child of similar mental age. The normal child is capable of distinguishing visually between three dimensional objects; also his ability to perform above chance level on a <b>tactile-visual</b> cross-modal task with different pairs of objects increases as he gets older. The next experiment (Experiment 3) which is described in Chapter 6 investigated the possibility that the mongol T s poor visual discrimination of three dimensional objects was a result of the way in which he looked at them. Normal and mongol children were presented on successive trials with two dimensional patterns which could not be touched, and with three dimensional patterns which could be touched. A number of measures were taken of the way in which the children responded to the patterns. These were the total length of fixation, the number of fixations, the number of comparisons made between the patterns, the number of repeated fixations of one pattern, the times taken to fixate both patterns, the average fixation length, the lengths of the first fixation to both patterns and the amount of time which the children touched the three dimensional patterns. Both groups of children showed greater visual interest in the three dimensional patterns than they did in the two dimensional patterns. However, the normal children, especially at a mean mental age of six and a half months, fixated the three dimensional patterns in a different way from the way in which they fixated the two dimensional patterns. In particular these younger normal children made more comparisons between three dimensional patterns than they did between two dimensional patterns. The younger mongol children made fewer comparisons between three dimensional patterns than did the younger normal children. However, the mongol children, but not the normal children, made more repetitions of fixation to two dimensional patterns than to three dimensional patterns. The normal children made more repetitions of fixation to three dimensional patterns than did the mongol children. Thus this experiment provided some evidence for a difference in the way in which normal and mongol children look at three dimensional patterns, and confirmed the similarity in their visual responses to two dimensional patterns. The normal children seemed to be more active perceptually, particularly when they were looking at three dimensional patterns, since they moved their eyes more extensively than did the mongols. One possible problem with this experiment was that the three dimensional patterns could be touched but the two dimensional patterns could not. The next experiment (Experiment 4) which is reported in Chapter 7, investigated the possibility that the difference in the tactile abilities of the mongol and the normal children which was found in Experiment 2, could account for the difference in the ways in which the mongol and the normal children fixated the three dimensional patterns in Experiment 3, in that three dimensional patterns offer more tactile information than do two dimensional patterns. This possibility was tested in this experiment (Experiment 4) by allowing the children to touch and look at the patterns on half of the trials, and on the remaining trials only allowing them to look at the patterns. On each trial two patterns were presented side by side, and these were sometimes both two dimensional, sometimes both three dimensional and sometimes on. e of each. The measures were the same as those scored in Experiment 3. The results failed to replicate the difference found in Experiment 3 in the ways in which the mongol and normal children fixated two and three dimensional patterns. However, this may have been due to the fact that the younger children in Experiment 4 were older than the younger group in Experiment 3 : it was in this latter group of children that the difference in fixation pattern was most marked in Experiment 3. Nevertheless this experiment confirmed that three dimensional patterns attract more visual attention and are also touched for longer than two dimensional patterns, although overall the normals touched for longer than the mongols did. It was also found that the older children touched the patterns more and made more visual comparisons than the younger children did. This was taken as evidence for a development towards more extensive exploration of these patterns with increasing age. However the most exciting result and one which was quite unexpected, was that the. opportunity to touch the patterns resulted in both the mongol and the normal children paying more visual attention to the patterns. Thus although the mongols have some form of tactile deficit which probably resulted in them touching the patterns for a shorter time than the normals did, their visual behaviour is affected by touch, and appears to be affected as much as it is in normal children. In this experiment (Experiment 4) there was an indication in some of the results that when a two dimensional pattern was presented with a three dimensional pattern the visual response was affected by the relative left-right positions of the two patterns. Therefore the aim of Experiment 5 which is described in Chapter 8, was to explore spatial influences in more detail. This experiment compared the visual response to two patterns arranged horizontally with the visual response to two patterns arranged vertically. The patterns could not be touched and as before two and three dimensional patterns were used. Once again both the mongol and the normal children looked longer at a pair of three dimensional patterns than at a pair of two dimensional patterns. The previous findings of Experiment 4 of visual responses to a pair of two dimensional and three dimensional patterns being influenced by their relative left- right positions were not replicated in Experiment 5. However there was a marked effect of the two axes. Patterns arranged along a horizontal axis were compared more frequently than were patterns arranged vertically. On the other hand, patterns arranged vertically received more repetitions of fixation than did horizontally arranged patterns. The effect of the spatial arrangements of the patterns was found for both the mongol and the normal children, although there was some indication that the normal children moved their eyes more actively than the mongol children did. However within both groups there was a sign of more active scanning by older than by younger children. In Chapter 9 the results of the experiments are considered with respect to six questions. Three of these concern the way in which the children looked at two dimensional patterns, at three dimensional patterns and at patterns in different spatial locations. Two others concern the tactile perception of the children and the amount of touching which occurred. The final question concerns the effect which touch has on visual behaviour. It is concluded that the experiments have furthered our understanding of the way in which the normal child investigates patterns through the modalities of touch and vision, and have indicated two areas of perceptual deficit in the young mongol: (1) some form of tactile deficit s and (2) a deficit in his visual exploration of patterns. The possible role of these deficits in the mongol's subsequent cognitive development is examined and finally some ideas for future experiments are outlined. </p...|$|E
40|$|Typescript. Bibliography: leaves 166 - 171. Microfiche. xiv, 171 leaves, bound ill. 29 cmA {{field and}} {{laboratory}} {{study was conducted}} in Kaneohe Bay, Oahu, Hawaii, to determine the factors that cause sex change in the fish Thalassoma duperrey, a protogynous, diandric hermaphrodite. Unlike other sequential hermaphrodites that have been studied thus far, this species is non-haremic and non-schooling. By nature of its unique social organization, it could have a special sex-change mechanism. The home ranges of T. duperrey overlap extensively and are distributed randomly or uniformly over the reef. Home-range size and location do not differ between the sexes. Size-related aggressive dominance controls feeding interactions. Sexual maturity is reached at about 60 mm standard length, less than 1 year after fertilization. Gonad development (gonosomatic index, percent gonad weight of body weight) in both males and females peaks at about 120 mm, nearly 2 years later. Terminal-phase coloration typically appears soon thereafter, accompanied by as much as a 10 -fold drop in gonosomatic index. This drop is correlated with a change in spawning mode in males from group to pair spawning, which apparently requires less sperm production. Sex change in females occurs at a mean size of 125 mm, 2 years after sexual maturation. Most females probably change sex in late spring or early summer, after the height of the reproductive season. Transitional gonad stages are similar in structure to those reported in other wrasses. A major change in the reproductive tract is the formation of the sperm duct within and between the urogenital papilla and the oviduct. Anatomical and behavioral evidence points to the existence of three cyclic components in the timing of reproduction: annual, semilunar, and diel. On an annual basis, both percent spawnable ova and number of females spawning are greatest in the winter (December). Over the lunar cycle, the same parameters are greatest during the new and full moon and least during the quarter moons. On a daily basis, they are greatest at the time of high tide during daylight hours. The adaptive significance of having a winter spawning maximum is unknown. Spawning on high spring tides, however, may be an anti-egg-predator or dispersal strategy, or both. Reproductive behavior includes the occurrence of lekking, looping, circling, pectoral fluttering, quivering, and group and pair spawning. Spawning is promiscuous though some females spawn with the same TP male repeatedly. All fish are able to choose spawning partners and initial-phase fish frequently migrate as far as half the reef perimeter to do so. Females spawn at most once a day, but large males pair spawn with as many as 20 or more females per day. This relationship supports the size-advantage model for the evolution of sequential hermaphroditism. A comparison of several population parameters between a small and a large patch reef showed that only fish size differed between reefs (the large reef had larger individuals). This comparison did not support the hypothesis that local population size determines the sexual composition of populations on isolated reefs. An interspecific comparison based on population size and density did support the hypothesis. Both population size and fish density were directly related to the percent of primary males present and inversely related to the percent of terminal-phase males present. To determine the proximate causes of individual sex change, experiments were conducted in outdoor pens or tanks at the Hawaii Institute of Marine Biology. Adult wrasses were subjected to various social regimes using size, sex, coloration (phase), density, and type of isolation from conspecifics as independent variables. Single isolated females did not change sex while the larger individuals of paired females did, regardless of absolute size. These results were independent of the amount of space available to the fish. Females paired with smaller initial-phase males also changed sex, but those paired with smaller heterospecific wrasses did not. A tactile barrier separating two females did not prevent sex change in the larger fish. However, a <b>tactile-visual</b> barrier placed between two females significantly reduced the percentage of sex changes. Sex change did not occur when only olfactory cues were available but did occur when only visual cues were available. The presence of an initial-phase or terminal-phase male did not suppress sex change in larger female wrasses. In the case of female threesomes, only the largest female changed sex, demonstrating inhibition of sex change in the intermediate-sized fish. These results show that sex change is socially controlled in T. duperrey. It is dependent upon stimulation from smaller conspecifics and is inhibited in the presence of larger conspecific females. The stimulation-inhibition process suggests that, in nature, the ratio of the number of smaller fish to larger fish would actually control the initiation of sex change in candidate females. The ratio of the number of behavioral interactions with smaller fish to that with larger fish would be the equivalent behavioral mechanism. Either mechanism would function to predict the number of females available as mates for potential sex changers. The precise role of behavior in this mechanism will require further experimentation...|$|E
40|$|O ensino de Arte em {{interface}} com as deficiências, ao longo dos últimos 30 anos, tem sido um tema de interesse crescente em pesquisas no meio acadêmico, sobretudo no que se refere à Educação Especial, porém ainda apresenta certa escassez no tocante a socialização de estudos que discutam esse ensino na perspectiva da educação inclusiva. Diante desse cenário o objeto de estudo desta investigação é a abordagem inclusiva do desenho no contexto escolar, apresentando como objetivo geral a construção de uma proposta de intervenção pedagógica em Artes Visuais, a qual teve como referência o desenho e seu processo de construção, mediante a participação de alunos videntes e não videntes. Para tanto, a abordagem metodológica utilizada, de natureza qualitativa, foi a pesquisa-intervenção, a luz dos princípios bakhtinianos do dialogismo e da alteridade, com características de estudo exploratório. O lócus da pesquisa foi a Escola Estadual Almirante Newton Braga de Faria, a qual está localizada no bairro do Alecrim na Zona Leste do Natal/RN e mantém proximidade com o Instituto de Educação e Reabilitação de Cegos – IERC/RN. A turma escolhida para a intervenção foi o 7 º ano C do turno vespertino, a qual apresentava um público com idade entre 12 e 16 anos, num total de 27 alunos matriculados, sendo três alunos com deficiência: 02 alunas cegas e 01 aluno surdocego com perdas auditivas e visuais leves. Como interlocutores da pesquisa também se pode contar com a professora de Arte que atuou como colaboradora, bem como o professor da Sala de Recursos Multifuncionais da instituição de ensino. Os instrumentos e procedimentos de pesquisa foram a observação, a entrevista semiestruturada, o diário de campo e o registro fotográfico/videográfico. No itinerário da pesquisa foram realizadas 10 oficinas com sequências didáticas multissensoriais, articulando as expressões corporal, tátil e gráfica como intrínsecas ao processo de leitura e produção do desenho de alunos videntes e com deficiência visual. O processo e os dados construídos na pesquisa permitiram uma reflexão sobre as experiências culturais com o desenho no contexto escolar e sobre as interações entre videntes e não videntes na produção e análise de desenhos tátilvisuais. Assinalam, ainda, a construção de uma abordagem de ensino de desenho no contexto da classe comum, a partir de oficinas pedagógicas que possibilitem interações artísticas e estéticas na perspectiva da inclusão escolar. Desse modo, defende-se que a mobilização das expressões tátil, corporal e gráfica, podem ser adotadas em uma abordagem multissensorial que possibilite um enfoque pedagógico que envolva todos os alunos e não se restrinja à presença de alunos com deficiência visual. Over {{the past}} 30 years, Art Education in interface with disabilities {{has been a}} subject of increasing interest in research in academia, {{especially with regard to}} Special Education, but still has some shortages in terms of socialization studies to discuss this type of teaching from the perspective of inclusive education. In this scenario, this paper presents an analysis from the field of teaching Visual Arts in the context of school inclusion, with emphasis on teaching drawing to the visually impaired. The conducted literature indicates a number of authors who discuss teaching drawing to people with visual disabilities, who are dedicated primarily to the Special Education context. In this sense, the shortage of research that discuss this teaching from the perspective of inclusive education, this research aimed at the inclusive approach to teaching drawing in the school context. Thus, the aim {{of this study was to}} develop a proposal for a pedagogical intervention in Visual Arts, with reference to drawing and its construction process, with the participation of seeing and unseeing students. Therefore, the methodological approach, which was qualitative, was the intervention research, in the light of the Bakhtinian principles of dialogism and otherness, with exploratory study characteristics. The locus of the research was the State School Admiral Newton Braga Faria, which is located in Alecrim, on the East Zone of Natal / RN and is near the Institute for Education and Rehabilitation of the Blind - IERC / RN. The class chosen for intervention was the 7 th grade “C” afternoon shift, which had children aged 12 to 16, with 27 students enrolled, three students with disabilities: 02 blind girls and 01 deafblind boy with light hearing and visual loss. As interlocutors of the research, we could also count on the Art teacher who served as a collaborator, as well as teacher in the school’s Multifunction Resource Room. The instruments and research procedures were observation, semi-structured interview, field diary and the photo / video recording. In the development of research, we conducted 10 workshops with multisensory teaching sequences, articulating the physical, tactile and graphical expressions as intrinsic to the reading and production of drawing for both seeing and unseeing students. The process and data built on research allowed for a reflection on cultural experiences with drawing in the school context and on the interactions between seeing and unseeing students in the production and analysis of <b>tactile-visual</b> drawings. They also point out the construction of a teaching approach to drawing, in the context of the common class, from educational workshops that enable artistic and aesthetic interactions from the perspective of school inclusiveness. Thus, we argued that the mobilization of the tactile, physical and graphical expressions can be adopted in a multisensory approach that enables a pedagogical focus that involves all students and is not restricted to the presence of students with visual impairment...|$|E
40|$|Visual motion {{strongly}} influences tactile motion judgments. When visual {{motion was}} presented simultaneously {{but in the}} opposite direction to tactile motion, the accuracy of the tactile motion judgments were substantially reduced. These psychophysical observations suggest that crossmodal interaction occurs during motion direction judgment, although the neural substrates of this are largely unknown. Motion-direction discrimination requires (a) the coding of motion in the two sensory modalities and (b) a decision stage that compares the two motion direction signals. Therefore cross-modal interference could occur at either stage. One candidate locus for the integration of visual and tactile motion information in the coding stage is the human middle temporal (MT) /V 5 area. According to visual mediation heuristics, the tactile system is less efficient than the visual system at processing the spatial attributes of an object; hence, tactile inputs are translated into corresponding visual representations, which are further processed by the visual system. It is therefore predicted that the visual cortex is the site of crossmodal interaction. Instead, such neural mechanisms might involve multisensory areas in the decision stage, because our space perception is highly integrated across modalities. Hence, an alternative candidate area for crossmodal integration is the multisensory posterior parietal cortex. To explore these alternatives, they conducted a functional magnetic resonance imaging (fMRI) experiment. Our hypothesis was that spatial analysis of the direction of movement via visual and tactile modalities activates both sensory-specific areas and multisensory areas. Brain areas participating in crossmodal integration should show signs of convergence and interaction. They initially performed independent tactile and visual unimodal experiments involving motion direction matching tasks to define the common multimodal areas activated during each of the independent tactile and visual tasks (convergence). They then carried out tactile and visual crossmodal experiments with event-related designs, to identify the areas in which the crossmodal response was enhanced by comparing stimuli whose direction of motion were congruent and incongruent (interaction). 　　Fifteen healthy volunteers (seven men and eight women; mean age ± standard deviation [SD]= 27. 9 ± 6. 7 years) participated in this study. In the unimodal experiments, they used a block design. The subjects performed two different tasks: a tactile-tactile (T), and visual-visual (V) motion-direction matching task, and searched for commonly activated areas. In the cross-modal experiment, they used an event-related design to analyze crossmodal congruency effects. The design consisted of four conditions: <b>tactile-visual</b> (TV), tactile- tactile (TT), visual-visual (VV) matching tasks, and a still condition (ST). To analyze congruency effects, they divided TV, TT, and VV into two conditions respectively, the congruency, and the incongruency condition (TVc, TVi, etc). And, they searched for areas that showed crossmodal congruency effects, that is, areas where TVc showed greater activation compared with TVi within bimodal areas. 　　In the unimodal experiments, Tactile motion direction discrimination activated the bilateral inferior parietal lobule (LPi), LPs, secondary somatosensory area (SII), dorsal premotor cortex (PMd), ventral premotor cortex (PMv), inferior frontal gyrus (GFi), insula, putamen, left primary sensorimotor area (SM 1), postcentral gyrus (GPoC), supplementary motor area (SMA) and pre-SMA. Deactivation was observed in the occipital cortices including the MT/V 5, medial prefrontal, orbitofrontal, parietal and temporal cortices. Visual motion orientation discrimination activated the bilateral cuneus (Cu), fusiform gyrus (GF), lingual gyrus (GL), MT/V 5, inferior occipital gyrus (GOi), middle occipital gyrus (GOm), precuneus (PCu), LPs, IPS, PMv and right GPoC. The MT/V 5 area was identified using the previously reported Talairach’s coordinates and anatomical criteria. Deactivation was observed in the right prefrontal cortex, left MT gyrus, right superior temporal gyrus and right PMd. Areas that were activated by both tactile and visual tasks were found within the bilateral posterior parietal cortex, including the left LPs, bilateral PMd and PMv, and right cerebellum. Task-related activities specific to tactile motion direction matching (T-V, masked with T) were seen in the bilateral parieto-premotor cortices, SIIs, insula, left putamen and right cerebellum. Visual-specific activities (V-T, masked with V) were observed in the occipital cortices. In the areas implicated in matching the direction of visual motion, the bilateral GOm, MT gyrus (GTm) and superior occipital gyrus (GOs) showed significantly less activity during tactile motion discrimination than during the rest conditions. No significant deactivation was found during visual motion direction matching in the areas implicated in tactile motion direction matching. 　　In the crossmodal experiment, within the polymodal areas defined by the unimodal block design experiment, the left LPs and the PMv showed significant activation during the TV condition in the event-related design experiment. The left LPs showed a congruency effect specific to the TV. No congruency effect was found during the VV or TT conditions. To identify brain areas with significantly lower activity during crossmodal matching than during intramodal matching, the following contrasts were used: TT-TV masked with T and (T-V), and VV-TV masked with V and (V-T). Compared with the TT condition, the TV condition showed a decrease in signal in the left secondary somatosensory cortex, bilateral LPi and bilateral PMd. Compared with the VV condition, the activities in the bilateral MT/V 5, GOm and right Cu were significantly reduced during the TV condition. 　　In the unimodal experiment, the tactile task deactivated the visual cortical areas including MT/V 5. The deactivation of cortical regions that are not directly related to task modalities might be functionally significant, in that it reduces the probability that there will be interference due to information from other sensory modalities. Crossmodal deactivation is therefore an essential component of the selective attention mechanism, playing a complementary role to the activation of cortical areas that are required for the performance of a given task. This may explain the apparently discrepant results of previous functional neuroimaging studies which have found that tactile motion activated MT/V 5, as the tasks in neither of these studies required a motion-direction discrimination. The current findings go against the visual mediation heuristics hypothesis, but are consistent with the idea that the association of features with tactile entities occurs primarily within the tactile modality. 　　They also found that the left LPs, and the PMd and PMv, were activated by both visual and tactile motion direction discrimination. These areas should represent the processes common to both visual and tactile intra-modal motion direction discrimination. 　　In the crossmodal experiment, among the areas showing visuo-tactile convergence, the posterior portion of the left LPs demonstrated more prominent activation under congruent conditions than incongruent conditions. This congruency effect was specific to the crossmodal condition. Thus, the crossmodal congruency effect observed in this study seems to reflect the interaction at the decision stage that requires the comparison of the two motion signals that have been coded in the modality-specific areas. In this regard, the left posterior LPs may represent a node through which the senses can access each other directly from their sensory-specific system. 　　They also found that the motion-related MT/V 5 activity was suppressed in the TV condition compared with the VV condition. The activity in the tactile unimodal areas was also reduced compared with the TT condition. This pattern was not observed in the parieto-premotor areas that showed activation during the tactile and visual tasks. 　　These findings support the notion of different roles for the modality-specific areas and the polymodal areas in crossmodal motion discrimination: the coding of motion is modality-specific, whereas a decision stage might be represented by the polymodal parieto-premotor networks with ‘competitive’ interaction between modality-specific areas. In this regard, the left posterior LPs might represent a node through which the senses can access each other directly from their sensory-specific systems...|$|E

