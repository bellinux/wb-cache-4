2020|10000|Public
25|$|A {{functional}} model must thus achieve two aims {{in order}} to be of use. It must furnish a throughput description mechanics capable of completely defining the first and last throughput states, and perhaps some of the intervening states. It must also offer some means by which any input, correctly described in terms of this mechanics, can be used to generate an output which is an equally correct description of the output which the actual system would have given for the input concerned. It may also be noted that there are two other things which a functional model may do, but which are not necessary to all functional models. Thus such a system may, but need not, describe the system <b>throughputs</b> other than at the input and output, and it may also contain a description of the operation which each element carries out on the throughput, but once again this is not.|$|E
500|$|In an {{experimental}} comparison, Richter et al. {{found that the}} Multiply-Shift family of hash functions (defined as [...] ) was [...] "the fastest hash function when integrated with all hashing schemes, i.e., producing the highest <b>throughputs</b> and also of good quality" [...] whereas tabulation hashing produced [...] "the lowest throughput".|$|E
500|$|In October 2012, Juniper {{introduced}} the MX2020 and 2010 3D Universal Edge Routers, with <b>throughputs</b> of 80 Tbit/s and 40 Tbit/s respectively. Juniper also released a video caching {{system for the}} MX family and a suite of software applications that include parental control, firewall and traffic monitoring. New [...] "Virtual Chassis" [...] features allowed network operators to manage multiple boxes {{as though they were}} a single router or switch.|$|E
30|$|We define {{that the}} <b>throughput</b> of {{entering}} the node represents the downlink <b>throughput,</b> while the <b>throughput</b> {{of leaving the}} node indicates the upstream <b>throughput.</b>|$|R
3000|$|UDec) {{corresponding}} {{to the level of}} sub-block parallelism and the computed number of decoding iterations is calculated (line 4). Finally, the UDec <b>throughput</b> and the target <b>throughput</b> are compared. If the target <b>throughput</b> is greater than the current UDec <b>throughput,</b> the level of sub-block parallelism has to be increased to reach the <b>throughput</b> requirement. Once loop iterations finished (line 7), the UDec <b>throughput</b> and the target <b>throughput</b> values are compared. If the UDec <b>throughput</b> is greater than the target <b>throughput,</b> then a configuration solution exists with a level of sub-block parallelism of P and N [...]...|$|R
30|$|As {{discussed}} in Section 2.1. 3, the <b>throughput</b> of a user {{depends on the}} user data rate demand and the available <b>throughput</b> capacity. The total <b>throughput</b> is obtained by adding the <b>throughput</b> of all users. Therefore, to estimate the total <b>throughput</b> at a grid point (as a UAV position), we need to estimate the <b>throughput</b> for each user and then compute its total.|$|R
2500|$|The {{dramatic}} {{decrease in}} evasion {{during this period}} coincided with a reinvigorated Transit Police, a 25% expansion of City police, and a general drop in crime in U.S. cities. In the city, crime rate decline begun in 1991 under Mayor David Dinkins and continued through next two decades under Mayors Rudolph Giuliani and Michael Bloomberg. Some observers credited the “broken windows” approach of law enforcement [...] where minor crimes like evasion are routinely prosecuted, and statistical crimefighting tools, whereas others have indicated different reasons for crime reduction. Regardless of causality, evasion checks resulted in many arrests for outstanding warrants or weapons charges, likely contributing somewhat to public safety improvements. Arrests weren’t {{the only way to}} combat evasions, and by the early 1990s NYCTA was examining methods to improve fare control passenger <b>throughputs,</b> reduce fare collection costs, and maintain control over evasions and general grime. The AFC system was being designed, and evasion-preventing capability was a key consideration.|$|E
2500|$|DESI {{has been}} widely studied since its {{inception}} in 2004 by Professor Zoltan Takáts, [...] et al., in Professor Graham Cooks' group from Purdue University with the goal of looking into methods that didn't require the sample to be inside of a vacuum. Both DESI and direct analysis in real time (DART) have been largely responsible for the rapid growth in ambient ionization techniques, with a proliferation of more than thirty new techniques being found today. These methods allow for complex systems to be analyzed without preparation and <b>throughputs</b> as high as 45 samples a minute. DESI is a combination popular techniques, such as, electrospray ionization and surface desorption techniques. Electrospray ionization with mass spectrometry was reported by Malcolm Dole in 1968, but John Bennett Fenn was awarded a nobel prize in chemistry for the development of ESI-MS in the late 1980s. Then in 1999, desorption of open surface and free matrix experiments were reported in the literature utilizing an experiment that was called desorption/ionization on silicon. The combination of these two advancements led to the introduction of DESI and DART as the main ambient ionization techniques that would later become multiple different techniques. One in particular, due to increasing studies into optimization of DESI is, Nanospray desorption electrospray ionization. In this technique the analyte is desorbed into a bridge formed via two capillaries and the analysis surface.|$|E
50|$|In 2009, {{passenger}} <b>throughputs</b> of all nationwide airports reached 486.063 million, up by 19.8% {{over the}} last year; cargo and mail <b>throughputs</b> were 9.456 million tons, up by 7.0%.|$|E
30|$|The per-client <b>throughput</b> in {{backbone}} communications will {{be compared}} with the per-client <b>throughput</b> in local communications to decide the per-client <b>throughput</b> in the WMN. Note that if a mesh client is connected directly to a gateway, its <b>throughput</b> is decided only by the per-client <b>throughput</b> in local communications.|$|R
50|$|Version 3 of HEVC added one 3D profile: 3D Main. The February 2016 {{draft of}} the screen content coding {{extensions}} added seven screen content coding extensions profiles, three high <b>throughput</b> extensions profiles, and four scalable extensions profiles: Screen-Extended Main, Screen-Extended Main 10, Screen-Extended Main 4:4:4, Screen-Extended Main 4:4:4 10, Screen-Extended High <b>Throughput</b> 4:4:4, Screen-Extended High <b>Throughput</b> 4:4:4 10, Screen-Extended High <b>Throughput</b> 4:4:4 14, High <b>Throughput</b> 4:4:4, High <b>Throughput</b> 4:4:4 10, High <b>Throughput</b> 4:4:4 14, Scalable Monochrome, Scalable Monochrome 12, Scalable Monochrome 16, and Scalable Main 4:4:4.|$|R
50|$|The Screen-Extended High <b>Throughput</b> 4:4:4 14 profile {{allows for}} a bit depth of 8-bits to 14-bits per sample with support for 4:0:0, 4:2:0, 4:2:2, and 4:4:4 chroma sampling. The Screen-Extended High <b>Throughput</b> 4:4:4 14 profile has an HbrFactor 6 times higher than most inter frame HEVC profiles. HEVC decoders that conform to the Screen-Extended High <b>Throughput</b> 4:4:4 14 profile must be capable of {{decoding}} bitstreams made with the following profiles: Monochrome, Main, Main 10, Main 4:2:2 10, Main 4:4:4, Main 4:4:4 10, Screen-Extended Main, Screen-Extended Main 10, Screen-Extended Main 4:4:4, Screen-Extended Main 4:4:4 10, Screen-Extended High <b>Throughput</b> 4:4:4, Screen-Extended High <b>Throughput</b> 4:4:4 10, Screen-Extended High <b>Throughput</b> 4:4:4 14, High <b>Throughput</b> 4:4:4, High <b>Throughput</b> 4:4:4 10, and High <b>Throughput</b> 4:4:4 14.|$|R
5000|$|There {{are five}} major ports along the Bohai Sea rim, with <b>throughputs</b> over 100 million tons: ...|$|E
50|$|MoCA 1.1 {{provides}} 175 Mbit/s net <b>throughputs</b> (275 Mbit/s PHY rate) {{and operates}} in the 500 to 1500 MHz frequency range.|$|E
50|$|Danner and Vello {{processes}} {{are used for}} the production of thin-walled glass tubes of relatively small diameter, with <b>throughputs</b> of up to 55 tonnes per day.|$|E
3000|$|... (maximum <b>throughput</b> position). Lines 4 to 11 {{loop over}} the grid points to {{determine}} the point with the maximum estimated <b>throughput.</b> Line 5 calls Procedure 2 to compute the <b>throughput</b> capacity for each user at a grid point. Line 6 calls Procedure 3 to estimate the total <b>throughput</b> at a grid point. Lines 7 checks whether the <b>throughput</b> at the current grid point {{is more than the}} current maximum; if it is, then line 8 updates the maximum <b>throughput</b> value and lines 9 records the current grid point as the maximum <b>throughput</b> position. At the termination of the loop, the point with estimated maximum <b>throughput,</b> p [...]...|$|R
3000|$|Because {{the network}} <b>throughput</b> fluctuates {{significantly}} over time, calculating the network <b>throughput</b> {{with only the}} size of the last segment and the download time can lead to substantial errors. Therefore, ABR schemes using the network <b>throughput</b> usually use average network <b>throughput</b> for a period [8]. However, this causes a major error in the calculated <b>throughput</b> when non-stationary <b>throughput</b> changes (e.g., level shift) occur. Therefore, the previous <b>throughput</b> is ignored in this case [21]. Similarly, the proposed scheme uses average download time as the second input parameter as expressed in Eq. (9): [...]...|$|R
30|$|In {{order to}} {{evaluate}} the performance of gateway placement algorithms, the aggregate <b>throughput</b> and the worst-case per-client <b>throughput</b> need to be derived. In this subsection, two problems of <b>throughput</b> maximization are formulized, {{which leads to the}} definitions of two <b>throughput</b> metrics. The actual framework of computing the nonasymptotic value of these <b>throughput</b> metrics will be provided in Section 4.|$|R
50|$|TRA has {{recently}} installed advanced signalling on the northernmost {{portion of the}} West Coast Main Line around Taipei, and has performed extensive capacity analysis to maximize train <b>throughputs.</b>|$|E
50|$|MoCA 2.0 offers actual <b>throughputs</b> (MAC rate) up to 1 Gbps. Operating {{frequency}} range is 500 to 1650 MHz. Packet error rate is 1 packet error in 100 million.|$|E
50|$|In 2011, D.J. Bernstein and Tanja Lange {{published}} RFSB, {{which is}} 10x {{faster than the}} original FSB-256. RFSB was shown to run very fast on the Spartan 6 FPGA, reaching <b>throughputs</b> of around 5 Gbit/s.|$|E
50|$|The High <b>Throughput</b> 4:4:4 14 profile {{allows for}} a bit depth of 8-bits to 14-bits per sample with support for 4:0:0, 4:2:0, 4:2:2, and 4:4:4 chroma sampling. The High <b>Throughput</b> 4:4:4 14 profile has an HbrFactor 6 times higher than most inter frame HEVC profiles. HEVC decoders that conform to the High <b>Throughput</b> 4:4:4 14 profile must be capable of {{decoding}} bitstreams made with the following profiles: High <b>Throughput</b> 4:4:4, High <b>Throughput</b> 4:4:4 10, and High <b>Throughput</b> 4:4:4 14.|$|R
30|$|The {{aforementioned}} research {{works in}} [3 – 5, 14] take the ergodic <b>throughput</b> as the performance measure. For applications insensitive to delay, the ergodic <b>throughput</b> is a suitable performance measure [7]. On the other hand, the outage <b>throughput</b> is {{more appropriate to}} characterize the downlink <b>throughput</b> for real-time applications [8]. In this work, we discuss the outage <b>throughput</b> maximization with imperfect CSI.|$|R
30|$|The second {{option is}} to allow, in {{specific}} rooms, that the <b>throughput</b> {{is lower than the}} <b>throughput</b> provided by the original network. E.g., one can set the minimal <b>throughput</b> in a toilet to 0 Mbps, while the original network provides a <b>throughput</b> of e.g., 24 Mbps. It is allowed that the <b>throughput</b> is higher than this lower limit, but it is not required.|$|R
5000|$|During a cache miss, the CPU usually ejects {{some other}} entry {{in order to}} make room for the {{previously}} uncached data. The heuristic used to select the entry to eject is known as the replacement policy. One popular replacement policy, [...] "least recently used" [...] (LRU), replaces the least recently used entry (see cache algorithm). More efficient caches compute use frequency against the size of the stored contents, as well as the latencies and <b>throughputs</b> for both the cache and the backing store. This works well for larger amounts of data, longer latencies and slower <b>throughputs,</b> such as experienced with a hard drive and the Internet, but is not efficient for use with a CPU cache.|$|E
50|$|MoCA Access is {{intended}} for multiple dwelling units (MDUs) such as hotels, resorts, hospitals, or educational facilities. It {{is based on the}} current MoCA 2.0 standard which is capable of 1 Gbps net <b>throughputs,</b> and MoCA 2.5 which is capable of 2.5 Gbps.|$|E
5000|$|Tubular bowl {{centrifuge}} {{is widely}} used for nano-scale particles separation {{and is one of}} old design of centrifuge processes. Nanoparticles are separated from a suspension using this process because very high G value i.e. high rotation speed ensures reasonable <b>throughputs</b> are produced.|$|E
5000|$|This is the <b>throughput.</b> <b>Throughput</b> is {{intended}} to mean the probability of successful transmission during minimum possible period. Therefore, the <b>throughput</b> in pure ALOHA, ...|$|R
50|$|When {{discussing}} <b>throughput,</b> {{there is}} often a distinction between the peak data rate of the physical layer, the theoretical maximum data <b>throughput</b> and typical <b>throughput.</b>|$|R
40|$|The medium {{access control}} {{protocol}} of IEEE 802. 11 networks has been extensively studied to explore its <b>throughput</b> performance. A popular regime of study is the saturation regime where users {{are assumed to be}} saturated with information bits. The <b>throughput</b> achieved in this regime, called the saturation <b>throughput,</b> is commonly interpreted as the maximum achievable <b>throughput</b> for any given system. In this paper, we formalize the conditions under which saturation <b>throughput</b> is indeed the maximum achievable <b>throughput.</b> We provide specific settings which may increase the maximum aggregate <b>throughput</b> of the system beyond the saturation <b>throughput.</b> Furthermore, we observe and prove that reducing the MAC buffer size significantly increases the maximum aggregate <b>throughput,</b> beyond the saturation <b>throughput,</b> a fact that seems counter-intuitive. We formally establish that under small buffer conditions and under UDP-type traffic, a reduction in effective collisions due to the buffer size choice has a positive effect on the <b>throughput</b> performance. This is despite the fact that some packets are dropped because of likely buffer overflow events. In other words, by identifying the notion of saturation <b>throughput</b> as an inherently pessimistic notion, this paper brings to the attention the significant impact of an optimized choice of MAC buffer size on the performance of 802. 11 networks...|$|R
50|$|Dedicated {{point-to-point}} links are not {{the only}} option for many connections between systems. Frame Relay, ATM, and MPLS based services can also be used. When calculating or estimating data <b>throughputs,</b> the details of the frame/cell/packet format and the technology's detailed implementation need to be understood.|$|E
50|$|In the United States, {{the band}} 36.0 - 40.0 GHz {{is used for}} {{licensed}} high-speed microwave data links, and the 60 GHz band {{can be used for}} unlicensed short range (1.7 km) data links with data <b>throughputs</b> up to 2.5 Gbit/s. It is used commonly in flat terrain.|$|E
50|$|Operations on {{different}} railroads are variations of same general principles. TRA’s practices are like JR's - somewhat labour-intensive, but immediate on-site accountability and close supervision contribute to high service quality, good delay-recovery capabilities, skills to execute complex maneuvers, and <b>throughputs</b> closer to theoretical line capacity than otherwise achievable.|$|E
5000|$|... is {{the total}} <b>throughput,</b> usually by {{convention}} not measured as a mass <b>throughput</b> {{but rather as a}} pressure <b>throughput</b> and having units of pressure times volume per second, ...|$|R
30|$|Following intuition, {{increased}} altruism (a 1 [*]>[*] 50) by player 1 {{resulted in}} lower <b>throughput</b> {{for him and}} higher <b>throughput</b> for the other two players. Similarly, decreased altruism by player 1 (a 1 [*]<[*] 50) resulted in higher <b>throughput</b> for him and lower <b>throughput</b> for the other players.|$|R
3000|$|By {{adjusting}} this threshold parameter, {{the system}} benefits from flexible operation of either achieving high system <b>throughput</b> or enhanced fairness {{in terms of}} cell-edge user <b>throughput.</b> A onefold (uplink) and tenfold (downlink) improvement in average cell-edge user <b>throughput</b> is achieved at a reduction in system <b>throughput</b> of about [...]...|$|R
