13|2|Public
40|$|This paper {{examines}} the different interactions that can exist between an independent central {{bank and the}} economic policy in a country. The focal point of this survey {{is based on the}} « <b>temporal</b> <b>incoherence</b> »problem raised in the years 1970 by Prescott and Kydland. These two authors arrived to the conclusion that, the separation between public authorities and monetary authorities would guarantee an economic stability. The rush observed since some years of the central banks toward the independence vis-`a-vis of public authorities contributed to carry a decisive stroke to the economic policy’s efficiency thus. ...|$|E
40|$|Abstract: Effects of {{the beam}} finite {{transverse}} size on electromagnetic radiation emitted by rel-ativistic charged beam are commonly observed in condition of <b>temporal</b> <b>incoherence</b> in several elec-tromagnetic radiative phenomena such as syn-chrotron radiation in an electron storage ring or photon bremsstrahlung in a positron-electron col-lider. Similarly, beam transverse size effects can be also predicted to affect the transition radia-tion emission by an electron beam in a particle accelerator. The main theoretical arguments in favour of such a sort of ”source size ” effect in the transition radiation energy spectrum and the main consequences in the field {{of the beam}} di-agnostics in a particle linear accelerator will be described...|$|E
40|$|Abstract—View {{synthesis}} {{is dedicated}} to generating arbitrary views of the same scene from given inputs. As an alterna-tive to depth-image-based rendering (DIBR), image warping based view synthesis approaches could automatically generate visually plausible virtual views in real-time. Recognizing that existing techniques would lead to <b>temporal</b> <b>incoherence</b> and shape distortions in synthesized videos, this paper proposes a novel video warping algorithm which motion saliency map and global motion from reference views are incorporated into motion-aware constraints to maintain temporal coherence in virtual views. Furthermore, a salient curve based disparity constraint is imposed to prevent shape deformations and avoid possible artifacts. Extensive experiments are validated by visual comparison, which demonstrates that the proposed algorithm outperforms existing warping-based methods. Index Terms—View synthesis, image warping, spatio-temporal coherence, motion saliency map, salient curve detection I...|$|E
40|$|The {{holographic}} stereogram, a hologram synthesized {{from ordinary}} stereoscopic component photographs, is investigated {{as an alternative}} to classical holograms and to previous types of stereograms for three-dimensional perfect imagery. The process is partly holographic in nature, but it provides images of naturally illuminated objects, and its application is not limited by the technology of laser illumination. The pinhole camera stereogram and the fly's eye lens stereogram are also analyzed, since the principles of their operation are similar. Pinhole camera stereogram imagery is shown to have several deficiencies, among which is the necessity for small camera-object distances. The fly's eye lens is much superior, but is limited in practice by aberrations, a difficulty which the holographic stereogram overcomes. Also treated are the full-color, the focused type, and the distortionless-scaled holographic stereogram, and optical spatial filtering of holographic stereogram images. The achromatically imaged Fresnel zone plate is analyzed as a technique of very general applicability which compensates for source incoherency in two-beam type holographic arrangements. The emphasis is on physical interpretation rather than mathematical formulation. Two simple graphical mnemonics are developed for rapid analytical inspection of the effects of, respectively, <b>temporal</b> and spatial <b>incoherence</b> of the source in any achromatically imaged zone plate or Gabor in-line type holographic system. The scalar wave function approximation of physical optics is used throughout. ...|$|R
40|$|A novel four-color beam {{smoothing}} scheme with a capability {{similar to}} that planned for the proposed National Ignition Facility has been deployed on the Nova laser, and has been successfully used for laser fusion experiments. Wavefront aberrations in high power laser systems produce nonuniformities in the energy distribution of the focal spot that can significantly degrade the coupling of the energy into a fusion target, driving various plasma instabilities. The introduction of <b>temporal</b> and spatial <b>incoherence</b> over {{the face of the}} beam using techniques such as smoothing by spectral dispersion (SSD) can reduce these variation in the focal irradiance when averaged over a finite time interval. We developed a multiple frequency source that is spatially separated into four quadrants, each containing a different central frequency. Each quadrant is independently converted to the third harmonic in a four-segment Type I/ Type II KDP crystal array with independent phase-matching for efficient frequency conversion. Up to 2. 3 kJ of third harmonic light is generated in a 1 ns pulse, corresponding to up to 65 % conversion efficiency. SSD is implemented by adding limited frequency modulated bandwidth to each frequency component. Smoothing by spectral dispersion is implemented during the spatial separation of the FM modulated beams to provide additional smoothing, reaching a 16 % rms intensity variation level. The four- color system was successfully used to probe NIF-like plasmas, producing {lt} 1 % SBS backscatter at {gt} 2 x 10 {sup 15 } W/cm{sup 2 }. This paper discusses the detailed implementation and performance of the segmented four-color system on the Nova laser system...|$|R
40|$|The {{performance}} of massively parallel program is often {{impacted by the}} cost of communication across computing nodes. Analysis of communication patterns is critical for understanding and optimizing massively parallel programs. Visualization can help identify potential communication bottlenecks by displaying message trace data. However, the visual clutter and <b>temporal</b> <b>incoherence</b> problems are typically incurred in existing visualization tools for {{a considerable number of}} processors. In this paper, we present a new tool, named CommGram, which supports visual analysis of communication patterns for massive parallel MPI programs. With the benefit of MPI trace library DUMPI of SST, our framework builds hierarchical clustering trees for computational community domain, and takes advantage of graphical user interface (GUI) to convey communication patterns at different levels of detail. The effectiveness of our tool is demonstrated using large-scale parallel applications...|$|E
40|$|Because of the <b>temporal</b> <b>incoherence</b> of sunlight, {{solar cells}} {{efficiency}} should {{depend on the}} degree of coherence of the incident light. However, numerical computation methods, which are used to optimize these devices, fundamentally consider fully coherent light. Hereafter, we show that the incoherent efficiency of solar cells can be easily analytically calculated. The incoherent efficiency is simply derived from the coherent one thanks to a convolution product with a function characterizing the incoherent light. Our approach is neither heuristic nor empiric but is deduced from first-principle, i. e. Maxwell's equations. Usually, in order to reproduce the incoherent behavior, statistical methods requiring a high number of numerical simulations are used. With our method, such approaches are not required. Our results are compared with those from previous works and good agreement is found. Comment: 13 pages, 3 figures, published in Optics Expres...|$|E
40|$|Numerical {{simulations}} {{of the temporal}} evolution of laser light filamentation and stimulated Brillouin forward scattering (SBFS) in plasmas, under conditions {{that are relevant to}} laser fusion, are presented and analyzed. Long term unsteady behavior of filaments is observed to be the norm. Temporal and spatial incoherence due to filamentation and SBFS are impressed upon time-independent incident laser beams. The bandwidth and angular divergence imposed upon the beam increase with the strength of the interaction. In addition, the spectrum of the transmitted light is redshifted by an amount that increases with the interaction strength. Spectral analysis of the transmitted light reveals that SBFS plays a role in the generation of the observed <b>temporal</b> <b>incoherence.</b> Incident beams with some spatial incoherence but no temporal smoothing are compared to those with ab initio temporal beam smoothing (TBS). Under typical conditions, TBS beams will undergo far less angular and spectral spreading and far less SBFS than unsmoothed beams. ...|$|E
40|$|Optical beams {{can carry}} {{information}} in their amplitude and phase; however, optical analog numerical calculators {{such as an}} optical matrix processor use incoherent light to achieve linear operation. Thus, the phase information is lost and only the magnitude can be used. This limits such processors to the representation of positive real numbers. Many systems have been devised to overcome this deficit {{through the use of}} digital number representations, but they all operate at a greatly reduced efficiency in contrast to analog systems. The most widely accepted method to achieve sign coding in analog optical systems has been the use of an offset for the zero level. Unfortunately, this results in increased noise sensitivity for small numbers. In this paper, we examine the use of spatially coherent sign coding in acoustooptical processors, a method first developed for digital calculations by D. V. Tigin. This coding technique uses spatial coherence for the representation of signed numbers, while <b>temporal</b> <b>incoherence</b> allows for linear analog processing of the optical information. We show how spatial phase coding reduces noise sensitivity for signed analog calculations...|$|E
40|$|This paper {{presents}} an Interactive View-Driven Evenly Spaced Streamline placement algorithm (IVDESS) for 3 D explorative visualization of large complex planar or curved surface flows. IVDESS rapidly performs accurate streamline integration in 3 D physical space, i. e., the flow field, while achieving high quality streamline density control in 2 D view space, i. e., the output image. The {{correspondence between the}} two spaces is established by using a projectionunprojection pair constituted through geometric surface rendering. An inter-frame physical-space seeding strategy based on streamline reuse+lengthening is adopted, on top of intra-frame view-space seeding, to not only enable coherent flow navigation but also speedup placement generation. IVDESS employs a view-sensitive streamline representation that is well suited for streamline reuse, lengthening, and rendering. In addition, it avoids <b>temporal</b> <b>incoherence</b> caused by streamline splitting and jaggy lines caused by unprojection errors. Our algorithm can run at interactive frame rates (9 FPS for placement generation) to allow for 3 D exploration of surface flows with smooth evolution of high-density (1 %) evenly spaced streamlines in a large window (990 × 700 pixels) on an ordinary PC without either pre-processing or GPU support...|$|E
40|$|Abstract — This paper {{addresses}} {{the problem of}} hallucinating the missing high-resolution (HR) details of a low-resolution (LR) video while maintaining the temporal coherence of the recon-structed HR details using dynamic texture synthesis (DTS). Most existing multiframe-based video superresolution (SR) methods suffer from the problem of limited reconstructed visual quality due to inaccurate subpixel motion estimation between frames in an LR video. To achieve high-quality reconstruction of HR details for an LR video, we propose a texture-synthesis (TS) -based video SR method, in which a novel DTS scheme is proposed to render the reconstructed HR details in a temporally coherent way, which effectively {{addresses the}} <b>temporal</b> <b>incoherence</b> problem caused by traditional TS-based image SR methods. To further reduce {{the complexity of the}} proposed method, our method only performs the TS-based SR on a set of key frames, while the HR details of the remaining nonkey frames are simply predicted using the bidirectional overlapped block motion compensation. After all frames are upscaled, the proposed DTS-SR is applied to maintain the temporal coherence in the HR video. Experimental results demonstrate that the proposed method achieves significant subjective and objective visual quality improvement over state-of-the-art video SR methods. Index Terms — Video super-resolution, video hallucination, dynamic texture synthesis, video upscaling, motion-compensated interpolation. I...|$|E
40|$|Editing {{faces in}} videos {{is a popular}} yet {{challenging}} aspect of computer vision and graphics, which encompasses several applications including facial attractiveness enhancement, makeup transfer, face replacement, and expression manipulation. Simply applying image-based warping algorithms to video-based face editing produces <b>temporal</b> <b>incoherence</b> in the synthesized videos because {{it is impossible to}} consistently localize facial features in two frames representing two different faces in two different videos (or even two consecutive frames representing the same face in one video). Therefore, high performance face editing usually requires significant manual manipulation. In this paper we propose a novel temporal-spatial-smooth warping (TSSW) algorithm to effectively exploit the temporal information in two consecutive frames, as well as the spatial smoothness within each frame. TSSW precisely estimates two control lattices in the horizontal and vertical directions respectively from the corresponding control lattices in the previous frame, by minimizing a novel energy function that unifies a data-driven term, a smoothness term, and feature point constraints. Corresponding warping surfaces then precisely map source frames to the target frames. Experimental testing on facial attractiveness enhancement, makeup transfer, face replacement, and expression manipulation demonstrates that the proposed approaches can effectively preserve spatial smoothness and temporal coherence in editing facial geometry, skin detail, identity, and expression, which outperform the existing face editing methods. In particular, TSSW is robust to subtly inaccurate localization of feature points and is a vast improvement over image-based warping methods...|$|E
40|$|The image matting problem {{refers to}} {{foreground}} object extraction from an image. Similarly, video matting problem refers to extraction of a foreground object from each frame of a video-sequence producing a moving foreground layer. Layer extraction process {{should deal with}} the transparency caused by camera point spread function (PSF) and motion blur, thus the natural way is to store extracted layer {{as a pair of}} images: color and opacity. The latter is referred to as an alpha-channel. In this paper we propose an algorithm that takes alpha for the first frame (or an arbitrary key-frame) provided by the user (e. g. by using some image matting algorithm) and tracks its motion in time through the video sequence. Unlike the obvious approach that models the whole scene motion from one frame to the next with an optical flow (e. g. to warp the rough input segmentation (trimap) or the alpha channel with this flow), we use it to model the foreground layer motion only. This prevents us from otherwise unavoidable artifacts on the boundaries of foreground objects, which are of the main interest in the matting problem. Instead of matching pixel colors in the pair of frames, we measure how the optical-flow-warped alpha-channel fits the next frame (we use color matching as an additional regularization though). By minimizing this measure with respect to optical flow we fully preserve the structure of the foreground object and prevent <b>temporal</b> <b>incoherence</b> artifacts...|$|E
40|$|This study {{examines}} {{the phenomenon of}} dreaming. Through interpretation and comparative analyses of different philosophical and psychological theories on dreams, it {{is the purpose of}} this examination to try and find out in which way dreaming relates to consciousness and which possibilities dreams may offer for acquiring knowledge of the world and oneself. Beginning in the 17 th century with Descartes’ dream scepticism and moving further up through history with John Locke, Gottfried Leibniz, Carl Gustav Jung and Norman Malcolm, we will see that these philosophers’ respective theories on dreams relies on their respective ways of understanding human consciousness. Each philosopher represents a certain philosophical method when trying to accumulate a theory of consciousness that either contains or is separate from a theory of dreams. Descartes argues that the mind is constantly thinking even when sleeping, and that the <b>temporal</b> <b>incoherence</b> of dreaming is simply a result of a form of memory loss. Locke takes a more analytical stand and says that it is absurd by definition to assert that conscious thinking occurs in an unconscious (sleeping) individual. Leibniz conjoins the two and develops an early theory of the subconscious, and argues that both waking and sleeping life is a continuous stream of consciousness. Jung further develops a theory of dreams that allows us to see dreaming as a way of knowing more about ourselves. Lastly we have Malcolm, who poses an interesting objection to previous dream theories in saying that we can’t verify that we are dreaming. Thus proclaiming that when we think of a dream we are actually of a memory of a dream...|$|E
40|$|In this {{supplementary}} material, {{we first}} show results on extra synthetic and real test sequences (Section 1). We {{also show that}} the method deals with viola-tions of our assumptions; for example, non-Lambertian surfaces (Section 2). We perform a sensitivity analysis and find that the results are quite insensitive to the parameter settings (Section 3). We explain the error metrics used to compare our estimated intrinsic video to ground truth (Section 4). We next provide more details on our optimization scheme (Section 5). We then depict more examples of non-local weights {{that are important to}} improve shading estimation (Section 6). Finally, we explain how our input data was created, and show the full results in addition to optical flow, occlusion and boundary intrinsic images for each example (Section 7). We overview our test procedure in Fig. 1 : The input is a video sequence and optical flow estimated from the sequence. We used the Classic+NL method [5] with its default settings to compute the optical flow. Occlusion maps and motion boundary maps detected from the flow are used in our coarse-to-fine decompo-sition algorithm. The output is the estimated albedo and shading sequences. These sequences of optical flow, occlusion, motion boundaries, albedo and shad-ing define intrinsic video. We measure an LMSE (local mean squared error) [3] of the reconstructed albedo and shading images, which is a standard error mea-sure in the field. We also introduce a new measure of <b>temporal</b> <b>incoherence,</b> which assesses how consistent the albedo is over time. Details of the LMSE and incoherence metrics are given below in Sections 4. 1 and 4. 2, respectively...|$|E

