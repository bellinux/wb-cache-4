98|355|Public
2500|$|McConkie's and Currie's saccade <b>target</b> <b>theory</b> {{is similar}} to {{research}} by Schneider {{who came up with}} a similar [...] "reference object theory". Both theories hypothesize that each saccade is preceded by processes in the visual system that chose an object as the target for the next fixation point. The object is usually located in peripheral vision. The object's features are stored as a mental representation in transsaccadic memory for identification of future fixations. These target features are searched for by the visual system when the eye lands on its fixation point, and [...] the physical features are compared to the mental representation of the target object. The theory assumes that visual stability is attained when these processes are successful (when the visual stimuli and the mental representation of the target object match). This process occurs before each saccade. Experiments performed by McConkie to support the role of a saccadic target in transsaccadic memory show two things: first, there is a limited peripheral area where a saccadic target exists, and second, attention is vital in recollection of items in the target area. The experiments involved recalling changes to an image that occurred in the peripheral area. Irwin performed similar experiments in which participants recalled letters that occurred near the target area. Due to confounding factors of the controlled environment in the studies, the involvement of saccade target objects is inferred and not established.|$|E
50|$|With {{the rise}} of the ability to present complex, {{real-world}} images on a computer screen, Dr. George McConkie, in the early 1990s, as part of the new initiatives of the new Beckman Institute for Advanced Science and Technology, began a renewed attempt to investigate why the world looked stable and continuous despite the shifting retinal input signal that accompanied each saccade. This research began when John Grimes and Dr. George McConkie (1996) began to use actual photographs to study visual stability. This development in change blindness research was able to show the effects of change blindness in more realistic settings. Additionally, further research stated that rather large changes will not be detected when they occur during saccadic movements of the eye. In the first experiment of this kind, in 1995, Blackmore et al forced saccades by moving the image and making a change in the scene at the same time. Observers' ability to detect the changes fell to chance. The effect was stronger using this method than when using brief grey flashes between images, although subsequent research has mostly used grey flashes or masking stimuli. Another finding based on similar studies stated that a change was easily picked up on by participants when the eye was fixated on the point of change. Therefore, the eye must be directly fixated on the area of change for it to be noticed. This was called the saccade <b>target</b> <b>theory</b> of transsaccadic memory of visual stability. However, other research in the mid-1990s has indicated that individuals still have difficulty detecting change even when they are directly fixated on a particular scene. A study by Rensink, O'Regan, & Clarke demonstrated that change blindness can have an effect even if the eye was fixated on a scene. In this study, a picture was presented followed by a blank screen or “masking” stimulus, which was followed by the initial picture with a change. The masking stimulus almost acts like a saccadic movement of the eye which makes it significantly more difficult for individuals to detect the change. This was a critical contribution to change blindness research because it demonstrated that a change can remain unnoticed with the smallest disruptions.|$|E
40|$|Abstract. This text applies grey <b>target</b> <b>theory</b> to {{evaluate}} the safety of highway alignment design. According to grey <b>target</b> <b>theory,</b> many factors which affect the safety were selected. The model of the safety evaluation of highway alignment design model was put forward based on grey <b>target</b> <b>theory.</b> After we apply this method in the practice, this method of the safety evaluation of highway alignment design is proved {{to be effective in}} course of the accuracy of the safety evaluation. Investigative results indicate that some subjective factors can be eliminated to a certain extent based on evaluation model of grey <b>target</b> <b>theory</b> in the course of alignment scheme choice，which make the choice result more objective. And it is a certain application value for the safety evaluation of highway alignment design...|$|E
40|$|We propose an {{approach}} for {{the integration of}} abduction and induction in Logic Programming. We de ne an Abductive Learning Problem as an extended Inductive Logic Programming problem where both the background and <b>target</b> <b>theories</b> are abductive theories and where abductive derivability is used as the coverage relation instead of deductive derivability. The two main bene ts of this integration are the possibility of learning in presence of incomplete knowledge and the increased expressive power of the background and <b>target</b> <b>theories.</b> We present the system LAP (Learning Abductive Programs) that is able to solve this extended learning problem and we describe, by means of examples, four di erent learning tasks that can be performed by the system: learning from incomplete knowledge, learning rules with exceptions, learning from integrity constraints and learning recursive predicates...|$|R
40|$|A {{method is}} {{proposed}} for latticizing {{a class of}} supersymmetric gauge theories, including N= 4 super Yang-Mills. The technique is inspired by recent work on ``deconstruction''. Part of the <b>target</b> <b>theory's</b> supersymmetry is realized exactly on the lattice, reducing or {{eliminating the need for}} fine tuning. (Talk based on the paper "Supersymmetry on a Spatial Lattice", hep-lat/ 0206019, by D. B. K., Emmanuel Katz and Mithat Unsal) ...|$|R
40|$|In 1995, Hill and Velani {{introduced}} the shrinking <b>targets</b> <b>theory.</b> Given a dynamical system ([0, 1],T), they investigated the Hausdorff dimension of sets of points whose orbits {{are close to}} some fixed point. In this paper, we study the sets of points well-approximated by orbits {T^n x}_n≥ 0, where T is an expanding Markov map with a finite partition supported by [0, 1]. The dimensions of these sets are described using the multifractal properties of invariant Gibbs measures. Comment: 24 pages, 3 figures; To appear in ETDS, 201...|$|R
40|$|This paper {{presents}} an information theoretic ILP system, NFOIL which, by {{the virtue of}} its unconditional look-ahead while searching for the <b>target</b> <b>theory,</b> guarantees the <b>target</b> <b>theory</b> {{to be found in}} the hypothesis space. The contribution of the paper is twofold: the first one is the discovery of some novel techniques for taming the intractable search space encountered by existing ILP systems and the second one is the implementation of look-ahead which is the result of a direct exploitation of the first one...|$|E
40|$|Diluted bull semen {{samples were}} {{irradiated}} with 180 kv X-rays. Dose response curves were measured {{for the survival}} fraction of the spermatozoa, and for the average velocity of the surviving cells. The dose response curves did not show a sensitivity threshold. The half-value dose was determined as 11 kr for the survival fraction and 10 kr for the average velocity. <b>Target</b> <b>theory</b> was adapted specially to explain {{the form of the}} measured dose response curves. From this <b>target</b> <b>theory</b> it was found that a small sensitive element is present in the sperm cell with a volume of approximately 0. 75 × 10 - 15 cm 3...|$|E
40|$|We {{construct}} lattice {{action for}} five-dimensional maximally supersymmetric Yang-Mills theory. This supersymmetric lattice formulation {{can be used}} to explore the non-perturbative regime of the continuum <b>target</b> <b>theory,</b> which has a known gravitational dual. Comment: v 2 : 20 pages, 0 figures. References added. New section added. Published versio...|$|E
40|$|We {{propose a}} non-perturbative {{criterion}} {{to examine whether}} recently proposed supersymmetric lattice gauge theory with preserved supercharges can have the desired continuum limit or not. Since the <b>target</b> continuum <b>theories</b> of the lattice models are extended supersymmetric gauge theories including the topological field theory as a special subsector, the continuum limits of them should reproduce the topological properties. Therefore, whether the topological quantities can be recovered at the continuum limit becomes a non-perturbative criterion. Then we propose it as a criterion. In this work, among the topological properties, we investigate the BRST cohomology on the two dimensional N=(4, 4) CKKU lattice model without moduli fixing mass term. We show that the BRST cohomology in the <b>target</b> continuum <b>theory</b> cannot be realized from the BRST cohomology on the lattice. From this result, we obtain the possible implication that the N = (4, 4) CKKU model cannot realize the <b>target</b> continuum <b>theory</b> if the non-perturbative effects are taken into account...|$|R
3000|$|... is {{the virtual}} load {{which we are}} <b>targeting.</b> In <b>theory</b> we may want to target 100 %; however, {{experience}} has shown that a margin should be left for handover users so that we will use [...]...|$|R
40|$|Basic {{representative}} set (BRS) {{is necessary}} for the induction of recursive concept using generalization under `-subsumption. To provide BRS, information is required about the <b>target</b> recursive <b>theory</b> which is yet to be learnt. Generalization method under inverse implication eliminates the strict necessity of the BRS, but is limited to learning very simple recursive programs. This paper proposes a new top-down approach implemented as a prototype system SMART, which learns fairly complex recursive programs from a small number of examples all lying on non-intersecting resolution path with respect to the <b>target</b> recursive <b>theory.</b> In addition, this paper illustrates some novel techniques for reducing the search complexities involved in logic program synthesis task...|$|R
40|$|<b>Target</b> <b>theory</b> {{is one of}} the {{essential}} concepts for understand-ing radiation biology. Although many complex interpreta-tions of <b>target</b> <b>theory</b> have been developed, its fundamental principle is that ‘inactivation of the target(s) inside an organ-ism by radiation results in the organism’s death’. The number of ‘targets ’ and the locations of these ‘targets ’ inside an organism are not always clear, although the ‘target ’ is considered as a unit of biological function. Assuming that when an average one-hit dose (inactivation of one target) per organism is used and one-hit of irradiation results in the organism’s death, then the probability of survival [P(1) = S] is expressed by: P 1 ð Þ S e 1 ð 1 Þ When the number of organism units and the number of trials are sufficiently large, the survival rate of an organism (cells...|$|E
40|$|This paper {{describes}} a type preserving and computationally adequate {{interpretation of a}} full-edged object calculus that supports message passing and constructs for object update and extension. The <b>target</b> <b>theory</b> is a higher-order -calculus with records and recursive folds/unfolds, polymorphic and recursive types, and subtyping. The interpretation specializes to calculi of nonextensible objects, and validates the expected subtyping relationship...|$|E
40|$|We {{consider}} operations {{between two}} multiplicative, complex orientable cohomology theories. Under suitable hypotheses, we construct a map from unstable to stable operations, left-inverse {{to the usual}} map from stable to unstable operations. The main example is where the <b>target</b> <b>theory</b> {{is one of the}} Morava K-theories in which case our map is closely related to the Bousfield-Kuhn functor. ...|$|E
50|$|XinMo Li's {{research}} <b>targets</b> on feminism <b>theory</b> {{and modern}} arts which criticize social structure and stereotype.|$|R
40|$|We {{present a}} new scheme to {{calculate}} isotope effects. Only selected frequencies at the <b>target</b> level of <b>theory</b> are calculated. The frequencies are selected by {{an analysis of}} the Hessian from a lower level of theory. We obtain accurate isotope effects without calculating the full Hessian at the <b>target</b> level of <b>theory.</b> The calculated frequencies are very accurate. The scheme converges to the correct isotope effect...|$|R
5000|$|Falk, D. Brain {{evolution}} in Homo: the [...] "radiator" [...] <b>theory</b> (<b>target</b> article). (1990). Behav. Brain Sci. 13:333-344.|$|R
40|$|The ICF Quarterly Reports is {{published}} four times each fiscal {{year by the}} Inertial Confinement Fusion Program at the Lawrence Livermore National Laboratory. The journal reports selected current research within the ICF Program. Major areas of investigation presented here include fusion <b>target</b> <b>theory</b> and design, target fabrication, target experiments, and laser and optical science and technology...|$|E
40|$|We {{consider}} operations {{between two}} multiplicative, complex orientable cohomology theories. Under suitable hypotheses, we construct a map from unstable to stable operations, left-inverse {{to the usual}} map from stable to unstable operations. In the main example, where the <b>target</b> <b>theory</b> {{is one of the}} Morava K-theories, this provides a simple and explicit description of a splitting arising from the Bousfield-Kuhn functor. ...|$|E
40|$|We {{present a}} general {{unification}} algorithm modulo Presburger Arithmetic for a restricted class of modularly specified theories where function {{symbols of the}} <b>target</b> <b>theory</b> have non arithmetic codomain sorts. Additionally, we comment on conditions guaranteeing decidability of matching and unification problems modulo more general theories than the arithmetic ones, which appear when automated deduction is implemented by combining conditional rewriting techniques and decision algorithms for built-in predicates...|$|E
5000|$|... "Concordance <b>Theory,</b> <b>Targeted</b> Partnership, and Counterinsurgency Strategy", Published online before print, Armed Forces & Society, July 20, 2011 0095327X11415491* ...|$|R
40|$|Proces s of the {{motivation}} {{is more difficult}} than most managers think. It {{is not possible to}} use the same attitude in motivation of different employees. People seem to have different needs, values, preferences and they set their own <b>targets.</b> <b>Theories</b> of motivation want to analyze and describe these differences. The company should understand its people, to be able to choose proper stimulative instruments, which will influence working behavior of empIoyees, their satisfaction and performance. The motivation pIan in the company presents system of rules and measures of which main goal is to achieve a good motivation of employees, to improve their satisfaction and optimal performance. This work wants to show how the particular company can setup good motivation pIan for its effective functioning and how to design organizations that maximize productivity...|$|R
40|$|I {{present a}} type-preserving {{translation}} that eliminates subtyping and bounded quantification without introducing any run-time costs. This translation {{is based on}} Mitchell and Pierce's encoding of bounded quantification using intersection types. I show that, previous negative observations notwithstanding, the encoding is adequate given a sufficiently rich <b>target</b> type <b>theory.</b> The necessary <b>target</b> type <b>theory</b> is made easily typecheckable by including a collection of explicit coercion combinators, which are already desired for eliminating subtyping. However, no form of coercion abstraction is necessary (even to support bounded quantification), leading to a simple target language. 1 Introduction Type-preserving compilers, those that utilize strongly typed intermediate languages, offer several compelling advantages over untyped compilers. A typed compiler can utilize type information to enable optimizations {{that would otherwise be}} prohibitively difficult or impossible. Internal type check [...] ...|$|R
40|$|Target {{analysis}} of radiation inactivation of mushroom tyrosinase yields different target sizes for diphenoloxidase and monophenoloxidase activities, which {{correspond to the}} subunits H and HL 2 (or HL), respectively. After gel electrophoresis of irradiated samples, all diphenoloxidase activity is observed at {{the same position as}} seen in the original material. Radiolytic fragments contain no detectable activity, consistent with a fundamental assumption of <b>target</b> <b>theory...</b>|$|E
40|$|We {{construct}} {{a variety of}} supersymmetric gauge theories on a spatial lattice, including N= 4 supersymmetric Yang-Mills theory in 3 + 1 dimensions. Exact lattice supersymmetry greatly reduces or {{eliminates the need for}} fine tuning to arrive at the desired continuum limit in these examples. A novel feature of our proposal is that ground state correlation functions in the <b>target</b> <b>theory</b> are measured in an excited state of the lattice theory...|$|E
40|$|AbstractA theory, in this context, is a Boolean formula; {{it is used}} to {{classify}} instances, or truth assignments. Theories can model real-world phenomena, and can do so more or less correctly. The theory revision, or concept revision, problem is to correct a given, roughly correct concept. This problem is considered here in the model of learning with equivalence and membership queries. A revision algorithm is considered efficient if the number of queries it makes is polynomial in the revision distance between the initial theory and the <b>target</b> <b>theory,</b> and polylogarithmic in the number of variables {{and the size of the}} initial theory. The revision distance is the minimal number of syntactic revision operations, such as the deletion or addition of literals, needed to obtain the <b>target</b> <b>theory</b> from the initial theory. Efficient revision algorithms are given for Horn formulas and read-once formulas, where revision operators are restricted to deletions of variables or clauses, and for parity formulas, where revision operators include both deletions and additions of variables. We also show that the query complexity of the read-once revision algorithm is near-optimal...|$|E
40|$|The Author(s) 2010. This {{article is}} {{published}} with open access at Springerlink. com Abstract We present a new scheme to calculate isotope effects. Only selected frequencies at the <b>target</b> level of <b>theory</b> are calculated. The frequencies are selected by {{an analysis of}} the Hessian from a lower level of theory. We obtain accurate isotope effects without calculating the full Hessian at the <b>target</b> level of <b>theory.</b> The calculated frequencies are very accurate. The scheme converges to the correct isotope effect...|$|R
40|$|A {{method is}} {{proposed}} for latticizing {{a class of}} supersymmetric gauge theories, including N= 4 super Yang-Mills theory. The technique is inspired by recent work on “deconstruction”. Part of the <b>target</b> <b>theory’s</b> supersymmetry is realized exactly on the lattice, reducing or {{eliminating the need for}} fine tuning. (Talk based on the paper Supersymmetry on a Spatial Lattice, hep-lat/ 0206019, by D. B. K., Emmanuel Katz and Mithat Unsal) 1. Exact supersymmetry on the lattice Supersymmetric gauge theories are expected to exhibit various fascinating phenomena, including electromagnetic duality, nontrivial conformal fixed points, monopole condensation, and relations to gravity and string theory through the AdS/CFT correspondence. It is desirable to study these theories nonperturbatively, and the lattice is the obvious tool. There has been much work done on lattice supersymmetry, but the prospects for practical success presently seem limited...|$|R
40|$|Questions {{connected}} to innovations {{were included in}} survey realized within the research <b>target</b> "New <b>theory</b> of economics and management in organizations and its adaptation processes". These questions also touched the area of measuring the intensity of innovations and impulses of innovations. Inovace, Innovations, Podněty pro inovace, impulses of innovations, Intenzita inovací, Intensity of innovations...|$|R
40|$|Diluted bull semen {{samples were}} bombarded with a 24 Mev proton beam. Dose {{response}} curves for {{the fraction of}} cells which survived the bombardment and for the average velocity of the surviving cells were measured. <b>Target</b> <b>theory</b> indicated {{a cross section of}} the sensitive volume of 2. 1 × 10 - 10 cm 2. Respiration measurements showed that the oxidative phosphorylation in the sperm remained coupled after the bombardments. The efficiency with which free energy from ATP hydrolysis was converted into mechanical work by the sperm was found to decrease after proton bombardment. The half-value dose for this effect was {{two and a half times}} higher than the half-value dose for motility damage. These respiration measurements indicate that the damage due to the bombardment is not to the metabolic system or to the contractile system in the sperm flagellum, but to a control system for the motility. The results of the <b>target</b> <b>theory</b> shows that this control system is localized in a small element of approximately 1600 A diameter. The centriole is tentatively proposed as being this control element...|$|E
40|$|A unified {{mathematical}} model is presented of the reversible effects of ultraviolet (UV) and photoreactivating (PR) {{light on the}} chloroplast-forming ability of dark-grown Euglena gracilis (var. bacillaris). This model {{is an extension of}} several aspects of <b>target</b> <b>theory</b> and also of a model for the decay of photoreactivability in Euglena proposed by Schiff et al. The data presented in several earlier papers are compared with the predictions of the proposed unified model and reasonably good agreement is found...|$|E
40|$|Graduation date: 1964 A {{probability}} {{model has}} been developed {{for the survival of}} irradiated bacteria with respect to the dose of radiation. This model is applicable to those bacterial taxa to which the <b>target</b> <b>theory</b> applies. Three estimation procedures are given for the purpose of obtaining estimates of the probability model's parameters. These procedures are: logarithmic estimation, iterative least-squares estimation and weighted iterative least-squares estimation. The possibility of multiple solutions when the latter two procedures are used is explored...|$|E
40|$|Abstract. We {{propose a}} non-perturbative {{criterion}} {{to examine whether}} recently proposed supersymmetric lattice gauge theory with preserved supercharges can have the desired continuum limit or not. Since the <b>target</b> continuum <b>theories</b> of the lattice models are extended supersymmetric gauge theories including the topological field theory as a special subsector, the continuum limits of them should reproduce the topological properties...|$|R
40|$|Marketing in {{libraries}} {{has been}} widely discussed in literature, but is often limited to either prescriptive writing on the application of marketing theory to libraries, or descriptions of marketing at individual libraries with little theoretical basis. The purpose {{of this research was}} to compare the teen marketing practiced by public libraries with library marketing theory, and to discover whether the application of theory is a conscious decision by libraries. Staff were interviewed at two New Zealand public library networks to discover whether they considered marketing <b>targeting</b> <b>theory</b> and the marketing mix when marketing to teens. It was found that while both library networks did do some formal teen marketing, the majority of marketing was conducted more informally by individual community libraries. Libraries struggled in particular with defining their teen users, and the marketing mix was dealt with in an ad hoc manner. Overall, library marketing was more tactical than strategic...|$|R
40|$|Basic {{representative}} set (BRS) {{is necessary}} for the induction of recursive theory using generalization under `-subsumption. To provide BRS, information is required about the <b>target</b> recursive <b>theory</b> which is yet to be learnt. Generalization under inverse implication partly eliminates the necessity of the BRS, but is limited to learning very simple recursive scheme. This paper proposes a new top-down ILP system SMART, which learns complex recursive programs from a small number of examples all lying in non-intersecting resolution path with respect to the <b>target</b> recursive <b>theory.</b> 1 Introduction Induction of recursive programs deserves some special attention. Top-down induction algorithms employing extensional evaluation require selective examples in order to induce recursive theories. For instance, presence of the example reverse([1, 2, 3],[3, 2, 1]) necessarily requires the existence of reverse([2, 3],[3, 2]) in the training set, because extensional proof of the former requires the later. Thes [...] ...|$|R
