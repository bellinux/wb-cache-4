5|794|Public
50|$|WMCCM is {{an online}} {{marketplace}} providing e-business <b>tools,</b> <b>capability</b> {{and support to}} engineering businesses in the region. As of 2015, the website had over 12,000 members.|$|E
40|$|Documentation of the {{preliminary}} software {{developed as a}} framework for a generalized integrated robotic system simulation is presented. The program structure is composed of three major functions controlled by a program executive. The three major functions are: system definition, analysis tools, and post processing. The system definition function handles user input of system parameters and definition of the manipulator configuration. The analysis tools function handles the computational requirements of the program. The post processing function allows for more detailed study of the results of analysis tool function executions. Also documented is the manipulator joint model software to be used as the basis of the manipulator simulation which {{will be part of the}} analysis <b>tools</b> <b>capability...</b>|$|E
40|$|Analysing {{the data}} is an {{important}} part of a research in data science. There are many tools that can be used in analysing a data set to get the experiment results for classification, clustering and others. However, the researchers are concerned about how to increase the efficiency in analysing a data set. In this paper, three open source tools which are the Waikato Environment for Knowledge Analysis (WEKA), Konstanz Information Miner (KNIME) and Salford Predictive Modular (SPM) were compared to identify the better processing tools in evaluating the presented data. All of these tools have their own different characteristics. WEKA can handle pre-processing of data and then analyses it based on different algorithms. It is suitable to be used for classification, regression, clustering, association rules, and visualisation. The algorithms can be applied directly to a data set or called from its own Java code. KNIME is more inclined towards producing graphical view, while SPM is a highly accurate and ultra-fast analytics which also data mines platforms for any sizes, complexity or organisation. The results illustrate the <b>tools</b> <b>capability</b> in analysing data sets and evaluators in an efficient and effective manner...|$|E
40|$|The {{emergence}} of financially and environmentally conscious manufacturing {{has resulted in}} a need for efficient process planning in today's manufacturing system. Process planning based on nominal machine tool specifications, limits predictive capabilities with regard to the final part quality. More efficient process plans can be achieved once an accurate machine <b>tool</b> <b>capability</b> profile has been defined. Machine <b>tool</b> <b>capability</b> profiles deliver up-To-date resource attributes such as availability, health and applicability into the process-planning stage. A manufacturing resource's health degrades continuously throughout its life cycle due to environmental factors, part wear, operator competence, etc. Identifying and compensating for these factors during process planning may alleviate material wastage and machining estimate production time and cost via decision-making mechanisms. In this paper, the STEP-NC Standard is used to represent a model of machining resources, including worktable, spindle and tool status during a machine tool's operational lifespan. A prototype of machine <b>tool</b> <b>capability</b> profile enabled process planning system is then presented and tested to highlight the advantages of this approach...|$|R
50|$|Eucalyptus 3.4, {{released}} on October 24, 2013, added new features including improved image management and migration <b>tools,</b> <b>capabilities</b> for warm upgrades, a hybrid cloud user console to manage both Eucalyptus and AWS resources, Identity and Access Management (IAM) roles, and improved High Availability (HA) capabilities.|$|R
5000|$|More {{powerful}} {{data import}} <b>tools,</b> de-duplication <b>capability</b> now included ...|$|R
40|$|The {{research}} is framed within the quantitative approach and mode of Feasible Project {{was held at}} the Francisco de Paula Santander, Northern Department of Santander (Colombia) University with populations of entrepreneurs, high school students, alumni and representatives of clusters different sectors of the region. The fundamental objective of the {{research is}} to design a proposed model to evaluate the social relevance in academic programs offered at the Francisco de Paula Santander (UFPS) University. Data collection was conducted through surveys, semi-structured interviews, panel, mathematician SWOT, using six sigma. The selection of indicators includes indices linking systems at national and international levels, and hierarchical multivariate analysis, principal components. The creation of the model followed different phases as a result of information analysis and includes diagnostics, measurement, analysis, improvement, monitoring and control, also contains models to analyze population projections to support decision-making. For the analysis and interpretation of information diagramming <b>tools,</b> <b>capability</b> studies, multivariate analyzes were used, analysis was carried out following model Rash through Item response theory, design of experiments and using triangulation as an element involved in obtaining multiple views of the research problem. The proposed model expected to sustain the role and social mission of the UFPS to offer knowledge producing, sharing and socializing in the innovation system in the formation of human capital for society and companies in the region. The model was validated through structural analysis...|$|E
40|$|In the past, {{noise was}} {{not such a}} big issue in digital {{integrated}} circuits. However, the continuous progress in semiconductor technology put the noise issue among the major concerns of digital CMOS IC designers. This study concerns with the noise immunity of static CMOS low power digital design by investigating the noise immunity of the current low power static CMOS design schemes and presenting a fast and accurate methodology to evaluate the noise sensitivity of the different nodes in a design during the design phase. In addition, for the modeling/characterization of noise in digital circuits, techniques to measure the non-periodic noise and sensing the peak minimum/maximum fluctuation on-chip have been presented. The study is presented in five chapters in addition to conclusion. //　The first chapter includes a background about the power consumption and noise issues in current and future VLSI/ULSI digital design. It also includes {{the objectives of the}} study and thesis organization. //　In chapter two, we present the effect of noise on the performance of a selected group of low power as well as traditional digital design techniques. First, we present a model for the different noise sources in the digital circuits. Then we applied the model to a selected group of low power and traditional designs as testing circuits. The noise immunity of the tested schemes has been reported in terms of logic error and delay error. At the end of the chapter, we present a methodology for leakage power saving {{and at the same time}} has high noise immunity. One of the ways to increase the noise immunity of a digital circuit is to give special strengthen considerations to the soft (weak) parts (nodes) against noise. Since it is time consuming to analyze the noise-sensitivity of different nodes in a big design using transistor level simulators, an analytical (fast and accurate) method is required. //　In chapter three, we present a methodology to evaluate the noise-induced logic error probability in a given CMOS digital design in terms of supply voltage, threshold voltage, noise level and circuit configuration. At first, we modeled the noise immunity of the different logic gates in terms logic error probability including the effect of supply and threshold voltage, which is called electrical masking. Then, time masking has been modeled to include the variation of the spurious pulse width and generation time in the overall logic error probability. Moreover, the logic masking effect has been also considered. The electrical, timing and logic masking have been combined to form the overall logic error probability model. The model has been used to evaluate the logic error probability caused by the noise at the different nodes in digital circuit examples. The model results have been compared with results obtained from HSPICE simulation. The results reveal that the model fit with the expected simulation results achieving speedup factor of more than 1000 over HSPICE. Moreover, the calculation time of the methodology is linearly proportional with the number of gates in a design, and hence, the method is suitable for investigating the noise immunity of the big circuits. The model can be used to identify the weak parts against the noise in a given design during the design phase and hence it helps the designer in giving specific design considerations to strengthen the weak nodes. The methodology is based on hypothetical noise distribution. So that, for more accurate results, a real noise distribution should be provided. //　In chapter four we present, first, an overview on the previous works regarding the on-chip noise measurement has been given. To avoid the problems attached with the previous designs, an on-chip noise detector has been designed and fabricated using 0. 18 μm technology. The detector can detect the single-event or the non-periodic signals within the measurement time window. It is equipped with a programmable voltage divider to be able to detect high-swing signals having maximum theoretical frequency of 5 GHz. The bandwidth of the output signal can be controlled by the user to fit the monitoring <b>tools</b> <b>capability</b> off-chip and to avoid the effects of the on-chip parasitic elements and hence conventional equipments can be used to measure the signal off-chip. Moreover, the detector is synthesizable and the designer can flexibly adjust its main parameters. A test chip is fabricated and tested successfully. The detector's design has been modified to increase the sampling rate. Upon the simulation results, the modified version is capable to measure signals of frequency (theoretically) up to 10 GHz. //　Chapter five includes the description of a CPU-interfaced system to monitor the minimum/maximum fluctuation in both VDD and ground in a design. In addition to the magnitude information, the system has the ability to report the timing and spatial information of the spurious pulse. The system is designed using Rohm 0. 18 μm technology. The fluctuation is detected by comparing with a reference voltage supplied form off-chip, and the fluctuation information is send off-chip in digital format. The detector is simple, therefore, it can be replicated within a design to detect the fluctuations on VDD/Ground net at different spots and hence, safe operation can be guaranteed. The detector is interfaced by a CPU and hence it is suitable for future VLSI/ULSI circuits. //　Finally, we conclude the study in chapter six. 報告番号: 甲 21838; 学位授与年月日: 2006 - 09 - 29; 学位の種別: 課程博士; 学位の種類: 博士(工学); 学位記番号: 博工第 6368 号; 研究科・専攻: 工学系研究科電子工学専...|$|E
5000|$|February 26, 1999 - Luggage can {{be stored}} in boxes and <b>tool</b> <b>capability</b> fishing rod case, rod magnet stand, {{water-repellent}} seat cover, handy features with hazard lights, refrigerator temperature, equipped with a portable power sport fishing with a small light The specially equipped vehicles to enjoy a [...] "fishing gear" [...] released.|$|R
5000|$|Adobe Captivate - A rapid eLearning <b>tool</b> with <b>capability</b> {{to publish}} {{directly}} the Connect server ...|$|R
5000|$|... #Caption: A modern CNC {{tool grinder}} with {{automatic}} wheel pack exchanger and <b>tool</b> loading <b>capabilities.</b>|$|R
40|$|Goals of the Project * Experience how Moodle works: as a teacher, a learner, and {{a course}} designer. * Learn various Moodle <b>tools,</b> <b>capabilities,</b> and limitations. * Engage with other faculty {{to see how}} they use Moodle and how the library can support them. * Explore ways to {{highlight}} a variety of library-funded information resources. * Experiment with embedding library and information resources directly into Moodle pages...|$|R
40|$|In this paper, we {{introduce}} a new tool that enables collaboration in Model-Based Design. To accomplish this, we outline a recipe {{within the context of}} <b>tool</b> <b>capabilities</b> that will motivate organizations large and small, to jumpstart team initiatives while lowering costs. Categories and Subject Descriptors K. 6. 1 [Management of Computing and Information Systems]: Project and People Management – systems analysis and design, systems development...|$|R
50|$|With {{every new}} release, out of box {{features}} and functionalities were introduced. Later, AnalytiX DS began to add new modules including Release Management, Reference Data Manager, Code Set Manager, CATfX, LiteSpeed Conversion, Code automation Templates for Data Vault, Mapping Manager Big Data Edition, Data Quality Assessment Manager(DQAM), Metadata Management, Data Vault-Code Gen Bundle, and Test Manager, which extends the <b>tools</b> <b>capabilities</b> {{above and beyond}} management of the data mapping process.|$|R
40|$|Tools for remote team {{collaboration}} within {{businesses have}} been available since the mid- 1980 s. Two opposing trends cause complete collaboration solutions to remain elusive. On the one hand, core <b>tool</b> <b>capabilities</b> are developed as point solutions, and then extra functions are added. These added functions may not integrate well with or be as fully developed as the core functionality. On the other hand, enterprises are rapidly globalizing and becoming more dependent on comprehensive collaboration applications to coordinate distributed teams. This means that overall productivity is affected by how well <b>tools,</b> processes, and <b>capabilities</b> are integrated; the tools should not be just a collection of separate features/functions...|$|R
40|$|We {{present a}} {{holistic}} framework for analyzing and specifying collaboration solutions, developed by an {{oil and gas}} company in response to practical needs in supporting integrated collaboration and information management. A typology of collaboration <b>tool</b> <b>capabilities,</b> termed the Wheel of Collaboration Tools (WCT), is described. We assess its contributions, and discuss areas of application and potential further development. Our intent is to stimulate discussion and research related {{to this type of}} collaboration modeling...|$|R
40|$|The {{problem of}} rapidly {{generating}} optimal parallel circuit implementations from high level, formal descriptions of affinely indexed algorithms is addressed {{here in the}} context of reconfigurable FPGA-based computing. A specialized software tool, SPADE, is described that will take a user's high level code description of his algorithms and automatically generate an abstract latency-optimal, locally-connected parallel array of elemental processing elements. A design example, the Faddeev algorithm, is used to illustrate the <b>tool's</b> <b>capabilities.</b> 1...|$|R
40|$|This work {{deals with}} issues of {{automatic}} code generation for microcontrollers. Knowledge of this area is subsequently used for adjustment of the part of code of the experimental vehicle Car 4. The main theme of this work is to design a control platform of the based platform dsPIC, which serve for driving Car 4. <b>Tooling</b> <b>capabilities</b> for automatic code generation in creating firmware for this remote control are then tested in practice on this remote control...|$|R
40|$|Proposition of {{answer from}} the INRIA-ATLAS {{team to the}} OMG Request For Information named "MDA Tool Capabilities"In the past years, the INRIA ATLAS Group has been {{building}} an MDA tool bench named AMMA (ATLAS Model Management Architecture). The present discusses the main characteristics and overall vision of this platform {{in the context of}} the OMG MDA <b>Tool</b> <b>Capabilities</b> RFI. In the following pages, we will provide an overall description of what MDA <b>tool</b> <b>capabilities</b> means for the ATLAS Group. We will show, within this response, how our overall Model-Driven Engineering (MDE) vision and implemented platform bring answers to the different RFI questions. We will also highlight the various MDA tool-specific needs and requirements we have already identified, even though some are not yet fully addressed by the current version of our platform. In a more organizational point of view, we have tried to follow as much as possible the logical sequence of the RFI proposed questions; however in many cases we have answered several questions at once. Our goal is not to answer exhaustively all the questions but more to cover all the different requirement areas...|$|R
40|$|Video {{digitization}} {{techniques have}} been developed to analyze the exhaust plume of the Space Shuttle Main Engine. Temporal averaging and a frame-by-frame analysis provide data used to evaluate the capabilities of image processing techniques for use as measurement <b>tools.</b> <b>Capabilities</b> include the determination of the necessary time requirement for the Mach disk to obtain a fully-developed state. Other results show the Mach disk tracks the nozzle for short time intervals, and that dominate frequencies exist for the nozzle and Mach disk movement...|$|R
40|$|Abstract. Machining {{parameters}} optimization in face-milling the {{hypoid gear}} was often {{needed in order}} to obtain lowest cost or highest productivity. In this study, the optimum value of machining parameters including feed rate, rotation speed are obtained using improved harmony search algorithm(IHSA), to yield minimum total time while considering constrains such as allowable cutting speed, tool life and machine <b>tool</b> <b>capabilities.</b> Results indicate that the IHSA converged to optimum solution with similar accuracy in comparison with the genetic algorithm (GA) ...|$|R
40|$|An {{overview}} of microsystems technology is presented {{along with a}} discussion of the recent trends and challenges associated with its development. A typical bottom-up design methodology is described and we propose, in contrast, an efficient and effective top-down methodology. We illustrate its implementation with the development of a microsystem design that has been completed and fabricated in CMOS technology. Gaps in the <b>tool</b> <b>capabilities</b> are identified and suggestions for future directions in CAD tool support for microsystems technology are presented. 1...|$|R
40|$|In {{this paper}} we present the Model Advisor Transformation Extension (MATE). The purpose of MATE is to {{complement}} the functionality of the MathWorks MATLAB®, Simulink®, and Stateflow®, Model Advisor, and to extend the <b>tool’s</b> <b>capabilities</b> with regard to model transformation and improvement functions. Examples of MATE features are: automatic or interactive model analysis and repair functions; design pattern instantiation; beautifier operations. We present typical use cases for MATE and discuss {{the relevance of the}} MATE approach compared with other available tools and approaches...|$|R
40|$|The Desert {{software}} engineering environment is {{a suite of}} tools developed to enhance programmer productivity through increased tool integration. It introduces an inexpensive form of data integration to provide additional <b>tool</b> <b>capabilities</b> and information sharing among tools, uses a common editor to give high-quality semantic feedback and to integrate different types of software artifacts, and builds virtual files on demand to address specific tasks. All this is done in an open and extensible environment capable of handling large software systems. 1...|$|R
40|$|Paper {{from the}} 2006 20 th anniversary conference on Computer {{supported}} cooperative workWe present a holistic framework for analyzing and specifying collaboration solutions, developed by an {{oil and gas}} company in response to practical needs in supporting integrated collaboration and information management. A typology of collaboration <b>tool</b> <b>capabilities,</b> termed the Wheel of Collaboration Tools (WCT), is described. We assess its contributions, and discuss areas of application and potential further development. Our intent is to stimulate discussion and research related {{to this type of}} collaboration modeling...|$|R
40|$|AbstractWe present SPHIN, a model checker for {{reconfigurable}} {{hybrid systems}} {{based on the}} model checker SPIN. We observe that physical (analog) mobility can be modeled {{in the same way}} as logical (discrete) mobility is modeled in the π-calculus by means of channel name passing. We chose SPIN because it supports channel name passing and can model reconfigurations. We extend the syntax of PROMELA and the verification algorithms based on the expected semantics. We demonstrate the <b>tool's</b> <b>capabilities</b> by modeling and verifying a reconfigurable hybrid system...|$|R
40|$|While a {{large number}} of tools have been {{developed}} to support application portability, high performance application developers often prefer to use vendor-provided, non-portable programming interfaces. This phenomena indicates the mismatch between user priorities and <b>tool</b> <b>capabilities.</b> This paper summarizes the results of a user survey and a developer survey. The user survey has revealed the user priorities and resulted in three criteria for evaluating tool support for portability. The developer survey has resulted in the evaluation of portability support and indicated the possibilities and difficulties of improvements...|$|R
5000|$|Haskins Laboratories is equipped, in-house, with a {{comprehensive}} suite of <b>tools</b> and <b>capabilities</b> to advance its mission of research into language and literacy. These include (as of 2014): ...|$|R
40|$|MYRRHA is an {{advanced}} multi-purpose irradiation facility under development at SCK-CEN in Mol, Belgium. In {{order to ensure}} an economical and safe operation of the reactor, an in-core fuel management tool is being developed within the project to address the loading pattern optimization problem. In the paper, {{the current version of}} the tool – its architecture and design, unique features,and the field of its application, are presented. In {{the second part of the}} paper, the <b>tool’s</b> <b>capabilities</b> are demonstrated on simple MYRRHA in-core fuel management optimization problems. status: publishe...|$|R
40|$|Abstract. Manufacturing Execution System (MES) has {{significantly}} evolved into {{more powerful and}} integrated software applications. However, MES applications still fall short of adding decision-making <b>tools</b> <b>capabilities</b> in adaptive manufacturing. On the base of analyzing the deficiencies of the traditional MES, this paper proposes the model of MES based multi-agent and the Contract Net based mechanism of cooperation planning. In the process of communication among multi-agents, strategy agent cooperates with schedule agent so as to realize dynamic and adaptive scheduling. Finalay, system framework based on CORBA and Multi-Agent System was put forward...|$|R
40|$|An {{optimized}} {{metal cutting}} process plan {{can only be}} developed with an accurate capability profile of a machine tool. Based on the information within this profile, a manufacturing decision making process can ascertain the time and production cost of parts. In this paper, a standardized methodology for modelling manufacturing resources is realized to enable accurate representation of actual resources and custom constraints. An example case study demonstrates {{the application of the}} machine <b>tool</b> <b>capability</b> profile through the selection of available cutting tools rather than using nominal cutting tools...|$|R
40|$|This article {{describes}} the motivation, development, and implementation of a software tool, www. vaccineselection. com, introduced to assist health care professionals and public health administrators in managing pediatric vaccine purchase decisions and making economically sound formulary choices. The tool integrates general operations research methodologies with specific local practice choices to solve for the lowest overall cost set of vaccines required to immunize a child according to the Recommended Childhood Immunization Schedule. A description of the <b>tool's</b> <b>capabilities</b> is provided. Results {{on the use of}} the software tool are reported and discussed...|$|R
40|$|This paper {{describes}} an evaluation on software documentation generated using redocumentation approaches and tools. The evaluation {{is based on}} the selected Document Quality Attributes (DQA). Firstly, the paper presents an overview of the software redocumentation and the main components involved in the process for better understanding of the redocumentation. Consequently, several approaches and tools are highlighted in the context of aiding understanding to support the software evolution. Finally, the evaluation identifies some aspects of DQA that might benefit from refinement to better reflect the redocumentation approaches and <b>tools</b> <b>capabilities</b> that support the software maintenance...|$|R
50|$|The virtual {{radiology}} network {{can help}} radiologists manage image-related workflow across distributed sites, providing productivity-enhancing <b>tools</b> and <b>capabilities</b> that include universal work lists, automatic routing, workload balancing and management control dashboards.|$|R
40|$|INERIS {{has set up}} {{large-scale}} fully instrumented {{experiments to}} study the formation of flammable clouds resulting from a finite duration spillage of hydrogen in a quiescent room (80 m 3 chamber). Concentration, temperature and mass flow measurements were monitored during the release period and several hours after. Experiments were carried out for mass flow rates ranging from 0, 2 g/s to 1 g/s. The instrumentation allowed the observation and quantification of rich hydrogen layers stratification effects. This paper presents both the experimental facility and the test results. These experimental results {{can be used to}} assess and benchmark CFD <b>tools</b> <b>capabilities.</b> ...|$|R
40|$|CAD {{tools are}} {{necessary}} {{for even the most}} rudimentary hardware designs when the target technology is FPGA or VLSI. This paper presents an experiment in the use of vendor-supplied vs. third-party tools, of high-level design (behavioral) vs. cell-based design, of technology tradeoffs among different vendors, and of design styles among designers. The experiment is a n-version hardware design project, in which many designs were made from common specifications, using different CAD tools and design styles. Some interesting conclusions can be drawn regarding the process, and these conclusions show new trends in terms of <b>tool</b> <b>capabilities</b> and desirable design flows...|$|R
