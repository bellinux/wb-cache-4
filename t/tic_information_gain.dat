0|10000|Public
5000|$|The <b>information</b> <b>gain</b> {{ratio is}} just the ratio between the <b>information</b> <b>gain</b> and the {{intrinsic}} value: ...|$|R
40|$|We {{investigate}} {{the relationship between}} the <b>information</b> <b>gain</b> and the interaction strength between the quantum system and the measuring device. A strategy is proposed to calculate the <b>information</b> <b>gain</b> of the measuring device as the coupling strength is a variable. For qubit systems, we prove that the <b>information</b> <b>gain</b> increases monotonically with the coupling strength. It is obtained that the <b>information</b> <b>gain</b> of the projective measurement along the x-direction reduces with the increasing of the measurement strength along the z-direction, and a complementarity of <b>information</b> <b>gain</b> in the measurements along those two directions is presented. Comment: 7 pages, 1 figure...|$|R
30|$|<b>Information</b> <b>gain,</b> an {{evaluation}} method based on entropy, involves lots of mathematical theories and complex theories and formulas about entropy. It {{is defined as}} the amount of information that a certain feature item is able to provide for the whole classification, taking no account of the entropy of any features but the difference value of entropy of the feature [17]. According to the training data, it computes <b>information</b> <b>gain</b> of each feature item and deletes items with small <b>information</b> <b>gain</b> while the rest are ranked in a descending order based on <b>information</b> <b>gain.</b>|$|R
5000|$|In ID3, <b>information</b> <b>gain</b> can be {{calculated}} (instead of entropy) for each remaining attribute. The attribute with the largest <b>information</b> <b>gain</b> is used to split the set [...] on this iteration.|$|R
3000|$|In {{order to}} {{understand}} the contribution from each feature for link prediction in the PPI network, we comparatively analyzed the predictive power of the features. To measure the relative importance of different features, we analysed the <b>information</b> <b>gain</b> with respect to each feature. <b>Information</b> <b>gain</b> is based on the decrease in entropy after a dataset is split on an attribute. An attribute with highest <b>information</b> <b>gain</b> is selected for the split. We obtained the <b>information</b> <b>gain</b> of an attribute as follows: Information gain=(Entropy of distribution before the split) - (entropy of distribution after the split) [...]...|$|R
40|$|Abstract — In this paper, {{we examine}} {{adaptive}} compression policies, when {{the sequence of}} vector-valued measurements to be compressed is noisy and the compressed variables are themselves noisy. The optimization criterion is <b>information</b> <b>gain.</b> In the case of sequential scalar compressions, the unit-norm compression vectors that greedily maximize per-stage <b>information</b> <b>gain</b> are eigenvectors of an a priori error covariance matrix, and the greedy policy selects them according to eigenvalues of a posterior covariance matrix. These eigenvalues depend on all previous com-pressions and are computed recursively. A water-filling solution is given for the optimum compression policy that maximizes net <b>information</b> <b>gain,</b> under a constraint on the average norm of compression vectors. We provide sufficient conditions under which the greedy policy for maximizing stepwise <b>information</b> <b>gain</b> actually is optimal {{in the sense of}} maximizing the net <b>information</b> <b>gain.</b> In the case of scalar compressions, our examples and simulation results illustrate that the greedy policy can be quite close to optimal when the noise sequences are white. Index Terms — Entropy, <b>information</b> <b>gain,</b> compressive sensing, compressed sensing, greedy policy, optimal policy...|$|R
5000|$|The key {{concept in}} the {{exploration}} {{problem is the}} notion of <b>information</b> <b>gain,</b> that is, the amount of knowledge acquired while pushing the frontiers. A probabilistic measure of <b>information</b> <b>gain</b> is defined by the entropy ...|$|R
30|$|Time {{complexity}} of mutual information computation {{is similar to}} <b>information</b> <b>gain.</b> Its mean value is <b>information</b> <b>gain.</b> The deficiency of mutual information is that the score is extremely impacted by marginal probabilities of words [13, 14].|$|R
30|$|<b>Information</b> <b>gain</b> is {{a measure}} that {{provides}} a set of same-rank training records for each feature. The criterion of “Entropy” which is widely used in information theory {{is also used to}} determine <b>information</b> <b>gain</b> (Han et al. 2012).|$|R
3000|$|The entropy then is {{used with}} the score {{equation}} Score(v) = InfoGain(v)/AnonyLoss([...] v [...]) + 1, which defines the relation between <b>information</b> <b>gained</b> and anonymization loss. As shown in Eq.  7, the <b>information</b> <b>gained</b> adopts the entropy equation [24].|$|R
30|$|Calculate the <b>information</b> <b>gain.</b>|$|R
50|$|In {{decision}} tree learning, <b>Information</b> <b>gain</b> ratio is {{a ratio of}} <b>information</b> <b>gain</b> to the intrinsic information. It is used to reduce a bias towards multi-valued attributes by taking the number and size of branches into account when choosingan attribute.|$|R
2500|$|As {{stated above}} Busch's theorem {{prevents}} a free lunch: {{there can be}} no <b>information</b> <b>gain</b> without disturbance. However the tradeoff between <b>information</b> <b>gain</b> and disturbance has been characterized by many authors including Fuchs and Peres; [...] Fuchs; [...] Fuchs and Jacobs; and Banaszek.|$|R
30|$|The <b>information</b> <b>gain</b> {{is based}} on the {{decrease}} in entropy after an information system is split on a block by a selector. Constructing a decision tree is all about finding a block as well as a selector that returns the highest <b>information</b> <b>gain.</b>|$|R
5000|$|As {{stated above}} Busch's theorem {{prevents}} a free lunch: {{there can be}} no <b>information</b> <b>gain</b> without disturbance. However the tradeoff between <b>information</b> <b>gain</b> and disturbance has been characterized by many authors including Fuchs and Peres; [...] Fuchs; [...] Fuchs and Jacobs; and Banaszek.|$|R
40|$|International audienceContent-based image {{retrieval}} {{systems are}} meant to retrieve the most similar images of a collection to a query image. One of the most well-known models widely applied for this task is the bag of visual words (BoVW) model. In this paper, we introduce a study of different <b>information</b> <b>gain</b> models used {{for the construction of}} a visual vocabulary. In the proposed framework, <b>information</b> <b>gain</b> models are used as a discriminative information to index image features and select the ones that have the highest <b>information</b> <b>gain</b> values. We introduce some extensions to further improve the performance of the proposed framework: mixing different vocabularies and extending the BoVW to bag of visual phrases. Exhaustive experiments show the interest of <b>information</b> <b>gain</b> models on our retrieval framework...|$|R
40|$|Intrinsically {{motivated}} behaviors {{have been}} defined as behaviors that do not come with any primary external rewards. Previous studies on intrinsic motivation has often depended on self-report measures, or only tested how subjects’ motivation is impacted by punishments or no gain differences. The present study aims to test these two conditions, {{with the addition of}} a third, where selecting an <b>information</b> <b>gain</b> option results in reward. This will be tested empirically using an existing information theoretic operationalization, where subjects will choose between <b>information</b> <b>gain</b> or no <b>information</b> <b>gain.</b> Results of the study show that <b>information</b> <b>gain</b> has some degree of attraction when subjects expect no gain differences, and when comparing punishment and reward conditions.  Curiosity and the reward of learnin...|$|R
40|$|Abstract—The {{purpose of}} this article is to examine the greedy {{adaptive}} measurement policy in the context of a linear Guas-sian measurement model with an optimization criterion based on <b>information</b> <b>gain.</b> In the special case of sequential scalar measurements, we provide sufficient conditions under which the greedy policy actually is optimal in the sense of maximizing the net <b>information</b> <b>gain.</b> In the general setting, we also discuss cases where the greedy policy is not optimal. Index Terms—entropy, <b>information</b> <b>gain,</b> compressive sensing, compressed sensing, greedy policy, optimal policy...|$|R
30|$|Choosing the {{greatest}} value of <b>information</b> <b>gain.</b>|$|R
5000|$|... #Subtitle level 2: Kullback-Leibler {{divergence}} (<b>information</b> <b>gain)</b> ...|$|R
50|$|<b>Information</b> <b>Gain</b> is {{also known}} as Mutual Information.|$|R
40|$|In this paper, {{the short}} coming of ID 3 's inclining to choose {{attributes}} with many values is discussed, {{and then a}} new decision tree algorithm which is improved version of ID 3. Our proposed methodology uses greedy approach to select the best attribute. To do so the <b>information</b> <b>gain</b> is used. The attribute with highest <b>information</b> <b>gain</b> is selected. If <b>information</b> <b>gain</b> is not good then again divide attributes values into groups. These steps are done until we get good classification/misclassification ratio. The proposed algorithms classify the data sets more accurately and efficiently...|$|R
40|$|Junius and Oosterhaven (2003) {{developed}} the GRAS algorithm that minimizes the <b>information</b> <b>gain</b> when updating input-output tables with {{both positive and}} negative signs. Jackson and Murray (2004), however, claim that minimizing squared differences in coefficients produces a smaller <b>information</b> <b>gain,</b> which is theoretically impossible. In this comment, calculation errors are sorted out from differences in measures, and it is shown that the <b>information</b> <b>gain</b> needs to be taken in absolute terms when increasing and decreasing cell values occur together. The numerical results show that GRAS outperforms both sign-preserving alternatives in all but one comparison of lesser economic importance. Moreover, as opposed to the result of Jackson and Murray, they show that minimizing absolute differences consistently outperforms minimizing squared differences, which overweighs large errors in small coefficients. RAS, biproportional updating, input-output, <b>information</b> <b>gain,...</b>|$|R
40|$|We {{examine the}} binding of {{transcription}} factors to DNA {{in terms of}} an information transfer problem. The input of the noisy channel is the biophysical signal of a factor bound to a DNA site, and the output is a distribution of probable DNA sequences at this site. This task involves an inherent tradeoff between the <b>information</b> <b>gain</b> and the energetics of the binding interaction - high binding energies provide higher <b>information</b> <b>gain</b> but hinder the dynamics of the system as factors are bound too tightly. We show that adaptation of the binding interaction towards increasing information transfer under a general energy constraint implies that the <b>information</b> <b>gain</b> per specific binding energy at each base-pair is maximized. We analyze hundreds of prokaryote and eukaryote transcription factors from various organisms to evaluate the discrimination energies. We find that, in accordance with our theoretical argument, binding energies nearly maximize the <b>information</b> <b>gain</b> per energy. This work suggests the adaptation of <b>information</b> <b>gain</b> as a generic design principle of molecular recognition systems...|$|R
40|$|We explore quantum {{signatures}} of classical chaos {{by studying the}} rate of <b>information</b> <b>gain</b> in quantum tomography. The tomographic record consists of a time series of expectation values of a Hermitian operator evolving under application of the Floquet operator of a quantum map that possesses (or lacks) time reversal symmetry. We find {{that the rate of}} <b>information</b> <b>gain,</b> and hence the fidelity of quantum state reconstruction, depends on the symmetry class of the quantum map involved. Moreover, we find an increase in <b>information</b> <b>gain</b> and hence higher reconstruction fidelities when the Floquet maps employed increase in chaoticity. We make predictions for the <b>information</b> <b>gain</b> and show that these results are well described by random matrix theory in the fully chaotic regime. We derive analytical expressions for bounds on <b>information</b> <b>gain</b> using random matrix theory for different class of maps and show that these bounds are realized by fully chaotic quantum systems. Comment: 19 pages, Invited review for Pramana J of physics. arXiv admin note: substantial text overlap with arXiv: 1212. 457...|$|R
5000|$|<b>Information</b> <b>Gain</b> = Entropy(parent) - Weighted Sum of Entropy(Children) ...|$|R
2500|$|An {{information}} theoretic {{analysis using}} a simplified but useful model {{shows that in}} asexual reproduction, the <b>information</b> <b>gain</b> per generation of a species is limited to 1 bit per generation, while in sexual reproduction, the <b>information</b> <b>gain</b> is bounded by , where [...] {{is the size of}} the genome in bits.|$|R
30|$|<b>Information</b> <b>gain</b> {{is one of}} {{the most}} common feature {{selection}} methods for sentiment analysis [3, 9, 19, 35], which measures the content of information obtained after knowing the value of a feature in a document. The higher the <b>information</b> <b>gain,</b> the more power we have to discriminate between different classes.|$|R
5000|$|An {{information}} theoretic {{analysis using}} a simplified but useful model {{shows that in}} asexual reproduction, the <b>information</b> <b>gain</b> per generation of a species is limited to 1 bit per generation, while in sexual reproduction, the <b>information</b> <b>gain</b> is bounded by , where [...] {{is the size of}} the genome in bits.|$|R
30|$|The {{study used}} the <b>Information</b> <b>Gain</b> (ID 3) {{algorithm}} {{to select the}} attribute that minimized the value of entropy and hence maximizing the <b>information</b> <b>gain.</b> Entropy is an information-theoretic measure of the ‘uncertainty’ contained in a training set due {{to the presence of}} more than one possible classification (Hand et al. 2001).|$|R
40|$|Abstract — In this paper, {{the short}} coming of ID 3 's inclining to choose {{attributes}} with many values is discussed, {{and then a}} new decision tree algorithm which is improved version of ID 3. Our proposed methodology uses greedy approach to select the best attribute. To do so the <b>information</b> <b>gain</b> is used. The attribute with highest <b>information</b> <b>gain</b> is selected. If <b>information</b> <b>gain</b> is not good then again divide attributes values into groups. These steps are done until we get good classification/misclassification ratio. The proposed algorithms classify the data sets more accurately and efficiently...|$|R
50|$|Consider {{an example}} data set with four attributes: outlook (sunny, overcast, rainy), {{temperature}} (hot, mild, cool), humidity (high, normal), and windy (true, false), with a binary (yes or no) target variable, play, and 14 data points. To construct a decision tree on this data, {{we need to}} compare the <b>information</b> <b>gain</b> of each of four trees, each split {{on one of the}} four features. The split with the highest <b>information</b> <b>gain</b> will be taken as the first split and the process will continue until all children nodes are pure, or until the <b>information</b> <b>gain</b> is 0.|$|R
40|$|Abstract. The {{design of}} fusion {{diagnostics}} {{is essential for}} the physics program of future fusion devices. The goal is to maximize the <b>information</b> <b>gain</b> of a future experiment with respect to various constraints. A measure of <b>information</b> <b>gain</b> is the mutual information between the posterior and the prior distribution. The Kullback-Leibler distance is used as a utility function to calculate the expected <b>information</b> <b>gain</b> marginalizing over data and parameter space. The expected utility function is maximized with respect to the design parameters of the experiment. The method will be applied to the design of a Thomson scattering experiment...|$|R
50|$|Let a_best be the {{attribute}} {{with the}} highest normalized <b>information</b> <b>gain.</b>|$|R
50|$|To {{build the}} tree, the <b>information</b> <b>gain</b> of each {{possible}} first split {{would need to}} be calculated. The best first split is the one that provides the most <b>information</b> <b>gain.</b> This process is repeated for each impure node until the tree is complete. This example is adapted from the example appearing in Witten et al.|$|R
40|$|Abstract — Dexterous {{grasping}} {{of objects}} with uncertain pose {{is a hard}} unsolved problem in robotics. This paper solves this problem using <b>information</b> <b>gain</b> re-planning. First we show how tactile information, acquired during a failed attempt to grasp an object {{can be used to}} refine the estimate of that object’s pose. Second, we show how this information can be used to replan new reach to grasp trajectories for successive grasp attempts. Finally we show how reach-to-grasp trajectories can be modified, so that they maximise the expected tactile <b>information</b> <b>gain,</b> while simultaneously delivering the hand to the grasp configuration that is most likely to succeed. Our main novel outcome is thus to enable tactile <b>information</b> <b>gain</b> planning for Dexterous, high degree of freedom (DoFs) manipulators. We achieve this using a combination of <b>information</b> <b>gain</b> planning, hierarchical probabilistic roadmap planning, and belief updating from tactile sensors for objects with non-Gaussian pose uncertainty in 6 dimensions. The method is demonstrated in trials with simulated robots. Sequential replanning is shown to achieve a greater success rate than single grasp attempts, and trajectories that maximise <b>information</b> <b>gain</b> require fewer re-planning iterations than conventional planning methods before a grasp is achieved. I...|$|R
