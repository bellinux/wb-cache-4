0|29|Public
50|$|Articles 46-53 of the Vienna Convention on the Law of Treaties set out {{the only}} ways that {{treaties}} can be invalidated—considered unenforceable and void under international law. A treaty will be invalidated due to either the circumstances by which a state party joined the treaty, or due {{to the content of}} the treaty itself. Invalidation is separate from withdrawal, suspension, or <b>termination</b> (<b>addressed</b> above), which all involve an alteration in the consent of the parties of a previously valid treaty rather than the invalidation of that consent in the first place.|$|R
50|$|Ironically, {{a lengthy}} <b>termination</b> note <b>addressed</b> to Foster was included, unsent, in Kurt Cobain's {{published}} Journals, which while praising Foster's drumming, also bemoans {{the difference in}} cultural background between Foster and Cobain, who both were Aberdeen natives.|$|R
5000|$|Type 1 {{character}} field, specifies {{whether the}} record is data (6) or termination (8). (6 record contains data, placed at the <b>address</b> specified. 8 <b>termination</b> record: The <b>address</b> field may optionally contain {{the address of the}} instruction to which control is passed there is no data field.) ...|$|R
5000|$|In {{a special}} {{section of the}} [...] "Reinstatement Act" [...] of 15 May 1978 {{reversing}} all of the Oklahoma <b>Termination</b> Acts it <b>addresses</b> the Modoc Tribe of Oklahoma confirming that {{the provisions of the}} Klamath Termination Act did not apply to them except as provided for sharing in future claims against the United States.|$|R
40|$|Delay {{discounting}} (DD) {{procedures are}} emerging {{as an important}} new method for psychotherapy researchers. In this paper a framework for conceptualizing existing, seemingly discrepant, research findings on termination is introduced and new directions for research are described. To illustrate {{the value of a}} DD framework, the common psychotherapy problem of premature <b>termination</b> is <b>addressed.</b> First, a DD framework for how premature termination may be defined is presented. Second, common variables that have long been linked to premature termination (expectancies, and preferences) are explored using DD procedures. These investigations demonstrate that DD procedures are a methodological advancement that can advance psychotherapy research and, potentially, improve client outcomes...|$|R
40|$|Recently, {{the problem}} of proving {{outermost}} <b>termination</b> has been <b>addressed</b> mainly by methods relying on transformations ([4, 1, 3]). Here we describe a more direct approach inspired by the dependency pair (DP) framework of [2]. The basic idea is to enrich dependency pairs by an additional component, namely the calling context of the corresponding recursive function call. Then one can use the additiona...|$|R
5000|$|... 1 On December 16, 1921, Malaviya {{send the}} {{following}} telegram to Gandhi:“Am arranging deputation of about seven to Viceroy on 21st to press upon him necessity of Round Table Conference. Hence going to Calcutta, Jamnadas and Kunzru reach Sabarmati tomorrow to explain situation. Desire {{to have your}} authority {{to say that if}} conference is accepted and Government stays hands and releases leaders, you will withdraw opposition to Prince’s welcome and suspend civil disobedience till <b>termination</b> conference. Calcutta <b>address</b> till 21 No. 31 Burtillo Street.” ...|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceIn {{rule-based}} languages, {{control of}} rule application {{can be expressed}} thanks to strategy constructors. The paper <b>addresses</b> <b>termination</b> of such strategy-guided evaluation. To fix ideas, we use the ELAN strategy language. We first give a sufficient criterion for ELAN-like strategies to terminate, only lying on rewrite rules involved in the strategy. We then give a simplification process of strategies, itself described by rewriting, to empower the previous criterion. This simplification can also make proofs of other program properties easier...|$|R
40|$|This paper {{presents}} two randomized protocols for {{the problem}} of electing a "leader" among a set of nodes in an arbitrary multi-hop radio network. First, {{a variation of the}} leader election protocol by Bar-Yehuda et al. [BGI 87] is presented, in which the <b>termination</b> problem is <b>addressed.</b> Then, an efficient randomized leader election protocol in arbitrary multi-hop radio networks is presented. Our election protocol is shown both analytically and experimentally to be asymptotically more efficient than previously known leaden election protocols for (almost) all networks. Also the protocol is much simpler than previously known leader election protocols...|$|R
40|$|Abstract—A new {{generalization}} of the PML with wide-angle ab-sorption is presented, for the efficient truncation of FDTD lattices. The proposed unsplit-field layer uses a nondiagonal symmetric tensor anisotropy and via an appropriate parameter selection achieves notable attenuation {{rates in the}} case of near-grazing angles. Hence, it can be placed much closer to large structures. Improved accuracy and lower dispersion errors are attained via higher-order FDTD schemes with regular and non-Cartesian lattices constructed by hexagonal or tetradecahedral cells. Finally, Ramahi ABC’s are invoked for the absorber’s <b>termination.</b> Nu-merical results, <b>addressing</b> wave attenuation at grazing incidence, prove the efficiency of the proposed PML. Index Terms—Electromagnetic scattering, FDTD methods, nu-merical analysis, perfectly matched layers. I...|$|R
40|$|Cereal rye (Secale cereale) {{has emerged}} as a key player, as {{acceptance}} of cover cropping grows. Organic growers are invested in incorporating cereal rye and strip tillage in their reduced tillage production systems. However, termination of cereal rye continues to be a challenge. Many organic growers have embraced the chevron-patterned roller crimper as a promising method of <b>termination</b> to <b>address</b> this issue. Unfortunately, many farmers are concerned about the potential delay of planting their cash crop. This concern is due to the requirement of cereal rye to be at the anthesis (flowering) stage for successful termination. Moreover, many growers are planting VNS (variety not stated) cereal rye, which complicates the issue. Growers need specific information on cereal rye cultivars, establishment, growth, anthesis, and termination methods. The purpose of this research was to investigate the effect of planting date and performance of five cereal rye cultivars (Aroostook, Elbon, Prima, Wheeler, and Wrens Abruzzi) under Midwest growing conditions. This research is intended to serve as a decision making tool for Midwest organic growers who want to select the best cereal rye cultivar to use in their no-till production system...|$|R
40|$|In my {{dissertation}} I {{examine the}} following question: {{why do some}} leaders stay in costly wars that are unlikely to end in victory while other leaders willingly capitulate to their adversary’s demands when resistance remains an option? To explain this variation, I argue, the settlement costs associated with a leader’s personal culpability for involving {{the state in the}} conflict must be recognized. Leaders who can be linked to the decision to bring the state to war (culpable leaders) will feel more pressure to secure a favorable outcome and, consequently, will be more tolerant of the costs of war and more likely to “gamble for resurrection” if the war is going poorly. Although the extant war <b>termination</b> literature <b>addresses</b> the notion of settlement costs, pressures specific to individual leaders are often overlooked, obscuring the powerful effect a leader’s culpability has on his war termination calculus. The pressures associated with culpability have implications for both theory and policy because their presence creates a dysfunctional relationship between a democratic leader and his citizens in times of war. I use a multiple methods approach (analyzed an original dataset of all warring leaders from 1816 - 1990, a national survey experiment funded by Time-sharing Experiments for the Social Sciences (TESS)) to evaluate this theory, and find broad support for my hypotheses...|$|R
40|$|We {{present a}} new method for the {{solution}} of the box constrained variational inequality problem, BVIP for short. Basically, this method is a nonsmooth Newton method applied to a reformulation of BVIP as a system of nonsmooth equations involving the natural residual. The method is globalized by using the D-gap function. We show that the proposed algorithm is globally and fast locally convergent. Moreover, if the problem is described by an affine function, the algorithm has a finite termination property. Numerical results for some large-scale variational inequality problems are reported. Key words: Variational inequality problem, mixed complementarity problem, natural residual, D-gap function, Newton's method, global convergence, quadratic convergence, finite <b>termination.</b> 2 Current <b>address</b> (October 1, 1997 [...] - September 30, 1998) : Computer Sciences Department, University of Wisconsin [...] - Madison, 1210 West Dayton Street, 53706 Madison, WI; e-mail: kanzow@cs. wisc. edu. The research of t [...] ...|$|R
40|$|AbstractWe study {{termination}} of programs in concurrent higher-order languages. A higher-order concurrent calculus combines {{features of the}} λ-calculus and of the message-passing concurrent calculi. However, {{in contrast with the}} λ-calculus, a simply-typed discipline need not guarantee termination and, in contrast with message-passing calculi such as the π-calculus, divergence can be obtained even without a recursion (or replication) construct. We first consider a higher-order calculus where only processes can be communicated. We propose a type system for termination that borrows ideas from termination in rewriting systems (and following the approach to termination in the π-calculus in [3]). We then show how this type system can be adapted to accommodate higher-order functions in messages. Finally, we <b>address</b> <b>termination</b> in a richer calculus that includes localities and a passivation construct, as well as name-passing communication. We illustrate the expressiveness of the type systems on a few examples...|$|R
40|$|This paper {{presents}} {{a novel approach}} {{to the problem of}} implementing programs in Gamma, a computation model of chemical-reaction-like multiset transformations, by translating them into a process calculus with broadcasting communication, CBS. The concurrent message reception of broadcasting communication fits very naturally to the implicit parallelism of the Gamma model: A value that may trigger reactions with several others in the multiset is broadcast to the potential receivers and may thus react with all of them at the same time. This kind of triggering reactions, which we call quasi-unary, is very common in Gamma programs and is found in a large class of problems. The translation constitutes a correct refinement of the Gamma program and offers possibilities for further optimisations for several classes of problems. We <b>address</b> <b>termination</b> of Gamma programs and identify several classes of programs where termination can be detected and practically implemented...|$|R
40|$|This paper {{presents}} two randomized protocols for {{the problem}} of electing a "leader" among a set of nodes in an arbitrary multi-hop radio network. First, {{a variation of the}} leader election protocol by Bar-Yehuda et al. [BGI 87] is presented, in which the <b>termination</b> problem is <b>addressed.</b> Then, an efficient randomized leader election protocol in arbitrary multi-hop radio networks is presented. Our election protocol is shown both analytically and experimentally to be asymptotically more efficient than previously known leader election protocols for (almost) all networks. Also, the protocol is much simpler than previously known leader election protocols. College of Computing Georgia Institute of Technology Atlanta, Georgia 30332 [...] 0280 Author's current address: Bellcore, P. O. Box 7040, Red Bank, NJ 07701 - 5699. 1 Introduction A radio network is a collection of radios that communicate with each other over radio channels. If all units in a network can hear each other, the radio network is s [...] ...|$|R
40|$|The ptaci'tce of {{termination}} offranchise agreements raises significant {{strategic and}} legal issues. This paper aims to provide descriptive information about franchise terminations {{in relation to}} which the appropriateness of regulatory responses can be measured. Data were collected from surveys of Australian franchisers in / 998 and / 999 to explore the nature, reasons and outcomes offranchise agreement terminations. A model predicting the likelihood of terminations was developed, based on franchise system maturity, support structures provided, and level ofconflict experienced. The results indicate that mature franchises {{were more likely than}} younger systems to experience franchise terminations. No consistent link was found between the amount ofsystem support or the level ofconflict and the incidence of franchise terminations. Tlte data lends suppon to judicial responses to termination issues which accommodate the relational aspect of Panchise relationships and <b>addresses</b> <b>termination</b> issues {{in the context of the}} underlying relationship and the legitimate business expectations of the parties...|$|R
40|$|Program {{termination}} {{analysis is}} an important task in logic and computer science. While determining if a program terminates {{is known to be}} undecidable in general, there has been a significant amount of attention given to finding sufficient and computationally practical conditions to prove termination. One such method takes a program and builds from it a matrix weighted digraph. These are directed graphs whose edges are labeled by square matrices with entries in {- 1, 0, 1 }, equipped with a nonstandard matrix multiplication. Certain properties of this digraph are known to imply the termination of the related program. In particular, termination of the program can be determined from the weights of the circuits in the digraph. In this talk, the motivation for <b>addressing</b> <b>termination</b> and how matrix weighted digraphs arise will be briefly discussed. The remainder of the talk will describe an efficient method for bounding the weights of a finite set of the circuits in a matrix weighted digraph, which allows termination of the related program to be deduced...|$|R
40|$|The {{application}} of hydrogen fibre Z-pinches {{to the study}} of the radiative collapse phenomenon is studied computationally. Two areas of difficulty, the formation of a fully ionized pinch from a cryogenic fibre and the processes leading to collapse <b>termination,</b> are <b>addressed</b> in detail. A zero-D model based on the energy equation highlights the importance of particle end losses and changes in the Coulomb logarithm upon collapse initiation and termination. A 1 -D Lagrangian resistive MHD code shows the importance of the changing radial profile shapes, particularly in delaying collapse termination. A 1 -D, three fluid MHD code is developed to model the ionization of the fibre by thermal conduction from a high temperature surface corona to the cold core. Rate equations for collisional ionization, 3 -body recombination and equilibration are solved in tandem with fluid equations for the electrons, ions and neutrals. Continuum lowering is found to assist ionization at the corona-core interface. The high density plasma phenomena responsible for radiative collapse termination are identified as the self-trapping of radiation and free electron degeneracy. A radiation transport model and computational analogues for the effects of degeneracy upon the equation of state, transport coefficients and opacity are implemented in the 1 -D, single fluid model. As opacity increases the emergent spectrum is observed to become increasingly Planckian and a fall off in radiative cooling at small radii and low frequencies occurs giving rise to collapse termination. Electron degeneracy terminates radiative collapse by supplementing the radial pressure gradient until the electromagnetic pinch force is balanced. Collapse termination is found to be a hybrid process of opacity and degeneracy effects across a wide range of line densities with opacity dominant at large line densities but with electron degeneracy becoming increasingly important at lower line densities. (author) Available from British Library Document Supply Centre-DSC:DX 205768 / BLDSC - British Library Document Supply CentreSIGLEGBUnited Kingdo...|$|R
40|$|Different {{algorithms}} for transient modelling of {{capillary electrophoresis}} {{have been described}} in several papers. Programs based on such algorithms were applied to various modes of CE. Surprisingly, simulations of capillary isotachophoresis (cITP) at realistic current densities (2 ̆ 6 gt; 1 kA/m 2) were not reported. Using these programs for practical cITP conditions resulted in either severe oscillations, mass-balance violation or unexpected program <b>termination.</b> This paper <b>addresses</b> several numerical paths available for modelling one-dimensional capillary electrophoretic behaviour. Tests for determining {{the validity of the}} presented solutions with respect to cITP were mass balance checks, zone boundary thickness and the Kohlrausch regulating function. Six different numerical schemes fulfilled these requirements, yet only few could be used for simulating practical current density situations without causing the aforementioned problems. Attention was paid to space discretization (central difference and quadratic upwind) and time integration (implicit, explicit). A single computer program comprising these strategies was developed. Special features for studying transient state phenomena were visualization of concentrations, velocities, Peclet and Courant numbers, electric field strength, conductivity, pH, buffering capacity and charge excess. All parameters could be displayed in both the space domain (profile) {{as well as in the}} time domain (electropherogram) ...|$|R
40|$|The {{considerable}} {{interest in}} distributed systems that can execute algorithms to process large graphs {{has led to}} the creation of many graph processing systems. However, existing systems suffer from two major issues: (1) poor performance due to frequent global synchronization barriers and limited scalability; and (2) lack of support for graph algorithms that require serializability, the guarantee that parallel executions of an algorithm produce the same results as some serial execution of that algorithm. Many graph processing systems use the bulk synchronous parallel (BSP) model, which allows graph algorithms to be easily implemented and reasoned about. However, BSP suffers from poor performance due to stale messages and frequent global synchronization barriers. While asynchronous models have been proposed to alleviate these overheads, existing systems that implement such models have limited scalability or retain frequent global barriers and do not always support graph mutations or algorithms with multiple computation phases. We propose barrierless asynchronous parallel (BAP), a new computation model that overcomes the limitations of existing asynchronous models by reducing both message staleness and global synchronization while retaining support for graph mutations and algorithms with multiple computation phases. We present GiraphUC, which implements our BAP model in the open source distributed graph processing system Giraph, and evaluate it at scale to demonstrate that BAP provides efficient and transparent asynchronous execution of algorithms that are programmed synchronously. Secondly, very few systems provide serializability, despite the fact that many graph algorithms require it for accuracy, correctness, or <b>termination.</b> To <b>address</b> this deficiency, we provide a complete solution that can be implemented on top of existing graph processing systems to provide serializability. Our solution formalizes the notion of serializability and the conditions under which it can be provided for graph processing systems. We propose a partition-based synchronization technique that enforces these conditions efficiently to provide serializability. We implement this technique into Giraph and GiraphUC to demonstrate that it is configurable, transparent to algorithm developers, and more performant than existing techniques. 4 month...|$|R
40|$|Transmission of {{broadband}} {{over power}} lines has received considerable attention recently {{to cater to}} broadband distribution within the premises of a home or m the local area served by a substation. The power line has a very different gauge and topology compared to traditional twisted pair copper that today has evolved substantially to support broadband over DSL. The power line has a thicker gauge and shorter straight lengths, but {{a large number of}} bridge taps with inductive load <b>terminations.</b> This paper <b>addresses</b> the dual issues of modelling typical power line channels and analyzes the resultant channel for Multicarrier Transmission The basic approach to analyze the power line channel employs ABCD parameters of the individual sections. The effect of up to 10 bridge taps over a 600 meter length is studied. Signal to noise ratio profiles have been obtained using Discrete Multitone Transmission as in ADSL 2 and VDSL 2 over a bandwidth of 30 MHz. The noise profiles considered include impulse noise which is predominant over power line sections, apart from AWGN. A tone loading analysis for various types of power line channels have been presented assuming the Transmit power spectral densities (PSDs) for ADSL 2 and VDSL 2. This analysis points to the fact that lower Transmit PSDs would suffice to match the rates achievable by xDSL over traditional twisted pan copper, and this can be distinct advantage considering the need to distribute broadband within residential premises. Â© 2011 IET...|$|R
40|$|International audienceWe {{investigate}} verification {{problems for}} gap-order constraint systems (GCSGCS), an (infinitely-branching) abstract model of counter machines, in which constraints (over ZZ) between {{the variables of}} the source state and the target state of a transition are gap-order constraints (GCGC) [32]. GCSGCS extend monotonicity constraint systems [7], integral relation automata [16], and constraint automata in [19]. First, we <b>address</b> <b>termination</b> and fairness analysis of GCSGCS. Since GCSGCS are infinitely-branching, termination does not imply strong termination, i. e. {{the existence of an}} upper bound on the lengths of the runs from a given state. We show that the termination problem, the strong termination problem, and the fairness problem for GCSGCS (the latter consisting in checking the existence of infinite runs in GCSGCS satisfying acceptance conditions à la Büchi) are decidable and Pspace-complete. Moreover, for each control location of the given GCSGCS, one can build a GCGC representation of the set of counter variable valuations from which termination (resp., strong termination, resp., fairness) does not hold (resp., does not hold, resp., does hold). Next, we consider a constrained branching-time logic, GCCTL⁎GCCTL⁎, obtained by enriching CTL⁎CTL⁎ with GCGC, thus enabling expressive properties and subsuming the setting of [16]. We establish that, while model-checking GCSGCS against the universal fragment of GCCTL⁎GCCTL⁎ is undecidable, model-checking against the existential fragment, and satisfiability of both the universal and existential fragments are instead decidable and Pspace-complete (note that the two fragments are not dual since GCGC are not closed under negation). Moreover, our results imply Pspace-completeness of known verification problems that were shown to be decidable in [16] with no elementary upper bounds...|$|R
40|$|Thesis (Ph. D.) [...] University of Washington, 2012 Few legal {{proceedings}} in the U. S. have more profound consequences for families than {{the termination of}} parental rights. Previously described as family law's "death penalty," termination leads to the complete severance of the parent-child bond. Yet, despite its profound gravity, <b>termination</b> is infrequently <b>addressed</b> in social work scholarship. This dissertation aims to help fill this gap by examining North Carolina judicial opinions, written in 2010, that resolved disputed actions to terminate parental rights. A total of 100 opinions were examined using content analysis. All of the cases involved child neglect. The study focused on neglect because of ongoing difficulty in clearly defining this common form of child maltreatment. A large majority (n= 86) of the cases resulted in the termination of parental rights. The study yielded a typology of factors appellate courts used to justify their termination decisions. Altogether, 39 factors were identified and organized into 10 different domains: parental conditions, service compliance, home environment, economic conditions, child conditions, bonding, child welfare history, physical abuse, physical presence, and sexual abuse. These factors are significantly more expansive than the termination criteria listed in the federal Adoption and Safe Families Act as well as North Carolina statutes. Just as important, chi-squared analyses revealed that when courts made their termination decision, they looked to different factors depending upon which parents {{were involved in the}} cases (mothers, fathers, or both parents). Two domains were selected for closer examination using discourse analytics: "service compliance" and "economic conditions. " Here, the goal was to understand the ideology and social values underlying the rulings. The results indicate that the courts placed great weight on parents' compliance with case plans in justifying their termination decisions. The courts also emphasized parents' poverty and their surrounding economic circumstances when explaining their decisions in the opinions. Overall, the study underscores the critically important role the courts play in the child welfare system. The results indicate that the courts help create child welfare policy and that they contribute to setting the broad parameters of social work practice in the field...|$|R
40|$|Testing is a {{critical}} element of systems engineering, as it allows engineers to ensure that products meet specifications before they go into production. The testing literature, however, has been largely theoretical, and is difficult to apply to real world decisions that testers and program managers face daily. Nowhere is this problem more present than for military systems, where testing is complicated by {{of a variety of}} factors like politics and the complexities of military operations. Because of the uniqueness of military systems, the consequences of failure can be very large and thus require special testing considerations, as program managers need to make absolutely sure that the system will not fail. In short, because of the high stakes consequences associated with the development and use of military systems, testers must adjust their testing strategies to ensure that high stakes consequences are adequately mitigated. The high consequence space is broken down into two types of consequences, programmatic and operational. Programmatic consequences occur while a system is under development, and result when insufficient testing is conducted on a system, leading a program manager to have inadequate certainty that the system works to specification. When the program comes under inevitable scrutiny, a lack of testing data makes the program difficult to defend and can thus result in program <b>termination.</b> To <b>address</b> programmatic consequences, testers must utilize a broad based and adaptive test plan that ensures adequate testing across all system attributes, as a failure in any attribute might lead to program termination. To connect programmatic consequences to the realities of system development, the developments of the Division Air Defense System (DIVAD) and the M- 1 Abrams main battle tank are examined in comparative perspective, using testing as an explanation for their dramatically different programmatic outcomes. The DIVAD's testing strategy was not adequate, and the program suffered termination because of public and Congressional criticism; the M- l's strategy, by contrast, was very rigorous, allowing the system to avoid programmatic consequences despite criticism. Operational consequences result from failures of specific attributes during military operations, after the system has already been fielded. Operational consequences are distinguished by their disproportionate impacts at operational and strategic levels of operations, and require targeted testing based on analysis of critical system attributes. The procedure for this analysis is established through use of two case studies. The first case examines a sensor network designed to stop SCUD launches in austere areas; the second case, designed to analyze one system across several missions, conducts an analysis of the potential operational consequences of failures in the Predator drone's system attributes. The following seeks to better define the consequences of system failure with the understanding that the military world is in many ways unique from the civilian world. Implicit in this thesis is a plea for program managers to think carefully before cutting testing time in order to reduce program costs and shorten schedules, because less testing means a higher likelihood of disastrous programmatic consequences and less insurance against operational consequences that can dramatically effect the lives of troops in the field. by Raphael Moyer. Thesis (S. B.) [...] Massachusetts Institute of Technology, Dept. of Mechanical Engineering, 2010. Cataloged from PDF version of thesis. Includes bibliographical references (p. 79 - 82) ...|$|R
40|$|This thesis {{develops}} a semiunification-based type inference procedure for the rank 2 fragment of System F, {{with an emphasis}} on practical considerations for the adoption of such a procedure into existing programming languages. Current semiunification-based rank 2 inference procedures (notably that of Kfoury and Wells) are limited in several ways, which hinder their use in real-world settings. First of all, the translation from an instance of the type inference problem to an instance of the semiunification problem (SUP) is indirect; in particular, because of a series of source-level transformations that take place before translation, the translation is not syntax-directed. As a result, type errors discovered during the semiunification process cannot be cleanly translated back to specific subexpressions of the source program that caused the error. Also, because the rank 2 fragment of System F lacks a principal types property, an inference procedure cannot output a single type that encompasses all of a given term's derivable types. The procedure must therefore either rely on user assistance to produce the right type, or simply choose arbitrarily one of the given term's possible types. The algorithm of Kfoury and Wells in particular makes degenerate type assumptions in the absence of user assistance, and consequently produces types that are of no practical use. We build up our system in stages; we begin by improving the SUP translation. Whereas termination for the Kfoury-Wells rank 2 inference procedure is assured by translating terms into instances of the acyclic semiunification problem (a decidable subset of SUP, which is undecidable in general), we formulate and target the R-acyclic semiunification problem [...] -a larger decidable subset of SUP that facilitates a more concise translation from source terms. We next eliminate the source-level transformation of terms, in order to formulate a truly syntax-directed translation from a source term to a set of SUP-like constraints. In doing so, we find that even the full SUP itself is not sufficiently equipped to support such a translation. We formulate USUP, a superset of SUP that incorporates a new class of identifier we call an unknown. We formulate decidable subsets of USUP, and then formulate a truly syntax-directed translation from source terms into USUP, with guaranteed <b>termination.</b> Finally, to <b>address</b> the principal types problem, we introduce a notation for types in which we allow a particular class of variable to stand for type constructors, rather than ordinary types (an idea based on the so-called third-order lambda-calculus). We show that, with third-order types we can not only output large sets of useful types for a given term, without programmer assistance, but the types we output also generalize over more System F types than any type within System F itself can do, and still be a valid type for the source term. Thus, our system increases opportunities for separate compilation and code reuse beyond any existing system of which we are aware. Our system is sound, though incomplete in certain well-characterized ways, despite which our system performs exactly as one would hope on a variety of examples, which we illustrate in this thesis...|$|R
40|$|Doctor of Philosophy (PhD), EngineerigFree radical {{emulsion}} polymerization (FRP) is widely adopted in industry {{due to its}} applicability {{to a wide range}} of monomers. Despite its many benefits and wide spread use, the fast chain growth and the presence of rapid irreversible termination impose limitations with respect to the degree of control in FRP. Furthermore, producing block copolymers and polymers with complex structures via FRP is not feasible. Closer control of macromolecular chain structure and molar mass, using novel polymerization techniques, is required to synthesize and optimize many new polymer products. Reversible addition fragmentation chain transfer (RAFT) -mediated polymerization is a novel controlled living free radical technique used to impart living characters in free radical polymerization. In combination with {{emulsion polymerization}}, the process is industrially promising and attractive for the production of tailored polymeric products. It allows for the production of particles with specially-tailored properties, including size, composition, morphology, and molecular weights. The mechanism of RAFT process and the effect of participating groups were discussed with reviews on the previous work on rate retardation. A mathematical model accounting for the effect of concentrations of propagating, intermediate, dormant and dead chains was developed based on their reaction pathways. The model was combined with a chain-length dependent termination model in order to account for the decreased termination rate. The model was validated against experimental data for solution and bulk polymerizations of styrene. The role of the intermediate radical and the effect of RAFT agent on the chain length dependent <b>termination</b> rate were <b>addressed</b> theoretically. The developed kinetic model was used with validated kinetic parameters to assess the observed retardation in solution polymerization of styrene with high active RAFT agent (cumyl dithiobenzoate). The fragmentation rate coefficient was used as a model parameter, and a value equal to 6 × 104 s- 1 was found to provide a good agreement with the experimental data. The model predictions indicated that the observed retardation could be attributed to the cross termination of the intermediate radical and, to some extent, to the RAFT effect on increasing the average termination rate coefficient. The model predictions showed that to preserve the living nature of RAFT polymerization, a low initiator concentration is recommended. In line with the experimental data, model simulations revealed that the intermediate radical prefers fragmentation in the direction of the reactant. The application of RAFT process has also been extended to emulsion polymerization of styrene. A comprehensive dynamic model for batch and semi-batch emulsion polymerizations with a reversible addition-fragmentation chain transfer process was developed. To account for the integration of the RAFT process, new modifications were added to the kinetics of zero-one emulsion polymerization. The developed model was designed to predict key polymer properties such as: average particle size, conversion, particle size distribution (PSD), and molecular weight distribution (MWD) and its averages. The model was checked for emulsion polymerization processes of styrene with O-ethylxanthyl ethyl propionate as a RAFT based transfer agent. By using the model to investigate the effect of RAFT agent on the polymerization attributes, it was found that the rate of polymerization and the average size of the latex particles decreased with increasing amount of RAFT agent. It was also found that the molecular weight distribution could be controlled, as it is strongly influenced by the presence of the RAFT based transfer agent. The effects of RAFT agent, surfactant (SDS), initiator (KPS) and temperature were further investigated under semi-batch conditions. Monomer conversion, MWD and PSD were found to be strongly affected by monomer feed rate. With semi-batch mode, Mn and increased with increasing monomer flow rate. Initiator concentration had a significant effect on PSD. The results suggest that living polymerization can be approached by operating under semi-batch conditions where a linear growth of polymer molecular weight with conversion was obtained. The lack of online instrumentation was the main reason for developing our calorimetry-based soft-sensor. The rate of polymerization, which is proportional to the heat of reaction, was estimated and integrated to obtain the overall monomer conversion. The calorimetric model developed was found to be capable of estimating polymer molecular weight via simultaneous estimation of monomer and RAFT agent concentrations. The model was validated with batch and semi-batch emulsion polymerization of styrene with and without RAFT agent. The results show good agreement between measured conversion profiles by calorimetry with those measured by the gravimetric technique. Additionally, the number average molecular weight results measured by SEC (GPC) with double detections compare well with those calculated by the calorimetric model. Application of the offline dynamic optimisation to the emulsion polymerization process of styrene was investigated for the PSD, MWD and monomer conversion. The optimal profiles obtained were then validated experimentally and a good agreement was obtained. The gained knowledge has been further applied to produce polymeric particles containing block copolymers. First, methyl acrylate, butyl acrylate and styrene were polymerized separately to produce the first block. Subsequently, the produced homopolymer attached with xanthate was chain-extended with another monomer to produce block copolymer under batch conditions. Due to the formation of new particles during the second stage batch polymerization, homopolymer was formed and the block copolymer produced was not of high purity. The process was further optimized by operating under semi-batch conditions. The choice of block sequence was found to be important in reducing the influence of terminated chains on the distributions of polymer obtained. It has been found that polymerizing styrene first followed by the high active acrylate monomers resulted in purer block copolymer with low polydispersity confirmed by GPC and H-NMR analysis...|$|R
40|$|THESE are {{interesting}} times {{for all of}} us. In recent years, our ecological awareness has dramatically increased due to better understanding, education, awarenessraising and perceivable changes in both nature and climate. Even in our daily lives major transformations are hard to ignore: energy saving lamps, electric cars, windmills, solar panels –to name just a few–, along with increasing energy bills. The Internet, and Information and Communication Technology (ICT) by extension, which has managed to penetrate nearly {{every aspect of our}} modern society in mere decades, is undeniably essential in the quest for means to reduce our ecological footprint and striving towards a sustainable future because of its unique capabilities to instantly and globally unite massive amounts of data, calculation power and specialized manpower. Thus, allowing to cope with increasingly challenging scientific and technological issues and to use scarce resources sparingly, whether by optimizing existing production processes, trading physical encounters for virtual alternatives or migrating from an economy based on the manufacturing of goods to one based on trading in knowledge and services. Though ICT clearly has the potential to evolve towards a sustainable society, a darker side becomes apparent. After decades of explosive expansion, the global ICT infrastructure has grown to consume a considerable share of the worldwide available energy. Though estimations vary considerably and are mostly based on –more or less conservative– extrapolations, alternatingly including office and consumer electronics, care is urgently required to avoid ICT from completely overshadowing its enabling effect. Among others, access networks and data centers are notorious for their power consumption. The introduction chapter of this dissertation reflects on the necessity of uninterrupted efforts and research to further increase the performance of the ICT infrastructure; on issues related to the rising energy consumption and on the considerable share access networks usurps. Besides, an overview of early attempts and initiatives to turn the tide is presented. The remainder of this work consists of two main components. The first component, described in chapter 2 aims to augment the functionality and performance of the present network technology. This work was a contribution to the IWT Vampire project, which suggested an access network topology in which a considerable part of the video processing which now takes place on the subscribers’ equipment –e. g. for digital TV and video conferencing– would be shifted to and centralized on specialized high-end hardware {{on the edge of the}} access network. This so-called “thinbox” concept, requiring mere basic and static hardware at the subscribers’ premises, at first would allow for more flexibility and smoother upgrades. In the opposing –“thickbox”–approach, new services all too often require upgrades of the end-user hardware, a statistical fraction of which ends in costly failures. The thin-box approach, additionally, could allow for a whole range of new, tailored services benefiting from the location in the network and reducing the data traffic to the end-user. The main objective of IWT Vampire was to define a novel hardware architecture for the delivery of enhanced video based services, and a number of technological building blocks (both software and hardware), necessary to enable these services in large scale deployments. The compressed nature of video streams, however, is an important obstruction to perform elaborate video processing. Consequently, research in the IWT Vampire project has focused on simultaneous and real-time H. 264 encoding of multiple (10 - 1000) video streams. More specifically, Field Programmable Gate Array (FPGA) based building blocks for a high-throughput H. 264 encoding architecture were researched. Focusing on intra-prediction, residual transformation and reconstruction, a throughput of over 13 million macroblocks (blocks of 256 pixels) per second can be achieved. This easily allows to simultaneously process 32 HD video streams at 30 fps. This was achieved by realizing a massively parallel and deeply pipelined architecture in which bubbles were mostly avoided by exploiting the availability of other video streams. This architecture is elaborately discussed in chapter 2. The second component of this work deals with a novel network communication protocol that could drastically reduce the energy consumption in the access network. This protocol, coined Bit-Interleaving PON (BiPON), is motivated and explained in detail in chapter 3. Its Application Specific Integrated Circuit (ASIC) implementation, coined BiCDR, is elaborately discussed in chapter 4. This new protocol specifically aims to reduce the energy consumption in the subscribers’ equipment. Because of their numbers, this equipment is responsible for a considerable fraction of global ICT power consumption. Passive Optical Network (PON), the physical layer for the new BiPON and the well-known B/(X) G/(G) E-PON, is a promising, passive, low-power optical access network technology which has seen massive deployment over the past few years. Its tree-shaped, shared nature requires some kind of multiplexing for the Optical Line <b>Termination</b> (OLT) to <b>address</b> Optical Network Units (ONUs) individually, despite broadcasting its message. To this day, only Time Division Multiplexing (TDM) -based approaches have been standardized and deployed, namely B/(X) G/(G) E-PON, which are packet-switched to cope with the typically bursty IP-traffic in the access network. In short, the problem with the current packet-switched TDM protocols is that each subscriber performs considerable amounts of processing on the downstream broadcast data at aggregated line rate, before selecting the useful data targeted for that specific ONU. Assuming 10 Gbit=s downstream, to be shared over 128 users which could roughly be assigned 100 Mbit=s each on average, data is processed at 10 Gbit=s while keeping a mere 1 %. Clearly, this is a costly approach in terms of energy and reveals considerable room for improvement in terms of energy efficiency. Solutions relying on sleep-mode techniques have been suggested, yet Quality of Service (QoS) requirements and non-negligible sleep/wake transition times limit their efficacy. BiPON takes a radically different approach. A single frame contains data for all users, be it in a highly regular structure, while still offering high flexibility to scale and distribute bandwidth resources. The ONU can immediately subsample the incoming data, depending on the actual, dynamically adjustable, ONU-bitrate, virtually eliminating processing at the aggregated line rate. In chapter 3, a comparison between FPGAimplementations of both BiPON and XG-PON reveal an energy saving potential of a factor between 35 and 180, depending on the actual bandwidth allocated to a particular ONU. Chapter 4 presents the ASIC implementation of this protocol along with a Clock and Data Recovery (CDR) system and a decimator, which overcomes the well-known power inefficiency of the aforementioned FPGA-implementations. Chapter 5 finally presents the ongoing project DISCUS, part of the EU’s Seventh Framework Programme (FP 7), which suggests radical changes in the entire network relying on state of the art optical network technology. Part of this project aims to take the Bit-Interleaving CDR/decimator (BiCDR) to the next level, namely 40 Gbit=s. Initial work is presented along with prospects for the future...|$|R

