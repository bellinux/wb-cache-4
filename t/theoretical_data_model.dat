0|10000|Public
40|$|Partial {{information}} {{is common in}} real-world databases. Yet the <b>theoretical</b> foundations of <b>data</b> <b>models</b> are not designed to support references to missing data (often termed nulls). Instead, we usually analyse a clean <b>data</b> <b>model</b> based on assumptions about complete information, and later retrofit support for nulls...|$|R
40|$|Partial {{information}} {{is common in}} real-world databases. Yet the <b>theoretical</b> foundationsof <b>data</b> <b>models</b> are not designed to support references to missing data (often termed nulls). Instead, we usually analyse a clean <b>data</b> <b>model</b> based on assumptions about complete information, and later retrofit support for nulls. The sketch <b>data</b> <b>model</b> is a recently developed approach to database specification basedon category theory. The sketch <b>data</b> <b>model</b> is general enough to support references to missing information within itself (rather than by retrofitting). In this paper we explore three approaches to incorporating partial information in thesketch <b>data</b> <b>model.</b> The approaches, while fundamentally different, are closely related, an...|$|R
40|$|This paper {{presents}} an eye model that was constructed from a geometric simplification {{of the eye}} and anthropometric data about eye feature sizes in order to circumvent calibration per individual user. It was designed for efficiently performing uncalibrated eye gaze estimation on a user with frontal head pose. The model was implemented and tested on a database of still images obtained from 5 subjects. It was then compared against <b>theoretical</b> <b>data.</b> The <b>model</b> results in 3 ◦ of angular gaze estimation error which provides comparable performance to other methods without requiring calibration...|$|R
40|$|Geographic Information Systems (GIS) {{are widely}} used in both the {{management}} of spatial data {{as well as in}} the study and analysis of spatiotemporal processes. However, contemporary spatial <b>data</b> <b>models</b> are based on the principles of traditional two-dimensional cartography that simplify space to the horizontal Cartesian plane. This is partly due to the limitations in the way spatial phenomena are generally conceptualized and represented in GIS databases using the vector and raster geospatial <b>data</b> <b>models.</b> Over the last two decades, various methods of modeling the third dimension, incorporating the temporal component, and linking the field and object perspectives have been proposed but they have received little integration in GIS software applications. The main objective of this dissertation is to develop modeling approaches that can represent dynamic spatial phenomena in the four-dimensional (4 D) space-time domain (three-dimensional space plus time) using a <b>theoretical</b> geospatial <b>data</b> <b>model</b> and the principles of complex systems and geographical automata theory. Using the theory of complex systems and the geo-atom concepts, this dissertation proposes and implements a voxel-based automata modelling approach for the study and analysis of 4 D spatial dynamic phenomena. The data are structured using the geo-atom <b>model,</b> a <b>theoretical</b> geospatial <b>data</b> <b>model</b> that links the object and field perspectives of space and explicitly models the four dimensions of the space-time continuum. The results from implementing voxel-based automata indicate their usefulness in simulating dynamic processes, the management of geographic data, and the development of three-dimensional landscape indices and spatiotemporal queries. The significance of the study is that it provides a robust platform that demonstrates the potential of the voxel automata and geo-atom spatial <b>data</b> <b>model</b> to represent spatial dynamic phenomena in 4 D...|$|R
40|$|Experimental and <b>theoretical</b> <b>data</b> {{relevant}} to <b>models</b> and {{measurements of the}} chemical and thermal structures and luminosity of the thermospheres {{of the earth and}} planets published during the last four years are surveyed. Among chemical processes, attention is given to ion-molecule reactions, dissociative recombination of molecular ions, and reactions between neutral species. Both reactions between ground state species and species in excited states are considered, including energy transfer and quenching. Measured and calculated cross sections for interactions of solar radiation with atmospheric species, such as photoabsorption, photoionization, and photodissociation and related processes are surveyed...|$|R
40|$|A {{method for}} {{modeling}} discontinuities in a coaxial transmission line is presented. The methodology {{involves the use}} of a nonlinear least-squares fit program to optimize the fit between <b>theoretical</b> <b>data</b> (from the <b>model)</b> and experimental <b>data.</b> When this method was applied to modeling discontinuities in a slightly damaged Galileo spacecraft S-band (2. 295 -GHz) antenna cable, excellent agreement between theory and experiment was obtained over a frequency range of 1. 70 - 2. 85 GHz. The same technique can be applied for diagnostics and locating unknown discontinuities in other types of microwave transmission lines, such as rectangular, circular, and beam waveguides...|$|R
40|$|AbstractPartial {{information}} {{is common in}} real-world databases. Yet the <b>theoretical</b> foundations of <b>data</b> <b>models</b> are not designed to support references to missing data (often termed nulls). Instead, we usually analyse a clean <b>data</b> <b>model</b> based on assumptions about complete information, and later retro£t support for nulls. The sketch <b>data</b> <b>model</b> is a recently developed approach to database speci£cation based on category theory. The sketch <b>data</b> <b>model</b> is general enough to support references to missing information within itself (rather than by retro£tting). In this paper we explore three approaches to incorporating partial information in the sketch <b>data</b> <b>model.</b> The approaches, while fundamentally different, are closely related, and we show that under certain fairly strong hypotheses they are Morita equivalent (that is {{they have the same}} categories of models, up to equivalence). Despite this equivalence, the query languages arising from the three approaches are subtly different, and we explore some of these differences...|$|R
40|$|We {{study the}} {{self-assembly}} of mixtures of n-alkyl mono- and difunctionalized poly(ethylene oxide) (PEO) chains in the dilute concentration regime. The monofunctional PEOs were prepared by living anionic polymerization with varying n-alkyl length (n = 14, 16, 22, 28) and constant PEO molecular weight of 5 kg/mol. The difunctional materials were obtained through end-to-end coupling {{of two of}} the monofunctionalized PEOs via their terminal hydroxyl groups. The chosen synthetic pathway yields well-defined model compounds with narrow molecular weight distribution and complete end-group functionalization. By using both small-angle neutron scattering (SANS) and dynamic light scattering (DLS) combined with <b>theoretical</b> <b>data</b> <b>modeling,</b> we have systematically investigated both the global and inner structure of the self-assembled micellar structures. For short n-alkyl chain-ends, we find a formation of clustered micelles with a finite size whereas, intriguingly, at longer n-alkyls, we observe a crossover to flowerlike micelles. This was confirmed both by DLS, which is very sensitive to formation of larger clusters, as well as with SANS, which also showed a clear transition from attractive to repulsive intermicellar interactions upon increasing n-alkyl length. We attribute this to the balance between the hydrophobic enthalpic terms that favor anchoring of both chain-ends to the core and the entropic cost associated with the bending of the polymer chains. For short n-alkyls, exposure of the chain-ends in the corona structure leads to net dominance of the attractive interactions while for longer hydrophobic chains it leads to a stabilization of loops and consequently flowerlike micellar morphology. Using contrast-variation SANS, the contribution of mono- and difunctional chains could be separated, confirming the flowerlike micellar structure...|$|R
40|$|Objectives: To {{quantify}} {{the value of}} TDM of dual PIs (IDV and RTV 800 / 100 bid) as cost per additional person with undetectable viral load< 50 copies per mL (UVL) at 6 months from a government payer perspective. Methods: We developed a <b>theoretical</b> <b>model</b> (<b>DATA</b> 3. 5) to estimate the costs and outcomes of usual care with genotyping (UC) compared to genotyping + TDM in HIV+ and ART experienced patients beginning a new regimen. Based on previous studies, we estimated a 20...|$|R
40|$|Partial {{information}} {{is common in}} real-world databases. Yet the <b>theoretical</b> foundations of <b>data</b> <b>models</b> are not designed to support references to missing data (often termed nulls). Instead, we usually analyse a clean <b>data</b> <b>model</b> based on assumptions about complete information, and later retro£t support for nulls. The sketch <b>data</b> <b>model</b> is a recently developed approach to database speci£cation based on category theory. The sketch <b>data</b> <b>model</b> is general enough to support references to missing information within itself (rather than by retro£tting). In this paper we explore three approaches to incorporating partial information in the sketch <b>data</b> <b>model.</b> The approaches, while fundamentally different, are closely related, and we show that under certain fairly strong hypotheses they are Morita equivalent (that is {{they have the same}} categories of models, up to equivalence). Despite this equivalence, the query languages arising from the three approaches are subtly different, and we explore some of these differences. 18 page(s...|$|R
40|$|One Rayleigh step lift pad {{and three}} spiral groove {{self-acting}} face seal configurations were tested to measure film thickness and frictional torque {{as a function}} of shaft speed. The seals were tested at a constant face load of 73 N (16. 4 lb) with ambient air at room temperature and atmospheric pressure as the fluid medium. The test speed range was from 7000 to 17, 000 rpm. The measured film thickness was compared with <b>theoretical</b> <b>data</b> from mathematical <b>models.</b> The mathematical models overpredicted the measured film thickness at the lower speeds of the test speed range and underpredicted the measured film thickness at the higher speeds of the test speed range...|$|R
40|$|A {{quantitative}} determination method of N-acetyl-d-glucosamine (GlcNAc) and N,N′-diacetylchitobiose (GlcNAc) 2 is proposed using a proton {{nuclear magnetic resonance}} experiment. N-acetyl groups of GlcNAc and (GlcNAc) 2 are chosen as target signals, and the deconvolution technique is {{used to determine the}} concentration of the corresponding compound. Compared to the HPLC method, 1 H-NMR spectroscopy is simple and fast. The method can be used for the analysis of chitin hydrolyzed products with real-time analysis, and for quantifying the content of products using internal standards without calibration curves. This method can be used to quickly evaluate chitinase activity. The temperature dependence of 1 H-NMR spectra (VT-NMR) is studied to monitor the chemical shift variation of acetyl peak. The acetyl groups of products are involved in intramolecular H-bonding with the OH group on anomeric sites. The rotation of the acetyl group is closely related to the intramolecular hydrogen bonding pattern, as suggested by the <b>theoretical</b> <b>data</b> (molecular <b>modeling)</b> ...|$|R
40|$|Based on {{laboratory}} tests, {{still further}} results on local scour at bridge piers were elaborated. By using {{the approach of}} Oliveto and Hager (2002) as a framework, equations providing useful information on the analysis of literature <b>data,</b> <b>theoretical</b> <b>models</b> and field investigations were developed. Local scour at piers founded on piles was also considered. A typical evolution of the scour area is shown in Figure 1. Moreover, Oliveto and Hager’s (2002) scour equation was tested with large-scale experiments by Sheppard et al. (2004) on prototype size piers...|$|R
40|$|Abstract. Because {{digital images}} are not {{meaningful}} by themselves, images are often coupled with some descriptive or qualitative data in an image database. These data also divided into syntactic (color, shape, and texture) and semantic (meaningful real word object or concept) features, necessitate novel querying techniques. Most image systems and prototypes have focussed on similarity searches {{based upon the}} syntactic features. In the DISIMA system, we proposed an object-oriented image <b>data</b> <b>model</b> that introduces two main types: image and salient object. We further defined operations on the images and the salient objects as new joins. This approach is {{necessary in order to}} envision a declarative query language for images. This paper summarizes the querying facilities implemented for the DISIMA system and gives their <b>theoretical</b> foundation: the <b>data</b> <b>model</b> and the complementary algebraic operations, the textual query language (MOQL) and its visual counterpart (Visual-MOQL) based on an image calculus. Both languages are declarative and allow the combination of semantic and similarity queries...|$|R
40|$|Multiple in {{microwave}} {{transmission lines}} can cause unusual reflection and transmission loss characteristics as functions of frequency. This article presents {{a method for}} developing models that simulate return loss and insertion loss data measured over a broad band of frequencies. The overall cable is modeled as one consisting of shunt susceptance separated by line lengths. A nonlinear least-squares fit is then performed between <b>theoretical</b> <b>data</b> (from the <b>model)</b> and experimental <b>data.</b> When this method was applied to modeling in a slightly damaged S-band antenna cable, excellent agreement between theory and experiment was obtained over a frequency range of The probable causes of the are described. The same technique {{can be used for}} simulations and diagnostics of in other types of microwave transmission lines such as rectangular and circular waveguides. 10 INTRODUCTION The Galileo spacecraft, launched on October 18, 1989, is currently on its interplanetary journey to encounter Jupiter [...] ...|$|R
40|$|Pulsation {{constants}} and period ratios {{are given}} {{for the first six}} radial pulsation modes of a set of seven polytropes with indices ranging from n = 2. 25 to n = 4. 00. The polytrope results are combined with published <b>theoretical</b> <b>data</b> from stellar <b>model</b> pulsation calculations and observational data on thirteen double mode variables in the Cepheid instability strip to obtain four interpolation formulae relating fundamental periods Po, pulsation constants Qo, and period ratios P 1 /P 0 and P 2 /P 1. The derived relations are used to obtain accurate densities for the thirteen observed variables, which include six dwarf Cepheids or AI Vel stars, one S Sct star, one RR Lyr star, and five Cepheids. Approximate masses and luminosities are obtained for some of these stars. The probable connection between mass- luminosity ratios and the existence of double mode variables is discussed...|$|R
40|$|Mechanisms {{that may}} support magnetic-field-aligned {{electric}} fields in collisionless plasma {{are discussed in}} the light of recent magnetospheric observations, which for the first time allow a quantitative test of the <b>theoretical</b> <b>models.</b> <b>Data</b> from barium ion releases which indicate large field-aligned potential drops and direct electric field probe measurements at high altitude which reveal electric fields of several hundred millivolts per meter are discussed. It is concluded that the large field strengths observed (1) cannot be explained by anomalous resistivity or thermoelectric effects based on wave-particle interaction, (2) are much larger than required merely to balance the local mirror forces, and (3) are compatible with electric double layers of the same nature as those observed in the laboratory...|$|R
40|$|Given {{the absence}} of ground truth {{information}} on seismic structure, heat flow, and rock strength, or short wavelength gravity or magnetic data for Venus, information on the thermal, mechanical and compositional nature of the shallow interior must be obtained by indirect methods. Using pre-Magellan <b>data,</b> <b>theoretical</b> <b>models</b> constrained by the depths of impact craters and the length scales of tectonic features yielded estimates on the thickness of Venus' brittle-elastic lithosphere and the allowable range of crustal thickness and surface thermal gradient. The {{purpose of this study}} is to revisit the question of the shallow structure of Venus based on Magellan observations of the surface and recent experiments that address Venus' crustal rheology...|$|R
40|$|Many Cyber-Physical Systems (CPS), {{distributed}} embedded real-time (DRE) applications like {{military command}} and control, time critical planning collaboration, and wireless embedded sensor networks, require shared data among various {{components of the}} system to be available within stringent deadlines for processing and for making critical decisions on time. In order for these decisions to be correct {{in accordance with the}} current situation, the data received and processed must be valid. These applications need a data distribution mechanism that can deliver valid data in a specified time. The goal of this work was to develop such a mechanism. We approached it in the following way. First, since {{a better understanding of the}} problems involved in real-time data distribution leads to a better solution, we, by grouping characteristics of different systems that require real-time data distribution, defined the data distribution problem space taxonomy. Then, we targeted specific subspaces (static and dynamic systems) in the real-time data distribution problem space and worked on our solutions for them. The solutions we provided include a <b>theoretical</b> base, <b>data</b> <b>models</b> and algorithms for computation of distribution deadlines to ensure data validity in both static and dynamic environment, and the actual data delivery mechanism Timely Data Distribution Service (TDDS) ...|$|R
40|$|The recent {{description}} of potentially generic early warning signals is a promising development {{that may help}} conservationists to anticipate a population's collapse prior to its occurrence. So far, the majority of such warning signals documented have been in highly controlled laboratory systems or <b>theoretical</b> <b>models.</b> <b>Data</b> from wild populations, however, are typically restricted both temporally and spatially due to limited monitoring resources and intrinsic ecological heterogeneity – limitations that may affect the detectability of generic early warning signals, as they add additional stochasticity to population abundance estimates. Consequently, spatial and temporal subsampling may serve either to muffle or magnify early warning signals. Using a combination of theoretical models and analysis of experimental data, we evaluate {{the extent to which}} statistical warning signs are robust to data corruption...|$|R
40|$|Abstract — This paper {{considers}} {{an approach}} for analyzing fibrillar collagen structures based on digital signal processing. It {{focuses on the}} quantitative comparison between collagen structural data (electron-optical data) and chemical <b>data.</b> <b>Theoretical</b> <b>models</b> {{in the form of}} sequence-generated histograms are used as reference for extracting and analyzing the structural unit in images from collagen fibrils. In this respect, collagen provides a valuable model system for studying the chemical basis of ultrastructure and the mechanisms of various treatments on a protein, as well as detecting the alterations in its structure produced by a disorder. The algorithms developed in this study can be applied to any fibrous proteins. Some application examples are presented. I. INTRODUCTION AND PROBLEM DEFINITION ne of the most important components of connectiv...|$|R
40|$|The work {{deals with}} the {{relationship}} of the relational model and XML schema document and its technological and pragmatic aspects. It defines the <b>theoretical</b> field of <b>data</b> <b>modeling</b> at conceptual level and the two mentioned possible implementation models at the physical level. The aim is to answer the question when in the design and development of application or system it is appropriate to proceed with one of these models. Furthermore, this work also provides a general procedure for mapping conceptual schema into XML schema structures and solutions to problems that can come across during the mapping process. The problem is solved by analyzing two real issues - timetables of public transportation and the information system of a swimming school, formalized through a mechanism of predicate logic. Unlike most works on a similar topic this one varies in a pragmatic view on the problem - the concept of data, their origin, their target user and structuring...|$|R
30|$|Inversion {{attempts}} to reconstruct subsurface features from a given set of geophysical measurements, {{and to do}} so in a manner that the model response fits the observations according to some measure of error. The necessary conditions for inversion of any geophysical data sets are a fast forward algorithm required for calculating <b>theoretical</b> <b>data</b> from input <b>model</b> parameters, and technique for calculating derivatives of the data with respect to the model parameters known as the Jacobian or derivative matrix. Among the numerous methods available in the computation of Jacobian matrix is the use of the finite differences to approximate the partial derivatives. This includes the computation of the model responses for each value of model parameters. The drawback of this approach is the long time required for computation. Narayan et al. (1994) proposed the use of perturbation analysis and reciprocity method which results in algebraic equation {{in the construction of the}} Jacobian matrix. The detailed explanations of this work are found in Narayan et al. 1994 and Olayinka and Yaramanci 2000).|$|R
40|$|Abstract: This study {{investigated}} the acceptance and purchasing of Takaful life insurance policies among South African Muslims using the Theory of Reasoned Action (TRA) as the <b>theoretical</b> <b>model.</b> <b>Data</b> were obtained by administering a survey to 235 Muslims in the Gauteng Province of South Africa. Statistical {{analysis of the data}} was carried out using the Statistical Package for Social Sciences Research and SmartPls. The results suggest that attitude towards Takaful life insurance purchases and subjective norms are salient determinants of participants’ behavioural intention towards Takaful insurance policies. Furthermore, actual behaviour towards this Islamic financial product is significantly predicted by behavioural intention. The findings of the study contribute to enhancing our understanding of Takaful life insurance policies acceptance and purchase among South African Muslims – an area that is sparsely investigated – and validate the TRA in a South African Muslim sample...|$|R
40|$|Though various {{attempts}} have been made in literature to model the particle size distribution of an active pharmaceutical ingredient (API) in function of the required release profile of the pharmaceutical product, so far one has not succeeded to develop a universal approach in the correlation of particle size distribution and in vitro dissolution data. In this publication, a new approach is presented on the use of particle size distribution data in the prediction of the in vitro dissolution profile of a suspension formulation. For this purpose, various theoretical experiments were done simply on paper and based on the Noyes-Whitney [A. A. Noyes, W. R. Whitney, J. Am. Chem. Soc. 19 (1897) 930 - 934] equation, the normalized dissolution profiles of various imaginary size distributions were calculated. For each size distribution, its weighted mean diameters were then calculated. Based on these <b>theoretical</b> <b>data,</b> a <b>model</b> could be developed which scientifically explains the dissolution profile of a suspension in function of its volume-weighted mean particle size (D[4, 3]). The applicability of this correlation model could experimentally be confirmed by evaluation of laser diffraction and in vitro dissolution data as they were obtained for different batches of a suspension formulation. This new approach in the correlation between particle size and dissolution may be an important analytical tool in the engineering of the particle size distribution of drug substance, and more precisely monitoring the D[4, 3] volume-weighted mean diameter may allow one to model the dissolution profile of a suspension formulation and thereby its in vivo release profile...|$|R
40|$|The DLS {{collaboration}} {{has recently}} completed a high statistics study of dilepton production at the Bevalac. In particular, we have measured dielectrons (e+e-) from p-p and p-d collisions to understand the basic dilepton production mechanisms in the energy range from 1. 05 - 4. 9 GeV. These data {{can be used to}} determine the basic processes which contribute to nucleon-nucleon dilepton production such as hadronic bremsstrahlung, vector meson processes, and hadronic Dalitz decay. The data show that a simple elastic bremsstrahlung calculation is insufficient to explain the <b>data.</b> <b>Theoretical</b> <b>models</b> are compared with the data. A new high statistics study of Ca-Ca at 1. 05 A GeV has been made to study the collectivity of A-A collisions. Comment: 6 pages, Preprints available from HSMatis@lbl. gov. Will be published in Nuclear Physics A - The Proceedings on the 1994 Nucleus Nucleus Collisions Conference, Taorimin...|$|R
40|$|The {{measurement}} of charged particle spectra is performed for centre-of-mass energy \sqrt(s) = 13 TeV in experiment ATLAS. It is an inclusive measurement aiming at fast comparison of particle activity between <b>data</b> and <b>theoretical</b> <b>model.</b> <b>Data</b> are acquired with minimal model dependence avoiding unnecessary bias. Various efficiencies and fractions are determined {{in order to}} correct reconstructed spectra of tracks in the Inner Detector to distributions of primary particles. Correction of certain distributions involves more sophisticated methods, such as Bayesian unfolding. The corrected distributions are compared to Monte Carlo generators - Pythia 8 (A 2 and Monash tunes), Herwig++, EPOS and QGSJET. Though no generator describes measured data perfectly, {{in many cases the}} differences are within few percent. The measured average number of charged particles per unit of pseudorapidity is 2. 876 ± 0. 001922 (stat.) ± 0. 03526 (syst.) and is found to be in a good agreement with EPOS generator. Apart from the analysis, an introduction to simulation of proton-proton collision is given in this thesis. Furthermore, the detector ATLAS is described, as well as methods of track reconstruction...|$|R
40|$|The study {{explores the}} dinamics {{influencing}} Alternative Food Networks (AFNs) {{in the region}} of Madrid. To reach this goal, 13 farmers enrolled in the Control Body for organic agriculture have been interviewed. In-depth interviews have been designed using the concept of embeddedness, in its three aspects: ecological, spatial, and social. Three behavioural dimensions have been considered: i) understanding of the relationship between farming practices and benefits; ii) realising practices in the production process, and iii) utilising information to relate with consumers. Codification method has been used to build a <b>theoretical</b> <b>model.</b> <b>Data</b> have been collected through snowball sampling, along with saturation method. Four visions working together have been identified: economy, ecology, innovation/tradition, and society, determining the behavioural styles. Also, opinions about organic certification have been considered. The study could be useful for policy makers, considering the importance of AFNs in the new CAP 2014 - 2020...|$|R
40|$|The {{advantages}} of a central `data warehouse' that holds relevant project data are obvious. Due to their flexibility and given functionalities professional Relational Data Base Management System (RDBMS) (like ORACLE) seem to be better suited for this purpose than Object Oriented Data Base Systems (OODBS) that are optimized for speed and structural sophistication. In modern accelerator control diverse but multiply connected data areas have to be maintained: Classical DB applications provide the static data necessary to activate real time DBs for hardware control and data acquisition. Recently generic high level software tools have come into use that need complex configuration <b>data.</b> <b>Theoretical</b> <b>models</b> and their connections to operational procedures can be put into a reference framework due to the centralized storage of design data, calibration factors, geometries etc. On the technical side active nodes are increasingly distributed on large (multi-layered) networks. Different computer sys [...] ...|$|R
40|$|ABSTRACT: This study {{exhibits}} {{the experimental}} results of axial compression tests on concrete cylinders, circumferentially confined by the set-up of the composite grids arranged inside the cylinder, {{according to several}} combinations of circumscribed grids. The main aim is to verify the applicability of this method and then to quantify the contribution to strength improvement due to confinement {{as well as its}} influence on the rupture mode under axial compression. The test results of loading carried out on cylindrical concrete specimens, confined by alveolus composite grids arranged inside the section, show {{that it is possible to}} substantially increase the ductility of the columns, and in certain cases, their strength. It is also noted that the rupture of confined concrete is highly influenced by the presence of the grids depending on the configuration and the shape of the cells (rhombus or hexagonal) constituting the composite grid. The experimental results are compared with the <b>theoretical</b> <b>model</b> <b>data...</b>|$|R
40|$|Employee {{engagement}} {{is linked}} to higher productivity, lower attrition, and improved organizational reputations resulting in increased focus and resourcing by managers to foster an engaged workforce. While drivers of employee engagement {{have been identified as}} perceived support, job characteristics, and value congruence, internal communication is theoretically suggested to be a key influence in both the process and maintenance of employee engagement efforts. However, understanding the mechanisms by which internal communication influences employee engagement has emerged as a key question in the literature. The purpose of this research is to investigate whether social factors, namely perceived support and identification, play a mediating role in the relationship between internal communication and engagement. To test the <b>theoretical</b> <b>model,</b> <b>data</b> are collected from 200 non-executive employees using an online self-administered survey. The study applies linear and mediated regression to the model and finds that organizations and supervisors should focus internal communication efforts toward building greater perceptions of support and stronger identification among employees in order to foster optimal levels of engagement...|$|R
40|$|This {{work had}} three stages. In {{the first stage}} was {{examined}} pull-out process for steel fiber was embedded into a concrete by one end and was pulled out of concrete under the angle to pulling out force direction. Angle was varied. On the obtained forcedisplacement diagrams were observed jumps. For such mechanical behavior explanation, fiber channel in concrete surface microscopical experimental investigation, using microscope KEYENCE VHX 2000, was performed. At the second stage were obtained diagrams for load- crack opening displacement for breaking homogeneously reinforced and layered fiberconcrete prisms (with dimensions 10 x 10 x 40 cm) subjected to 4 -point bending. After testing was analyzed main crack. At the third stage elaborated prediction model for the fiberconcrete beam, failure under bending, using the following data: a) diagrams for fibers pulling out at different angles; b) experimental data about steel-straight fibers locations in the main crack. Experimental and <b>theoretical</b> (<b>modeling)</b> <b>data</b> were compared...|$|R
40|$|This paper {{reports a}} current GIS {{research}} project {{which is being}} undertaken in the Tweed area of north coast New South Wales. The project focuses on drainage management problems which are of increasing concern for land and environmental management for the sugar industry in this area. GIS network capabilities are employed with enhancements of specific needs for the drainage simulation. Natural and artificial drainage networks have been mapped, based on an accurate field survey, {{with the assistance of}} digitised aerial photographs. Specialised data processing routines have been developed to allow computation of important network parameters such as impedance, capacity, flow velocity and flow direction using field <b>data</b> and <b>theoretical</b> hydrologic <b>models.</b> <b>Data</b> links can be established to link the drainage network, which is managed in a GIS, with the hydrologic models, allowing dynamic simulation of drainage corresponding to individual rainfall events...|$|R
40|$|The {{thermal history}} and {{current state of}} the lunar {{interior}} are investigated using constraints imposed by recent geological and physical <b>data.</b> <b>Theoretical</b> temperature <b>models</b> are computed taking into account different initial conditions, heat sources, differentiation and simulated convection. To account for the early formation of the lunar highlands, the time duration of magmatism and present-day temperatures estimated from lunar electrical conductivity profiles, it is necessary to restrict initial temperatures and abundances of radioactive elements. Successful models require that the outer half of the moon initially heated to melting temperatures, probably due to rapid accretion. Differentiation of radioactive heat sources toward the lunar surface occurred during the first 1. 6 billion years. Temperatures in the outer 500 km are currently low, while the deep interior (radius less than 700 to 1000 km) is warmer than 1000 C, and is of primordial material...|$|R
40|$|In {{the present}} work, a {{nonlinear}} forced vibration model for fiber reinforced composites was developed with varying fiber orientations and laminate sequences. A nonlinear viscoelastic beam model was developed using nonlinear von Kármán strains and Kelvin–Voigt stress–strain relationship to model viscoelasticity. The effect of fiber orientation and laminate sequence {{was included in}} the model using classic laminated plate theory. Method of multiple time scales was used to solve the resulting nonlinear equation and an inverse problem approach was used to extract the model parameters from experimental <b>data.</b> <b>Theoretical</b> <b>model</b> parameters were calculated and compared to experimentally determined values for different fiber orientations and laminate sequences, and a nominally good qualitative agreement was observed. Finally, the experimentally extracted model parameters were substituted in the analytical model, and the model predictions in terms of frequency shifts were compared against experimental observations. Nominally good agreement was observed for 45 ° and 90 ° fiber orientations, however the experimental observations didn 2 ̆ 7 t match well for 0 °...|$|R
40|$|This {{study is}} {{concerned}} with the continuation of a feasibility and design study of laser-based diagnostic techniques for the non-instrusive measurement of species concentrations, temperatures, and velocity in the low density, high enthalpy flow through the arc-heated wind tunnel facility (ARMSEF) at NASA/JSC. Last summer several laser-induced radiation scattering methods were investigated and some preliminary measurements of the spectral distribution of radiation emitted by the arc-heated gas flow were made. Based upon those preliminary measurements and subsequent investigations, four laser-induced radiation scattering methods were selected for further detailed study, and preliminary design of a measurement system has been undertaken. Further measurements of the spectral distribution of radiation emitted from the arc-heated free stream and shock layer flows, using a redesigned measurement system, have been made for one axial position in the flow for a range of tunnel operating power levels. Further study of the literature for physical property <b>data,</b> <b>theoretical</b> <b>models</b> of processes, and applications of the diagnostic methods has been also carried out...|$|R
