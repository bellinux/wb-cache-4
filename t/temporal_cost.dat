37|116|Public
40|$|International audienceIn 1997, Accot and Zhai {{presented}} seminal work {{analyzing the}} <b>temporal</b> <b>cost</b> and instantaneous speed profiles associated with movement along constrained paths. Their work posited and validated the steering law, which described {{the relationship between}} path constraint, path length and the <b>temporal</b> <b>cost</b> of path traversal using a computer input device (e. g. a mouse). In this paper, we argue that the steering law fails to correctly model constrained paths of varying, arbitrary curvature, propose {{a new form of}} the law that accommodates these curved paths, and empirically validate our model...|$|E
40|$|International audienceRegular cost {{functions}} {{have been}} introduced recently as an extension {{to the notion of}} regular languages with counting capabilities. The specificity of cost functions is that exact values are not considered, but only estimated. In this paper, we study the strict subclass of regular <b>temporal</b> <b>cost</b> functions. In such cost functions, it is only allowed to count the number of occurrences of consecutive events. For this reason, this model intends to measure the length of intervals, i. e., a discrete notion of time. We provide various equivalent representations for functions in this class, using automata, and 'clock based' reduction to regular languages. We show that the conversions are much simpler to obtain, and much more efficient than in the general case of regular cost functions. Our second aim in this paper is to use <b>temporal</b> <b>cost</b> function as a test-case for exploring the algebraic nature of regular cost functions. Following the seminal ideas of Schützenberger, this results in a decidable algebraic characterization of regular <b>temporal</b> <b>cost</b> functions inside the class of regular cost functions...|$|E
40|$|Community {{structure}} {{is one of}} the most important properties in social networks. In dynamic networks, there are two conflicting criteria that need to be considered. One is the snapshot quality, which evaluates the quality of the community partitions at the current time step. The other is the <b>temporal</b> <b>cost,</b> which evaluates the difference between communities at different time steps. In this paper, we propose a decomposition-based multiobjective community detection algorithm to simultaneously optimize these two objectives to reveal community structure and its evolution in dynamic networks. It employs the framework of multiobjective evolutionary algorithm based on decomposition to simultaneously optimize the modularity and normalized mutual information, which quantitatively measure the quality of the community partitions and <b>temporal</b> <b>cost,</b> respectively. A local search strategy dealing with the problem-specific knowledge is incorporated to improve the effectiveness of the new algorithm. Experiments on computer-generated and real-world networks demonstrate that the proposed algorithm can not only find community structure and capture community evolution more accurately, but also be steadier than the two compared algorithms...|$|E
40|$|THE SOCIAL AND TEMPORAL COSTS OF MOBILITY IN INDUSTRIAL DISTRICTS. THE CASE OF THE BARCELONA METROPOLITAN REGION. Since the 1960 s, {{there has}} been an {{increasing}} tendency towards relocating industrial activities to areas located in the urban peripheries that are destined for that specific purpose. The private car has become the main means of connecting these production spaces {{with the rest of the}} urban fabric. This connectivity option entails high mobility costs, which can be analytically divided into operative, environmental, social and <b>temporal</b> <b>costs.</b> This article focuses on both the social and the <b>temporal</b> <b>costs</b> of the journeys to and from industrial estates located in two peripheral municipalities of the Barcelona Metropolitan Region. The main findings of the research highlight the important role played by territorial organisation and transport planning in reducing these costs, as well as their consequent usefulness when adequately embedded into social policies...|$|R
40|$|Emilia. In this context, {{the main}} aim of our {{research}} is to study solutions for the flexible querying of distributed data collected by heterogeneous devices providing measurement readings. To this end, we propose a middleware for wireless sensor networks which is able to autonomously configure the communication and the operations required to each device {{in order to reduce}} energy and <b>temporal</b> <b>costs...</b>|$|R
50|$|Attentional blink (AB) is a {{phenomenon}} that reflects the <b>temporal</b> <b>costs</b> in the allocating selective attention. The AB is typically measured by using rapid serial visual presentation (RSVP) tasks, where participants often fail to detect a second salient target occurring in succession if it is presented between 180-450 ms after the first one. Also, the AB has been observed using two backward-masked targets and auditory stimuli. The term attentional blink was first used in 1992, although the phenomenon was probably known before.|$|R
40|$|Inhibition {{of return}} (IOR) {{refers to the}} {{relative}} suppression of processing at locations that have recently been attended. It is frequently explored using a spatial cueing paradigm and is characterized by slower responses to cued than to uncued locations. The current study investigates the impact of IOR on overt visual orienting involving saccadic eye movements. Using a spatial cueing paradigm, our experiments have demonstrated that at a cue-target onset asynchrony (CTOA) of 400 ms saccades to the vicinity of cued locations are not only delayed (<b>temporal</b> <b>cost)</b> but also biased away (spatial effect). Both of these effects are basically no longer present at a CTOA of 1200 ms. At a shorter 200 ms CTOA, the spatial effect becomes stronger while the <b>temporal</b> <b>cost</b> {{is replaced by a}} temporal benefit. These findings suggest that IOR has a spatial effect that is dissociable from its temporal effect. Simulations using a neural field model of the superior colliculus (SC) revealed that a theory relying on short-term depression (STD) of the input pathway can explain most, but not all, temporal and spatial effects of IOR. © 2012 Wang, Theeuwes...|$|E
40|$|Abstract. In {{this work}} we {{consider}} temporal networks, i. e. networks {{defined by a}} labeling λ assigning to each edge of an underlying graph G a set of discrete time-labels. The labels of an edge, which are natural numbers, indicate the discrete time moments at which the edge is avail-able. We focus on path problems of temporal networks. In particular, we consider time-respecting paths, i. e. paths whose edges are assigned by λ a strictly increasing sequence of labels. We begin by giving two efficient algorithms for computing shortest time-respecting paths on a temporal network. We then prove {{that there is a}} natural analogue of Menger’s the-orem holding for arbitrary temporal networks. Finally, we propose two cost minimization parameters for temporal network design. One is the temporality of G, in which the goal is to minimize the maximum number of labels of an edge, and the other is the <b>temporal</b> <b>cost</b> of G, in which the goal is to minimize the total number of labels used. Optimization of these parameters is performed subject to some connectivity constraint. We prove several lower and upper bounds for the temporality and the <b>temporal</b> <b>cost</b> of some very basic graph families such as rings, directed acyclic graphs, and trees. ...|$|E
40|$|This paper studies multi-period public {{procurement}} when {{the acquisition of}} a single good over several periods is fixed once for all. The optimal mechanism is derived over two periods with <b>temporal</b> <b>cost</b> correlation. The most efficient firm delivers the good and gets informational rent at each period. But it must pay a fee in the first {{in order to keep}} the market in the second. Moreover, we present two implementation mechanisms which generalize the price equivalence theorem established for first and second price sealed-bid auctions. {{public procurement}}, asymmetric information, multi, period...|$|E
30|$|As the {{backbone}} of urban mobility in Bogotá, TransMilenio is potentially a crucial medium to reach significant urban opportunities, {{at least for the}} inhabitants who are able {{to make use of the}} BRT system. TransMilenio seems to limitedly improve accessibility to urban opportunities in Bogotá, though. The service provided by TransMilenio has a commercial speed of 26  km/h, much higher in comparison with the previous 10  km/h speed of the ordinary services (Montezuma 2000). The increase in the speed reduces the travel times and, consequently, the <b>temporal</b> <b>costs</b> of access to valued urban opportunities. However, the city suffers from a consolidated imbalance in the distribution of inhabitants and opportunities: while the most densely populated (and poorest) areas of the city are located in the southern part of Bogotá, most of the job opportunities are located in the northern sector of the city, privileging in particular an area along the Carrera Septima—slightly above the historic city center (Gutiérrez 2011; Olarte Bacares 2011). Therefore, the areas with the poorer share of the populations are also those that face higher monetary and <b>temporal</b> <b>costs</b> for their everyday mobility. The unequal distribution of activities and the partial coverage of the TransMilenio network strongly limit the improvements provided by the public transport system.|$|R
40|$|Abstract- Software project {{change is}} a common problem in project management. Changes in requirements, {{activities}} or peoples roles however are usually not free from conflicts, which in some cases if not dealt adequately could bring the whole project to a standstill. Herein, we present a method that examines the impact of change to project duration. The method proposed utilizes two main criteria namely, the degree of dependency among activities and requirements, and the <b>temporal</b> <b>costs</b> associated with the change. The proposed methodology is realised in Event Calculus and elaborated with an example...|$|R
40|$|In {{this paper}} we present the {{research}} activity we are carrying {{out in the}} "Mobile Semantic Self-Organizing Wireless Sensor Networks" Project at the Department of Information Engineering of the University of Modena and Reggio Emilia. In this context, the main aim of our research is to study solutions for the flexible querying of distributed data collected by heterogeneous devices providing measurement readings. To this end, we propose a middleware for wireless sensor networks which is able to autonomously configure the communication and the operations required to each device {{in order to reduce}} energy and <b>temporal</b> <b>costs...</b>|$|R
40|$|We {{describe}} {{here two}} efficient parsing algorithms for natural language texts {{based on an}} extension of recursive transition networks (RTN) called recursive transition networks with string output (RTNSO). RTNSO-based grammars may be semiautomatically built from samples of a manually built syntactic lexicon. Efficient parsing algorithms are needed to minimize the <b>temporal</b> <b>cost</b> associated {{to the size of}} the resulting networks. We focus our algorithms on the RTNSO formalism due to its simplicity which facilitates the manual construction and maintenance of RTNSO-based linguistic data as well as their exploitation. 1...|$|E
40|$|In this paper, {{we study}} a {{sequential}} decision making problem. The {{objective is to}} maximize the average reward accumulated over time subject to <b>temporal</b> <b>cost</b> constraints. The novelty of our setup is that the rewards and constraints are controlled by an adverse opponent. To solve our problem in a practical way, we propose an expert algorithm that guarantees both a vanishing regret and a sublinear number of violated constraints. The quality of this solution is demonstrated on a real-world power management problem. Our results {{support the hypothesis that}} online learning with convex cost constraints can be performed successfully in practice...|$|E
40|$|Abstract. The Continuous Distance Transformation (CDT) used in {{conjunction}} with a k-NN classifier has been shown to provide good re-sults in the task of handwriting recognition [1]. Unfortunately, efficient techniques such as kd-tree search methods cannot be directly used in the case of certain dissimilarity measures like the CDT-based distance functions. In order to avoid exhaustive search, a simple methodology which combines kd-trees for fast search and Continuous Distance Trans-formation for fine classification, is presented. The experimental results obtained show that the recognition rates achieved have no significant dif-ferences with those found using an exhaustive CDT-based classification, with a very important <b>temporal</b> <b>cost</b> reduction. ...|$|E
40|$|The {{general theory}} of {{cellular}} automata is investigated with special attention to structural complexity. In particular, simulation of cellular automata by cellular automata is used to make explicit trade-off relationships between neighborhood size and state-set cardinality. A minimum neighborhood template with d + 1 elements is established for the class of d-dimensional cellular automata. The minimum state set for this class is shown to be the binary state set. The <b>temporal</b> <b>costs,</b> if any, of structural complexity trade-offs are also studied. It is demonstrated that any linear time cost can be eliminated and, in fact, a speed-up by arbitrary positive integer factor k can be attained at an increased structural cost...|$|R
40|$|An {{analytical}} model {{is presented as}} a possible methodology to analyse Human-Robot (H-R) cooperative systems that can collaborate as peers or co-workers in a shared work-, time-space for a common time-critical task [1] [2]. The jointefficiency of the H-R system as a whole in a timecritical task is developed as an optimization problem. For this, an objective function is derived that accommodates all the operational and <b>temporal</b> <b>costs</b> of the system for a successful and fluent handover [3]. The performance of the system is then measured in terms of the fluency of the system or the successes of the coordination [4]. This is evaluated by solving the objective function for a solution that minimizes (or maximizes, if that is the goal) the overall cost of the system...|$|R
50|$|To be {{eligible}} for entering the importance calculation, an account must have at least 10,000 vested XEM. All accounts owning more than 10,000 vested XEM have a non-zero importance score. With a supply of 8,999,999,999 XEM, the theoretical maximum number of accounts with non-zero importance is 899,999. In practice, the number of actual accounts with non-zero importance {{is not expected to}} approach the theoretical max due to inequalities in held XEM and also the <b>temporal</b> <b>costs</b> associated with vesting. If NEM becomes very popular, a threshold of 10,000 vested XEM could be undesirable. If necessary, this number could be updated in the future via a hard fork, which is the same procedure for adjusting transaction fees and other parameters related to harvesting.|$|R
40|$|Stereo {{matching}} algorithms {{are nearly}} always designed to find matches between {{a single pair of}} images. A method is presented that was {{specifically designed to}} operate on sequences of images. This method considers the cost of matching image points in both the spatial and temporal domain. To maintain real-time operation, a <b>temporal</b> <b>cost</b> aggregation method is used to evaluate the likelihood of matches that is invariant with respect to the number of prior images being considered. This method has been implemented on massively parallel GPU hardware, and the implementation ranks as one of the fastest and most accurate real-time stereo matching methods as measured by the Middlebury stereo performance benchmark...|$|E
40|$|Principles of {{resource}} ecology predict {{that as the}} travel cost (e. g. time and energy) to the site {{of resource}} gain increases, the relative value of the resource diminishes (Andersson, 1978). Although primarily applied in behavioural investigations concerned with optimal foraging (see Pyke, 1984; Stephens and Krebs, 1986; Kamil et al., 1987), resource maximisation models also pertain to the acquisition of oxygen from water versus air in bimodally respiring vertebrates (Kramer, 1988; Boutilier, 1990). The ‘theory of optimal breathing ’ (Kramer, 1988) predicts that, as the cost of travel for pulmonary gas exchange increases, the proportion of total VO • accounted for by atmospheric O 2 uptake decreases relative to aquatic VO•. Habitat selection by aquatic vertebrates affects metabolic and <b>temporal</b> <b>cost</b> associated with travel to and from the surface for pulmonary respiration (Kramer and McClure, 1981...|$|E
40|$|Community {{detection}} in dynamic networks is {{an important}} research topic and has received {{an enormous amount of}} attention in recent years. Modularity is selected as a measure to quantify the quality of the community partition in previous detection methods. But, the modularity has been exposed to resolution limits. In this paper, we propose a novel multiobjective evolutionary algorithm for dynamic networks community detection based on the framework of nondominated sorting genetic algorithm. Modularity density which can address the limitations of modularity function is adopted to measure the snapshot cost, and normalized mutual information is selected to measure <b>temporal</b> <b>cost,</b> respectively. The characteristics knowledge of the problem is used in designing the genetic operators. Furthermore, a local search operator was designed, which can improve the effectiveness and efficiency of community detection. Experimental studies based on synthetic datasets show that the proposed algorithm can obtain better performance than the compared algorithms...|$|E
30|$|To {{improve the}} quality of GPS/A data, the {{improvement}} of instruments and/or data processing methods are considered. As mentioned above, the possible source of the multiple reflections, based on the time lag between the direct and multipath signals, is the surface of the pressure-resistant glass sphere storing the acoustic control unit of the transponder (Fig.  3). Such a multipath effect must be identified and improved in actual field experiments. However, even if improving the acoustic unit of the instrument reduced the multipath effect, it requires considerably high monetary and <b>temporal</b> <b>costs</b> to replace or repair them at all sites because each site comprises 3 – 6 transponders. Thus, we developed a new solution to avoid the misreading of large-amplitude multipath signals, and we provisionally applied it to a waveform analysis.|$|R
40|$|Soft Sensors (SSs) are on-line estimators of “hardly to be measured” {{quantities}} of a process. The difficulty in measuring {{can be related}} to economic or <b>temporal</b> <b>costs</b> that cannot be afforded in a high-intensive manufacturing production. In semiconductor manufacturing this technology goes with the name of Virtual Metrology (VM) systems. While a lot of efforts in research have been produced in the past years to identify the best regression algorithms for these statistical modules, small amount of work has been done to develop algorithms for data clustering of the entire production. This paper contains a new Information Theory-based approach to data clustering for Virtual Metrology and Soft Sensors; the proposed algorithm allows to automatically split the dataset into groups to be equally modeled. The proposed approach has been tested on real industrial datase...|$|R
40|$|The {{objective}} of this project was to create similar exposure groups (SEGs) for occupational monitoring in a structural steel fabrication facility. Qualitative SEG formation involved worksite observation, interviews, and audits of materials and procedures. These were supplemented with preliminary task-based shop survey data collected using a condensation particle counter. A total of six SEGs were formed, with recommendations for occupational exposure sampling for five groups, as well as ambient sampling recommendations to address areas on the operational floor found to have higher particle concentrations. The combination of direct reading device data and qualitative SEG formation techniques is a valuable approach, as it contains both the monetary and <b>temporal</b> <b>costs</b> of worksite exposure monitoring. This approach also provides an empowering in-house analysis of potentially problematic areas, and results in the streamlining of occupational exposure assessment...|$|R
40|$|SummaryWhile it is {{commonly}} assumed that decisions taken slowly result in superior outcomes, {{is it possible that}} optimal decision making does not always require sacrificing speed? For odor categorization decisions, it was previously shown that rats use < 300  ms regardless of difficulty, but these findings could be interpreted as a tradeoff of accuracy for speed. Here, by systematically manipulating the task contingencies, we demonstrate that this is the maximum time over which sampling time can improve accuracy. Furthermore, we show that decision accuracy increases at no <b>temporal</b> <b>cost</b> when rats can better anticipate either the identity of stimuli or the required timing of responses. These experiments suggest that uncertainty in odor category decisions arises from noise sources that fluctuate slowly from trial-to-trial rather than rapidly within trials and that category decisions in other species and modalities might likewise be optimally served by rapid choices...|$|E
40|$|Obtaining a {{survival}} strategy (policy) {{is one of}} the fundamental problems of biological agents. In this paper, we generalize the formulation of previous research related to the survival of an agent and we formulate the survival problem as a maximization of the multi-step survival probability in future time steps. We introduce a method for converting the maximization of multi-step survival probability into a classical reinforcement learning problem. Using this conversion, the reward function (negative <b>temporal</b> <b>cost</b> function) is expressed as the log of the temporal survival probability. And we show that the objective function of the reinforcement learning in this sense is proportional to the variational lower bound of the original problem. Finally, We empirically demonstrate that the agent learns survival behavior by using the reward function introduced in this paper. Comment: Joint 8 th International Conference on Soft Computing and Intelligent Systems and 17 th International Symposium on Advanced Intelligent System...|$|E
40|$|We study a {{model of}} traffic where drivers adopt {{different}} behavioral strategies. These can be cooperative or defective according to a driver abiding or not by a traffic rule. Drivers can change their strategy by imitating the majority, with a rule {{that depends on the}} strategies with which they have interacted. These interactions occur at intersections, where vehicles pay a <b>temporal</b> <b>cost</b> according to their strategy. We analyze the conditions under which different strategy compositions represent an advantage in the system velocity. We found that the cooperators' mean speed is higher than the defectors' even when the vehicle density is large. However, defectors can obtain benefits in their mean speed when they are a minority in an essentially cooperative population. The presence of a core of educated drivers, who persist firmly in a cooperative behavior, optimizes the speed in the system, especially for intermediate values of vehicular density and higher temporal costs...|$|E
50|$|In short, GIS {{works as}} a tool for {{mediating}} and diffusing socio-environmental conflicts. It does so by working within Ranciere’s notion of the partition of the sensible. Whilst it may allow previously unheard voices to gain a voice (in environmental justice campaigns, foremostly), it still does not - as a tool of neoliberal governance - make room for those who are deemed ‘outside’, unruly or conflictual to have a voice. For example, Elwood laments the notionally ‘participatory’ flag-waving carried out by those involved in urban GIS-based projects. As she says; ‘the skills and financial and <b>temporal</b> <b>costs</b> of using GIS effectively bar many individuals, social groups and organizations from participation in research and decision-making where it is used’, denying those without the means to participate, from participation. GIS does not necessaily facilitate involvement for all.|$|R
40|$|This paper {{proposes a}} {{theoretical}} framework for verifying and deriving code optimizations for programs written in parallel programming languages. The key idea of this framework is to formalize code optimizations as compositional transformation rules for programs presented as terms of an enriched process calculus. The rules are formulated {{on the basis of}} an algebraic order relation between two programs which states that they are behaviorally equivalent {{and one of them is}} faster than the other. The correctness and e#ectiveness of optimized programs derived from the rules can be ensured in all circumstances. The framework is unique among other existing works in being able to quantitatively analyze the <b>temporal</b> <b>costs</b> of synchronizations among parallel programs. This paper presents basic ideas and definitions of the framework with several examples. 1. Introduction Parallel computation will play an increasingly important role in many areas of computer systems. As it becomes popular, custome [...] ...|$|R
40|$|Abstract—The {{multiplication}} of {{the number}} of GSM base stations raises the issue of the harmfulness of the electromagnetic waves radio frequencies. In such a context, evaluation methods of the quantity of energy absorbed (SAR-Specific Absorption Rate) by human tissues during an exposition exist: dosimetry for cellular phone and in-situ measurement for base station. However, the in-situ methods require devices for measuring electric fields (spectrum analyzer, personal dosimeter and probe, etc…) that are characterized by high financial and <b>temporal</b> <b>costs.</b> In this paper, we propose an analytical calculation method of electric fields emitted by the GSM base station (BS). It relies on a propagation model of electromagnetic wave. The simulation of our model with MATLAB tools shows a lot of similarities with real measures obtained with in-situ measurements. The advantage of our model is that it doesn’t require equipments but only a prior study of the base station vicinity. Index Terms—Base stations, Electromagnetic fields...|$|R
40|$|The {{design of}} {{efficient}} distributed applications {{depends on the}} coordinate use of different API (Application Programming Interface) like MPI and NT API's. In fact, a particular optimized code can be reused in many other applications reducing the cost of its design {{by means of a}} set of libraries. Distributed processing is applied in remote sensing in order to reduce spatial or <b>temporal</b> <b>cost</b> using the message passing paradigm. In this paper, we presentaworkbench called DIPORSI, developed to provide a framework for the distributed processing of Landsat images using a cluster of NT workstations. Our application is based on a NT implementation (WMPI) of the MPI standard. Thus, the large amount of time required by the sequential processes drops when the parallel processing is used. Moreover, wehave obtained a reduction of computation time over the 400 % for large size images and a moderate number of parallel nodes. Our results confirm that cluster computing is a cost/performance effective solution to the remotely sensed image processing...|$|E
40|$|While it is {{commonly}} assumed that decisions taken slowly result in superior outcomes, {{is it possible that}} optimal decision making does not always require sacrificing speed? For odor categorization decisions, it was previously shown that rats use < 300  ms regardless of difficulty, but these findings could be interpreted as a tradeoff of accuracy for speed. Here, by systematically manipulating the task contingencies, we demonstrate that this is the maximum time over which sampling time can improve accuracy. Furthermore, we show that decision accuracy increases at no <b>temporal</b> <b>cost</b> when rats can better anticipate either the identity of stimuli or the required timing of responses. These experiments suggest that uncertainty in odor category decisions arises from noise sources that fluctuate slowly from trial-to-trial rather than rapidly within trials and that category decisions in other species and modalities might likewise be optimally served by rapid choices. © 2013 Elsevier Inc. All rights reserved...|$|E
40|$|Abstract. During {{the late}} 19 th Century, {{stakeholders}} {{from the building}} construction industry were in need of rational, quantified, and repeatable assessment of building materials and structures subject to heating during fire; thus the standard fire resistance test was born {{within the context of}} the knowledge available at that time. This paper briefly illustrates the early conception and evolution of the standard fire resistance test and presents a new fire testing methodology, named the Heat-Transfer Rate Inducing System (H-TRIS), developed to address shortcomings of the ‘standard ’ procedure using an innovative thermal loading technique in which the thermal exposure is actively controlled not using gas phase temperature, but by incident heat flux measurements at the test element’s exposed surface using a high precision loop feedback system. H-TRIS is based on the use of a mobile array of propane-fired high performance radiant heating elements, along with a computer-controlled mechanical linear motion system, allowing the development of rational fire resistance studies with high repeatability, realistic boundary conditions, and good statistical confidence, all at low economical and <b>temporal</b> <b>cost...</b>|$|E
40|$|After people incur {{costs to}} get future benefits, they usually track these costs in their mental {{accounts}} and are keen {{to receive the}} benefits when they become available. We introduce the notion that costs and benefits can occur either in the same accounting period (day, season, etc.) or in different periods. Our key argument is that monetary costs are tracked across accounting periods but that <b>temporal</b> <b>costs</b> are written off {{at the end of}} the period in which they are incurred. Thus, accounting periods lead to a time-money asymmetry in the tracking of costs and, consequently, in the likelihood of seeking benefits. In a laboratory study, an online-panel study, and a field study with movie-theater patrons, we demonstrate how this relationship among accounting periods, cost tracking, and benefit seeking is different for time than for money. Our findings offer insights into the sunk-cost effect, time-money differences, and mental accounting. (c) 2010 by JOURNAL OF CONSUMER RESEARCH, Inc [...] ...|$|R
40|$|Landscape {{restoration}} has {{the potential}} to mitigate habitat loss and fragmentation. However, restoration can take decades to reach the ecological conditions of the target habitats. The National Trust’s Stonehenge Landscape Restoration Project provides an opportunity to evaluate the ecological benefits against the economic and <b>temporal</b> <b>costs.</b> A field survey between June and September 2010 using Lepidoptera as bio-indicators showed that restored grasslands can approach the ecological conditions of the target chalk grassland habitat within 10 years. However, specialist species like Lysandra bellargus (Adonis blue) were absent from restored grasslands and may require additional management to assist their colonisation. Analysis of the Lepidoptera communities showed that both small-scale habitat heterogeneity and age of the habitat were important for explaining Lepidoptera occurrence. These results demonstrate that habitat restoration at the landscape scale combined with appropriate site-scale management can be a relatively rapid and effective method to restore ecological networks and buffer against future climate change...|$|R
30|$|In synthesis, TransMilenio {{contributes}} to the personal ability to move in Bogotá, but its contribution is limited to certain areas and groups of inhabitants. Around half of the urban population has direct walking access to the stations of the system, while other groups of inhabitants need to reach the BRT stations with feeder services; the presence of transfers, {{as well as the}} increased economic and <b>temporal</b> <b>costs</b> of the trips, reduce the possibility to make effectively use of TransMilenio. The lack of significant forms of integration with other modal options, such as cars or bicycles, furtherly limits the possibility to access the BRT network. Other features instead reduce the intention or the possibility that wide groups have for using TransMilenio. For example, the decreasing quality of the service has pushed the better-off groups of inhabitants towards other modal choices, such as private vehicles. Instead, low-wage groups experience difficulties in accessing the TransMilenio service also due to its fares, so that the system ends up with a majority of middle-class users (Lotero et al. 2014; Heres et al. 2009; Kash and Hidalgo 2014).|$|R
