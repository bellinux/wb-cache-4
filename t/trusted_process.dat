12|565|Public
50|$|Nucleus is {{configured}} {{by a set}} {{of system}} tables, and processes which have a need to modify the operation of nucleus are given access to the relevant system tables. This would be the case for processes which directly change the state of other processes, processes which allocate and delete memory segments, processes which can change the routing of messages between other processes or change the mapping of I/O devices to processes, etc. Normally system table access is limited to relatively few trusted processes, and other processes which need to perform operations such as loading processes, allocating memory, etc. will pass a message to the relevant <b>trusted</b> <b>process</b> which it will vet before performing the action and replying.|$|E
40|$|Abstract. Aiming {{the lack}} of the {{authentication}} and access control when the business processes of the power business systems visit the enterprise data center, this article proposes a <b>trusted</b> <b>process</b> security model for the access to the power enterprise data center. The model gives the concept of “Trusted Process ” firstly, and then builds “Trusted Process List ” and the “Process Access List ” to convert the business process into <b>trusted</b> <b>process,</b> and finally implements the authentication and access control of the business processes when visiting the data center...|$|E
40|$|Microsoft’s Windows Vista {{operating}} system implements an interesting model of multi-level integrity. In this model, any information-flow attack requires {{the participation of}} a <b>trusted</b> <b>process,</b> and can therefore be eliminated by static analysis. We formalize this model by presenting a type system that can efficiently enforce data-flow integrity on Vista. Typechecking guarantees that objects whose contents are statically trusted never contain untrusted values, regardless of what untrusted code runs in the environment. Some of Vista’s runtime access checks are necessary for soundness; others are redundant and can be optimized away. 1...|$|E
25|$|The term trusted {{computing}} base {{goes back}} to Rushby, who defined it as the combination of kernel and <b>trusted</b> <b>processes.</b> The latter refers to processes which are allowed to violate the system's access-control rules.|$|R
40|$|This {{doctoral}} thesis studies the interorganisational <b>trust</b> <b>process</b> in the Belgian criminal justice system. It {{is the result}} of a five-year (2012 - 2017) study in the context of the IAP project Justice and Populations (IAP VII/ 22) financed by Belspo. The research takes a public administration perspective and studies the <b>trust</b> <b>process</b> between the local police, the federal police, the public prosecutor’s office and the examining magistrates; these are the central actors. The purpose of the study was twofold. The first goal was descriptive. The meaning of the <b>trust</b> <b>process</b> was examined from the perspective of the central actors. The second goal was explanatory. Here, the (sub) antecedents that might influence on the <b>trust</b> <b>process</b> were examined. The study thus tries to fill the gaps in the literature on ‘trust within justice’. On the basis of these goals, 4 research questions were formulated: RQ 1. What is the formal-legal context of the relationships between the local police, the federal police, the public prosecutor’s office and the examining magistrates, henceforth called the actors? RQ 2. How do the actors reflect on the specific aspects of the <b>trust</b> and distrust <b>process?</b> RQ 3. How do the actors interpret the three central elements of the <b>trust</b> <b>process</b> in their relationship with the respective other actors? RQ 4. What are the (sub) antecedents of the <b>trust</b> <b>process</b> (for the three elements separately as well as for the process as a whole) in the relationship between the actors? The <b>trust</b> <b>process</b> as defined as follows in this study: the willingness of the trustor to be vulnerable (passive trust), based on the positive expectations regarding the intentions and the behavior of the trustee (the perceived trustworthiness), which can lead to actual actions (active trust). The terms between brackets are the central elements of the <b>trust</b> <b>process.</b> A central proposition of this study is inspired by Dietz and Den Hartog (Dietz, 2011, p. 215) and states that the <b>trust</b> <b>process</b> starts with the perceived trustworthiness, and runs through passive trust, to active trust. This means that there is only active trust when the trustee is perceived to be trustworthy and when there is passive trust. Hence, when the trustee is perceived as trustworthy, this does not automatically imply that there will be passive trust and active <b>trust.</b> The <b>trust</b> <b>process</b> can be influenced by different antecedents, that were further subdivided into different subantecedents in this study. In order to answer the research questions, an exploratory qualitative study was done, consisting of 6 parts: Part 1 : development of the initial conceptual framework Part 2 : selection of central actors Part 3 : outline of the formal-legal context Part 4 : first refinement of the initial conceptual framework by means of an analysis of legal sources Part 5 : second refinement of the initial conceptual framework by means of an analysis of scientific literature, other relevant documents and 6 expert interviews Part 6 : third refinement of the initial conceptual framework by studying the embedded cases, based on 32 semi-structured interviews No comparison was made between the different parts of the study and thus between the different data collection methods. On the other hand, the different parts did not follow sequentially, so it is possible that they somehow influenced one another. In part 1, the initial conceptual framework was developed by studying the scientific literature. In part 2, the central actors of this study were determined by means of an analysis of the criminal procedural law. In part 3, we described the formal legal context. This part gave more insight in the relationships between the central actors and served as a background for the empirical research. Part 4 consisted of the analysis of legal sources. This resulted in a list of tentative propositions regarding the influence of the (sub) antecedents on ‘trust’. This list was the basis for part 5. On the one hand, further information on these propositions was sought in the scientific literature and other relevant documents. On the other hand, the propositions from part 4 were presented to 6 experts. In part 5 we examined whether the (sub) antecedents had specific properties that could explain their influence on the <b>trust</b> <b>process</b> and whether there were interactions between the different (sub) antecedents in their impact on the <b>trust</b> <b>process.</b> This resulted in a new list of propositions. Part 6 of the study concerned the study of the embedded cases. Here, 32 semi-structured interviews were conducted with the central actors of two departments of one judicial district. Specifically, interviews were conducted with the local police (the police chiefs and members of the local police), the federal police (the “dirjuds”, i. e. judicial directors, and the members of the federal police), the public prosecutors, and the examining magistrates. These interviews had two aims. First, they were used to explore respondents’ views on four specific issues regarding the trust process: the definition, negative trust and positive distrust, the connection between interpersonal trust/distrust process and the interorganisational trust/distrust process, and the model of Lewicki, McAllister and Bies (1998). Second, the interviews were used to investigate the impact of the (sub) antecedents on the <b>trust</b> <b>process.</b> This part also resulted in a new list of propositions. It is expected that research results will be published in the beginning of 2018 status: accepte...|$|R
40|$|In this chapter, {{we study}} interorganisational trust of {{regulated}} organisations in regulating organisations in the Flemish public administration. The {{objective is to}} better understand interorganisational trust and the (perceived) characteristics of interorganisational interactions that contribute to its development. We propose that the interorganisational <b>trust</b> <b>process</b> is affected by boundary spanners’ perceptions of certain macro and meso-level interaction characteristics. Findings from our nested mixed-method analysis, in which we compared trusted and distrusted interorganisational interactions in Flemish public administration, show that macro- and meso-level interaction characteristics affect the <b>trust</b> <b>process</b> through various direct and indirect mechanisms, that both extent and form of these interaction characteristics are important to understand how they affect interorganisational trust, and that macro- and meso-level interaction characteristics shape each other in neo-institutional structuration processes. On {{the basis of these}} findings, we suggest that any due understanding of interorganisational trust must acknowledge that no single group of institutional, rational, or social exchange theories can provide a full understanding of interorganisational trust. A model which allows interdependent macro- and meso-level interaction characteristics to affect the <b>trust</b> <b>process</b> may be required to achieve a comprehensive understanding of interorganisational trust. status: accepte...|$|R
40|$|Vendors {{who develop}} Trusted Computing Base (TCB) {{equipped}} secure operating systems face difficult choices as they design and implement the requisite protection features {{appropriate to the}} evaluation class being targeted (e. g., Labeled Security Protection, Class B 1). On the one hand, vendors seek to meet each and every evaluation class requirement unconditionally, being careful to limit every possible opportunity for latent vulnerabilities to occur. However, on the other hand, vendors must not implement their secure product with so many constraints that it loses its competitive advantage and utility as an operating system having general applicability throughout the marketplace. Balancing these conflicting goals often results in the vendor's implementing a more restrictive rule set than permitted by theoretical considerations. Unfortunately, unlike the published criteria for TCB classes themselves 1, developers who implement trusted processes have had to depend on ad hoc experimentally derived guidelines and rules to meet both mission and security requirements simultaneously. This paper presents a new methodology, derived from the theory of a TCB-equipped operating system and practical experience, to explicitly determine to which of several classes a specific <b>trusted</b> <b>process</b> * belongs, as well citing applicable programming confinement rules to ensure additional risks, if any, will be acceptable. * A <b>trusted</b> <b>process</b> is a program, module, or algorithm which has extraordinary privilege(s), which if not otherwise strictly controlled and limited, could subvert the security policy in unpredictable ways [...] in the extreme, subvert the protection domain provided by the TCB for itself...|$|E
40|$|If trusted processes' secrets or privileged system {{objects such}} as file handles are leaked to an untrusted process, {{the result could be}} the loss of secrecy and {{integrity}} of the data produced by the program. The advent of privilegeseparated programs has led to an additional risk: sensitive data or system objects may be leaked when the <b>trusted</b> <b>process</b> of the privilege-separated application forks an untrusted child process. We have identified several channels by which information may flow to the child process: memory, the environment, memory mappings, filesystem information, and file descriptors. We propose fixes for each of these leaks. Some are handled by a novel static source code analysis of the target privilege-separated application's source code, but some require modifications to the kernel or compiler...|$|E
40|$|Industrial Control Systems (ICS) are an {{integral}} part of the industrial infrastructure providing for the national good. While sharing basic constructs with Information Technology (IT) business systems, ICSs are technically, administratively, and functionally more complex and unique than business IT systems. Critical infrastructure protection focuses on protecting and maintaining a safe and reliable supply of electric power, oil, water, gasoline, chemicals, food, etc. Cyber vul-nerabilities are important if they can affect the safe, functional performance of these systems and processes. The majority of ICS exhibit vulnerable devices with unsecured physical access and/or subject to insider attack. In this whitepaper, we advocate <b>trusted</b> <b>process</b> control networks as a way to address the serious cyber security flaws which combines both white/black listing into a design philosophy that addresses information warfare scenarios, software process monitoring and an attack recognition and management architecture...|$|E
40|$|Abstract. We present two generic formal {{security}} {{models for}} operating systems of multiapplicative smart cards. The models formalize the main security aspects of secrecy, integrity, secure communication between applications and secure downloading of new applications. The first model is maximally abstract, whereas the second extends the first by adding practically relevant {{issues such as}} a structured file system. The models satisfy a common security policy consisting of authentication and intransitive noninterference. The policy extends the classical security policy of Bell/LaPadula and Biba models, but avoids the need for <b>trusted</b> <b>processes</b> that are allowed to circumvent the security policy. Instead <b>trusted</b> <b>processes</b> are incorporated directly in the model itself and {{are subject to the}} security policy. The security policy has been formally proven to be correct for both models. ...|$|R
30|$|Identification of {{the trust}} {{attributes}} for a node’s <b>trust</b> building <b>process.</b>|$|R
5000|$|WP 2: Business, <b>Trust</b> and <b>Processes</b> (without {{participation}} of German subproject) ...|$|R
40|$|Role based {{access control}} (RBAC) is {{attracting}} increasing attention {{as a security}} mechanism for both commercial and many military systems. This paper shows how RBAC can be implemented using the mechanisms available on traditional multi-level security systems that implement information flow policies. The construction from MLS to RBAC systems is significant because {{it shows that the}} enormous investment in MLS systems can be leveraged to produce RBAC systems. The method requires no changes to the existing MLS system kernel and allows implementation of hierarchical RBAC entirely through site configuration options. A single <b>trusted</b> <b>process</b> is used to map privileges of RBAC roles to MLS labels. Access is then mediated by the MLS kernel. Where C is the number of categories and d the depth of the role hierarchy, the number of roles that can be controlled is approximately ` C=d C= 2 d ' d. 1 Introduction Role based access control (RBAC) is an alternative to traditional discretionary (DAC) a [...] ...|$|E
40|$|Abstract — If trusted {{processes}} ’ secrets or privileged system {{objects such}} as file handles are leaked to an untrusted process, {{the result could be}} the loss of secrecy and integrity of the data produced by the program. The advent of privilegeseparated programs has led to an additional risk: sensitive data or system objects may be leaked when the <b>trusted</b> <b>process</b> of the privilege-separated application forks an untrusted child process. We have identified several channels by which information may flow to the child process: memory, the environment, memory mappings, filesystem information, and file descriptors. We propose fixes for each of these leaks. Some are handled by a novel static source code analysis of the target privilege-separated application’s source code, but some require modifications to the kernel or compiler. As a proof of concept, we applied our technique to privilege-separated OpenSSH running on the Linux 2. 6 kernel. Using our tools, we were able to verify easily that it does not leak secrets from its trusted components to its untrusted components; all sensitive data is erased or downgraded appropriately before being inherited by untrusted components. This suggests that our method is a useful way of reasoning about privilege-separated programs...|$|E
40|$|Approved {{for public}} release, {{distribution}} is unlimitedThe use of specialized single-level networks in current military operations is inadequate {{to meet the}} need to share information envisioned by the Global Information Grid (GIG). Multilevel security (MLS) is a key Information Assurance enabler for the GIG vision. The Monterey Security Architecture (MYSEA), a distributed MLS network, eliminates the need to use separate equipment to connect to many networks at different classification levels. It allows users to view data at different sensitivities simultaneously. MYSEA also allows commercial software and hardware to be used at clients. To address the threat of residual data on the client after a user session change in security state, the MYSEA clients are required to be "stateless", i. e., there is no non-volatile writable memory. Hence the MYSEA server must provide the clients {{with the ability to}} execute server-resident client-side applications to access data at different security levels over the MLS Local Area Network (LAN). The MYSEA server currently does not support such capability. This thesis addresses this limitation. A new <b>trusted</b> <b>process</b> family is introduced to provide a pseudo-socket interface for the single level remote application to access the MLS LAN interface. Detailed design specifications were created to facilitate implementation of the remote application support. Lieutenant, United States Nav...|$|E
50|$|Metadata ensures {{a secure}} {{transaction}} between an identity provider and a service provider. Before metadata, trust information was encoded into the implementation in a proprietary manner. Now {{the sharing of}} trust information is facilitated by standard metadata. SAML 2.0 provides a well-defined, interoperable metadata format that entities can leverage to bootstrap the <b>trust</b> <b>process.</b>|$|R
5000|$|When {{a process}} is [...] "trusted", {{it has been}} deemed safe and {{excluded}} from risk scanning. There are two trust levels; [...] "standard" [...] and [...] "high". The third option is to disable Norton Insight. In standard <b>trust,</b> <b>processes</b> appearing {{in the majority of}} participants' computers are deemed safe. High trust, in addition, excludes digitally signed files from scanning.|$|R
5000|$|The term trusted {{computing}} base {{goes back}} to Rushby, who defined it as the combination of kernel and <b>trusted</b> <b>processes.</b> The latter refers to processes which are allowed to violate the system's access-control rules.In the classic paper Authentication in Distributed Systems: Theory and Practice Lampson et al. define the TCB of a computer system as simply ...|$|R
40|$|Department of Defense {{official}} communications often require special protections to prevent accidental disclosure to unauthorized personnel. A Multilevel High Assurance LAN {{provides a framework}} for secure electronic communications, and obviates the need for multiple single level networks. A high assurance trusted computing base (TCB), allows untrusted commercial off-the-shelf (COTS) software, such as an Internet Message Access Protocol (IMAP) server, to run untrusted while access to the file system is mediated by the TCB. Control of creation and deletion of hierarchical structured objects, {{such as those in}} the file system, is based on the ability to write to the directory containing the object. For a mail server, this directory structure corresponds to a mailbox hierarchy. The mailbox hierarchy must be designed to allow users to read, create, and send mail at multiple levels. The purpose of this research is to develop a <b>trusted</b> <b>process</b> that automatically creates the mailbox hierarchy for any system user. A Mail File Administration Tool for a Multilevel High Assurance LAN allows administrators to easily set up IMAP-compatible mailboxes for each user. The tool assists in the management of the file structure and enables account administration for multiple LAN users and group accounts at multiple security levels. Lieutenant, United States Nav...|$|E
40|$|Abstract—Monitoring {{a process}} and its file I/O {{behaviors}} {{is important for}} security inspection for a data center server against intrusions, malware infection and information leakage. In {{the case of the}} Linux kernel 2. 6, a set of hook functions called the Linux Security Module (LSM) has been implemented in order to monitor and control the system calls. By using the LSM we can inspect the activity of unknown malicious processes. However, a sophisticated attacker could breach the kernel configurations using the rootkits. Furthermore since the monitoring results of the malicious process activity are stored as a file on Hard Disk Drive (HDD), it will be easily manipulated by the attacker. In this paper, we propose a secure monitoring scheme that addresses the attacks against the monitoring module and its result for security inspection of the data center server. The monitoring module is implemented as a LSM-based function and protected by the kernel protection technique. The integrity of the monitoring result is guaranteed by using a Mandatory Access Control (MAC) of the Linux kernel and a mechanism of the <b>trusted</b> <b>process</b> invocation. This mechanism can serve as an infrastrucuture of secure inspection platform for data center server because the integrity of the monitoring module and its result is guaranteed. Keywords-Secure system monitoring; Linux Security Mod-ule; Lifetime kernel code integrity; Mandatory Access Control...|$|E
40|$|The {{future of}} digital systems is {{complexity}}, and complexity {{is the worst}} enemy of security. [...] Bruce Schneier [40]. The large size and high complexity of securitysensitive applications and systems software is a primary cause for their poor testability and high vulnerability. One approach to alleviate this problem is to extract the securitysensitive parts of application and systems software, thereby reducing the size and complexity of software {{that needs to be}} trusted. At the system software level, we use the Nizza architecture which relies on a kernelized trusted computing base (TCB) and on the reuse of legacy code using trusted wrappers to minimize the size of the TCB. At the application level, we extract the security-sensitive portions of an already existing application into an AppCore. The AppCore is executed as a <b>trusted</b> <b>process</b> in the Nizza architecture {{while the rest of the}} application executes on a virtualized, untrusted legacy operating system. In three case studies of real-world applications (e-commerce transaction client, VPN gateway and digital signatures in an email client), we achieved a considerable reduction in code size and complexity. In contrast to the few hundred thousand lines of current application software code running on millions of lines of systems software code, we have AppCores with tens of thousands of lines of code running on a hundred thousand lines of systems software code. We also show the performance penalty of AppCores to be modest (a few percent) compared to current software...|$|E
40|$|Trust {{plays an}} {{important}} role between companies and customers in the online shopping environment because of the anonymous transaction environment and the advantage of virtual property. The most rapidly developing trend in Chinese e-business may come from Guanxi, a Chinese term for social trust. In this study, we define Guanxi as the dynamic <b>trust</b> <b>process</b> in the social decisions or activities of the Chinese. With increasing global attention on the outstanding development of Chinese e-business, it would be worthwhile to analyze the dynamic <b>trust</b> <b>process</b> of social e-commerce customers in close combination with the social network. The statistical results obtained using structural equation modeling (SEM) show the importance of trust in a social e-commerce context. The direct positive relationship between the components of the web marketing mix and purchase intention is partially mediated by initial trust and ongoing trust, while initial trust only partially affects purchase intention through ongoing trust...|$|R
30|$|No {{detailed}} modelling {{has been}} proposed in terms of trust evolution. The only model that describes trust in the lending process {{has been proposed}} by Howorth and Moro (2006). However, while their model focuses on describing the <b>trust</b> <b>process,</b> it does not explore the dynamics of trust evolution. Therefore, in this paper, we aim to correct this gap in the research.|$|R
5000|$|The Cloverdale Rancheria of Pomo Indians of California is {{a federally}} {{recognized}} tribe of Pomo Indians in California. The tribe is currently considered [...] "landless", {{as they do}} not have any land that is in Federal Trust. In 2008 they acquired approximately 80 acres of property on the southern end of Cloverdale, California. The property is currently going through the Fee to <b>Trust</b> <b>process</b> to become the tribe's landbase.|$|R
40|$|Aim:The aim of {{our study}} is to analyzeelements of online <b>trust</b> {{building}} <b>process</b> from sellers’ standpoint based on case study of Chinese website: Taobao. Method:This {{study was conducted in}} qualitative method with 12 interviewees as online sellers from Taobao website. Data presentation involves tables and figures to help readers to understand <b>trust</b> building <b>process</b> and apply it in business. Result & Conclusions: Online trust building is dynamic and interactive. Three main elements of trust building are product, communication and 3 rd party. <b>Trust</b> building <b>process</b> goes through three stages: knowledge-based trust, experience-based trust, and relationship-based trust. Suggestions for future research: Limitation of generality suggests further study in quantitative method. Since it is a single case study specific in China, comparison cross-culture or between websites is also suggested as future possibilitiesto test generalizability of this theoretic framework. Contribution & implication: This study provided atheoretic framework for online <b>trust</b> building <b>process</b> in real-world context. Management implication was suggested to focus on development of product, communication and 3 rdparty service for sellers and website holde...|$|R
5000|$|A <b>trusted</b> payment <b>process</b> {{will use}} leading edge {{technology}} to provide {{efficient and effective}} customer service {{to the people of}} the Kingdom ...|$|R
40|$|We {{provide a}} largely {{automated}} system for verifying Clark-Wilson interprocess information-flow integrity. Informationflow integrity properties {{are essential to}} isolate <b>trusted</b> <b>processes</b> from untrusted ones by removing unwanted input dependences. For example, an untrusted user process should {{not be able to}} write to sshd config via a cron script. A useful notion of integrity is the Clark-Wilson integrity model [7], which allows <b>trusted</b> <b>processes</b> to accept necessary untrusted inputs (e. g., network data or print jobs) via filtering interfaces that sanitize the data. However, Clark-Wilson has the requirement that programs undergo formal semantic verification; in practice, this kind of burden has meant that no information-flow integrity property is verified on most widely-used systems. We define a weaker version of Clark-Wilson integrity, called CW-Lite, which has the same interprocess information-flow guarantees, but which requires less filtering, only small changes to existing applications, and which we can check using automated tools. We modify the SELinux user library and kernel module in order to support CW-Lite integrity verification and develop new software tools to aid developers in finding and enabling filtering interfaces. Using our toolset, we found and fixed several integrity-violating configuration errors in the default SELinux policies for OpenSSH and vsftpd...|$|R
40|$|Resilience to {{specified}} {{kinds of}} disasters {{is an active}} area of research and practice. However, rare or unprecedented disturbances that are unusually intense or extensive require a more broad-spectrum type of resilience. General resilience is the capacity of social-ecological systems to adapt or transform in response to unfamiliar, unexpected and extreme shocks. Conditions that enable general resilience include diversity, modularity, openness, reserves, feedbacks, nestedness, monitoring, leadership, and <b>trust.</b> <b>Processes</b> for building general resilience are an emerging and crucially important area of research...|$|R
40|$|When {{we discuss}} {{institutional}} phenomena, elements and rogic must be selected {{in view of}} institutional context. In this process, it needed definition of function. According to "communication media" framework, function should {{be described as a}} position on spectrum. However, It {{is important to note that}} some types of system, To take examples education system or welfare system need another dimention of descrive. What is more, this also causes new evaluative criteria. In this paper, we suggested information processing framework. We found key concept "social trust", and discussed application to institution analysis by operationalizing this concept. As a result, we proposed several requirements of functioning <b>trust</b> information <b>process.</b> This cofigulation leads to two discussions, (i) operatinalised evaluative concepts of education system, (ii) "social capital" as a concept of tool of analytical control of <b>trust</b> <b>process</b> in education system...|$|R
3000|$|... has in each user {{participating}} in the <b>trust</b> evaluation <b>process.</b> The Public Key Encryption Protocol PKEP outputs a set of the exact trust values given by the users without linking the user that contributed a specific trust value to the trust this user contributed. The obtained vector of trust values assists in removing outliers. Given the set of trust values, the outliers that provide extremely low or high trust values can {{be removed from the}} <b>trust</b> evaluation <b>process.</b> We extend our schemes to the case when the initiator, U [...]...|$|R
40|$|AbstractBased on Linux startup actual conditions, {{critical}} {{files in}} the startup process are analyzed {{so as to}} ensure the rationality of the credibility measurement. In order to provide a method to build the trust chain and do trust measurement and transferring on the trusted computing platform, a TPM simulation platform which has partial specific security features was constructed on the CentOS Linux, and then designed and implemented the <b>trusted</b> startup <b>process</b> based on data integrity. At last, the time cost which caused by <b>trusted</b> startup <b>process</b> was analyzed and calculated...|$|R
30|$|Aside {{from all}} the {{attributes}} mentioned above, an ideal trust model should also have a <b>trust</b> management <b>process</b> which involves the generation of trust, presentation, measurement, interplay, punishment, and updating.|$|R
3000|$|Thirdly, trust {{propagation}} {{chain is}} categorized; recommendations from peer services are given more weight in recommended <b>trust</b> calculation <b>process</b> in respect with recommendation from services in other autonomous pervasive environments [...]...|$|R
40|$|An {{increasing}} number of scholars have recognized trust as {{an important factor in}} governance processes. However, theoretical and empirical analyses of <b>process</b> <b>trust,</b> or trust in the course and outcome of policy processes, are scarce. This paper builds a theoretical framework to further the understanding of <b>process</b> <b>trust.</b> Four elements of <b>process</b> <b>trust</b> are elaborated upon: (1) set-up of the process; (2) institutional trust; (3) organizational trust; (4) individual trust. The way that monitoring can help or hinder the formation of trust is explored. It is argued that monitoring enhances <b>process</b> <b>trust</b> provided that actors perceive monitoring as a collaborative effort. This argument is underpinned by the analysis of a governance process on landscape management in a Dutch municipality, where a local co-operative and the municipality agreed on the members of a monitoring team and the way of monitorin...|$|R
30|$|To {{minimize}} the bootstrapping time and expedite the <b>trust</b> building <b>process,</b> and to effectively {{deal with the}} selective misbehavior, {{there is a strong}} need for a mechanism that works on multi-attribute-based trust strategy. Each node should be observed in the context of all the possible network functions, such as control message generation, control message forwarding, and data packet forwarding. Moreover, an efficient recommendation filtration technique is required to filter the source of information and information itself. To avoid bad-mouthing and false praise attacks, second-hand information from only designated and trustworthy nodes must be considered in a <b>trust</b> computation <b>process.</b>|$|R
40|$|We {{present a}} generic formal {{security}} model for operating systems of multiapplicative smart cards. The model formalizes the main security aspects of secrecy, integrity, secure communication between applications and secure downloading of new applications. The model satisfies a security policy consisting of authentication and intransitive noninterference. The model extends the classical security models of Bell/LaPadula and Biba, but avoids {{the need for}} <b>trusted</b> <b>processes,</b> which {{are not subject to}} the security policy by incorporating such processes directly in the model itself. The correctness of the security policy has been formally proven with the VSE II system...|$|R
