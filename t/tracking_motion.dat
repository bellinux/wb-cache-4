128|3703|Public
50|$|The Java Motion Tracking Framework (JMTF) is a modular {{framework}} for detecting and <b>tracking</b> <b>motion</b> in prerecorded image sequences. Unlike others, it is pure java and requires therefore no native libraries. The JMTF is free software and available under a BSD license.|$|E
50|$|The show moved {{production}} locations 3 times. The first 2 {{years the}} show was produced and shot in BET's headquarters in Washington, DC. The third year {{the show was}} moved to Harlem in BET's newly rented space. The Cita's World set and technical infrastructure literally sat next to the 106 & Park set. The fourth and final year the show was moved to Burbank, CA. The show was also given a major overhaul. New optical <b>tracking</b> <b>motion</b> capture to acquire Kali Troy's performances, its own dedicated stage for the blue screen set, and a remodeled and designed Cita. The show would benefit from the relocation to Los Angeles with staff that was already proficient in visual effects workflows and techniques.|$|E
50|$|Ward Leonard Control, {{also known}} as the Ward Leonard Drive System, was a widely used DC motor speed control system {{introduced}} by Harry Ward Leonard in 1891. In early 1900s, the control system of Ward Leonard was adopted by the U.S. Navy and also used in passenger lift of large mines. It also provided a solution to a moving sidewalk at the Paris Exposition of 1900, where many others had failed to operate properly. It was applied to railway locomotives used in World War I, and was used in anti-aircraft radars in World War II. Connected to automatic anti-aircraft gun directors, the <b>tracking</b> <b>motion</b> in two dimensions had to be extremely smooth and precise. The MIT Radiation Laboratory selected Ward-Leonard to equip the famous radar SCR-584 in 1942. The Ward Leonard control system was widely used for elevators until thyristor drives became available in the 1980s, because it offered smooth speed control and consistent torque. Many Ward Leonard control systems and variations on them remain in use.|$|E
50|$|A motion {{controller}} {{is a type}} of {{game controller}} that uses accelerometers or other sensors to <b>track</b> <b>motion</b> and provide input.|$|R
50|$|In {{areas of}} {{compositing}} and motion graphics, Vegas provides a broad tool set including 3D <b>track</b> <b>motion</b> compositing with control over z-depth, and spatial arrangement of visual planes including plane intersection.|$|R
50|$|Incremental {{encoders}} {{are used}} to <b>track</b> <b>motion</b> {{and can be used}} to determine position and velocity. This can be either linear or rotary motion.Because the direction can be determined, very accurate measurements can be made.|$|R
5000|$|The swing-arm {{mechanism}} has {{a distinctive}} {{advantage over the}} other in {{that it does not}} [...] "skip" [...] when the rail becomes dirty. The swing arm mechanisms tend to have a much longer life than their radial counterparts. The main difference between the two mechanisms is the way they read the data from the disc. The swing-arm mechanism uses a magnetic coil wound over a permanent magnet to provide the tracking movement to the laser assembly in a similar way a hard drive moves its head across the data tracks. It also uses another magnetic movement mechanism attached to the focusing lens to focus the laser beam on the disc surface. By operating the tracking or the focus actuators, the laser beam can be positioned on any part of the disc.This mechanism employs a single laser beam and a set of four photodiodes to read, focus and keep track of the data coming from the disc.The linear tracking mechanism uses a motor and reduction gears to move the laser assembly radially across the tracks of the disc and it also has a set of six coils mounted in the focusing lens over a permanent magnetic field. One set of two coils moves the lens closer to the disc surface, providing the focusing motion, and the other set of coils moves the lens radially, providing a finer <b>tracking</b> <b>motion.</b> This mechanism uses the three-beam tracking method in which a main laser beam is used to read and focus the data track of the disc using three or four photodiodes, depending on the focus method, and two smaller beams read the adjacent tracks at each side to help the servo keep the tracking using two more [...] "helper" [...] photodiodes.|$|E
40|$|In {{order to}} reduce the {{environmental}} contact force and make the operation task completed successfully, the robot is frequently required with force perception and active compliance control. Based on the six-axis wrist force sensor measuring, a robot model of surface <b>tracking</b> <b>motion</b> is proposed, and its force control algorithm and experiment are studied. The measurement principle of the six-axis wrist force sensor and the inadequacy of the sensor measuring the six-dimensional force online are introduced firstly. The surface <b>tracking</b> <b>motion</b> model and its coordinate system are established. On this basis, the relationship between the pose adjustment of surface <b>tracking</b> <b>motion</b> and the measuring results of the six-axis wrist force sensor is deduced. At last, the experimental study of the surface tracking robot system that applied the force control algorithm is conducted. The experiment shows that the robot can adjust the current position and orientation in real time according to the six-axis wrist force sensor measuring, which demonstrates the feasibility of the surface <b>tracking</b> <b>motion</b> model and the correctness of the force control algorithm...|$|E
40|$|An interplanetary low-thrust, solar {{electric}} propulsion mission simulation program {{suitable for navigation}} studies is presented. The mathematical models for trajectory simulation, error compensation, and <b>tracking</b> <b>motion</b> are described. The languages, input-output procedures, and subroutines are included...|$|E
40|$|The <b>motion</b> <b>track</b> is an {{important}} feature to show the spatio-temporal relationship of a video object [2, 5, 7, 8]. In this paper, we propose a novel <b>motion</b> <b>track</b> representation to represent the <b>motion</b> <b>track</b> in the X-Y plane and the trend of velocity changes. Moreover, a new similarity measure for comparing two <b>motion</b> <b>tracks</b> based on the representation is proposed. Furthermore, the <b>motion</b> <b>track</b> segmentation method is proposed to handle a complicated motion behavior and the relevance feedback is used to improve the query results...|$|R
40|$|This paper proposes and evaluates an {{adaptive}} technique and a variable structure control approach for piezoelectric actuation systems to <b>track</b> specified <b>motion</b> trajectories. The proposed control methodologies are formulated to accommodate unknown or uncertain system parameters, nonlinearities including the hysteresis effect, and external disturbances in the piezoelectric actuation systems without {{any form of}} feed-forward compensation. In this study, both control methodologies are demonstrated to possess a promising <b>motion</b> <b>tracking</b> ability experimentally. In comparison, the variable structure control approach is evaluated to be superior to the adaptive technique in the <b>motion</b> <b>tracking</b> control. With the ability to <b>track</b> <b>motion</b> trajectories under parametric uncertainties, nonlinearities, and external disturbances, the proposed control methodologies are very attractive in realising the high-precision piezoelectric actuation systems for micro/nano manipulation...|$|R
50|$|Qpel - <b>Tracks</b> <b>motion</b> changes more {{precisely}} sharpening images. Tends to work best on mid range rate bit rates. Low rates are too blocky to gain advantage from the finer intra-scene motion detailing, and high bit rates adequately capture all motion details anyway.|$|R
40|$|Abstract. In this work, we have {{developed}} a real-time camera control module for navigation in virtual environments. With this module, the <b>tracking</b> <b>motion</b> of a third-person camera can be generated automatically to allow a user {{to focus on the}} control of an avatar. The core of this module consists of a motion planner that uses the probabilistic roadmap method and a lazy update strategy to generate the motion of the camera, possibly with necessary intercuts. A dynamic roadmap specified relative to the avatar is updated in real time within a time budget to account for occlusions in every frame of the control loop. In addition, the planner also allows a user to specify preferences on how the <b>tracking</b> <b>motion</b> is generated. We will use several examples to demonstrate the effectiveness of this real-time camera planning system...|$|E
40|$|Abstract. In robot teleoperation, {{safety and}} {{operational}} performance are two important indicators. This paper presents {{a way to}} use virtual fixture to assist robot teleoperation and studies the realization method of virtual fixture assisting teleoperation in trajectory <b>tracking,</b> <b>motion</b> navigation and obstacle avoidance. The simulation experimental results indicate that virtual fixture method improves security and control performance of teleoperation system...|$|E
40|$|Abstract: In view of {{the strong}} arc weld of images, using {{combined}} MCD correlation matching method with genetic algorithm of traversing search the real-time image and target the best match position between the template image, build <b>tracking</b> <b>motion</b> model, accurately track the weld seam. Experiments show that the method in background, interference problem and tracking stability has achieved expected effect...|$|E
40|$|<b>Motion</b> <b>track</b> is an {{important}} feature to show the spatio-temporal relationship of a video object in a video. In this paper, we propose a novel <b>motion</b> <b>track</b> representation based on MPEG- 7 motion descriptor. A new descriptor is proposed to represent the <b>motion</b> <b>track</b> in the X-Y plane and the trend of velocity changes. Moreover, a new similarity measure for comparing two <b>motion</b> <b>tracks</b> based on the motion trajectory and velocity differences is proposed. The trajectory is compared by {{the properties of the}} polynomials, and the velocity is compared by the different trends. Furthermore, the <b>motion</b> <b>track</b> segmentation method is proposed to handle a complicated motion behavior and the relevance feedback is used to improve the query results. Experiment results show that this approach has a higher precision than existing approaches. Keywords: <b>motion</b> <b>track,</b> MPEG- 7, similarity measure, <b>motion</b> <b>track</b> segmentation, relevance feedback 1...|$|R
40|$|Local {{correlation}} tracking (LCT) is {{a commonly}} used <b>motion</b> <b>tracking</b> technique, particularly in solar physics. When used to <b>track</b> <b>motions</b> smaller than one pixel per time sample, interpolation {{of the original}} data is required. We demonstrate {{that it is possible}} to introduce large systematic errors by using an inappropriate interpolation method, and describe how to avoid these errors. The effect of these errors on the calculated velocity field is demonstrated on simulated solar granulation data...|$|R
30|$|With the {{improving}} {{resolution of}} modern PET scanners, any slight motion during the scan can cause significant blurring {{and loss of}} resolution. MRI scanners {{have the capacity to}} perform quick successive scans and thus provide a means to <b>track</b> <b>motion</b> during a scan. Hence, with the advent of simultaneous PET-MR scanners, it has become possible to use the MR scanner to <b>track</b> the <b>motion</b> and thereby provide the necessary motion parameters to correct the PET data. Using a suitable segmentation approach a separate MR scan can provide the attenuation map to produce quantitative PET images.|$|R
40|$|False {{matching}} due to {{errors in}} feature extraction {{and changes in}} illumination between frames may occur in feature tracking in image sequences. False matching leads to outliers in feature motion trajectory. One way of reducing the effect of outliers is stochastic filtering using a state space model for motion trajectory. Hyper-parameters in the state space model, e. g., variances of noise distributions, must be determined appropriately to control <b>tracking</b> <b>motion</b> and outlier rejection properly. Likelihood {{can be used to}} estimate hyper-parameters, {{but it is difficult to}} apply online tracking due to computational cost. To estimate hyper-parameters online, we include hyper-parameters in state vector and estimate feature coordinates and hyper-parameters simultaneously. A Monte Carlo filter is used in state estimation, because adding hyper-parameters to state vector makes state space model nonlinear. Experimental results using synthetic and real data show that the proposed method can estimate appropriate hyper-parameters for <b>tracking</b> <b>motion</b> and reducing the effect of outliers...|$|E
40|$|Abstract:- In this paper, we {{proposed}} a randomised algorithm to estimate the motion parameters of a planar shape without knowing a priori point-to-point correspondences. By randomly searching points on two shapes measured at different times, we determine the centroids, after which the algorithm proceeds to determine the rotation by searching points on each shape that form congruent polygons. Key-Words:- Motion estimation algorithm, rigid object motion, object <b>tracking,</b> <b>motion</b> parameters estimation...|$|E
40|$|Specific to Cognitive Psychology: Human spatial ability; spatial cognition, spatial perception, {{and spatial}} memory; navigation, wayfinding, {{landmark}} use, and reference frames; Multidisciplinary: applied virtual reality simulation and training; motion <b>tracking,</b> <b>motion</b> capture and animation; immersive user interfaces, human-computer-interaction, and human factors issues in virtual reality; Teaching Interests Specific to Cognitive Psychology: Spatial cognition, cognition, memory, perception, statistics, research methods, virtual reality {{as a research}} tool, computer programming for psychologists, human factors Multidisciplinary: 3 D modeling and animation, motion capture, human-computer interaction...|$|E
40|$|Recent {{progress}} in live cell imaging suggests {{a role for}} nuclear actin in chromatin movement. In this issue, for the first time, a gene locus moving toward a subnuclear compartment was <b>tracked.</b> <b>Motion</b> of the locus is actin dependent, raising {{the question of whether}} chromatin movements are random or directed...|$|R
50|$|Kean {{introduces}} {{other scientists}} {{such as the}} duo Hubel and Wiesel, who tried various experiments with cats to get their neurons to fire. Through many botched experiment attempts, one fateful accident led to the breakthrough that certain neurons fire at certain things. They discovered that neurons like to <b>track</b> <b>motion.</b>|$|R
50|$|The data {{collected}} is extrapolated to provide ball flight trajectory and roll out according to certain calculated relationships to the ball's flight performance per the <b>tracked</b> <b>motion</b> {{of the ball}} or club, adding environmental aspects through which the ball is projected, including terrain, wind, rain and other such influences or obstacles.|$|R
40|$|International audienceIn the furrow {{illusion}} (Anstis, 2012), {{the perceived}} {{path of a}} moving target follows the veridical path orientation when viewed foveally, but follows {{the orientation of the}} texture when viewed peripherally. These radically different motion percepts depending on whether the stimulus is viewed foveally or peripherally has led Anstis to conclude that the furrow illusion reveals " profound differences {{in the way that the}} periphery and fovea process visual motion. " In the current study, we rather argue that the different percepts can be explained by reduced position acuity with eccentricity and therefore do not imply different ways of processing motion per se. If feature tracking, which is position-based, is involved in the perception of the veridical motion direction, then impairing the feature <b>tracking</b> <b>motion</b> system should strengthen the illusion. To reduce contribution of the feature <b>tracking</b> <b>motion</b> system, we used a crowding paradigm consisting in presenting many nearby targets. We found that under crowding conditions, the furrow illusion was stronger. We conclude that feature tracking was involved in the perception of the veridical motion direction, which is compatible with the hypothesis that the different motion percepts at fixation and in the periphery are due to a reduced position acuity with eccentricity affecting feature tracking, not to different ways of processing motion per se...|$|E
40|$|Abstract â€” In {{this paper}} a robotic batting {{algorithm}} using a high-speed arm and high-speed stereo vision is proposed. With this strategy, the desired {{trajectory of the}} manipulator is generated so that both high-speed swing motion and <b>tracking</b> <b>motion</b> combine to meet the ball squarely with the bat. As a result the manipulator can follow the ball while swinging the bat at high speed {{even if it is}} difficult to predict the trajectory of a ball. Experimental results are shown in which a high-speed manipulator hits a ball thrown by a human. I...|$|E
40|$|Dynamic {{vision and}} imaging systems can sub-stantially improve our quality of life. However, key issues {{that must be}} {{addressed}} in order to deploy these systems are their potential fragility and the need to process vast amounts of infor-mation in real time. As we show in this paper, these issues can be addressed by appealing to a common systems theoretic substrate that al-lows for recasting a wide range of problems into a tractable convex optimization form. These ideas are illustrated with several applications including multiframe <b>tracking,</b> <b>motion</b> segmen-tation, texture analysis/synthesis and video re-construction and inpainting. 1...|$|E
50|$|Commotion set a high {{standard}} for a rotoscoping application, introducing rotosplines and offering features like <b>motion</b> <b>tracking</b> and <b>motion</b> blurring for masks.It was the first desktop application to allow real-time playback of full quality video clips from RAM.|$|R
5000|$|Michael Black and David Fleet, Probabilistic Detection and <b>Tracking</b> of <b>Motion</b> Discontinuities ...|$|R
50|$|GameSpot {{felt the}} camera's {{inclusion}} in Your Shape {{was one of}} the few positive aspects of the game, as it removed the dependency on other accessories for the Wii to <b>track</b> <b>motion</b> for this purpose, and did a favorable job at judging the player's movement, but noted that it required a large-enough room to function correctly.|$|R
40|$|We {{sought to}} {{determine}} whether or not motion-from-texture mechanisms have access to monocular input. Adopting a strategy used by Kolb and Braun (1995), we created drifting textures that were invisible to purely binocular processes. Monocular signals readily conveyed motions defined by local orientation and flicker. However, when left-eye and right-eye signals were displayed simultaneously, only flicker motion was visible. We conclude that motion-from-texture mechanisms do not have access to monocular input. Further evidence suggests that motion from texture involves attentional <b>tracking.</b> <b>Motion</b> from texture Attentional tracking 2 nd-order motio...|$|E
40|$|The {{existence}} of a second-order motion system distinct from both the first-order and feature <b>tracking</b> <b>motion</b> systems remains controversial even though many consider it well established. In the present study, the texture contribution to motion was measured within and beyond the spatial acuity of attention by presenting the stimuli in the near periphery where the spatial resolution of attention is low. The logic was that when moving elements are too close one to another for attention to individually select them (i. e., crowding), {{it is not possible}} to track them. To test the {{existence of}} a dedicated second-order motion system, the texture contribution to motion was measured when neutralizing both the feature <b>tracking</b> <b>motion</b> system and the contribution of the first-order motion system due to preprocessing nonlinearities introducing residual distortion products. When the contribution of distortion products was not neutralized, texture substantially contributed to motion for spatial frequencies within and beyond the spatial acuity of attention. When neutralizing the contribution of distortion products, texture substantially contributed to motion for spatial frequencies within the spatial acuity of attention, but not for spatial frequencies beyond the spatial acuity of attention. We conclude that there is no dedicated second-order motion system; the texture contribution to motion is mediated solely by the first-order (due to residual distortion products) and feature tracking (at frequencies within spatiotemporal acuity of attention) motion systems...|$|E
40|$|Anatomical {{structures}} are rarely static during a surgical procedure due to breathing, heartbeats, and peristaltic movements. Inspired by observing an expert surgeon, we propose an intermittent synchronization with the extrema of the rhythmic motion (i. e., the lowest velocity windows). We performed 2 experiments: (1) pattern cutting, and (2) debridement. In (1), {{we found that}} the intermittent synchronization approach, while 1. 8 x slower than <b>tracking</b> <b>motion,</b> was significantly more robust to noise and control latency, and it reduced the max cutting error by 2. 6 x In (2), a baseline approach with no synchronization achieves 62 % success rate for each removal, while intermittent synchronization achieves 80 %...|$|E
30|$|One of {{the main}} {{limitations}} affecting gesture-based haptic feedback generation is noisy and volatile motion data during mid-air interactions. The occlusion of the <b>tracked</b> <b>motion</b> and range limitations of <b>motion</b> <b>tracking</b> sensors deteriorate the haptic feedback based on mid-air fingertip motion [4, 5]. Conventional filtering approaches {{may not be able}} to provide stable motion data generation because human gestures and interactions are highly arbitrary and do not have specific frequency distinctions with anomalies. In this paper, we intend to propose a new method for generating stable and realistic haptic feedback even during unstable tracking conditions.|$|R
40|$|We {{describe}} a vision system that monitors activity in a site over {{extended periods of}} time. The system uses a distributed set of sensors to cover the site, and an adaptive tracker detects multiple moving objects in the sensors. Our hypothesis is that <b>motion</b> <b>tracking</b> is sufficient to support a range of computations about site activities. We demonstrate using the <b>tracked</b> <b>motion</b> data: to calibrate the distributed sensors, to construct rough site models, to classify detected objects, to learn common patterns of activity for different object classes, and to detect unusual activities...|$|R
40|$|October 8, 2009. Media Hall, Mie University, Tsu, Mie, JapanWe {{propose a}} new {{methodology}} for <b>motion</b> <b>tracking</b> of local myocardial tissue on M-mode echocardiograms. This methodology is {{applicable to the}} quantitative assessment of myocardial performance in clinics. The Mmode echocardiogram is widely used in clinics to measure diagnostic indexes like thickening and thinning of myocardial muscle layers. To measure such indexes, doctors are required to <b>track</b> myocardial <b>motion</b> manually, however the <b>tracking</b> of myocardial <b>motion</b> by hand is tedious and time-consuming process. Our proposed method is able to <b>track</b> the myocardial <b>motion</b> on M-mode echocardiograms automatically by employing DP-based optimization. In this report we present the proposed method...|$|R
