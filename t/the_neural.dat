10000|10000|Public
5|$|At the {{beginning}} of the third week of development, the embryonic ectoderm forms a thickened strip called <b>the</b> <b>neural</b> plate. By the fourth week of development <b>the</b> <b>neural</b> plate has widened to give a broad cephalic end, a less broad middle part and a narrow caudal end. These swellings represent {{the beginning}}s of the forebrain, midbrain and hindbrain. Neural crest cells (derived from the ectoderm) populate the lateral edges of the plate at <b>the</b> <b>neural</b> folds. In the fourth week in the neurulation stage <b>the</b> <b>neural</b> plate folds and closes to form <b>the</b> <b>neural</b> tube, bringing together <b>the</b> <b>neural</b> crest cells at <b>the</b> <b>neural</b> crest. <b>The</b> <b>neural</b> crest runs the length of the tube with cranial neural crest cells at the cephalic end and caudal neural crest cells at the tail. Cells detach from the crest and migrate in a craniocaudal (head to tail) wave inside the tube. Cells at the cephalic end give rise to the brain, and cells at the caudal end give rise to the spinal cord.|$|E
5|$|The {{developing}} forebrain surrounds <b>the</b> <b>neural</b> cord. As the forebrain develops, <b>the</b> <b>neural</b> cord {{within it}} becomes a ventricle, ultimately forming the lateral ventricles. Along the inner surface of both ventricles, the ventricular wall remains thin, and a choroid plexus develops, producing and releasing CSF. The CSF quickly fills <b>the</b> <b>neural</b> canal. Arachnoid villi are formed around the 35th week of development, with aracnhoid granulations noted around the 39th, and continuing developing until 18 months of age.|$|E
5|$|The {{skull of}} the Acrocanthosaurus atokensis holotype shows light exostotic {{material}} on the squamosal. <b>The</b> <b>neural</b> spine of the eleventh vertebra was fractured and healed while <b>the</b> <b>neural</b> spine of its third tail vertebra had an unusual hook-like structure.|$|E
3000|$|..., then <b>the</b> {{response}} <b>neural</b> network (41) can globally asymptotically synchronize <b>the</b> drive <b>neural</b> network (40), and the [...]...|$|R
40|$|Abstract- This paper {{presents}} a modified neural network for solving strictly quadratic programming problems with general linear constraints. It is shown that <b>the</b> proposed <b>neural</b> network is globally convergent to a unique optimal solution within a finite time. Compared with <b>the</b> existing primal-dual <b>neural</b> network and <b>the</b> dual <b>neural</b> network for solving such problems, <b>the</b> proposed <b>neural</b> network {{has a low}} complexity for implementation and can be guaranteed to have an exponential convergence rate. The good performance of <b>the</b> proposed <b>neural</b> network is illustrated by a real-time application to Kinematic Control...|$|R
50|$|<b>The</b> cardiac <b>neural</b> crest {{develops}} from <b>the</b> dorsal <b>neural</b> tube. It overlaps <b>the</b> vagal <b>neural</b> crest and migrates to {{populate the}} pharyngeal arches 3, 4 and 6 (producing {{structures in the}} head) and to the heart, forming connective tissue that separates the great vessels of the heart.|$|R
5|$|Around {{the third}} week of development, the embryo is a three-layered disc, covered with ectoderm, {{mesoderm}} and endoderm. A tube-like formation develops in the midline, called the notochord. The notochord releases extracellular molecules that affect the transformation of the overlying ectoderm into nervous tissue. <b>The</b> <b>neural</b> tube, forming from the ectoderm, contains CSF prior {{to the development of the}} choroid plexuses. The open neuropores of <b>the</b> <b>neural</b> tube close after the first month of development, and CSF pressure gradually increases.|$|E
5|$|For vertebrates, {{the early}} stages of neural {{development}} are similar across all species. As the embryo transforms from a round blob of cells into a wormlike structure, a narrow strip of ectoderm running along the midline of the back is induced to become <b>the</b> <b>neural</b> plate, the precursor of the nervous system. <b>The</b> <b>neural</b> plate folds inward to form <b>the</b> <b>neural</b> groove, and then the lips that line the groove merge to enclose <b>the</b> <b>neural</b> tube, a hollow cord of cells with a fluid-filled ventricle at the center. At the front end, the ventricles and cord swell to form three vesicles that are the precursors of the forebrain, midbrain, and hindbrain. At the next stage, the forebrain splits into two vesicles called the telencephalon (which will contain the cerebral cortex, basal ganglia, and related structures) and the diencephalon (which will contain the thalamus and hypothalamus). At about the same time, the hindbrain splits into the metencephalon (which will contain the cerebellum and pons) and the myelencephalon (which will contain the medulla oblongata). Each of these areas contains proliferative zones where neurons and glial cells are generated; the resulting cells then migrate, sometimes for long distances, to their final positions.|$|E
5|$|The neck {{formed a}} straighter S shape (a sigmoid curve typical of theropods) than that seen in other theropods; in fact, the neck was {{initially}} thought to lack the Scurve. The {{shape of the}} cervical vertebrae indicate that they tapered towards the head and were progressively longer front to back. <b>The</b> <b>neural</b> spines of the cervical vertebrae were low, thin, and were not always sutured to the centra (the bodies of the vertebrae). The axis vertebra, small relative {{to the size of}} the skull, had a well-developed hyposphene. The centra of the dorsal vertebrae were similar in size. Like other dinosaurs, Baryonyx reduced its weight (skeletal pneumaticity) with fenestrae (openings) in <b>the</b> <b>neural</b> arches and with pleurocoels (hollow depressions) in the centra (primarily near the transverse processes). From front to back, <b>the</b> <b>neural</b> spines of the dorsal vertebrae changed from short and stout to tall and broad.|$|E
50|$|The {{society was}} formed as <b>the</b> IEEE <b>Neural</b> Networks Council on November 17, 1989 {{with representatives from}} 12 {{different}} IEEE societies. On November 21, 2001, <b>the</b> IEEE <b>Neural</b> Networks Council became <b>the</b> IEEE <b>Neural</b> Networks Society. In November 2003, it {{changed its name to}} the IEEE Computational Intelligence Society.|$|R
40|$|AbstractMathematical essence and {{structures}} of <b>the</b> feedforward <b>neural</b> networks are investigated in this paper. The interpolation mechanisms of <b>the</b> feedforward <b>neural</b> networks are explored. For example, the well-known result, namely, that a neural network is an universal approximator, can be concluded naturally from the interpolative representations. Finally, the learning algorithms of <b>the</b> feedforward <b>neural</b> networks are discussed...|$|R
40|$|<b>The</b> Graph <b>Neural</b> Network is a {{relatively}} new machine learning method capable of encoding data as well as relationships between data elements. This paper applies <b>the</b> Graph <b>Neural</b> Network for <b>the</b> first time to a given learning task at an international competition on the classification of semi-structured documents. Within this setting, <b>the</b> Graph <b>Neural</b> Network is trained to encode and process {{a relatively}} large set of XML formatted documents. It will be shown that the performance using <b>the</b> Graph <b>Neural</b> Network approach significantly outperforms the results submitted by the best competitor...|$|R
5|$|Another {{possible}} pathology was {{noticed by}} Parks, and {{from around the}} notch. In the fourth, fifth, and sixth vertebrae, directly anterior to the notch, <b>the</b> <b>neural</b> spines were damaged. The fourth had an obvious fracture, {{with the other two}} possessing a swelling {{at the base of the}} break.|$|E
5|$|Any {{electrical}} current generates a magnetic field; neural oscillations induce weak magnetic fields, and in functional magnetoencephalography the current produced can show localised brain function in high resolution. Tractography uses MRI and image analysis to create 3D {{images of the}} nerve tracts of the brain. Connectograms give a graphical representation of <b>the</b> <b>neural</b> connections of the brain.|$|E
5|$|Elaborate body {{structures}} of many modern-day animals usually serve to attract {{members of the}} opposite sex during mating. It is quite possible that the sails or humps of these dinosaurs were used for courtship, in a way similar to a peacock's tail. Stromer speculated that males and females may have differed in the size of <b>the</b> <b>neural</b> spine.|$|E
40|$|Abstract- In this letter, we will {{clarify the}} reducibility of <b>the</b> {{complex-valued}} <b>neural</b> network. In <b>the</b> case of <b>the</b> complex-valued <b>neural</b> network, <b>the</b> reducibility is expressed by nπ/ 2 rotation-equivalence instead of sign-equivalence which Sussmann defined {{to show the}} reducibility of <b>the</b> real-valued <b>neural</b> network. In addition to the two conditions of sign-equivalence, nπ/ 2 rotation-equivalence has two new conditions related to the rotation of complex numbers...|$|R
5000|$|... #Caption: Transverse {{sections}} through <b>the</b> first <b>neural</b> of A. Aspideretes hurum {{showing the}} suture between <b>the</b> wide <b>neural</b> bone (N) and <b>the</b> vertebral <b>neural</b> arch (V). B. Chelodina longicollis at pleural IV showing a narrow midline neural bone, lateral pleurals (P) and underlying vertebral neural arch. and C. Emydura subglobosa at pleural IV showing {{location of a}} rudimentary neural bone underneath medially contiguous pleurals.|$|R
40|$|Abstract — In this study, {{we address}} the {{durability}} of the brain, which is able to operate in various imperfect situ-ations. In our previous research, we have proposed a new network structure called <b>the</b> “Affordable <b>Neural</b> Network”, where affordable neurons in the hidden layer of <b>the</b> feedforward <b>neural</b> network reflect {{important aspects of the}} real brain mechanism. We consider that the concept of <b>the</b> affordable <b>neural</b> network embodies <b>the</b> important feature of durability. In our contribution, we investigate {{the durability of}} <b>the</b> affordable <b>neural</b> network when some of the neurons in the hidden layer are damaged after the learning process. I...|$|R
5|$|In {{addition}} to PET and fMRI, which show which {{areas of the}} brain are activated by certain tasks, researchers also use diffusion tensor imaging (DTI), which shows <b>the</b> <b>neural</b> pathways that connect different brain areas, thus providing insight into how different areas interact. Functional near-infrared spectroscopy (fNIRS) is another hemodynamic method used in language tasks.|$|E
5|$|Like other hadrosaurids, it {{was able}} to walk on either two legs or four. It {{probably}} preferred to forage for food on four legs, but ran on two. <b>The</b> <b>neural</b> spines of the vertebrae were tall, as was common in lambeosaurines; tallest over the hips, they increased the height of the back. Skin impressions are known for P. walkeri, showing uniform tubercle-like scales but no larger structures.|$|E
5|$|Similar to the {{mechanism}} of ethanol's effect, the increase of gas dissolved in nerve cell membranes may cause altered ion permeability properties of <b>the</b> <b>neural</b> cells' lipid bilayers. The partial pressure of a gas required to cause a measured degree of impairment correlates well with the lipid solubility of the gas: the greater the solubility, the less partial pressure is needed.|$|E
40|$|In this paper, {{we propose}} a fast winner-take-all (WTA) <b>neural</b> network. <b>The</b> fast winner-take-all <b>neural</b> network with <b>the</b> dynamic ratio in mutual-inhibition is {{developed}} from <b>the</b> general mean-based <b>neural</b> network (GEMNET), which adopts {{the mean of}} the active neurons as the threshold of mutual inhibition. Furthermore, <b>the</b> other win-ner-take-all <b>neural</b> network enhances <b>the</b> convergence speed to become a decimal system. <b>The</b> proposed WTA <b>neural</b> networks statistically achieve the large ratio of mutual inhibi-tion. <b>The</b> new WTA <b>Neural</b> Networks converge faster than <b>the</b> existing WTA <b>neural</b> networks for a large number of competitors based on both theoretical analyses and simu-lation results...|$|R
40|$|Abstract—In this paper, {{we present}} a {{recurrent}} neural network for solving the nonlinear projection formulation. It is shown here that <b>the</b> proposed <b>neural</b> network is stable {{in the sense of}} Lyapunov and globally convergent, globally asymptotically stable, and glob-ally exponentially stable, respectively under different conditions. Compared with <b>the</b> existing <b>neural</b> network for solving the projec-tion formulation, <b>the</b> proposed <b>neural</b> network has a single-layer structure and is amenable to parallel implementation. Moreover, <b>the</b> proposed <b>neural</b> network has no Lipschitz condition, and, thus can be applied to solve a very broad class of constrained optimiza-tion problems that are special cases of the nonlinear projection for-mulation. Simulation shows that <b>the</b> proposed <b>neural</b> network is effective in solving these constrained optimization problems. Index Terms—Constrained optimization problems, global sta-bility, recurrent neural network. I...|$|R
40|$|In this paper, an {{integrated}} neural-fuzzy process controller {{was developed to}} study the coagulation of wastewater treatment in a paper mill. In order to improve <b>the</b> fuzzy <b>neural</b> network performance, <b>the</b> self-learning ability embedded in <b>the</b> fuzzy <b>neural</b> network model was emphasized for improving the rule extraction performance. It proves <b>the</b> fuzzy <b>neural</b> network more effective in modeling the coagulation performance than artificial neural networks (ANN). For comparing between <b>the</b> fuzzy <b>neural</b> controller and PID controller, a coagulation unit in a paper mill wastewater treatment process (PMWTP) was chosen to support the derivation of a fuzzy control rule base. It is shown that, using <b>the</b> fuzzy <b>neural</b> controller, in terms of cost effectiveness, enables us to save almost 25 % of the operating costs during {{the time when the}} controller can be applied...|$|R
5|$|The {{cervical}} vertebrae of {{the neck}} had broad neural spines that increased in height towards the body. The front part of <b>the</b> <b>neural</b> spines had well developed entheses, which was common among adult dinosaurs, and indicates the presence of large ligaments which helped support the massive head. The dorsal vertebrae of the back had centra (or bodies) that were short relative to their width, and their neural spines were short and narrow. The dorsal vertebrae were tightly spaced, which limited the downwards movement of the back. <b>The</b> <b>neural</b> spines had ossified (turned to bone) tendons, which also overlapped some of the vertebrae. The ribs {{of the last four}} back vertebrae were fused to them, and the ribcage was very broad {{in this part of the}} body. The ribs had scars that show where muscles attached to them. The caudal vertebrae of the tail had centra that were slightly amphicoelous, meaning they were concave on both sides. The interlocked zygapophyses (articular processes) of the caudal vertebrae formed a U-shape when seen from above, instead of the more usual V-shape.|$|E
5|$|The {{first few}} dorsal {{vertebrae}} {{are similar to}} the cervical vertebrae, but have taller and more prong-like neural spines. The rest are amphiplatyan, meaning that they are flat at both ends. They also have postzygapophyses which are less elongate and more pedestal-like, in addition to taller and more rectangular neural spines. The parapophyses, which are depressions instead of projections, have moved off from the transverse processes to <b>the</b> <b>neural</b> arch, between the transverse processes and the articular processes known as the prezygapophyses {{at the front of the}} vertebrae. However, they move back onto the base of the transverse processes in the last few dorsals. In the third or fourth dorsal, the parapophysis is located very close to the suture between <b>the</b> <b>neural</b> spine and the centrum, which is unlike the other dorsals but similar to the first few dorsals in Edmontosaurus. Also like Edmontosaurus, the median ridge separating the prezygapophyses become more pronounced in the rear dorsals.|$|E
5|$|The large groove {{that runs}} {{the length of the}} spine was once thought to be a channel for blood vessels, but since the bone does not contain {{vascular}} canals, the sail is not thought to have been as highly vascularized as once thought. Some specimens of Dimetrodon preserve deformed areas of <b>the</b> <b>neural</b> spines that appear to be healed-over fractures. The cortical bone that grew over these breaks is highly vascularized, suggesting that soft tissue must have been present on the sail to supply the site with blood vessels. Layered lamellar bone makes up most of <b>the</b> <b>neural</b> spine's cross-sectional area, and contains lines of arrested growth {{that can be used to}} determine the age of each individual at death. In many specimens of D. gigashomogenes the distal portions of spines bend sharply, indicating that the sail would have had an irregular profile in life. Their crookedness suggests that soft tissue may not have extended all the way to the tips of the spines, meaning that the sail's webbing may not have been as extensive as it is commonly imagined.|$|E
25|$|<b>The</b> {{migration}} of <b>neural</b> crest cells involves a highly coordinated cascade {{of events that}} begins with closure of <b>the</b> dorsal <b>neural</b> tube.|$|R
40|$|This paper {{introduces}} {{a kind of}} diagnosis principle and learning algorithm of steam turbine fault diagnosis which based on Elman <b>neural</b> network. Comparing <b>the</b> results of <b>the</b> Elman <b>neural</b> network and <b>the</b> traditional BP <b>neural</b> network diagnosis, <b>the</b> results shows that Elman neural network is {{an effective way to}} improve the learning speed, effectively suppress the minimum defects that <b>the</b> traditional <b>neural</b> network easily trapped in, and shorten the autonomous learning time. All these proves that <b>the</b> Elman <b>neural</b> network is an effective way to diagnose the steam turbine...|$|R
3000|$|... {{which implies}} that the error {{dynamical}} system (8) is globally asymptotically stable by the Lyapunov stability theory. Accordingly, <b>the</b> response <b>neural</b> network (3) can globally asymptotically synchronize <b>the</b> drive <b>neural</b> network (1). <b>The</b> proof is completed.|$|R
5|$|The methodological {{breakthroughs}} of the neurosciences, {{in particular}} the introduction of high-tech neuroimaging procedures, has propelled scientists toward the elaboration of increasingly ambitious research programs: {{one of the main}} goals is to describe and comprehend <b>the</b> <b>neural</b> processes which correspond to mental functions (see: neural correlate). Several groups are inspired by these advances.|$|E
5|$|The neck {{vertebra}} {{referred to}} Hatzegopteryx sp. contains {{a number of}} traits that allow {{for it to be}} definitely identified as that of an azhdarchid. The centrum is relatively low, the zygapophyses are large and flattened, and the preserved portions of <b>the</b> <b>neural</b> spine indicate that it is bifid, or split into two.|$|E
5|$|The {{sense of}} smell is {{generated}} by receptor cells in the epithelium of the olfactory mucosa in the nasal cavity. This information passes through a relatively permeable part of the skull to the olfactory nerve. This nerve transmits to <b>the</b> <b>neural</b> circuitry of the olfactory bulb from where information is passed to the olfactory cortex.|$|E
40|$|One of {{the most}} common {{problems}} encountered in agriculture is that of predicting a response variable from covariates of interest. The aim {{of this paper is to}} use a Bayesian neural network approach to predict dairy daughter milk production from dairy dam, sire, herd and environmental factors. The results of <b>the</b> Bayesian <b>neural</b> network are compared with results obtained when the regression relationship is described using <b>the</b> traditional <b>neural</b> network approach. In addition, the "baseline" results of a multiple linear regression employing both frequentist and Baysian methods are presented. The potential advantages of <b>the</b> Bayesian <b>neural</b> network appraoch over <b>the</b> traditional <b>neural</b> network approach are discussed...|$|R
40|$|ABSTRACT. <b>The</b> {{proposed}} IAFC <b>neural</b> {{networks have}} both stability and plasticity because {{they use a}} control structure {{similar to that of}} the ART- 1 (Adaptive Resonance Theory) <b>neural</b> network. <b>The</b> unsupervised IAFC <b>neural</b> network is <b>the</b> unsupervised <b>neural</b> network which uses the fuzzy leaky learning rule. This fuzzy leaky learning rule controls the updating amounts by fuzzy membership values. <b>The</b> supervised IAFC <b>neural</b> networks are <b>the</b> supervised <b>neural</b> networks which use the fuzzified versions of Learning Vector Quantization (LVQ). In this paper, several important adaptive learning algorithms are compared from the viewpoint of structure and learning rule. The performances of several adaptive learning algorithms are compared using Iris data set...|$|R
40|$|In this paper, {{we present}} a {{recurrent}} neural network for solving mixed linear complementarity problems (MLCPs) with positive semi-definite matrices. <b>The</b> proposed <b>neural</b> network is derived based on an NCP function and has a low complexity respect to the other existing models. In theoretical and numerical aspects, global convergence of <b>the</b> proposed <b>neural</b> network is proved. As an application, we show that <b>the</b> proposed <b>neural</b> network {{can be used to}} solve linear and convex quadratic programming problems. The validity and transient behavior of <b>the</b> proposed <b>neural</b> network are demonstrated by using five numerical examples. NCP functions, dynamical system, linear programming, mixed linear complementarity problem, quadratic programming, stability, global convergence...|$|R
