5|10000|Public
50|$|Lebedev {{then began}} {{development}} of a new, more powerful computer, the M-20, the number denoting its expected processing speed of twenty <b>thousand</b> <b>operations</b> <b>per</b> <b>second.</b> In 1958 the machine was accepted as operational and put into series production. Simultaneously the BESM-2, a development of the BESM-1, went into series production. Though the BESM-2 was slower than the M-20, it was more reliable. It was used to calculate satellite orbits and the trajectory of the first rocket to reach {{the surface of the}} Moon. Lebedev and his team developed several more computers, notably the BESM-6, which was in production for 17 years.|$|E
50|$|Type 670-I CDS is a {{centralized}} {{system based on}} specially developed 22-bit, 8K-RAM, MLB minicomputers, which is built on DTL small-scale integrated circuits (IC). The minicomputer is capable of performing two hundred <b>thousand</b> <b>operations</b> <b>per</b> <b>second</b> (ops/sec). The thirty-one centimeter display is fully transistorized and adopts a mixture of analog and digital circuitry. If accepted into service, the system would be designated as ZKJ, short for Zi-dong Kong-zhi Ji-qi (自动控制机器), meaning automatic control machine, because system was intended to automate shipborne weaponry control that was performed manually. However, the political turmoil in China at the time, namely, the Cultural Revolution, had serious hampered {{the development of the}} first Chinese CDS. The only prototype built was plagued with reliability problem, and instead of the originally name planned, the system was frequently and candidly referred by the nickname given by the sailors as seasick machine (Yun-chuan-ji, 晕船机) due to its frequent breakdowns, especially in severe sea states. As a result, Type 670-I Poseidon-1 did not enter service after seven years of development. Although Type 670-1 failed to enter production and service, it is nonetheless an important milestone in the development of CDS in China in that it has provided the foundation of CDS framework for similar systems developed later in China.|$|E
50|$|Karpiński {{soon after}} the {{completion}} of perceptron fell out with Węgrzyn, which forced him to leave the Institute of Automatics. He moved to the Polish Academy of Sciences’ Institute of Physics led by Jerzy Pniewski. Pniewski’s team worked on the analysis of data from CERN - pictures from Glaser bubble chambers, traces of colliding electrons and neutrons. The Institute struggled with the amount of data and was looking for a mechanism to speed up the processing of data. In 1965, on Pniewski’s request Karpiński firstly designed a scanner, then after its success began work on the mathematical machine that could compute the scanned data. With the help of newly formed team of seven people including later long-time cooperators Tadeusz Kupniewski and Teresa Pajkowska, Karpiński finished the machine in 1968, dubbed KAR-65, after three years of work. Due to financial constraints, KAR-65 was built using Polish germane transistors TG-40 and DOG-61 diodes, consideralby slower than their western counterparts. KAR-65 was asynchronic and used a dedicated operation system, designed by Karpiński. The computer could perform 100 <b>thousand</b> <b>operations</b> <b>per</b> <b>second,</b> which made him then the fastest Polish computer. The computer consisted of two parts, both measuring 1,7m x 1,4 m x 0,4m, but was still considerably smaller that the leading Polish computers of the time - Odra mainframes. Computer’s interface was designed by the artist Stanisław Tomaszewski, who also worked previously on the AKAT-1. The total cost of construction was estimated to be 6 million złotys. Only one machine was built and it continued to work in the Institute of Physics for 20 years. It currently resides in the Museum of Technology in Warsaw.|$|E
50|$|In 2004 Quadrics was {{selected}} by Bull for {{what will be the}} fastest supercomputer in Europe: TERA-10 at the French CEA: 544 Bull NovaScale 6160 computing nodes, each including eight Itanium 2 processors. The global configuration will feature 8,704 processors with 27 terabytes of core memory. Each of these computing nodes will contain multiple Quadrics QsNetII (Elan4) network adapters to deliver over 60 teraflops (sixty <b>thousands</b> billions of <b>operations</b> <b>per</b> <b>second).</b>|$|R
40|$|SIP is a {{protocol}} of growing importance, with uses for VoIP, instant messaging, presence, and more. However, its performance is not well-studied or understood. In this paper we experimentally evaluate SIP proxy server performance using micro-benchmarks meant to capture common SIP proxy server scenarios. We use standard open-source SIP software such as OpenSER and SIPp, running on an IBM BladeCenter with Red Hat Enterprise Linux and Gigabit Ethernet connectivity. We show performance varies greatly {{depending on how}} the protocol is used. Depending on the configuration, throughput can vary from hundreds to <b>thousands</b> of <b>operations</b> <b>per</b> <b>second.</b> For example, we observe that the choice of stateless vs. stateful proxying, using TCP rather than UDP, or including MD 5 -based authentication can each affect performance by a factor of 2 – 4. Categories and Subject Descriptor...|$|R
40|$|Recent {{advances}} in high-performance computing have pushed computational capabilities to a petaflop (a <b>thousand</b> trillion <b>operations</b> <b>per</b> <b>second)</b> {{in a single}} computing cluster. This breakthrough has been hailed {{as a way to}} fundamentally change science and engineering by letting people perform experiments that were previously beyond reach. But for those interested in exploring the I/O behavior of their simulation model, efficient experimental design has a much higher payoff at a much lower cost. A well-designed experiment allows the analyst to examine many more factors than would otherwise be possible, while providing insights that cannot be gleaned from trial-and-error approaches or by sampling factors one at a time. We present the basic concepts of experimental design, the types of goals it can address, and why it is such an important and useful tool for simulation. Ideally, this tutorial will entice you to use experimental designs in your upcoming simulation studies. ...|$|R
40|$|ABSTRACT. We {{suggest an}} {{adaptive}} sampling rule for obtaining information from noisy signals using wavelet methods. The technique involves increasing the sampling rate when relatively high-frequency terms {{are incorporated into}} the wavelet estimator, and decreasing it when, again using thresholded terms as an empirical guide, signal complexity is judged to have decreased. Through sampling {{in this way the}} algorithm is able to accurately recover relatively complex signals without increasing the long-run average expense of sampling. It achieves this level of performance by exploiting the opportunities for near-real time sampling that are available if one uses a relatively high primary resolution level when constructing the basic wavelet estimator. In the practical problems that motivate the work, where signal to noise ratio is particularly high and the long-run average sampling rate may be several hundred <b>thousand</b> <b>operations</b> <b>per</b> <b>second,</b> high primary resolution levels are quite feasible...|$|E
40|$|We {{suggest an}} {{adaptive}} sampling rule for obtaining information from noisy signals using wavelet methods. The technique involves increasing the sampling rate when relatively high-frequency terms {{are incorporated into}} the wavelet estimator, and decreasing it when, again using thresholded terms as an empirical guide, signal complexity is judged to have decreased. Through sampling {{in this way the}} algorithm is able to accurately recover relatively complex signals without increasing the long-run average expense of sampling. It achieves this level of performance by exploiting the opportunities for near-real time sampling that are available if one uses a relatively high primary resolution level when constructing the basic wavelet estimator. In the practical problems that motivate the work, where signal to noise ratio is particularly high and the long-run average sampling rate may be several hundred <b>thousand</b> <b>operations</b> <b>per</b> <b>second,</b> high primary resolution levels are quite feasible. Comment: Published at [URL] in the Annals of Statistics ([URL] by the Institute of Mathematical Statistics ([URL]...|$|E
40|$|This paper {{presents}} {{the design and}} implementation of NetQuery, a knowledge plane for federated networks such as the Internet. In such networks, not all administrative domains will generate information that an application can trust and many administrative domains may have restrictive policies on disclosing network information. Thus, both the trustworthiness and accessibility of network information pose obstacles to effective reasoning. NetQuery employs trustworthy computing techniques to facilitate reasoning about the trustworthiness of information contained in the knowledge plane while preserving confidentiality guarantees for operator data. By characterizing information disclosure between operators, NetQuery enables remote verification of advertised claims and contractual stipulations; this enables new applications because network guarantees can span administrative boundaries. We have implemented NetQuery, built several NetQuery-enabled devices, and deployed applications for cloud datacenters, enterprise networks, and the Internet. Simulations, testbed experiments, and a deployment on a departmental network indicate NetQuery can support hundreds of <b>thousands</b> of <b>operations</b> <b>per</b> <b>second</b> and can thus scale to large ISPs...|$|R
40|$|The {{article of}} record as {{published}} may be located at [URL] advances in high-performance computing have pushed computational capabilities to a petaflop (a <b>thousand</b> trillion <b>operations</b> <b>per</b> <b>second)</b> {{in a single}} computing cluster. This breakthrough has been hailed {{as a way to}} fundamentally change science and engineering by letting people perform experiments that were previously beyond reach. But for those interested in exploring the I/O behavior of their simulation model, efficient experimental design has a much higher payoff at a much lower cost. A well-designed experiment allows the analyst to examine many more factors than would otherwise be possible, while providing insights that cannot be gleaned from trial-and-error approaches or by sampling factors one at a time. We present the basic concepts of experimental design, the types of goals it can address, and why it is such an important and useful tool for simulation. Ideally, this tutorial will entice you to use experimental designs in your upcoming simulation studies...|$|R
40|$|As {{organizations}} {{become increasingly}} reliant on cloud com-puting for servicing their data storage requirements, {{the need to}} govern access control at finer granularities becomes particularly important. This challenge is increased {{by the lack of}} policy supporting data migration across geographic boundaries and through organizations with divergent regu-latory policies. In this paper, we present an architecture for secure and distributed management of provenance, enabling its use in security-critical applications. Provenance, a meta-data history detailing the derivation of an object, contains information that allows for expressive, policy-independent access control decisions. We consider how to manage and validate the metadata of a provenance-aware cloud system, and introduce protocols that allow for secure transfer of provenance metadata between end hosts and cloud authori-ties. Using these protocols, we develop a provenance-based access control mechanism for Cumulus cloud storage, capa-ble of processing <b>thousands</b> of <b>operations</b> <b>per</b> <b>second</b> on a single deployment. Through the introduction of replicated components, we achieve overhead costs of just 14 %, demon-strating that provenance-based access control is a practical and scalable solution for the cloud...|$|R
40|$|SEED Center PaperRecent {{advances}} in high-performance computing have pushed computational capabilities to a petaflop (a <b>thousand</b> trillion <b>operations</b> <b>per</b> <b>second)</b> {{in a single}} computing cluster. This breakthrough has been hailed {{as a way to}} fundamentally change science and engineering by letting people perform experiments that were previously beyond reach. But for those interested in exploring the I/O behavior of their simulation model, efficient experimental design has a much higher payoff at a much lower cost. A well-designed experiment allows the analyst to examine many more factors than would otherwise be possible, while providing insights that cannot be gleaned from trial-and-error approaches or by sampling factors one at a time. We present the basic concepts of experimental design, the types of goals it can address, and why it is such an important and useful tool for simulation. Ideally, this tutorial will entice you to use experimental designs in your upcoming simulation studies. This work {{was supported in part by}} the U. S. Army Training and Doctrine Command Analysis Center Monterey (TRACMTRY), the Department of Defense’s Modeling & Simulation Coordination Office (M&SCO), and the Netcentric Systems Test Science & Technology focus area (NST S&T). Portions of this tutorial appeared earlier in Sanchez (2008 a, 2008 b). Thanks to David Kelton and Paul Sanchez for helpful comments...|$|R
40|$|Data {{management}} systems {{have traditionally been}} designed to support either long-running analytics queries or short-lived transactions, but {{an increasing number of}} applications need both. For example, online games, socio-mobile apps, and e-commerce sites need to not only maintain operational state, but also analyze that data quickly to make predictions and recommendations that improve user experience. In this paper, we present Minuet, a distributed, main-memory B-tree that supports both transactions and copy-on-write snapshots for in-situ analytics. Minuet uses main-memory storage to enable low-latency transactional operations as well as analytics queries without compromising transaction performance. In addition to supporting read-only analytics queries on snapshots, Minuet supports writable clones, so that users can create branching versions of the data. This feature can be quite useful, e. g. to support complex "what-if" analysis or to facilitate wide-area replication. Our experiments show that Minuet outperforms a commercial main-memory database in many ways. It scales to hundreds of cores and TBs of memory, and can process hundreds of <b>thousands</b> of B-tree <b>operations</b> <b>per</b> <b>second</b> while executing long-running scans. Comment: VLDB 201...|$|R
40|$|Large-scale {{information}} processing often relies on subset matching for data classification and routing. Examples are publish/subscribe and stream processing systems, database systems, social media, and information-centric networking. For instance, an advanced Twitter-like messaging service where users might follow specific publishers {{as well as}} specific topics encoded as tag sets must join a stream of published messages with the users and their preferred tag sets so that the user tag set is {{a subset of the}} message tags. Subset matching is an old but also notoriously difficult problem. We present TagMatch, a system that solves this problem by taking advantage of a hybrid CPU/GPU stream processing architecture. TagMatch targets large-scale applications with <b>thousands</b> of matching <b>operations</b> <b>per</b> <b>seconds</b> against hundreds of millions of tag sets. We evaluate Tag- Match on an advanced message streaming application, with very positive results both in absolute terms and in comparison with existing systems. As a notable example, our experiments demonstrate that TagMatch running on a single, commodity machine with two GPUs can easily sustain the traffic throughput of Twitter even augmented with expressive tag-based selection...|$|R
40|$|Abstract. The {{last decade}} has seen {{rapid growth of}} single-chip multi-processors (CMPs), which have been {{leveraging}} Moore’s law to deliver high concurrency via increases {{in the number of}} cores and vector width. Modern CMPs execute from several hundreds to several <b>thousands</b> con-current <b>operations</b> <b>per</b> <b>second,</b> while their memory subsystem delivers from tens to hundreds Giga-bytes <b>per</b> <b>second</b> bandwidth. Taking advantage of these parallel resources requires highly tuned paral-lel implementations of key computational kernels, which form the back-bone of modern HPC. Sparse triangular solver is one such kernel and is the focus of this paper. It is widely used in several types of sparse lin-ear solvers, and it is commonly considered challenging to parallelize and scale even on a moderate number of cores. This challenge {{is due to the fact}} that triangular solver typically has limited task-level parallelism and relies on fine-grain synchronization to exploit this parallelism, compared to data-parallel operations such as sparse matrix-vector multiplication. This paper presents synchronization sparsification technique that sig-nificantly reduces the overhead of synchronization in sparse triangular solver and improves its scalability. We discover that a majority of task dependencies are redundant in task dependency graphs which are used to model the flow of computation in sparse triangular solver. We propose a fast and approximate sparsification algorithm, which eliminates more than 90 % of these dependencies, substantially reducing synchronization overhead. As a result, on a 12 -core IntelR © XeonR © processor, our approach improves the performance of sparse triangular solver by 1. 6 x, compared to the conventional level-scheduling with barrier synchronization. This, in turn, leads to a 1. 4 x speedup in a pre-conditioned conjugate gradient solver...|$|R
40|$|Approved {{for public}} display, {{distribution}} unlimitedSUSAN M. SANCHEZ is a Professor in Operations Research at the Naval Postgraduate School, and Co-Director of the Simulation Experiments & Efficient Design (SEED) Center for Data Farming. She also holds a joint appointment in the Graduate School of Business & Public Policy. She has a B. S. in Industrial & Operations Engineering from the University of Michigan, and a Ph. D. in Operations Research from Cornell. She {{has been active}} in various service capacities within the simulation community over many years, and is currently on the WSC Board of Directors. Her web page is and her email is. HONG WAN is an Assistant Professor in the School of Industrial Engineering at Purdue University. She is currently visiting the department of Operations Research at Naval Postgraduate School. Her research interests include design and analysis of simulation experiments, simulation optimization, applied statistics, quality management, and healthcare engineering. She has taught a variety of courses {{and is a member of}} INFORMS and ASA. Her email address is and her web page is. Recent advances in high-performance computing have pushed computational capabilities to a petaflop (a <b>thousand</b> trillion <b>operations</b> <b>per</b> <b>second)</b> in a single computing cluster. This breakthrough has been hailed as a way to fundamentally change science and engineering by letting people perform experiments that were previously beyond reach. But for those interested in exploring the I/O behavior of their simulation model, efficient experimental design has a much higher payoff at a much lower cost. A well-designed experiment allows the analyst to examine many more factors than would otherwise be possible, while providing insights that cannot be gleaned from trial-and-error approaches or by sampling factors one at a time. We present the basic concepts of experimental design, the types of goals it can address, and why it is such an important and useful tool for simulation. Ideally, this tutorial will entice you to use experimental designs in your upcoming simulation studies...|$|R
40|$|University of Minnesota M. S. thesis. March 2011. Major: Electrical Engineering. Advisor: David Lilja. 1 {{computer}} file (PDF); viii, 44 pages, appendix A. Solid state storage devices have become {{widely available in}} recent years, and can replace disk drives in many applications. While their performance continues to rise quickly, prices of the NAND flash devices used to build them continue to fall. Flash-based SSDs have been proposed for use in computing environments from high-performance server systems to lightweight laptops. High-performance SSDs can perform hundreds of <b>thousands</b> of I/O <b>operations</b> <b>per</b> <b>second.</b> To achieve this performance, drives make use of parallelism and complex flash management techniques to overcome flash device limitations. These characteristics cause SSD performance to depart significantly from that of disk drives under some workloads. This leads to opportunities and pitfalls both in performance and in benchmarking. In this paper we discuss {{the ways in which}} high-performance SSDs are different from consumer SSDs and from disk drives, and we set out guidelines for measuring their performance based on worst-case workloads. We use these measurements to evaluate improvements to Linux I/O driver architecture for a prototype high-performance SSD. We demonstrate potential performance improvements in I/O stack architecture and device interrupt handling, and discuss the impact on other areas of Linux system design. As a result of these improvements we are able to reach a significant milestone for single drive performance: over one million random read IOPS with throughput of 1. 4 GBps...|$|R
2500|$|An {{independent}} {{third-party software}} developer utilised the Python bindings to LMDB in a high-performance environment and published, on the prominent technical news site Slashdot, {{how the system}} managed to successfully sustain 200,000 simultaneous read, write and delete <b>operations</b> <b>per</b> <b>second</b> (a total of 600,000 database <b>operations</b> <b>per</b> <b>second)</b> ...|$|R
30|$|Flops is {{an acronym}} for floating-point <b>operations</b> <b>per</b> <b>second.</b>|$|R
50|$|ODRA-1002 {{were capable}} of only 100-400 <b>operations</b> <b>per</b> <b>second.</b>|$|R
5000|$|Performance: 125 MIPS (million {{instructions}} <b>per</b> <b>second),</b> 93.75 MFLOPS (million floating-point <b>operations</b> <b>per</b> <b>second).</b>|$|R
50|$|EDVAC's average {{addition}} time was 864 microseconds (about 1,160 <b>operations</b> <b>per</b> <b>second)</b> and its average multiplication time was 2,900 microseconds (about 340 <b>operations</b> <b>per</b> <b>second).</b> Time for an operation depended on memory access time, which varied {{depending on the}} memory address and the current point in the serial memory's recirculation cycle.|$|R
5000|$|... performance: 200-300 {{arithmetic}} <b>operations</b> <b>per</b> <b>second</b> on 5 digit numbers ...|$|R
50|$|This record means a {{calculation}} speed of about 5 <b>operations</b> <b>per</b> <b>second.</b>|$|R
5000|$|Floating point: 6.2 billion single {{precision}} (32-bit) floating point <b>operations</b> <b>per</b> <b>second</b> ...|$|R
50|$|Weighted million <b>operations</b> <b>per</b> <b>second</b> (WMOPS) is {{a similar}} measurement, used for audio codecs.|$|R
5000|$|... a {{high-performance}} computer system with peak computing speeds of 150 billion <b>operations</b> <b>per</b> <b>second.</b>|$|R
25|$|On August 29, 2007, IBM {{announced}} the BladeCenter QS21. Generating a measured 1.05 giga–floating point <b>operations</b> <b>per</b> <b>second</b> (gigaFLOPS) <b>per</b> watt, with peak performance of approximately 460GFLOPS {{it is one}} of the most power efficient computing platforms to date. A single BladeCenter chassis can achieve 6.4 tera–floating point <b>operations</b> <b>per</b> <b>second</b> (teraFLOPS) and over 25.8 teraFLOPS in a standard 42U rack.|$|R
2500|$|The work [...] {{denotes the}} number of {{operations}} performed by a given kernel or application. This metric may refer to any type of operation, from number of array points updated <b>per</b> <b>second,</b> to number of integer <b>operations</b> <b>per</b> <b>second,</b> to number of floating point <b>operations</b> <b>per</b> <b>second</b> (FLOPS), and the choice of one or another is driven by convenience. In {{the majority of the}} cases however, [...] is expressed as FLOPS.|$|R
50|$|Note: GMACS {{stands for}} Giga (billions of) Multiply-Accumulate <b>operations</b> <b>per</b> <b>Second,</b> a common measure of DSPperformance.|$|R
30|$|For each test-case, through trial-and-error, we {{determined}} {{that the value of}} approximately 6000 <b>operations</b> <b>per</b> <b>second</b> is the maximum throughput that remained stable during the one hour period. Our systems is capable of serving much larger numbers than this (i.e. up to 100, 000 <b>operations</b> <b>per</b> <b>second),</b> but only in “short bursts,” after which the backend datastore needed some time to manage all the write operations.|$|R
50|$|The metric was {{introduced}} in April 2006 to replace the Composite Theoretical Performance (CTP) metric which {{was introduced}} in 1993. APP was itself replaced in November 2007 when the BIS amended 15 CFR to include the December 2006 Wassenaar Arrangement Plenary Agreement Implementation's new metric - Gigaflops (GFLOPS), one billion floating point <b>operations</b> <b>per</b> <b>second,</b> or TeraFLOPS, one trillion floating point <b>operations</b> <b>per</b> <b>second.</b>|$|R
30|$|Maximum {{number of}} file {{metadata}} <b>operations</b> <b>per</b> <b>second</b> (includes file creation, deletion or gathering of file information).|$|R
50|$|The peak {{performance}} of Brutus is slightly over 200 teraflops (200 &times; 1012 floating-point <b>operations</b> <b>per</b> <b>second).</b>|$|R
5000|$|FLOPS - The {{number of}} {{floating}} point <b>operations</b> <b>per</b> <b>second</b> is often important in selecting computers for scientific computations.|$|R
50|$|The Am2045 {{delivers}} 1 TeraOPS (<b>Operations</b> <b>Per</b> <b>Second)</b> and 50 Giga-MACs (Multply-Accumulates <b>per</b> <b>second)</b> of fixed-point processing with 6-12W {{of power}} consumed (dependent on the application).|$|R
