5|211|Public
50|$|HawkSat I is a single-unit CubeSat {{which was}} built and is being {{operated}} by the Hawk Institute for Space Sciences. It {{is based on a}} Pumpkin Incorporated CubeSat kit, and carries a technology demonstration payload, primarily as a proof-of-concept mission, <b>testing</b> <b>command,</b> data and power subsystems, as well as solar panels and communications.|$|E
50|$|By June 1917 the {{cumbersome}} {{tail unit}} {{had been replaced}} by a cleaner design with a single tailplane and finely formed fins and rudders mounted {{at the end of each}} boom. The new boom structure was much stronger and of simpler design. Evaluation by the SVK (Seeflugzeugs-Versuchs-Kommando - Seaplane <b>Testing</b> <b>Command),</b> was carried out from 23 to 26 June 1917 testing various engine off configurations and water-borne handling. Given a qualified clean bill of health, the Rs.II was prepared for a transit flight to Norderney on the North Sea coast to carry out seaworthiness trials.|$|E
50|$|According to the Army, the M4 only {{suffered}} 296 stoppages, {{and said}} that the high number reported could be attributed to discrepancies in the scoring process. The Army <b>testing</b> <b>command</b> stated that if the number of stoppages caused by a broken part met some threshold, they would be eliminated from the final report pending redesign of the part. Colt also claimed that the testing conditions were unfair to the M4, as the M4s used in the test were normal guns from active inventory, with remaining service life varying randomly. Further, the trial M4s had burst-mode fire groups, which are more complicated and prone to failure than the fully automatic fire groups the other manufacturers presented for testing.|$|E
5000|$|Marine Communication Facilities (German:Marinenachrichtenmittel) <b>test</b> <b>command.</b>|$|R
5000|$|... 1. To {{test whether}} a file is nonexistent or empty, type: if test ! -s [...] "$1" [...] then echo $1 {{does not exist}} or is empty. fiIf the file {{specified}} by the first positional parameter to the shell procedure, $1, does not exist or is of size 0, the <b>test</b> <b>command</b> displays the message. If $1 exists and has a size greater than 0, the <b>test</b> <b>command</b> displays nothing.|$|R
5000|$|The TEST {{frame is}} simply a ping command for {{debugging}} purposes. The payload of the <b>TEST</b> <b>command</b> is returned in the TEST response.|$|R
40|$|The {{overall goal}} of this {{contract}} is to provide virtually all individuals with a cervical level spinal cord injury, regardless of injury level and extent, {{with the opportunity to}} gain additional useful function through the use of FNS and complementary surgical techniques. Specifically, we will expand our applications to include individuals with high tetraplegia (C 1 -C 4), low tetraplegia (C 7), and incomplete injuries. We will also extend and enhance the performance provided to the existing C 5 -C 6 group by using improved electrode technology for some muscles and by combining several upper extremity functions into a single neuroprosthesis. The new technologies that we will develop and implement in this proposal are: the use of nerve cuffs for complete activation in high tetraplegia, the use of current steering in nerve cuffs, imaging-based assessment of maximum muscle forces, denervation, and volume activated by electrodes, multiple degree-of-freedom control, the use of dual implants, new neurotization surgeries for the reversal of denervation, new muscle transfer surgeries for high tetraplegia, and an improved forward dynamic model of the shoulder and elbow. During this contract period, all proposed neuroprostheses will come to fruition as clinically deployed and fully evaluated demonstrations. Summary of activities during this reporting period The following activities are described in this report: • Musculo-skeletal modelling of the shoulder and elbow • Development of a 3 D virtual reality environment for <b>testing</b> <b>command</b> source...|$|E
40|$|The {{purpose of}} {{multimedia}} devices development is controlling through voice. Nowdays voice {{that can be}} recognized only in English. To overcome the issue, then recognition using Indonesian language model and accousticc model and dictionary. Automatic Speech Recognizier is build using engine CMU Sphinx with modified english language to Indonesian Language database and XBMC used as the multimedia player. The experiment is using 10 volunteers testing items based on 7 commands. The volunteers is classifiedd by the genders, 5 Male & 5 female. 10 samples is taken in each command, continue with each volunteer perform 10 <b>testing</b> <b>command.</b> Each volunteer also have to try all 7 command that already provided. Based on percentage clarification table, the word “Kanan” had the most recognize with percentage 83 % while “pilih” is the lowest one. The word which had the most wrong clarification is “kembali” with percentagee 67 %, while the word “kanan” is the lowest one. From the result of Recognition Rate by male there are several command such as “Kembali”, “Utama”, “Atas “ and “Bawah” has the low Recognition Rate. Especially for “kembali” cannot be recognized as the command in the female voices but in male voice that command has 4 % of RR {{this is because the}} command doesn’t have similar word in english near to “kembali” so the system unrecognize the command. Also for the command “Pilih” using the female voice has 80 % of RR but for the male voice has only 4 % of RR. This problem is mostly because of the different voice characteristic between adult male and female which male has lower voice frequencies (from 85 to 180 Hz) than woman (165 to 255 Hz). The result of the experiment showed that each man had different number of recognition rate caused by the difference tone, pronunciation, and speed of speech. For further work {{needs to be done in}} order to improving the accouracy of the Indonesian Automatic Speech Recognition system. Keywords: Automatic Speech Recognizer, Indonesian Acoustic Model, CMU Sphinx, indonesian Language Model, Recognition Rate, XBMC...|$|E
30|$|In the {{analysis}} part, the gravity analysis {{is carried out}} using Newton algorithm. The algorithm solves the nonlinear equations {{and is able to}} be updated each iteration. Moreover, the Norm Displacement Increment <b>test</b> <b>command</b> was used to construct a Convergence <b>test</b> object. The <b>command</b> determines if convergence has been achieved {{at the end of an}} iteration step.|$|R
5000|$|The {{quotation}} marks around $1 {{ensure that the}} test works properly even if the value of $1 is a null string. If the {{quotation marks}} are omitted and $1 is the empty string, the <b>test</b> <b>command</b> displays the error message: ...|$|R
50|$|Jam: Event which <b>tests</b> {{speakers}} <b>command</b> {{on their}} language and grammatical accuracy.|$|R
40|$|Results of RF {{compatibility}} test between KOMPSAT(Korea Multi-Purpose SATellite) and TTC(Tracking, Telemetry, and Command) station are described. S/C(Spacecreft) RF Test, telemetry <b>test,</b> <b>command</b> <b>test,</b> ranging test, {{and tracking}} receiver test were performed {{with respect to}} pass/fail criteria. To provide physical RF interface between KOMPSAT and TTC equipment, direct low cable and antenna-to-antenna interface were implemented. Through RF compatibility test, it was fully demonstrated that KOMPSAT and TTC equipment are functionally workable...|$|R
40|$|AbstractA Smart Component {{is used in}} {{the setup}} of an expert Knowledge based Computer-aided Power fault {{detection}} system. The Smart Component will interpret <b>test</b> <b>commands</b> that a user will input into a database. When the fault detection workflow is finished, the complex task will be decomposed into several separate tasks. Professionals will then tackle these tasks. This will allow for division of labor, the testing system will be convenient and flexible, and a good result will be gotten in practice...|$|R
30|$|Testing {{is a part}} of {{the created}} application. Fig.  14 {{illustrates}} an example of testing application, where setting of number of repetitions and selection of the <b>tested</b> <b>command</b> can be seen. After the test is completed, a notification window is displayed with information about the particular test. Although the number of well recognized commands is one hundred of one hundred, the average recognition success rate is only 94.61  %. This is because the number of recognized words is a real value, while average recognition success rate represents a program-wise estimated recognition success rate. Ambient noise, which influences the very recognition, is a major factor that has a great influence on aver-age recognition success rate. 10 persons of different sex and age have participated in testing of this system. Both men and women in age range of 22 – 50  years. An integrated microphone, which {{is a part of}} a PC, and a wireless microphone (Logitech Wireless Headset H 600) have been used for testing. Every speaker tested a random voice command several times. Each of the ten speakers has <b>tested</b> the given <b>command,</b> in the first case (lights on) 100 times. In order to compare results of the individual speakers, testing was performed on the same command for each of them. The result is an average percentage success rate of the <b>tested</b> <b>command</b> and real recognition success rate of the success rate.|$|R
50|$|Naval {{stations}} {{were the highest}} land based commands of Imperial German naval authority. The Chief of the Naval Station was usually an admiral who commanded the military police in the port area and the fortifications of the port. He oversaw the operation of sailors and shipyard divisions, and the ship reserve divisions. In addition he had command of all warships in his zone {{that did not have}} permanent commanders, such as <b>test</b> <b>commands.</b> Administrative sections of the two naval {{stations were}} Garrison Station services and funds, building authorities, offices clothing, food, offices and laundries.|$|R
50|$|The United States Naval Academy (USNA) Small Satellite Program (SSP) {{was founded}} in 1999 to {{actively}} pursue flight opportunities for miniature satellites designed, constructed, <b>tested,</b> and <b>commanded</b> or controlled by midshipmen.|$|R
50|$|Consolidation of all Army {{developmental}} and operational <b>testing</b> <b>commands</b> {{was approved by}} the Vice Chief of Staff of the Army on Nov. 18, 1998. The decision led to the redesignation of the Operational Test and Evaluation Command to ATEC on Oct. 1, 1999. All major subordinate commands of OPTEC were redesignated as well with the Test and Evaluation command redesignated as the U.S. Army Developmental Test Command, Aberdeen Proving Ground; the Test and Experimentation Command was redesignated the U.S. Army Operational Test Command, Fort Hood, Texas; and the Operational Evaluation Command and the Evaluation Analysis Center were combined to form the new U.S. Army Evaluation Center located at Aberdeen Proving Ground.|$|R
40|$|Abstract. There {{continues}} to be a trend towards using the power of cloud computing to tackle inherently large and complicated problem domains. Validating domain-intensive cloud applications presents a significant challenge because of the complexity of both the problem domain and the underlying cloud platform. In this paper, we describe an approach that leverages model-driven engineering to improve testing domain-intensive cloud applications. Our approach combines a set of abstract <b>test</b> <b>commands</b> with various domain and configuration models to define a domain-specific testing language. We have developed a prototype of our approach that provides language editing and platform configuration tools to aid test specification, execution and debugging...|$|R
50|$|Re-activated as an Air Material <b>Command</b> <b>test</b> {{squadron}} at Eglin AFB, Florida in 1998.|$|R
50|$|Two test registers, TR6 and TR7, were {{provided}} {{for the purpose of}} testing. TR6 was the <b>test</b> <b>command</b> register, and TR7 was the test data register. These registers were accessed by variants of the MOV instruction. A test register may either be the source operand or the destination operand. The MOV instructions are defined in both real-address mode and protected mode. The test registers are privileged resources. In protected mode, the MOV instructions that access them can only be executed at privilege level 0. An attempt to read or write the test registers when executing at any other privilege level causes a general protection exception. Also, those instructions generate invalid opcode exception on any CPU newer than 80486.|$|R
50|$|Apollo 8 was {{a similar}} mission to EM-2 in 1968, {{in that it}} was crewed, and did not land on the Moon; crewed by 3 astronauts, {{designed}} to flight <b>test</b> a <b>Command</b> Service Module beyond low Earth orbit. It however did enter lunar orbit, for an extended stay.|$|R
40|$|This {{document}} {{defines a}} new <b>test</b> <b>command,</b> "duplicate", for the Sieve email filtering language. This test adds {{the ability to}} detect duplications. The main application for this new test is handling duplicate deliveries commonly caused by mailing list subscriptions or redirected mail addresses. The detection is normally performed by matching the message ID to an internal list of message IDs from previously delivered messages. For more complex applications, the "duplicate " test can also use the content of a specific header field or {{other parts of the}} message. Status of This Memo This is an Internet Standards Track document. This document {{is a product of the}} Internet Engineering Task Force (IETF). It represents the consensus of the IETF community. It has received public review and has been approved for publication by th...|$|R
50|$|In the Star Trek canon, the Kobayashi Maru {{simulation}} is {{a no-win}} scenario {{designed as a}} character <b>test</b> for <b>command</b> track cadets at Starfleet Academy. It first appears in the film Star Trek II: The Wrath of Khan. In the film, Admiral James T. Kirk states {{that he does not}} believe in the no-win scenario.|$|R
40|$|NASA has {{completed}} initial construction and verification {{testing of the}} Integrated Systems Test Facility (ISTF) Cryogenic Testbed. The ISTF is located at Complex 20 at Cape Canaveral Air Force Station, Florida. The remote and secure location is ideally suited for the following functions: (1) development testing of advanced cryogenic component technologies, (2) development testing of concepts and processes for entire ground support systems designed for servicing large launch vehicles, and (3) commercial sector testing of cryogenic- and energy-related products and systems. The ISTF Cryogenic Testbed consists of modular fluid distribution piping and storage tanks for liquid oxygen/nitrogen (56, 000 gal) and liquid hydrogen (66, 000 gal). Storage tanks for liquid methane (41, 000 gal) and Rocket Propellant 1 (37, 000 gal) are also specified for the facility. A state-of-the-art blast proof <b>test</b> <b>command</b> and control center provides capability for remote operation, video surveillance, and data recording for all test areas...|$|R
50|$|The <b>Command</b> <b>test</b> record (Stereo Check Out) was an LP album {{produced}} by Command Records in 1960. It contained recordings {{designed to allow}} users to test their stereo equipment.|$|R
2500|$|The Service School Command was {{organized}} to train selected personnel who had completed [...] "recruit" [...] basic training and demonstrated an aptitude for a skill during initial recruit <b>testing.</b> The <b>command</b> had {{a capacity of}} providing specialty training to 4,000 sailors at a time. These personnel were assigned to training in gunnery, fire control, radio, telemetry, and other technical subjects.|$|R
50|$|The United States Air Force's 505th Command and Control Wing is {{organized}} under the United States Air Force Warfare Center. The wing {{is dedicated to}} improving readiness through integrated training, tactics development and operational <b>testing</b> for <b>command</b> and control of air, space and cyberspace. It hosts the Air Force's only Air Operations Center Formal Training Unit at Hurlburt Field, Florida.|$|R
5000|$|The Service School Command was {{organized}} to train selected personnel who had completed [...] "recruit" [...] basic training and demonstrated an aptitude for a skill during initial recruit <b>testing.</b> The <b>command</b> had {{a capacity of}} providing specialty training to 4,000 sailors at a time. These personnel were assigned to training in gunnery, fire control, radio, telemetry, and other technical subjects.|$|R
2500|$|Combat Target was a March 1967 {{task force}} that {{recommended}} a Combat Skyspot site closer to Hanoi for more accurate bombing at night and during poor weather (endorsed by General Earle G. Wheeler on April 25, 1967.) [...] In April 1967, Reeves Instrument Corporation was contracted to modify the trailer-mobile ("M") AN/MSQ-77 design to a helicopter transportable ("T") version without trailer chassis/wheels and other mobility equipment. [...] The initial variant (AN/TSQ-81) was tested at Bryan Field, Texas, using bomb runs over Matagorda Island General Bombing and Gunnery Range and was emplaced for Combat Skyspot in Thailand. [...] After Bryan/Matagorda testing of the 2nd AN/TSQ-81, it was operational at LS-85 in late 1967, the period when the [...] "1st CEVG began “Combat Keel” tests using F-4s guided by an AN/MSQ-77 on the USS Thomas J. Gary in the Gulf of Tonkin to <b>test</b> <b>command</b> guidance by ships against northern targets [...] (Gary after beginning by August 9, departed by December 12.|$|R
40|$|Humans can {{understand}} and produce new utterances effortlessly, {{thanks to their}} systematic compositional skills. Once a person learns {{the meaning of a}} new verb "dax," he or she can immediately understand the meaning of "dax twice" or "sing and dax. " In this paper, we introduce the SCAN domain, consisting of a set of simple compositional navigation commands paired with the corresponding action sequences. We then test the zero-shot generalization capabilities of a variety of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence methods. We find that RNNs can generalize well when the differences between training and <b>test</b> <b>commands</b> are small, so that they can apply "mix-and-match" strategies to solve the task. However, when generalization requires systematic compositional skills (as in the "dax" example above), RNNs fail spectacularly. We conclude with a proof-of-concept experiment in neural machine translation, supporting the conjecture that lack of systematicity is an important factor explaining why neural networks need very large training sets...|$|R
40|$|This thesis {{presents}} {{a model for}} improving the Operations and Maintenance Navy budget execution function at Naval field activities ashore. The model utilizes five techniques to encourage five concepts shown to be critical for effective budget execution. Following {{a description of the}} current extent to which field activities implement these concepts, the model is presented within the framework of its development and pre- testing in academia. Development of questionnaires for testing the model at five Naval field activities in California and the test results are also presented. Over 60 cost center managers from five <b>test</b> <b>commands</b> responded to the questionnaires and rated the model as yielding potential benefits over their current procedures. The respondents rated the model as having "moderate" acceptability and "good" applicability. Based on the test results, widespread promulgation of the model is recommended within the U. S. Naval Shore establishment. [URL] Commander, Supply Corps, United States NavyLieutenant Commander, United States Nav...|$|R
5000|$|Combat Target was a March 1967 {{task force}} that {{recommended}} a Combat Skyspot site closer to Hanoi for more accurate bombing at night and during poor weather (endorsed by General Earle G. Wheeler on April 25, 1967.) In April 1967, Reeves Instrument Corporation was contracted to modify the trailer-mobile ("M") AN/MSQ-77 design to a helicopter transportable ("T") version without trailer chassis/wheels and other mobility equipment. The initial variant (AN/TSQ-81) was tested at Bryan Field, Texas, using bomb runs over Matagorda Island General Bombing and Gunnery Range and was emplaced for Combat Skyspot in Thailand. [...] After Bryan/Matagorda testing of the 2nd AN/TSQ-81, it was operational at LS-85 in late 1967, the period when the [...] "1st CEVG began “Combat Keel” tests using F-4s guided by an AN/MSQ-77 on the USS Thomas J. Gary in the Gulf of Tonkin to <b>test</b> <b>command</b> guidance by ships against northern targets [...] (Gary after beginning by August 9, departed by December 12.|$|R
2500|$|After Massie's initial {{recuperation}} {{he trained}} with the Machine Gun Corps at Grantham, passing the <b>tests</b> to <b>command</b> {{a machine gun}} battalion. [...] He {{was attached to the}} Australian Corps School on 12 September, appointed commandant on 24 September, and promoted to lieutenant colonel on 21 October. [...] He was demobilised on 16 August 1919. [...] His combined injuries meant he never played competitive cricket again.|$|R
40|$|The initial {{checkout}} of {{the control}} moment gyro system for the astronaut stabilizer maneuvering unit is described, and the test results are presented. The life test proceeded smoothly to its completion, and problem areas encountered in the engineering tests are described. These <b>tests</b> included <b>command</b> rate and torquer current transfer, cage and lock, static inverter and signal noise, dynamic response, closed loop drift rate, and gimbal disturbance torque evaluation tests...|$|R
30|$|The {{second group}} {{comprises}} approaches {{that give the}} developer awareness of concurrent changes, sometimes informing them if conflicts are likely to occur. This group includes tools such as Palantir (Sarma and van der Hoek 2002), CollabVS (Dewan and Hegde 2007), Crystal (Brun et al. 2011), Lighthouse (da Silva et al. 2006), FASTDash (Biehl et al. 2007), and WeCode (Guimarães and Silva 2012). Among these, only Crystal and FASTDash work with DVCSs. Crystal detects physical, syntactic, and semantic conflicts in Mercurial and Git repositories (provided that the user informs the compiling and <b>testing</b> <b>commands),</b> but does not precisely deal with repositories that pull updates {{from more than one}} peer. FASTDash does not detect conflicts directly, as the previously cited studies, but provides awareness of potential conflicts, such as two programmers editing the same region of the same source file in repositories stored in Microsoft Team Foundation Server. Although DyeVC primary focus is not to detect conflicts, it can be combined with such approaches to allow conflicts and metrics analysis over DVCS.|$|R
40|$|About 95 {{percent of}} faults detected. Programable {{instrument}} periodically checks for failures in system that generates alphanumerical and other symbol voltages for cathode-ray-tube displays. Symbol-generator tester compares gated test-point voltages with predetermined voltage limits while circuit under <b>test</b> performs <b>commanded</b> operation. A go/no-go indication given, {{depending on whether}} test voltage {{is or is not}} within its specification. Tester in plug-in modular form, temporarily wired to generator test points, or permanently wired to these points...|$|R
