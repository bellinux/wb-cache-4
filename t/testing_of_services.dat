12|10000|Public
5000|$|The Mu Service Analyzer is a {{commercial}} service testing tool developed by Mu Dynamics. The Mu Service Analyzer performs black box and white box <b>testing</b> <b>of</b> <b>services</b> {{based on their}} exposed software interfaces, using denial-of-service simulations, service-level traffic variations (to generate invalid inputs) and the replay of known vulnerability triggers. All these techniques exercise input validation and error handling and are {{used in conjunction with}} valid protocol monitors and SNMP to characterize the effects of the test traffic on the software system. The Mu Service Analyzer allows users to establish and track system-level reliability, availability and security metrics for any exposed protocol implementation. The tool has been available in the market since 2005 by customers in the North America, Asia and Europe, especially in the critical markets of network operators (and their vendors) and Industrial control systems (including Critical infrastructure).|$|E
40|$|Recently, {{a growing}} {{interest}} on robustness <b>testing</b> <b>of</b> <b>services</b> composition is emerging. In this paper, we propose a robustness testing approach of services composition {{by means of}} fault injection of the BPEL process. The proposed solution is implemented into the existing TASSA framework aimed at functional and non-functional testing of service applications. A case study is provided for assessing {{the effectiveness of the}} proposed approach...|$|E
30|$|The {{versatile}} tool {{presented and}} {{described in this}} work is a suitable and powerful platform for a broad variety of multidisciplinary studies ranging from specific low-level studies related to individual subcomponents of the network and its associated algorithms and protocols, to e 2 e <b>testing</b> <b>of</b> <b>services</b> and user applications at the application level. Several live demonstrations performed in international conferences have already demonstrated {{the applicability of the}} presented tool [28, 29]. The following lines provide some examples.|$|E
50|$|Rational Service Tester for SOA Quality is a {{tool for}} {{automated}} functional <b>testing</b> <b>of</b> web <b>services</b> and service-oriented architecture (SOA) software components from the Rational Software division of IBM. It is primarily used by Software Quality Assurance teams to perform automated regression <b>testing</b> <b>of</b> web <b>services.</b>|$|R
40|$|This project {{deals with}} <b>testing</b> <b>of</b> web <b>services.</b> The result <b>of</b> this {{work will be}} a tool for load <b>testing</b> <b>of</b> web <b>services</b> using fault {{injection}} in their communication. The {{first part of the}} project discusses the basic aspects <b>of</b> <b>testing</b> web <b>services.</b> The second part of the work is more focused on testing high loads in combination with fault injection. The tool will allow automated run <b>of</b> the <b>tests.</b> The distributed model of the tool was designed to simulate real loads. In the last chapter are summarized achieved results...|$|R
50|$|The first <b>tests</b> <b>of</b> HbbTV <b>services</b> in Poland {{were started}} by TVN in March 2012.|$|R
40|$|Engineering of service-oriented {{systems is}} still an {{immature}} discipline. Traditional software engineering approaches do not adequately fit development needs arising in this widely adopted paradigm. In particular, because of dynamic service composition, several engineering activities typically performed off-line (i. e., pre deployment) have to be carried on also on-line (i. e., during real usage). In this paper, we present a framework called (role) cast which supports an instantiation {{of the concept of}} on-line <b>testing</b> <b>of</b> <b>services,</b> for the purpose of validating their compliance to role-based service access policies...|$|E
40|$|Service-Oriented Architecture (SOA) {{has changed}} the way {{business}} enterprises get aligned with technology with a very fast pace keeping the demand of re-alignment time very short. <b>Testing</b> <b>of</b> <b>services</b> becomes equally important in SOA implementation {{in the context of}} enterprise architecture, business re-alignment and so on maintaining quality. Unit and integration testing though holds a key testing strategy but regression test becomes inevitable when services are orchestrated, choreographed and bound dynamically as per the change in requirement as well as when services are upgraded. In this paper a survey work has been done for regression testing method for SOA. Here the changed scenario of implementation of SOA enabled applications has been considered...|$|E
40|$|Although {{there are}} countless tools to track and manage the {{configuration}} {{of large numbers of}} Unix systems, {{there seems to be a}} lack of tools to manage the interaction and dependencies between systems. As our site has grown, many machines provide services that are required for the operation of other machines and applications. We have been unable to maintain accurate lists of services and servers, and even routine system upgrades have resulted in unexpected service outages. To address this problem, we are developing a system to automatically detect many of these service dependencies, and generate up to date server listings. In addition, it provides a general framework for indexing and accessing troubleshooting, operational, installation and a number of other types of documentation. The system also assists in verifying the configuration of systems being installed, and assists with the real time <b>testing</b> <b>of</b> <b>services.</b> Introduction As the number of Unix machines being supported gr [...] ...|$|E
50|$|After {{running a}} closed Alpha <b>test</b> <b>of</b> its <b>service,</b> JustShareIt {{launched}} {{to the public}} on January 5, 2012.|$|R
40|$|Software testers {{have great}} {{challenges}} in <b>testing</b> <b>of</b> web <b>services</b> therefore <b>testing</b> technique {{must be developed}} for <b>testing</b> <b>of</b> web <b>services.</b> Web service composition is an active research area over last few years. This paper proposes a framework for <b>testing</b> <b>of</b> fault tolerant composition <b>of</b> web <b>services.</b> It will tolerate faults while composition <b>of</b> web <b>services.</b> Exception handling and transaction techniques are used as fault handling mechanisms. After composition web services are deployed on WS-BPEL engine. Testing Framework will fetch results <b>of</b> composite web <b>service</b> from WS-BPEL engine and check whether composed web service is fault tolerant {{and it is in}} the consistent state...|$|R
40|$|Reducing {{the effort}} {{required}} {{to make changes in}} web <b>services</b> is one <b>of</b> the primary goals in web service projects maintenance and evolution. Normally, functional and non-functional <b>testing</b> <b>of</b> a web <b>service</b> is performed by testing the operations specified in its WSDL. The regression testing is performed by identifying the changes made thereafter to the web service code and the WSDL. In this thesis, we present a tool-supported approach to perform efficient regression <b>testing</b> <b>of</b> web <b>services.</b> By representing a web service as a directed graph of WSDL elements, we identify and gathers the changed portions of the graph and use this information to reduce regression testing efforts. Specifically, we identify, categorize, and capture the web service testing needs in two different ways, namely, Operationalized Regression <b>Testing</b> <b>of</b> Web <b>Service</b> (ORTWS) and Parameterized Regression <b>Testing</b> <b>of</b> Web <b>Service</b> (PRTWS). Both <b>of</b> the approach can be combined to reduce the regression testing efforts in the web service project. The proposed approach is prototyped as a tool, named as Automatic Web Service Change Management (AWSCM), which helps in selecting the relevant test cases to construct reduced test suite from the old test suite. We present few case studies on different web service projects to demonstrate the applicability of the proposed tool. The reduction in the effort for regression <b>testing</b> <b>of</b> web <b>service</b> is also estimated. Comment: Master of Technology Thesis, PDPM Indian Institute of Information Technology, Design and Manufacturing Jabalpur (2014...|$|R
40|$|Abstract—Speed {{and size}} are two {{important}} factors while designing the electronic system. It’s Speed of operation and flexibility to modify, measures {{the performance of}} the system operation. Microprocessor/microcontroller (MPMC) system can handle sequential operations with high flexibility and use of Complex Programmable Devices (CPLD) can handle concurrent operations with high speed in small size area. So combined features of both these systems can enhance {{the performance of the}} system. High performance Hybrid Telephone Switching System (HTSS) is designed using combination of stored program control (SPC) and VLSI technology. Call handling operations are handled by concurrent operations using CPLD and complicated sequential operations like service handling are handled by MPMC. VHDL codes are designed and tested for different call handling operations. The test benches are designed to act as MPMC for the <b>testing</b> <b>of</b> <b>services</b> like Do Not Disturb (DND), Call Forwarding (CF), Outgoing Bar (OGB) and STD Bar (STDB) facilities. Call handling speed of available system designed with MPMC and proposed system designed with CPLD is compared...|$|E
40|$|We {{present a}} {{description}} of the development and deployment infrastructure being created to support the integration effort of HARNESS, an EU FP 7 project. HARNESS is a multi-partner research project intended to bring the power of heterogeneous resources to the cloud. It consists of a number of different services and technologies that interact with the OpenStack cloud computing platform at various levels. Many of these components are being developed independently by different teams at different locations across Europe, and keeping the work fully integrated is a challenge. We use a combination of Vagrant based virtual machines, Docker containers, and Ansible playbooks to provide a consistent and up-to-date environment to each developer. The same playbooks used to configure local virtual machines are also used to manage a static testbed with heterogeneous compute and storage devices, and to automate ephemeral larger-scale deployments to Grid 5000. Access to internal projects is managed by GitLab, and automated <b>testing</b> <b>of</b> <b>services</b> within Docker-based environments and integrated deployments within virtual-machines is provided by Buildbot...|$|E
40|$|To date {{implementations}} of Internet of Things (IoT) architectures are {{confined to}} particular application areas and tailored to meet only the limited requirements of their narrow applications. To overcome technology and sector boundaries this paper proposes a dynamic service creation environment that employs i) orchestration of business services based on re-usable IoT service components, ii) self-management capable components for automated configuration and <b>testing</b> <b>of</b> <b>services</b> for things, and iii) abstraction of the heterogeneity of underlying technologies to ensure interoperability. To ensure reliability and robustness the presented approach integrates self-testing and self-adaptation in all service life cycle phases. The service life cycle management distinguishes the IoT service creation phase (design-time) and the IoT service provision phase (run-time). For test-friendly service creation (1) semantic service descriptions are employed to derive semi-automatically services and related tests, (2) and testing is systematically integrated into a Service Creation Environment. For reliable and robust service provisioning the presented system (3) forces validation tests in a sandbox environment before deployment and (4) enables run-time monitoring for service adaptation. The system under test is modelled by finite state machines (FSM) that are semi-automatically composed of re-usable test components. Then path searching algorithms are applied to derive automatically tests from the FSM model. The resulting tests are specified in the test control notation TTCN- 3 and compiled to run the validation tests. © 2012 IIMC Ltd...|$|E
40|$|To assure new {{services}} attain {{a certain level}} <b>of</b> quality, <b>services</b> should be developed and tested systematically like products or software. In practice, this is rarely the case, {{especially in regards to}} the <b>testing</b> <b>of</b> <b>service</b> concepts due to appropriate solutions, processes, and methodology seem to be missing. In this paper, the authors propose an approach to how service testing can be realized in practice and present supporting processes, methods, and technologies for testing services in laboratory environments...|$|R
5000|$|JBossWS Tools. Inspecting, invoking, {{developing}} and functional/load/compliance <b>testing</b> <b>of</b> web <b>services</b> over HTTP, base tooling provided by soapUI {{with the addition}} of JBossWS specific features/support.|$|R
40|$|The aim of {{research}} is to determine modern approaches to the physical fitness <b>testing</b> <b>of</b> <b>service</b> personnel. In the army with modern military experience, marked by a tendency to view the content <b>of</b> <b>tests</b> to determine the level of physical fitness of military personnel. Observed differentiation <b>of</b> unified systems <b>tests</b> to determine the general physical and military training military application. Summary <b>of</b> <b>tests</b> determined the nature of loads and motions of the structure inherent in the military during combat operations...|$|R
40|$|Testing {{and demonstrating}} context aware {{services}} {{can be extremely}} difficult Context-aware services inherently need information such as the position oftheir users, but it is complicated to gather and supply services with information of that kind. Obviously, one needs to do this when the services are up and running, but it may help to simulate the context information while the services are under development or for demonstration purposes. Even though the simulated context information is not real, the services and the routines that gather and receive the context information can be. This enables systems to be developed with less regard for constraints that stem from using actual sensor technology while also keeping the core functionality of services separate and ready for real-world deployment. One can image two types of simulation tools: those that simulate a set of values {{as a part of}} a test suite, and those that allow interactive <b>testing</b> <b>of</b> <b>services</b> in semirealistic circumstances. We have chosen the latter approach because it has the added advantage of allowing us to demonstrate services. QuakeSim is a tool that interactively simulates context information in real time. It simulates the real 3 D world and different kinds of context information. With QuakeSim, it is possible to test and demonstrate context-aware services without requiring users or objects to actually be located in and move around in the real world...|$|E
40|$|This {{document}} {{is the second}} deliverable of PLASTIC Work Package 4 (WP 4) : Service Validation Methodology and Tools. It provides guidelines for installing and using the tools {{that have been developed}} within the work package. The first deliverable released by the work package complements this deliverable providing a more detailed view on the proposed PLASTIC validation framework. As described in the Deliverable 4. 1, the framework is organised around two main phases, respectively called off-line and on-line, which correspond to two consecutive phases in the service lifecycle. The first phase, referred as off-line validation, concerns validation at development time. In this phase services are tested in a fake/simulated environment that reproduces functional and/or non-functional run-time conditions. The second phase of the validation framework is referred as on-line validation. This phase foresees testing of a service when it is ready for deployment and final usage. Two main stages have been identified within the on-line phase. The first stage is called admission and concerns <b>testing</b> <b>of</b> <b>services</b> when they ask to be included in a registry. Following the admission testing idea registration will be granted only to services that pass the testing phase. The last stage of the framework, part of the on-line phase, is the validation during the Live Usage stage. In this stage service behaviours are observed during real execution to reveal possible deviation from the expected behaviour. Also in this case validation can cover both functional and non-functional properties...|$|E
40|$|Laufzeitüberwachung (engl. runtime monitoring) ist eine wichtige Qualitätssicherungs-Technik für selbst{{adaptive}} Service-Komposition. Laufzeitüberwachung überwacht den Betrieb der Service-Komposition. Zur Bestimmung der Genauigkeit von Software-Tests werden häufig Überdeckungskriterien verwendet. Überdeckungskriterien definieren Anforderungen die Software-Tests erfüllen muss. Wegen ihrer wichtigen Rolle im Software-Testen haben Forscher Überdeckungskriterien an die Laufzeitüberwachung von Service-Komposition angepasst. Die passive Art der Laufzeitüberwachung und die adaptive Art der Service-Komposition können die Genauigkeit von Software-Tests zur Laufzeit negativ beeinflussen. Dies kann jedoch die Zuversicht in der Qualität der Service-Komposition begrenzen. Um die Überdeckung selbstadaptiver Service-Komposition zur Laufzeit zu verbessern, untersucht diese Arbeit, wie die Laufzeitüberwachung und Online-Testen kombiniert werden können. Online-Testen bedeutet dass Testen parallel zu der Verwendung einer Service-Komposition erfolgt. Zunächst stellen wir einen Ansatz vor, um gültige Execution-Traces für Service-Komposition zur Laufzeit zu bestimmen. Der Ansatz berücksichtigt die Execution-Traces von Laufzeitüberwachung und (Online) -Testen. Er berücksichtigt Änderungen im Workflow und Software-Services eines Service-Komposition. Zweitens, definieren wir Überdeckungskriterien für Service-Komposition. Die Überdeckungskriterien berücksichtigen Ausführungspläne einer Service-Komposition und berücksichtigen die Überdeckung für Software-Services und die Service-Komposition. Drittens stellen wir Online-Testfälle Priorisierungs Techniken, um die Abdeckungniveau einer Service-Komposition schneller zu erreichen. Die Techniken berücksichtigen die Überdeckung einer Service-Komposition durch beide Laufzeitüberwachung und Online-Tests. Zusätzlich, berücksichtigen sie die Ausführungszeit von Testfällen und das Nutzungsmodell der Service-Komposition. Viertens stellen wir einen Rahmen für die Laufzeitüberwachung und Online-Testen von Software-Services und Service-Komposition, genannt PROSA, vor. PROSA bietet technische Unterstützung für die oben genannten Beiträge. Wir evaluieren die Beiträge anhand einer beispielhaften Service-Komposition, die häufig in dem Forschungsgebiet Service-oriented Computing eingesetzt wird. Runtime monitoring (or monitoring for short) {{is a key}} {{quality assurance}} technique for self-adaptive service compositions. Monitoring passively observes the runtime behaviour of service compositions. Coverage criteria are extensively used for assessing the adequacy (or thoroughness) of software testing. Coverage criteria specify certain requirements on software testing. The importance of coverage criteria in software testing has motivated researchers to adapt them to the monitoring of service composition. However, the passive nature of monitoring and the adaptive nature of service composition could negatively inﬂuence the adequacy of monitoring, thereby limiting the conﬁdence {{in the quality of}} the service composition. To enhance coverage adequacy of self-adaptive service compositions at runtime, this thesis investigates how to combine runtime monitoring and online testing. Online testing means testing a service composition in parallel to its actual usage and operation. First, we introduce an approach for determining valid execution traces for service compositions at runtime. The approach considers execution traces of both monitoring and (online) testing. It considers modiﬁcations in both workﬂow and constituent services of a service composition. Second, we deﬁne coverage criteria for service compositions. The criteria consider execution plans of a service composition for coverage assessment and consider the coverage of an abstract service and the overall service composition. Third, we introduce online-test-case prioritization techniques to achieve a faster coverage of a service composition. The techniques employ coverage of a service composition from both monitoring and online testing, execution time of test cases, and the usage model of the service composition. Fourth, we introduce a framework for monitoring and online <b>testing</b> <b>of</b> <b>services</b> and service compositions called PROSA. PROSA provides technical support for the aforementioned contributions. We evaluate the contributions of this thesis using service compositions frequently used in service-oriented computing research...|$|E
40|$|Shandong Automat Assoc, Qingdao Technol Univ, Comp Engn Inst, Trent UnivBased on OSI and ODP {{conformance}} testing theory, combining Web Services specifications and the characteristics <b>of</b> E-government, the <b>testing</b> reference model, testing configure and <b>testing</b> process <b>of</b> Web <b>Services</b> solution for E-government {{conformance testing}} is analyzed. The <b>test</b> method <b>of</b> Web <b>Services</b> solution for E-government is proposed, Based on this method, conformance <b>test</b> items <b>of</b> Web <b>Services</b> solution for E-government is studied, thus test items provide test guidelines for performance testing, function testing, interoperation testing, compatibility testing, security testing etc...|$|R
40|$|This article {{presents}} a literature overview about natural durability, service life and {{factors that influence}} them. Further variability of wood resistance in tree and between individual trees is presented. Natural durability of wood together with service conditions and mode of use influence the service life, which {{is more important than}} just natural durability. Therefore the <b>tests</b> <b>of</b> <b>service</b> life and natural durability, respectively, along with problems with wood sorting in durability classes are introduced in the end of article...|$|R
50|$|<b>Testing</b> <b>of</b> the European <b>Service</b> Module {{began in}} February 2016, at the Space Power Facility.|$|R
30|$|An online tool (wsrbench) that {{implements}} {{the robustness}} testing approach proposed for Web services robustness testing This tool fills {{a gap in}} current development tools, providing an easy interface for robustness <b>testing</b> <b>of</b> Web <b>services.</b>|$|R
5000|$|... 4 June {{launched}} the first <b>test</b> version <b>of</b> the <b>service</b> Videoavatarki [...] (paid service) ...|$|R
2500|$|... (AFHSC), a {{subordinate}} of the United States Army Center for Health Promotion and Preventive Medicine (USACHPPM), itself {{evolved from the}} [...] Johns Hopkins School of Hygiene and Public Health. The DoDSR traces its origins to 1985 and {{the beginnings of the}} United States Armed Forces HIV screening program (originally referred to as the HTLV-III screening program), when serum remaining after periodic laboratory <b>testing</b> <b>of</b> <b>service</b> members was retained first by the Walter Reed Army Institute of Research (WRAIR), then later systematically archived in the Army/Navy Serum Repository, the precursor to the DoDSR.|$|R
40|$|International audienceThis paper {{presents}} the automation <b>of</b> the functional <b>test</b> <b>of</b> <b>services</b> (black-box <b>testing)</b> and services architectures (grey-box testing) {{that has been}} developed by the MIDAS project and is accessible on the MIDAS SaaS. In particular, the paper illustrates the solutions <b>of</b> tough functional <b>test</b> automation problems such as: (i) the configuration <b>of</b> the automated <b>test</b> execution system against large and complex services architectures, (ii) the constraint-based test input generation, (iii) the specification-based test oracle generation, (iv) the intelligent dynamic scheduling <b>of</b> <b>test</b> cases, (v) the intelligent reactive planning <b>of</b> <b>test</b> campaigns. The paper describes the usage of the MIDAS prototype for the functional <b>test</b> <b>of</b> an operational distributed application {{in the domain of}} healthcare...|$|R
40|$|Abstract—Whitening the <b>testing</b> <b>of</b> service-oriented {{applications}} {{can provide}} service consumers confidence {{on how well}} an application has been tested. However, to protect business interests <b>of</b> <b>service</b> providers and to prevent information leakage, the implementation details <b>of</b> <b>services</b> are usually invisible to service consumers. This makes it challenging to determine the <b>test</b> coverage <b>of</b> a <b>service</b> composition {{as a whole and}} design test cases effectively. To address this problem, we propose an approach to whiten the <b>testing</b> <b>of</b> <b>service</b> compositions based on events exposed by services. By deriving event interfaces to explore only necessary test coverage information from service implementations, our approach allows service consumers to determine test coverage based on selected events exposed by services at runtime without releasing the service implementation details. We also develop an approach to design test cases effectively based on event interfaces concerning both effectiveness and information leakage. The experimental results show that our approach outperforms existing testing approaches for service compositions with up to 49 percent more test coverage and an up to 24 percent higher fault-detection rate. Moreover, our solution can trade off effectiveness, efficiency, and information leakage for test case generation. Index Terms—Web service composition, white-box testing, event interface, events Ç...|$|R
40|$|Abstract This paper {{presents}} a formal approach to conformance <b>testing</b> <b>of</b> CORBAbased distributed <b>services</b> using TTCN framework. It discusses mapping of CORBA IDL to TTCN, {{concentrating on the}} obstacles and the design issues to be considered. The paper overviews {{the architecture of the}} CORBA/TTCN gateway, which acts as an intermediary between test environment and system under test (SUT). It goes through an example <b>of</b> <b>test</b> session and distinguishes the typical stages of dynamic behaviour. The results of the study indicate that TTCN framework especially facilitates <b>testing</b> <b>of</b> active <b>service</b> components, although conformance <b>testing</b> <b>of</b> reactive parts is also possible...|$|R
5000|$|... {{document}} {{service contracts}} included using a service description language for better understanding and <b>testing</b> <b>of</b> the Keyword <b>Service</b> Provider.|$|R
40|$|Designing {{usability}} lab <b>tests</b> <b>of</b> instant-messaging <b>services,</b> whether {{conducted on}} a hand-held device or a computer, presents unique {{challenges for the}} testing team. This presentation describes three instant-messaging studies and the technology and techniques used to instill realism and maintain rigor...|$|R
40|$|The {{control is}} one of the factors that can {{contribute}} to the success of any organization. In this paper, research {{for one of the most}} important control types is presented: the management and evaluation of the local public policies. The research determines citizen satisfaction with local <b>services</b> <b>of</b> a public organization; and, also the criteria, analysis and prescriptions of a different group of experts. Application of this research to a significantly sized municipal results in a descriptive, explicative and prescriptive model system being offered that will greatly assist those responsible at the moment in which they formulate or reformulate performance level <b>tests</b> <b>of</b> <b>services,</b> social events, programs and policies. ...|$|R
40|$|Specification-based {{regression}} <b>testing</b> <b>of</b> web <b>services</b> is {{an important}} activity which verifies the quality <b>of</b> web <b>services.</b> A major problem in web services is that only provider has the source code and both user and broker only have the XML based specification. So {{from the perspective of}} user and broker, specification based regression <b>testing</b> <b>of</b> web <b>services</b> is needed. The existing techniques are code based. Due to the dynamic behavior <b>of</b> web <b>services,</b> web services undergo maintenance and evolution process rapidly. Retesting <b>of</b> web <b>services</b> is required in order to verify the impact of changes. In this paper, we present an automated safe specification based regression testing approach that uses original and modified WSDL specifications for change identification. All the relevant test cases are selected as reusable hence our regression test selection approach is safe. Comment: 9 figures, 2 tables, 11 pages, ASEA 201...|$|R
40|$|Continuous {{monitoring}} of achieved level <b>of</b> <b>service</b> quality in packet-switched networks represents an activity of major importance for network and service providers. This is paramount for network resources provisioning which have to satisfy expectations of fickle customers. However, providing enough resources to specific user {{does not automatically}} increase their Quality of Experience (QoE), hence {{understanding of the relationship}} between these two is crucial in the network management process. Essentially, this requires subjective <b>testing</b> <b>of</b> <b>service</b> quality which is usually done in controlled environments such as laboratories. Nevertheless, the most accurate subjective evaluation of QoE includes real-life experiments in the environments where the services are actually used. Therefore, the aim {{of this paper is to}} provide a review of the current state-of-the-practice in evaluating QoE in real-life environments. <br /...|$|R
50|$|In {{response}} to an inquiry {{from members of the}} United States House of Representatives Telecommunications Subcommittee about its pilot <b>test</b> <b>of</b> NebuAd's <b>services,</b> Embarq said it had notified consumers by revising its privacy policy 2 weeks prior to sending its users' data streams to NebuAd.|$|R
