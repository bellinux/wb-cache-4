16|411|Public
5000|$|A marker {{can be on}} or off {{depending}} on whether a probe is connected to it or not. Code which wants to hook into a <b>trace</b> <b>point</b> first calls: ...|$|E
30|$|The {{algorithm}} {{works as}} follows: firstly, map links nearby the first <b>trace</b> <b>point</b> are picked {{and each one}} will constitute a scored path candidate (a possible match sequence). The score of each candidate is then based on {{the sum of the}} least Euclidean distance between each <b>trace</b> <b>point</b> and its matched link (also named as matching distance). Hence, best candidates have lowest scores.|$|E
30|$|Individuals of the {{population}} are match candidates for each given trace. Each gene of the individual corresponds to a <b>trace</b> <b>point</b> and everyone has their own set of alleles that are unchangeable between them. Candidates are ranked according to a fitness function.|$|E
5000|$|GFS2 {{specific}} <b>trace</b> <b>points</b> {{have been}} available since kernel 2.6.32 ...|$|R
50|$|In mathematics, in geometry, a cyclogon is {{the curve}} traced by a vertex of a polygon that rolls without {{slipping}} along a straight line. There are no {{restrictions on the}} nature of the polygon. It can be a regular polygon like an equilateral triangle or a square. The polygon need not even be convex: it could even be a star-shaped polygon. More generally, the curves <b>traced</b> by <b>points</b> other than vertices have also been considered. In such cases it would be assumed that the <b>tracing</b> <b>point</b> is rigidly attached to the polygon. If the <b>tracing</b> <b>point</b> is located outside the polygon, then the curve is called a prolate cyclogon, and if it lies inside the polygon it is called a curtate cyclogon.|$|R
40|$|Representative {{embodiments}} {{are directed}} to systems and methods for processing analyzer trace data of a multi-tone signal to more accurately estimate the frequencies and amplitudes of the {{tones of the}} multi-tone signal. Specifically, trace data may be processed to determine peak <b>trace</b> <b>points.</b> For each identified peak point, an error minimization algorithm minimizes the sum of differences between a plurality of <b>trace</b> <b>points</b> surrounding the respective peak point and the predicted Fourier transform through a raised-cosine window of a theoretical tone. The result of the minimization algorithm identifies the amplitude and frequency of a tone of the multi-tone signal with appreciable degree of accuracy...|$|R
40|$|Mean shift {{algorithm}} {{is widely used}} in 2 D images. In this paper a novel 3 D corresponding control points estimation using mean shift {{algorithm is}} proposed. This algorithm {{is not a simple}} extension from 2 D to 3 D, but computes the probability density function in each slice of the search region and connects them into a whole density function smoothed by Gaussian function. And then we calculate and compare Bhattacharyya coefficients to determine a new location of the <b>trace</b> <b>point.</b> A cylinder instead of ellipsoid is utilized as the search region to improve tracking accuracy. Also three revising methods different from the direct round-off way are proposed to modify the floating <b>trace</b> <b>point.</b> Experiment demonstrates the feasibility of this 3 D mean shift algorithm and the effectiveness of the three revising methods. </p...|$|E
30|$|As {{previously}} mentioned, the segmentation {{was inspired}} on [12] {{in order to}} speed up the algorithm and to have better results. Before starting the matching process, the algorithm segments the trace in the following manner: firstly, the algorithm scores every <b>trace</b> <b>point.</b> Lowest scores represent less ambiguous areas to the matching process; then, it looks for sets of four consecutive points that are under a given threshold (fixed in 0.9); finally, using the previous sets as segment borders, the algorithm will try to form the widest segments available, yet these are restricted to a maximum number of points per segment (currently fixed at 50). The score is based on the sum of four distinct variables, which are normalized according to their units. The variables are: the difference of heading between the point and the closest map link, the distance between the point and the same link, the number of map links that are nearby the <b>trace</b> <b>point</b> (the defined distance is 20  m) and the heading variation in the neighbourhood of the trace point—the closer the trace curves are the larger the heading variation is.|$|E
30|$|For each <b>trace</b> <b>point,</b> {{a set of}} link {{candidates}} {{is available}} as alleles. A special allele is also inserted {{in order to give}} the possibility of an unmatched point to be performed. At this time, these link candidates can be collected according to two distinct methods. The first comes directly from the map. Firstly, links in the area of each point are picked up. Then, the closest one per super-link is selected. The maximum distance allowed is set at 20  m. Links with opposite heading to the <b>trace</b> <b>point</b> are discarded in order to avoid matches with roads running in the opposite direction. The second method, Marchal’s algorithm is first run for each candidate search. The candidates of each point are all links to which that point matched during the entire running of that algorithm. Afterwards, candidates are filtered using the same rules applied in the first method (maximum distance of 20  m, opposite heading and one link per super-link). This second approach improved results especially close to junctions during the first versions of the fitness function, but at the moment, the difference between them is minimal.|$|E
5000|$|... #Caption: Animation {{showing the}} tracing of a curtate cyclogon as an {{equilateral}} triangle rolls over {{a straight line}} without skipping. The <b>tracing</b> <b>point</b> Y is inside the disk of the triangle. (Click on the image to see the animation.) ...|$|R
5000|$|The Sanctuary of Elwyn the Ardent: A legendary holy {{artifact}} {{has been}} stolen, and all <b>traces</b> <b>point</b> to the mysterious Elwyn the Ardent. The players must enter Elwyn's fortress and {{fight their way}} through a number of traps and monsters, all under Elwyn's scornful watch and taunting words.|$|R
50|$|Existing data {{printed on}} paper or PET film maps can be {{digitized}} or scanned to produce digital data. A digitizer produces vector data as an operator <b>traces</b> <b>points,</b> lines, and polygon boundaries from a map. Scanning a map results in raster data {{that could be}} further processed to produce vector data.|$|R
30|$|We use the Linux Trace Toolkit next {{generation}} (LTTng) [32] {{to gather the}} VMs performance metrics. LTTng is a powerful, low impact and lightweight [33] open source Linux tracing tool. It provides precise and detailed information on the underlying kernel and user-space executions. LTTng contains different trace points in various modules of the operating system kernel. Once a predefined <b>trace</b> <b>point</b> is reached, it generates an event containing a time-stamp, CPU number and other run-time information related to the running processes.|$|E
30|$|Due to {{all these}} new situations, we decided not to include the {{condition}} of testing if a jump to the following link is performed or not. Instead of this, at each <b>trace</b> <b>point</b> we decided to create a set of candidates per current candidate. Each new path candidate has a distinct link to perform the matching. The links are as follows: the link that matched the previous point of the past candidate and, all reachable links to a maximum depth level {{of the number of}} tolerance links plus one. After scoring all the new candidates, they are filtered before passing to the following point. Two restrictions are applied in order to avoid similar path candidates that only would increase the number of candidates exponentially without having any improvement and to invalidate matches that, although being topologically correct, are far away from the trace points and so we assume that it is a new road segment instead. For the first restriction, only the best candidate passes per most recently matched super-link. This way, the number of candidates is drastically reduced and we guarantee to have the best possible candidates available. On the second restriction, the distance between the last <b>trace</b> <b>point</b> and its matched link must be lower than a given threshold (fixed to 45  m). All candidates where the last match is above this threshold are simply removed, so these candidates will not be considered better than the “real” accurate ones on the following points in unexpected and rare situations.|$|E
30|$|We {{have created}} a new genetic {{algorithm}} since {{we did not find}} any reference in the Map-Matching literature to algorithms that use evolutionary approaches and which would meet our expectations. We knew that in terms of computational performance it would be less efficient than other types of algorithm, especially Marchal’s. The main concern was on improving the quality of the matches. The goal was ultimately to design an algorithm that would not have the same problems commonly seen in other algorithms, as described in the state-of-the-art section (e.g. matching errors due to topological situations or outliers) and also one that could perform smooth transitions between a matched segment to an unmatched and vice-versa, and in transitions between two matched segments that are not yet interconnected. In our genetic algorithm 3, each individual consists of a matching sequence (from beginning {{to the end of the}} trace). Each gene corresponds to a <b>trace</b> <b>point.</b> The possible alleles for each gene are the links that are close to the respective <b>trace</b> <b>point.</b> A special value is also inserted to give the opportunity not to perform any match for the given point. After an initial population that is randomly created, the algorithm will run for a given number of generations and the best individual of the last population is considered to be the correct match. In each generation, individuals have the possibility to be recombined and mutated. Afterwards, they are evaluated using a fitness function that considers many factors (described below). Since the search space (and thus the program complexity) increases exponentially with trace length, we decided to break the trace into small segments inspired on [12]. In doing so, better individuals are obtained in less time. The break points are then selected based on a score function that prefers less crowded areas, noticeably away from junctions.|$|E
50|$|An integraph {{consists}} of a rectangular carriage which moves left to right on rollers, two sides of which run parallel to the x axis on the Cartesian plane. The other two sides are parallel to the y axis. Along the trailing vertical (y axis) rail, slides a smaller carriage holding a <b>tracing</b> <b>point.</b> Along the leading vertical rail slides a second smaller carriage to which is affixed a small, sharp disc, which rests and rolls (but does not slide) on the graphing paper. It will not rotate about its point of contact with the paper. The trailing carriage is connected both with {{a point in the}} center of the carriage and the disc on the leading rail by a system of sliding crossheads and wires, such that the <b>tracing</b> <b>point</b> must follow the disc's tangential path.|$|R
40|$|Local {{models are}} {{given for the}} {{singularities}} which can appear on the trajectories of general motions of the plane with more than two degrees of freedom. Versal unfoldings of these model singularities give rise to computer generated pictures describing the family of trajectories arising from small deformations of the <b>tracing</b> <b>point,</b> and determine the local structure of the bifurcation curves. ...|$|R
40|$|Includes bibliographical {{references}} (pages 29 - 30). In this research, I am {{proposing a}} solution for grid navigation and path planning using a Greedy Approach. Path planning is a major challenge for agent on given conditions that include mandatory visits points and mandatory avoidance of certain obstacles to reach final destination. Hence, finding a shortest path is considered a core issue in collision-free path planning. In {{order to deal with}} these issues successfully, I am proposing an approximate solution for shortest path determination and navigation with obstacle avoidance mechanism. A map composed of coordinates (<b>trace</b> <b>points,</b> obstacle points, and the final target) is entered using an interactive user Interface. The goal is to find an approximate optimal path to reach the destination, starting from a predefined coordinate and orientation in the grid from where it could head to the final target in the grid by following the respective <b>trace</b> <b>points</b> and avoiding obstacle points. 	On the output side, a rectangular grid clearly showing mandatory points to either visit or avoid is displayed. This makes it visually simple for a user to see the original problem and its solution...|$|R
40|$|In {{order to}} assess the {{accuracy}} and validity of subchannel, system, and computational fluid dynamics codes, the Paul Scherrer Institut has participated in the OECD/NRC PSBT benchmark with the thermal-hydraulic system code TRACE 5. 0 developed by US NRC, the subchannel code FLICA 4 developed by CEA, and the computational fluid dynamic code STAR-CD developed by CD-adapco. The PSBT benchmark consists {{of a series of}} void distribution exercises and departure from nucleate boiling exercises. The results reveal that the prediction by the subchannel code FLICA 4 agrees with the experimental data reasonably well in both steady-state and transient conditions. The analyses of single-subchannel experiments by means of the computational fluid dynamic code STAR-CD with the CD-adapco boiling model indicate that the prediction of the void fraction has no significant discrepancy from the experiments. The analyses with <b>TRACE</b> <b>point</b> out the necessity to perform additional assessment of the subcooled boiling model and bulk condensation model of TRACE...|$|E
40|$|The National Aeronautics and Space Administration {{has been}} funding {{university}} research into flexible, six-legged walking machines capable of exploring alien terrain. This research {{has led to}} a progressive new look at standard four bar mechanisms. Four bar mechanisms, by definition, consist of a crank link, coupler link, rocker link and fixed (ground) link. The passive role of the coupler link, in traditional four bar mechanisms, can be reversed so that the coupler becomes the transmission link. This is achieved by replacing the coupler with an oblique triangular link. The internal angles of the modified coupler can be varied to create an array of continuous, ovoid paths at the disjointed vertex of the triangle. Attaching a pantograph mechanism to the modified coupler's <b>trace</b> <b>point</b> amplifiers and translates the ovoid path. The combination of these two mechanisms provides a stable, one degree of freedom walking path which emulates that of humans. This mechanism can therefore be used as a robotic leg. A second degree of freedom is obtained by attaching an adjacent link to the pantograph mechanism which raises or lowers the walking path without effecting its shape or magnitude. This is used for climbing and maneuvering amidst rugged terrain...|$|E
40|$|Pathways and {{dilution}} of a {{point source}} ocean discharge in the farfield (≈ 10 − 66 km) were measured using the deliberate tracer sulfur hexafluoride (SF 6). The injection of SF 6 was performed by bubbling the gas {{over a period of}} 6 days into an ocean outfall pipe discharging into the southeast Florida coastal ocean. The surface SF 6 concentrations show that the discharged water flowed northward parallel to the coast with a broadening of the width of the plume to about 3 km at the farthest point sampled, 66 km from the outfall. The discharge was fully mixed throughout the water column within 13 km of the outfall terminus. In the first 20 km from the outfall, SF 6 surface concentrations were highly variable, while beyond this the SF 6 concentrations decreased monotonically going northward. The currents were measured during the study with a bottom-mounted acoustic Doppler current profiler (ADCP) located 5. 5 km from the outfall. Velocities were variable in magnitude and direction but showed a net northward flow during the 6 -day study. Maximum concentrations decreased by about 200 -fold per kilometer from the outfall to the northern end of the study area. The study shows that SF 6 is an effective method to <b>trace</b> <b>point</b> source releases far from their origin...|$|E
50|$|Thus, by the {{properties}} of inversive geometry, since the figure <b>traced</b> by <b>point</b> D is the inverse of the figure <b>traced</b> by <b>point</b> B, if B traces a circle passing {{through the center of}} inversion O, then D is constrained to trace a straight line. But if B traces a straight line not passing through O, then D must trace an arc of a circle passing through O. Q.E.D.|$|R
40|$|Paleoparasitology may be {{developed}} as a new tool to parasite evolution studies. DNA sequences dated thousand years ago, recovered from archaeological material, means the possibility to study parasite-host relationship coevolution through time. Together with tracing parasite-host dispersion throughout the continents, paleoparasitology points to the interesting field of evolution at the molecular level. In this paper {{a brief history of}} paleoparasitology is <b>traced,</b> <b>pointing</b> to the new perspectives opened by the recent techniques introduced...|$|R
40|$|Conference Name:International Conference on Computational Intelligence and Natural Computing. Conference Address: Wuhan, PEOPLES R CHINA. Time:JUN 06 - 07, 2009. In {{this article}} we {{simulate}} a complex economic system based on network economics, game theory and computer simulation technology. We develop a method to find approximate solution of Nash Equilibrium in the simulated economic system by <b>tracing</b> <b>points</b> of the optimal curve and thus estimate enterprise's income {{in the neighborhood of}} Nash Equilibrium...|$|R
40|$|If posed a {{question}} to our society these days about what is recyclable? Sure many are able to answer it. For the purpose of more accurate, {{recycling is the process}} of treating waste materials to produce new products. Realizing this, many related to recycling campaigns have been implemented by government agencies or NGOs. Recycling is a key component of waste management in modern times. Some of the wastes that can be recycled include aluminum, plastic and newspapers. Aluminum is a material that can be recycled 100 %. According to the facts, the aluminum can be reused within 60 days after recycling. RECYCLING means collecting and sorting of solid waste for the purpose of producing, the other meaning is to treat things that have already been used {{so that they can be}} used again (from Oxford dictionary). Machine means a piece of equipment with moving parts that is designed to do a particular job (from Oxford dictionary). RECYCLING MACHINE is the machine for recycle such as paper and plastic. This recycling machine used a card to <b>trace</b> <b>point</b> when student use it when they want recycle. By means of the use of this card can attract the attention of children or students to recycle every day. Also, at this stage can increase the sense of competition in them since child...|$|E
40|$|Knowledge {{about the}} {{structure}} and organization of terrorist networks is important for both terrorism investigation {{and the development of}} effective strategies to prevent terrorists ’ attacks. However, except for network visualization, terrorist network analysis remains primarily a manual process. Existing tools do not provide advanced structural analysis techniques that allow extraction of network knowledge from large volumes of criminal-justice data. It is a well known fact that terrorist activities consist of dispersed organizations (like non-hierarchical organizations), small groups, and individuals who communicate, coordinate and conduct their campaign in a network-like manner. There is a pressing need to automatically collect data of terrorist networks, analyze such networks to find hidden relations and groups, prune datasets to locate regions of interest, find key players, characterize the structure, <b>trace</b> <b>point</b> of vulnerability, and detect efficiency of the network. To meet this challenge, we designed and developed a knowledgebase for storing and manipulating data collected from various authenticated websites. This paper presents framework of investigative data mining toolkit, our recently introduced techniques and algorithms (which are implemented in the investigative data mining toolkit) could be useful for law enforcement agencies that need to analyze terrorist networks and prioritize their targets. Applying recently introduced algorithms for constructing hidden hierarchy of non-hierarchical terrorist networks, we present case studies of the terrorist attacks that occurred in past, in order to construct command structure of the networks...|$|E
30|$|After {{the initial}} {{matching}} process, for each {{point of the}} trace, {{it is assumed that}} the current point matches the last link of each candidate. Then, an update of the score occurs and the candidate is put into a new set. Afterwards, if the trace has {{reached the end of the}} link, new path candidates are created. To see if an intersection has been reached, a comparison is made between the travelled length through the trace points and the travelled length through the links of the path candidate. If the first length is longer than a given percentage of the second, it is assumed that the next junction has possibly been reached 2. For this percentage, the authors fixed the value in 50 %, which in their opinion tends to give fair results. New candidates are created, they are similar to the current one and a link per new road segment starting on that junction will be added to each one of the new candidates. Their score is updated and they are inserted into the new set. When no more candidates to match the current point are available, the algorithm will pick only the best N candidates of the new set, it passes to the following <b>trace</b> <b>point</b> and does everything all over again. The authors tested some values for N and, based on these experiments, they say that with values above 30, improvements on matching accuracy are insignificant. The best candidate obtained gives the final match. This algorithm has some additional mechanisms that permits breaking the match and restarting it from scratch when the distance between two consecutive points or the difference between timestamps of two consecutive points is above given thresholds. The authors use, as an example, 300  m for the distance and 30  s for time difference.|$|E
5000|$|... 2) Then, build a [...] "stair" [...] by <b>tracing</b> the <b>points</b> {{reached by}} this {{sequence}} of vectors (see figure). For example, the first points are: ...|$|R
40|$|Point set {{surfaces}} are a smooth manifold surface approximation from {{a set of}} sample points. The surface definition {{is based on a}} projection operation that constructs local polynomial approximations. I present techniques for ray <b>tracing</b> <b>point</b> set surfaces. For the computation of ray-surface intersections, properties of the projection operator are exploited. My results show that 2 - 3 projection operations are sufficient to accurately intersect a ray with the surface. In addition, i devise a spatial hierarchy and other techniques to further minimize the number of projection operations when tracing several rays...|$|R
5000|$|... #Caption: to the <b>tracing</b> algorithm: {{starting}} <b>points</b> {{are green}} ...|$|R
40|$|Seismic time {{migration}} {{is known for}} its ability to generate well-focused and interpretable images, based on a velocity field specified in the time domain. A fundamental requirement of this time-migration velocity field is that lateral variations are small. In the case of 3 D time migration for symmetric elementary waves (e. g., primary PP reflections/diffractions, for which the incident and departing elementary waves at the reflection/diffraction point are pressure [P] waves), the time-migration velocity is a function depending on four variables: three coordinates specifying a <b>trace</b> <b>point</b> location in the time-migration domain and one angle, the so-called migration azimuth. Based on a time-migration velocity field available for a single azimuth, we have developed a method providing an image-ray transformation between the time-migration domain and the depth domain. The transformation is obtained by a process in which image rays and isotropic depth-domain velocity parameters for their propagation are estimated simultaneously. The depth-domain velocity field and image-ray transformation generated by the process have useful applications. The estimated velocity field can be used, for example, as an initial macrovelocity model for depth migration and tomographic inversion. The image-ray transformation provides a basis for time-to-depth conversion of a complete time-migrated seismic data set or horizons interpreted in the time-migration domain. This time-to-depth conversion can be performed without the need of an a priori known velocity model in the depth domain. Our approach has similarities as well as differences compared with a recently published method based on knowledge of time-migration velocity fields for at least three migration azimuths. We show that it is sufficient, as a minimum, to give as input a time-migration velocity field for one azimuth only. A practical consequence of this simplified input is that the image-ray transformation and its corresponding depth-domain velocity field can be generated more easily...|$|E
40|$|In this paper, we {{investigate}} {{the relationship between}} the squared Weil/Tate pairing and the plain Weil/Tate pairing. Along these lines, we first show that the squared pairing for arbitrary chosen point can be transformed into a plain pairing for the <b>trace</b> zero <b>point</b> which has a special form to compute them more efficiently. This transformation requires only a cost of some Frobenius actions. Additionally, we show that the squared Weil pairing can be computed more efficiently for <b>trace</b> zero <b>point</b> and derive an explicit formula for the 4 th powered Weil pairing as an optimized version of the Weil pairing...|$|R
30|$|Next {{iterations}} will {{be predicted}} substituting λ _j+ 1 = 2 λ _j-λ _j- 1 in (11), {{as shown in}} Fig.  7. If the values calculated using (11) satisfy (7) it can be assured that they belong to the homotopic path. This procedure shall be repeated for next predictions until the obtained values no longer satisfies (7). It means that iterations with straight lines found a breakpoint on the homotopic path {{just like the one}} in Fig.  7 b. Therefore, two new iterations using the hypersphere <b>tracing</b> <b>point</b> should be performed to create a new straight line and predict points for the new segment.|$|R
5000|$|The film {{suggests}} that a British professional hit-man {{was hired by the}} CIA to assassinate the Swedish Prime Minister Olof Palme, because of Palme's stance on nuclear weapons in Scandinavia [...] The hit-man (Michael Kitchen) works for money alone and is very careful. He finds a Norwegian man that hates the Swedish P.M. He also involves a man to be blamed (this character is Christer Pettersson, originally convicted of the real assassination, but freed on appeal). The Norwegian man kills Palme just as his wife notices Christer Pettersson. Soon afterwards the hitman kills the killer, and all <b>traces</b> <b>pointing</b> to the professional hitman are gone.|$|R
50|$|The Vallum {{has been}} <b>traced</b> to a <b>point</b> {{just short of}} the {{south-east}} angle of the fort.|$|R
5000|$|Curtate cycloid: Here the <b>point</b> <b>tracing</b> out {{the curve}} {{is inside the}} circle, which rolls on a line.|$|R
