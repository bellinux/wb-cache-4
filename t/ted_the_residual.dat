0|10000|Public
40|$|For a system, {{which is}} {{observed}} at time <b>t,</b> <b>the</b> <b>residual</b> and past entropies measure the {{uncertainty about the}} remaining and the past life of the distribution, respectively. In this paper, we have presented <b>the</b> <b>residual</b> and past entropy of Morgenstern family based on the concomitants of {{the different types of}} generalized order statistics (gos) and give the linear transformation of such model. Characterization results for these dynamic entropies for concomitants of ordered random variables have been considered...|$|R
2500|$|If ei, <b>t</b> is <b>the</b> <b>residual</b> from an OLS {{regression}} with fixed {{effects for}} each observational unit i, {{associated with the}} observation in panel i at time <b>t,</b> then <b>the</b> test statistic is ...|$|R
30|$|F that is {{estimated}} during <b>the</b> training of <b>T.</b> It models <b>the</b> <b>residual</b> variabilities not {{captured by the}} total variability matrix T.|$|R
40|$|The {{effect of}} {{vortices}} on quasiparticle transport in cuprate superconductors was investigated {{by measuring the}} low temperature thermal conductivity of YBa_ 2 Cu_ 3 O_ 6. 9 in magnetic fields up to 8 <b>T.</b> <b>The</b> <b>residual</b> linear term (as T → 0) is found to increase with field, directly reflecting the occupation of extended quasiparticle states. A study for different Zn impurity concentrations reveals a good agreement with recent calculations for a d-wave superconductor, thereby shedding light {{on the nature of}} scattering by both impurities and vortices. It also provides a quantitative measure of the gap near the nodes. Comment: 4 pages, 2 included eps figures, significant new analysis wrt other experiments, to appear in Phys Rev Lett 29 March 199...|$|R
3000|$|<b>T)</b> until <b>the</b> shape <b>residual</b> error converges. <b>The</b> cost {{function}} is solved as a {{least squares problem}} and the rotation matrix is calculated by QR decomposition, as in [5]. Finally, a new 3 D facial shape S [...]...|$|R
5000|$|... {{algorithm}} ford-fulkerson is input: Graph G with {{flow capacity}} c, [...] source node s, [...] sink node t output: Flow f such that f is maximal from s to t [...] (Note that f(u,v) is the flow from node u to node v, and c(u,v) is the flow capacity from node u to node v) [...] for each edge (u, v) in GE do f(u, v) &larr; 0 f(v, u) &larr; 0 [...] while {{there exists a}} path p from s to <b>t</b> in <b>the</b> <b>residual</b> network Gf do let cf be the flow capacity of <b>the</b> <b>residual</b> network Gf cf(p) &larr; min{cf(u, v) | (u, v) in p} for each edge (u, v) in p do f(u, v) &larr; f(u, v) + cf(p) f(v, u) &larr; &minus;f(u, v) [...] return f ...|$|R
40|$|Accurate {{measurements}} of the energy loss of all charged particles are needed to determine {{the reliability of the}} Bethe theory of stopping power. Few measurements have been made for particles with energies greater than 20 MeV/u. A first step to accurate measurements is to establish the precision of an experimental method. The authors report here about the recent energy loss measurements for 290 MeV/u carbon ions from the HIMAC. They have been made with the method used for 70 MeV protons. The ion beam traverses an absorber of thickness <b>t</b> and <b>the</b> <b>residual</b> range of <b>the</b> ions is measured with a water container of adjustable thickness (``range gauge``) ...|$|R
40|$|The {{concept of}} {{analytic}} redundancy is extended to identify nonzero constant output failures in large spacecraft active control sensors and actuators, using {{a set of}} distributed sensors which do not nominally produce equivalent signals but are related through the structural dynamics of the system. The suboptimal technique uses a Sequential Probability Ratio <b>Test</b> on <b>the</b> <b>residual</b> sequence of a Kalman filter based on a modal structure model, to determine failure of a component based on an assumed failure hypothesis. The specific failure is identified and then the Kalman filter gains are reconfigured for the identified remaining working sensor set. Experimental data using an apparatus whose dynamics are representative of a large spacecraft show the nominal filter performance under failed and unfailed conditions...|$|R
40|$|Spore integuments of Bacillus coagulans were {{prepared}} containing {{nearly all the}} hexosamine and α, ε-diaminopimelic acid (DAP) present in intact spores. Subsequent autolytic action resulted in the destruction and removal of <b>the</b> <b>residual</b> cortical structure and "cortical membrane" leaving {{the appearance of the}} inner and outer spore coats unchanged in electron micrographs. Concurrently, all the hexosamine and DAP in the preparation was released mainly as non-diffusible mucopeptide containing alanine, glutamic acid, DAP, and all the glucosamine and muramic acid. Some diffusible peptides containing alanine, glutamic acid, and DAP were also present but there was little protein or carbohydrate. Lysozyme digestion of integument preparations from heated spores of Bacillus 636, B. subtilis, B. coagulans, and B. stearothermophilus specifically removed <b>the</b> <b>residual</b> cortex and cortical membrane with the release of the mucopeptide. In B. cereus <b>T,</b> only <b>the</b> <b>residual</b> cortex and part of the mucopeptide were solubilized by lysozyme. The effect of several reagents and enzymes upon the appearance and removal of hexosamine from B. coagul ans spore integuments is reported. The results show that spore mucopeptide is mainly located in <b>the</b> <b>residual</b> cortex and cortical membrane and suggest that these structures consist essentially of mucopeptide. The implications of these results in relation to the "contractile cortex" theory of heat resistance in spores are discussed...|$|R
30|$|The P uptake {{of mustard}} was not {{influenced}} by the direct effects of three vermicompost applications. However, the different rate significantly affect P uptake of the mustard where the highest P uptake was found at an application rate of 10 <b>t</b> ha− 1. <b>The</b> <b>residual</b> effect of three kinds of vermicompost on the P uptake of the second mustard {{was found on the}} plot treated with vermicompost V 1 at application rates of 15 – 20 t ha− 1, while on the third and fourth mustard cropping, the highest P uptake was found in vermicompost 3 with an application rate of 15 – 20 t ha− 1 (Table  2).|$|R
40|$|As {{function}} of time t, a mean <b>residual</b> life is <b>the</b> remaining {{life expectancy of}} a subject given survival up to <b>t.</b> <b>The</b> proportional mean <b>residual</b> life model, proposed by Oakes & Dasu (1990), provides {{an alternative to the}} Cox proportional hazards model for studying the association between survival times and covariates. In the presence of censoring, we use counting process theory to develop semiparametric inference procedures for the regression coefficients of the Oakes [...] Dasu model. Simulation studies and an application to the well-known Veterans' Administration lung cancer survival data are presented. Copyright 2005, Oxford University Press. ...|$|R
40|$|As a {{function}} of time t, mean <b>residual</b> life is <b>the</b> remaining life expectancy of a subject given survival up to <b>t.</b> <b>The</b> proportional mean <b>residual</b> life model, proposed by Oakes & Dasu (1990), provides {{an alternative to the}} Cox proportional hazards model to study the association between survival times and covariates. In the presence of censoring, we develop semiparametric inference procedures for the regression coefficients of the Oakes-Dasu model using martingale theory for counting processes. We also present simulation studies and an application to the Veterans' Administration lung cancer data. Counting process, estimating equation, failure time, life expectancy, proportional model, stochastic process,...|$|R
40|$|This paper {{examines}} the long-run relationship between {{oil prices and}} stock market prices of G 7 countries by using Robinson (1994 a) tests for fractional integration and cointegration instead of the classical approaches. Having found that the unit root null hypothesis cannot be rejected for any individual series, it is examined whether oil prices and stock market prices have a fractional cointegration relationship. <b>Test</b> results on <b>the</b> <b>residuals</b> from <b>the</b> cointegrating regressions indicate that {{there is evidence of}} fractional cointegration between oil prices and DAX 30, Dow Jones, FTSE 100 and SP-TSX indices while {{there is no evidence of}} fractional cointegration for others. stock markets, oil prices, G 7 countries, fractional integration, fractional cointegration...|$|R
40|$|Este trabalho contempla a utilização dos modelos de Langmuir, Freundlich, Sips, Redlich- Petersen, Toth, Dubinin–Radushkevich e Tempkin para análise de isotérmicas de adsorção de compostos fenólicos, amitriptilina e fluoxetina em carvões ativados e negros de fumo em fase líquida, obtidas pelo Grupo de Investigação de Química de Superfícies e Materiais da Universidade de Évora. Foi utilizado o ajuste não linear aos dados experimentais usando o {{software}} Solver do MS Excel. Para a avaliação da aplicabilidade dos modelos foram usadas as funções de erro, coeficiente de determinação, soma dos erros quadrados, média do erro relativo, desvio padrão percentual de Marquardt, função de erro fracionada hibrida, soma dos erros absolutos, chi-quadrado, raíz quadrada da média do erro e média percentual dos erros. Os modelos que apresentaram melhor ajuste foram os modelos de Sips, Freundlich, Toth e Langmuir observando-se para estes modelos as melhores correlações e minimização das funções de erro; ### Abstract: Title: Study of the Application of Various Models and Methodologies in the Analysis of Adsorption {{from the}} Liquid Phase. Isotherm adsorption models of Langmuir, Freundlich, Sips, Redlich-Petersen, Toth, Dubinin– Radushkevich and Tempkin {{were used to}} analyse isotherms of adsorption of phenolic compounds, amitriptyline and fluoxetine on activated carbons and carbon blacks from the liquid phase. The samples were obtained by the Surface & Materials Chemistry Group from University of Évora. The non-linear form of the models were used and fitted to the data using Solver from the MS Excel software. Several error functions were used, such as the Coefficient of Determination, the Sum of Squares of Errors, the Average Relative Error, the Marquardt’s Percent Standard Deviation, the Hybrid Fractional Error Function, the Sum of Absolute Errors, <b>the</b> Nonlinear Chi-square <b>Test,</b> <b>the</b> <b>Residual</b> Root Mean Square Error and the Average Percentage Errors. Sips, Freundlich, Toth and Langmuir models {{were considered to be}} the best-fitting, as they gave the best correlation and minimization of the error functions of the data...|$|R
40|$|This paper {{demonstrates}} a new gravest empirical mode (GEM) technique that constructs multi-index lookup tables of temperature (T) and specific volume anomalies () using historical hydrocasts {{as a function}} of three indices: round-trip travel time () from sea floor to the surface, sea surface temperature, and pressure. Moreover, the historical hydrocasts are separated into non-mixed-layer (NML) and mixed-layer (ML) groups, and a single GEM field is constructed for each group. This is called the MI-GEM technique. The appropriate dates for MI-GEM fields are determined by the monthly distribution of the number of NML and ML profiles in the historical hydrocasts, which are also well correlated with the strength of the winds during the 2 yr of observations. <b>The</b> <b>T</b> and profiles that are determined by this MI-GEM technique capture 92 % and 88 % of <b>the</b> <b>T</b> and variances in the depth range of 0 – 200 db. These values reduce by about one-third of the unexplained error variance of <b>the</b> <b>residual</b> GEM, which was recently developed and applied to the optimal interpolated data in the southwestern Japan/East Sea (JES) by Mitchell et al. Comparisons with the in situ CTD casts demonstrate that the MI-GEM technique almost always produces improved full water column profiles of <b>T</b> and. Whereas <b>the</b> <b>residual</b> GEM estimates had exhibited qualitatively erro-neous features like <b>T</b> inversions in <b>the</b> near–surface layer and too thin or thick intermediate water layers in some regions, the MI-GEM estimates avoid those problems, which were inherent to <b>the</b> <b>residual</b> GEM technique in the southwestern JES. 1...|$|R
40|$|Simultaneous {{very long}} {{baseline}} interferometry (VLBI) and water vapor radiometer (WVR) measurements on a 21 km baseline showed that calibration by WVRs removed a significant {{fraction of the}} effect of tropospheric delay fluctuations for these experiments. From comparison of <b>the</b> <b>residual</b> delay variations within scans and between scans, the total tropospheric contribution <b>t</b> <b>the</b> delay <b>residuals</b> {{for each of the three}} 5 to 20 hour sessions was estimated as 1, 17, and 10 %, with the first value being uncertain. The observed improvement in rms residual delay from WVR calibration during these three sessions was 4, 16, and 2 %, respectively. The improvement is consistent with the estimated 2 to 3 mm path delay precision of current WVRs. The VLBI measurements, of natural radio sources, were conducted in April and May 1993 at Goldstone, California. Dual-frequency (2. 3 and 8. 4 GHz) observations were employed to remove the effects of charged particles from the data. Measurements with co-pointed WVRs, located within 50 m of the axis of each antenna, were performed to test the ability of the WVRs to calibrate line-of-sight path delays. Factors that made WVR performance assessment difficult included (1) the fact that the level of tropospheric fluctuations was smaller than is typical for Goldstone during these experiments and (2) VLBI delay variations on longer time scales (i. e., over multiple scans) contained uncalibrated instrumental effects (probably a result of slow temperature variations in the VLBI hardware) that were larger than the tropospheric effects...|$|R
30|$|In {{order to}} test the {{distribution}} of <b>the</b> <b>residuals,</b> we conducted a Jarque-Bera <b>Test.</b> <b>The</b> test value was 13.03, with p[*]=[*]. 0014. The results suggest that that <b>the</b> <b>residual</b> term is normally distributed (Jarque and Bera 1980) and that the OLS estimation method can be conducted.|$|R
40|$|We {{present a}} study of <b>the</b> superconducting {{properties}} (<b>T</b> c and H c 2) in the solid solution (TMTSF) _ 2 (ClO_ 4) _(1 -x) (ReO_ 4) _x, with a ReO_ 4 ^- nominal concentration up to x= 6 %. The dramatic suppression of <b>T</b> c when <b>the</b> <b>residual</b> resistivity is increased upon alloying with no modification of the Fermi surface is the signature of non-conventional superconductivity. This behaviour strongly supports p or d wave pairing in quasi one dimensional organic superconductors. The determination of the electron lifetime in the normal state at low temperature confirms that a single particle Drude model is unable to explain the temperature dependence of the conductivity and that a very narrow zero frequency mode {{must be taken into}} account for the interpretation of the transport properties. Copyright Springer-Verlag Berlin/Heidelberg 2004...|$|R
40|$|Oil {{reservoir}} {{numerical simulation}} technology is one research approach of stratum geology {{as well as}} oil reservoir development by applying mathematical methods, which establishes the simulation model of stratum oil reservoir through the oil reservoir geology model, permeability mathematical equation and numerical model. In this study, we want to seek for the oil-water distribution law {{as well as its}} characteristics in X block geology of an oil field by using the STARS model. In addition, the development history of the geology of this oil field was simulated and the development potential of this block was discussed. The results indicated that the geological model of 13 wells was extracted, which were divided into 7 simulation layer vertically with the grid system of 23 × 9 × 7 = 1449. According to the single well fitting, among the 9 producing wells in the testing well block, six wells achieved good fitting, occupying 66. 67 %, while the rest three wells achieved poor fitting, occupying 33. 33 %. The prediction result that on Oct., 2026, the recovery percentage of X block was 40. 95 %, the oil produced was 11. 09 × 104 <b>t</b> and <b>the</b> <b>residual</b> geological reserves were 15. 99 × 104 t...|$|R
40|$|Phosphorus (P) {{deficiency}} {{is widespread}} in Cambodian rice growing soils, and strong responses are generally obtained from P fertilizer application. Since P fertilizer use {{is expected to}} increase in Cambodian rice crops, the present study was conducted to examine <b>the</b> <b>residual</b> value of P fertilizer applied to rice. Phosphorus fertilizer at a rate of 16. 5 kg P ha- 1 was applied to a wet season rainfed rice crop on a sandy lowland soil (Plinthustalf) in 1997, and the response of rice to this P was quantified in four successive rice crops by reference to yield obtained from a fresh application of 16. 5 kg P ha- 1 in each succeeding crop. In crop one, P increased rice yield from 1. 5 to 2. 8 t. ha- 1, whereas in the crop two, grown with irrigation in the following dry season, <b>the</b> <b>residual</b> P and <b>the</b> freshly applied P, increased grain yield by 62 and 85 %, respectively. In crop three, <b>the</b> <b>residual</b> P from crop one barely increased growth, producing a yield of about 2. 0 <b>t.</b> ha, whereas <b>the</b> <b>residual</b> P from crop two increased growth by 60 %, and freshly applied P increased growth of 70 %. In the fourth crop, grain yield responded only weakly or not at all to <b>the</b> <b>residual</b> P from that applied to crop one. These results suggest that P needs to be reapplied every two crops on sandy lowland soils of Cambodia provided grain yields similar to those obtained in the present study are maintained. The mechanisms underlying <b>the</b> decline in <b>residual</b> value of P, including P removal in harvested crop products and long-term reactions of P with soils under alternating waterlogged and dry conditions warrant further investigation. These data will be incorporated into a model of P cycling in the lowland rainfed rice ecosystems of Cambodia...|$|R
40|$|Several {{studies using}} test-day models show clear {{heterogeneity}} of residual variance along lactation. A changepoint technique {{to account for}} this heterogeneity is proposed. The data set included 100 744 test-day records of 10 869 Holstein-Friesian cows from northern Spain. A three-stage hierarchical model using the Wood lactation function was employed. Two unknown changepoints at times T 1 and T 2, (0 <T 1 <T 2 <tmax), with continuity of residual variance at these points, were assumed. Also, a nonlinear relationship between <b>residual</b> variance and <b>the</b> number of days of milking <b>t</b> was postulated. <b>The</b> <b>residual</b> variance at a time <b>t()</b> in <b>the</b> lactation phase i was modeled as: for (i = 1, 2, 3), where λι is a phase-specific parameter. A Bayesian analysis using Gibbs sampling and the Metropolis-Hastings algorithm for marginalization was implemented. After a burn-in of 20 000 iterations, 40 000 samples were drawn to estimate posterior features. The posterior modes of T 1, T 2, λ 1, λ 2, λ 3,,, were 53. 2 and 248. 2 days; 0. 575, - 0. 406, 0. 797 and 0. 702, 34. 63 and 0. 0455 kg 2, respectively. <b>The</b> <b>residual</b> variance predicted using these point estimates were 2. 64, 6. 88, 3. 59 and 4. 35 kg 2 at days of milking 10, 53, 248 and 305, respectively. This technique requires less restrictive assumptions and the model has fewer parameters than other methods proposed to account for <b>the</b> heterogeneity of <b>residual</b> variance during lactation...|$|R
40|$|Summary. A {{new method}} of {{estimating}} the yields of events a t a nuclear test site is introduced and tested against the Amchitka experience. The inter-correlation method is a relative waveform comparison technique, which involves convolution of the first few seconds of each short-period P-wave recorded at a given station for two events with estimates of the effective source function (including p P) for the other event. This procedure accounts for common path and receiver effects as well as differences in time functions and near-source surface interactions. If the source parameters for a master event are determined independently, the assumed source parameters for a second event can be adjusted <b>t</b> o minimize <b>the</b> <b>residual</b> differences in <b>the</b> inter-correlated signal pairs for {{a large number of}} stations simultaneously. Yield estimates can then be made using empirical relations between the source parameters and yield. The source time function representation used i...|$|R
40|$|The expectation-maximization {{algorithm}} (EM) is {{used for}} many estimation problems in statistics. Here we give a short tutorial on how to program a segmentation algorithm using EM. Those interested in the theory or in more advanced versions of the algorithm should consult the references at the end. Suppose we are given a set of datapoints that were generated by multiple processes, for example two lines. We need to estimate two things: (1) the parameters (slope and intercept) of the two lines and (2) the assignment of each datapoint to the process that generated it. The intuition behind EM is {{that each of these}} steps is easy assuming the other one is solved. That is, assuming we know the assignment of each datapoint, then we can estimate the parameters of each line by taking into consideration only those points assigned to it. Likewise, if we know the parameters of the lines we can assign each point to <b>the</b> line that <b>ts</b> it best. This gives the basic structure of an EM algorithm: start with random parameter values for the two models. Iterate until parameter values converge: { E step: assign points to <b>the</b> model that <b>ts</b> it best. { M step: update the parameters of the models using only points assigned to it. In fact both steps are slightly more complicated, due to the assignment being continuous rather than binary valued. The following sections go into more detail regarding the E step and the M step. 1 The Expectation (E) step In the E step we compute for each datapoint twoweights w 1 (i);w 2 (i) (the soft assignment of the point to models 1 and 2 respectively 1). Again, we assume that the parameters of the processes are known. Thus for each datapoint we can calculate two residuals r 1 (i);r 2 (i) - the di erence between the observation at point i and the predictions of each model. In the case of line <b>tting</b> <b>the</b> <b>residual</b> is simply given by: r 1 (i) =a 1 x i+b 1 y i (1) 1 Throughout this tutorial we assume the number of models is known and is equal to two. A method for automatically estimating the number of models is presented in (Weiss and Adelson, 1996) 1 and similarly for r 2 (i). For example, suppose we havetwoline models: (1) y = x + 3 and (2) y = 2 x 1. Suppose the ith datapoint isx= 1;y = 1 : 1. Then <b>the</b> <b>residual</b> for line 1 is r 2 1 (i) =(1 + 3 1 : 1) 2 = 2 : 92 and for line 2 we get r...|$|R
2500|$|If et is <b>the</b> <b>residual</b> {{associated}} with <b>the</b> observation at time <b>t,</b> then <b>the</b> test statistic is ...|$|R
30|$|Some of {{the tests}} {{statistics}} on <b>the</b> <b>residuals</b> are shown, including the mean (which is {{not significantly different from}} 0, according to <b>the</b> <b>t</b> statistic). We will use <b>the</b> <b>residual</b> standard deviation, 0.4829, and its square 0.2332, <b>the</b> <b>residual</b> variance, denoted V in Sect. 2.|$|R
40|$|Reconstitution of the {{recipient}} lymphoid compartment following hematopoietic cell transplantation (HCT) is typically delayed. The present studies investigated <b>the</b> <b>residual</b> host CD 4 +CD 25 +Foxp 3 + (Treg) compartment after several conditioning regimens, including T cell–depleted and T cell–replete HCT and observed (1) {{a small number of}} recipient Treg cells survived aggressive conditioning; (2) the surviving, that is, residual Tregs underwent marked expansion; and (3) recipient CD 4 +FoxP 3 + cells composed the majority of the Treg compartment for several months post-syngeneic HCT. Notably, residual Tregs also dominated the compartment post-HCT with T cell–depleted (TCD) major histocompatibility complex–matched allogeneic bone marrow but not following <b>T</b> cell–replete transplantations. <b>The</b> <b>residual</b> Treg cell compartment was functionally competent as assessed by in vitro lymphoid suppression and in vivo autoimmune disease transfer assay. These observations support the notion that functional host Tregs initially occupy a niche in lymphopenic transplantation recipients, undergo significant expansion, and contribute to the compartment for an extended period before donor-derived CD 4 +FoxP 3 + T cells eventually compose the majority of the compartment. In total, the findings suggest that the presence of host Tregs may be important to consider regarding elicitation of immune (eg, antitumor, vaccine) responses in recipients during the early post-transplant period involving autologous and certain allogeneic HCT regimens...|$|R
40|$|Abstract Several {{studies using}} test-day models show clear {{heterogeneity}} of residual variance along lactation. A changepoint technique {{to account for}} this heterogeneity is proposed. The data set included 100 744 test-day records of 10 869 Holstein-Friesian cows from northern Spain. A three-stage hierarchical model using the Wood lactation function was employed. Two unknown changepoints at times T 1 and T 2, (0 T 1 T 2 t max), with continuity of residual variance at these points, were assumed. Also, a nonlinear relationship between <b>residual</b> variance and <b>the</b> number of days of milking <b>t</b> was postulated. <b>The</b> <b>residual</b> variance at a time <b>t</b> () in <b>the</b> lactation phase i was modeled as: for (i = 1, 2, 3), where λ ι is a phase-specific parameter. A Bayesian analysis using Gibbs sampling and the Metropolis-Hastings algorithm for marginalization was implemented. After a burn-in of 20 000 iterations, 40 000 samples were drawn to estimate posterior features. The posterior modes of T 1, T 2, λ 1, λ 2, λ 3,,, were 53. 2 and 248. 2 days; 0. 575, - 0. 406, 0. 797 and 0. 702, 34. 63 and 0. 0455 kg 2, respectively. <b>The</b> <b>residual</b> variance predicted using these point estimates were 2. 64, 6. 88, 3. 59 and 4. 35 kg 2 at days of milking 10, 53, 248 and 305, respectively. This technique requires less restrictive assumptions and the model has fewer parameters than other methods proposed to account for <b>the</b> heterogeneity of <b>residual</b> variance during lactation. </p...|$|R
40|$|BACKGROUND. Healthcare workers (HCWs) lack {{familiarity}} with evidence-based {{guidelines for the}} prevention of healthcare-associated infections (HAIs). There is good evidence that effective educational interventions help to facilitate guideline implementation, so we investigated whether e-learning could enhance HCW knowledge of HAI prevention guidelines. METHODS. We developed an electronic course (e-course) and tested its usability and content validity. An international sample of voluntary learners submitted to a pretest (TO) that determined their baseline knowledge of guidelines, and they subsequently studied the e-course. Immediately after studying the course, posttest 1 (<b>T</b> 1) assessed <b>the</b> immediate learning effect. After 3 months, during which participants had no access to the course, a second posttest (<b>T</b> 2) evaluated <b>the</b> <b>residual</b> learning effect. RESULTS. A total of 3, 587 HCWs representing 79 nationalities enrolled: 2, 590 HCWs (72 %) completed TO; 1, 410 HCWs (39 %) completed T 1; and 1, 011 HCWs (28 %) completed <b>T</b> 2. <b>The</b> median study time was 193 minutes (interquartile range [IQR], 96 - 306 minutes). The median scores were 52 % (IQR, 44 %- 62 %) for TO, 80 % (IQR, 68 %- 88 %) for T 1, and 74 % (IQR, 64 %- 84 %) for <b>T</b> 2. <b>The</b> immediate learning effect (TO vs T 1) was + 24 % (IQR, 12 %- 34 %; P 300 minutes yielded <b>the</b> greatest <b>residual</b> effect (24 %). CONCLUSIONS. Moderate time invested in e-learning yielded significant immediate and residual learning effects. Decision makers could consider promoting e-learning as a supporting tool in HAI prevention...|$|R
40|$|A Bootstrap bias {{correction}} The bootstrap {{has become}} a common method for correcting small-sample mean bias. 1 Here we detail the steps for bias-corrected estimation of the VAR specified in the paper. Denote the demeaned observations by ˜ Xt = Xt − T − 1 ∑ T i= 1 Xi, and let B denote the number of bootstrap samples. The algorithm for mean bias correction using the bootstrap is as follows: 1. Estimate the model by OLS and save the OLS estimates ˆ θ = vec (ˆ Φ) and <b>the</b> <b>residuals.</b> Set b = 1. 2. Generate bootstrap sample b using <b>the</b> <b>residual</b> bootstrap: Resample <b>the</b> OLS <b>residuals,.</b> Randomly choose a starting value among <b>the</b> <b>T</b> denoting <b>the</b> bootstrap <b>residuals</b> by u ∗ t observations. For t> 1, construct the bootstrap sample using ˜ X ∗ t = ˆ Φ ˜ X ∗ t− 1 +u∗t. 3. Calculate the OLS estimates on bootstrap sample b and denote it by ˆ θ ∗ b. 4. If b < B then increase b by one and return to step two. 5. Calculate the average over all samples as ¯ θ ∗ = B − 1 ∑ B b= 1 ˆ θ ∗ b. 6. Calculate the bootstrap bias-corrected estimate as ˜θ B = ˆ [] θ − ¯θ ∗ −θ ˆ = 2 ˆ θ − ¯ θ ∗. For large B, the estimated bias ¯ θ ∗ − ˆ θ will be close to bT (ˆ θ). The motivation for this approach {{comes from the fact}} that E(bT (ˆ θT)) = bT(θ 0) +O(T − 2), thus we can reduce the bias to order T − 2 by using this bias correction (Horowitz, 2001) ...|$|R
3000|$|The OMP can {{be viewed}} as the {{successive}} interference cancellation method, i.e., at each iteration the strongest signal component is subtracted from <b>the</b> <b>residual</b> vector. We denote <b>the</b> <b>residual</b> vector at <b>the</b> <b>t</b> th iteration by r [...]...|$|R
3000|$|<b>Test</b> <b>the</b> {{stopping}} condition (i.e., {{reaching to}} [...] "goal"; predefined Mse —mean square error- of <b>the</b> total <b>residuals)</b> [...]...|$|R
40|$|We {{consider}} a fluid queue fed by a superposition of n homogeneous on-off sources with generally distributed on- and off-periods. We scale buffer space B and link rate C by n, such {{that we get}} nb and nc, respectively. Then we let n grow large. In this regime, the overflow probability decays exponentially {{in the number of}} sources n; we specifically examine the situation in which also b is large. We explicitly compute asymptotics for the case in which the on-periods have a subexponential distribution, e. g., Pareto, Lognormal, or Weibull. We provide a detailed interpretation of our results. Crucial is the shape of the function v(t) := -log P(A* > t) for large <b>t,</b> A* being <b>the</b> <b>residual</b> on-period. If v(&middot;) is slowly varying (e. g., Pareto, Lognormal), then, during the trajectory to overflow, the input rate will only slightly exceed the link rate. Consequently, the buffer will fill `slowly', and the typical time to overflow will be `more than linear' in the buffer size. In contrast, if v(&middot;) [...] ...|$|R
40|$|Abstract An {{approach}} for solving inverse problems involving obsta cles is proposed The approach uses a levelset method {{which has been}} shown to be eective in treating problems of moving boundaries particu larly those that involve topological changes in the geometry We develop two computational methods based on this idea One method results in a nonlinear timedependent partial dierential equation for the levelset function whose evolution minimizes <b>the</b> <b>residual</b> in <b>the</b> data <b>t</b> <b>The</b> second method is an optimization that generates a sequence of level set functions that reduces <b>the</b> <b>residual</b> <b>The</b> methods are illustrated in two applications a deconvolution problem and a diraction screen reconstruction proble...|$|R
3000|$|... r is <b>the</b> <b>residual</b> {{potential}} when <b>the</b> discharging curves approaching flat. <b>T</b> is <b>the</b> applied temperature on the PS films, and dT is {{the temperature}} width of glass transition region. T [...]...|$|R
40|$|<b>The</b> <b>residual</b> stress {{distributions}} for plate T {{butt welds}} were determined from a detailed {{finite element analysis}} of the welding process and they were {{compared with those of}} the measured data for validation. <b>The</b> <b>residual</b> stress distributions from the analyses and measurements were shown to be in similar shape. The distributions were found to be below the master curve for <b>the</b> <b>residual</b> stresses that were previously determined from a statistical analysis for a range of weld geometries and materials. A failure assessment for <b>the</b> <b>T</b> butt weld with cracks under residual stress distributions has been carried out. The conservatism in the current life assessment procedures regarding <b>the</b> <b>residual</b> stresses were quantified based on the stress intensity factor SIF calculations for <b>the</b> <b>T</b> butt weld. It was shown that the master curve profile provides more realistic values for the SIFs with reasonable conservatism than the profiles recommended in the existing assessment procedure...|$|R
5000|$|... where X is <b>the</b> data, <b>T</b> are <b>the</b> {{component}} {{scores and}} P are the component loadings. E is <b>the</b> <b>residual</b> or error matrix. Because ASCA models the variation partitions by SCA, {{the model for}} effect estimates looks like this: ...|$|R
