143|547|Public
25|$|The {{use of the}} p-value in {{statistics}} was {{popularized by}} Ronald Fisher, and it plays {{a central role in}} his approach to the subject. In his influential book Statistical Methods for Research Workers (1925), Fisher proposes the level p = 0.05, or a 1 in 20 chance of being exceeded by chance, as a limit for statistical significance, and applies this to a normal distribution (as a <b>two-tailed</b> <b>test),</b> thus yielding the rule of two standard deviations (on a normal distribution) for statistical significance (see 68–95–99.7 rule).|$|E
25|$|A simple {{generalization}} of the example considers {{a mixed bag}} of beans and a handful that contain either very few or very many white beans. The generalization considers both extremes. It requires more calculations and more comparisons {{to arrive at a}} formal answer, but the core philosophy is unchanged; If the composition of the handful is greatly {{different from that of the}} bag, then the sample probably originated from another bag. The original example is termed a one-sided or a one-tailed test while the generalization is termed a two-sided or <b>two-tailed</b> <b>test.</b>|$|E
25|$|Suppose a {{researcher}} flips a coin some arbitrary {{number of times}} (n) and assumes a null hypothesis that the coin is fair. The test statistic is {{the total number of}} heads and is a <b>two-tailed</b> <b>test.</b> Suppose the researcher observes heads for each flip, yielding a test statistic of n and a p-value of 2/2n. If the coin was flipped only 5 times, the p-value would be 2/32 = 0.0625, which is not significant at the 0.05 level. But if the coin was flipped 10 times, the p-value would be 2/1024 ≈ 0.002, which is significant at the 0.05 level.|$|E
40|$|AbstractThis paper {{demonstrates}} {{that there is}} currently a widespread misuse of <b>two-tailed</b> <b>testing</b> for directional research hypotheses tests. One probable reason for this overuse of <b>two-tailed</b> <b>testing</b> is the seemingly valid beliefs that <b>two-tailed</b> <b>testing</b> is more conservative and safer than one-tailed testing. However, the authors examine the legitimacy of this notion and find it to be flawed. A second and more fundamental cause of the current problem is the pervasive oversight in making {{a clear distinction between}} the research hypothesis and the statistical hypothesis. Based upon the explicated, sound relationship between the research and statistical hypotheses, the authors propose a new scheme of hypothesis classification to facilitate and clarify the proper use of statistical hypothesis testing in empirical research...|$|R
3000|$|... 42 via <b>two-tailed</b> <b>tests</b> at {{the alpha}} level of 0.05. For both of them, {{there are no}} {{significant}} differences between the means of the correlation coefficient (R) obtained from the emails and the game, respectively (H [...]...|$|R
30|$|Comparisons between {{control and}} {{experimental}} kidneys were established by paired <b>two-tailed</b> t <b>test</b> for normally distributed (tracer distribution) or the Wilcoxon signed rank for nonparametric values (caspase- 3). The same {{was used for}} the increase in GFR (paired <b>two-tailed</b> t <b>test)</b> and diuresis (Wilcoxon signed rank) in the control groups compared to baseline. Differences between the groups were established by unpaired <b>two-tailed</b> t <b>test</b> values (GFR) or by Mann–Whitney rank sum test (caspase- 3). p[*]<[*] 0.05 were considered statistically significant.|$|R
25|$|Thus {{computing}} a p-value {{requires a}} null hypothesis, a test statistic (together with deciding whether the researcher is performing a one-tailed test or a <b>two-tailed</b> <b>test),</b> and data. Even though computing the test statistic on given data may be easy, computing the sampling distribution under the null hypothesis, and then computing its {{cumulative distribution function}} (CDF) is often a difficult problem. Today, this computation is done using statistical software, often via numeric methods (rather than exact formulae), {{but in the early}} and mid 20th century, this was instead done via tables of values, and one interpolated or extrapolated p-values from these discrete values. Rather than using a table of p-values, Fisher instead inverted the CDF, publishing a list of values of the test statistic for given fixed p-values; this corresponds to computing the quantile function (inverse CDF).|$|E
2500|$|In {{statistical}} significance testing, a one-tailed test and a <b>two-tailed</b> <b>test</b> are {{alternative ways of}} computing the {{statistical significance}} of a parameter inferred from a data set, {{in terms of a}} test statistic. A <b>two-tailed</b> <b>test</b> is appropriate if the estimated value may be more than or less than the reference value, for example, whether a test taker may score above or below the historical average.|$|E
2500|$|In the {{approach}} of Ronald Fisher, the null hypothesis H0 will be rejected when the p-value of the test statistic is sufficiently extreme (vis-a-vis the test statistic's sampling distribution) and thus judged unlikely {{to be the result}} of chance. In a one-tailed test, [...] "extreme" [...] is decided beforehand as either meaning [...] "sufficiently small" [...] or meaning [...] "sufficiently large" [...] – values in the other direction are considered not significant. In a <b>two-tailed</b> <b>test,</b> [...] "extreme" [...] means [...] "either sufficiently small or sufficiently large", and values in either direction are considered significant. For a given test statistic there is a single <b>two-tailed</b> <b>test,</b> and two one-tailed tests, one each for either direction. Given data of a given significance level in a <b>two-tailed</b> <b>test</b> for a test statistic, in the corresponding one-tailed tests for the same test statistic it will be considered either twice as significant (half the p-value), if the data is in the direction specified by the test, or not significant at all (p-value above 0.05), if the data is in the direction opposite that specified by the test.|$|E
50|$|The two {{conditions}} for the paired-sample sign test are that a sample must be randomly selected from each population, and the samples must be dependent, or paired. Independent samples cannot be meaningfully paired. Since the test in nonparametric, the samples need not come from normally distributed populations. Also, the test works for left-tailed, right-tailed, and <b>two-tailed</b> <b>tests.</b>|$|R
30|$|Statistical {{significance}} was determined using non-parametric <b>Two-tailed</b> Mann-Whitney <b>test</b> without assuming Gaussian distribution.|$|R
25|$|The {{statistical}} tables for t and for Z provide critical values for both one- and <b>two-tailed</b> <b>tests.</b> That is, {{they provide the}} critical values that cut off an entire region at {{one or the other}} end of the sampling distribution as well as the critical values that cut off the regions (of half the size) at both ends of the sampling distribution.|$|R
2500|$|Explicit {{expressions}} {{that can}} be used to carry out various t-tests are given below. [...] In each case, the formula for a test statistic that either exactly follows or closely approximates a t-distribution under the null hypothesis is given. [...] Also, the appropriate degrees of freedom are given in each case. [...] Each of these statistics can be used to carry out either a one-tailed or <b>two-tailed</b> <b>test.</b>|$|E
2500|$|Suppose a {{researcher}} flips a coin {{five times in}} a row and assumes a null hypothesis that the coin is fair. The test statistic of [...] "total number of heads" [...] can be one-tailed or two-tailed: a one-tailed test corresponds to seeing if the coin is biased towards heads, but a <b>two-tailed</b> <b>test</b> corresponds to seeing if the coin is biased either way. The researcher flips the coin five times and observes heads each time (HHHHH), yielding a test statistic of 5. In a one-tailed test, this is the upper extreme of all possible outcomes, and yields a p-value of (1/2)5 = 1/32 ≈ 0.03. If the researcher assumed a significance level of 0.05, this result would be deemed significant and the hypothesis that the coin is fair would be rejected. In a <b>two-tailed</b> <b>test,</b> a test statistic of zero heads (TTTTT) is just as extreme and thus the data of HHHHH would yield a p-value of 2×(1/2)5 = 1/16 ≈ 0.06, which is not significant at the 0.05 level.|$|E
2500|$|For example, if {{flipping}} a coin, testing {{whether it}} is biased towards heads is a one-tailed test, and getting data of [...] "all heads" [...] {{would be seen as}} highly significant, while getting data of [...] "all tails" [...] would be not significant at all (p=1). By contrast, testing {{whether it is}} biased in either direction is a <b>two-tailed</b> <b>test,</b> and either [...] "all heads" [...] or [...] "all tails" [...] would both be seen as highly significant data. In medical testing, while one is generally interested in whether a treatment results in outcomes that are better than chance, thus suggesting a one-tailed test; a worse outcome is also interesting for the scientific field, therefore one should use a <b>two-tailed</b> <b>test</b> that corresponds instead to testing whether the treatment results in outcomes that are different from chance, either better or worse. In the archetypal lady tasting tea experiment, Fisher tested whether the lady in question was better than chance at distinguishing two types of tea preparation, not whether her ability was different from chance, and thus he used a one-tailed test.|$|E
30|$|The dentofacial {{morphology}} of {{the subjects}} in the experimental group was compared using paired t tests. The starting forms of the control and experimental samples were compared with a <b>two-tailed</b> t <b>test.</b> The skeletal and dental changes between the treated and control sample at the two time periods were compared with a <b>two-tailed</b> t <b>test.</b> The confidence level was set at 95 %.|$|R
30|$|The {{statistical}} analysis {{was carried out}} utilizing the JMP version 90.9 SAS Software (Cary, NC). The starting forms of the control and experimental samples were compared using a <b>two-tailed</b> t <b>test.</b> The skeletal and dental changes between the treated and control sample at the two time periods were compared with a <b>two-tailed</b> t <b>test.</b> The confidence level was set at 95  %.|$|R
50|$|The {{statistical}} tables for t and for Z provide critical values for both one- and <b>two-tailed</b> <b>tests.</b> That is, {{they provide the}} critical values that cut off an entire region at {{one or the other}} end of the sampling distribution as well as the critical values that cut off the regions (of half the size) at both ends of the sampling distribution.|$|R
2500|$|The {{number at}} the {{beginning}} of each row in the table above is ν, which has been defined above as nnbsp&−nbsp&1. [...] The percentage along the top is 100%(1nbsp&−nbsp&α). [...] The numbers in the main body of the table are tα, ν. [...] If a quantity T is distributed as a Student's t-distribution with ν degrees of freedom, then there is a probability 1nbsp&−nbsp&α that T will be less than tα, ν. (Calculated as for a one-tailed or one-sided test, as opposed to a <b>two-tailed</b> <b>test.)</b> ...|$|E
2500|$|In coin flipping, {{the null}} {{hypothesis}} is a sequence of Bernoulli trials with probability 0.5, yielding a random variable X which is 1 for heads and 0 for tails, and a common test statistic is the sample mean (of the number of heads) [...] If testing for whether the coin is biased towards heads, a one-tailed test would be used – only large numbers of heads would be significant. In that case a data set of five heads (HHHHH), with sample mean of 1, has a [...] chance of occurring, (5 consecutive flips with 2 outcomes - ((1/2)^5 =1/32), and thus would have [...] and would be significant (rejecting {{the null hypothesis}}) if using 0.05 as the cutoff. However, if testing for whether the coin is biased towards heads or tails, a <b>two-tailed</b> <b>test</b> would be used, and a data set of five heads (sample mean 1) is as extreme as a data set of five tails (sample mean 0), so the p-value would be [...] and {{this would not be}} significant (not rejecting the null hypothesis) if using 0.05 as the cutoff.|$|E
5000|$|... binom.test(51,235,(1/6),alternative="two.sided") (<b>two-tailed</b> <b>test)</b> ...|$|E
30|$|Raw {{survey data}} were {{downloaded}} and processed, then inputted into the IBM SPSS Statistics 23 software package for analysis. Descriptive statistics were generated for results {{from each of}} the survey sub-tests. Where appropriate, comparisons between the means of specialist and self-contained teachers’ responses were conducted using independent sample t tests along with integrated Levene’s tests for equality of variances. All significance values were obtained via <b>two-tailed</b> <b>tests.</b>|$|R
30|$|For {{pairwise}} comparisons of endpoint means of {{experimental and control}} groups, <b>two-tailed</b> t <b>tests</b> were conducted using Prism (GraphPad).|$|R
25|$|One-tailed {{tests are}} used for {{asymmetric}} distributions that have a single tail, such as the chi-squared distribution, which are common in measuring goodness-of-fit, or for {{one side of a}} distribution that has two tails, such as the normal distribution, which is common in estimating location; this corresponds to specifying a direction. <b>Two-tailed</b> <b>tests</b> are only applicable when there are two tails, such as in the normal distribution, and correspond to considering either direction significant.|$|R
5000|$|... scipy.stats.binom_test(51, 235, 1.0/6, alternative='two-sided') (<b>two-tailed</b> <b>test)</b> ...|$|E
5000|$|... #Caption: A <b>two-tailed</b> <b>test</b> {{applied to}} the normal distribution.|$|E
50|$|The {{use of a}} {{one-tailed test}} is {{dependent}} on whether the research question or alternative hypothesis specifies a direction such as whether a group of objects is heavier or the performance of students on an assessment is better. A <b>two-tailed</b> <b>test</b> may still be used {{but it will be}} less powerful than a one-tailed test because the rejection region for a one-tailed test is concentrated {{on one end of the}} null distribution and is twice the size (5% vs. 2.5%) of each rejection region for a <b>two-tailed</b> <b>test.</b> As a result, the null hypothesis can be rejected with a less extreme result if a one-tailed test was used. The one-tailed test is only more powerful than a <b>two-tailed</b> <b>test</b> if the specified direction of the alternative hypothesis is correct. If it is wrong, however, then the one-tailed test has no power.|$|E
30|$|Differences were {{evaluated}} using the χ 2 -test, Student’s t test, or Welch’s t test. Factors {{that were not}} normally distributed {{were evaluated}} by Welch’s t test. Predictors of SVR 12 and viral relapse after treatment completion were evaluated using multivariate logistic regression analyses. Odds ratios (ORs) and 95  % confidence intervals were also calculated. All p values < 0.05 on <b>two-tailed</b> <b>testing</b> were considered significant. Data were statistically analyzed using SPSS software ver. 18.|$|R
50|$|One-tailed {{tests are}} used for {{asymmetric}} distributions that have a single tail, such as the chi-squared distribution, which are common in measuring goodness-of-fit, or for {{one side of a}} distribution that has two tails, such as the normal distribution, which is common in estimating location; this corresponds to specifying a direction. <b>Two-tailed</b> <b>tests</b> are only applicable when there are two tails, such as in the normal distribution, and correspond to considering either direction significant.|$|R
30|$|Table 2. Species exhibiting {{significantly}} (P < 0.05, <b>two-tailed</b> t <b>tests)</b> greater emergence {{after treatment}} with 10 % (vol/vol) aqueous smoke.|$|R
5000|$|In the {{approach}} of Ronald Fisher, the null hypothesis H0 will be rejected when the p-value of the test statistic is sufficiently extreme (vis-a-vis the test statistic's sampling distribution) and thus judged unlikely {{to be the result}} of chance. In a one-tailed test, [...] "extreme" [...] is decided beforehand as either meaning [...] "sufficiently small" [...] or meaning [...] "sufficiently large" [...] - values in the other direction are considered not significant. In a <b>two-tailed</b> <b>test,</b> [...] "extreme" [...] means [...] "either sufficiently small or sufficiently large", and values in either direction are considered significant. For a given test statistic there is a single <b>two-tailed</b> <b>test,</b> and two one-tailed tests, one each for either direction. Given data of a given significance level in a <b>two-tailed</b> <b>test</b> for a test statistic, in the corresponding one-tailed tests for the same test statistic it will be considered either twice as significant (half the p-value), if the data is in the direction specified by the test, or not significant at all (p-value above 0.05), if the data is in the direction opposite that specified by the test.|$|E
5000|$|... #Caption: In a <b>two-tailed</b> <b>test,</b> the {{rejection}} region for a significance level of α=0.05 is partitioned to {{both ends of}} the sampling distribution and makes up 5% of the area under the curve (white areas).|$|E
50|$|In Dunnett's test {{we can use}} {{a common}} table of {{critical}} values, but more flexible options are nowadays readily available in many statistics packages such as R. The critical values for any given percentage point depend on: whether a one- or- <b>two-tailed</b> <b>test</b> is performed; the number of groups being compared; {{the overall number of}} trials.|$|E
30|$|Data were {{presented}} as mean[*]±[*]SD unless otherwise stated. Statistical significance was determined using a <b>two-tailed</b> student’s <b>test</b> (P[*]<[*] 0.05) unless otherwise stated.|$|R
5000|$|When {{there are}} exactly two {{treatments}} the Cochran Q test {{is equivalent to}} McNemar's test, which is itself equivalent to a <b>two-tailed</b> sign <b>test.</b>|$|R
30|$|Descriptive statistics, {{including}} {{mean scores}} and proportions, {{were calculated for}} the items and scales, as applicable. The IBDQ, EQ- 5 D, MOS-SFS, WHO-HPQ, and HADS were scored according to scoring instructions of the developer. EQ- 5 D scores were calculated using UK weights. Selected item-level and scale scores were compared using Wilcoxon–Mann–Whitney test or Chi square, as applicable. All comparisons were <b>tested</b> using <b>two-tailed</b> <b>tests</b> at α =  0.05. All analyses were performed using SAS Enterprise Guide Version 4.3 (Cary, NC, USA).|$|R
