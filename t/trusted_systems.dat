87|1907|Public
50|$|Global Distribution System Link (GDS Link) in Monaco is the <b>trusted</b> <b>systems</b> {{partner of}} CIBI.|$|E
50|$|In public policy, {{authorization}} is {{a feature}} of <b>trusted</b> <b>systems</b> used for security or social control.|$|E
5000|$|A {{mandatory}} subtype policy, {{which allows}} {{some of the}} functionality of <b>trusted</b> <b>systems</b> which support a full type enforcement or domain-type enforcement policy; ...|$|E
40|$|Abstract—This paper {{discusses}} {{the use of}} a communications net-work security device, called a <b>trust</b> <b>system,</b> to enhance supervisory control and data-acquisition (SCADA) security. The major goal of the <b>trust</b> <b>system</b> is to increase security with minimal impact on ex-isting utility communication systems. A previous paper focused on the technical operation of the <b>trust</b> <b>system</b> by augmenting routers to protect User Datagram Protocol (UDP) -based traffic. This paper concentrates on placing the <b>trust</b> <b>system</b> into a broader context, creates new <b>trust</b> <b>system</b> implementations to increase its flexibility, and demonstrates the <b>trust</b> <b>system</b> using TCP traffic. Specifically, the article expands on previous work in the following ways: 1) the article summarizes major threats against SCADA systems; 2) it discusses new <b>trust</b> <b>system</b> implementations, which allow the <b>trust</b> <b>system</b> to be used with a wider array of network-enabled equip-ment; 3) it discusses key SCADA security issues in the literature and shows how the <b>trust</b> <b>system</b> responds to such issues; 4) the paper shows the impact of the <b>trust</b> <b>system</b> when widely prevalent TCP/IP network communication is used; and 5) finally, the paper discusses a new hypothetical scenario to illustrate the protection that a <b>trust</b> <b>system</b> provides against insider threats. Index Terms—Computer network security, computer networks, power system security, supervisory control and data-acquisition (SCADA) systems. I...|$|R
40|$|ABSTRACT This paper {{analyzes}} the “camel <b>trust</b> <b>system</b> ” (dabare) of the Gabra, pastoral-ists in the Eastern Province of Kenya. The camel <b>trust</b> <b>system</b> creates the multiple {{networks in the}} Gabra society. This paper describes the <b>trust</b> <b>system</b> and {{analyzes the}} relationships which {{are found in the}} multiple networks. Then, how the <b>trust</b> <b>system</b> makes Gabra imagine the reality of their ethnicity and clanship is discussed...|$|R
50|$|In the {{security}} engineering subspecialty of computer science, a <b>trusted</b> <b>system</b> {{is a system}} that is relied upon to a specified extent to enforce a specified security policy. This is equivalent to saying that a <b>trusted</b> <b>system</b> is one whose failure would break a security policy (if a policy exists that the <b>trusted</b> <b>system</b> is <b>trusted</b> to enforce).|$|R
50|$|The Trusted Computing Group creates {{specifications}} {{that are}} meant to address particular requirements of <b>trusted</b> <b>systems,</b> including attestation of configuration and safe storage of sensitive information.|$|E
50|$|An {{introduction}} to the calculus of trust (Example: 'If I connect two <b>trusted</b> <b>systems,</b> are they more or less trusted when taken together?') is given in.|$|E
5000|$|Gillespie, Tarleton. [...] "Copyright and Commerce: The DCMA, <b>Trusted</b> <b>Systems,</b> and the Stabilization of Distribution." [...] The Information Society. (v20n4, September 2004: 239-254, {{available}} at: http://hdl.handle.net/1813/3473 ...|$|E
40|$|Feedback {{plays an}} {{important}} role in P 2 P <b>trust</b> <b>systems.</b> Existing <b>trust</b> <b>systems</b> usually assume that most of normal peers have idealized feedback behaviors, that is, peers can provide honest feedback after download immediately. However, studies show that feedback sparsity and delay widely exist in a real P 2 P network. Unfortunately, their effect on <b>trust</b> <b>systems</b> has received little attention in previous researches. In this paper, we propose a feedback model considering feedback ratio and feedback delay to analyze the effect. We find that most <b>trust</b> <b>systems</b> have poor reliability when the number of feedbacks is small in a decentralized P 2 P network. We propose an implicit feedback mechanism based on the retention time of files to remove the impact of user feedback on <b>trust</b> <b>systems.</b> Simulation results show that <b>trust</b> <b>systems</b> using implicit feedback can not only effectively isolate normal peers from malicious peers but also provide differential services for normal peers with different behaviors. </p...|$|R
40|$|This paper {{analyzes}} the "camel trust system" (dabare) of the Gabra, pastoralists in the Eastern Province of Kenya. The camel <b>trust</b> <b>system</b> creates the multiple {{networks in the}} Gabra society. This paper describes the <b>trust</b> <b>system</b> and {{analyzes the}} relationships which {{are found in the}} multiple networks. Then, how the <b>trust</b> <b>system</b> makes Gabra imagine the reality of their ethnicity and clanship is discussed...|$|R
40|$|Abstract: In an open P 2 P network environment, it’s full {{of various}} {{malicious}} actions,dishonesty, deceit, selfish and so on. So it’s necessary {{to build a}} robust <b>trust</b> manage <b>system</b> to keep the community run healthily. There are mainly two kinds of <b>trust</b> <b>system,</b> one is based on Global <b>Trust.</b> the <b>system</b> maintains a Global Trust value for every peer. The other one is based on peer itself, it rates the object peer trust according to historical transactions between them or recommendation from the other peers. Because the second <b>trust</b> manage <b>system</b> mainly bases on Fuzzy algorithm, we call it Fuzzy <b>Trust</b> <b>system.</b> The paper will focus on Fuzzy <b>Trust</b> <b>system,</b> we will introduce the related algorithms and involve Outlier Identification algorithm to alleviate the risk from malicious action. 1...|$|R
50|$|In public policy, {{access control}} to {{restrict}} access to systems ("authorization") or to track or monitor behavior within systems ("accountability") is an implementation feature of using <b>trusted</b> <b>systems</b> for security or social control.|$|E
50|$|She was {{a faculty}} member at Stanford University for the Electrical Engineering and Computer Science Departments for 10 years. Her {{research}} interests include distributed systems, performance analysis, and <b>trusted</b> <b>systems</b> for electronic commerce and she published numerous articles and patents on her research.|$|E
50|$|<b>Trusted</b> <b>systems</b> in {{the context}} of {{information}} theory is based on the definition of trust as ''''Trust is that which is essential to a communication channel but cannot be transferred from a source to a destination using that channel'''' by Ed Gerck.|$|E
40|$|Part 1 : Full PapersInternational audienceCryptographic {{mechanisms}} {{alone are}} insufficient to protect Wireless Sensor Networks (WSNs), because sensors are deployed {{for long periods}} in hostile environments where {{it is possible for}} an adversary to physically take over a sensor and obtain access to the cryptographic keys stored in the sensor’s internal memory. Thus, reputation-based <b>trust</b> <b>systems</b> are employed to detect abnormal activities and enhance the trustworthiness among sensors. Unfortunately, existing reputation-based <b>trust</b> <b>systems</b> for WSNs do not investigate the robustness against WSN-related or reputation-related attacks. This paper provides a comprehensive analysis for current reputation-based <b>trust</b> <b>systems</b> by surveying the current “state-of-the-art” work in this area...|$|R
5000|$|Life-cycle Assurance : Security Testing, Design Specification and Verification, Configuration Management and <b>Trusted</b> <b>System</b> Distribution ...|$|R
40|$|Abstract. This paper {{proposes a}} {{protection}} mechanism called <b>trust</b> <b>system.</b> The {{purpose of this}} article is to enhance supervisory control and data-acquisition (SCADA) security with minimal impact on our existing power communication systems. This paper concentrates on placing <b>trust</b> <b>system</b> into our existing power system and creates new security system implementations to increase its flexibility. What’s more, the SCADA security issues between electric utilities are also discussed...|$|R
50|$|<b>Trusted</b> <b>systems</b> in {{the context}} of {{national}} or homeland security, law enforcement, or social control policy are systems in which some conditional prediction about the behavior of people or objects within the system has been determined prior to authorizing access to system resources.|$|E
5000|$|Policy {{appliances}} are {{technical control}} and logging mechanisms to enforce or reconcile policy rules (information use rules) {{and to ensure}} accountability in information systems. [...] Policy appliances {{can be used to}} enforce policy or other systems constraints within and among <b>trusted</b> <b>systems.</b>|$|E
50|$|The above {{examples}} {{show that}} if <b>trusted</b> <b>systems</b> (and look-alikes) intend {{to play an}} important role in the future without intruding on anonymity, etc., one will have to incorporate these values as gaps in the architecture of these systems. It is, however, doubtful whether this will happen.|$|E
40|$|Abstract: The reputation-based trust {{mechanism}} {{is a way}} to assess the trustworthiness of offered services, based on the feedback obtained from their users. In the absence of appropriate safeguards, service users can still manipulate this feedback. Auction mechanisms have already addressed the problem of manipulation by market-trading participants. When auction mechanisms are applied to <b>trust</b> <b>systems,</b> their interaction with the <b>trust</b> <b>systems</b> and associated overhead need to be quantitatively evaluated. This paper proposes two distributed architectures based on centralized and hybrid computing for integrating an auction mechanism with the <b>trust</b> <b>systems.</b> The empirical evaluation demonstrates how the architectures help to discourage users from giving untruthful feedback and reduce the overhead costs of the auction mechanisms. Key words: trust systems; software architecture; economic mechanisms...|$|R
50|$|GNUnet {{provides}} <b>trust</b> <b>system</b> {{based on}} excess-based economic model. The idea of employing economic system {{is taken from}} MojoNation network.|$|R
40|$|A Delay Tolerant Network (DTN) is {{one where}} nodes can be highly mobile, with long message delay times forming dynamic and {{fragmented}} networks. Traditional centralised network security is difficult to implement in such a network, therefore distributed security solutions are more desirable in DTN implementations. Establishing effective <b>trust</b> in distributed <b>systems</b> with no centralised Public Key Infrastructure (PKI) such as the Pretty Good Privacy (PGP) scheme usually requires human intervention. Our aim is to build and compare different de- centralised <b>trust</b> <b>systems</b> for implementation in autonomous DTN systems. In this paper, we utilise a key distribution model based on the Web of Trust principle, and employ a simple leverage of common friends <b>trust</b> <b>system</b> to establish initial trust in autonomous DTN’s. We compare this system with two other methods of autonomously establishing initial trust by introducing a malicious node and measuring the distribution of malicious and fake keys. Our {{results show that the}} new <b>trust</b> <b>system</b> not only mitigates the distribution of fake malicious keys by 40 % {{at the end of the}} simulation, but it also improved key distribution between nodes. This paper contributes a comparison of three de-centralised <b>trust</b> <b>systems</b> that can be employed in autonomous DTN systems...|$|R
50|$|These {{standards}} {{describe a}} process of evaluation for <b>trusted</b> <b>systems.</b> In some cases, U.S. government entities (as well as private firms) would require formal validation of computer technology using this process {{as part of their}} procurement criteria. Many of these standards have influenced, and have been superseded by, the Common Criteria.|$|E
50|$|Mark Stefik, a {{researcher}} at Xerox PARC, {{is known as the}} originator of the concepts that became the XrML language. Stefik was engaged in research on the topic of <b>trusted</b> <b>systems</b> for secure digital commerce, of which one part was a language to express the rights that the system would allow users to perform on digital resources.|$|E
50|$|Trusted Computing (TC) is a {{technology}} developed and {{promoted by the}} Trusted Computing Group. The term is taken {{from the field of}} <b>trusted</b> <b>systems</b> and has a specialized meaning. With Trusted Computing, the computer will consistently behave in expected ways, and those behaviors will be enforced by computer hardware and software. Enforcing this behavior is achieved by loading the hardware with a unique encryption key inaccessible {{to the rest of the}} system.|$|E
5000|$|Trusted Computing {{encompasses}} six {{key technology}} concepts, of which all {{are required for}} a fully <b>Trusted</b> <b>system,</b> that is, a system compliant to the TCG specifications: ...|$|R
40|$|E-test is {{that test}} {{performed}} {{over the internet}} inwhich questions and solutions are computer files rather thansheets of paper. The application of e-test as a perspectiveknowledge measurement is apparent. But, security for suchscheme is not obvious. Thus {{in this article we}} introduce asecure e-test scheme with wireless networks. In addition, wesuggest a swapping technique between test application andtest security. The main contribution of the proposed schemeis to overcoming of the limitations in the milieu <b>trust</b> <b>system.</b> We are claimed that the proposed scheme is efficient andmore flexible than the milieu <b>trust</b> <b>system...</b>|$|R
40|$|The {{design of}} a <b>trusted</b> <b>system</b> based on the Trusted Computing Group’s Trusted Platform Module (TPM) was {{analyzed}} to understand the role and trust relationships of the TPM, firmware, and software modules involved. The objective was {{to confirm that the}} measurements stored and reported by the TPM can successfully discriminate a normal boot sequence, which leaves <b>trusted</b> <b>system</b> software in control, from an insecure one, where some trusted modules might have been replaced by malicious ones. The principal tool used in the analysis was the SMV symbolic model checker. ...|$|R
50|$|The main {{security}} feature that sets STOP apart from most operating systems is the mandatory sensitivity policy. Support for a mandatory integrity policy, also sets STOP apart from most MLS or <b>trusted</b> <b>systems.</b> While a sensitivity policy deals with preventing unauthorized disclosure, an integrity policy deals with preventing unauthorized deletion or modification (such as {{the damage that}} a virus might attempt). Normal (i.e., untrusted) users {{do not have the}} discretion to change the sensitivity or integrity levels of objects. The Bell-LaPadula and Biba formal models are the basis for these policies.|$|E
5000|$|This was a {{security}} initiative {{directed by the}} University of Pennsylvania Distributed Systems Laboratory and paid for through the Composable High Assurance <b>Trusted</b> <b>Systems</b> programme. POSSE was a US$2,125,000 grant [...] "to introduce advanced security features used in special-purpose government computers into standard office PCs." [...] The United States government hoped {{to benefit from the}} availability of better security features in affordable, standardized computers and software. OpenBSD was selected as [...] "the computing world’s most secure forum for the development of open-source software" [...] and approximately US$1,000,000 was allotted to its development.|$|E
5000|$|A {{subset of}} <b>trusted</b> <b>systems</b> ("Division B" [...] and [...] "Division A") {{implement}} {{mandatory access control}} labels; as such, it is often assumed {{that they can be}} used for processing classified information. However, this is generally untrue. There are four modes in which one can operate a multilevel secure system (viz.., multilevel mode, compartmented mode, dedicated mode, and system-high mode) and, as specified by the National Computer Security Center's [...] "Yellow Book," [...] B3 and A1 systems can only be used for processing a strict subset of security labels, and only when operated according to a particularly strict configuration.|$|E
30|$|Tackling with security-related characteristics, the {{proposed}} routing solution will specify trust metrics {{that will be}} able to investigate and exclude malicious nodes from the traversed path to the destination node (VGW). The attacks that a <b>trust</b> management <b>system</b> can detect depend on the number and type of node behavior aspects that are monitored [39] and range from network up to application layer attacks (data inconsistency). Trading off hardware resource requirements for the realization of the <b>trust</b> <b>system</b> and mitigation of the most probable attacks, the VSN <b>trust</b> <b>system</b> will be capable of detecting the black-hole, selective forwarding, denial of routing service, and selfish behavior attack. All these attacks lead to data loss which (when systematic) lead to loss of connectivity.|$|R
50|$|Metavante {{products}} and services drive account processing for deposit, loan and <b>trust</b> <b>systems,</b> image-based and conventional check processing, electronic funds transfer, consumer healthcare payments, and electronic presentment and payment.|$|R
5000|$|... 2008 - Anna Kournikova Deleted By Memeright <b>Trusted</b> <b>System</b> - Art in the Age of Intellectual Property. Postcapital Archive. Hartware MedienKunstVerein, PHOENIX Halle Dortmund, Germany. Curated by: Inke Arns and Francis Hunger ...|$|R
