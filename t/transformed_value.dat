22|1047|Public
5000|$|Critical {{values for}} the gamma {{statistic}} are sometimes found by using an approximation, whereby a <b>transformed</b> <b>value,</b> t of the statistic is referred to Student t distribution, where ...|$|E
5000|$|If [...] is {{invariant}} {{under the}} group [...] then the loss function [...] {{is said to}} be invariant under [...] if for every [...] and [...] there exists an [...] such that [...] for all [...] The <b>transformed</b> <b>value</b> [...] will be denoted by [...]|$|E
50|$|For example, {{suppose we}} observe r = 0.3 {{with a sample}} size of n=50, and we wish to obtain a 95% {{confidence}} interval for ρ. The <b>transformed</b> <b>value</b> is artanh(r) = 0.30952, so the confidence interval on the transformed scale is 0.30952 ± 1.96/√47, or (0.023624, 0.595415). Converting back to the correlation scale yields (0.024, 0.534).|$|E
5000|$|LISTAGG: A {{function}} to <b>transform</b> <b>values</b> {{from a group}} of rows into a delimited string ...|$|R
40|$|Abstract In {{order to}} numerically invert Laplace {{transforms}} to calculate probability density functions (pdf's) and cumulative distribution functions (cdf's) in queueing and related models, {{we need to}} be able to calculate the Laplace <b>transform</b> <b>values.</b> In many cases the desired Laplace <b>transform</b> <b>values</b> (e. g., of a waiting-time cdf) can be computed when the Laplace <b>transform</b> <b>values</b> of component pdf's (e. g., of a service-time pdf) can be computed. However, there are few explicit expressions for Laplace transforms of component pdf's available when the pdf does not have a pure exponential tail. In order to remedy this problem, we propose the construction of infinite-series representations for Laplace transforms of pdf's and show how they can be used to calculate <b>transform</b> <b>values.</b> We use the Laplace transforms of exponential pdf's, Laguerre functions and Erlang pdf's as basis elements in the series representations. We develop several specific parametric families of pdf's in this infinite-series framework. We show how to determine the asymptotic form of the pdf from the series representation and how to truncate so as to preserve the asymptotic form for a time of interest. 1...|$|R
40|$|Algorithm 662 of the ACM TOMS {{library is}} a {{software}} package, {{based on the}} Weeks method, which is used for calculating function values of the inverse Laplace transform. The software requires <b>transform</b> <b>values</b> at arbitrary points in the complex plane. We developed a software package, called ReLIADiff, which is a modification of Algorithm 662 using <b>transform</b> <b>values</b> at arbitrary points on real axis. ReLIADiff, implemented in C++, relies on TADIFF software package designed for Algorithmic Differentiation. In this article we present ReLIADiff focusing on its design principles, performance and use...|$|R
5000|$|If {{we observe}} {{a set of}} n values X1, ..., Xn with no ties (i.e., there are n {{distinct}} values), we can replace Xi with the <b>transformed</b> <b>value</b> Yi = k, where k is defined such that Xi is the kth largest among all the X values. This is called the rank transform, and creates data with a perfect fit to a uniform distribution. This approach has a population analogue.|$|E
5000|$|In statistics, data {{transformation}} is {{the application of}} a deterministic mathematical function to each point in a data set [...] - [...] that is, each data point zi is replaced with the <b>transformed</b> <b>value</b> yi = f(zi), where f is a function. Transforms are usually applied so that the data appear to more closely meet the assumptions of a statistical inference procedure that is to be applied, or to improve the interpretability or appearance of graphs.|$|E
50|$|In electrodynamics and quantum electrodynamics, in {{addition}} to the global U(1) symmetry related to the electric charge, there are also position dependent gauge transformations. Noether's theorem states that for every infinitesimal symmetry transformation that is local (local {{in the sense that the}} <b>transformed</b> <b>value</b> of a field at a given point only depends on the field configuration in an arbitrarily small neighborhood of that point), there is a corresponding conserved charge called the Noether charge, which is the space integral of a Noether density (assuming the integral converges and there is a Noether current satisfying the continuity equation).|$|E
40|$|Simple {{geometric}} representations show symmetry and periodicity {{of discrete}} Fourier transforms (DFT's). Help in visualizing requirements for storing and manipulating <b>transform</b> <b>value</b> in computations. Representations useful {{in any number}} of dimensions, but particularly in one-, two-, and three-dimensional cases often encountered in practice...|$|R
3000|$|... {{are then}} {{used in the}} {{evaluation}} of the energy functional. It should be emphasised that the values of h and Φ do not change and that the original candidate contour and image remain intact: their <b>transformed</b> <b>values</b> are used exclusively for evaluating energy functionals.|$|R
40|$|Abstract — It {{is often}} {{possible}} to effectively calculate probability density functions (pdf’s) and cumulative distribution functions (cdf’s) by numerically inverting Laplace transforms. However, {{to do so}} {{it is necessary to}} compute the Laplace <b>transform</b> <b>values.</b> Unfortunately, convenient explicit expressions for required transforms are often unavailable for component pdf’s in a probability model. In that event, we show that it is sometimes possible to find continuedfraction representations for required Laplace transforms that can serve as a basis for computing the <b>transform</b> <b>values</b> needed in the inversion algorithm. This property is very likely to prevail for completely monotone pdf’s, because their Laplace transforms have special continued fractions called S fractions, which have desirable convergence properties. We illustrate the approach by considering application...|$|R
5000|$|Let's {{just assume}} for {{simplicity}} {{here that the}} symmetry in question is local (not local {{in the sense of}} a gauge symmetry, but in the sense that the <b>transformed</b> <b>value</b> of the field at any given point under an infinitesimal transformation would only depend on the field configuration over an arbitrarily small neighborhood of the point in question). Let's also assume that the action is local in the sense that it is the integral over spacetime of a Lagrangian, and thatfor some function [...] where [...] only depends locally on [...] (and possibly the spacetime position).|$|E
40|$|We {{propose the}} use of the cubic {{transformation}} for public-key applications and digital signatures. Transformations modulo a prime p or a composite n = pq, where p and q are primes, are used in such a fashion that each <b>transformed</b> <b>value</b> has only 3 roots that makes it a more efficient transformation than the squaring transformation of Rabin, which has 4 roots. Such a transformation, together with additional tag information, makes it possible to uniquely invert each <b>transformed</b> <b>value.</b> The method may be used for other exponents as well...|$|E
40|$|Abstract. This note proposes {{the use of}} the cubic {{transformation}} for public-key {{applications and}} random event and number generation, in a manner akin to the Rabin cipher. Transformations modulo a prime p or a composite n = pq, where p and q are primes, are so used that each <b>transformed</b> <b>value</b> has only three roots. Such a transformation, together with additional tag information, makes it possible to uniquely invert each <b>transformed</b> <b>value.</b> The effectiveness of the method as a random number generator (used in a variant with nine roots) {{comes from the fact that}} the cryptanalyst must contend with a ninefold branching at each step. Key words: Public-key cryptography, random number generation, cubic transformation. 1...|$|E
30|$|A log {{reduction}} (LR) per experiment {{was calculated by}} subtracting {{the average of the}} log 10 <b>transformed</b> <b>values</b> from micropatterned surfaces from the average of the log 10 <b>transformed</b> <b>values</b> from unpatterned surfaces. After confirming the normality of the {{log reduction}}s by residual and normal probability plots, the mean log reduction was interpreted as the median percent reduction with the equation: 1 - 10 (-LR). Statistical significance of the reductions were assessed using a 1 -sided t-test of log reductions compared to zero. Estimates of variances and Tukey tests were assessed using an ANOVA model of the log transformed data for each unpatterned control sample and micropatterned sample, with a random effect for experiment [47]. All analyses were performed using the statistical software MiniTab 16.|$|R
40|$|This paper {{describes}} {{methods for}} adapting the scanning order through wavelet <b>transform</b> <b>values</b> {{used in the}} Wavelet Difference Reduction (WDR) algorithm of Tian and Wells. These new methods are called Adaptively Scanned Wavelet Difference Reduction (ASWDR). ASWDR adapts the scanning procedure used by WDR in order to predict locations of significant <b>transform</b> <b>values</b> at half thresholds. These methods retain all of the important features of WDR: lowcomplexity, region of interest, embeddedness, and progressive SNR. They improve the rate-distortion performance of WDR {{so that it is}} essentially equal to that of the SPIHT algorithm of Said and Pearlman when arithmetic compression is not employed. When arithmetic compression is used, then the rate-distortion performance of the ASWDR algorithms is only slightly worse than SPIHT. The perceptual quality of ASWDR images is clearly superior to SPIHT. 1...|$|R
40|$|Color poster with text {{describing}} the new method of cryptography developed by Jacqueline Christy {{under the supervision}} of James S. Walker. A new method of cryptography was developed using randomly altering wavelet <b>transform</b> <b>values</b> of the plain text language. University of Wiconsin [...] Eau Claire Office of Research and Sponsored Programs...|$|R
30|$|The {{corrected}} {{mortality of}} the T. urticae females recorded at 72  h was transformed using the function \(y = ar\sin \sqrt p\), where p is the mortality ratio, and “y” is the <b>transformed</b> <b>value.</b> To assess the {{significant differences between}} treatments, analysis of variance (ANOVA) and Tukey’s multiple comparison test were used. Logistic regression models were fitted using the generalized linear model technique assuming a binomial distribution and using the logit link function to determine the median lethal dose (LC 50) {{at different times of}} evaluation. The analyses were performed in the statistical language R, version 3.1. 2 (Grainge and Ahmesds 1988).|$|E
30|$|These {{are useful}} in {{checking}} estimates, as discussed later. The values of p and q determine {{the shape of the}} standard beta distribution. For the mode {{to be in the middle}} of the range of θ, p and q must be equal. Values of q much smaller or larger than p (provided both > 1) skew the distribution to the right or left. If the lower and upper bounds of the actual distribution are [a,[*]b], respectively, rather than the [0, 1] values of the standard distribution, the scale value (b[*]−[*]a) stretches (or contracts) the distribution and the location value (a) shifts the starting point of the distribution. The <b>transformed</b> <b>value</b> of the random variable, y, is given by y[*]=[*]a[*]+[*]θ[*](b[*]−[*]a).|$|E
3000|$|It {{is common}} to report grain-size {{fractions}} in percentages, but such data are not independent, because they must sum to 100 %. Compositional data such as mud and gravel fractions are therefore difficult to use in statistical analyses as they are (Aitchison 1986, 2003; Aitchison and Egozcue 2005). Aitchison (1986, 2003) proposed, instead, to evaluate the relative magnitudes of constituents in comparison to other compositional variables and to use logarithms to simplify the computation of the variance and covariance. After taking logarithms, the resulting transformed values are free to vary over {{the entire range of}} real numbers. However, a zero value in the compositional data prohibits log-ratio transformation, because the <b>transformed</b> <b>value</b> is −∞, and therefore cannot be included in the statistical analysis. In order to avoid this problem, a multiplicative approach (Martín-Fernández et al. 2003) replaces a zero value with a value that is sufficiently small, as follows: [...]...|$|E
40|$|Iteration stops when R-squared changes by {{less than}} delrsq in 3 {{consecutive}} iterations (default 0. 01). 1 2 avas Value A structure with the following components: x the input x matrix. y the input y vector. tx the <b>transformed</b> x <b>values.</b> ty the <b>transformed</b> y <b>values.</b> rsq the multiple R-squared <b>value</b> for the <b>transformed</b> <b>values.</b> l not used in this version of ace m not used in this version of ace References Breiman and Friedman, Journal of the American Statistical Association (September, 1985). The R code is adapted from S code for avas() by Tibshirani, in the Statlib S archive; the FORTRAN is a double-precision version of FORTRAN code by Friedman and Spector in the Statlib general archive. Examples TWOPI <- 8 *atan(1) x <- runif(200, 0,TWOPI) y <- exp(sin(x) +rnorm(200) / 2) a <- ace(x,y) p...|$|R
40|$|This paper {{reports from}} {{preparations}} {{in an ongoing}} research study concerning how digital service innovation <b>transforms</b> <b>value</b> networks in manufacturing industries. The research study is {{in the context of}} the vehicle industry and concerns digital e-maintenance services based on remote diagnostics systems. This digital service innovation in particular is of great importance since manufacturing industries have great potential to expand their business and found new and extended boundaries and relationships with other stakeholder in a network they are attached to. Core challenges and opportunities for digital service innovation will lead us to the study of its influence on the business and innovation environment i. e. the value network. This paper presents a framework to study how digital service innovation <b>transforms</b> <b>value</b> networks based on literature reviews on value network, digital innovation and transformation of value networks...|$|R
5000|$|Slightly out of {{the usual}} sign {{conventions}} for Legendre <b>transforms,</b> the <b>value</b> ...|$|R
40|$|Nineteen {{patients}} with juvenile chronic arthritis were followed up and serum IgG subclass concentrations measured {{at different stages}} of disease activity. Patients were divided into three groups according to clinical activity of the disease: active disease, partial remission, and remission. The results were compared with normal values obtained in 448 healthy children aged 6 months to 18 years with a homogeneous distribution for each year of age. Serum IgG subclass concentrations of each child were first log transformed and then age corrected, taking the deviation of the log <b>transformed</b> <b>value</b> from that expected for a child of the same age. It was found that {{patients with}} partial remission had increased concentrations of IgG 2 and decreased concentrations of IgG 1 compared with patients with active disease. This suggests that the remission inducing process, at least in juvenile chronic arthritis, is accompanied by a switch of IgG subclass production...|$|E
40|$|The {{objective}} {{of this study was}} to develop a tablet pc application that allows generation of value stream maps across multiple clinical environments. As part of this objective, a methodology was put in place to reduce barriers for using a systems engineering approach in the medical field. The overall intent of using value stream mapping tools and lean philosophies in the medical environment is to begin the process of standardization among different medical centers. An interdisciplinary team of Medical Doctors, Clinical Researchers, and Industrial Engineers created a <b>transformed</b> <b>Value</b> Stream Mapping Application that can be easily used in the management of injured patients. Initial testing demonstrated that there was high inter-rater reliability in application use. This study showed that a systems engineering approach is highly relevant in the medical field and that the developed application can be used for the generation of future research data and for ongoing decision support assisted hospital quality improvement efforts...|$|E
40|$|ABSTRACT. The {{purpose of}} this work is to employ trainable neural {{networks}} to start solving the problem facing the designers and users of computer psychological tests: Culturail, national and social adaptation of tests. Mathematical construction of up-to-date objective diagnostic tests is based on comparison, of revealed condition with the norm, standard [3]. It is understandable that the norms worked out for one socio-cultural group are not necessarily such for an other. By way of example {{it is possible to}} cite the difficulties to be reckoned with in adapting foreign techniques. Neural networks were successfully used for classical explicit diagnoses. The typical experiment is described. NEURAL NETWORK A neural network is a system of non-linear functional transformers for example f=:z/(c+lzl), where f is the output signal, x is the input signal and c is the characteristic of the transformer), connected by linear (of the form of f=Wx, where f is the <b>transformed</b> <b>value,</b> W is the weight of connection, x is the input value) connections- synapses. Neurons can be connected in different *) Address for correspondenc...|$|E
30|$|To {{involve some}} other well-testing {{variables}} in the estimation process, the <b>transformed</b> <b>values</b> of the model-related parameters are used as the targets for training the neural network models. To estimate the model-related parameters for a given pressure derivative plot using the trained neural networks, the network outputs are converted back to the expected variables using the proper equations.|$|R
30|$|In this example, we {{will use}} the same {{techniques}} introduced {{in the beginning of}} this chapter. The difference from the previous example is {{that we are going to}} use the <b>transformed</b> <b>values</b> to filter the weights in the directed network so that along the filtration, edges having large weights are born first as described in Sect.  3.4.|$|R
40|$|This paper {{shows that}} the ‘New Approach’ to the ‘problem of <b>transforming</b> <b>values</b> into prices’, first, is {{subjected}} to a crucial logical inconsistency and second, {{is not in a}} position to deal with the heterogeneous labour case. Thus, the paper proposes an approach, which overcomes these problems and concludes that values of commodities are their actual prices. ...|$|R
40|$|WO 2005006624 A UPAB: 20050321 NOVELTY - The {{arrangement}} has a first device (102) {{for processing}} a first block of discrete values using a first transformation rule {{to give a}} first <b>transformed</b> <b>value</b> block, a device (104) for rounding the first block of values, a device (106) for summing the rounded value block, a device (108) for processing the summed values with a second rule, a device (110) for rounding the resulting values and a device (112) for subtracting the second block of rounded transformed values from the first block of discrete values to give a block of integer output values of the transformed values. DETAILED DESCRIPTION - INDEPENDENT CLAIMS are also included for the following: (A) a method of converting discrete values into a transformed representation (B) a method of inverse conversion of a block of integer values and a block of summed values (C) a reverse transformation method (D) and a computer program with program code for implementing an inventive method. USE - For converting discrete values into a transformed representation of audio and/or image information. ADVANTAGE - Enables more efficient and more accurate conversion and inverse conversion...|$|E
40|$|Measured {{vertical}} {{gravity gradients}} usually quite {{differ from the}} normal value of 0. 3086 mGal/m (1 mGal = 10 – 5 ms – 2). Generally the changing of vertical gradient is rather big, up to a few 10 cm height above the ground and can {{be taken into consideration}} as a second order function. Over 40 m height the changing is linear and over 500 m height the changing is very small, the measured value of vertical gradient is about 0. 3073 mGal/m. At present the datum level (mGal level) of modern gravity networks are mostly determined by absolute gravity values measured by absolute gravimeters, which values are referred to the reference heights of absolute gravimeters. So the datum level (mGal level) of the network of absolute points differs from the datum level of the network of relative measurements. The vertical gradients can be used for the conversion of measured gravity from the reference height of an instrument to a bench mark. So the vertical gradients are playing a key role for joining the two types of network. The height correction is necessary to determine by an accuracy of several µGal, not to decrease the reliability of the <b>transformed</b> <b>value</b> of gravity. So the vertical gradients should be determined as high accuracy as it possible and using the normal value of vertical gradient (0. 3086 mGal/m) is not sufficient for this purpose...|$|E
40|$|Background: Analyses of {{longitudinal}} health-related {{quality of}} life data often exclude participants who die, which limits {{the generalizability of the}} results. Methods to incorporate death as a valid score in the Medical Outcomes Study Short-Form (SF- 36) have been suggested but need to be evaluated in other populations. Objectives: We sought to apply a method of transforming the SF- 36 Physical Component Score (PCS) to include death. A transformation to estimate the probability of being "healthy" in 3 years, based on the current PCS value, will be developed and validated. Subjects: Women in the Australian Longitudinal Study on Women's Health (ALSWH), ages 70 - 75 years at Survey 1 in 1996 (n = 12, 432), were followed-up at 3 yearly intervals for 6 years. Results: The transformation derived from the ALSWH data provides evidence that the methodology for transforming the PCS to account for deaths is sound. The 3 -year equation provided good estimates of the probability of being healthy in 3 years and the method allowed deaths to be included in an analysis of changes in health over time. Conclusions: For longitudinal studies involving the SF- 36 in which subjects have died, we support the recommendation that both the PCS and its <b>transformed</b> <b>value</b> which includes deaths should be analyzed to examine the influence of deaths on the study conclusions. Using study data to derive empirical parameters for the transformations may be appropriate for studies with follow-up intervals of other lengths...|$|E
3000|$|... are the eigenfunctions of the {{corresponding}} <b>transformed</b> boundary <b>value</b> problem, (1)-(3), with eigenvalues [...]...|$|R
3000|$|... {{is unique}} in that the {{interval}} of the <b>transformed</b> boundary <b>value</b> problem shrinks by one unit. Furthermore, {{a comparison of the}} original and <b>transformed</b> boundary <b>value</b> problems and their corresponding eigenvalues is given in Tables  1 and 2 in Section 4. In addition, the analogies between the hierarchy presented in this paper and that found in [2 – 4] are mentioned.|$|R
40|$|It {{is often}} {{possible}} to e#ectively calculate probability density functions (pdf's) and cumulative distribution functions (cdf's) by numerically inverting Laplace transforms. However, {{to do so}} {{it is necessary to}} compute the Laplace <b>transform</b> <b>values.</b> Unfortunately, convenient explicit expressions for required transforms are often unavailable for component pdf's in a probability model. In that event, we show that it is sometimes possible to find continuedfraction representations for required Laplace transforms that can serve as a basis for computing the <b>transform</b> <b>values</b> needed in the inversion algorithm. This property is very likely to prevail for completely monotone pdf 's, because their Laplace transforms have special continued fractions called S fractions, which have desirable convergence properties. We illustrate the approach by considering applications to compute first-passage-time cdf's in birth-and-death processes and various cdf's with non-exponential tails, which can be used to model service-time cdf's in queueing models. Included among these cdf's is the Pareto cdf...|$|R
