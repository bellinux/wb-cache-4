271|1066|Public
5000|$|Generalized {{and updated}} <b>Transient</b> <b>Fault</b> Handling Application Block ("Topaz") to help {{increasing}} resiliency to errors ...|$|E
5000|$|A <b>transient</b> <b>fault</b> is a {{fault that}} is no longer present if power is {{disconnected}} for a short time and then restored; or an insulation fault which only temporarily affects a device's dielectric properties which are restored after a short time. Many faults in overhead power lines are transient in nature. When a fault occurs, equipment used for power system protection operate to isolate the area of the fault. A <b>transient</b> <b>fault</b> will then clear and the power-line can be returned to service. Typical examples of transient faults include: ...|$|E
50|$|Momentary {{power outages}} are often caused by {{transient}} faults, such as lightning strikes or vegetation contacting a power line, and many utilities use reclosers to automatically restore power quickly after a <b>transient</b> <b>fault</b> has cleared.|$|E
5000|$|<b>Transient</b> <b>faults</b> {{are hard}} to detect, {{and there are no}} well defined faults to detect. Errors in RAM {{introduced}} by <b>transient</b> <b>faults</b> are often called software errors, the following examples are possible factors that will contribute to <b>transient</b> <b>faults</b> : ...|$|R
40|$|<b>Transient</b> <b>faults</b> {{became an}} {{increasing}} {{issue in the}} past few years as smaller geometries of newer, highly miniaturized, silicon manufacturing technologies brought to the mass-market failure mechanisms traditionally bound to niche markets as electronic equipments for avionic, space or nuclear applications. This chapter presents the origin of <b>transient</b> <b>faults,</b> it discusses the propagation mechanism, it outlines models devised to represent them and finally it discusses the state-of-the-art design techniques that can be used to detect and correct <b>transient</b> <b>faults.</b> The concepts of hardware, data and time redundancy are presented, and their implementations to cope with <b>transient</b> <b>faults</b> affecting storage elements, combinational logic and IP-cores (e. g., processor cores) typically found in a System-on-Chip are discusse...|$|R
40|$|A <b>transient</b> {{hardware}} <b>fault</b> {{occurs when}} an energetic particle strikes a transistor, {{causing it to}} change state. These faults do not cause permanent damage, but may result in incorrect program execution by altering signal transfers or stored values. While the likelihood that such <b>transient</b> <b>faults</b> will cause any significant damage may seem remote, {{over the last several}} years <b>transient</b> <b>faults</b> have caused costly failures in high-end machines at America Online, eBay, and the Los Alamos Neutron Science Center, among others [6, 44, 15]. Because susceptibility to <b>transient</b> <b>faults</b> is proportional to the size and density of transistors, the problem of <b>transient</b> <b>faults</b> will become increasingly important in the coming decades. This paper defines the first formal, type-theoretic framework for studying reliable computation in the presence of <b>transient</b> <b>faults.</b> More specifically, it defines λzap, a lambda calculus that exhibits intermittent data faults. In order to detect and recover from these faults, λzap programs replicate intermediate computations and use majority voting, thereby modeling software-based fault tolerance techniques studied extensively, but informally [10, 20, 30, 31, 32...|$|R
5000|$|A glitch is a {{short-lived}} fault in a system, {{such as a}} <b>transient</b> <b>fault</b> that corrects itself, {{making it difficult to}} troubleshoot. The term is particularly common in a computing and electronics industries, in circuit bending, as well as among players of video games. More generally, all types of systems including human organizations and nature experience glitches.|$|E
50|$|Transmission and {{distribution}} systems use an automatic re-close function which {{is commonly used}} on overhead lines to attempt to restore power {{in the event of}} a <b>transient</b> <b>fault.</b> This functionality is not as common on underground systems as faults there are typically of a persistent nature. Transient faults may still cause damage both at the site of the original fault or elsewhere in the network as fault current is generated.|$|E
50|$|A {{distributed}} {{algorithm is}} self-stabilizing if, starting from an arbitrary state, it {{is guaranteed to}} converge to a legitimate state and remain in a legitimate set of states thereafter. A state is legitimate if starting from this state the algorithm satisfies its specification. The property of self-stabilization enables a distributed algorithm to recover from a <b>transient</b> <b>fault</b> regardless of its nature. Moreover, a self-stabilizing algorithm {{does not have to}} be initialized as it eventually starts to behave correctly regardless of its initial state.|$|E
40|$|<b>Transient</b> <b>faults</b> {{are hard}} to be {{detected}} and located due to their unpredictable nature and short duration, {{and they are the}} dominant causations of system failures, which makes it necessary to consider transient fault-tolerant design in the development of modern safety-critical industrial system. In this paper an approach based on system theory is proposed to tolerate the <b>transient</b> <b>faults</b> in tunnel construction wireless monitoring and control systems (TCWMCS), in which the effects of <b>transient</b> <b>faults</b> are expressed by dysfunction of interactions among software applications. After analyzing the dysfunctional interactions of the system by the operational process model and educing the causes of dysfunction in the functional control diagram, a safety enhancement way was proposed for the designers, in which effictive safety constraints were set up to tolerate the <b>transient</b> <b>faults.</b> The experiment evaluation indicated that the effects of <b>transient</b> <b>faults</b> could be exposed by the causal factors of dysfunctional interactions and system safety could be enhanced by the enforcement of  appropriate constraints...|$|R
40|$|ISBN: 0769524060 This paper {{presents}} hardening techniques against <b>transient</b> <b>faults</b> for quasi delay insensitive (QDI) circuits. Because {{of their}} specific architecture, asynchronous circuits {{have a very}} different behavior than synchronous circuits in the presence of faults. We address the effects of <b>transient</b> <b>faults</b> in QDI circuits and describe consequences on the circuit behavior. Three techniques exploiting QDI circuit properties are proposed for hardening. These techniques improve the tolerance to <b>transient</b> <b>faults,</b> and make their detection easier. These techniques are compared in terms of efficiency and cost...|$|R
40|$|Scaling of {{very large}} scale {{integration}} (VLSI) technologies, coupled with increased integrated circuit complexity, will strongly increase {{the occurrence of}} <b>transient</b> <b>faults</b> (also known as soft errors) [1]. <b>Transient</b> <b>faults,</b> unlike manufacturing or design faults, do not occur consistently. Instead, these faults are caused by external events, such as electromagnetic interferences, powe...|$|R
5000|$|On 23 and 28 July Albert Einstein {{suffered}} a <b>transient</b> <b>fault</b> {{with two of}} its three computers, numbers 2 and 3. While only a single computer was required to operate the ATV, two out of the three were required for any [...] "mission critical" [...] operations. However, by 29 July a restart had been performed on both units, bringing {{all three of the}} ATVs computers back on-line without impacting the mission schedule. Transfer of fuel and oxidiser from the ATV to the Russian segment of the ISS took place on 1 August 2013 in an operation that took approximately 1.5 hours; this fuel allowed the ISS to adjust its orbit in the absence of docked vessels to perform reboosts. The pipelines were then purged to avoid any complications during Albert Einsteins undocking from the ISS.|$|E
5000|$|Residential {{customers}} in areas fed by affected {{overhead power lines}} can occasionally see the effects of an autorecloser in action. If the fault affects the customer's own distribution circuit, they may see one or several brief, complete outages followed by either normal operation (as the autorecloser succeeds in restoring power after a <b>transient</b> <b>fault</b> has cleared) or a complete outage of service (as the autorecloser exhausts its retries). If the fault is on an adjacent circuit, the customer may see several brief [...] "dips" [...] (sags) in voltage as the heavy fault current flows into the adjacent circuit and is interrupted one or more times. A typical manifestation would be the dip, or intermittent black-out, of domestic lighting during an electrical storm. Autorecloser action may result in electronic devices losing time settings, losing data in volatile memory, halting, restarting, or suffering damage due to power interruption. Owners of such equipment may need to protect electronic devices against the consequences of power interruptions and also power surges.|$|E
50|$|COMTRADE {{files are}} {{typically}} generated by Intelligent Electronic Devices (IEDs), {{such as an}} electronic protective relay, in electrical substations during power systems disturbances. These IEDs are monitoring the electrical characteristics of the power system by digitally sampling measurements of the current, voltage, power, frequency, etc. at a high speed. The IEDs then use digital signal processing algorithms on that data to detect abnormal conditions in the power system so that automated control actions {{can be taken to}} prevent damage to the power system. When faults are detected, the IEDs will record the digitized <b>transient</b> <b>fault</b> data that was used during processing into a file using the COMTRADE file format. Analysis tools can then download the COMTRADE file and calculate useful information related to the disturbance. For instance, a COMTRADE recording of the fault current absorbed by a transformer prior to the circuit breaker opening can be used to calculate the total energy dissipated by the transformer which helps the utility to more accurately estimate the impact of that fault on the lifetime of the transformer. COMTRADE files from multiple substations can be used collectively to perform forensic analysis of large scale power disturbance events (e.g. blackouts) to determine the root cause of the disturbance, help improve system protection and guide future mitigation strategies.|$|E
30|$|The <b>fault</b> model {{comprises}} <b>transient</b> <b>faults</b> {{that are}} unable to cause permanent failure of a system. <b>Transient</b> <b>faults</b> can occur {{for a number of}} reasons such as sending wrong and contradictory information, or receiving altered data during transmission. Transmitted packets may also get dropped for a variety of reasons such as link failure and channel interference.|$|R
40|$|International audienceSeveral {{architectures}} of Bulk Built-In Current Sensors (BBICS) {{were recently}} proposed to monitor <b>transient</b> <b>faults</b> induced on integrated circuits by radiation or malicious sources. This work compares {{for the first}} time all existing static BBICS architectures in terms of their sensitivities to detect <b>transient</b> <b>faults.</b> In addition, we propose a new static BBICS that presents better results of transient-fault detection sensitivity than previous sensor architectures...|$|R
40|$|New {{testing methods}} are {{required}} as {{the complexity of}} Field Programmable Gate Array (FPGA) designs grow rapidly and time-to-market demands shorten. In this {{paper we propose a}} new, physical fault injection method for the test of a system’s self-stabilizing property, that is its intrinsic ability to recover from <b>transient</b> <b>faults.</b> Therefore we inject <b>transient</b> <b>faults</b> in Look-Up Table (LUT) -based FPGA designs by dynamical, partial reconfiguration. 1...|$|R
40|$|<b>Transient</b> <b>fault</b> {{simulation}} is {{an important}} veri cation activity for circuits used in critical applications since such faults account for over 80 % of all system failures. This paper presents a timing level <b>transient</b> <b>fault</b> simulator that bridges the gap between electrical and gate-level <b>transient</b> <b>fault</b> simulators. A generic MOS circuit primitive and analytical solutions of node di erential equations are used to perform transistor level simulation with accurate MOS-FET models. The <b>transient</b> <b>fault</b> is modeled byapiecewise quadratic injected current waveform � this retains the electrical nature of the <b>transient</b> <b>fault</b> and provides SPICElike accuracy. Detailed comparisons with SPICE 3 show the accuracy of this technique and speedups of two orders of magnitude are observedforcircuits containing up to 2000 transistors. Latched error distributions of the benchmark circuits are alsoprovided. ...|$|E
40|$|This paper {{presents}} the results of a preliminary experiment to study the effectiveness of a fault-tolerant system's ability to handle transient faults. The primary goal of the experiment was to develop the techniques to measure the parameters needed for a reliability analysis of the SIFT computer system which includes th effects of transient faults. A key aspect of such an analysis is the determination of the effectiveness of the operating system's ability to discriminate between transient and permanent faults. A detailed description of the preliminary <b>transient</b> <b>fault</b> experiment along with the results from 297 <b>transient</b> <b>fault</b> injections are given. Although not enough data was obtained to draw statistically significant conclusions, the foundation has been laid for a large-scale <b>transient</b> <b>fault</b> experiment...|$|E
40|$|Technology {{trends are}} {{increasing}} {{the frequency of}} serious transient (soft) faults in digital systems. For example, ICs are becoming more susceptible to cosmic radiation, and are being embedded in applications with dynamic noisy environments. We propose a generic framework for representing such faults and characterizing them on-line. We formally define {{the impact of a}} <b>transient</b> <b>fault</b> in terms of three basic parameters: frequency, observability and severity. We distinguish fault modes in systems whose noise environment changes dynamically. Based on these ideas, the problem of designing on-line architectures for <b>transient</b> <b>fault</b> characterization is formulated and analyzed for several optimization goals. Finally, experiments are described that determine <b>transient</b> <b>fault</b> impact and the corresponding tests for various simulated fault modes of the ISCAS- 89 benchmark circuits...|$|E
40|$|Abstract—Reliability is an {{important}} design constraint in modern microprocessors, {{and one of the}} fundamental reliability challenges is combating the effects of <b>transient</b> <b>faults.</b> This requires extensive analysis, including significant fault modeling to allow architects to make informed reliability tradeoffs. Recent data shows that multi-bit <b>transient</b> <b>faults</b> are becoming more common, increasing from 0. 5 % of SRAM faults in 180 nm to 3. 9 % in 22 nm, and are predicted to be even more prevalent in smaller technology nodes. Therefore, accurately modeling the effects of multi-bit <b>transient</b> <b>faults</b> is increasingly important to the microprocessor design process. Architecture vulnerability factor (AVF) analysis is a method to model the effects of single-bit <b>transient</b> <b>faults.</b> In this paper, we propose a method to calculate AVFs for spatial multi-bit <b>transient</b> <b>faults</b> (MB-AVFs) and provide insights that can help reduce the impact of these faults. First, we describe a novel multi-bit AVF analysis approach for detected, uncorrected errors (DUEs) and show how to measure DUE MB-AVFs in a performance simulator. We then extend our approach to measure SDC MB-AVFs. We find that MB-AVFs are not derivable from single-bit AVFs. We also find that larger fault modes have higher MB-AVFs. Finally, we present a case study on using MB-AVF analysis to optimize processor design, yielding SDC reductions of 86 % in a GPU vector register file. Keywords-reliability; soft errors; fault tolerance; I...|$|R
40|$|Embedded {{systems are}} {{increasingly}} deployed in harsh environments that their components {{were not necessarily}} designed for. As a result, systems may have to sustain <b>transient</b> <b>faults,</b> i. e., both single-bit soft errors caused by radiation from space and transient errors caused by lower signal/noise ratio in smaller fabrication sizes. Hardware can protect and even correct <b>transient</b> <b>faults</b> {{at the cost of}} redundant circuits. Software approaches can also protect/correct these faults, e. g., by instruction duplication or algorithmic design. Recent work focuses on hybrid solutions of both hardware and software support to counter <b>transient</b> <b>faults</b> while minimizing the cost of protection. While hybrid approaches have been proposed for selectively protecting hardware regions and for control-flow checking, data representations have been widely ignored. The contribution of this work is to assess the benefits of inherently error-detecting and optionally error-correcting data representations on the software side. We present some programming patterns which exhibit properties for inherent detection of <b>transient</b> <b>faults.</b> These patterns are compared with techniques which rely on instruction duplication for error detection. Additionally, we introduce a framework to verify the resilience of these patterns with respect to <b>transient</b> <b>faults</b> and compare their performance with other error detection methods. Preliminary results indicate that a software approach for fault-resilient data representations compares favorably to past work and can reduce the duplication cost in software without compromising error-detection capabilities. 1...|$|R
40|$|This paper {{develops}} {{a method for}} the quantitative analysis of network connectivity {{in the presence of}} both permanent and <b>transient</b> <b>faults.</b> Even though <b>transient</b> noise is considered a common occurrence in networks, a survey of the literature reveals an emphasis on permanent <b>faults.</b> <b>Transient</b> <b>faults</b> introduce a time element into the analysis of network reliability. With permanent faults it is sufficient to consider the faults that have accumulated {{by the end of the}} operating period. With <b>transient</b> <b>faults</b> the arrival and recovery time must be included. The number and location of faults in the system is a dynamic variable. <b>Transient</b> <b>faults</b> also introduce system recovery into the analysis. The goal is the quantitative assessment of network connectivity in the presence of both permanent and <b>transient</b> <b>faults.</b> The approach is to construct a global model that includes all classes of faults: permanent, transient, independent, and correlated. A theorem is derived about this model that give distributions for (1) the number of fault occurrences, (2) the type of fault occurrence, (3) the time of the fault occurrences, and (4) the location of the fault occurrence. These results are applied to compare and contrast the connectivity of different network architectures in the presence of permanent, transient, independent, and correlated faults. The examples below use a Monte Carlo simulation, but the theorem mentioned above could be used to guide fault-injections in a laboratory...|$|R
40|$|Targeting on {{the future}} fault-prone hybrid CMOS/nanodevice digital memories, this paper {{presents}} two fault tolerance design approaches that integrally address the tolerance for defects and transient faults. The first approach is straightforward and easy to implement but suffers from a rapid drop of achievable storage capacity as defect densities and/or <b>transient</b> <b>fault</b> rates increase, while the second approach can achieve much higher storage capacity under high defect densities and/or <b>transient</b> <b>fault</b> rates {{at the cost of}} higher implementation complexity and longer memory access latency. With the use of BCH codes as ECC, we carried out simulations to demonstrate the effectiveness of the presented approaches under a wide range of defect densities and <b>transient</b> <b>fault</b> rates, while taking into account of the fault tolerance storage overhead in CMOS domain. ...|$|E
40|$|Transient faults are {{emerging}} as a critical concern in the reliability of microprocessors. While hardware reliability techniques are often employed for <b>transient</b> <b>fault</b> tolerance, software techniques represent a more cost-effective and flexible alternative. This paper proposes a software approach to <b>transient</b> <b>fault</b> tolerance which utilizes a run-time system to automatically apply process-level redundancy (PLR). PLR creates a set of redundant processes per application process and compares the processes during run time to guarantee correct execution. Redundancy at the process level allows the operating system to freely schedule the processes across all available hardware resources (i. e. extra threads or cores). PLR is a software-centric approach to <b>transient</b> <b>fault</b> tolerance in which the focus is shifted from ensuring correct hardware execution, to ensuring correct software execution. The software-centric approach is able to ignore many benign faults which do not propagate to affect the program output. In addition, the dynamic deployment creates a very flexible fault tolerant system which transparently applies PLR without prior modifications to the application, shared libraries, or operating system. Experiments using a real PLR prototype on an SMP machine demonstrate that PLR can effectively provide <b>transient</b> <b>fault</b> tolerance with a slowdown of only 1. 26 x. 1...|$|E
40|$|A superstabilizing {{protocol}} is {{a protocol}} that (i) is self-stabilizing, {{meaning that it}} can recover from an arbitrarily severe transient fault; and (ii) can recover from a local <b>transient</b> <b>fault</b> while satisfying a passage predicate during recovery. This paper investigates the possibility of superstabilizing protocols for mutual exclusion in a ring of processors, where a local fault consists of any <b>transient</b> <b>fault</b> at a single processor; the passage predicate specifies that there be at most one token in the ring, with the single exception of a spurious token colocated with the <b>transient</b> <b>fault.</b> The first result of the paper is an impossibility theorem for a class of superstabilizing mutual exclusion protocols. Two unidirectional protocols are then presented to show that conditions for impossibility can independently be relaxed so that superstabilization is possible using either additional time or communication registers. A bidirectional protocol subsequently demonstrates that superstabiliz [...] ...|$|E
40|$|Abstract. In {{this paper}} we {{demonstrate}} how to formalize UML-based development of protective wrappers for tolerating <b>transient</b> <b>faults.</b> In particular, {{we focus on}} the fault tolerance mechanisms common in the avionics domain and show the development of a protective wrapper, called Failure Management System. We demonstrate how to integrate the formal refinement approach proposed earlier into the UML-based development. Keywords: Event-B, fault tolerance, refinement, statemachines, <b>transient</b> <b>faults,</b> UML-B. ...|$|R
40|$|Abstract- Computer chips {{implementation}} {{technologies are}} evolving to obtain more performance. The {{side effect of}} such a scenario is that processors are less robust than ever against <b>transient</b> <b>faults.</b> As on-chip solutions are expensive or tend to degrade processor performance, the efforts {{to deal with these}} <b>transient</b> <b>faults</b> in higher levels are increasing. Software based fault tolerance approaches against <b>transient</b> <b>faults</b> often use fault injection experiments to evaluate the behavior of applications with and without their fault detection or fault tolerance proposals. Those fault injection experiments consumes lots of CPU time by running or simulating the application being evaluated as many times as necessary to obtain a reasonable valid statistical approximation. This paper proposes the concept of a program's robustness against <b>transient</b> <b>faults</b> and presents a methodology for exhaustively calculate this robustness based on program's execution trace over an architecture and on information about the used architecture. The presented approach, besides calculating a precise robustness, accomplishes its work faster than using fault injection experiments with ± 2 % of confidence interval...|$|R
40|$|AbstractIntermittent and <b>transient</b> <b>faults</b> are {{the largest}} source of failure for sensor networks. In order to provide a method for {{detecting}} permanent, intermittent and <b>transient</b> <b>faults,</b> a distributed detection algorithm is developed. This algorithm uses repeated testing in discrete time and considers the case of system level faults. It subsumes several algorithms already reported in the literature. Simulation result shows that the false detection rate is well under control while maintaining high detection accuracy...|$|R
40|$|Mixed analog {{and digital}} mode {{simulators}} {{have been available}} for accurate <b>transient</b> <b>fault</b> simulation. However, they are not fast enough to simulate {{a large number of}} transient faults on a relatively large circuit in a reasonable amount of time. In this paper, we describe a gate-level <b>transient</b> <b>fault</b> simulation environment which has been developed based on realistic fault models. The simulation environment uses a timing fault simulator as well as a zero-delay parallel fault simulator. The timing fault simulator uses high level models of the actual <b>transient</b> <b>fault</b> phenomenon and latch operation to accurately propagate the fault effects to the latch outputs, after which point the zero-delay parallel fault simulator is used to speed up the simulation without any loss in accuracy. The simulation environment is demonstrated on ISCAS- 89 sequential benchmark circuits. 1 Introduction High-performance computers are increasingly being used in applications in which continuous and reliable service [...] ...|$|E
40|$|International audienceThis paper {{reports a}} case study about the {{automatic}} layout generation and <b>transient</b> <b>fault</b> injection analysis of a Phase-Locked Loop (PLL). A script methodology was used to generate the layout based on transistor level specifications. After layout validation, experiences were performed in the PLL in order to evaluate the sensibility against <b>transient</b> <b>fault.</b> The circuit was generated using the STMicroelectronics HCMOS 8 D process (0. 18 ìm). Results report the PLL sensitive points allowing the study and development of techniques to protect this circuit against transient faults...|$|E
40|$|Abstract—Transient faults are {{emerging}} as a critical concern in the reliability of general-purpose microprocessors. As architectural trends point toward multicore designs, there is substantial interest in adapting such parallel hardware resources for <b>transient</b> <b>fault</b> tolerance. This paper presents process-level redundancy (PLR), a software technique for <b>transient</b> <b>fault</b> tolerance, which leverages multiple cores for low overhead. PLR creates a set of redundant processes per application process and systematically compares the processes to guarantee correct execution. Redundancy at the process level allows the operating system to freely schedule the processes across all available hardware resources. PLR uses a software-centric approach to <b>transient</b> <b>fault</b> tolerance, which shifts the focus from ensuring correct hardware execution to ensuring correct software execution. As a result, many benign faults that do not propagate to affect program correctness can be safely ignored. A real prototype is presented {{that is designed to}} be transparent to the application and can run on general-purpose single-threaded programs without modifications to the program, operating system, or underlying hardware. The system is evaluated for fault coverage and performance on a four-way SMP machine and provides improved performance over existing software <b>transient</b> <b>fault</b> tolerance techniques with a 16. 9 percent overhead for fault detection on a set of optimized SPEC 2000 binaries. Index Terms—Fault tolerance, reliability, transient faults, soft errors, process-level redundancy. Ç...|$|E
40|$|Fault {{tolerance}} {{has become}} an important issue for parallel applications {{in the last few}} years. The parallel systems' users want them to be reliable considering two main dimensions, availability and data consistency. Availability can be provided with solutions such as RADIC, a fault tolerant architecture with different protection levels, offering high availability with transparency, decentralization, flexibility and scalability for message-passing systems. <b>Transient</b> <b>faults</b> may cause an application running in a computer system to be removed from execution, however the biggest risk of <b>transient</b> <b>faults</b> is to provoke undetected data corruption that changes the final result of the application without anyone knowing. To evaluate the effects of <b>transient</b> <b>faults</b> in the robustness of applications and validate new fault detection mechanism and strategies, we have developed a full-system simulation fault injection environmen...|$|R
40|$|Submitted {{on behalf}} of EDAA ([URL] audienceSingle Event Upsets (SEU) as well as {{permanent}} faults can significantly affect the correct on-line operation of digital systems, such as memories and microprocessors; a memory can be made resilient to permanent and <b>transient</b> <b>faults</b> by using modular redundancy and coding. In this paper, different memory systems are compared: these systems utilize simplex and duplex arrangements {{with a combination of}} Reed Solomon coding and scrubbing. The memory systems and their operations are analyzed by novel Markov chains to characterize performance for dynamic reconfiguration as well as error detection and correction under the occurrence of permanent and <b>transient</b> <b>faults.</b> For a specific Reed Solomon code, the duplex arrangement allows to efficiently cope with the occurrence of permanent faults, while the use of scrubbing allows to cope with <b>transient</b> <b>faults...</b>|$|R
40|$|With {{the advent}} of VLSI technology, the systems {{fabricated}} in deep sub micron technology {{are more prone to}} errors like intermittent or <b>transient</b> <b>faults,</b> causing unidirectional errors. Research has been established to provide protection against these <b>transient</b> <b>faults</b> to improve the overall reliability of the system. This paper provides a comprehensive survey of fault detection techniques and describe in brief the promising techniques comes under coding techniques that allow the detection of these errors and their performance evaluation...|$|R
