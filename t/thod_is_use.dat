0|10000|Public
40|$|A {{study has}} been made of {{phosphosilicate}} glass films prepared by pre-depositing P 205 on thermally oxidized silicon. Many of the properties of these films including composition, density, etch rate, conductivity, dielectric con-stant, and dielectric strength have been measured and are compared with the corresponding properties of thermal ly produced silicon dioxide layers. A po-larization effect is discussed which gives rise to an increase of about 20 % in the dielectric constant of the glass at high temperatures and low frequencies (~ 250 ~ at 50 cps). Under d-c bias at lower temperatures this polarization causes a slow drift in the capacitance-voltage characteristic of metal-oxide-semiconductor (MOS) capacitors which use the glass as a dielectric. The MOS capacitance-voltage m <b>thod</b> <b>is</b> <b>used</b> to study the time, temperature, and vol-tage dependence of the polarization, and mechanisms are discussed which can account for the observed results. Modern silicon planar technology (1) involves th...|$|R
40|$|Sensory {{analysis}} {{is the standard}} analysis of foods made with the senses. Under the name of sensometrics regroup statistical methods address {{to this type of}} data. An important application area of sensory {{analysis is}} the wine industry. The companies are beginning to see the potential of sensory analysis and they are organizing more hall test sessions every passing day to learn about their products and use these results to improve their production and marketing. However, yet these m <b>thods</b> <b>are</b> not <b>used</b> very much because of their little knowledge between wine industry companies...|$|R
40|$|A new on-line {{tool wear}} states {{detecting}} me thod, with spindle and feed current signal in boring, is presented. By an alyzing {{the effects of}} tool wear, as we ll as the cutting parameters on the current signals, the models {{of the relationship between}} the curren t signals and the cutting parame te rs are established under differen t tool wear state s with partial experimental design and regression analysis. Fuzzy classification me <b>thod</b> <b>is</b> then <b>used</b> to obtain the membership degree of each tool wear classification with measured spindle and feed current values. Finally, the membership results of the spindle current and feed current are fused by the fuzzy inference method, and the tool wear state may be detected e ffe ctive ly. The validity and reliability of the method are verified by experimental results. The method can be e ffe ctive ly employed in practice. 1...|$|R
50|$|The <b>ThOD</b> <b>is</b> {{the sum of}} {{the oxygen}} {{required}} for all three steps.|$|R
40|$|The stress-wave momdestructive test (NDT) me <b>thod</b> <b>was</b> applies in this {{research}} to test the joint strength of T-type joint and try to predict the joint defect. The relationship of joint strength predicted by NDT and tested by traditional destructive本研究主要以應力波非破壞性測定法，檢測 3 種T型接合構件之接合強度，及預測 構件缺點之可行性，並比較其他與傳統破壞性檢測接合強度之相關性。試材加工前後之波速 並沒有明顯的差異，但構件組合後橫檔之波速會變慢；以打音頻譜分析系統檢測構件縱向振 動頻率時，抗彎構件中兩種針葉樹材彎曲接合構件之振動頻率平均比兩種闊葉樹材低約 30...|$|R
40|$|In {{this paper}} a new {{approach}} to obtain the interface propagation speed in superconductors by means of a variationalme <b>thod</b> <b>is</b> introduced. The results of the approach proposed coincide with the numerical simulations. The hyperbolic differential equations are introduced {{as an extension of the}} modelin order to take into account delay effects in the front propagation due to the pinning. Comment: 4 pages, 3 figure...|$|R
50|$|Theoretical {{oxygen demand}} (<b>ThOD)</b> <b>is</b> the {{calculated}} amount of oxygen required to oxidize a compound to its final oxidation products. However, {{there are some}} differences between standard methods that can influence the results obtained: for example, some calculations assume that nitrogen released from organic compounds is generated as ammonia, whereas others allow for ammonia oxidation to nitrate. Therefore, in expressing results, the calculation assumptions should always be stated.|$|R
40|$|There is con suring nucle tions. The m <b>thod</b> <b>is</b> the r {{analyzed}} wit (Ct) method. performed h {{of initial}} con a concentrat resultant Ct dard and no riability/relia supports th replicates, th tically distin ten orders o tion. As exp grow as the demonstrate confound qu tion at low t that a miscl 3000 initial c tion region thermal wea vide data th detection str and plate fi classification becomes un...|$|R
40|$|The {{results of}} {{proximal}} nerve injuries with nerve gaps {{are less than}} perfect and provide only extrinsic muscle function with sensation at the best; intrinsic muscle function recovery is rarely seen. The imbalance in the hand resulting from denervation of the intrinsic muscles is usually treated by tendon transfers in a second sitting; since the results of tendon transfer depend on multiple factors, the final outcome may not be predictable for the individual patient the {{aims and objectives of}} this. S tudy to know the anatomical feasibility of the distal expendable motor branches of the median nerve to selectively reinnervate the intrinsic muscles of the hand. T he m e <b>thod</b> <b>used</b> <b>are</b> 10 upper limbs from 5 cadavers were dissected in this study. 4 X loup e magnification <b>was</b> <b>used</b> for the dissection. Length and width of nerves were measured with measuring scale & calipers. THE RESULTS : The length of the thenar motor nerve is about 2 - 3 cm, (which reaches upto distal wrist crease) and from there to distal end of the pronator quadratus nerve is 4. 5 - 6. 0 cm. Pronator quadratus nerve can be lengthened by 1 - 1. 2 cm by intramuscular dissection. The deep branch of ulnar nerve is 9. 5 - 10. 6 cm length and can be easily brought to the distal end of pronator quadratus nerve The diameters of all three nerve matches in 90 - 95...|$|R
40|$|Determination {{of protein}} {{structure}} in space {{is a crucial}} part of protein function analysis. But structure determination is an expensive and time consuming pro- cess, therefore structure prediction model raised on popularity. The most notable subproblem of protein structure prediction is prediction of local conformation of the adjacent amino acids, ie. secondary structure. This thesis studies usage of deep neural networks for protein secondary structure prediction. We implemented pre- diction model and different modifications are evaluated. Especially compassion of LSTM and GRU memory cells was done. Furthermore, two new preprocessing me- <b>thods</b> <b>are</b> evaluated. Fast PSSM calculation method was proposed and prediction of tertiary structure <b>was</b> <b>used</b> as input for prediction model. Last part of this thesis examine application of filtering methods for models predicting secondary structure with eight classes. ...|$|R
40|$|Four {{different}} extraction {{methods were}} compard, in oder {{to optimize the}} HPLC separation and quantitation of hydroxyphenols in «Thymus capitatus». One method was not suitable for HPLC ansly,is, whereas the others partially destroyed the hydroxyphenols extracted from the plant. The Charpentier-Cowles me <b>thod</b> <b>was,</b> found the most effective allowing to analyse, {{in spite of the}} losses, most of the free phenolic acids and of those bounded extractable in hot acidic medium but not in ethanol. For the phenolics in free form a method whith recoverier greater than those obtained with Hagerman Nicholson and Horvat-Senter methods was developed...|$|R
40|$|In {{this paper}} a {{feasibility}} study of brain MRI data set classification, using ROIs {{which have been}} segmented either manually or throug h a superpixel based method in conjunction with statistical pattern recognition me <b>thods</b> <b>is</b> presented. In our study, 471 extracted ROIs from 21 Brain MRI datasets are u sed, {{in order to establish}} which features distinguish better between three grading c lasses. Thirty-eight statistical measurements were collected from the ROIs. We found by using the Leave-One-Out method that the combination of the features from th e 1 st and 2 nd order statistics, achieved high classification accuracy in pair-wise grading comparisons...|$|R
40|$|ABSTRACT: An {{analytical}} me <b>thod</b> <b>is</b> {{developed to}} calculate an effective perme-ability tensor for a grid block by accounting for small-scale heterogenei ty within the grid block. The me thod honours bo th {{the location and}} {{the orientation of the}} small-scale heterogeneity. Effective permeability tensors calculated using the analytical me thod and a numerical me thod show excellent agreement. Single phase flow simulations show that the effective permeability tensor me thod outperforms non-tensor scale-up techniques in predict ing the fluid flow distances in cases of general permeabili ty anisotropy. The tensor m e t h o d was also applied to two-phase flow simulations and it was shown that it retains the directionality in preferential flow paths after up-scaling...|$|R
40|$|It {{has been}} {{proposed}} that, in animals, aretinohypothalamic pathway exists which mediates the synchronization f the diurnal ight-dark cycle with the central neural components regulating endogenous rhythms. There have been numerous anatomic, physiologic and behavioral investigations tosubstantiate his proposed connection i experimental nimals. Morphologic investigation ofa retinohypothalamic tract in man has awaited the development ofa technique capable of axonal trac-ing in the human brain. The paraphenylenediamine m <b>thod</b> <b>was</b> applied to 7 post-mortem human brains. Degenerated axons {{were found in the}} suprachiasmatic nuclei of the hypothalamus in each of the 4 patients who had incurred prior optic nerve damage. The ret-inosuprachiasmatic pathway may be the anatomical substrate for the integration of retinal ight information with endogenous rhythms in man...|$|R
40|$|A novel texture-based weed {{classification}} method was developed. The method comprised a low-level Gabor wavelets-based feature extraction algorithm and a high-level neural network-based pattern recognition algorithm. The design strategy simulated {{the function of}} the human visual system, which uses low-level receptors for early stage vision processing and high-level cognition for pattern recognition and image understanding. This model was specifically developed to classify images into broadleaf and grass c tegories for real-time selective herbicide application. The results showed that the m <b>thod</b> <b>is</b> capable of performing texture-based broadleaf and grass classification effectively and with 100 percent classification accuracy over 40 sample images with 20 samples from each class. Based on the elapsed time to do weed classification, the method meets real-time constraints. 1...|$|R
40|$|This article {{describes}} the streamline upwind Petrov-Galerkin (SUPG) method as being a stabilisation technique for resolving the diffusion-advection-reaction equation by finite elements. The {{first part of this}} article has a short analysis of the importance of this type of differential equation in modelling physical phenomena in multiple fields. A one-dimensional description of the SUPG me- <b>thod</b> <b>is</b> then given to extend this basis to two and three dimensions. The outcome of a strongly advective and a high numerical complexity experiment is presented. The results show how the version of the implemented SUPG technique allowed stabilised approaches in space, even for high Peclet numbers. Additional graphs of the numerical experiments presented here can be downloaded from www. gnum. unal. edu. co...|$|R
40|$|Summary. The variance-eovariance m <b>thod</b> <b>is</b> {{employed}} at low doses and in radiation fields of low dose rates from an 241 Am (4 nGy/s) and a 9 °Sr (300 nGy/s) source. The preliminary applications and results illustrate {{some of the}} potential of the method, and show that the dose average of lineal energy or energy imparted can be determined over a wide range of doses and dose rates. The dose averages obtained with the variance-covariance method in time-varying fields, for which the conventional variance method is not suitable, agree well with results obtained under the condition of con-stant dose rate. The results are compared to data obtained in terms of the conventional single-event measurements. The method has evident advan-tages, such as facility and speed of measurement...|$|R
40|$|Mefenamic acid <b>is</b> {{routinely}} <b>used</b> as tablet dosage forms. Thin layer chromatography (TLC) promotes {{for higher}} separation efficiencies, shorter analysis time, lower amounts of mobile phase, and efficient data acquisition and processing. There are various analytical methods for their estimation of mefenamic acid but till date {{there is no}} TLC method for its analysis. The paper presents the development and validation of a new TLC method for analysis of mefenamic acid in tablet. Separation was performed on silica gel 60 F 254 plates. The mobile phase is comprised of chloroform: methanol (9. 0 : 0. 1, v: v). Densitometry evaluation of the separated zones was performed at 320 nm. The drug was satisfactorily resolved with RF values of 0. 55 ± 0. 03. The accuracy and reliability of the me <b>thod</b> <b>was</b> assessed by evaluation of linearity (50 - 300 µg/mL), precision intra-day and inter-day RSD values were always less than 2, accuracy (102. 45...|$|R
40|$|Assessment and {{evaluation}} {{are among the}} essential functions performed by an educator. What is more, they {{are closely related to}} the communication of the teaching process efficiency in terms of verification of learner and educator expectations, determination of learning and teaching quality achievement, and generalization of educational activities. The present study aims at the analysis of assessment techniques applied in the master degree linguistic studies. Initially, a brief theoretical overview of both formal and informal assessment me- <b>thods</b> <b>is</b> provided, with the focus on their distinctive features and ways of application in the light of Bloom’s taxonomy and Dublin description representing the competence requirements set for the gain of definite skills. Further, the results of the survey (conducted at Kaunas Faculty of Humanities, Vilnius University) are described. Finally, the eligible assessment techniques serving the purpose of efficient educational process in the second-cycle study process are identified...|$|R
40|$|A {{synthesis}} me <b>thod</b> <b>is</b> {{developed for}} estimating deterministically strong motions during the mainshock, using the records o[small {{events such as}} foreshocks and aftershocks which occurred within {{the area of the}} mainshock fault. This synthesis formulation is based on the kinematic source model o [Haskell type and the similarity law of earthquakes. The parame ters for this synthesis are determined to be consistent with the scaling relations between the moments and the fault parameters such as fault length, width and dislocation rise time. If the ratio of the mainshock moment Mo to the small event one Mo, is assumed to be lf 3, then the mainshock fault can be divided into Nx N elements, each dimension of which is consistent with that of the small event and N events at each element may be sr-rperposed with a specific time delay to correct the difference in the rise time between the mainshock and the small event and to keep a constant slip velocity between them. By means of this method, the mainshock velocity motions <b>are</b> synthesized <b>using</b> the small event records obtained by velocity-type-strong-motion-seismographs for l 9 B 0 fzu-Hanto-Toho-Oki Earthquake (lvl: 6. 7). The resultant synthesized motions show a good agreement with the observed ones in the frequenc...|$|R
40|$|Objective: To compare two {{analytical}} {{techniques used}} in the determination of plasma digoxin (LC-MS/MS and immunoassay) and to verify which one better answer the need of the clinical monitoring routine of patients with cardiac heart failure. Method: The clinical findings in 15 cardiac heart failure (CHF) outpatients of the Cardiac Heart Service of the Goias Federal University Clinical Hospital were investigated. Blood samples of the patients were collected and analysed by Immunoassay and by Liquid Chromatography coupled to Mass Spectrometry (LC-MS/MS). Results: The results of the statistic test (Student p = 0, 05) showed {{a significant difference between}} the analytical methods: immunoassay concentrations were higher than the concentrations determined by LCMS/ MS. The explanation may be because immunoassay method measures digoxin plus other metabolites and endogenous substances, while the LC-MS/MS method measures only the digoxin molecule. None of the patients, showed relevant clinical data suggestive of digitalis intoxication, even several drugs with potential interaction were associated with treatment. Conclusion: It was concluded, therefore, that LC-MS/MS me <b>thod</b> <b>is</b> safer, more selective and specific than immunoassay, being an option for therapeutic drug monitoring of digoxin, since the reference values would be obtain for digoxinemia by LC-MS/MS. ...|$|R
40|$|Digital {{predistortion}} <b>is</b> {{a technique}} <b>used</b> {{to reduce the}} signal Various methods have been formulated to achievePAR dynamic range in a multichannel system {{in order to improve}} reduction in multicarrierOFDM systems. The simplest mepower amplifier (PA) efficiency. These techniques have <b>thods</b> <b>are</b> based on the observation that a high signal peak is been developed for orthogonal frequency-division multi- created when signals in multiple channels add construcplexing (OFDM) systems, but are not directly applicable to tively in phase. Such methods attempt to systematically general frequency-division multiplexing (FDM) systems insert phase shifts to subcarriers to reduce their in-phase such as those used in broadcast. A modification to the tone probability. Various algorithms have been proposed in deinjection approach allows constellation translations to be termining the optimal phase selections [2 - 5]. Coding is directly applied at the digital intermediate frequency (IF) another promising approach that systematically adds redundomain and provides redundancy in lowering peak-to- dancy to avoid certain symbol combinations that cause high average ratio (PAR). Simulation ofa 24 -channel 256 -QAM signal peaks [6 - 1 1]. Coding also enhances error tolerance FDM cable television transmission system shows a 3. 3 dB of the system. Recent efforts explore the possibility of PAR reduction at 10 - 6 clipping probability. varying signal constellation in order to mitigate high PAR...|$|R
40|$|We {{developed}} and evaluated a multiplex PCR (m-PCR) for application in routine diagnostic labor- atories to detect Campylobacter spp. in stool samples including C. concisus, C. jejuni, and C. coli. When this m-PCR was applied on spiked faecal samples, C. concisus, C. jejuni, and C. coli were spe- cifically identified at 105 cells/gm of faeces. To compare {{the sensitivity of}} the m-PCR with conven- tional culture techniques, the same spiked stool samples were cultured on an antibiotic free Co- lumbia blood agar using the filtration technique. The detection limit of conventional culture me- <b>thod</b> <b>was</b> 105 cells/gm of stool for C. concisus and 106 cells/gm of stool for C. jejuni and C. coli. The m-PCR was applied to test 127 faecal samples from children with gastroenteritis and the results were compared with the conventional bacterial cultures data. By this m-PCR technique, C. jejuni was detected in 7 samples, C. coli in 2 samples, and C. concisus in 7 samples. However, the conven- tional culture results for these samples were 6 for C. jejuni, 2 for C. coli and only one sample was positive for C. concisus. In total, 19 samples were positive for Campylobacter spp. by m-PCR while only 9 samples were positive for Campylobacter spp. by culture. In conclusion, m-PCR is more sen- sitive than the culture technique to detect C. concisus and other fastidious campylobacters in faeces...|$|R
5000|$|The Menngagde or 'Instruction Class' of Dzogchen teachings {{are divided}} into two parts: Trekchö and Tögal (thod rgal). Ron Garry: [...] The {{practice}} is that of Cutting through Solidity (khregs chod), which is related to primordial purity (ka dag); and Direct Vision of Reality (<b>thod</b> rgal), which <b>is</b> related to spontaneous presence (Ihun grub).|$|R
40|$|VI Abstract This Master’s thesis {{was done}} for Borealis Polymers Oy in {{co-operation}} with Chalmers University of Technology. The research concentrated on the load of petrochemical waste waters. Borealis’ Petrochemical plants consist of cracker, butadiene, benzene, cumene and phenol plants. There are two waste water systems in Borealis Polymers Petrochemical plants: phenolic waters (PW) and oily waters (OW) which were studied separately. The phenol plant discharges its waste water to both systems, while other plants discharge only to OW-system. The loads of waste waters were assessed with two methods. The first method was chemical oxygen demand and the second method {{was to assess the}} quality of waste water streams from plants. Chemical oxygen demand (COD) was studied with theoretical oxygen demand (ThOD) analysis. The quality of different waste water streams were assessed by taking samples from waste waters generated in the plants. In phenolic waters, the <b>ThOD</b> <b>was</b> mostly caused by methanol and phenol. In OW-system the contribution to COD-load was divided more equally between all the components found in the waste waters. Petrochemical waste waters contain a variety of different components, so ThOD analysis based only on known components did not give a full answer how different sorts of chemicals contribute to COD. On average the determined <b>ThOD</b> <b>was</b> one fifth of measured in COD in phenolic waters and one third of measured COD in oily waters. In the phenol plant the load originated from the effluent stripper and methylhydroperoxide (MHP) reactor to the phenolic waters. When the quality of waste waters was studied, the MHP-reactor was the main contributor to the load to biological treatment feed, biolsy. It is recommended that the known components should be analysed also from the outlet of the MHP-reactor continuously. The waste water from the MHP-reactor contained high concentrations of cumene and phenol. Also because of the high phenol and cumene content of the water, it should be treated either in effluent stripper or in the OW-stripper. The cracker was responsible for benzene, toluene, xylenes and phenol load to oily waters system. The phenol and aromatics were responsible for methanol, and total nitrogen load. The known components should be continuously analysed from all the main waste water sources; the diluting steam generator, the NaOH and FCC washing steps, the carbonyl wash, the OW-stripper and the ejector waters. The streams that contained high hydrocarbon concentrations should be treated in OW-stripper and streams that contained phenol should be treated in effluent stripper. The reduction of load is difficult even impossible if the reduction concentrates only on the total load, measured either from pit 27 in case of the OW-system or from the biolsy in case of phenolic waters. Firstly the variety of components in the final stream increases because waste waters from different plants are aggregated. The reduction of different kinds of components is difficult, because of different nature of components. In the final stream also the components are diluted, which also makes the reduction of components more difficult. The reduction of components can be more efficient if it is carried out at the origin of the load...|$|R
40|$|The problem-oriented {{approach}} (POA) is a ratio- nal {{method to}} manage clinical cases globally {{adopted in the}} medical practice. The centre of this me- <b>thod</b> <b>is</b> the ‘problem’, which becomes {{the goal of the}} medical path aimed to the resolution of this evidence. Additionally, the medical record build around the ‘problem’ (POMR, problem oriented medical record) becomes an effective means to follow the evolution of this condition and it allows a persuasive management of the patient. The following scheme is develop to describe the medical action: data base collection, to arrange the initial database of patient’s problems; list of problems, where the meaning for problem is “anything that has, does, or may require health care management, and that has or could significantly affect a patient’s well-being” 1, and it should be formulated by pro- gressive refinements until becomes a short list of master problems; plan formulation, including a dia- gnostic plan to verify and localize the problem and then to look for both its pathophysiologic mecha- nism and cause, and a therapeutic plan incorporating a specific, supportive, symptomatic and palliative treatment. Based on this scheme prognostic consi- deration and supplying an effective client education could be formulated. Finally, the medical action path is completed with progress notes including: subjective (S) and objective (O) data collected from the patien- t’s follow-up or monitoring, problem assessment (A) which is then re-evaluated and further diagnostic or therapeutic plan (P) revised and up-dated (the so-called SOAP). The POA is really useful to the application of the evidence-based medicine...|$|R
40|$|Serologic {{diagnostic}} of hydatid cyst by immuno-fluorescence technique Of the serological {{methods for}} the diognosis of hydatid cystimmuno-fl uoresccnt technique using fro zen {{section of the}} sco lex as antigen has given encouraging results. In t he present study examina t io n o f 8 5 sera correspond ing to h yd atido se patien ts by t his met hod, has shown th at 94 % of th e cas es can be d e tect ed with thi s high sensit ivit y te chniq ue. And thi s me <b>thod</b> can <b>be</b> co nsid ered as o ne o f th e best serologica l methods for the diagnostic of Echinococcosis. </p...|$|R
5000|$|Dzogchen {{is itself}} the {{pinnacle}} of the ninefold division of practice according to the Nyingma school of Tibetan Buddhism. Menngagde focuses on rigpa. The Menngagde or 'Instruction Class' of Dzogchen teachings are divided into two parts: trekchö and tögel. The practice is that of Cutting through Solidity (khregs chod), which is related to primordial purity (ka dag); and Direct Vision of Reality (<b>thod</b> rgal), which <b>is</b> related to spontaneous presence (Ihun grub).|$|R
40|$|A nume rical a pproach that cou ples Loren tz-Drude model {{incorporated}} Maxwell equations with Schrödinger {{equation is}} presented for the simula tion of pla smonics nanodevices. Maxwell equa tions w ith Lore ntz-Drude (LD) dispersive model are a pplied to l arge size c omponents, w hereas coupled Maxwell and Schrödinger equations {{are applied to}} components where quantum effec ts a re nee ded. The finite difference time do main me <b>thod</b> (F DTD) <b>is</b> appl ied to simulate these coupled equations. Numerical results of the coupled ap proach are compared w ith th e conventional approach. 1...|$|R
40|$|The diploma thesis "The Process of Establishing and Building a Fashion Brand" {{deals with}} the process of {{establishing}} a fashion brand, how to write its business plan and which me- <b>thods</b> and techniques <b>are</b> suitable to <b>use</b> to create a fashion brand. The first part of this thesis covers the issues of establishing small business, then it is explained the structure and utilization of business plan {{and at the end of}} the theoretical part is closely described fashion marketing, as well as marketing and strategic analyzes and tools, which <b>are</b> generally <b>used</b> for building brands. In the practical part of this thesis the author, according to the acquired knowledge, handles the business plan of the streetwear brand called yen 3 k. Author focuses on SWOT strategic analysis, market segmentation and mainly on the marketing mix. Especially the promotion part of the marketing mix is described deeply. In conclusion, organizational plan, risks assessment and financial plan are evaluated. Keywords Fashion brand, brand, yen 3 k, business plan, fashion marketing, entrepreneurship, branding, streetwear, brand establishing, creation of a brand, brand identity, brand building, fashion, clothing v...|$|R
40|$|In 2008, {{the first}} Proficiency Testing Scheme of Chemical Oxygen Demand (1 st COD-PTADG) was {{conducted}} to assess the results obtained for different research groups whose field work is mainly anaerobic digestion. This study <b>was</b> performed <b>using</b> four samples, two solid samples as raw materials and two solid samples to prepare high concentration suspended solid solutions. Invitations were sent to {{a large number of}} laboratories, mainly to anaerobic digestion research groups. Finally, thirty labs from sixteen countries agreed to participate, but for different reasons four participants could not send any data. In total, twenty-six results were reported to the COD-PT coordinator. This study showed the importance of continuous participation in proficiency testing (PT) schemes in order to compare the results obtained. Taking into account the lack of a general standard method and high quality certified reference materials (CRMs), the traceability of COD determination is not currently easy to check. In addition, the spread of participants’ results obtained was high and pointed to the advisability of using consensus values due to their unreliability. Therefore, the theoretical oxygen demand (<b>ThOD)</b> values <b>were</b> considered as assigned values for all the samples analysed. On the other hand, in this PT the established standard deviation (ESD) has been determined by the Horwitz modified function. Participants of this 1 st COD-PTADG were asked to give a short report on the analytical method used. Although all the participants used potassium dichromate as their oxidant reagent, their experimental procedures were very different. With the purpose of comparing the results obtained, the different experimental conditions <b>used</b> <b>were</b> classified into five methods, corresponding to two main categories, open and closed reflux. The performance of laboratories was expressed by the z-score, whose value is considered satisfactory when z-score ≤± 2. The overall analytical data evaluation showed that 64 % of z-scores obtained were outside the accepted limits...|$|R
40|$|Aim is {{to develop}} a method for a {{prolonged}} support of recovery processes in damaged liver. Materials and me- <b>thods.</b> It <b>was</b> carried out 3 groups of experiments on Wistar rats with the modeling of chronic fi brotic liver injury (n = 70) : I group control (n = 20); in the II group (n = 20) a suspension of liver cells was transplanted into liver; in the III group (n = 30) cell-engineering designs (CED), which contained liver cells and BM MMSC, enclosed in a heterogeneous biodegradable gel “ Sphero ® GEL-long” were transplanted into damaged liver. The activity of recovery processes <b>was</b> evaluated by <b>using</b> biochemical and morphological methods in dynamics on 30, 60, 90   and 180 days. Results. It was shown that in the II and III gr. significantly accelerated the recovery processes in damaged livers compared with the I gr. The normalization of biochemical parameters took place in II and III du- ring 30 days instead of 90 days in the I group. However, the normalization of morphological signs of hepatocytes theirs viability and a degree of defibrotic changes in liver were more pronounced and prolonged in the III group. A study showed integration of CED by liver structures with formation of new bile ducts after 90 and 180 days. Conclusion. Higher levels and prolonged periods of recovery processes in damaged liver after CED transplanta- tion were due to the creation of biologically appropriate conditions for prolonged cell activity, included in their structure (donor liver cells and BM MMSC).   </div...|$|R
40|$|In this study, the {{surfaces}} of NaCl particles were modified with metal films using the polygonal barrel-sputtering me <b>thod.</b> When Pt <b>was</b> sputtered on NaCl particles, the individual particles changed from white to metallic. Characteriza tion of the treated samples indicated that thin Pt metal films were uniformly deposited on the NaCl particles. Immer sion of the treated NaCl particles in water revealed that they floated {{to the surface of}} the water with the increase in the immersion time, although their original cubic shapes remained unchanged. The floating phenomenon of the Pt-coated NaCl particles, as mentioned above, suggests that NaCl was dissolved by the permeation of water through invisible de fects such as grain boundaries in the Pt films, leading to the formation of hollow particle-like materials. It should be noted that uniform film deposition on the NaCl particles could also be achieved by sputtering with Au or Cu. Based on the obtained results, our sputtering method allows uniform surface modification of water-soluble and water-reactive powders that cannot be treated by conventional wet process using water. </p...|$|R
40|$|Worldwide, slope {{stability}} analysis {{is fundamental to}} satisfy the increa singly societal demand for safe infrastructures and natural resources. W ith the increase in computational power and the advance in the developme nt of numerical methods, new techniques for {{slope stability}} analysis hav e become very attractive to engineers. The finite element method (FEM) p resents many advantages over classic methods, e. g., no a-priori failure mechanism is necessary to assess the stability of slopes. Furthermore, n umerical techniques provide information about stresses and displacements, what contributes {{to the understanding of}} slope processes. Despite thes e advantages to become the state-of-the-practice method, FEM should be c apable of handling different aspects of slope stability analysis. The aim of this research is twofold. The first objective is to investiga te the application of finite element analysis techniques in slope stabil ity studies and to define ways to enhance its use in practical geotechni cal applications. The second objective <b>is</b> exploring the <b>use</b> of FEM to de tect the precursors to slope failure and to assist in defining the optim al positioning of sensors for slope stability monitoring. The research i n these areas will contribute to a safe and a more economic design of sl opes. The thesis presents a comprehensive and critical literature review on th e state-of-the-art in finite element slope stability analysis, in partic ularly with focus on the strength reduction technique. Static, pseudosta tic and dynamic finite element analyses are conducted to obtain {{a better understanding of the}} method and to demonstrate practical applications. The applications of FEM, that have been developed and validated in this research, encompass: a process to detect different sliding surfaces from performing a finite element analysis, the computation of the critical s lip surface from shear strain contours, and the coupling of FEM with opt imisation algorithms for the back-analysis of soil parameters. Additiona lly, a broad comparative analysis between the classical limit equilibriu m method (LEM) and the FEM with focus on the differences between both me <b>thods</b> <b>is</b> presented. The <b>use</b> of the finite element stress field in a limi t equilibrium context, including the effects of the tensile strength and dilatancy is also investigated. The results, in terms of the factor of safety and the location of the critical slip surface have been compared against the output of classical slope stability methods. The FEM is a ro bust method, giving values for the factor of safety lower than classical methods and determining the location of the critical slip surface accur ately. Prior to the dynamic finite element analysis an overview of the pseudost atic method is given. The determination of the critical seismic coeffici ent by finite elements has been presented and a terminology for this pro cess is introduced namely stress increase method. The finite element res ults of the seismic coefficient are compared to those obtained by the li mit equilibrium and the limit analysis method. For the dynamic finite element analysis, a parametric analysis, using a harmonic motion, is performed to detect the effect of the frequency, pea k ground acceleration, duration, soil properties, and slope geometry. Th e effect on the slope stability of each parameter is assessed by identif ying the vertical displacement of the top of the slope. Actual earthquak e records <b>are</b> also <b>used</b> to assess the stability of the slope and the res ults are compared against those calculated by the Newmark method. Two ap proaches to enhance the Newmark displacements are suggested. The first o ne is based on the modification of the input acceleration and the second on the change of the acceleration coefficient. Potential unstable zones are evaluated and possible locations to install monitoring sensors are proposed. The FEM <b>is</b> <b>used</b> to predict the critica l displacements (total, horizontal and vertical) in a case study and the results <b>are</b> <b>used</b> to guide the instrumentation setup. This procedure has <b>been</b> <b>used</b> to detect early signs of failure and a better understanding o f the mechanism of movement. The proposed methodologies to use the FEM for practical problems have be en validated, demonstrating the applicability of finite elements to asse ss the stability of slopes for several situations and conditions. 1 General introduction 1 1. 1 The importance of slope stability assessment 1 1. 2 General aspects in landslide analysis 2 1. 3 Scope of Research 5 1. 3. 1 Solution strategy and original contributions 7 1. 4 Organisation of the dissertation 8 2 Methods for slope stability analysis 11 2. 1 Introduction 11 2. 2 Methods of analysis 12 2. 3 Limit equilibrium method 14 2. 3. 1 General considerations of LEM 15 2. 3. 2 Unified formulation for LEM. 16 2. 3. 3 Bishop’s simplified method 17 2. 3. 4 Limit equilibrium variational calculus 19 2. 4 Limit analysis method 20 2. 5 Numerical methods for slope stability 23 2. 6 Limitations and advantages of LEM compared to FEM 25 2. 6. 1 Limitations of the LEM 25 2. 6. 2 Limitations of FEM for slope stability analysis 25 2. 6. 3 Advantages of FEM over conventional methods 26 2. 7 Other slope stability methods 26 2. 8 Location of the critical slip surface 27 2. 8. 1 Slip surface optimisation 28 2. 8. 2 Physical admissibility of the solution 28 2. 9 Important aspects in slope stability analysis 29 2. 9. 1 Factor of safety 29 2. 9. 2 Criteria for the selection of the design factor of safety 30 2. 9. 3 Reliability analysis in slope stability 36 2. 9. 4 Safety map 36 2. 9. 5 Stability number 37 2. 9. 6 Effect of dilatancy on slope stability 38 2. 10 Conclusions 39 3 Finite element method for slope stability analysis 41 3. 1 Introduction 41 3. 2 Considerations in finite element analysis 42 3. 3 Literature review 43 3. 4 Mathematical formulation 57 3. 4. 1 Finite element discretisation 58 3. 4. 2 Implicit integration of differential plasticity models 59 3. 5 Strength reduction technique 61 3. 5. 1 Factor of safety definition in FE-SRM 61 3. 5. 2 Mathematical formulation for SRM 62 3. 6 Finite element slope stability analysis 63 3. 6. 1 Discretisation of the model 64 3. 6. 2 Initial state of stress 64 3. 6. 3 Strength reduction process 66 3. 6. 4 Failure mechanisms detection 67 3. 7 Comparative analysis between FEM and LEM 69 3. 7. 1 Numerical model and results 69 3. 8 Detection of local failures by FE-SRM 81 3. 8. 1 Example 1, benched slope 81 3. 8. 2 Example 2, two-slope-angles 84 3. 8. 3 Example 3, complex slope configuration 86 3. 8. 4 Discussion on determination of local failures 87 3. 9 Determination of the CSS from FE-SRM 88 3. 9. 1 Numerical examples and verification 89 3. 9. 2 Discussion on the determination of the CSS 95 3. 10 Conclusions 96 4 Enhanced limit method for slope stability analysis 99 4. 1 Introduction 99 4. 2 Enhanced limit method 100 4. 2. 1 Factor of safety definition in ELM 100 4. 2. 2 Scheme of enhanced limit method 102 4. 2. 3 Search for the critical slip surface 103 4. 3 Applications of the enhanced limit method 103 4. 3. 1 Application 2 H: 1 V slope 103 4. 3. 2 Discussion on the applicability of the results 105 4. 3. 3 Reduced strength cases, 2 H: 1 V slope 108 4. 3. 4 Application 1 H: 2 V slope 109 4. 4 Conclusions 112 5 Dynamic finite element analysis for slope stability 115 5. 1 Introduction 115 5. 2 Seismic instability in soil slopes 116 5. 3 Pseudostatic analysis 117 5. 3. 1 Selection of the design seismic coefficient 118 5. 3. 2 Critical seismic coefficient 120 5. 3. 3 Comments on pseudostatic approach 124 5. 3. 4 Determination of kc by different methods 125 5. 4 Displacement based analysis 128 5. 4. 1 Newmark method 129 5. 5 Time integration FEM 131 5. 5. 1 Boundary and initial conditions 131 5. 6 Parametric study for dynamic assessment 135 5. 6. 1 Effect of ground motion input 136 5. 6. 2 Effect of soil properties 143 5. 6. 3 Effect of slope geometry 147 5. 6. 4 Discussion on parametric study 152 5. 7 Dynamic earthquake analysis 153 5. 7. 1 Elastic response spectrum analysis 153 5. 7. 2 Newmark and FE displacements 159 5. 8 Conclusions 166 6 Slope stability monitoring 169 6. 1 Introduction 169 6. 2 Slope stability monitoring 169 6. 3 Slope monitoring sensors 171 6. 4 Presentation of case study 176 6. 4. 1 Site description 176 6. 4. 2 Geology and geotechnical characteristics 176 6. 4. 3 Finite element model 178 6. 4. 4 Location of the critical displacements 180 6. 4. 5 Slope stability analysis of case study 180 6. 4. 6 Comparison between FEM and LEM results 193 6. 4. 7 Parametric study on cohesion and friction angle, Case 1 194 6. 5 Conclusions 196 7 Back analysis of soil parameters 197 7. 1 Introduction 197 7. 2 Back analysis of strength parameters 198 7. 2. 1 Conventional procedure for back analysis 200 7. 2. 2 Optimisation problem 202 7. 2. 3 Numerical examples 203 7. 3 Back analysis of soil parameters for seepage problem 221 7. 3. 1 Groundwater flow formulation 221 7. 3. 2 Site description Fosso S. Martino Landslide 222 7. 3. 3 Numerical results from NLLS and CLM 223 7. 3. 4 Optimisation based on selected piezometers 227 7. 4 Conclusions 231 8 Conclusions and recommendations for further research 235 8. 1 Conclusions 235 8. 2 Recommendations for further research 240 Bibliography 243 status: publishe...|$|R
5000|$|... /*@cc_on @if (@_jscript_version == 11) {{document}}.write("You <b>are</b> <b>using</b> IE11 with {{an older}} document mode"); @elif (@_jscript_version == 10) document.write("You <b>are</b> <b>using</b> IE10"); @elif (@_jscript_version == 9) document.write("You <b>are</b> <b>using</b> IE9"); @elif (@_jscript_version == 5.8) document.write("You <b>are</b> <b>using</b> IE8"); @elif (@_jscript_version == 5.7 && window.XMLHttpRequest) document.write("You <b>are</b> <b>using</b> IE7"); @elif (@_jscript_version == 5.6 || (@_jscript_version == 5.7 && !window.XMLHttpRequest)) document.write("You <b>are</b> <b>using</b> IE6"); @elif (@_jscript_version == 5.5) document.write("You <b>are</b> <b>using</b> IE5.5"); @elif (@_jscript_version < 5.5) document.write("You <b>are</b> <b>using</b> a version older than IE5.5"); @else document.write("You <b>are</b> <b>using</b> an unknown version of IE"); @end @*/ ...|$|R
50|$|Where {{the list}} of suffixes has 4 forms for consonant-final stems, with the link vowels o/(a)/e/ö, the a form <b>is</b> <b>used</b> with certain back noun stems. For example, -om/(-am)/-em/-öm/-m: -om <b>is</b> <b>used</b> for lakás, -am <b>is</b> <b>used</b> for ház, -em <b>is</b> <b>used</b> for szem, -öm <b>is</b> <b>used</b> for kör and -m <b>is</b> <b>used</b> for fürdő.|$|R
