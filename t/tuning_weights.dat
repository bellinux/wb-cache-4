15|305|Public
5000|$|... #Caption: HK USP Elite and Expert 9mm with Merkle <b>Tuning</b> <b>weights</b> ...|$|E
40|$|Abstract:- In this paper, we {{extend the}} work in [2] where a genetic {{algorithm}} for <b>tuning</b> <b>weights</b> in a decisional fuzzified process was proposed. The genetic algorithm works using a multi-point dynamic crossover function. As a case study, we will test {{the behavior of the}} proposed GA on a game examples. Key-Words:- Genetic Algorithms, Fuzzy Logic, Game playing...|$|E
40|$|Abstract:- In this paper, {{we present}} a genetic {{algorithm}} for <b>tuning</b> <b>weights</b> in a decisional fuzzified process. The genetic algorithms will work using a multi-poin dynamic crossover function. As a case study, we will test {{the behavior of the}} proposed GA on a simple yet interesting game, where a winning strategy can only be based on a multi-criteria computational process...|$|E
40|$|Abstract. The paper proposes an {{adaptive}} fusion algorithm using competitiveness sensors for fire detection module, and uses computer simulation results {{to select the}} optimal weight values for each optic-sensor. Then we design the fire detection module using the <b>tuned</b> <b>weight</b> values of optic-sensors. The competitiveness flame sensor type is ultra-violet sensor (R 2868). The controller of the module is HOLTEK microchip, and acquires the detection signals from the optic-sensors through I/O pins, and transmits the detection signals of all sensors to the computer via wire series interface. The adaptive fusion algorithm can <b>tunes</b> <b>weight</b> values according to decision output of the fusion center. The fusion algorithms of the fusion center use Bayesian estimated method to decide the fire event to be true or not. We set the improved weight values in the module for each optic-sensor. From the simulation and experimental implementation results, it demonstrates that the proposed algorithms can compute the adequate weight values...|$|R
30|$|In this paper, the {{parameters}} of the <b>weight</b> functions were <b>tuned</b> by loop-shaping of the T-S response. The circuit parameters and the <b>tuned</b> <b>weight</b> function parameters can be found in Appendix A. The H∞ controllers were synthesized with the robust control toolbox included in MATLAB. In all cases, a H∞ norm of γ =  1.0046 was achieved, indicating the robust stability of the designed uncertainty.|$|R
3000|$|... where λ is the regularization {{parameter}} {{related to}} τ and it <b>tunes</b> the <b>weight</b> between the regularization term ||x [...]...|$|R
40|$|This paper {{describes}} TÜB˙ITAK-B˙ILGEM statistical {{machine translation}} (SMT) systems submitted to the Eighth Workshop on Statistical Machine Translation (WMT) shared translation task for German-English language pair in both directions. We implement phrase-based SMT systems with standard parameters. We present the results of using a big tuning data {{and the effect of}} averaging <b>tuning</b> <b>weights</b> of different seeds. Additionally, we performed a linguistically motivated compound splitting in the Germanto-English SMT system. ...|$|E
40|$|We {{introduce}} XMEANT—a new cross-lingual {{version of}} the semantic frame based MT evaluation metric MEANT—which can cor-relate even more closely with human ade-quacy judgments than monolingual MEANT and {{eliminates the need for}} expensive hu-man references. Previous work established that MEANT reflects translation adequacy with state-of-the-art accuracy, and optimiz-ing MT systems against MEANT robustly im-proves translation quality. However, to go beyond <b>tuning</b> <b>weights</b> in the loglinear SMT model, a cross-lingual objective function that can deeply integrate semantic frame crite-ria into the MT training pipeline is needed. We show that cross-lingual XMEANT out-performs monolingual MEANT by (1) replac-ing the monolingual context vector model in MEANT with simple translation probabilities, and (2) incorporating bracketing ITG con-straints. ...|$|E
40|$|To {{tackle the}} {{sensitivity}} to outliers in system identification, a new robust dynamic partial least squares (PLS) model {{based on an}} outliers detection method is proposed in this paper. An improved radial basis function network (RBFN) is adopted to construct the predictive model from inputs and outputs dataset, and a hidden Markov model (HMM) is applied to detect the outliers. After outliers are removed away, a more robust dynamic PLS model is obtained. In addition, an improved generalized predictive control (GPC) with the <b>tuning</b> <b>weights</b> under dynamic PLS framework is proposed {{to deal with the}} interaction which is caused by the model mismatch. The results of two simulations demonstrate the effectiveness of proposed method...|$|E
50|$|It {{is worth}} noting that TextRank was applied to {{summarization}} exactly as described here, while LexRank was used {{as part of a larger}} summarization system (MEAD) that combines the LexRank score (stationary probability) with other features like sentence position and length using a linear combination with either user-specified or automatically <b>tuned</b> <b>weights.</b> In this case, some training documents might be needed, though the TextRank results show the additional features are not absolutely necessary.|$|R
40|$|In the {{controller}} {{design of a}} linear time-invariant system, {{it is important to}} improve the feedback properties such as robust stability and sensitivity. In the multi-input multi-output case, these properties can be estimated by using the singular values of return difference matrix. The design method to obtain better singular-value-points is desired. How to <b>tune</b> the <b>weight</b> matrix of performance index and/or covariance matrix of noise in the Linear Quadratic Gaussian (LQC) theory to get a desired singular-value-plot was studied. First, the property of singular-value plots of return difference matrix of a system designed by LQG theory is examined from the viewpoint of <b>tuning</b> <b>weight.</b> Second, a distance between real singular-value-plots and a desired plot is defined, and the weight of performance index is numerically determined by quasi-Newton method so that the distance is minimized...|$|R
40|$|The tuning {{process of}} Unit Selection TTS (US-TTS) system is usually {{performed}} by an expert that typically conducts {{the task of}} weighting the cost function by hand. However, hand tuning is costly {{in terms of the}} required training time and inaccurate and ambiguous in terms of methodology. With the purpose of easing the task of properly <b>tuning</b> the <b>weights</b> of the cost function, this thesis make its contribution from a perceptual-based approach using of active interactive Genetic Algorithms (aiGAs). The thesis pursues four major guidelines: i) accuracy when <b>tuning</b> the <b>weights,</b> ii) robustness of the obtained weights, iii) real world applicability of the methodology to any cost function design, and iv) finding consensus of the different users when <b>tuning</b> the <b>weights.</b> The experimentation is carried out through a small and medium sized corpus (1. 9 h) applied to different configurations (type of features) of the US-TTS cost function. The thesis concludes that aiGAs are highly competitive in comparison to other <b>weight</b> <b>tuning</b> techniques from the state-of-the-artPeer ReviewedPostprint (published version...|$|R
40|$|With a few exceptions, discriminative {{training}} in {{statistical machine translation}} (SMT) has been content with <b>tuning</b> <b>weights</b> for large feature sets on small development data. Evidence from machine learning indicates that increasing the training sample size results in better prediction. The goal {{of this paper is}} to show that this common wisdom can also be brought to bear upon SMT. We deploy local features for SCFG-based SMT that can be read off from rules at runtime, and present a learning algorithm that applies ℓ 1 /ℓ 2 regularization for joint feature selection over distributed stochastic learning processes. We present experiments on learning on 1. 5 million training sentences, and show significant improvements over tuning discriminative models on small development sets. ...|$|E
40|$|Abstract—In {{this paper}} {{performance}} of Puma 560 manipulator is being compared for hybrid gradient descent and {{least square method}} learning based ANFIS controller with hybrid Genetic Algorithm and Generalized Pattern Search tuned radial basis function based Neuro-Fuzzy controller. ANFIS {{which is based on}} Takagi Sugeno type Fuzzy controller needs prior knowledge of rule base while in radial basis function based Neuro-Fuzzy rule base knowledge is not required. Hybrid Genetic Algorithm with generalized Pattern Search is used for <b>tuning</b> <b>weights</b> of radial basis function based Neuro- fuzzy controller. All the controllers are checked for butterfly trajectory tracking and results in the form of Cartesian and joint space errors are being compared. ANFIS based controller is showing better performance compared to Radial Basis Function based Neuro-Fuzzy Controller but rule base independency of RBF based Neuro-Fuzzy gives it an edge over ANFI...|$|E
40|$|In this paper, {{the authors}} {{describe}} design and motivational {{issues of the}} web-based system SocialX. It supports social-collaborative and cooperative aspects of e-learning such as sharing and reuse of (solutions to) single exercises, and development of projects by group-work and social exchange. Such aspects are supported {{in the framework of}} a reputation system, in which learners participate. A learner’s reputation is computed, presented, and maintained during her/his interactions with the system. The algorithm to compute reputation can be configured by the teacher from <b>tuning</b> <b>weights</b> associated to various aspects of the interactions. To enhance collaboration on exercises, the authors support contextual (to the exercise) micro-forum and FAQs with a currency-based concretization of the perceived usefulness of questions/answers. Group responsibilities, peer-assessment, and self-evaluation are supported by group-based projects with self/peer-evaluated phases, i. e., different stages of a project are assigned to different groups and a stage-deliverable is both self-evaluated (at submission) and peer-evaluated (by the group receiving it for the next stage) ...|$|E
40|$|Structured perceptrons are {{attractive}} {{due to their}} simplicity and speed, and have been used successfully for <b>tuning</b> the <b>weights</b> of binary features in a machine translation system. In attempting to apply them to <b>tuning</b> the <b>weights</b> of real-valued features with highly skewed distributions, we found {{that they did not}} work well. This paper describes a modification to the update step and compares the performance of the resulting algorithm to standard minimum error-rate training (MERT). In addition, preliminary results for combining MERT or structured-perceptron tuning of the log-linear feature weights with coordinate ascent of other translation system parameters are presented. ...|$|R
40|$|Abstract: Following {{the works}} {{presented}} in St Petersburg during the 16 th IFAC Symposium on Automatic Control in Aerospace, Airbus {{has been working}} on the design and evaluation of more integrated control laws, taking into account multi-objectives design criteria, gathering from the very beginning the specifications in term of handling qualities, comfort, loads, and robustness. A non-conservative H ∞ schema allows to directly associate each criterion to a dedicated exogenous transfer function and a <b>tuning</b> <b>weighting.</b> This approach offers an easy tuning, criterion by criterion, guaranteeing optimal results. This is also very convenient for industrial evaluation of reachable compromises between criteria, and Pareto-like plotting. Copyright © 2005 IFA...|$|R
40|$|In {{this paper}} {{we present a}} family of {{algorithms}} for estimating stream weights for dynamic Bayesian networks with multiple observation streams. For the 2 stream case, we present a <b>weight</b> <b>tuning</b> algorithm optimal in the minimum classification error sense. We compare the algorithms to brute-force search where feasible, {{as well as to}} previously published algorithms and show that the algorithms perform as well as brute-force search and outperform previously published algorithms. We test the stream <b>weight</b> <b>tuning</b> algorithm in the context of speech recognition with distinctive feature tandem models. We analyze how the criterion used for <b>weight</b> <b>tuning</b> differs from the standard word error rate criterion used in speech recognition...|$|R
40|$|Classification {{is one of}} {{the most}} {{frequent}} studies in the area of Artificial Neural Network (ANNs). The ANNs are capable of generating a complex mapping between the input and the output space to form arbitrarily complex nonlinear decision boundaries. One of the best-known types of ANNs is the Multilayer Perceptron (MLP). MLP usually requires a large amount of available measures in order to achieve good classification accuracy. To overcome this, a Functional Link Neural Networks (FLNN) which has a single layer of trainable connection weights is used. The single layer property of FLNN also make the learning algorithm used less complicated compared to MLP network. The standard learning method for <b>tuning</b> <b>weights</b> in FLNN is Backpropagation (BP) learning algorithm. However, the algorithm is prone to get trapped in local minima which affect the performance of FLNN network. This work proposed the implementation of modified Artificial Bee Colony with Firefly algorithm for training the FLNN network to overcome the drawback of BP-learning algorithm. The aim is to introduce an improved learning algorithm that can provide a better solution for training the FLNN network for the task of classification...|$|E
40|$|SocialX is a web {{application}} supporting social-collaborative and cooperative aspects of e-learning, such as sharing and reuse of (solutions to) single exercises, {{and development of}} projects by group-work and social exchange. Such aspects are supported {{in the framework of}} a reputation system, in which learners participate. We describe design and motivational issues of the system, show implementation details and describe a small-scale experimentation that helped evaluating the effectiveness of the system as well as the best lines for further development. In the system, learner’s reputation is computed, presented and maintained during her/his interactions with the system. The algorithm to compute reputation can be configured by the teacher, by <b>tuning</b> <b>weights</b> associated to various aspects of the interactions. To enhance collaboration on exercises, we support contextual (to the exercise) micro-forum and FAQs, together with a currency-based concretization of the perceived usefulness of questions/answers. Group responsibilities, peer-assessment and self-evaluation are supported by group-based projects with self/peer-evaluated phases: Different stages of a project are assigned to different groups; a stage-deliverable is both self-evaluated (at submission) and peer-evaluated (by the group receiving it for the next stage). This paper is an extension of the original version, published on the International Journal of Information Systems and Social Change: mainly two sections were added, describing the latest improvements and some experimentation...|$|E
40|$|Abstract—We {{study the}} {{performance}} of an opportunistic scheduling scheme maximum quantile scheduling, i. e., scheduling a user whose current rate is in the highest quantile relative to its current rate distribution, in a wireless system. In a practical scenario {{it is unlikely that}} users ’ rate distributions are known at the scheduler, and have to be estimated via measurement. Under the assumption of fast fading, we prove a bound on the relative penalty associated with such estimates, showing that number of independent samples need only grow linearly with the number of active users. This is a fairly limited cost, suggesting one could track distributional changes in users ’ channels. By contrast other opportunistic scheduling schemes require estimating or setting weights/thresholds that implicitly depend not only on the number of users, but also their rate distributions, and possibly their traffic characteristics. In other words the penalty associated with <b>tuning</b> <b>weights</b> for other schemes can be higher than that associated with estimating users ’ rate distributions for maximum quantile scheduling. This statement is supported by our simulation results. Furthermore we prove that if rates are bounded and number of users is high, maximum quantile scheduling is sum average throughput maximizing subject to temporal fairness...|$|E
40|$|In {{our recent}} work on concatenative speech synthesis, we have devised an efficient, {{graph-based}} search to perform unit selection given symbolic information. By encapsulating concatenation and substitution costs defined at the class level, the graph expands only linearly {{with respect to}} corpus size. To date, these costs were manually tuned over pre-specified classes, which was a knowledgeintensive engineering process. In this research paper, we turn to information-theoretic metrics for automatically learning the costs from data. These costs can be analyzed in a minimum description length (MDL) framework. The performance of these automatically determined weights is compared against that of manually <b>tuned</b> <b>weights</b> in a perceptual evaluation...|$|R
40|$|This is {{the first}} year for the Centre for Interactive Systems Research {{participation}} of INEX. Based on a newly developed XML indexing and retrieval system on Okapi, we extend Robertson’s field-weighted BM 25 F for document retrieval to element level retrieval function BM 25 E. In this paper, we introduce this new function and our experimental method in detail, and then show how we <b>tuned</b> <b>weights</b> for our selected fields by using INEX 2004 topics and assessments. Based on the tuned models we submitted our runs for CO. Thorough, CO. FetchBrowse, the methods we propose show real promise. Existing problems and future work are also discussed. 1...|$|R
40|$|A novel surface-integral-equation (SIE) {{formulation}} {{is proposed}} by <b>tuning</b> the <b>weighting</b> {{coefficients for the}} external- and inter nal-region integral equations. Without increasing the computational cost, the present formulation significantly enlarges the solvable skin-depth range. © 2005 Wiley Periodicals, Inc. link_to_subscribed_fulltex...|$|R
40|$|Purpose – Electromagnetic design utilising {{finite element}} or similar {{numerical}} methods is computationally expensive, thus efficient algorithms {{reducing the number}} of objective function calls to locate the optimum are sought. The balance between exploration and exploitation may be achieved using a reinforcement learning approach, as demonstrated previously. However, in practical design problems, in addition to finding the global optimum efficiently, information about the robustness of the solution may also be important. In this paper, the aim is to discuss the suitability of different search algorithms and to present their fitness to solve the optimization problem in conjunction with providing enough information on the robustness of the solution. Design/methodology/approach – Two novel strategies enhanced by the surrogate model based weighted expected improvement approach are discussed. The algorithms are tested using a two-variable test function. The emphasis of these strategies is on accurate approximation of the shape of the objective function to accomplish a robust design. Findings – The two novel strategies aim to pursue the optimal value of weights for exploration and exploitation throughout the iterative process for better prediction of the shape of the objective function. Originality/value – It is argued that the proposed strategies based on adaptively <b>tuning</b> <b>weights</b> perform better in predicting the shape of the objective function. Good accuracy of predicting the shape of the objective function is crucial for achieving a robust design...|$|E
40|$|Model {{predictive}} control (MPC) {{has often been}} referred to in literature as a potential method for more efficient control of building heating systems. Though a significant performance improvement can be achieved with an MPC strategy, the complexity introduced to the commissioning {{of the system is}} often prohibitive. Models are required which can capture the thermodynamic properties of the building with sufficient accuracy for meaningful predictions to be made. Furthermore, a large number of <b>tuning</b> <b>weights</b> may need to be determined to achieve a desired performance. For MPC to become a practicable alternative, these issues must be addressed. Acknowledging the impact of the external environment as well as the interaction of occupants on the thermal behaviour of the building, in this work, techniques have been developed for deriving building models from data in which large, unmeasured disturbances are present. A spatio-temporal filtering process was introduced to determine estimates of the disturbances from measured data, which were then incorporated with metaheuristic search techniques to derive high-order simulation models, capable of replicating the thermal dynamics of a building. While a high-order simulation model allowed for control strategies to be analysed and compared, low-order models were required for use within the MPC strategy itself. The disturbance estimation techniques were adapted for use with system-identification methods to derive such models. MPC formulations were then derived to enable a more straightforward commissioning process and implemented in a validated simulation platform. A prioritised-objective strategy was developed which allowed for the tuning parameters typically associated with an MPC cost function to be omitted from the formulation by separation of the conflicting requirements of comfort satisfaction and energy reduction within a lexicographic framework. The improved ability of the formulation to be set-up and reconfigured in faulted conditions was shown...|$|E
40|$|Video is {{the most}} {{demanding}} modality from the viewpoints of bandwidth, computational complexity, and resolution. Thus, there has been limited progress {{in the field of}} mobile video technology. In the research, the focus is on elastic wireless video technology, and its adaptation to diagnostic application requirements in real-time clinical assessment. It is important and timely to apply wireless video technology to real-time remote diagnosis of emergent medical events. This premise comes from initial successes in telehealth based on wired networks. The enablement of mobility (for the physician and/or the patient) by wireless communication will be a next major step, but this advance will depend on definitive and compelling demonstrations of reliability. Thus, an important goal of the research is to develop a complete methodology that will be embraced by physicians. Acute pediatric asthma has been identified as a domain where this new capability will be highly welcome. The research uses flexible and interactive algorithms for Region-of-Interest (ROI) processing. ROI processing is a useful approach to achieve the optimal balance in the quality-bandwidth tradeoff characteristic of visual communication services. The notion of ROI has been traditionally used mostly for foreground-background separation in scene rendering and manipulation, and only more recently for variably quality compression. Even when the latter goal is considered, quality criteria have been ad-hoc and at best useful for video conferencing, given that the medical domain has its own fidelity criteria. The research thus focuses on the design of an elastic ROI-based compression paradigm with medical diagnosis as a central criterion. The research describes the methodology to achieve elasticity through rate control algorithms at the encoder. An elastic non-parametric approach is proposed that uses a priori user-specified video quality information, quantifies this information, and incorporates this into the encoder in the form of region-quality mappings. This method is compared to a parametric bit allocation approach that is based on region-features and a set of <b>tuning</b> <b>weights.</b> A number of videos of actual patients were filmed and used as the video database for the developed algorithms. In testing the elastic non-parametric and parametric algorithms, both objective measures in the form of Peak Signal to Noise Ratio (PSNR), and subjective evaluations were used. Thus, in this work, the focus is on domain relevance of the algorithms developed, as opposed to network related issues such as packet losses. This is justified in that these may have broader value with other applications, and continuation of this work will include realistic network conditions. To summarize, the research shows the usefulness of ROI processing as a means of achieving a gain (in a bits per pixel sense) over uniform compression at the same bitrate. It also shows how quantifying a notion of functionally lossless video quality diagnostically lossless video quality in a video-based telehealth system, in a bits per pixel sense is useful from an applications and bitrate perspective. Finally, a combination of these two concepts is advantageous i. e. diagnostically lossless ROI video quality is achievable over bitrate limited channels. Ph. D. Committee Chair: Jayant, Nikil; Committee Member: Abowd, Gregory; Committee Member: Madisetti, Vijay; Committee Member: Mersereau, Russell; Committee Member: Yezzi, Anthon...|$|E
40|$|Abstract: According to {{the time}} delay in {{industrial}} control objects, the PID neural network control method and Smith predictor compensation principle are combined to form the PIDNN-Smith control algorithm. Namely, in Smith predictor compensation control system, the PIDNN as the controller, using the PIDNN neural network on-line self-learning function to <b>tune</b> <b>weight</b> value, make the implicit layers of proportion, integral and differential neurons to achieve the best combination, thus overcome disadvantages of the conventional PID algorithm that does not adapt to the control of large delay system and conventional Smith algorithm depended too much on model precision of the defect. Simulation results show strong robustness and good control quality of this algorithm. ...|$|R
3000|$|... [...]. As {{the optimal}} number of {{iteration}} k increases, u {{is close to}} the noisy image f. The scale parameter λ <b>tunes</b> the <b>weight</b> between the regularization and fidelity terms. The iterated refinement method yields a well-defined sequence of minimizers {u [...]...|$|R
40|$|In {{this paper}} we propose a {{constrained}} version of Mumford-Shah’s[1] segmentation with an information-theoretic point of view[2] in order to devise a systematic procedure to segment brain MRI data for two modalities of parametric T 1 -Map and T 1 -weighted images in both 2 -D and 3 -D settings. The incorporation of a <b>tuning</b> <b>weight</b> in particular adds a probabilistic �avor to our segmentation method, and makes the three-tissue segmentation possible. Our method uses region based active contours which have proven to be robust. The method is validated by two real objects which were used to generate T 1 -MapsandalsobytwosimulatedbrainsofT 1 -weighted data from the BrainWeb[3] public database. Index Terms — Active contour, Region-based active contour, Mumford-Shah, T 1 -Map, T 1 -weighted imag...|$|R
40|$|In the {{electromagnetic}} field measurement data postprocessing, this paper introduced the moving least squares (MLS) approximation method. The MLS combines {{the concept of}} moving window and compact support weighting functions. It {{can be regarded as}} a combination of weighted least squares and segmented least square. The MLS not only can acquire higher precision even with low order basis functions, but also has good stability due to its local approximation scheme. An attractive property of MLS is its flexible adjustment ability. Therefore, the data fitting can be easily adjusted by <b>tuning</b> <b>weighting</b> function’s parameters. Numerical examples and measurement data processing reveal its superior performance in curves fitting and surface construction. So the MLS is a promising method for measurement data processing...|$|R
40|$|AutoNowCaster (ANC) is an {{automated}} system that nowcasts thunderstorms, including thunderstorm initiation. However, its parameters {{have to be}} tuned to regional environments, {{a process that is}} time-consuming, labor-intensive and quite subjective. When the National Weather Service decided to explore using ANC in forecast operations, a faster, less laborintensive and objective mechanism to tune the parameters for all the forecast offices was sought. In this paper, a genetic algorithm approach to tuning ANC is described. The process consisted of choosing data sets, employing an objective forecast verification technique and devising a fitness function. ANC was modified to create nowcasts offline using weights iteratively generated by the genetic algorithm. The weights were generated by probabilistically combining weights with good fitness, leading to better and better <b>weights</b> as the <b>tuning</b> process proceeded. The nowcasts created by ANC using the automatically determined weights are compared with the nowcasts created by ANC using weights that were the result of manual tuning. It is shown that nowcasts created using the automatically <b>tuned</b> <b>weights</b> are as skilled as the ones created through manual tuning. In addition, automated tuning can be done in a fraction of the time that it takes experts to analyze the data and <b>tune</b> the <b>weights.</b> 2...|$|R
50|$|The most {{original}} {{feature of}} KnightCap, {{introduced in the}} late 1990s, was an experiment in temporal difference learning as applied to chess. This technique allowed KnightCap to automatically <b>tune</b> the <b>weights</b> applied to the various features in its evaluation function based on the games it played.|$|R
40|$|Linear {{parameter}} varying (LPV) {{models are}} widely used in control applications of the nonlinear MIMO dynamic systems. LPV models depend on the time varying parameters. This paper develops a polytopic quasi-LPV model for a nonlinear pan-tilt robotic system. A Linear Quadratic Regulator (LQR) that utilizes Linear Matrix Inequalities (LMIs) with well <b>tuned</b> <b>weighting</b> matrices is synthesized based on the developed LPV model. The number of time varying parameters in the developed polytopic LPV model is 4 so the number of vertices becomes 16. The desired controller is generated by the interpolation of LMIs at each vertex. The performance of the optimal LQR controller is evaluated by using the designed feedback gain matrix to stabilize the nonlinear pan-tilt system. Simulations performed on the nonlinear model of the pan-tilt system demonstrate success of the proposed LPV control approach...|$|R
30|$|SSTC {{algorithm}} {{described above}} {{has the advantage}} of not requiring any <b>tuning</b> of <b>weights</b> in Eq. (14). This has two reasons. The first reason is that different suffix units are used for pitch and LSF features and suffix selection is done independently for those two features. The second reason is that concatenation cost is not used.|$|R
40|$|We {{develop a}} theory characterizing optimal {{stopping}} times for discrete-time ergodic Markov processes with discounted rewards. The theory differs from prior work by {{its view of}} per-stage and terminal reward functions as elements of a certain Hilbert space. In addition to a streamlined analysis establishing existence and uniqueness of a solution to Bellman's equation, this approach provides an elegant framework {{for the study of}} approximate solutions. In particular, we propose a stochastic approximation algorithm that <b>tunes</b> <b>weights</b> of a linear combination of basis functions in order to approximate a value function. We prove that this algorithm converges (almost surely) and that the limit of convergence has some desirable properties. We discuss how variations on this line of analysis can be used to develop similar results for other classes of optimal stopping problems, including those involving independent increment processes, finite horizons, and two [...] player zero [...] sum games. We illustrate [...] ...|$|R
