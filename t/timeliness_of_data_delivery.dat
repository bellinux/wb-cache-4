8|10000|Public
40|$|Messages transported {{within a}} sensor network {{are subject to}} losses due {{to a number of}} factors. These factors include losses in the {{wireless}} channel, MAC layer collisions, node error or failure and losses due to incorrect routing. This paper describes these sources of data loss and discusses the various strategies available to prevent data loss. The effectiveness of each of the strategies to prevent the different types of data loss is discussed. In particular, it is examined how the implementation of any particular scheme affects network performance. Here we define performance as accurate sensing of phenomena, reliable delivery of data, and the <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery.</b> The implementation of reliability mechanisms in a sensor network can adversely effect the <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery</b> thus presenting a design trade off in this area. Our principal contribution is the identification and description of this problem. Furthermore, we discuss the trade offs between reliability and delay and investigate the need for a framework to aid in WSN design in this area. It is our intention to implement and evaluate such a framework in our ongoing research. I...|$|E
40|$|The 'Firefly' {{project is}} {{developing}} an infrared {{remote sensing system}} to provide near real-time wildland fire information for fire management and suppression. Recent technological advances in several areas now allow the design of an end-to-end, infrared system to map and detect wildland fires. The system components will include an airborne infrared sensor, automatic onboard signal and data processing, telecommunications link, and integration into a ground data terminal. The system will provide improved performance over current systems in terms of increased <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery,</b> quantifiable accuracy, data consistency, reliability, and maintainability. The system {{will be the next}} generation of wildland fire mapping and detection system for the United States Forest Service...|$|E
40|$|Abstract — Lightweight {{protocols}} {{that are}} both bandwidth and power thrifty are desirable for sensor networks. In addition, for many sensor network applications, <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery</b> at a sink that collects and interprets raw sensor data is of great importance. In this work, we propose a lightweight framework for source-to-sink data transfer in a wireless sensor network that is geared towards achieving the above two objectives. Our integrated framework consists of three elements: 1) simple labels that eliminate complex addressing requirements, 2) implicit routing that provides an inherent robustness during sleep/wake schedules, and 3) MAC layer anycast to support routing. Our framework, in addition, facilitates the self-organization of sensor nodes into a network that efficiently relays information from the sources to the sink. The key idea of our framework is to associate each sensor node with a hierarchical level {{with respect to a}} sink and using MAC layer anycast to simply further packets to higher levels towards the sink. There are no explicit route tables created or maintained; this eliminates the overhead due to route queries or updates, the need for complex processing and the memory requirements for caching routing information. Furthermore, with our framework, the energy costs of data transmission are evenly distributed across the nodes, thereby improving the longevity of the network. Our MAC layer anycast mechanism not only facilitates routing, but also reduces the number of MAC layer back-offs incurred and, consequently, the waiting times for data transmission. This in turn, improves the <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery</b> at the sink. To summarize, our framework is a) energy efficient, b) inherently robust, and c) conceptually simple. We qualitatively assess our scheme to show its efficiency in terms of power consumption, robustness to failure, ease of setup. The results from our simulations and assessments demonstrate the aforementioned benefits and the viability and potential of using our framework...|$|E
40|$|Unlike non-time-critical {{applications}} like email {{and file}} transfer, network games demand timely <b>data</b> <b>delivery</b> {{to maintain the}} seemingly interactive presence of players in the virtual game world. Yet the inherently large transmission delay mean and variance of 3 G cellular links make on-time game <b>data</b> <b>delivery</b> difficult. Further complicating the timely game <b>data</b> <b>delivery</b> problem is the frequent packet drops at these links due to inter-symbol interference, fading and shadowing at the physical layer. In this paper, we propose a proxy architecture that enhances the <b>timeliness</b> and reliability <b>of</b> <b>data</b> <b>delivery</b> <b>of</b> interactive games over 3 G wireless networks. In particular, a performance enhancing proxy is designed to optimize a new time-critical data type — variable-deadline data, where the utility of a datum is inversely proportional to {{the time required to}} deliver it. We show how a carefully designed and configured proxy can noticeably improve the <b>delivery</b> <b>of</b> network game <b>data...</b>|$|R
40|$|High Speed Packet Data Access (HSDPA) is {{a recent}} {{development}} of third gen-eration (3 G) wireless systems to enable several applications to be available through wireless communication. In order to increase performance (reliable and timely <b>data</b> <b>delivery),</b> HSDPA supports new features related to the con-trol of the radio resources, and scheduling of the users. However, even though HSDPA evolution offers several performance improvements, large fluctuations in the delay <b>of</b> the <b>data</b> <b>delivery</b> still exist. This makes difficult {{the adoption of the}} Transmission Control Protocol (TCP) over HSDPA. In this thesis, a con-trol structure already proposed in literature is studied and extended to im-prove user experience of TCP over HSDPA. Specifically, the control structure is a proxy entity residing in the communication chain between the server and the mobile phone. The proxy can enhances the <b>timeliness</b> and reliability <b>of</b> <b>data</b> <b>delivery,</b> thus it is a good candidate for real time applications. We have implemented a complete HSDPA communication chain from the server (th...|$|R
5000|$|Improved <b>timeliness</b> <b>of</b> <b>data</b> {{exchange}} (no more {{waiting for}} the mail & faster lien releases).|$|R
40|$|Towards {{understanding}} {{the complexity of}} joint QoS and in-network processing (INP) optimization in sensornets, we study the problem of jointly optimizing packet packing and the <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery.</b> We identify {{the conditions under which}} the problem is strong NP-hard, and we find that the problem complexity heavily depends on aggregation constraints instead of network and traffic properties. For cases when the problem is NP-hard, we show that there is no polynomial-time approximation scheme (PTAS); for cases when the problem can be solved in polynomial time, we design polynomial time, offline algorithms for finding the optimal packet packing schemes. We design a distributed, online protocol tPack that schedules packet transmissions to maximize the local utility of packet packing at each node. We evaluate the properties of tPack in NetEye testbed. We find that jointly optimizing data delivery timeliness and packet packing and considering real-world aggregation constraints significantly improve network performance...|$|E
40|$|Data {{transport}} is a core {{function for}} Wireless Sensor Networks (WSNs) with different applications having varied requirements on {{the reliability and}} <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery.</b> While node redundancy, inherent in WSNs, increases the fault tolerance, no guarantees on reliability levels can be assured. Furthermore, the frequent failures within WSNs impact the observed reliability over time {{and make it more}} challenging to achieve the desired reliability. Unfortunately, a framework for modeling reliability of data transport protocols in WSNs is currently missing. The existence of such a framework would simplify evaluation, comparison and also adaptation of these protocols. We formulate the problem of data transport in a WSN as a set of operations carried out on raw data. The operations aim at filtering the raw data to streamline its reliable transport towards the sink. Based on this formulation we systematically define a reliability framework. This paper argues for the usefulness of the reliability framework by classifying existing transport protocols and comparing their reliability. 1...|$|E
40|$|Abstract—As sensornets are {{increasingly}} being deployed in mission-critical applications, it becomes imperative that we consider application QoS requirements in in-network processing (INP). Towards understanding the complexity of joint QoS and INP optimization, we study the problem of jointly optimizing packet packing (i. e., aggregating shorter packets into longer ones) and the <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery.</b> We identify {{the conditions under which}} the problem is strong NP-hard, and we find that the problem complexity heavily depends on aggregation constraints (in particular, maximum packet size and re-aggregation tolerance) instead of network and traffic properties. For cases when the problem is NP-hard, we show that there is no polynomial-time approximation scheme (PTAS); for cases when the problem can be solved in polynomial time, we design polynomial time, offline algorithms for finding the optimal packet packing schemes. To understand the impact of joint QoS and INP optimization on sensornet performance, we design a distributed, online protocol tPack that schedules packet transmissions to maximize the local utility of packet packing at each node. Using a testbed of 130 TelosB motes, we experimentally evaluate the properties of tPack. We find that jointly optimizing data delivery timeliness and packet packing and considering real-world aggregation constraints significantly improve network performance. Our findings shed light on the challenges, benefits, and solutions of joint QoS and INP optimization, and they also suggest open problems for future research. Index Terms—Wireless network, sensor network, real-time, packet packing, in-network processing I...|$|E
3000|$|Timeliness. The {{common ground}} of {{measurement}} methods {{for determining the}} validity <b>of</b> <b>data</b> {{can be found in}} the application of probability theory (Heinrich and Klier 2015; Hinrichs 2002). The value <b>of</b> <b>data</b> decreases exponentially over time (Heinrich and Klier 2015, 91 f). The <b>timeliness</b> <b>of</b> <b>data</b> remains dependent on the time of delivery to the respective recipient. Consequently, this can only be validly determined by the recipient (Wang and Strong 1996, 7). This leads to the following hypothesis H 1 : ‘The better the expected <b>timeliness</b> <b>of</b> <b>data,</b> the better the perceived objective truth.’ [...]...|$|R
5000|$|Reactive {{systems are}} limited by the quality and <b>timeliness</b> <b>of</b> the <b>data</b> entered into them. Deficiencies in crash {{reporting}} limit {{the effectiveness of these}} systems.|$|R
40|$|In hybrid energy {{harvesting}} sensor networks, {{there is a}} trade-off between the cost <b>of</b> <b>data</b> collection by a wireless sink and the <b>timeliness</b> <b>of</b> the collected <b>data.</b> The trade-off further depends on the {{energy harvesting}} capability of the sensor nodes as sensors cannot transmit data {{if they do not}} have sufficient energy. In this paper, we propose an analytic model for assessing the value of the information that a sensor node brings to decision making. We account for the <b>timeliness</b> <b>of</b> <b>data</b> by discounting the value of the information at the sensor over time and adopt the energy-chunk approach (i. e. discretise the energy level) to track energy harvesting and expenditure over time. Finally, by numerical experiments, we study the optimal data collection rate for the sensor node at hand...|$|R
30|$|The {{physical}} resources and infrastructures in a CPS span multiple scales (e.g., sensors capturing real-time {{events at the}} hardware layer, to networked communication for dissemination of critical information from event sources to multiple destinations). A key challenge in managing the disparate abstractions in the logical, physical, and temporal dimensions is the consistent cross-layer modeling of information flow across these abstractions. A modeling framework is required that can capture the layered CPS architecture and application needs, analyze current system state, detect violation of end-to-end dependability requirements, and reason {{about the validity of}} adaptations. To determine the best strategies for adaptation, a system that can carry out gedanken experiments to predict the outcomes under different policies or parameter settings is best suited (e.g., reflective route planning for DTNs [36]). To enable such gedanken experiments, a system must have a representation of and reason about itself. This can be achieved through executable models of the system that have well-described state and behavior in a framework with well-defined reasoning principles. Such formal executable models can then be used for reasoning and analysis, and relating dependability constraints (e.g., accuracy of measurement or expected <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery)</b> to component parameters. The verification and validation of CPS is notoriously difficult and conventional techniques are too expensive; factoring out the minimal functionality common to CPS is a first step toward making verification feasible, because the cost of verification can be amortized over many instantiations of the common framework. This is far from enough, however, because mission-specific properties and performance metrics will require verification, also, and the mission-specific software will typically be much more complex than the minimal framework. Furthermore, conventional verification cannot enable rapid deployment at acceptable cost.|$|E
40|$|As {{wireless}} cyber-physical systems (WCPS) {{are increasingly}} being deployed in mission-critical applications, it becomes imperative that we consider application QoS requirements in in-network processing (INP). In this dissertation, we explore the potentials of two INP methods, packet packing and network coding, on improving network performance while satisfying application QoS requirements. We find that not only can these two techniques increase the energy efficiency, reliability, and throughput of WCPS while satisfying QoS requirements of applications in a relatively static environment, but also they can provide low cost proactive protection against transient node failures in a more dynamic wireless environment. We first study the problem of jointly optimizing packet packing and the <b>timeliness</b> <b>of</b> <b>data</b> <b>delivery.</b> We identify {{the conditions under which}} the problem is strong NP-hard, and we find that the problem complexity heavily depends on aggregation constraints instead of network and traffic properties. For cases when the problem is NP-hard, we show that there is no polynomial-time approximation scheme (PTAS); for cases when the problem can be solved in polynomial time, we design polynomial time, offline algorithms for finding the optimal packet packing schemes. We design a distributed, online protocol tPack that schedules packet transmissions to maximize the local utility of packet packing at each node. We evaluate the properties of tPack in NetEye testbed. We find that jointly optimizing data delivery timeliness and packet packing and considering real-world aggregation constraints significantly improve network performance. We then work on the problem of minimizing the transmission cost of network coding based routing in sensor networks. We propose the first mathematical framework so far as we know on how to theoretically compute the expected transmission cost of NC-based routing in terms of expected number of transmission. Based on this framework, we design a polynomial-time greedy algorithm for forwarder set selection and prove its optimality on transmission cost minimization. We designed EENCR, an energy-efficient NC-based routing protocol that implement our forwarder set selection algorithm to minimize the overall transmission cost. Through comparative study on EENCR and other state-of-the-art routing protocols, we show that EENCR significantly outperforms CTP, MORE and CodeOR in delivery reliability, delivery cost and network goodput. Furthermore, we study the 1 + 1 proactive protection problem using network coding. We show that even under a simplified setting, finding two node-disjoint routing braids with minimal total cost is NP-hard. We then design a heuristic algorithm to construct two node-disjoint braids with a transmission cost upper bounded by two shortest node-disjoint paths. And we design ProNCP, a proactive NC-based protection protocol using similar design philosophy as in EENCR. We evaluate the performance of ProNCP under various transient network failure scenarios. Experiment results show that ProNCP is resilient to various network failure scenarios and provides a state performance in terms of reliability, delivery cost and goodput. Our findings in this dissertation explore the challenges, benefits and solutions in designing real-time, efficient, resilient and QoS-guaranteed wireless cyber-physical systems, and our solutions shed lights for future research on related topics...|$|E
3000|$|Velocity. Due {{to changes}} in the {{environment}} (Seufert 2016, 40) an increase <b>of</b> <b>data</b> value volatility can be observed. This means that there is a reduced half-life <b>of</b> <b>data.</b> This increases the technical speed requirements for the underlying data work (Vargas-Solar et al. 2016, 2 – 12; Seufert 2016, 41 and 48 – 54). A high up-to-date value implies new hardware and software technologies as promised by big data analytics. Velocity is necessary per a certain level on the <b>timeliness</b> <b>of</b> <b>data</b> resulting in hypothesis H 2 : ‘The greater the need for the big data characteristic velocity, the better the expected <b>timeliness</b> <b>of</b> the data’ [...]...|$|R
3000|$|... the {{performance}} evaluation <b>of</b> <b>data</b> <b>delivery</b> (e.g., ITS-related content) on service channels when only RSUs act as providers and when hybrid connectivity solutions are considered.|$|R
30|$|Our use <b>of</b> <b>data</b> {{from both}} {{providers}} {{does appear to}} be justified. If we were to include data from just one of the providers, MADIS would generally provide more timely data while MesoWest would provide coverage of some cells that MADIS does not cover. As such, the providers are complementary for our application. If we were most concerned with the overall size <b>of</b> our <b>data</b> downloads, we could possibly use MesoWest data alone, but we would be sacrificing <b>timeliness</b> <b>of</b> <b>data</b> in the process.|$|R
40|$|This {{report is}} a summary {{assessment}} <b>of</b> Sri Lanka’s <b>data</b> dissemination practices against the IMF’s Special Data Dissemination Standard (SDDS), complemented by an in-depth {{assessment of the}} elements <b>of</b> <b>data</b> quality that underlie the national accounts, prices, government finance, monetary, and balance-of-payments statistics. Sri Lanka has made good progress in meeting most of the SDDS specifications on coverage, periodicity, and <b>timeliness</b> <b>of</b> <b>data</b> categories. Shortcomings exist in the access, integrity, and quality dimensions compared with the SDDS. All agencies demonstrate professionalism and are generally transparent in their practices and policies...|$|R
5000|$|Sitebase Clinical Systems, Inc., a {{provider}} <b>of</b> remote <b>data</b> entry technology {{designed to enhance}} the quality and <b>timeliness</b> <b>of</b> clinical trial <b>data.</b>|$|R
30|$|MesoWest adds {{coverage}} {{at several}} maritime cells that MADIS does not cover, {{as well as}} a cell in Arizona near the southeast border with California. More importantly it adds coverage for a cell adjacent to Interstate 10 east of Barstow. MADIS improves the <b>timeliness</b> <b>of</b> <b>data</b> across nearly the entire map. There are a few exceptions including a cell northwest of Bakersfield in which MesoWest improves the average lag_coverage by over 50  mins. Another cell located east of San Diego is improved by over 40  mins.|$|R
40|$|In most states, police {{officers}} and trained investigators complete crash reports for nearly all reportable crashes that occur on public roads. Many states have made significant improvements in the quality and <b>timeliness</b> <b>of</b> their crash <b>data</b> systems by implementing, {{in addition to other}} improvements, electronic filing of these reports by {{police officers}}. Oregon relies on citizen reports for a majority <b>of</b> their crash <b>data</b> and paper forms must be submitted to the responsible state agency and are then manually coded into the crash data system. Police reports are also paper based. This process limits the improvements that can be made in both the quality and <b>timeliness</b> <b>of</b> <b>data</b> unless enhancements can be made to the reporting process. This paper summarizes the preliminary results of a study on the feasibility of implementing a web-based system for reporting crashes, with a focus on citizen reporting {{and to a lesser extent}} police reporting...|$|R
40|$|To {{assess the}} value of ICD- 9 -coded chief {{complaints}} for early detection of epidemics, we measured sensitivity, positive predictive value, and <b>timeliness</b> <b>of</b> Influenza detection using a respiratory set (RS) of ICD- 9 codes and an Influenza set (IS). We also measured inherent <b>timeliness</b> <b>of</b> these <b>data</b> using the cross-correlation function...|$|R
30|$|The global {{visibility}} and runtime programmability enabled by SDN technologies introduce unprecedented capabilities to guard {{a communication network}} adequately against cyber incidents. More specifically, the global visibility boosts the efficiency and effectiveness of network-wide traffic management, while the runtime programmability enables the SDN controller to adjust traffic management schedules on demand [52]. Besides, SDN technologies realize the per-flow micromanagement that is especially useful for checking the data integrity while ensuring the <b>timeliness</b> <b>of</b> <b>data</b> transmission. SDN technologies also make the implementation of security policies (i.e., access control, application whitelist) more convenient across the communication network.|$|R
40|$|International Telemetering Conference Proceedings / October 26 - 29, 1992 / Town and Country Hotel and Convention Center, San Diego, CaliforniaThe current F/A- 18 data reduction/analysis {{system is}} {{incapable}} of meeting increased customer demands. A new system has been developed {{and is based on}} new technologies. In the process of developing the new system, the design team had to divorce themselves from the current system and consider what the ideal system would consist of. This was accomplished with great success in the areas <b>of</b> <b>timeliness</b> <b>of</b> <b>data</b> turn around, customer satisfaction, and increased efficiency...|$|R
30|$|In this section, we {{analyze the}} {{important}} {{factors that may}} have great impact on the performance <b>of</b> <b>data</b> <b>delivery</b> <b>of</b> vehicular networks. Among the factors, only a small subset {{of them can be}} controlled in simulation study.|$|R
40|$|Abstract. The {{dissemination}} <b>of</b> context <b>data</b> {{across a}} pervasive environment {{has proven to}} be a difficult problem. Techniques using gossiping algorithms offer simplicity and flexibility but often result in poor performance with respect to <b>timeliness</b> <b>of</b> delivery and communication cost. In this ongoing-work, we present enhanced gossiping algorithms that aim to improve the efficiency <b>of</b> context <b>data</b> <b>delivery</b> in a decentralised manner using network and data-driven approaches. ...|$|R
50|$|Any message {{through the}} socket {{is treated as}} an opaque blob <b>of</b> <b>data.</b> <b>Delivery</b> to a {{subscriber}} can be automatically filtered by the blob leading string. Available message transports include TCP, PGM (reliable multicast), inter-process communication (IPC) and inter-thread communication (ITC).|$|R
40|$|The {{debate on}} quality issues in web surveys {{is open and}} lively (see, i. e., the Web Survey Methodology site). Data quality is {{required}} to satisfy the user's needs. Improving the survey process quality is a precondition for obtaining product quality at acceptable cost. This article contributes to the debate focusing on the <b>timeliness</b> <b>of</b> web surveys. From our perspective the <b>timeliness</b> <b>of</b> <b>data</b> collection is mainly due to the <b>timeliness</b> <b>of</b> response from {{the members of the}} eligible population. We identify several steps in the web survey process and divide the final response rate into different components, one for each step. We model the survival of eligible respondents, finding out which participants come farthest in the process of a web survey. The analysis contributes to the efforts to explore the nonresponse process and to shorten the individual survey period length...|$|R
40|$|Developing and {{deploying}} informatics solutions {{which are}} useful and acceptable to busy physicians are challenging tasks. We describe the design, deployment, and evaluation {{process by which}} the delivery of routine clinical laboratory reports is automated using electronic mail. Data from TMR, an operational computer-based patient record (CPR), are presented to providers using an individualized, modern interface. This system is compared to the existing, paper-based system for <b>delivery</b> <b>of</b> <b>data</b> from the same CPR. Differences between the two systems <b>of</b> <b>data</b> <b>delivery</b> are analyzed, with emphases on 1) electronic documentation <b>of</b> <b>data</b> <b>delivery</b> and receipt, 2) electronic and/or paper documentation of clinical action taken as a result of laboratory reports, 3) <b>timeliness</b> <b>of</b> report availability, 4) costs, 5) workflow compatibility, and 6) physician satisfaction. The new delivery system employs inexpensive, commercially available software applications and entails only trivial changes to the proprietary CPR. Built into the new system are features which allow quantitative measurements of its performance for analysis along with survey-based user satisfaction data. The open systems design is deliberately non-proprietary, inexpensive, and generalizable. Accordingly, it offers practical possibilities for settings in which clinical information systems are just being planned, as well as for those in which such systems are already established...|$|R
40|$|By {{streamlining}} {{corporate actions}} processing through automation and adoption of common messaging standards, companies {{can improve the}} quality and <b>timeliness</b> <b>of</b> <b>data</b> and enable a move to cloud-based utility services. Executive Summary As businesses expand into new geographies in search of growth, the volume of corporate actions is growing exponentially. Advances in communications technology allow issuers to send announcements {{in a variety of}} formats; however, the processing of these messages by corporations or their financial service providers remains highly manual and error-prone. At a time when the business environment is growing in complexity and volume, these errors are unaffordable...|$|R
3000|$|The success <b>of</b> <b>data</b> <b>delivery</b> is not {{dependent}} on the stable neighborhood, but on the node density. If there exists at least one path in the [...] "routing pipe" [...] specified by the routing vector, then the packet can be successfully delivered.|$|R
40|$|To {{assess the}} value of ICD- 9 coded chief {{complaints}} for early detection of epidemics, we measured sensitivity, positive predictive value, and <b>timeliness</b> <b>of</b> Influenza detection using a respiratory set (RS) of ICD- 9 codes and an Influenza set (IS). We also measured inherent <b>timeliness</b> <b>of</b> these <b>data</b> using the cross-correlation function. We found that, for a one-year period, the detectors had sensitivity of 100 % (1 / 1 epidemic) and positive predictive values of 50 % (1 / 2) for RS and 25 % (1 / 4) for IS. The <b>timeliness</b> <b>of</b> detection using ICD- 9 coded chief complaints was one week earlier than the detection using Pneumonia and Influenza deaths (the gold standard). The inherent <b>timeliness</b> <b>of</b> ICD- 9 <b>data</b> measured by the cross-correlation function was two weeks earlier than the gold standard...|$|R
40|$|It is {{challenging}} {{to support the}} <b>timeliness</b> <b>of</b> realtime <b>data</b> service requests in data-intensive real-time applications such as online auction or stock trading, while maintaining the freshness <b>of</b> temporal <b>data</b> that capture the current real-world status. Although deadline-aware real-time scheduling would significantly enhance the <b>timeliness</b> <b>of</b> <b>data</b> services, {{it is not clear}} how to assign explicit feasible deadlines to data service requests in an open environment. To address the problem, we design a new deadline assignment scheme to derive feasible deadlines for real-time data service requests considering their individual data needs. Further, we develop a systematic closed-loop approach to supporting the desired tardiness−the actual service delay to deadline ratio−of real-time data services even in the presence of dynamic workloads. We choose the tardiness metric due to its expressiveness compared to the deadline miss ratio and utilization that saturate at 0 and 1 when the system is underutilized or overloaded, respectively. The performance evaluation results acquired in our real-time stock trading testbed show that the desired average/transient tardiness is closely supported. Consequently, the deadline miss ratio is significantly reduced compared to a state-of-art database system with a real-time scheduling extension. ...|$|R
40|$|Objective: The {{main purpose}} of this study was to clarify the method used to {{calculate}} bed occupancy rates. Design: Qualitative, using semi-structured face-to-face interviews, telephone interviews and email correspondence with internal and external stakeholders, as well as analysis of key documents. Setting: A tertiary hospital in Queensland, Australia. Participants: Nursing and administrative staff from 34 clinical areas, nurse managers and finance officers. Main outcome measure: Identification of the method used to calculate bed occupancy. Results: A number of issues potentially impact on the accuracy <b>of</b> occupancy <b>data</b> including <b>timeliness</b> <b>of</b> <b>data</b> entry, knowledge about what should be entered and skill deficits. There was also considerable confusion and misinformation about how occupancy data is calculated, used and reported. Conclusion: Occupancy data integrity may be compromised by <b>timeliness</b> and accuracy <b>of</b> <b>data</b> entry and by methods used for calculation. Until these problems are resolved, occupancy remains a woolly measure on which to estimate nursing resources...|$|R
40|$|In recent days, {{compare to}} fixed users, the mobile users are {{increasing}} day by day. It becomes {{necessary to provide}} better quality <b>of</b> <b>data</b> <b>delivery</b> to the end mobile user. Formerly, the quality <b>of</b> <b>data</b> <b>delivery</b> at the destination is good for pedestrian users {{when compared to the}} users in vehicular environment. It is {{due to the lack of}} coverage of area. The coverage area can be increased with the help of heterogeneous network which improves the quality of service for vehicular environment. In this paper, the integrated WiMAX-WiFi networkis implemented and analyzed by comparing the performance of vehicular environment and pedestrian environment by transmitting the voice packets based on Mean Opinion Score value, jitter, end to end delay and throughpu...|$|R
40|$|We {{developed}} a framework {{to measure the}} <b>timeliness</b> <b>of</b> two <b>data</b> types—radiology and microbiology reports—for detection of diseases such as inhalational anthrax (IA) in a healthcare system. We measured the <b>timeliness</b> <b>of</b> a <b>data</b> type as the delay between patient registration in an emergency department (ED) and receipt <b>of</b> <b>data</b> type by a biosurveillance system. We also determined the lower and upper bounds of median delay time (LMDT and UMDT) for the two data types to be available for detection of a single IA case. Based on the data received from the University of Pittsburgh Medical Center (UPMC) Health System, the LMDT time was 1. 5 days and UMDT time was 6. 4 days. The study provides a range of delay time for detection of a single IA case within a healthcare system, and it may benefit outbreak planning and outbreak model simulation...|$|R
