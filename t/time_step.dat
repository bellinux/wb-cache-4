10000|8411|Public
5|$|Convolve the {{pixelated}} {{image with}} a heat kernel to simulate its evolution under the heat equation {{for a short}} <b>time</b> <b>step.</b> The result is a Gaussian blur of the image, or equivalently the Weierstrass transform of the indicator function, with radius proportional to the square root of the <b>time</b> <b>step.</b>|$|E
5|$|In {{order for}} this scheme to be accurate, the <b>time</b> <b>step</b> must {{be large enough}} to cause the curve to move by at least one pixel even at points of low curvature, but small enough to cause the radius of {{blurring}} to be less than the minimum radius of curvature. Therefore, the size of a pixel must be , small enough to allow a suitable intermediate <b>time</b> <b>step</b> to be chosen.|$|E
5|$|Any second-order {{automaton}} may {{be transformed}} into a conventional cellular automaton, in which the transition function depends only on the single previous <b>time</b> <b>step,</b> by combining pairs of states from consecutive time steps of the second-order automaton into single states of a conventional cellular automaton.|$|E
40|$|Adaptive time-stepping methods {{based on}} the Monte Carlo Euler method for weak {{approximation}} of Itô stochastic differential equations are developed. The main result is new expansions of the computational error, with computable leading-order term in a posteriori form, based on stochastic flows and discrete dual backward problems. The expansions lead to efficient and accurate computation of error estimates. Adaptive algorithms for either stochastic <b>time</b> <b>steps</b> or deterministic <b>time</b> <b>steps</b> are described. Numerical examples illustrate when stochastic and deterministic adaptive <b>time</b> <b>steps</b> are superior to constant <b>time</b> <b>steps</b> and when adaptive stochastic steps are superior to adaptive deterministic <b>steps.</b> Stochastic <b>time</b> <b>steps</b> use Brownian bridges and require more work for a given number of <b>time</b> <b>steps.</b> Deterministic <b>time</b> <b>steps</b> may yield more <b>time</b> <b>steps</b> but require less work; for example, {{in the limit of}} vanishing error tolerance, the ratio of the computational error and its computable estimate tends to 1 with negligible additional work to determine the adaptive deterministic <b>time</b> <b>steps...</b>|$|R
40|$|We {{present a}} method for the {{efficient}} computation and storage of approximations of error tables used for error estimation of a region between different <b>time</b> <b>steps</b> in time-varying datasets. The error between two <b>time</b> <b>steps</b> {{is defined as the}} distance between the data of these <b>time</b> <b>steps.</b> Error tables are used to look up the error between different <b>time</b> <b>steps</b> of a time-varying dataset, especially when run time error computation is expensive. However, even the generation of error tables itself can be expensive. For n <b>time</b> <b>steps,</b> the exact error look-up table (which stores the error values for all pairs of <b>time</b> <b>steps</b> in a matrix) has a memory complexity and pre-processing time complexity of O(n), and O(1) for error retrieval...|$|R
5000|$|Sub-hourly, user-definable <b>time</b> <b>steps</b> for {{interaction}} between thermal zones and the environment; with automatically varied <b>time</b> <b>steps</b> for interactions between thermal zones and HVAC systems ...|$|R
5|$|This rule is also {{connected}} to number theory {{in a different}} way, via Gould's sequence. This sequence counts the number of nonzero cells in each <b>time</b> <b>step</b> after starting Rule 90 with a single live cell.|$|E
5|$|The {{rule for}} the {{automaton}} {{within each of}} these subsets is equivalent (except for a shift by half a cell per <b>time</b> <b>step)</b> to another elementary cellular automaton, Rule 102, in which the new state of each cell is the exclusive or of its old state and its right neighbor. That is, the behavior of Rule 90 {{is essentially the same}} as the behavior of two interleaved copies of Rule 102.|$|E
5|$|This {{process can}} be modeled by Rule 184, as follows. The {{particles}} are modeled as points that are aligned, not with {{the cells of the}} automaton, but rather with the interstices between cells. Two consecutive cells that both have state 0 model a particle at the space between these two cells that moves rightwards one cell at each <b>time</b> <b>step.</b> Symmetrically, two consecutive cells that both have state 1 model an antiparticle that moves leftwards one cell at each <b>time</b> <b>step.</b> The remaining possibilities for two consecutive cells are that they both have differing states; this is interpreted as modeling a background material without any particles in it, through which the particles move. With this interpretation, the particles and antiparticles interact by ballistic annihilation: when a rightwards-moving particle and a leftwards-moving antiparticle meet, the result is a region of background from which both particles have vanished, without any effect on any other nearby particles.|$|E
5000|$|... {{and we wish}} {{to compute}} an {{approximation}} [...] of the true solution [...] at discrete <b>time</b> <b>steps</b> [...] For simplicity, assume the <b>time</b> <b>steps</b> are equally spaced: ...|$|R
5|$|A {{configuration}} in Rule 90 can be partitioned {{into two}} subsets of cells {{that do not}} interact with each other. One of these two subsets consists of the cells in even positions at even <b>time</b> <b>steps</b> and the cells in odd positions in odd <b>time</b> <b>steps.</b> The other subset consists of the cells in even positions at odd <b>time</b> <b>steps</b> and the cells in odd positions at even <b>time</b> <b>steps.</b> Each of these two subsets {{can be viewed as}} a cellular automaton with only its half of the cells.|$|R
40|$|To solve ODE {{systems with}} {{different}} time scales which are localized over the compo-nents, multirate <b>time</b> <b>stepping</b> is examined. In this paper we introduce a self-adjusting multirate <b>time</b> <b>stepping</b> strategy, {{in which the}} step size for a particular component is determined by its own local temporal variation, instead of using a single step size for the whole system. We primarily consider implicit <b>time</b> <b>stepping</b> methods, suitable for stiff or mildly stiff ODEs. Numerical results with our multirate strategy are presented for several test problems. Comparisons with the corresponding single-rate schemes show that substantial gains in computational work and CPU times can be obtained. AMS subject classification (2000) : 65 L 05, 65 L 06, 65 L 50. Key words: multirate <b>time</b> <b>stepping,</b> local <b>time</b> <b>stepping,</b> ordinary differential equa-tions. 1 Introduction. Standard single-rate time integration methods for ODEs work with <b>time</b> <b>steps</b> that are varying in time but constant over the components. There are, however, many problems of practical interest where the temporal variations have differen...|$|R
5|$|The Moran model assumes {{overlapping}} generations. At each <b>time</b> <b>step,</b> {{one individual}} is chosen to reproduce and one individual is chosen to die. So in each timestep, {{the number of}} copies of a given allele can go up by one, go down by one, or can stay the same. This means that the transition matrix is tridiagonal, which means that mathematical solutions are easier for the Moran model than for the Wright–Fisher model. On the other hand, computer simulations are usually easier to perform using the Wright–Fisher model, because fewer time steps need to be calculated. In the Moran model, it takes N timesteps to get through one generation, where N is the effective population size. In the Wright–Fisher model, it takes just one.|$|E
5|$|As Boykett argues, any {{one-dimensional}} reversible {{cellular automaton}} {{is equivalent to}} an automaton in rectangular form, in which the cells are offset a half unit at each <b>time</b> <b>step,</b> and in which both the forward and reverse evolution of the automaton have neighborhoods with just two cells, the cells a half unit away in each direction. If a reversible automaton has neighborhoods larger than two cells, it can be simulated by a reversible automaton with smaller neighborhoods and more states per cell, in which each cell of the simulating automaton simulates a contiguous block of cells in the simulated automaton. The two axioms of a semicentral bigroupoid are exactly the conditions required on the forward and reverse transition functions of these two-cell neighborhoods to be the reverses of each other. That is, every semicentral bigroupoid defines a reversible cellular automaton in rectangular form, in which the transition function of the automaton uses the operation to combine the two cells of its neighborhood, and in which the operation similarly defines the reverse dynamics of the automaton. Every one-dimensional reversible cellular automaton is equivalent to one in this form.|$|E
5|$|As {{shown in}} the figure, and as {{originally}} described by , Rule 184 {{may be used to}} model deposition of particles onto a surface. In this model, one has a set of particles that occupy a subset of the positions in a square lattice oriented diagonally (the darker particles in the figure). If a particle is present at some position of the lattice, the lattice positions below and to the right, and below and {{to the left of the}} particle must also be filled, so the filled part of the lattice extends infinitely downward to the left and right. The boundary between filled and unfilled positions (the thin black line in the figure) is interpreted as modeling a surface, onto which more particles may be deposited. At each <b>time</b> <b>step,</b> the surface grows by the deposition of new particles in each local minimum of the surface; that is, at each position where it is possible to add one new particle that has existing particles below it on both sides (the lighter particles in the figure).|$|E
50|$|Note {{that the}} {{algorithm}} above {{does not work}} if time-reversibility is needed.The algorithm has to be implemented in two parts, one for positive <b>time</b> <b>steps,</b> one for negative <b>time</b> <b>steps.</b>|$|R
5000|$|Strang {{splitting}} extends this ansatz {{to second}} order by choosing another order of operations. Instead of taking full <b>time</b> <b>steps</b> with each operator, instead, one performs <b>time</b> <b>steps</b> as follows: ...|$|R
40|$|Large eddy {{simulations}} (LES) of {{high speed}} compressible viscous flow require high space resolution {{as well as}} short <b>time</b> <b>steps</b> if explicit <b>time</b> <b>stepping</b> is used. A semi-implicit preconditioning scheme specially suitable for wall-bounded flow is developed which, when combined with an explicit <b>time</b> <b>stepping</b> algorithm, makes much larger <b>time</b> <b>steps</b> possible than with the explicit scheme alone. The method is validated for developing turbulent channel flow and applied to a transonic flow with shock wave turbulent boundary layer interaction. In both cases, the computational time saved is measured. Finally possible developments of the method are discussed. ...|$|R
5|$|Models are {{initialized}} {{using this}} observed data. The irregularly spaced observations are processed by data assimilation and objective analysis methods, which perform quality control and obtain values at locations usable by the model's mathematical algorithms (usually an evenly spaced grid). The data are then {{used in the}} model {{as the starting point}} for a forecast. Commonly, the set of equations used to predict the known as the physics and dynamics of the atmosphere are called primitive equations. These equations are initialized from the analysis data and rates of change are determined. The rates of change predict the state of the atmosphere a short time into the future. The equations are then applied to this new atmospheric state to find new rates of change, and these new rates of change predict the atmosphere at a yet further time into the future. This time stepping procedure is continually repeated until the solution reaches the desired forecast time. The length of the <b>time</b> <b>step</b> is related to the distance between the points on the computational grid.|$|E
25|$|Algorithms {{have been}} {{designed}} so that the calculations done in a preceding <b>time</b> <b>step</b> can be reused in the current <b>time</b> <b>step,</b> resulting in faster completion of the calculation.|$|E
25|$|A {{variety of}} minor {{enhancements}} to this basic scheme are possible, {{and there are}} many ways to save unnecessary computation. A cell that did not change at the last <b>time</b> <b>step,</b> and none of whose neighbours changed, is guaranteed not to change at the current <b>time</b> <b>step</b> as well. So, a program that keeps track of which areas are active can save time by not updating the inactive zones.|$|E
40|$|The {{equations}} governing {{saltwater intrusion}} in coastal aquifers are complex. Backward Euler <b>time</b> <b>stepping</b> approaches {{are often used}} to advance the solution to these equations in time, which typically requires that small <b>time</b> <b>steps</b> be taken {{in order to ensure}} that an accurate solution is obtained. We show that a method of lines approach incorporating variable order backward differentiation formulas can greatly improve the efficiency of the <b>time</b> <b>stepping</b> process...|$|R
30|$|Hence, {{there is}} no {{decrease}} of errors occurring at earlier <b>time</b> <b>steps.</b> On the other hand, the strong monotonicity property for parabolic problems implies that errors at earlier <b>time</b> <b>steps</b> decrease exponentially as time evolves.|$|R
40|$|In this paper, we {{will present}} a {{generalized}} convolution quadrature for solving linear parabolic and hyperbolic evolution equations. The original convolution quadrature method by Lubich works very nicely for equidistant <b>time</b> <b>steps</b> while the generalization of the method and its analysis to non-uniform <b>time</b> <b>stepping</b> {{is by no means}} obvious. We will introduce the generalized convolution quadrature allowing for variable <b>time</b> <b>steps</b> and develop a theory for its error analysis. This method opens the door for further development towards adaptive <b>time</b> <b>stepping</b> for evolution equations. As the main application of our new theory we will consider the wave equation in exterior domains which are formulated as retarded boundary integral equations...|$|R
25|$|Representing {{the input}} {{in the context}} of {{previous}} inputs: If one or more cells in the active column are in the predictive state (see below), they will be the only cells to become active in the current <b>time</b> <b>step.</b> If none of the cells in the active column are in the predictive state (during the initial <b>time</b> <b>step</b> or when the activation of this column was not expected), all cells are made active.|$|E
25|$|Another particle-based {{stochastic}} simulator {{that can}} read BNGL input files is RuleMonkey. Its simulation algorithm {{differs from the}} algorithms underlying both StochSim and DYNSTOC in that the simulation <b>time</b> <b>step</b> is variable.|$|E
25|$|When using rigid water {{models in}} {{molecular}} dynamics, {{there is an}} additional cost associated with keeping the structure constrained, using constraint algorithms (although with bond lengths constrained it is often possible to increase the <b>time</b> <b>step).</b>|$|E
30|$|Furthermore, in {{the three}} cities considered, {{available}} rainfall records are limited to daily <b>time</b> <b>steps.</b> Since rainfall data at shorter <b>time</b> <b>steps</b> are essential {{for the evaluation of}} IDF curves, a daily rainfall disaggregation model was adopted.|$|R
40|$|In {{this paper}} {{derivation}} {{of the second}} differentiation of a general yield surface by implicit <b>time</b> <b>stepping</b> method along with its consistent elastic-plastic modulus is studied. Moreover, the explicit, trapezoidal implicit and fully implicit <b>time</b> <b>stepping</b> schemes are compared in rate-dependant plasticity. It is shown that implementing fully implicit <b>time</b> <b>stepping</b> scheme in rate-dependant plasticity predicts more accurate experimental results than other schemes. doi: 10. 5829 /idosi. ije. 2013. 26. 06 c. 0...|$|R
50|$|Ta-Shma and Zwick {{show how}} to extend this {{solution}} {{to allow the}} robots to meet after only O(nc) <b>time</b> <b>steps</b> and {{how to deal with}} arbitrary labels (which increases the time until the robots meet to O(n5+l) <b>time</b> <b>steps).</b>|$|R
25|$|At each <b>time</b> <b>step,</b> a noisy {{measurement}} of the true position of the truck is made. Let us suppose the measurement noise v'k is also normally distributed, with mean 0 and standard deviation σ'z.|$|E
25|$|If {{an upper}} bound {{can be placed}} on the {{velocity}} of the physical bodies in a scene, then pairs of objects can be pruned based on their initial distance {{and the size of the}} <b>time</b> <b>step.</b>|$|E
25|$|The {{classical}} {{model of}} enzyme activity, Michaelis–Menten kinetics, {{can be viewed}} as a Markov chain, where at each <b>time</b> <b>step</b> the reaction proceeds in some direction. While Michaelis-Menten is fairly straightforward, far more complicated reaction networks can also be modeled with Markov chains.|$|E
30|$|The proper {{temporal}} {{scale for}} {{the representation of}} a major storm event is shorter than the 4 -h averaged period used for the spatially uniform wind. The center of a hurricane traveling 20  km/h moves 80  km between 4 -h <b>time</b> <b>steps,</b> {{a major portion of}} the combined TIME/BISCAYNE domain. The model must be capable of resolving finer <b>time</b> <b>steps</b> for the storm event duration and represent the longer <b>time</b> <b>steps</b> {{for the rest of the}} simulation.|$|R
40|$|We {{present a}} novel {{boundary}} handling scheme for incompressible fluids based on Smoothed Particle Hydrodynamics (SPH). In {{combination with the}} predictive-corrective incompressible SPH (PCISPH) method, the boundary handling scheme allows for larger <b>time</b> <b>steps</b> compared to existing solutions. Furthermore, an adaptive time-stepping approach is proposed. The approach automatically estimates appropriate <b>time</b> <b>steps</b> independent of the scenario. Due to its adaptivity, the overall computation time of dynamic scenarios is significantly reduced compared to simulations with constant <b>time</b> <b>steps...</b>|$|R
50|$|Suppose {{there are}} n items, m users, and N ratings. Computing the average rating {{differences}} for {{each pair of}} items requires up to n(n-1)/2 units of storage, and up to m n2 <b>time</b> <b>steps.</b> This computational bound may be pessimistic: {{if we assume that}} users have rated up to y items, then it is possible to compute the differences in no more than n2+my2. If a user has entered x ratings, predicting a single rating requires x <b>time</b> <b>steps,</b> and predicting all of his missing ratings requires up to (n-x)x <b>time</b> <b>steps.</b> Updating the database when a user has already entered x ratings, and enters a new one, requires x <b>time</b> <b>steps.</b>|$|R
