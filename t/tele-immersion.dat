81|0|Public
50|$|From 1997 to 2001, Lanier was the Chief Scientist of Advanced Network and Services, which {{contained}} the Engineering Office of Internet2, {{and served as}} the Lead Scientist of the 'National <b>Tele-immersion</b> Initiative', a coalition of research universities studying advanced applications for Internet2. The Initiative demonstrated the first prototypes of <b>tele-immersion</b> in 2000 after a three-year development period. From 2001 to 2004, he was Visiting Scientist at Silicon Graphics Inc., where he developed solutions to core problems in telepresence and <b>tele-immersion.</b> He was also visiting scholar with the Department of Computer Science at Columbia University (1997-2001), a visiting artist with New York University's Interactive Telecommunications Program, and {{a founding member of}} the International Institute for Evolution and the Brain.|$|E
50|$|In mid-1997, {{he was a}} {{founding}} member of the 'National <b>Tele-Immersion</b> Initiative', an effort devoted to utilizing computer technology to give people who are separated by great distances the illusion that they are physically together. Lanier is a member of the Global Business Network, part of the Monitor Group.|$|E
50|$|In 1995, {{after the}} {{transition}} to a new Internet architecture and the NSFNET Backbone Service was decommissioned, ANS sold its networking business to AOL for a little over $30M and became a philanthropic organization with a mission to advance education by accelerating the use of computer network applications and technology". This work helped create ThinkQuest, the National <b>Tele-Immersion</b> Initiative, the IP Performance Metrics program, and provided grant funding for educational programs including TRIO Upward Bound, the Internet Society, Internet2, Computers for Youth, Year Up, National Foundation for Teaching Entrepreneurship, Sarasota TeXcellence Program, and many others.|$|E
40|$|<b>Tele-Immersion</b> is the {{merging of}} audio and video {{conferencing}} with collaborative virtual reality, datamining and significant computation systems. As <b>Tele-Immersion</b> often involves distantly located participants all interacting with each other in real-time, it relies heavily {{on the quality of the}} underlying networks used to distribute information between participants. This paper presents our preliminary findings of testing a number of tele-immersive applications over the STAR TAP link between Chicago and Singapore. The goal is to be able to prescribe and deploy a suite of <b>Tele-Immersion</b> networking experiments around the world for testing and comparing the quality of their links so that predictions can be made of the suitability of the link for supporting different classes of <b>Tele-Immersion</b> applications...|$|E
40|$|Tele-Immersive {{applications}} {{possess an}} unusually {{broad range of}} networking requirements. As high-speed and Quality of Service-enabled networks emerge, it will becoming more difficult for developers of <b>Tele-Immersion</b> applications, and networked applications in general, {{to take advantage of}} these enhanced services. This paper proposes an adaptive networking framework to ultimately allow applications to optimize their network utilization in pace with advances in networking services. In working toward this goal, this paper will present a number of networking techniques for improving performance in tele-immersive applications and examines whether the Differentiated Services mechanism for network Quality of Service is suitable for <b>Tele-Immersion.</b> 1 Introduction <b>Tele-Immersion</b> is the integration of collaborative virtual reality (VR) with audio and video conferencing in the context of data-mining and significant computation. The ultimate goal of <b>Tele-Immersion</b> is not only to reprodu [...] ...|$|E
40|$|The term <b>Tele-Immersion</b> {{was first}} used in October 1996 {{as the title of}} a {{workshop}} the Electronic Visualization Laboratory (EVL) at University of Illinois at Chicago (UIC) organized in Chicago to bring together researchers in distributed computing, collaboration, virtual reality (VR), and networking. Workshop attendees paid specific attention to the future needs of applications in the sciences, engineering, and education. EVL defines <b>Tele-Immersion</b> as the union of networked VR and video in the context of significant computing and data mining. Some researchers use the terms Collaborative Virtual Environment (CVE) or Distributed Virtual Environment (DVE) to describe the field of networked VR. <b>Tele-Immersion,</b> as defined by the authors, encompasses more image-based technology, like video and bit maps, than CVE/DVE researchers typically envision, so that more "reality " (so to speak) is incorporated. It also has the benefit of being pronounceable. Global <b>Tele-Immersion</b> is "better than being there " because physical travel, especially international travel, is best devoted to vacation, not work, in the authors ' experienced opinion...|$|E
40|$|<b>Tele-immersion</b> is a {{technology}} that augments your space with real-time 3 D projections of remote spaces thus facilitating the interaction of people from different places in virtually the same environment. <b>Tele-immersion</b> combines 3 D scene recovery from computer vision, and rendering and interaction from computer graphics. We describe the realtime 3 D scene acquisition using a new algorithm for trinocular stereo. We extend this method in time by combining motion and stereo {{in order to increase}} speed and robustness. 1...|$|E
40|$|This paper {{presents}} the collaborative learning environment with sharing knowledge-based in <b>Tele-immersion.</b> It supports learners have natural interaction, perception and better real experience through working over wide networks of immersed virtual environments. For sharing knowledge, the multi-layer virtual room’s model is discussed. It provides a formal model for representing students ' knowledge and describing {{the structure of}} a domain of knowledge. The combination of <b>Tele-immersion</b> and Collaborative-Learning Environment with Sharing Knowledge-based leads to a framework for intelligent tutoring systems which provides individualized learning to a student...|$|E
40|$|Abstract. <b>Tele-immersion</b> is a {{new medium}} that enables a user to share a virtual space with remote participants, by {{creating}} the illusion that users at geographically dispersed locations reside at the same physical space. A person is immersed in a remote world, whose 3 D representation is acquired remotely, then transmitted and displayed in the viewer’s environment. <b>Tele-immersion</b> is effective only when the three components, computation, transmission, and rendering- all operate in real time. In this paper, we describe the real-time implementation of scene reconstruction on the Terascale Computing System at the Pittsburgh Supercomputing Center...|$|E
40|$|Abstract. Tele-Immersive {{applications}} {{possess an}} unusually {{broad range of}} networking requirements. As high-speed and Quality of Service-enabled networks emerge, it will becoming more difficult for developers of <b>Tele-Immersion</b> applications, and networked applications in general, {{to take advantage of}} these enhanced services. This paper proposes an adaptive networking framework to ultimately allow applications to optimize their network utilization in pace with advances in networking services. In working toward this goal, this paper will present a number of networking techniques for improving performance in tele-immersive applications and examines whether the Differentiated Services mechanism for network Quality of Service is suitable for <b>Tele-Immersion.</b> ...|$|E
40|$|Abstract—Real-time <b>tele-immersion</b> {{requires}} {{low latency}} and synchronized multi-camera capture. Prior high definition (HD) capture systems were bulky. We investigate {{the suitability of}} using flocks of smartphone cameras for <b>tele-immersion.</b> Smartphones integrate capture and streaming into a single portable package. However, they archive the captured video into a movie. Hence, we create a sequence of H. 264 movies and stream them. Capture delay is reduced by minimizing the number of frames in each movie segment. However, fewer frames reduces compression efficiency. Also, smartphone video encoders do not sacrifice video quality to lower the compression latency or the stream size. On an iPhone 4 S, our application that uses published APIs streams 1920 x 1080 videos at 16. 5 fps with a delay of 712 ms between a real-life event and displaying an uncompressed bitmap of this event on a local laptop. Note that the bulky Cisco Tandberg required 300 ms delay. Stereoscopic video from two unsynchronized smartphones also showed minimal visual artifacts in an indoor setting. Keywords-portable <b>tele-immersion,</b> smartphone camera I...|$|E
40|$|Abstract: <b>Tele-Immersion</b> helps {{users in}} {{different}} locations to collaborate in a shared, simulated environment {{as if they}} were in the same physical room. It's the ultimate synthesis of networking and media technologies to enhance collaborative environments. In the tele-immersive environment, computers recognize the presence and movements of individuals and objects, track those images, and then permit them to be projected in realistic, multiple, geographically distributed immersive environments where individuals can interact {{with each other and with}} computer generated models. With <b>tele-immersion</b> you will interact instantly with your friend on the other side of the globe through a simulated holographic environment. It will change the way we live...|$|E
40|$|Abstract — Telepresence or <b>tele-immersion</b> {{technologies}} {{allow people}} to attend a shared meeting without being physically present in the same location. Commercial telepresence solutions available in the market today have significant drawbacks- they are very expensive, and confine people to the area covered by stationary cameras. In this paper, we present a mobile <b>tele-immersion</b> platform that addresses these issues by using robots with embedded cameras. In our system, the users can move around freely because robots autonomously adjust their locations. We provide a geometric definition {{of what it means}} to get a good view of the user, and present control algorithms to maintain a good view. The algorithms are validated both in simulation and in real experiments. I...|$|E
40|$|Abstract—The {{processing}} power and network bandwidth required for true immersive telepresence applications {{are only now}} beginning to be available. We draw from our experience developing stereo based <b>tele-immersion</b> prototypes to present the main issues arising when building these systems. <b>Tele-immersion</b> is a new medium that enables a user to share a virtual space with remote participants. The user is immersed in a rendered three-dimensional (3 -D) world that is transmitted from a remote site. To acquire this 3 -D description, we apply binocular and trinocular stereo techniques which provide a view-independent scene description. Slow processing cycles or long network latencies interfere with the users ’ ability to communicate, so the dense stereo range data must be computed and transmitted at high frame rates. Moreover, reconstructed 3 -D views of the remote scene must be as accurate as possible to achieve a sense of presence. We address both issues of speed and accuracy using a variety of techniques including the power of supercomputing clusters and a method for combining motion and stereo in order to increase speed and robustness. We present the latest prototype acquiring a room-size environment in real time using a supercomputing cluster, and we discuss its strengths and current weaknesses. Index Terms—Stereo vision, <b>tele-immersion,</b> telepresence, terascale computing...|$|E
40|$|<b>Tele-Immersion</b> is the {{combination}} of collaborative virtual reality and audio / video teleconferencing. With {{a new generation of}} high-speed international networks and high-end virtual reality devices spread around the world, e ective trans-oceanic tele-immersive collaboration is now possible. But in order to make these shared virtual environments more convenient workspaces, a new generation of desktop display technology is needed...|$|E
40|$|Stereo Vision {{has been}} an active {{research}} field that has produced {{a variety of different}} algorithms. Unfortunately most of the algorithms that produce superior results rely on non-linear optimization techniques that are very computationally expensive, and therefore not feasible to use for real-time applications such as <b>tele-immersion.</b> This paper will examine a number of real-time stereo algorithms based on dynamic programming (DP) used in conjunction with structured light in order to improve the quality and facilitate the correspondence search. We will examine some of the early DP algorithms as well as the more recent work produced by [Criminisi et al] for the purpose of Gaze manipulation for teleconferencing in the context of 3 d reconstruction. We present adaptation of [Birchfield et al] DP algorithm to work with structured light. Additional we look at spatialtemporal support region for computing matching costs. Keywords: Dynamic Programming, Stereo, <b>Tele-immersion,</b> Real-Time 1...|$|E
40|$|Part of 3 DLife’s {{major goal}} {{to bring the}} 3 D media Internet to life, {{concerns}} the development and wide-spread distribution of online tele-immersive (TI) virtual environments. As the techniques powering challenging tasks for user reconstruction and activity tracking within a virtual environment are maturing, along with consumer-grade availability of specialized hardware, this paper focuses on the simple practices used to make real-time <b>tele-immersion</b> within a networked virtual world a reality...|$|E
40|$|This paper proposes FreeViewer, a 3 D <b>Tele-Immersion</b> view-control {{system that}} allows viewers to see {{arbitrary}} side of the performer by intelligently choosing the streams of a sub-set of cameras and changing {{the point of view}} in a 3 D vir-tual space. The view changing is actuated by the change of the sensor data from wearable devices (eg. Google Glass, smartphone) on the performer able to monitor the current orientation...|$|E
40|$|The {{study of}} 3 D <b>Tele-immersion</b> impact on remote {{collaborative}} work represents {{a very interesting}} and challenging research topic. In this paper, we introduce the latest accomplishments of TEEVE research which merges computer science with dance choreography. This collaborative research model is ideal for creative, interdisciplinary problem solving. TEEVE offers an entirely new interface for dance choreography as a creative tool and alternative performance venue. Categories and Subject Descriptor...|$|E
40|$|The goal of <b>tele-immersion</b> {{has long}} been to enable people at remote {{locations}} to share a sense of presence. A <b>tele-immersion</b> system acquires the 3 D representation of a collaborator’s environment remotely and sends it over the network where it is rendered in the user’s environment. Acquisition, reconstruction, transmission, and rendering {{all have to be}} done in real-time {{to create a sense of}} presence. With added commodity hardware resources, parallelism can increase the acquisition volume and reconstruction data quality while maintaining real-time performance. However this is not as easy for rendering since all of the data need to be combined into a single display. In this paper we present an algorithm to compress data from such 3 D environments in real-time to solve this imbalance. We expect the compression algorithm to scale comparably to the acquisition and reconstruction, reduce network transmission bandwidth, and reduce the rendering requirement for real-time performance. We have tested the algorithm using a synthetic office data set and have achieved a 5 to 1 compression for 22 depth streams...|$|E
40|$|Abstract—The primary {{objective}} {{of this paper is}} to present and analyze key aspects related to next-generation <b>tele-immersion</b> applications, studying the end-to-end chain from 3 D capturing of remote users to rendering. The key modules for 3 D reconstruction of moving humans and their mesh compression, are presented and discussed. The chain performance is evaluated in terms of frame-rates, delay, and visual quality. Index Terms—Tele-immersion, 3 D reconstruction, mesh com-pression, real-time, Free-Viewpoint rendering I...|$|E
40|$|Abstract — 3 D <b>Tele-Immersion</b> (3 DTI) {{systems have}} been {{developed}} {{as a way to}} create a more interactive and immersive experience for the user in the areas of sports learning, rehabilitation, entertainment and games. In this paper we introduce such a system with Microsoft Kinect cameras that {{can be used as a}} platform for developing some applications with unique features. Specifically, we demonstrate two features in this system that makes it possible to create some interesting applications. Keywords—immersive rehabilitation, sports training. I...|$|E
40|$|For {{over four}} years, our {{colleagues at the}} University of Pennsylvania {{and we have been}} {{developing}} an experimental 3 D <b>tele-immersion</b> testbed with the goal of providing high-fidelity scene reconstruction coupled with lifesize, view-dependent stereo display. The UPenn team has focused on stereo reconstruction algorithms, while UNC has worked on system architecture, network transport, and stereo rendering and display issues. This paper provides an overview of our testbed architecture and details the transport and rendering challenges and solutions we have explored...|$|E
40|$|The {{processing}} power and network bandwidth required for true immersive telepresence applications {{are only now}} beginning to be available. We draw from our experience developing stereo based <b>tele-immersion</b> prototypes to present the main issues arising when building these systems. <b>Tele-immersion</b> is a new medium that enables a user to share a virtual space with remote participants. The user is immersed in a rendered three-dimensional (3 -D) world that is transmitted from a remote site. To acquire this 3 -D description, we apply binocular and trinocular stereo techniques which provide a view-independent scene description. Slow processing cycles or long network latencies interfere with the users 2 ̆ 7 ability to communicate, so the dense stereo range data must be computed and transmitted at high frame rates. Moreover, reconstructed 3 -D views of the remote scene must be as accurate as possible to achieve a sense of presence. We address both issues of speed and accuracy using a variety of techniques including the power of supercomputing clusters and a method for combining motion and stereo in order to increase speed and robustness. We present the latest prototype acquiring a room-size environment in real time using a supercomputing cluster, and we discuss its strengths and current weaknesses...|$|E
40|$|Virtual reality (VR) {{has finally}} {{come of age}} for serious {{applications}} in the behavioral neurosciences. After capturing the public imagination a decade ago, enthusiasm for VR flagged due to hardware limitations, an absent commercial market and manufacturers who dropped the mass-market products that normally drive technological development. Recently, however, improvements in computer speed, quality of head-mounted displays and wide-area tracking systems have made VR attractive for both research and real-world applications in neuroscience, cognitive science and psychology. New and exciting applications for VR have emerged in research, training, rehabilitation, teleoperation, virtual archeology and <b>tele-immersion...</b>|$|E
40|$|This {{paper is}} {{in the field of}} <b>tele-immersion,</b> which {{pertains}} to the use of technology to virtually represent three dimensional bodies from remote locations. The primary goal of the project is to integrate real time motion capture data into the existing virtual environment and subsequently minimize the time required to render the bodies when facial movements and other detailed characteristics are not essential. The data from the motion capture system would be used to either control a three dimensional human model avatar or be represented as a set of markers for interaction in virtual space...|$|E
40|$|As {{computational}} power increases, tele-immersive {{applications are}} an emerging trend. These applications make extensive demands on computational resources through their heavy use of real-time 3 D reconstruction algorithms. Since computer vision developers {{do not necessarily}} have parallel programming expertise, {{it is important to}} give them the tools and capabilities to naturally express computer vision algorithms, yet retain high efficiency by exploiting modern GPU and large-scale multi-core platforms. In this paper, we describe our optimization efforts for a <b>tele-immersion</b> application by tuning it for GPU and multicore platforms. Additionally, we introduce a method to obtain portability, high performance, and increase programmer productivity...|$|E
40|$|Abstract. We present work in {{progress}} on a <b>tele-immersion</b> system for telerehabilitation using real-time stereo vision and virtual environments. Stereo reconstruction is used to capture user’s 3 D avatar in real time and project it into a shared virtual environment, enabling a patient and therapist to interact remotely. Captured data {{can also be used}} to analyze the movement and provide feedback to the patient as we present in a preliminary study of stepping-in-place task. Such tele-presence system could in the future allow patients to interact remotely with remote physical therapist and virtual environment while objectively tracking their performance...|$|E
40|$|In {{this paper}} we verify the {{insufficiency}} of Stevens ’ power law {{to describe the}} relationship between QoS and QoE factors. User studies that target different types of application scenarios of 3 D <b>Tele-immersion</b> (3 DTI) are conducted and the results show no significant power trend {{in the relationship between}} packet loss and perceptual quality metrics. We further verify that activity characteristics, activity objectives, and users ’ roles in the 3 DTI session also have profound effects on the service quality aside to the QoS level. Thus, simple one-factor psychophysical laws are inadequate of serving as a QoS-QoE mapping model...|$|E
40|$|<b>Tele-immersion</b> {{is one of}} the {{applications}} being developed in conjunction with the Internet- 2 initiative. Most of the research in this area has focused on issues pertaining to image acquisition and display, tracking technologies, robotics, haptics, etc. In order to maintain consistency of a tele-immersive experience one also needs to develop a suit of solutions that will ensure proper coordination between the participants. This will require protocols for real-time causal delivery of messages while maintaining the privacy of conversations and preventing forgery of message contents. This paper discusses these issues while considering a tele-immersive environment as a distributed message passing system...|$|E
40|$|Abstract—Synchronous {{cooperative}} systems (SCS) {{bring together}} users that are geographically distributed and connected through a network {{to carry out}} a task. Examples of SCS include <b>Tele-Immersion</b> and Tele-Conferences. In SCS, the coordination is the core of the system, and it has been defined as the act of managing interdependencies between activities performed to achieve a goal. Some of the main problems that SCS present deal with the management of constraints between simultaneous activities and the execution ordering of these activities. In order to resolve these problems, orderings based on Lamport’s happened-before relation have been used, namely, causal, �-causal, and causal-total orderings. They mainly differ in the degree of asynchronous execution allowed. One of the most important orderings is the causal order, which establishes that the events must be seen in the cause-effect order as they occur in the system. In this paper we show that for certain SCS (e. g. videoconferences, <b>tele-immersion)</b> where some degradation of the system is allowed, ensuring the causal order is still rigid, which can render negative affects to the system. In this paper, we illustrate how a more relaxed ordering, which we call Fuzzy Causal Order (FCO), is useful for such kind of systems by allowing a more asynchronous execution than the causal order. The benefit of the FCO is illustrated by applying it to a particular scenario of intermedia synchronization of an audio-conference system. Keywords—Event ordering, fuzzy causal ordering, happenedbefore relation and cooperative systems. S I...|$|E
40|$|The Globus grid toolkit is a {{collection}} of software components designed to support the development of applications for high-performance distributed computing environments, or ''computational grids'' [14]. The Globus toolkit is an implementation of a ''bag of services'' architecture, which provides application and tool developers not with a monolithic system but rather with a set of stand-alone services. Each Globus component provides a basic service, such as authentication, resource allocation, information, communication, fault detection, and remote data access. Different applications and tools can combine these services in different ways to construct ''grid-enabled'' systems. The Globus toolkit has been used to construct the Globus Ubiquitous Supercomputing Testbed, or GUSTO: a large-scale testbed spanning 20 sites and included over 4000 compute nodes for a total compute power of over 2 TFLOPS. Over the past six months, we and others have used this testbed to conduct a variety of application experiments, including multi-user collaborative environments (<b>tele-immersion),</b> computational steering, distributed supercomputing, and high throughput computing. The goal {{of this paper is to}} review what has been learned from these experiments regarding the effectiveness of the toolkit approach. To this end, we describe two of the application experiments in detail, noting what worked well and what worked less well. The two applications are a distributed supercomputing application, SF-Express, in which multiple supercomputers are harnessed to perform large distributed interactive simulations; and a <b>tele-immersion</b> application, CAVERNsoft, in which the focus is on connecting multiple people to a distributed simulated world...|$|E
40|$|We {{present a}} {{framework}} for new 3 D <b>tele-immersion</b> applications that allows collaborative and remote 3 D interactions. This framework {{is based on a}} multiple-camera platform that builds, in real-time, 3 D models of users. Such models are embedded into a shared virtual environment where they can interact with other users or purely virtual objects. 3 D models encode geometric information that is plugged into a physical simulation for interactive purposes. They also encode photometric information through the use of mapped textures to ensure a good sense of presence. Experiments were conducted with two multiple-camera platforms, and the preliminary results demonstrate the feasibility of such environments...|$|E
40|$|The {{preservation}} of temporal relations for real-time distributed continuos media {{is a key}} issue for emerging multimedia applications, such as <b>Tele-Immersion</b> and Tele-Engineering. Although several works try to model and execute distributed continuous media scenarios, they are far from resolving the problem. The present paper proposes a viable solution based on the identification of logical dependencies. Our solution considers two main components. First, it establishes a temporal synchronization model that expresses all possible temporal scenarios for continuous media according to their causal dependency constraints. The second component consists of an innovative synchronization mechanism that accomplishes the reproduction of continuous media according to its temporal specification...|$|E
40|$|Abstract—In this paper, {{the problem}} of real-time, full 3 D {{reconstruction}} of foreground moving objects, an important task for <b>Tele-Immersion</b> applications, is addressed. More specifically, the proposed reconstruction method receives input from multiple consumer RGB-Depth cameras. A fast and efficient method to calibrate the sensors in initially described. More importantly, an efficient method to smoothly fuse the captured raw point sets is then presented, followed by a volumetric method to produce watertight and manifold meshes. Given the implementation details, the proposed method can operate at high frame rates. The experimental results, with respect to reconstruction quality and rates, verify {{the effectiveness of the}} proposed methodology. Index Terms—Tele-immersion, 3 D reconstruction, real-time, Microsoft Kinect I...|$|E
40|$|Current {{interactive}} {{tele-presence systems}} are designed and optimized for one {{particular type of}} cyber-physical activity such as conversation, video chat, or gaming. However, with the emerging new 3 D tele-immersive (TI) systems, such as our own TI system, called TEEVE (<b>TEle-immersion</b> for EVErybody), we observe that the same TI system platform is being used for very different activities. In this paper, we classify the TI activities {{with respect to their}} physical characteristics, qualitatively analyze the cyber side of TI activities, and argue that one needs to consider very different performance profiles of the same TI system platform in order to achieve high quality of experience (QoE) for different cyber-physical TI activities. 1...|$|E
