43|38|Public
5000|$|Bible Analyzer [...] - [...] A {{freeware}} Bible {{study and}} analysis application with Advanced Searching, Bible Statistics, Parallel <b>Text</b> <b>Generator,</b> Text-To-Speech, Audio, and more.|$|E
5000|$|Bible Analyzer [...] - [...] A {{freeware}} Bible {{study and}} analysis application with Advanced Searching, Bible Statistics, Parallel <b>Text</b> <b>Generator,</b> Text-To-Speech, Audio, and more. Many free modules available with immediate download of premium modules; ...|$|E
50|$|The Nokia 3410 {{was one of}} {{the first}} mobile phones to be {{released}} outside Japan to feature mobile 3D graphics (notably the animated screensavers and the mobile game Munkiki's Castles). Despite it has a monochrome screen and a 96×65 screen resolution, it almost includes all of the rendering features (excluding texture mapping and its rendering features from OpenGL ES 1.0). It was only used in three applications (3D <b>text</b> <b>generator,</b> animated screensavers and Munkiki's Castles). It uses a proprietary API for the mobile phone to render 3D graphics via the baseband processor (Texas Instruments MAD2WDI C GSM Baseband Processor). However, rendering on this device is only displayed on lower polygon count (since it uses software renderer) and it runs slower than other mobile phones that supports 3D graphics.|$|E
50|$|Nondeterministic {{languages}} {{can be used}} {{to explore}} large search spaces, such as grammars, where exhaustive search is impractical. Random <b>text</b> <b>generators</b> such as the Dada Engine and rmutt are examples of this kind of nondeterminstic language.|$|R
50|$|Parody {{generators}} are {{computer programs}} which generate text that is syntactically correct, but usually meaningless, {{often in the}} style of a technical paper or a particular writer. They are also called travesty <b>generators</b> and random <b>text</b> <b>generators.</b>|$|R
40|$|Abstract-As {{a result}} of a {{previous}} study in which electronic voice phenom-enon failed to be found, the author introduced two new elements in an experiment seeking to produce instrumental transcommunication: the creation of text using random <b>text</b> <b>generators</b> and the presence of a medium. There were 26 experimental sessions carried out from April 28, 2003 to August 30, 2003 in the Psychology Laboratory at King's University College. The random <b>text</b> <b>generators</b> were engaged a total of 715 times producing 23, 281 discrete units of textual data. Only a yeslno generator produced anomalous results. Of the 49 times the yeslno generator was used, 11 of them were in response to questions for which the answers could be verified. Of those 11 responses, 9 were correct with a probability of occurrence by chance of. 042. Such a result could be due to chance, anomalous human-machine interaction between the participants and the computer, or some other influences such as those arising from possibly existent unseen dimensions of reality. The use of <b>text</b> <b>generators</b> and the pres-ence of a medium in instrumental transcommunication (ITC) research are discussed, including the potential provision of information by the medium regarding strategies that could facilitate ITC...|$|R
5000|$|Bible Analyzer {{is written}} in Python with a wxPython GUI. According to its author it was first {{conceived}} in 2003 to address areas in Bible study and analysis that are largely untouched among other Bible software programs. Primarily features such as Bible text comparison, proximity range searches, and textual statistical analysis. Versions 1.0 through 2.2 concentrated on these features. The version 3 series greatly expanded them and added other features such as a dedicated cross-reference panel, [...] "Related Verse" [...] Searches, Text-To-Speech and Audio features, etc. Version 4.0 includes a major updating of the interface and also a Harmony/Parallel <b>Text</b> <b>Generator,</b> Advanced Related Phrase Search, Multiple Bible Search capabilities, exporting of study data to the [...] "MultiWindow," [...] etc. Version 4.5 introduced the [...] "Session Manager" [...] which allows the user to configure different sessions of modules for various types of studies.|$|E
50|$|SCIRP {{generated}} {{controversy in}} 2010 {{when it was}} found that its journals duplicated papers which had already been published elsewhere, without notification of or permission from the original author and of the copyright holder. Several of these publications have subsequently been retracted. Some of the journals had listed academics on their editorial boards without their permission or even knowledge, sometimes in fields very different from their own. In 2012, one of its journals, Advances in Pure Mathematics, accepted a paper written by a random <b>text</b> <b>generator.</b> The paper was not published, but only due to its author's unwillingness to pay the publication fee. The company has also been noted for the many unsolicited bulk emails it sends to academics about its journals. In 2013, the Open Journal of Pediatrics, a SCIRP journal, published a study which concluded that the number of babies born with thyroid problems in the western United States increased by 16 percent in 2011 compared to 2010, after the Fukushima Daiichi nuclear disaster. The study has been criticized for not taking into account the fact that 2010 was a year with an unusually low number of births with thyroid problems. SCIRP refused to print a letter criticizing the study, but offered to publish it as an article for a charge.|$|E
40|$|An {{interactive}} {{report generator}} for bone scintigraphy will be demonstrated. It comprises a controlled reporting vocabulary, an adaptive user interface, and a <b>text</b> <b>generator.</b> The controlled vocabulary represents the relevant concepts for bone scan reports: anatomical sites, scintigraphical phenomena, and diagnoses, and various attributes for these concept domains. Within the vocabulary selectional constraints are defined that restricts to meaningful combination of concepts. The interface provides intelligent {{views on the}} vocabulary, and presents only those terms that are relevant in a certain context. Through the interface the user may choose appropriate terms and combine them to complex findings. A German <b>text</b> <b>generator</b> for a restricted finding language transforms the entered data into morpho-syntactic surface structures and produces acceptable reports...|$|E
5000|$|... @Horse ebooks is a bot {{that has}} gained a {{following}} among people who found its tweets poetic. It has inspired various _ebooks-suffixed Twitter bots which use Markov <b>text</b> <b>generators</b> (or similar techniques) to create new tweets by mashing up the tweets of their owner.|$|R
40|$|As {{a result}} of a {{previous}} study in which electronic voice phenomenon failed to be found, the author introduced two new elements in an experiment seeking to produce instrumental transcommunication: the creation of text using random <b>text</b> <b>generators</b> and the presence of a medium. There were 26 experimental sessions carried out from April 28, 2003 to August 30, 2003 in the Psychology Laboratory at King 2 ̆ 7 s University College. The random <b>text</b> <b>generators</b> were engaged a total of 715 times producing 23, 281 discrete units of textual data. Only a yeslno generator produced anomalous results. Of the 49 times the yeslno generator was used, 11 of them were in response to questions for which the answers could be verified. Of those 11 responses, 9 were correct with a probability of occurrence by chance of. 042. Such a result could be due to chance, anomalous human-machine interaction between the participants and the computer, or some other influences such as those arising from possibly existent unseen dimensions of reality. The use of <b>text</b> <b>generators</b> and the presence of a medium in instrumental transcommunication (ITC) research are discussed, including the potential provision of information by the medium regarding strategies that could facilitate ITC...|$|R
5000|$|Brainstorming {{software}} is computer software {{that is used}} for the development of creative ideas [...] - [...] brainstorming. Some formats or structures for this include flow charts, idea maps, word association and generative idea creation programs. Ideation is often associated with brainstorming software. Some of the earliest brainstorming software programs were IdeaFisher, Thinkle, Paramind and programs using Markov chains called Markov <b>text</b> <b>generators.</b>|$|R
40|$|Numerical weather {{prediction}} (NWP) models produce time series data of basic weather parameters which human forecasters use as guidance while writing textual forecasts. Our studies of humans writing textual weather forecasts {{led us to}} build SUMTIME-MOUSAM, a <b>text</b> <b>generator</b> that produces textual marine weather forecasts for offshore oilrig applications. SUMTIME-MOUSA...|$|E
40|$|In {{the context}} of the {{definition}} of a reference architecture for NLP, especialy for Natural Language Generation, we describe the problems we encountered when we combined two <b>text</b> <b>generator</b> systems that we initially thought were complementary: one dealing with “what to say? ” and the other with the “how to say?”. ...|$|E
40|$|In this paper, we {{describe}} SUMTIME-METEO, a parallel corpus of naturally occurring weather forecast texts and their corresponding forecast data; data {{that the human}} authors inspected while writing the forecast texts. We have analysed the corpus to acquire knowledge needed to build a <b>text</b> <b>generator</b> for automatically producing textual weather forecasts from numerical weather prediction data. Although parallel corpora are commonly used for the development and evaluation of machine translation technology, it is fairly novel in the text generation community. Our analyses of the corpus, in some cases, produced ambiguous results that are not useful and reflected inconsistencies in the underlying corpus. Despite the internal inconsistencies, the text-data parallel corpus was helpful in generating initial hypotheses, which were then tested with knowledge from other sources. We also describe how we have used the corpus for evaluating our prototype forecast <b>text</b> <b>generator.</b> ...|$|E
40|$|International audienceThe ACORD system {{combines}} Natural Language and Graphics {{techniques for}} the construction and interrogation of knowledge bases in French, German and English. The selected domain of application is a knowledge base concerning transport services. The major components of the system are parsers for the three languages, a graphic component, a knowledge base and a theorem prover, <b>text</b> <b>generators</b> for the three languages, and a dialogue manager including a resolver and a planner...|$|R
40|$|We {{argue that}} Discourse Representation Structures form a {{suitable}} level of languageneutral meaning representation for micro planning and surface realisation. DRSs {{can be viewed}} as the output of macro planning, and form the rough plan and structure for generating a text. We present the first ideas of building a large DRS corpus that enables the development of broad-coverage, robust <b>text</b> <b>generators.</b> A DRS-based generator imposes various challenges on micro-planning and surface realisation, including generating referring expressions, lexicalisation and aggregation. ...|$|R
40|$|The Readers Project is an aesthetically-oriented {{system of}} {{software}} entities designed {{to explore the}} culture of human reading. These entities, or 'readers', enact specific reading strategies and function as autonomous <b>text</b> <b>generators,</b> networked writing machines visible beyond the texts they 'read'. As the structures on which they operate are culturally implicated, the project's readers shed light {{on a range of}} institutional practices surrounding the digital literary and the aggregation of the linguistic commons by corporate interests. In this paper, we present the practical and theoretical considerations guiding the project's development, and consider various strategies to resist the commodification and enclosure of literary culture within the corporate 'cloud'...|$|R
40|$|Text {{generation}} {{is a field}} of artificial intelligence aiming at modelling the process of natural language production. Text {{generation is}} best characterized as {{the process of making}} choices between alternate linguistic realizations under the constraints specified in the input to a <b>text</b> <b>generator.</b> Depending on the practical application, the input can take different forms- streams of numbers in report generation, trace...|$|E
40|$|This paper {{presents}} an analysis conducted on a corpus of software instructions in French {{in order to}} establish whether task structure elements (the procedural representation of the users' tasks) are alone sufficient to control the grammatical resources of a <b>text</b> <b>generator.</b> We show that the construct of genre provides a useful additional source of control enabling us to resolve undetermined cases. Comment: 8 pages, Latex file [...] uses aclap. st...|$|E
40|$|This paper {{argues for}} more precise {{definitions}} of rhetorical relations that {{have often been}} proposed as intermediate forms between modules of text generators. As a case in point, we describe the problems we encountered when we combined two <b>text</b> <b>generator</b> systems that we initially thought were complementary: one dealt with "what to say?" {{and the other with}} the "how to say?". This experiment brought new insights into the generation process...|$|E
40|$|Meta-modeling {{is raising}} {{more and more}} {{interest}} {{in the field of}} language engineering. While this approach is now well understood for defining abstract syntaxes, formally defining textual concrete syntaxes with meta-models is still a challenge. Textual concrete syntaxes are traditionally expressed with rules, conforming to EBNF-like grammars, which can be processed by compiler compilers to generate parsers. Unfortunately, these generated parsers produce concrete syntax trees, leaving a gap with the abstract syntax defined by meta-models, and further ad hoc hand-coding is required. In this paper we propose a new kind of specification for concrete syntaxes, which takes advantage of meta-models to generate fully operational tools (such as parsers or <b>text</b> <b>generators).</b> The principle is to map abstract syntaxes t...|$|R
40|$|Though mos. t <b>text</b> <b>generators</b> {{are capable}} of sim- ply {{stringing}} together more 'than one sentence, they cannot determine which order will ensure a coherent paragraph. A paragraph is coherent when the information in successive sentences fol- lows some pattern of inference or of knowledge with which the hearer is familiar. To signal such inferences, speakers usually use relations that llnk successive sentences in fixed ways. A set of 20 relations that span most of what people usually say in English is proposed in the Rhetorical Structure Theory of Mann and Thompson. This paper describes the forrealization of these relations and their use in a prototype text planner that structures input elements into coherent paragraphs...|$|R
40|$|This paper {{describes}} an experimental dialog {{system designed to}} retrieve information and generate summaries of internet news reports related to user queries in Swedish and English. The extraction component is based on parsing and on matching the parsing output against stereotypic event templates. Bilingual text generation is accomplished by filling the templates after which grammar components generate the final text. The interfaces between the templates and the language-specific <b>text</b> <b>generators</b> are marked for prosodic information resulting in a text output where deaccentuation, accentuation, levels of focal accentuation, and phrasing are specified. These prosodic markers modify the default prosody rules of the text-to-speech system which then reads the text with subsequent improvement in intonation. 1...|$|R
40|$|In this note, {{we present}} a project (Auto-Text UIS) on applied text generation. The goal of Auto-Text is the {{production}} of air pollutant information from data in a relational data base. Auto-Text consists of two modules: the preprocessor, which evaluates the data compiling from them conceptual structures, and the <b>text</b> <b>generator,</b> which takes conceptual structures as input producing from them the multiparagraph reports. The linguistic framework that underlies the generator is the Meaning-Text Theory...|$|E
40|$|Document Planning- {{the task}} of {{deciding}} which content messages should be realised in a target document based on raw data provided by an underlying application, and how these messages should be structured- is arguably {{one of the most}} crucial tasks in Natural Language Generation (NLG). In this work we present a machine learning approach to Document Planning that is entirely trainable from annotated corpora, and which paves the way to our long-term goal of developing a <b>text</b> <b>generator</b> system based on a series of classifiers for a simple NLG application in the education domain...|$|E
40|$|In {{this article}} we {{describe}} a method for automatically generating text summaries of data corresponding to traces of spatial movement in geographical areas. The method can help humans to understand large data streams, such as the amounts of GPS data recorded {{by a variety of}} sensors in mobile phones, cars, etc. We describe the knowledge representations we designed for our method and the main components of our method for generating the summaries: a discourse planner, an abstraction module and a <b>text</b> <b>generator.</b> We also present evaluation results that show the ability of our method to generate certain types of geospatial and temporal descriptions...|$|E
50|$|Nick Montfort is an {{associate}} professor of digital media at MIT in the Program in Writing and Humanistic Studies. He is also a poet, computer scientist, and author of interactive fiction. Montfort has collaborated on the blog Grand Text Auto, the sticker novel Implementation, and the contemporary fiction novel 2002: A Palindrome Story. He writes poems, <b>text</b> <b>generators,</b> and interactive fiction such as Book and Volume and Ad Verbum. Most recently, he and Ian Bogost wrote Racing the Beam: The Atari Video Computer System (MIT Press, 2009). Montfort also wrote Twisty Little Passages: An Approach to Interactive Fiction (MIT Press, 2003) and co-edited The Electronic Literature Collection: Volume 1 (ELO, 2006) and The New Media Reader (MIT Press, 2003).|$|R
40|$|International audienceMetamodeling {{is raising}} {{more and more}} {{interest}} {{in the field of}} language engineering. While this approach is now well understood for defining abstract syntaxes, formally defining concrete syntaxes with metamodels is still a challenge. Concrete syntaxes are traditionally expressed with rules, conforming to EBNF-like grammars, which can be processed by compiler compilers to generate parsers. Unfortunately, these generated parsers produce concrete syntax trees, leaving a gap with the abstract syntax defined by metamodels, and further ad-hoc hand-coding is required. In this paper we propose a new kind of specification for concrete syntaxes, which takes advantage of metamodels to generate fully operational tools (such as parsers or <b>text</b> <b>generators).</b> The principle is to map abstract syntaxes to concrete syntaxes via bidirectional mapping-models with support for both model-to-text, and text-to-model transformations...|$|R
40|$|Abstract. Pronominal {{anaphora}} resolution {{consists in}} finding a referent for a given pronoun. Although being essential for many natural language processing systems, such as automatic translators, <b>text</b> <b>generators</b> and summarizers, there is a myriad of issues regarding this task, particularly when {{there is more than}} one possible referent for a given pronoun. Over the years, several approaches have been proposed to deal with this chal-lenge, usually taking only syntactic information into account. On the other hand, methods based on Centering Theory rely on concepts such as coherence, for instance, to do the job. In this work, we describe our implementation and evaluation of existing centering-based algorithms for pronominal resolution in Portuguese. As a result, we indicate both the strong and weak points of each of the tested algorithms, thereby helping other researchers to make a more informed decision about which method to use. ...|$|R
40|$|This paper reports {{experiments}} in which pC RU — a generation framework that combines probabilistic generation methodology with a comprehensive {{model of the}} generation space — is used to semi-automatically create several versions of a weather forecast <b>text</b> <b>generator.</b> The generators are evaluated in terms of output quality, development time and computational efficiency against (i) human forecasters, (ii) a traditional handcrafted pipelined NLG system, and (iii) a HALOGEN-style statistical generator. The most striking result is that despite acquiring all decision-making abilities automatically, the best pC RU generators receive higher scores from human judges than forecasts written by experts...|$|E
40|$|We {{address the}} problem of {{ordering}} several circumstantials when generating or revising a clause. This problem occurs {{in the context of a}} multi-document summarization system that relies on language generation to incrementally reformulate the wording of fragments of sentences extracted from the documents. We present the results of an extensive corpus analysis of the relative position of different types of circumstantials. Our approach learns a set of rules using parameters that can be effectively used by our system. Evaluation indicates that these rules, which we have implemented in our <b>text</b> <b>generator,</b> attain a high level of precision (95. 4 % over a baseline of 78. 6 %). ...|$|E
40|$|We present {{experiments}} on modifying the semantic {{orientation of the}} near-synonyms in a text. We analyze a text into an interlingual representation {{and a set of}} attitudinal nuances, with particular focus on its near-synonyms. Then we use our <b>text</b> <b>generator</b> to produce a text with the same meaning but changed semantic orientation (more positive or more negative) by replacing, wherever possible, words with nearsynonyms that differ in their expressed attitude. Near-synonyms and attitudinal nuances The choice of a word from among a set of near-synonyms that share the same core meaning but vary in their connotations is one {{of the ways in which}} a writer controls the nuances of a text. In many cases, the nuances that differentiate near-synonyms relate to expressed attitude and affect. Fo...|$|E
40|$|Natural {{language}} {{software tools}} {{may have an}} important role in making requirements specifications more accessible. Possible tools include text processors to support requirements elicitation, and <b>text</b> <b>generators</b> to support requirements validation. The current paper reports on our progress in developing a natural language generation system, integrating this tool with a graphical interface and an automated reasoning system, and applying it in the domain of requirements validation. The resulting synthesis of logic, language and graphics is an important first step in developing an intelligent assistant to support a designer in both requirements elicitation and validation. 1 Introduction The requirements specification for any system, written in some combination of diagrams and natural language, may be difficult for a designer or manager to reason about, just because of its complexity. An equivalent specification, written in a formal language, can also cause problems. It may be difficult to c [...] ...|$|R
40|$|This paper {{describes}} the NECA MNLG; a fully implemented Multimodal Natu-ral Language Generation module. The MNLG is deployed {{as part of}} the NECA system which generates dialogues be-tween animated agents. The genera-tion module supports the seamless inte-gration of full grammar rules, templates and canned <b>text.</b> The <b>generator</b> takes in-put which allows for the specification of syntactic, semantic and pragmatic con-straints on the output. ...|$|R
40|$|Metamodeling {{is raising}} {{more and more}} {{interest}} {{in the field of}} language engineering. While this approach is now well understood for the definition of abstract syntaxes, the formal definition of concrete syntaxes is still a challenge. Concrete syntaxes are traditionally expressed with rules, conforming to EBNF-like grammars, which can be processed by compiler compilers to generate parsers. Unfortunately, these syntax defined by metamodels. This gap is usually filled by time consuming ad-hoc hand-coding. In this paper we propose a new kind of specification for concrete syntaxes that takes advantage of metamodels to generate tools (such as parsers or <b>text</b> <b>generators)</b> which directly manipulate abstract syntax trees. The principle is to map abstract syntaxes to concrete syntaxes via EBNF-like rules that explain how to render an abstract concept into a given concrete syntax, and how to trigger other rules to handle the properties of the concepts. The major difference with EBNF is that rules may have sub-rules, which can be automatically triggered based on the inheritance hierarchy of the abstract syntax concepts. Key words: abstract concrete syntax mapping, metamodeling...|$|R
