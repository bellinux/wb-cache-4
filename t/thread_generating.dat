3|116|Public
30|$|KVM {{works in}} a way such that each vCPU of a VM is {{represented}} by a single thread on its host. Therefore, to complete the fused analysis, we need to map every VM’s vCPU with its respective thread. This mapping is achieved by using the payloads of both synchronization and VMEntry events. On the one hand, a synchronization event recorded on the host contains the identification number of the VM, so we can match the <b>thread</b> <b>generating</b> the event with the machine. On the other hand, a VMEntry gives the ID of the vCPU going to run. This second information allows the association of the host thread with its corresponding vCPU.|$|E
40|$|By {{focusing}} on structural features within developing economies, this paper attempts to reconcile developments observed in many post-liberalization countries {{with the help}} of modified versions of standard trade theory factor endowment models. The common <b>thread</b> <b>generating</b> most of our interesting results is the presence of sectors that are even more labor-intensive than those producing traded goods. Measures undertaken to enhance public sector efficiency and attract investment in an import-intensive export sector may increase rental-wage and skilled- unskilled wage gaps, contra the predictions of the simple Heckscher-Ohlin-Samuelson model. Moreover, increasing income inequality can exist side-by-side with informalization of the economy. The greater unskilled labor-intensity of the informal sector, factor market rigidities in the formal sector, and the sector specificity of some factors crucially influence the outcomes of policy experiments. Even within a simple framework that assumes full employment of resources, large segments of labor may have good reason to fear the consequences of reform...|$|E
40|$|This study {{investigated}} the communication styles of 5 mentors in telementoring a class of 33 preservice teachers. Electronic forum was the instrument of communication between the mentors and the students, and a Web-based computer mediated communication system was used to facilitate the instruction in the course. Data collected in an 8 -week period resulted in 52 mentors initiating discussion threads and 43 follow-up posts. Analysis of the 5 mentors ' 52 initial <b>thread</b> <b>generating</b> posts revealed 4 styles: the direct questioning, context explaining, experience sharing, and greeting styles. It {{was found that the}} five mentors most often posted a question in straightforward fashion (direct questioning). Context explaining was also used quite often. On the follow-up posts, it was found that 6 categorical styles exist among the 43 posts: the direct answering, suggesting, agreeing, summarizing, relating, and questioning styles. In this study, the agreeing, the relating, and the direct answering styles were used most often. It seeme...|$|E
25|$|Lawton {{was born}} at Dukinfield, Cheshire, the son of John Edward Lawton and his wife Ellen. His father owned a cotton {{spinning}} business at Dukinfield and in 1883 Frederic Charles Arkwright brought him to Matlock, Derbyshire to revive Masson Mill to meet the growing market for sewing <b>thread</b> <b>generated</b> by the popularity of sewing machines. Lawton senior built a substantial mansion Woodbank, later Cromford Court, overlooking Masson Mill.|$|R
40|$|The recent {{advent of}} multithreaded {{architectures}} holds many promises: {{the exploitation of}} intra-thread locality and the latency tolerance of multithreaded synchronization {{can result in a}} more efficient processor utilization and higher scalability. The challenge for a code generation scheme is to make effective use of the underlying hardware by <b>generating</b> large <b>threads</b> with a large degree of internal locality without limiting the program level parallelism or increasing latency. Top-down code generation, where threads are created directly from the compiler's intermediate form, is effective at creating a relatively large thread. However, having only a limited view of the code at any one time limits the quality of <b>threads</b> <b>generated.</b> These top-down <b>generated</b> <b>threads</b> can therefore be optimized by global, bottom-up optimization techniques. In this paper, we introduce the Pebbles multithreaded model of computation and analyze a code generation scheme whereby top-down code generation is combine [...] ...|$|R
30|$|Step 3. Creation and {{initiation}} of the threads T 1 and T 2. In this step, the two separate <b>threads</b> are <b>generated,</b> and initial conditions and control parameters are initiated (the threads are demonstrated in Figure  1 using two parallel vertical rectangles).|$|R
50|$|In practice, {{when the}} {{sequence}} identity {{in a sequence}} sequence alignment is low (i.e. <25%), homology modeling may not produce a significant prediction. In this case, if there is distant homology found for the target, protein <b>threading</b> can <b>generate</b> a good prediction.|$|R
30|$|In {{the main}} {{simulation}} loop, update Phya with collision data each physics step. This {{is a function}} call to the integration layer that queries the physics engine and updates the Phya collision state, which is in turn used by the audio <b>thread</b> to <b>generate</b> audio.|$|R
40|$|This paper {{presents}} a context-sensitive and path-sensitive, intra-thread and inter-thread solution to combined pointer analysis, escape analysis and data dependence analysis of multithreaded Java programs {{which uses a}} sparse representation. We build and maintain a complete Static Single Assignment (SSA) form even for fields variables. We show how to compute inter-thread dependencies for multithreaded programs with structured fork-join constructs, open-ended <b>threads,</b> recursively <b>generated</b> <b>threads,</b> monitors, and wait-notify synchronization. We have implemented our algorithm in a slicer for Java programs. Our experimental results show that a sparse representation improves the analysis time and strong updates on field variables improves the precision. © AC...|$|R
40|$|Thesis (M. S.) 				 California State University, Los Angeles, 2012 Committee members: Charles Liu, Khosrow Rad, Helen Ryaciotaki-Boussalis, Fereydoun DaneshgaranAudio Compression, Multi-Threading, PCM, Speex, Vorbis, ZlibThe thesis work {{focuses on}} data {{streaming}} methods within a Ubiquitous Video Conferencing (UVC) multicasting system. Such a system demands simultaneous communication channels among clients. The client-side UVC application supports independent control flows through separate <b>threads</b> <b>generated</b> on {{demand for the}} main UVC module, and the variant data streams. In this thesis, the different components of the UVC system are integrated based on the processing libraries belonging to the resident application platform Qt, cross-platform audio/video solution FFMPEG, and image processing library Open CV. The selective use, modification and integration {{of each of these}} three entities allow us to take our UVC application to the level necessary for our clientele's never-ending expansion...|$|R
40|$|Multiprocessor {{systems are}} {{increasingly}} becoming the systems {{of choice for}} low and high-end servers, running such diverse tasks as number crunching, large-scale simulations, data base engines and world wide web server applications. With such diverse workloads, system utilization and throughput, as well as execution time become important performance metrics. In this paper we present efficient kernel scheduling policies and propose a new kernel-user interface aiming at supporting efficient parallel execution in diverse workload environments. Our approach relies on support for user level threads which are used to exploit parallelism within applications, and a two-level scheduling policy which coordinates the number of resources allocated by the kernel {{with the number of}} <b>threads</b> <b>generated</b> by each application. We compare our scheduling policies with the native gang scheduling policy of the IRIX 6. 4 operating system on a Silicon Graphics Origin 2000. Our experimental results show substantial [...] ...|$|R
40|$|Speculative {{multithreading}} $(SpMT) $ {{promises to}} be an effective mechanism for parallelizing non-numeric programs. Proper thread formation is crucial for obtaining good speedup in an SpMT system. We have developed an $SpMT$ compiler framework for partitioning sequential programs into multiple threads. Since control and data speculations are the essence of $SpMT$ execution model, inter-thread data dependences and inter-thread control predictions at run-time play crucial roles in affecting the performance of the $SpMT$ system. Therefore, to evaluate existing $SpMT$ compiler or hardware systems, and to design more efficient systems it is necessary to characterize the dynamic program dependences carefully. In this paper, we have studied the run-time behaviors of inter-thread data and control dependences of the <b>threads</b> <b>generated</b> by our compiler in detail and used that for analyzing the performance. The analyses reveal that our compiler has successfully modeled the inter-thread data and control dependences of non-numeric applications and minimized them while <b>generating</b> the <b>threads...</b>|$|R
30|$|Stage I: Gel {{cross-linking}} induction stage. In this stage, the viscosity remained {{little and}} changed slowly. Intramolecular cross-linking appeared gradually after gel cross-linking agent and polymer were mixed. Many single-molecule clusters, which were polynuclear olation complex ions actually {{and looked like}} tight <b>threads,</b> were <b>generated</b> later because of the intramolecular contraction. Though the number of clusters was large, gel system apparent viscosity was barely influenced.|$|R
40|$|Abstract—The {{trend to}} develop {{increasingly}} more intelligent systems leads {{directly to a}} considerable demand {{for more and more}} computational power. Programming models that aid to exploit the application parallelism with current multi-core systems exist but with limitations. From this perspective, new execution models are arising to surpass limitations to scale up the number of processing elements, while dedicated hardware can help the scheduling of the threads in many-core systems. This paper depicts a data-flow based execution model that exposes to the multi-core x 86 _ 64 architecture up to millions of fine-grain threads. We propose to augment the existing architecture with a hardware thread scheduling unit. The functionality of this unit is exposed by means of four dedicated instructions. Results with a pure data-flow application (i. e., Recursive Fibonacci) show that the hardware scheduling unit can load the computing cores (up to 32 in our tests) in a more efficient way than run-time managed <b>threads</b> <b>generated</b> by programming models (e. g., OpenMP and Cilk). Further, our solution shows better scaling and smaller saturation when the number of workers increases...|$|R
40|$|Publication interne n˚ 1822 — Octobre 2006 — 19 pages Abstract: The {{relentless}} {{increase of}} power density has rendered temperature a primary design constraint for microprocessors. Although a power density increase {{does not necessarily}} lead to a higher time-average temperature, we show {{in this study that}} it increases the amplitude of temperature oscillations. As a consequence, thermal throttling may be engaged more often and degrade performance. We establish that a possible way to decrease the amplitude of temperature oscillations is to increase their frequency. In a multiprogrammed environment, executing multiple threads/processes alternately can result in temperature oscillations if different <b>threads</b> <b>generate</b> different power densities. We therefore suggest that, as power density increases and processors get faster, the time slice can and should be decreased. Using a short time slice also enables the operating system to take advantage of activity migration without special architectural support. Indeed, on a thermally constrained multi-core (TCMC), activity migration can be leveraged to decrease temperature by better distributing heat over the different cores. Furthermore, we show that fair scheduling with different thread priorities can be achieved but requires sometimes to ru...|$|R
40|$|AbstractThe {{use of an}} OpenMP {{compiler}} {{optimized for}} the corresponding multicore system is a good option, {{but it is possible}} in a system to have access to more than one compiler and different compilers can appropriately optimize different parts of the code. In this paper we present a proposal for an autotuning system for linear algebra routines that decides the best compiler for each situation, as well as other parameter values, as, for example, the number of <b>threads</b> to <b>generate...</b>|$|R
40|$|Using {{a virtual}} spider robot, we studied {{hypotheses}} about the weaving behaviour of orb spiders. Our model spiders built virtual webs that mimicked perfectly the visual architecture of real webs {{of the garden}} cross spider Araneus diadematus. The matching of capture spiral and auxiliary spiral pitch was an apparently emergent property in both types of web. This validated our interpretation of the garden spider's web-building decision rules, which use strictly local interactions with previously placed <b>threads</b> to <b>generate</b> global architecture...|$|R
40|$|Industry {{has shifted}} towards {{multi-core}} designs {{as we have}} hit the memory and power walls. However, single thread performance remains of paramount importance since some applications have limited thread-level parallelism (TLP), and even a small part with limited TLP impose important constraints to the global performance, as explained by Amdahl’s law. In this {{paper we propose a}} novel approach for leveraging multiple cores to improve single-thread performance in a multi-core design. The proposed technique features a set of novel hardware mechanisms that support the execution of <b>threads</b> <b>generated</b> at compile time. These threads result from a fine-grain speculative decomposition of the original application and they are executed under a modified multi-core system that includes: (1) mechanisms to support multiple versions; (2) mechanisms to detect violations among threads; (3) mechanisms to reconstruct the original sequential order; and (4) mechanisms to checkpoint the architectural state and recovery to handle misspeculations. The proposed scheme outperforms previous hardware-only schemes to implement the idea of combining cores for executing single-thread applications in a multi-core design by more than 10 % on average on Spec 2006 for all configurations. Moreover, single-thread performance is improved by 41 % on average when the proposed scheme is used on a Tiny Core, and up to 2. 6 x for some selected applications...|$|R
40|$|Alternative {{dispatch}} {{techniques for}} the Tcl VM Interpreter We compare {{the performance of}} various virtual machine dispatch strategies in Tcl, including traditional highlyportable techniques, and newer techniques which sacrifice some portability for performance. Tcl’s high-level opcodes have large implementation bodies and contain C function calls. Compared to other VMs, the opcodes require many cycles to execute. Dispatch overhead is relatively low, because large bodies consume much more execution time than dispatch. Direct threaded code improves tclbench benchmarks by about 5 % over switch dispatch. We review our catenation technique, which compiles bytecode using copied templates of Sparc code made from the normal C-compiled VM’s implementation of each virtual opcode. This eliminates all dispatch, but is impractical due to poor portability, and because the copying amplifies Tcl’s heavy instruction cache load. Based on subroutine <b>threading,</b> context <b>threading</b> <b>generates</b> native call instructions for dispatch. Simpler than catenation, it imposes much lower I-cache load. It preserves more interpreter state, is a better vehicle for mixed-mode execution, and accomodates interesting optimizations. Our implementation for Tcl on Sparc improves 97 % of benchmarks in the tclbench suite with more than 1000 dispatches, {{by an average of}} 9. 5 % over switch dispatch (12. 0 % and 16. 5 % for> 10000 and> 100000 dispatches, respectively. ...|$|R
50|$|GeNMR uses {{homology}} {{modeling and}} sequence/structure <b>threading</b> to rapidly <b>generate</b> a first-pass {{model of the}} query protein. The use of homology modeling/threading in GeNMR allows a considerable speed-up in its structure calculations since homology models can often be generated and refined in a minute or two.|$|R
40|$|The strain {{evolution}} in metal organic {{chemical vapor deposition}} growth of GaN on Si (111) substrate with an AlN interlayer is studied. During the growth of GaN film on AlN interlayer, the growth stress changes from compression to tension. The study shows that the density of V trenches in the AlN interlayer surface and the <b>threading</b> dislocations <b>generated</b> in the AlN interlayer have a significant influence on this strain evolution process. The dislocations generated in AlN interlayer may thread across the interface and {{play a key role}} in the strain evolution process of the GaN layer grown on AlN interlayer...|$|R
40|$|The {{effectiveness}} of software testing is often assessed by mea-suring coverage of {{some aspect of}} the software, such as its code. There is much research aimed at increasing code cov-erage of sequential software. However, there has been lit-tle research on increasing coverage for concurrent software. This paper presents a new technique that aims to achieve high coverage of concurrent programs by <b>generating</b> <b>thread</b> schedules to cover uncovered coverage requirements. Our technique first estimates synchronization-pair coverage re-quirements, and then <b>generates</b> <b>thread</b> schedules that are likely to cover uncovered coverage requirements. This pa-per also presents a description of a prototype tool that we implemented in Java, and the results of a set of studies we performed using the tool on a several open-source programs. The results show that, for our subject programs, our tech-nique achieves higher coverage faster than random testing techniques; the estimation-based heuristic contributes sub-stantially to the {{effectiveness of}} our technique...|$|R
40|$|The {{relentless}} {{increase of}} power density has rendered temperature a primary design constraint for microprocessors. Although a power density increase {{does not necessarily}} lead to a higher time-average temperature, we show {{in this study that}} it increases the amplitude of temperature oscillations. As a consequence, thermal throttling may be engaged more often and degrade performance. We establish that a possible way to decrease the amplitude of temperature oscillations is to increase their frequency. In a multiprogrammed environment, executing multiple threads/processes alternately can result in temperature oscillations if different <b>threads</b> <b>generate</b> different power densities. We therefore suggest that, as power density increases and processors get faster, the time slice can and should be decreased. Using a short time slice also enables the operating system to take advantage of activity migration without special architectural support. Indeed, on a thermally constrained multi-core (TCMC), activity migration can be leveraged to decrease temperature by better distributing heat over the different cores. Furthermore, we show that fair scheduling with different thread priorities can be achieved but requires sometimes to run simultaneously fewer threads than cores when fewer threads are sufficient to maintain the TCMC at thermal saturation. We propose a scheduling method that implements activity migration while taking into consideration different thread priorities. We show that, under a temperature constraint, this scheduling method provides a fair partitioning of the overall computing power of a TCMC while delivering a global execution throughput close to the maximum throughput...|$|R
40|$|The Java {{programming}} language supports monitors. Monitor implementations, like other concurrent programs, {{are hard to}} test due to the inherent non-determinism. This paper presents the ConAn (Concurrency Analyser) tool for generating drivers for the testing of Java monitors. To obtain adequate controllability over the interactions between Java <b>threads,</b> the <b>generated</b> driver contains processes that are synchronized by a clock. The driver automatically executes the calls in the test sequence in the prescribed order and compares the outputs against the expected outputs specified in the test sequence. The method and tool are illustrated in detail on an asymmetric producer-consumer monitor, and their application to two other monitors is discussed...|$|R
25|$|Threading is {{the process}} of {{creating}} a screw thread. More screw threads are produced each year than any other machine element. There are many methods of <b>generating</b> <b>threads,</b> including subtractive methods (many kinds of thread cutting and grinding, as detailed below); deformative or transformative methods (rolling and forming; molding and casting); additive methods (such as 3D printing); or combinations thereof.|$|R
40|$|Two {{fractured}} main landing {{attachment bolts}} from an aircraft {{were sent to}} the laboratory for analysis. Examination showed that both the bolts have failed by fatigue. Examination also revealed numerous cracks at the thread roots of the bolts. The most probable reason for fatigue crack initiation appears to be the existence of fine cracks at the <b>thread</b> roots, possibly <b>generated</b> during tightening of the bolts...|$|R
30|$|The in-built {{registration}} algorithm of SMART affords high-accuracy static alignment between {{real and}} virtual objects. Efforts {{have also been}} made to reduce dynamical misregistration, including: 1) {{in order to reduce}} synchronization latency, multiple <b>threads</b> are dynamically <b>generated</b> for reading and processing sensor measurement immediately upon the data arrival in the host system; and 2) an adaptive lag compensation algorithm is designed to reduce the latency induced by the Finite Impulse Response (FIR) filter.|$|R
40|$|Concurrent {{programs}} {{are hard to}} test due to the inherent nondeterminism. This paper presents a method and tool support for testing concurrent Java components. Too[support is offered through ConAn (Concurrency Analyser), a too] for generating drivers for unit testing Java classes {{that are used in}} a multithreaded context. To obtain adequate controllability over the interactions between Java <b>threads,</b> the <b>generated</b> driver contains <b>threads</b> that are synchronized by a clock. The driver automatically executes the calls in the test sequence in the prescribed order and compares the outputs against the expected outputs specified in the test sequence. The method and tool are illustrated in detail on an asymmetric producer-consumer monitor. Their application to testing over 20 concurrent components, a number of which are sourced from industry and were found to contain faults, is presented and discussed...|$|R
40|$|This paper {{presents}} a finite element evaluation of residual stress in a <b>thread</b> form <b>generated</b> by a cold rolling process. Included in this evaluation area mesh development study, methodology sensitivity studies, {{and the effects}} of applied loads on the stress in a rolled thread root. A finite element analysis of the thread forming process using implicit modeling methodology, incremental large deformation, elastic-plastic material properties, and adaptive meshing techniques was performed. Results of the study indicate the axial component of the residual stress in the thread root of the fastener is highly compressive. Results also indicate that a rolled threaded fastener loaded to an average tensile stress equal to yield through the cross-section will retain compressive stresses in the thread root. This compressive stress state will be advantageous when evaluating fasteners for fatigue and environmental concerns...|$|R
40|$|This paper {{proposes a}} novel MAP {{inference}} framework for Markov Random Field (MRF) in parallel computing environments. The inference framework, dubbed Swarm Fusion, {{is a natural}} generalization of the Fusion Move method. Every thread (in a case of multi-threading environments) maintains and updates a solution. At each iteration, a <b>thread</b> can <b>generate</b> arbitrary number of solution proposals and take arbitrary number of concurrent solutions from the other threads to perform multi-way fusion in updating its solution. The framework is general, making popular existing inference techniques such as alpha-expansion, fusion move, parallel alpha-expansion, and hierarchical fusion, its special cases. We have evaluated the effectiveness of our approach against competing methods on three problems of varying difficulties, in particular, the stereo, the optical flow, and the layered depthmap estimation problems...|$|R
40|$|Efficient {{large-scale}} {{parallel processing}} can result only from proper handling of latency. Latency arises either from remote memory accesses or synchronizations. Multithreading is an execution model that can effectively deal with latency by switching among {{a set of}} ready threads. This model has been proposed {{in a variety of}} forms: a unit of storage can be based on either a collection of threads or a single thread, threads can be either blocking or non-blocking, and synchronization can be either implicit or explicit. This dissertation describes research in the evaluation and optimization of various issues in multithreading. Issues of particular interest are the development of a multithreaded execution model {{to be used as a}} test-bed and a hybrid code generation scheme where <b>threads</b> are <b>generated</b> in a top-down manner and then optimized in a bottom-up fashion. Various forms of locality are also ide [...] ...|$|R
40|$|This paper {{introduces}} Simultaneous Speculation Scheduling, a new compiler {{technique that}} enables speculative execution of alternative program paths. In our approach concurrently executed <b>threads</b> are <b>generated</b> that represent alternative program paths. Each thread {{is the result}} of a speculation on the outcome of one or more branches. All threads are simultaneously executed although only one of them follows the eventually correct program path. Our technique goes beyond the capabilities of usual global instruction scheduling algorithms, because we overcome most of the restrictions to speculative code motion. The architectural requirements are the ability to run two or more threads in parallel, and an enhanced instruction set to control threads. Our technique aims at multithreaded architectures, in particular simultaneous multithreaded, nanothreaded, and microthreaded processors, but can be modified for multiscalar, datascalar, and trace processors. We evaluate our approach using program ke [...] ...|$|R
40|$|Java event {{spaces are}} partial orders {{of memory and}} <b>thread</b> actions as <b>generated</b> by a multi-threaded Java program in execution. This paper shows how {{standard}} tech-niques of slicing {{can be used to}} reduce the size of Java event spaces. Furthermore, we face the problem that arises when two or more variables of an event space are aliased and we outline an algorithm that goes through an event space and calculates aliases of variables. We incorporate this algorithm in the calculation of the program program slice...|$|R
40|$|Abstract. We propose CUSTARD — CUStomisable Threaded ARchitecture — a soft {{processor}} {{design space}} that combines support for multiple hardware <b>threads</b> and automatically <b>generated</b> custom instructions. Multiple threads incur low additional hardware cost and allow fine-grained concurrency without multiple processor cores or software overhead. Custom instructions, generated {{for a specific}} application, accelerate frequently performed computations by implementing them as dedicated hardware. In this paper we present a flexible processor and compiler generation system, FPGA implementations of CUSTARD and performance/area results for media and cryptography benchmarks. ...|$|R
40|$|In-x Ga 1 -xN/GaN {{multiple}} {{quantum well}} (MQW) samples with strain-layer thickness lager/less than the critical one are investigated by temperature-dependent photoluminescence and transmission electron microscopy, and double crystal x-ray diffraction. For the sample with the strained-layer thickness {{greater than the}} critical thickness, we observe a high density of <b>threading</b> dislocations <b>generated</b> at the MQW layers and extended to the cap layer. These dislocations result from relaxation of the strain layer when its thickness is beyond the critical thickness. For the sample with the strained-layer thickness greater than the critical thickness, temperature-dependent photoluminescence measurements give evidence that dislocations generated from the MQW layers due to strain relaxation are main reason of the poor photoluminescence property, and the dominating status change of the main peak with increasing temperature is attributed to the change of the radiative recombination from the areas including dislocations to the ones excluding dislocations...|$|R
40|$|This paper {{proposes a}} new {{compiler}} technique that enables speculative execution of alternative program paths. In our approach separate <b>threads</b> are <b>generated</b> that simultaneously {{speculate on the}} outcome of branches and that may run in parallel. Our technique goes beyond the capabilities of usual global instruction scheduling algorithms, because we overcome the restrictions to speculative instruction movement introduced by branches that could not be handled. The architectural requirements are the ability to run two or more threads in parallel and an enhanced instruction set to control threads. Our technique aims at simultaneous multithreaded, nanothreaded, and microthreaded processors, but can be modified for multiscalar, datascalar, and trace processors. We evaluate our approach using program kernels from the SPECint benchmark suite. I. Introduction The continuous progress in microprocessor technology allows to implement a growing number of execution units on a single chip. With a sing [...] ...|$|R
