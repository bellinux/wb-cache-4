4|31|Public
5000|$|... #Caption: WA Parks and Wildlife fire crew {{lighting}} a prescribed burn (echelon lighting) at Octopus Bore <b>track</b> <b>buffer,</b> Lorna Glen former pastoral lease, now joint managed with traditional owners, May 2015.|$|E
40|$|Multi-GPU {{machines}} are being increasingly used in high-performance computing. Each GPU {{in such a}} machine has its own memory and does not share the address space either with the host CPU or other GPUs. Hence, applications utilizing multiple GPUs have to manually allocate and manage data on each GPU. Existing works that propose to automate data allocations for GPUs have limitations and inefficiencies in terms of allocation sizes, exploiting reuse, transfer costs, and scalability. We propose a scalable and fully automatic data allocation and buffer management scheme for affine loop nests on multi-GPU machines. We call it the Bounding-Box-based Memory Manager (BBMM). BBMM can perform at runtime, during standard set operations like union, intersection, and difference, finding subset and superset relations on hyperrectangular regions of array data (bounding boxes). It uses these operations along with some compiler assistance to identify, allocate, and manage data required by applications in terms of disjoint bounding boxes. This allows it to (1) allocate exactly or nearly as much data as is required by computations running on each GPU, (2) efficiently <b>track</b> <b>buffer</b> allocations and hence maximize data reuse across tiles and minimize data transfer overhead, and (3) and as a result, maximize utilization of the combined memory on multi-GPU machines. BBMM can work with any choice of parallelizing transformations, computation placement, and scheduling schemes, whether static or dynamic. Experiments run on a four-GPU machine with various scientific programs showed that BBMM reduces data allocations on each GPU by up to 75 % compared to current allocation schemes, yields performance of at least 88 % of manually written code, and allows excellent weak scaling...|$|E
40|$|Unexpected and {{apparently}} random crashes • In system heap routines • In previously stable places • These bugs {{are hard to}} find, but important to fix – Unpredictable and occur {{in a different place}} to the symptoms – But often remain unidentified and unfixed • There are many tools to help us find these errorsAnalogues • Failure to open file, window, DB connection, … • Failure to close file, window, DB connection, … • Closing one twice • Trying to use one that’s been closed • Correct closing on normal path but that code bypassed on exception — needs test cases that exercise exception raising • Using wrong resource • Misconfiguring device (camera &c) or driver • Memory is onlyone resource; this lecture is not just about memory! Style can help: s: = FileStream read: ‘foobar. txt’. n: = 0. [s atEnd] whileFalse: [s nextLine. n: = n+ 1]. s close. ⇑n “compare with” ⇑(FileStream read ‘foobar. txt’) bindOwn: [:s | n: = 0. [s atEnd] whileFalse: [s nextLine. n: = n+ 1]. n] “with second version, can’t forget to close, will be autoclosed on exception. Java: try (ResourceType resource = …) … cleans up anything that implements AutoCloseable. ” Ways to do monitoring • Macros+libraries • Source-to-source transformation • Object-to-object transformation • Object interpretation (emulation) • Object translation, load time or JIT • Trade off how much it can know about the program against what it can do; object level things can do stuff no ordinary compiler can generate. • How much does tool need? One file? All your files? All the files and all the shared objects? • MacOS Instruments can trace into OSLibraries • From last lecture – #define to replace malloc() and free() – Source code to <b>track</b> <b>buffer</b> over-run and under-runs – Source code to track memory leak...|$|E
5000|$|... 1965 — Staines West {{railway station}} closed. The station {{building}} survives intact and is Grade II listed. A section of <b>track</b> and <b>buffer</b> stop survive. The platform area {{is now part}} of a car park.|$|R
5000|$|... #Caption: End of the <b>tracks</b> at a <b>buffer</b> stop on {{the western}} side of the station ...|$|R
40|$|Monitoring and {{management}} of popular coastal destinations requires accurate benchmark data on access nodes, travel networks as well as detailed information on landscapes and seascapes. We investigated the 300 km long coastal strip along Ningaloo Reef using hyperspectral remote sensing techniques combined with extensive fieldwork. We mapped bathymetry and marine habitats at high resolution to a depth Of 20 In covering 762 km 2 of the reef. We mapped land cover including vegetation along the coast for an area of 988 krn 2. We also compiled a database of the track and road network up to 2 km inland from the coast and characterised the dominant sediment and vegetation cover along <b>track</b> <b>buffers.</b> Many of the areas with the highest density of tracks were adjacent to sanctuary areas in the marine pork with {{easy access to the}} reef from the beach. Land tenure is important in managing the coastal area and the highest track densities have been found in areas managed as pastoral stations while the lowest are in areas managed as national park. <b>Track</b> <b>buffers</b> contained a lot of vegetation and with track expansion this may be destroyed. With the proposed changes to the pastoral leases expected to result in changes in tenure, and it is vital that comprehensive and cost-effective monitoring is developed and implemented to protect the coastal area and adjacent reef. Remote sensing offers a range of quantitative, repetitive and operational methods suitable for creating benchmark data sets and follow up studies for monitoring. It is also effective for large areas where access and logistics for management are very challenging...|$|R
40|$|Multi-GPU {{machines}} are being increasingly used in high performance computing. These {{machines are}} being used both as standalone work stations to run computations on medium to large data sizes (tens of gigabytes) and as a node in a CPU-Multi GPU cluster handling very large data sizes (hundreds of gigabytes to a few terabytes). Each GPU in such a machine has its own memory and does not share the address space either with the host CPU or other GPUs. Hence, applications utilizing multiple GPUs have to manually allocate and managed at a on each GPU. A significant body of scientific applications that utilize multi-GPU machines contain computations inside affine loop nests, i. e., loop nests that have affine bounds and affine array access functions. These include stencils, linear-algebra kernels, dynamic programming codes and data-mining applications. Data allocation, buffer management, and coherency handling are critical steps {{that need to be}} performed to run affine applications on multi-GPU machines. Existing works that propose to automate these steps have limitations and in efficiencies in terms of allocation sizes, exploiting reuse, transfer costs and scalability. An automatic multi-GPU memory manager that can overcome these limitations and enable applications to achieve salable performance is highly desired. One technique that has been used in certain memory management contexts in the literature is that of bounding boxes. The bounding box of an array, for a given tile, is the smallest hyper-rectangle that encapsulates all the array elements accessed by that tile. In this thesis, we exploit the potential of bounding boxes for memory management far beyond their current usage in the literature. In this thesis, we propose a scalable and fully automatic data allocation and buffer management scheme for affine loop nests on multi-GPU machines. We call it the Bounding Box based Memory Manager (BBMM). BBMM is a compiler-assisted runtime memory manager. At compile time, it use static analysis techniques to identify a set of bounding boxes accessed by a computation tile. At run time, it uses the bounding box set operations such as union, intersection, difference, finding subset and superset relation to compute a set of disjoint bounding boxes from the set of bounding boxes identified at compile time. It also exploits the architectural capability provided by GPUs to perform fast transfers of rectangular (strided) regions of memory and hence performs all data transfers in terms of bounding boxes. BBMM uses these techniques to automatically allocate, and manage data required by applications (suitably tiled and parallelized for GPUs). This allows It to (1) allocate only as much data (or close to) as is required by computations running on each GPU, (2) efficiently <b>track</b> <b>buffer</b> allocations and hence, maximize data reuse across tiles and minimize the data transfer overhead, (3) and as a result, enable applications to maximize the utilization of the combined memory on multi-GPU machines. BBMM can work with any choice of parallelizing transformations, computation placement, and scheduling schemes, whether static or dynamic. Experiments run on a system with four GPUs with various scientific programs showed that BBMM is able to reduce data allocations on each GPU by up to 75 % compared to current allocation schemes, yield at least 88 % of the performance of hand-optimized Open CL codes and allows excellent weak scaling...|$|E
2500|$|The two outer bay platforms, {{which were}} used by {{terminating}} trains, were abandoned in the 1970s and the third rail was removed, although the <b>track</b> and <b>buffers</b> were left in place. The southern bay was brought back into use in May 2010 {{as part of the}} East London Line development.|$|R
30|$|We {{cast the}} problem as a {{regression}} task on the log-transformed crime counts in each census tract. For each census tract, we sum all crime incidents (total and per crime type) occurring in 2014 and in 2015 within the census tract. We opt for crime counts and not crime rates (which are crime counts normalized by the census population), as we like to show the explicit effect of both the resident population (as recorded by census) and of the ambient population (as recorded by the different proxies) on the raw counts. As a technical remark: we look in the following at points situated {{in the area of}} each census <b>track,</b> <b>buffered</b> by 50 feet (which is half the width of the main Manhattan avenues), to account for potential precision inaccuracies in the different spatial data types and to integrate the crime locations that lie on the bordering streets. The same applies for venues, subway, and pickup/drop-off locations.|$|R
5000|$|... vrCluster by Pixela Labs plugin for Unreal Engine 4 {{that allows}} to launch {{applications}} into stereoscopic multi-screen environments, support VRPN <b>tracking,</b> opengl quad <b>buffer</b> buffer, vsync, gsync and nvswapsync, easely configurable via GUI toolset. Source code available at github - https://github.com/vrCluster/vrCluster ...|$|R
50|$|The {{station has}} one island {{platform}} with two <b>tracks,</b> ending with <b>buffer</b> stops. In former times, these tracks merged {{to enter a}} facility for loading and unloading narrow-gauge trucks with material for and from the construction of dams in the Kurobe River gorge.|$|R
50|$|Another {{important}} TTM {{concept is}} fences. Fences are essentially {{a mechanism to}} manage concurrency between the CPU and the GPU. A fence <b>tracks</b> when a <b>buffer</b> object is no longer used by the GPU, generally to notify any user space process with access to it.|$|R
5000|$|... #Caption: The {{remainder}} of the railway, facing Mezőtúr. Behind the camera is the direction of Túrkeve; also behind the camera is a <b>buffer</b> ending the <b>track.</b> Beyond the <b>buffer</b> {{would have been the}} {{remainder of}} the track to Túrkeve, most of which has been removed.|$|R
50|$|After the {{building}} of the Berlin Wall on 13 August 1961, no trains ran to the south from Lichtenrade and the station became a terminus. The level crossing barriers were dismantled, but the access tunnel retained its function. The two <b>tracks</b> ended at <b>buffer</b> stops in front of Bahnhofstrasse. The Lrd signalbox at the northern end of the station was shut down in 1977-78 and only one platform track was used from then on.|$|R
40|$|Wetlands harbor an {{important}} compliment of regional plant diversity, {{but in many}} regions data on wetland diversity and composition is still lacking, thus hindering {{our understanding of the}} processes that control it. While patterns of broad-scale terrestrial diversity and composition typically correlate with contemporary climate it is not clear to what extent patterns in wetlands are complimentary, or conflicting. To elucidate this, we consolidate data from wetland forest inventories in Brazil and examine patterns of diversity and composition along temperature and rainfall gradients spanning five biomes. We collated 196 floristic inventories covering an area > 220 ha and including > 260, 000 woody individuals. We detected a total of 2, 453 tree species, with the Amazon alone accounting for nearly half. Compositional patterns indicated differences in freshwater wetland floras among Brazilian biomes, although biomes with drier, more seasonal climates tended to have a larger proportion of more widely distributed species. Maximal alpha diversity increased with annual temperature, rainfall, and decreasing seasonality, patterns broadly consistent with upland vegetation communities. However, alpha diversity-climate relationships were only revealed at higher diversity values associated with the uppermost quantiles, and in most sites diversity varied irrespective of climate. Likewise, mean biome-level differences in alpha-diversity were unexpectedly modest, even in comparisons of savanna-area wetlands to those of nearby forested regions. We describe attenuated wetland climate-diversity relationships as a shifting balance of local and regional effects on species recruitment. Locally, excessive waterlogging strongly filters species able to colonize from regional pools. On the other hand, increased water availability can accommodate a rich community of drought-sensitive immigrant species that are able to <b>track</b> <b>buffered</b> wetland microclimates. We argue that environmental conditions in many wetlands are not homogeneous with respect to regional climate, and that responses of wetland tree communities to future climate change may lag behind that of non-wetland, terrestrial habitat...|$|R
5000|$|The {{shop was}} {{completely}} destroyed as was a roundabout behind the shop. The train stopped some 40 metres past {{the end of}} the <b>track</b> and the <b>buffer</b> stop. Initial investigation showed that {{the end of the}} track in this location was not marked with a light but only with some unlit signs. Also the (Dutch) train driver was a temporary worker and it might be that he did not know the local situation of the tracks.Circumstances that might have contributed to the accident: ...|$|R
5000|$|This example, as written, {{requires}} that [...] is evenly divisible by {{if it is}} not evenly divisible, [...] produces the wrong buffer index after [...] wraps past [...] back to zero. An alternate solution without this restriction would employ two additional [...] variables to <b>track</b> the current <b>buffer</b> index for the head (producer) and tail (consumer). These [...] variables would be used in place of , and each of them would have to be incremented {{at the same time as}} the respective [...] variable is incremented, as follows: [...]|$|R
40|$|We {{present a}} {{realistic}} and dynamic simulation method {{of the needle}} implantation in brachytherapy. The needle is firstly modeled as a polygon model and then its position and orientation are dynamically and automatically located using a magnetic <b>tracking</b> technology. Two <b>buffers</b> that reserve {{the result of the}} volumetric rendering and geometric rendering are mixed in the context of image-level hybrid volume rendering. Thereafter pre-planning of virtual catheters and the interactive and vivid simulation of needle implantation in brachytherapy are carried out. The realistic enhancement ways such as depth weight, shadow and 3 D cutting view are also proposed in this paper...|$|R
40|$|Abstract — This paper {{investigates the}} {{scenario}} of a robot making a tradeoff between tracking a time-varying reference trajectory and stopping to communicate at points where the radio signal strength is high. Under {{the assumption that}} the signal is subject to multipath fading, we formulate this as a hybrid optimal control problem with penalties on <b>tracking</b> error, communication <b>buffer</b> length and control power. The problem is then solved using relaxed dynamic programming, resulting in control laws for the discrete switching sequence and the continuous control. We finally illustrate the results through simulations under non-ideal conditions, confirming that the system maintains a bounded buffer size and zero-mean tracking error. I...|$|R
50|$|CPorts {{also contain}} state {{variables}} {{that can be}} used to <b>track</b> how much <b>buffer</b> space the peer or connected CPort has. This is used to prevent the situation whereby a CPort sends segments to a CPort which has insufficient buffer space to hold the data, thus leading to stalled data traffic. Unless resolved fast, this traffic jam at the destination quickly grows into a network-wide gridlock. This is highly undesirable as it can greatly affect network performance for all users or, worse, can lead to deadlock situations. The described L4 mechanism is known as end-to-end flow control (E2E FC) because it involves the endpoints of a connection.|$|R
40|$|Security {{vulnerabilities}} often {{result from}} buffer overflows. A testing technique that instruments programs with code that keeps <b>track</b> of memory <b>buffers,</b> and checks arguments to functions {{to determine if}} they satisfy certain conditions, warns when a buffer overflow may occur. It does so when executed with "normal" test data as opposed to test data designed to trigger buffer overflows. A tool using this method was developed and evaluated by testing three widely used, open source software packages. This evaluation shows that the tool is useful for finding buffer overflow flaws, that it has a low false positive rate, and compares well with other techniques...|$|R
50|$|The Isar Valley Railway opened from Thalkirchen to Ebenhausen on 10 June 1891 {{and it was}} {{extended}} to Wolfratshausen on 27 July. From the beginning there was a railway station in Ebenhausen, which {{was known as the}} Isartalbahnhof (station of the Valley Railway Railway) because it was served by trains running on the Valley Railway Railway. The station had three tracks at the opening of line. In addition, two <b>tracks</b> running to <b>buffer</b> stops also existed, which were designed primarily for freight. The station building was built in the renaissance revival style and it is now a listed building. The building has of pavilions on both sides, which are connected by a waiting room.|$|R
40|$|This paper {{investigates the}} {{scenario}} of a robot making a tradeoff between tracking a time-varying reference trajectory and stopping to communicate at points where the radio signal strength is high. Under {{the assumption that}} the signal is subject to multipath fading, we formulate this as a hybrid optimal control problem with penalties on <b>tracking</b> error, communication <b>buffer</b> length and control power. The problem is then solved using relaxed dynamic programming, resulting in control laws for the discrete switching sequence and the continuous control. We finally illustrate the results through simulations under non-ideal conditions, confirming that the system maintains a bounded buffer size and zero-mean tracking error. © 2008 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works. QC 2011011...|$|R
40|$|Phase change memory (PCM) is a {{promising}} technology that can offer higher capacity than DRAM. Unfortunately, PCM 2 ̆ 7 s access latency and energy {{are higher than}} DRAM 2 ̆ 7 s and its endurance is lower. Many DRAM-PCM hybrid memory systems use DRAM as a cache to PCM, to achieve the low access latency and energy, and high endurance of DRAM, while taking advantage of PCM 2 ̆ 7 s large capacity. A key question is what data to cache in DRAM to best exploit the advantages of each technology while avoiding its disadvantages as much as possible. We propose a new caching policy that improveshybrid memory performance and energy efficiency. Our observation is that both DRAM and PCM banks employ row buffers that act as a cache for the most recently accessed memory row. Accesses that are row buffer hits incur similar latencies (and energy consumption) in DRAM and PCM, whereas accesses that are row buffer misses incur longer latencies (and higher energy consumption) in PCM. To exploit this, we devise a policy that avoids accessing in PCM data that frequently causes row buffermisses because such accesses are costly {{in terms of both}} latency and energy. Our policy <b>tracks</b> therow <b>buffer</b> miss counts of recently used rows in PCM, and caches in DRAM the rows that are predicted to incur frequent row buffer misses. Our proposed caching policy also takes into account the high write latencies of PCM, in addition to row buffer locality. Compared to a conventional DRAM-PCM hybridmemory system, our row buffer locality-aware caching policy improves system performance by 14...|$|R
40|$|Railway buffers {{during the}} {{operation}} are staying in almost permanent contact with each other, creating friction node in {{the point of}} contact of two railway buffer heads. In consequence of overcoming track curves, turnouts and unevenness of <b>track,</b> the railway <b>buffer</b> heads moves relative to each other causing friction, which results in its wear. When the wear is excessive, {{it might be a}} reason to withdrawn vehicle from service, it causes flattening of buffer head, and in consequence its abnormal cooperation. To avoid this phenomenon the buffer heads should be covered with graphitized grease, but this method has many disadvantages. Accordingly, it was found that it would be beneficial to cover the buffer head with bronze using laser cladding. In this article the metallographic and mechanical analysis of the newly created top layer of railway buffer head are presented. In article the results from tribological tests conducted on Amsler test bench are also presented. Based on test results described in article concluded that the layer of bronze coat on working surface of railway buffer head can be beneficial from operational point of view...|$|R
40|$|A biofuel cell {{electrochemical}} {{system based}} on the oxidation of glucose by glucose oxidase has been developed. The glucose oxidase was immobilised at the electrode surface by a cast Nafion polymer membrane neutralised and modified by tetrabutylammonium bromide to stabilise the membrane. Electrochemical communication with the electrode was established with ferrocene derivatives in solution or co-cast with the Nafion. The individual and combined properties {{of the components of}} the system were investigated to select the best components to create a biofuel cell. After establishing a functioning biofuel cell a scale-up procedure was followed in which the chemical system was transferred to higher area electrodes. A laboratory prototype biofuel cell was designed and used to test larger 3 -d electrode materials. Before use as an electrochemical reactor the flow properties of the test cell and electrodes were investigated by pulse injections of concentrated <b>buffer</b> <b>tracked</b> with an inline conductivity probe. The biofuel cell generated a steady state power density of up to 50 ?W cm- 2 superficial area at a graphite plate electrode or 6 ?W cm- 2 (actual surface basis) at a reticulated vitreous carbon electrode. The test cell demonstrated high cell potentials for a biofuel cell based on a single enzyme electrode and gave a stable output for several days...|$|R
40|$|A high-concurrency {{transactional}} memory (TM) implementation {{needs to}} <b>track</b> concurrent accesses, <b>buffer</b> speculative updates, and manage conflicts. We present a system, FlexTM (FLEXible Transactional Memory), that coordinates four decoupled hardware mechanisms: {{read and write}} signatures, which summarize per-thread access sets; per-thread conflict summary tables (CSTs), which identify the threads with which conflicts have occurred; Programmable Data Isolation, which maintains speculative updates in the local cache and employs a thread-private buffer (in virtual memory) in the rare event of overflow; and Alert-On-Update, which selectively notifies threads about coherence events. All mechanisms are softwareaccessible, to enable virtualization and to support transactions of arbitrary length. FlexTM allows software to determine when to manage conflicts (either eagerly or lazily), and to employ a variety of conflict management and commit protocols. We describe an STM-inspired protocol that uses CSTs to manage conflicts in a distributed manner (no global arbitration) and allows parallel commits. In experiments with a prototype on Simics/GEMS, FlexTM exhibits ∼ 5 × speedup over high-quality software TM, with no loss in policy flexibility. Its distributed commit protocol is also more efficient than a central hardware manager. Our results highlight the importance of flexibility in determining when to manage conflicts: lazy maximizes concurrency and helps to ensure forward progress while eager provides better overall utilization in a multi-programmed system. ...|$|R
40|$|Abstract We {{consider}} the online scheduling problem for sorting buffers {{on a line}} metric. Thisproblem is motivated by an application to disc scheduling. The input to this problem is a sequence of requests. Each request is a block of data to be written on a specified trackof the disc. The disc is modeled {{as a number of}} tracks arranged on a line. To write a block on a particular track, the scheduler has to bring the disc head to that track. The cost of moving the disc head from a track to another is the distance between those <b>tracks.</b> A sorting <b>buffer</b> that can store at most k requests at a time is available to thescheduler. This buffer can be used to rearrange the input sequence. The objective is to minimize the total cost of head movement while serving the requests. On a disc with n uniformly-spaced tracks, we give a randomized online algorithm with a competitiveratio of O(log 2 n) in expectation against an oblivious adversary. This algorithm alsoyields a competitive ratio of O(ff- 1 log 2 n) if we are allowed to use a buffer of size ffkfor any 1 < = ff < = log n. This is the first non-trivial approximation for the sorting buffersproblem on a line metric. Our technique is based on probabilistically embedding th...|$|R
40|$|A high-concurrency Transactional memory (TM) {{implementation}} {{needs to}} <b>track</b> concurrent accesses, <b>buffer</b> speculative updates, and manage conflicts. We {{propose that the}} requisite hardware mechanisms be decoupled from one another. Decoupling (a) simplifies hardware development, by allowing mechanisms to be developed independently; (b) enables software to manage these mechanisms and control policy (e. g., conflict management strategy and laziness of conflict detection); and (c) {{makes it easier to}} use the hardware for purposes other than TM. We present a system, FlexTM (FLEXible Transactional Memory), that employs three decoupled hardware mechanisms: read and write signatures, which summarize per-thread access sets; per-thread conflict summary tables, which identify the threads with which conflicts have occurred; and a lazy versioning mechanism, which maintains the speculative updates in the local cache and employs a thread-private buffer (in virtual memory) only in the rare event of an overflow. The conflict summary tables allow lazy conflict management to occur locally, with no global arbitration (they also support eager management). All three mechanisms are kept software-accessible, to enable virtualization and to support transactions of arbitrary length. In experiments with a prototype on the Simics/GEMS testbed, FlexTM provides a 5 × speedup over high-quality software TM, with no loss in policy flexibility. Our analysis highlights the importance of lazy conflict detection, which maximizes concurrency and helps to ensure forward progress. Eager detection provides better overall system utilization in a mixed-programming environment. We also present a preliminary case study in which FlexTM components aid {{in the development of a}} tool to detect memory-related bugs. ...|$|R
40|$|We {{consider}} the online scheduling problem for sorting buffers {{on a line}} metric. This problem is motivated by an application to disc scheduling. The input to this problem is a sequence of requests. Each request is a block of data to be written on a specified track of the disc. The disc is modeled {{as a number of}} tracks arranged on a line. To write a block on a particular track, the scheduler has to bring the disc head to that track. The cost of moving the disc head from a track to another is the distance between those <b>tracks.</b> A sorting <b>buffer</b> that can store at most k requests at a time is available to the scheduler. This buffer can be used to rearrange the input sequence. The objective is to minimize the total cost of head movement while serving the requests. On a disc with n uniformly-spaced tracks, we give a randomized online algorithm with a competitive ratio of O(log 3 n) in expectation against an oblivious adversary. This algorithm also yields a competitive ratio of O(α − 1 log 3 n) if we are allowed to use a buffer of size αk for any 1 ≤ α ≤ log n. This is the first non-trivial approximation for the sorting buffers problem on a line metric. Our technique is based on probabilistically embedding the line metric into hierarchically well-separated trees. We show that any deterministic strategy which makes scheduling decisions based only on the contents of the buffer has a competitive ratio of Ω(k). Category: Algorithms and Data Structures. ...|$|R
40|$|Abstract—Phase change memory (PCM) is a {{promising}} technology that can offer higher capacity than DRAM. Unfortunately, PCM’s access latency and energy {{are higher than}} DRAM’s and its endurance is lower. Many DRAM-PCM hybrid memory systems use DRAM as a cache to PCM, to achieve the low access latency and energy, and high endurance of DRAM, while taking advantage of PCM’s large capacity. A key question is what data to cache in DRAM to best exploit the advantages of each technology while avoiding its disadvantages as much as possible. We propose a new caching policy that improves hybrid memory performance and energy efficiency. Our observation is that both DRAM and PCM banks employ row buffers that act as a cache for the most recently accessed memory row. Accesses that are row buffer hits incur similar latencies (and energy consumption) in DRAM and PCM, whereas accesses that are row buffer misses incur longer latencies (and higher energy consumption) in PCM. To exploit this, we devise a policy that avoids accessing in PCM data that frequently causes row buffer misses because such accesses are costly {{in terms of both}} latency and energy. Our policy <b>tracks</b> the row <b>buffer</b> miss counts of recently used rows in PCM, and caches in DRAM the rows that are predicted to incur frequent row buffer misses. Our proposed caching policy also takes into account the high write latencies of PCM, in addition to row buffer locality. Compared to a conventional DRAM-PCM hybrid memory system, our row buffer locality-aware caching policy improves system performance by 14 % and energy efficiency by 10 % on data-intensive server and cloud-type workloads. The proposed policy achieves 31 % performance gain over an all-PCM memory system, and comes within 29 % of the performance of an all-DRAM memory system (not taking PCM’s capacity benefit into account) on evaluated workloads. I...|$|R
40|$|The routing {{architecture}} of an FPGA {{consists of the}} length of the wires, the type of switch used to connect wires (buffered, unbuffered, fast or slow) and the topology of the interconnection of the switches and wires. FPGA Routing architecture has a major influence on the logic density and speed of FPGA devices. Previous work [1] based on a 0. 35 um CMOS process has suggested that an architecture consisting of length 4 wires (where the length of a wire is measured {{in terms of the number}} of logic blocks it passes before being switched) and half of the programmable switches are active buffers, and half are pass transistors. In that work, however, the topology of the routing architecture prevented <b>buffered</b> <b>tracks</b> from connecting to pass-transistor tracks. This restriction prevents the creation of interconnection trees for high fanout nets that have a mixture of buffers and pass transistors. Electrical simulations suggest that connections closer to the leaves on interconnection trees are faster using pass transistors, but it is essential to buffer closer to the source. This latter effect is well known in regular ASIC routing [2]. In this work we propose a new routing architecture that allows liberal switching between buffered and pass transistor tracks. We explore various versions of the architecture to determine the density-speed trade-off. We show that one version of the new architecture results in FPGAs with 10 % faster critical path delay yet uses the same area than the previous architecture that does not allow such switching. We also show that the new architecture allows a useful area-speed trade off and several versions of the new architecture result in FPGAs with 8 % gain in area-delay product than the previous architecture that does not allow the switching. ...|$|R
5000|$|Prien {{station was}} opened on 7 May 1860 {{with the opening}} of the line from Rosenheim to Traunstein, which was {{extended}} to Salzburg on 1 August 1860. After the commissioning of the station, Prien was only a small town. On 18 August 1878 the station became a railway junction {{with the opening of}} the secondary railway (Vizinalbahn) to Aschau (the Chiemgau Railway). At the same time the station’s tracks were rebuilt. The station now had six tracks and three platforms: a bay platform, a through track next to the [...] "home" [...] platform (Hausbahnsteig, that is next to the station building), two through tracks on either side of an island platform and two freight tracks. In addition, there were a local freight facility with a loading track connecting towards Salzburg, a wagon turntable and two <b>tracks</b> ending at <b>buffers.</b> On 9 July 1887, the Chiemsee Railway was opened from Prien am Chiemsee to Prien-Stock on the edge of the lake, Chiemsee. In the following years traffic to the station grew because of the construction of the new Herrenchiemsee palace, which was completed in 1885. A signal box was built in 1891 and the first interlocking was installed in 1892. The mechanical interlocking was completed on 4 February 1899; already another signal box and a controlling signal box had been opened in the station building. Platform canopies, a separate station for Chiemsee Railway on the east side of the station and a platform underpass were built from 1909 to 1911. Deutsche Bundesbahn stationed a locomotive of class 323 in Prien for local freight traffic after the Second World War. Deutsche Bundesbahn replaced the mechanical interlocking with a relay interlocking on 20 March 1963 for 552,000 Deutsche Mark. The section of track maintained by the office of the track master (Bahnmeisterei) was extended on 31 May 1968 so that the Bahnmeisterei in Bad Endorf could close. In 1976, the station lost the class 323 locomotive, which was transferred to the Rosenheim depot. On 1 May 1979, the Prien Bahnmeisterei was closed and its section of line was taken over by the Rosenheim Bahnmeisterei. The station’s name was changed from Prien to Prien am Chiemsee on 27 May 1990 and the local freight facility was closed on 1 June 1997. The station’s signals have been remotely controlled from the Rosenheim electronic signal box since 3 November 2003. A travel centre was opened in the station building on 19 December 2007.|$|R
40|$|Cooking is an {{integral}} part of each and every human being as food is one of the basic necessities for living. Commonly used sources of energy for cooking are firewood, crop residue, cow dung, kerosene, electricity, liqueﬁed petroleum gas(LPG), biogas etc. Half of the world’s population is exposed to indoor air pollution, mainly the result of burning solid fuels for cooking and heating. Wood cut for cooking purpose contributes tothe 16 million hectares(above 4 % of total area of India) of forest destroyed annually. The World Health Organization(WHO) reports that in 23 countries 10 % of deaths are due to just two environmental risk factors: unsafe water, including poor sanitation and hygiene; and indoor air pollution due to solid fuel usage for cooking. In under-developed countries, women have to walk 2 kms on average and spend significant amount of time for collecting the firewood for cooking. The cooking energy demand in rural areas of developing countries is largely met with bio-fuels such as fuel wood, charcoal, agricultural residues and dung cakes, whereas LPG or electricity is predominantly used in urban areas. India has abandon amount of solar energy in most of the regions making it most ideal place for harvesting solar energy. With almost 300 sunny days each year, one can confidently relay on this source of energy. India’s geographical location is in such a way that theoretically it receives 5 x 1015 kWh/ year of solar energy. Solar cooking is the simplest, safest, environmental friendly and most convenient way to cook. It is a blessing for those who cook using firewood or cow dung, who walk for miles to collect wood, who suffer from indoor air pollution. Hence solar cooking is going to play major role in solving future energy problem. Solar based cooking has never been a strong contender in the commercial market or even close to being a preferred method of cooking. They have been relegated to demonstration appliances to show case the solar based concepts. In this mode, cooking is no longer a time independent activity that can be performed at any time of day. One is forced to cook only at certain times when there is sufficient insolation. The geography of the cooking activity also shifts away from the kitchen. The kitchen is no longer the hearth of the home as the actual cooking activity shifts to the roof tops or high insolation platforms. This further adds to the inconvenience apart from being unable to cook at night or during cloudy conditions or during most of the winter days. Another issue of significant inconvenience is the general social structure in most families of the developing countries wherein the cooking activity is carried out by the senior ladies of the home. They are generally not athletic enough to be moving to and from the kitchen and the roof top to carry out the cooking exercise. As the solar cookers are enclosed spaces, interactive cooking is not possible let alone having any control on the rate of cooking. These are some of the more significant issues in the social psyche that has abundantly impeded the acceptance of solar thermal based cooking appliances. These issues and problems are in fact the motivating factors for this thesis. Based on these motivating factors, this thesis aims to propose solutions keeping the following points as the major constraints. cooking should be performed in the kitchen. one should be able to perform the cooking activity independent of the time of day or insolation. the cooking activity should be interactive the time taken for cooking should be comparable with the conventional methods in vogue. there should be a reduction in the use of conventional energy. Using the constraints and the motivating factors discussed above as the central theme, this thesis proposes a method to transfer solar thermal energy to the kitchen and act as a supplement to the conventional source of energy like the LPG or other sources that are traditionally being used in the households. The method proposed is in fact a hybrid scenario wherein the solar thermal is used to supplement the traditional source. Solar photovoltaic cells are also used to power the electronics and apparatus proposed in this thesis. This thesis addresses in detail the issues in analysis, modeling, designing and fabrication of the proposed hybrid solar cooking topology. The main goal of the proposed system is to transfer heat from sun to the cooking load that is located in the kitchen. The topology includes an additional feature for storing the energy in a buffer. The heat is first transferred from the solar thermal collector to a heat storage tank(that acts as the buffer) by circulating the heat transfer fluid at a specific flow rate that is controlled by a pump. The stored heat energy that is collected in the buffer is directed into the kitchen by circulating the heat transfer fluid into the heat exchanger, located in the kitchen. This is accomplished by controlling the flow rate using another pump. The solar thermal collector raises the temperature of the thermic fluid. The collector can be of a concentrating type in order to attain high temperatures for cooking. Concentrating collector like linear parabolic collector or parabolic dish collector is used to convert solar energy into heat energy. Absorption of energy from the incident solar insolation is optimized by varying the flow rate of circulating thermic fluid using a pump. This pump is energized from a set of photovoltaic panels(PV cell) which convert solar energy into electrical energy. The energy absorbed from the solar thermal collector is stored in a buffer tank which is thermally insulated. Whenever cooking has to be carried out, the high temperature fluid from the buffer tank is circulated through a heat exchanger that is located in the kitchen. The rate of cooking can be varied by controlling both the flow rate of fluid from the buffer tank to heat exchanger and also by controlling the amount of energy drawn from the auxiliary source. If the available stored energy is not sufficient, the auxiliary source of energy is used for cooking in order to ensure that cooking is in-dependent of time and solar insolation. In the proposed hybrid solar cooking system, the thesis addresses the issues involved in optimization of energy extracted from sun to storage tank and its subsequent transfer from the storage tank to the load. The flow rate at which maximum energy is extracted from sun depends on many parameters. Solar insolation is one of the predominant parameters that affect the optimum flow rate. Insolation at any location varies with time on a daily basis (diurnal variations) and also with day on a yearly basis(seasonal variation). This implies that the flow rate of the fluid has to be varied appropriately to maximize the energy absorbed from sun. In the proposed system, flow rate control plays a very significant role in maximizing the energy transfer from the collector to the load. The flow rate of the thermic fluid in the proposed system is very small on the order of 0. 02 kg/s. It is very difficult to sense such low flows without disrupting the operating point of the system. Though there are many techniques to measure very low flow rates, they invariably disrupt the system in which flow rate has to be measured. Further, the low flow sensors are far too expensive to be included in the system. A reliable, accurate and inexpensive flow measuring technique has been proposed in this thesis which is non-disruptive and uses a null-deflection technique. The proposed measuring method compensates the pressure drop across the flow meter using a compensating pump. The analysis, modeling, design and fabrication of this novel flow meter are addressed. The design and implementation of different subsystems that involves the selection and design of solar concentrating collector and tracking are explained. Finally, it is essential to know the economic viability of the proposed system that is designed and implemented. To understand the economics, the life cycle cost analysis of the proposed system is presented in this thesis. The major contributions of this thesis are: Energy transport: Major challenge in energy transport is to bring heat energy obtained from the sun to the kitchen for cooking. Energy transferred from solar insolation to the cooking load has to be optimized to maximize the overall efficiency. This can be split in to two parts,(a) optimizing efficiency of energy transferred from the collect or to the energy buffer tank,(b) optimizing efficiency of energy transferred from the buffer tank to the load. The optimization is performed by means of a maximum power point tracking(MPPT) algorithm for a specific performance index. Modeling of the cooking system: There are several domains that exist in the solar cooking system such as electrical domain, thermal domain, and hydraulic domain. The analysis of power/energy flow across all these domains presents a challenging task in developing a model of the hybrid cooking system. A bond graph modeling approach is used for developing the mathematical model of the proposed hybrid cooking system. The power/energy flow across different domains can be seamlessly integrated using the bond graph modeling approach. In this approach, the various physical variables in the multi-domain environment are uniformly de-fined as generalized power variables such as effort and flow. The fundamental principle of conservation of power/energy issued in describing the flow of power/energy across different domains and thus constructing the dynamic model of the cooking system. This model is validated through experimentation and simulation. Flow measurement: A novel method of low fluid mass flow measurement by compensating the pressure drop across the ends of measuring unit using a compensating pump has been proposed. The pressure drop due to flow is balanced by feedback control loop. This is a null-deflection type of measurement. As insertion of such a measuring unit does not affect the functioning of the systems, this is also a non-disruptive flow measurement method. This allows the measurement of very low flow rate at very low resolution. Implementation and design of such a unit are discussed. The system is modeled using bond graph technique and then simulated. The flow meter is fabricated and the model is experimentally validated. Design Toolbox: Design of hybrid cooking system involves design of multi domain systems. The design becomes much more complex if the energy source to operate the system is hybrid solar based. The energy budget has to be evaluated considering the worst case conditions for the availability of the solar energy. The design toolbox helps in assessing the user requirement and help designing the cooking system to fulfill the user requirement. A detailed toolbox is proposed to be developed that can be used in designing/selecting sub-systems like collector, concentrator, <b>tracking</b> system, <b>buffer</b> tank, heat exchanger, PV panel, batteries etc. The toolbox can also be used for performing life cycle costing...|$|R

