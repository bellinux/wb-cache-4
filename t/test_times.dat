319|10000|Public
2500|$|Initially, thrombelastography {{was simply}} {{performed}} with whole blood without adding reagents (except calcium when citrate anticoagulated blood was used). This provides a global overview about {{all phases of}} clot formation, stabilization and degradation. In the case of monocausal haemostasis disorders, the resulting reaction curves may be quite typical; however, under most clinical conditions this approach has severe limitations. In reality various effects overlap, including haemodilution or application of high doses of parenteral anticoagulants. High doses of heparin often prevent clot formation at all. Absence of a controlled activation step leads to inferior reproducibility and very long <b>test</b> <b>times</b> which are not acceptable for POC applications.|$|E
2500|$|Most glucometers today use an {{electrochemical}} method. Test strips {{contain a}} capillary that sucks up a reproducible amount of blood. The glucose {{in the blood}} reacts with an enzyme electrode containing glucose oxidase (or dehydrogenase). The enzyme is reoxidized with an excess of a mediator reagent, such as a ferricyanide ion, a ferrocene derivative or osmium bipyridyl complex. The mediator in turn is reoxidized by reaction at the electrode, which generates an electric current. [...] The total charge passing through the electrode {{is proportional to the}} amount of glucose in the blood that has reacted with the enzyme. The coulometric method is a technique where the total amount of charge generated by the glucose oxidation reaction is measured over a period of time. The amperometric method is used by some meters and measures the electric current generated at a specific point in time by the glucose reaction. This is analogous to throwing a ball and using the speed at which it is travelling at a point in time to estimate how hard it was thrown. The coulometric method can allow for variable <b>test</b> <b>times,</b> whereas the test time on [...] a meter using the amperometric method is always fixed. Both methods give an estimation of the concentration of glucose in the initial blood sample.|$|E
2500|$|The {{magnitude}} and capacity {{of these systems}} makes the Ames Arc Jet Complex unique in the world. The largest power supply can deliver 75 megawatts (MW) for a 30-minute duration or 150 MW for a 15-second duration. This power capacity, in combination with a high-volume 5-stage steam ejector vacuum-pumping system, enables facility operations to match high-altitude atmospheric flight conditions with samples of relatively large size. The Thermo-Physics Facilities Branch operates four arc jet facilities. The Interaction Heating Facility (IHF), with an available power of over 60-MW, {{is one of the}} highest-power arc jets available. It is a very flexible facility, capable of long run times of up to one hour, and able to test large samples in both a stagnation and flat plate configuration. The Panel Test Facility (PTF) uses a unique semielliptic nozzle for testing panel sections. Powered by a 20-MW arc heater, the PTF can perform tests on samples for up to 20 minutes. The Turbulent Flow Duct provides supersonic, turbulent high temperature air flows over flat surfaces. The TFD is powered by a 20-MW Hüls arc heater and can test samples [...] in size. The Aerodynamic Heating Facility (AHF) has similar characteristics to the IHF arc heater, offering a wide range of operating conditions, samples sizes and extended <b>test</b> <b>times.</b> A cold-air-mixing plenum allows for simulations of ascent or high-speed flight conditions. Catalycity studies using air or nitrogen can be performed in this flexible rig. A 5-arm model support system allows the user to maximize testing efficiency. The AHF can be configured with either a Hüls or segmented arc heater, up to 20-MW. 1 MW is enough power to supply 750 homes.|$|E
40|$|The <b>test</b> <b>time</b> for core-external {{interconnect}} {{shorts and}} opens is typically {{much less than}} that for core-internal logic. Therefore, prior work on test-infrastructure design for core-based system-ona-chip (SOC) has mainly focused on minimizing the <b>test</b> <b>time</b> for core-internal logic. However, as feature sizes shrink for newer process technologies, the <b>test</b> <b>time</b> for signal integrity (SI) faults on interconnects cannot be neglected. The <b>test</b> <b>time</b> for SI faults can be comparable to, or even larger than, the <b>test</b> <b>time</b> for the embedded cores. We investigate the impact of interconnect SI tests on SOC test-architecture design and optimization. A compaction method for SI faults and algorithms for test-architecture optimization are also presented. Experimental results for the ITC’ 02 benchmarks show that the proposed approach can significantly reduce the overall <b>testing</b> <b>time</b> for core-internal logic and core-external interconnects...|$|R
30|$|In general, the {{estimation}} accuracy {{depends on the}} sample size and <b>test</b> <b>time.</b> To improve {{the estimation}} accuracy, more <b>test</b> <b>time</b> is required if the sample size is fixed. To compare {{the efficiency of the}} two plans quantitatively, the <b>test</b> <b>time</b> for the CSALT is elongated to when its variance factor equals that of the proposed plan. Here, 1157  h are obtained. Therefore, the <b>test</b> <b>time</b> could be shortened by 13.59 % if using the PCCSALT plan under the same requirements of estimation accuracy and sample size.|$|R
40|$|Traditional SoC test {{scheduling}} approaches minimize <b>test</b> <b>time</b> under additional constraints. We {{argue that}} test costs are not determined by <b>test</b> <b>time</b> alone. Indeed, {{the speed of}} used ATE channels influences both cost and <b>test</b> <b>time.</b> We present a case for using a mixture of high-speed and low-cost ATE channels. Two heuristics and an exact algorithm are proposed. Experimental results show that such a mixture scenario can reduce the cost with no impact on <b>test</b> <b>time.</b> Keywords: System-on-Chip <b>test,</b> Automatic test equipment, test economic...|$|R
50|$|This test is {{presented}} three times every year, the <b>test</b> <b>times</b> {{are on the}} center's website.|$|E
50|$|Blood {{fibrinogen}} levels {{of less than}} 0.1 g/L and prolonged bleeding <b>test</b> <b>times</b> are indicators of an individual having afibrogenemia.|$|E
50|$|Tunnels {{such as a}} Ludwieg tube have short <b>test</b> <b>times</b> (usually {{less than}} one second), {{relatively}} high Reynolds number, and low power requirements.|$|E
40|$|The <b>testing</b> <b>time</b> for a system-on-chip(SOC) largely {{depends on}} the design of test {{wrappers}} and the test access mechanism(TAM). Wrapper/TAM co-optimization is therefore necessary to minimize SOC <b>testing</b> <b>time.</b> In this paper, we propose an efficient algorithm to construct wrappers that reduce <b>testing</b> <b>time</b> for cores. We further propose a new approach for wrapper/TAM co-optimization based on two-dimensional rectangle packing. This approach considers the diagonal length of the rectangles to emphasize on both TAM widths required by a core and its corresponding <b>testing</b> <b>time.</b> Comment: 4 pages, 6 figures, 2 table...|$|R
50|$|Usually, the fab {{charges for}} <b>testing</b> <b>time,</b> with {{prices in the}} order of cents per second. <b>Testing</b> <b>times</b> vary from a few {{milliseconds}} to a couple of seconds, and the test software is optimized for reduced <b>testing</b> <b>time.</b> Multiple chip (multi-site) testing is also possible, because many testers have the resources to perform most or all of the tests in parallel.|$|R
40|$|Abstract—We {{propose a}} method of {{minimizing}} the <b>test</b> <b>time</b> for an SoCs (system-on-chip) with a given power budget by the test clock frequency for each test session. Since frequency {{is proportional to the}} <b>test</b> <b>time</b> and the power dissipated, by controlling the test clock frequency, the power dissipated and the <b>test</b> <b>time</b> per session can be adjusted so as to yield an optimal solution to the test scheduling problem. To achieve this, we modify the existing ILP (Integer-Linear Program) model for optimal test scheduling to include a variable frequency parameter which, in turn, controls the <b>test</b> <b>time</b> and power. For the optimization, we have used an open-source ILP solver. Results indicate that, executing individual cores (tests) per session at their maximum frequency of operation, such that their test power is same as the power budget, yields the most optimal <b>test</b> <b>time</b> for the SoC. We also prove that this solution is the lower bound on the optimal <b>test</b> <b>time,</b> for the SoC considered. I...|$|R
5000|$|... #Caption: Four {{generations of}} blood glucose meter, c. 1991-2005. Sample sizes vary from 30 to 0.3 &mu;l. <b>Test</b> <b>times</b> vary from 5 seconds to 2 minutes (modern meters are {{typically}} below 15 seconds).|$|E
5000|$|Apply VLF to XLPE cables in a {{monitored}} withstand approach where {{a diagnostic}} measurement is made {{before and during}} the course of the withstand test. Monitoring a diagnostic enables some additional decision making before the final test voltage is reached. Some cables are not good candidates for withstand testing and a diagnostic indication obtained at a lower voltage can negate the need to perform withstand testing. During the test measurement of a diagnostic parameter can be used to optimise <b>test</b> <b>times.</b> <b>Test</b> <b>times</b> can be shortened for cables with good diagnostic indications or lengthened for cables that show deteriorating diagnostic measurements during the test.|$|E
50|$|RF signal {{generators}} are available as benchtop instruments, rackmount instruments, embeddable modules and in card-level formats. Mobile, field-testing and airborne applications benefit from lighter, battery-operated platforms. In automated and production testing, web-browser access, which allows multi-source control, and faster frequency switching speeds improve <b>test</b> <b>times</b> and throughput.|$|E
40|$|Abstract Power {{dissipated}} during test is a constraint when {{it comes}} to <b>test</b> <b>time</b> reduction. In this work, we show that for a given test the minimum <b>test</b> application <b>time</b> is achieved when the total energy is dissipated evenly at the rate of the maximum allowable power for the device under test. This result, the <b>test</b> <b>time</b> theorem, leads to two alternatives for reducing <b>test</b> <b>time.</b> In the first alternative, we scale the supply voltage down to reduce power, which in turn allows us to increase the clock frequency, of course within the limit imposed by the critical path. Thus, optimum voltage and frequency can be found to minimize the <b>test</b> <b>time</b> of a fixed frequency synchronous test. In the other alternative, which also benefits from the reduced voltage, the clock period is dynamically varied so that each cycle dissipates the maximum allowable power. This test, termed aperiodic clock test, according to the theorem achieves the lower bound on <b>test</b> <b>time.</b> An illustrative example of an ISCAS’ 89 benchmark circuit shows a <b>test</b> <b>time</b> reduction of 71 %...|$|R
40|$|Abstract—This paper proposes an {{improved}} method of back-ground calibration that reduces production <b>testing</b> <b>time</b> of mixed-signal ICs. Production <b>testing</b> <b>time</b> typically consists of “calibra-tion convergence time ” + “functional <b>testing</b> <b>time</b> after calibration convergence”. The method that is proposed here reduces average calibration convergence time. This method {{does not require}} extra ADC operation for functional testing after calibration convergence, and can be implemented with little additional on-chip test-support circuitry when testing is performed by ATE (Automatic Test Equipment). As an application of this method, we discuss background calibration of pipelined ADCs and present simulation results that demonstrate its effectiveness in reducing <b>testing</b> <b>time...</b>|$|R
40|$|Abstract—We {{dynamically}} monitor per cycle scan {{activity to}} speed up the scan clock for low activity cycles without exceeding the specified peak power budget. The activity monitor is implemented as on-chip hardware. Two models, one for test sets with peak activity factor of 1 and the other for test sets with peak activity factor lower than 1 have been proposed. In test sets with peak activity factors of 1, the <b>test</b> <b>time</b> reduction accomplished depends upon an average activity factor of αin. For low αin, about 50 % <b>test</b> <b>time</b> reduction is analytically shown. With moderate activity, αin = 0. 5, simulated test data gives about 25 % <b>test</b> <b>time</b> reduction for ITC 02 benchmarks. BIST with dynamic clock showed about 19 % <b>test</b> <b>time</b> reduction for the largest ISCAS 89 circuits in which the hardware activity monitor and scan clock control required about 2 - 3 % hardware overhead. In test sets with peak activity factors lower than 1, the <b>test</b> <b>time</b> reduction depends on an input activity factor of αin and an output activity factor of αout. For low αin and high αout, a <b>test</b> <b>time</b> reduction of about 50 % is analytically shown. Index Terms—Scan <b>test,</b> <b>test</b> <b>time</b> reduction, <b>test</b> power, onchip activity monitor, adaptive test clock, activity factor, BIST I...|$|R
50|$|The {{parallel}} {{parametric test}} is an emerging strategy for wafer-level parametric testing that involves concurrent execution of multiple tests on multiple scribe line test structures. If {{offers the potential}} for increasing test throughput with existing test hardware, in response to market pressure on fabs to minimize <b>test</b> <b>times.</b> The figure illustrates {{the differences in the}} amount of time required to complete tests sequentially as compared to the same tests in parallel.|$|E
50|$|In human memory research, {{concurrent}} overlap, or task appropriate processing, {{is a type}} {{of processing}} overlap between an activity engaged in before the prospective memory is to be remembered and a cue that directs attention towards the prospective memory. It is prospective memory specific and is distinct from sequential overlap, or transfer-appropriate processing, which occurs in both retrospective and prospective memory and is defined as the overlap in processing the to-be-remembered memory between planning (or study in retrospective memory) and <b>test</b> <b>times.</b>|$|E
5000|$|In {{addition}} to measurements of rates of chemical kinetics shock tubes {{have been used}} to measure dissociation energies and molecular relaxation rates they have been used in aerodynamic tests. The fluid flow in the driven gas can be used much as a wind tunnel, allowing higher temperatures and pressures therein [...] replicating conditions in the turbine sections of jet engines. However, <b>test</b> <b>times</b> are limited to a few milliseconds, either by the arrival of the contact surface or the reflected shock wave.|$|E
40|$|International Telemetering Conference Proceedings / November 14 - 16, 1978 / Hyatt House Hotel, Los Angeles, CaliforniaThe {{testing of}} {{telemetry}} ground stations by manual methods {{can be very}} <b>time</b> consuming. The <b>test</b> <b>time</b> can be reduced by using an automated test system. A minicomputer controlled test system is described and is shown to provide accurate, repeatable results and to reduce the <b>test</b> <b>time</b> to about one-fifth of the manual <b>test</b> <b>time...</b>|$|R
40|$|This work {{discusses}} {{the role of}} BISTed cores in the <b>test</b> <b>time</b> reduction of NoC-based systems. A previously proposed technique that reuses network-on-chip for test purposes is used to define the optimum number of BISTed cores in the system, considering <b>test</b> <b>time</b> minimization and power consumption requirements. Experimental results show {{that not all of}} the embedded cores must have a self-contained test method to achieve a minimum global system <b>test</b> <b>time...</b>|$|R
40|$|Abstract—Conventionally, testing uses clock with fixed {{period during}} scan shift, which make the tests long. In this work, we propose two methods, scaling supply voltage and scaling frequency, that {{significantly}} reduce <b>test</b> <b>time</b> without increasing the power budget. The proposed methodologies were verified by simulation and through experiments. The experiments were {{carried on the}} Advantest T 2000 ATE. The simulations were performed using ISCAS 89 benchmark circuits and results show up to 70 % reduction in <b>test</b> <b>time.</b> I. POWER CONSTRAINED <b>TEST</b> <b>TIME</b> Theorem. For power constrained testing when the peak power during any clock cycle must not exceed PMAXfunc, the <b>test</b> <b>time</b> (T T) has a lower bound [8]...|$|R
50|$|A {{blow down}} {{facility}} is a testing facility {{that relies on}} charging an energy reservoir (often a tank of pressurized gas) and releasing the energy over {{a relatively short time}} to produce test conditions at higher energy release rates than can be maintained continuously. Impulse facilities are a special case of blow down facilities that release their energy very rapidly to create very high enthalpy conditions over very short <b>test</b> <b>times.</b> Contrasting with blow down facilities are continuous facilities that can operate at a certain conditions continuously, such as some types of wind tunnels.|$|E
50|$|The U.S. Air Force's Arnold Engineering Development Center (AEDC) {{currently}} (in 2010) {{operates the}} Hypervelocity Wind Tunnel 9. This facility, {{known simply as}} Tunnel 9, operates by blowing down hot, high-pressure nitrogen gas through one of several available axially-symmetric 12-meter-long De Laval nozzles, through a test section, and into a downstream vacuum sphere. Operating in the test-section Mach number range of 7 to 16, Tunnel 9 is the highest-pressure wind tunnel in the world. It produces realistic flight Reynolds numbers at hypersonic Mach numbers and beyond, with <b>test</b> <b>times</b> {{on the order of}} one second.|$|E
50|$|A testing {{facility}} {{that relies on}} rapid release of stored energy to generate {{a short period of}} high enthalpy test conditions for testing of aerodynamic flow, aerodynamic heating and atmospheric reentry, combustion, chemical kinetics, ballistics, and other effects. The rapid release of energy can result in very high instantaneous energy release rates even though the total energy released is modest. This effect also produces short <b>test</b> <b>times,</b> however, with some types of tests in these facilities lasting less than 100 microseconds. Impulse facilities are a special case of blow down facilities where an energy storage mechanism is charged {{over a period of time}} and then released to initiate a test and must be charged again before the next test. This contrasts with continuous facilities such as wind tunnels that may run continuously. Examples of impulse facilities are the shock tube, the shock tunnel, the expansion tube, the expansion tunnel, and the Ludwieg tube.|$|E
3000|$|... where Jv is {{the average}} {{permeate}} flux of the membrane [L/(m 2 h)]; Vp is the volume of permeate accumulated in <b>testing</b> <b>time</b> (L); Am is the effective areas of membrane (m 2); t is the <b>testing</b> <b>time</b> (h).|$|R
30|$|Now {{consider}} the case of using “blotched” images at <b>test</b> <b>time</b> (Fig. 8, top). When at least 40 training samples were used, the product of posteriors approach (C_prod) achieved higher accuracy than any other. As more touches were allowed at <b>test</b> <b>time</b> (top centre and right), the touch-only accuracy improved quickly, and the relative gain from multi-modal approaches declined, to the point that only C_prod was visibly superior for the case of 3 touches at <b>test</b> <b>time</b> (top, right).|$|R
40|$|Abstract—We {{dynamically}} monitor per cycle scan {{activity to}} speed up the scan clock for low activity cycles without exceeding the specified peak power budget. The activity monitor is implemented either as on-chip hardware or through presimulated and stored test data. In either case a handshake protocol controls the rate of test data flow between the automatic test equipment (ATE) and device under test (DUT). The <b>test</b> <b>time</b> reduction accomplished depends upon an average activity factor α. For low α, about 50 % <b>test</b> <b>time</b> reduction is analytically shown. With moderate activity, α = 0. 5, simulated test data gives about 25 % <b>test</b> <b>time</b> reduction for ITC 02 benchmarks. For full scan s 38584, the dynamic scan clock control reduced the <b>test</b> <b>time</b> by 19 % when fully specified ATPG vectors were used and by 43 % for vectors with don’t cares. BIST with dynamic clock showed about 19 % <b>test</b> <b>time</b> reduction for the largest ISCAS 89 circuits in which the hardware activity monitor and scan clock control required about 2 - 3 % hardware overhead. Index Terms—Scan <b>test,</b> <b>test</b> <b>time</b> reduction, <b>test</b> power, onchip activity monitor, adaptive test clock I...|$|R
50|$|Initially, thrombelastography {{was simply}} {{performed}} with whole blood without adding reagents (except calcium when citrate anticoagulated blood was used). This provides a global overview about {{all phases of}} clot formation, stabilization and degradation. In the case of monocausal haemostasis disorders, the resulting reaction curves may be quite typical; however, under most clinical conditions this approach has severe limitations. In reality various effects overlap, including haemodilution or application of high doses of parenteral anticoagulants. High doses of heparin often prevent clot formation at all. Absence of a controlled activation step leads to inferior reproducibility and very long <b>test</b> <b>times</b> which are not acceptable for POC applications. The assays for ROTEM analysis help to get a rapid differentiation between various potential haemostasis defects or anticoagulant drug effects and allow for a rapid differential diagnosis. They form the base for selecting a therapeutic strategy. Several diagnostic algorithms have been proposed and were clinically validated. Application of this strategy helps to minimize the exposure of patients to allogeneic blood products which have certain risks; and it saves costs. Numerous research applications have used the technique as well.|$|E
5000|$|Ferrari had {{dominated}} the pre-season tests in Rio with times {{that were not}} only faster than everyone else, but faster than had been recorded at the 1987 Brazilian Grand Prix, prompting rumors that the team had either shut off the FIA's mandatory pop-off valve which in 1988 limited turbo boost pressure to just 2.5 Bar, or more likely were running the 1987 valve which had a 4.0 Bar limit (most of the team engineers agreed that in 1988 the turbo engines had lost approximately [...] due to the reduction in boost). The rumors were renewed during qualifying in Brazil when neither Michele Alboreto nor Gerhard Berger could get near their <b>test</b> <b>times</b> from a month earlier and both drivers complained of engines that were down on power, too thirsty and had poor throttle response out of the slower corners. With the 1988 pop-off valve connected, both Ferraris were also significantly slower on the circuits long back straight than either the McLaren or Lotus Hondas which were all timed at over 290 km/h.|$|E
5000|$|The {{majority}} {{of what is}} understood on the neurological bases of post-hypnotic amnesia stems from an integral study completed by Mendelsohn et al. Two groups of participants viewed a narrative documentary. After one week participants were hypnotized while placed in an fMRI scanner and initiated into a suggestive post-hypnotic amnesia state where {{they were told to}} forget the details of the movie until they received a reversal cue. During scanning, participants were tested twice for their memory on either the movie details or context in which the movie was shown. These two <b>test</b> <b>times</b> allowed for the acquisition of brain activity [...] "maps" [...] during and after post-hypnotic amnesia had been lifted. Unlike in response to the Movie questions, the Context questions for both groups revealed several overlapping networks of activity, including visual, sensory and perceptual regions, the cerebellum, the parietal lobes, the superior frontal gyrus, and the inferior frontal gyrus. The post-hypnotic amnesia group showed reduced memory for the contents of the movie but not for context of viewing. These results identify specific circuits within the brain that regulate the suppression of long-term memory retrieval during post-hypnotic suggestion.|$|E
40|$|Abstract—Reducing test cost by {{minimizing}} the overall <b>test</b> <b>time</b> {{is one of}} the main goals of System-on-Chip (SoC) test scheduling. Power-aware strategies optimize the overall <b>test</b> <b>time</b> of a <b>test</b> schedule for a global peak power budget. For powerconstrained test scheduling with multiple test clock frequencies, a fast heuristic method for sessionless test scheduling is proposed. Experiments on several ITC’ 02 benchmarks show that a <b>test</b> <b>time</b> reduction of 10 - 20 % over optimized conventional session-based test scheduling is possible...|$|R
40|$|In {{this paper}} an {{analysis}} of <b>test</b> <b>time</b> by CBET (which is an acronym for Combination of BIST and External Test) test approach is presented. The analysis validates that CBET test approach can achieve shorter <b>testing</b> <b>time</b> than both external test and BIST in many situations. An efficient <b>test</b> <b>time</b> minimization algorithm for CBET-based LSIs is also proposed. It uses several characteristics of CBET test approach derived by the analysis to reduce computation time to find the optimum test sets...|$|R
40|$|In a Core based SoC design various Intellectual Property (IP) cores are {{integrated}} {{on a single}} chip called System on chip(SoC). The testing of this SoC is complex, resulting in a long <b>test</b> application <b>time.</b> But the <b>testing</b> <b>time</b> cannot be too long as the relevant cost will increase rapidly. The <b>testing</b> <b>time</b> can be minimized if an effective scheduling of the tests is done. This paper presents a test scheduling scheme for a core based SoC. The SoC test scheduling is an NP complete problem and hence this paper presents Genetic algorithm based test scheduling scheme for a core based SoC so as to minimize the <b>testing</b> <b>time</b> incorporating the power dissipation constraints. Genetic algorithm generate solutions to the scheduling problem using techniques inspired by natural evolution. The optimal solution obtained by running genetic algorithm {{is applied to the}} ITC‟ 02 SoC test Benchmarks and provides minimum <b>test</b> <b>time</b> results...|$|R
