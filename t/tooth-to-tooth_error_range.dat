0|2788|Public
40|$|The paper {{comprises}} {{a detailed}} analysis of the <b>error</b> <b>ranges</b> of two commonly proposed load estimation methods for household loads, based on statistics. Firstly, a household load profile model is built taking individual user preference into account. To analyze the <b>error</b> <b>range,</b> it is divided into system error (representing proportion factors) and random error (representing the diversity of stochastic loads and measurement inaccuracies). For both estimation methods, two kinds of bounds are used to evaluate the <b>error</b> <b>range,</b> with central limit theorem. Finally, comparisons between different errors are made using field data from a Dutch utility...|$|R
50|$|LD50 (<b>error</b> <b>ranges</b> not shown): Mouse: 65 mg/kg, i.p.; 900 mg/kg, p.o.|$|R
40|$|Numerical concept {{selection}} {{methods are}} used throughout industry {{to determine which}} among several design alternatives should be further developed. The results, however, are rarely believed at face value. Uncertainties (or errors) in subjective choices, modeling assumptions, and measurement errors are fundamental causes of this disbelief. This paper describes a methodology developed to predict overall final <b>error</b> <b>ranges</b> and to estimate a confidence measure in the numerical evaluation results, based upon assigning <b>error</b> <b>ranges</b> to the individual ratings and weightings. Each numerical assignment is given an associated <b>error</b> <b>range,</b> and then treated as a probability error to create a simple means to propagate the errors into an overall <b>error</b> <b>range</b> on the final rating value. Further, a degree of confidence is derived, similar to a statistical t-test, to indicate an induced confidence level in the final decision. Two preliminary concept selections are shown, to illustrate the methodology. Resu [...] ...|$|R
50|$|B4 = 0.87058 83800 ± 0.00000 00005, the <b>error</b> <b>range</b> {{having a}} 99% {{confidence}} level according to Nicely.|$|R
5000|$|... #Caption: Data from Salt Farm Brochure. Envelopes (yellow) and <b>error</b> <b>ranges</b> (brown) {{have been}} introduced. The scatter is quite high.|$|R
40|$|This study {{describes}} typical <b>error</b> <b>ranges</b> of {{high resolution}} regional climate models operated over complex orography and investigates the scale-dependence of these <b>error</b> <b>ranges.</b> The results are valid {{primarily for the}} European Alpine region, but to some extent {{they can also be}} transferred to other orographically complex regions of the world. We investigate the model errors by evaluating a set of 62 one-year hindcast experiments for the year 1999 with four different regional climate models. The analysis is conducted for the parameters mean sea level pressure, air temperature (mean, minimum and maximum) and precipitation (mean, frequency and intensity), both as an area average over the whole modeled domain (the "Greater Alpine Region", GAR) and in six subregions. The subregional seasonal <b>error</b> <b>ranges,</b> defined as the interval between the 2. 5 th percentile and the 97. 5 th percentile, lie between - 3. 2 and + 2. 0 K for temperature and between - 2. 0 and + 3. 1 mm/day (- 45. 7 and + 94. 7 %) for precipitation, respectively. While the temperature <b>error</b> <b>ranges</b> are hardly broadened at smaller scales, the precipitation <b>error</b> <b>ranges</b> increase by 28 %. These results demonstrate that high resolution RCMs are applicable in relatively small scale climate impact studies with a comparable quality as on well investigated larger scales as far as temperature is concerned. For precipitation, which is a much more demanding parameter, the quality is moderately degraded on smaller scales...|$|R
40|$|Abstract. This {{paper was}} {{developed}} by microwave measurement on the vegetation dielectric constant through using the rectangular-waveguide at C Band. The measurement system and the method of the measurement will be introduced in detail. We have a standard block of known dielectric constant measurement, and then evaluate the <b>error</b> <b>range.</b> The system of measurement <b>error</b> <b>range</b> is ± 5 %. At last, {{the result of this}} experiment showed that different density corresponds to different dielectric constant in the case of certain moisture content, and the dielectric constant increases with the density...|$|R
30|$|Dolphin Imaging’s {{software}} {{was determined to}} be accurate within an <b>error</b> <b>range</b> of +/− 2  mm in the X-axis at most landmarks. The lower lip predictions were most inaccurate.|$|R
30|$|The {{proposed}} algorithm should adequately {{cope with}} {{various kinds of}} map <b>errors</b> <b>ranging</b> from small ones, such as sensing errors, to large ones, such as the transformation of obstacles.|$|R
3000|$|... are the {{opposite}} sign, {{can be provided}} by an occultation observation of the AKR. It {{should be noted that}} these <b>error</b> <b>ranges</b> include the frequency dependence of the wave source.|$|R
3000|$|F 2 and M 3000 F 2, respectively. The model {{results have}} <b>errors</b> <b>ranging</b> from {{approximately}} 8 – 15 %, 9 – 17 %, and 3 – 5 %, respectively, for h [...]...|$|R
30|$|The polynomial-basis {{response}} surface approximation {{is different from}} the real function between cross-sectional area and nodal displacement, relative <b>error</b> <b>ranging</b> from 4.747 % to 23.56 % which does not meet the engineering requirement.|$|R
40|$|In this paper, an {{adaptive}} robust secure null-space projection (NSP) synthesis scheme is proposed for wireless transmission networks with artificial noise (AN) aided directional modulation (DM). This scheme {{is composed of}} three steps: direction of arrival (DOA) and signal-to-noise ratio (SNR) estimation, prediction of <b>error</b> <b>range,</b> and robust secure beamforming. In the first step, the direction angles of desired user and eavesdropping user are found by the Root-MUSIC algorithm, and their SNRs are estimated by {{the ratio of the}} corresponding eigenvalue to minimum eigenvalue. Then, by using the estimated DOA and SNR, the <b>error</b> <b>range</b> is predicted. Finally, those estimated parameters are used to design the robust secure NSP beamforming DM system. Simulation results show that the proposed adaptive robust NSP method performs much better than conventional non-adaptive robust scheme and unrobust NSP one in terms of bit error rate (BER) and secrecy rate (SR). Especially, the BER and SR performance gains of the proposed adaptive robust NSP over conventional methods increase gradually as the DOA <b>error</b> <b>range</b> increases. Comment: 8 pages, 8 figures, articl...|$|R
40|$|Spectral {{observations}} of the stars alpha CMa, gamma Ori, kappa Ori, and alpha Leo have been obtained in the range 1150 to 4000 Angstroms, using rocket borne spectrometers. The payloads have a 13 -inch diameter telescope, a rotatable concave diffraction grating, and three pulse counting photomultiplier photometers. The laboratory standards used as photometric references derive their primary calibration directly or indirectly from the National Bureau of Standards. An <b>error</b> <b>range</b> of up to + or - 10 percent is attributed to these laboratory standards; + or - 8 percent to the calibration procedure; and + or - 10 percent is assigned as an accidental <b>error</b> <b>range...</b>|$|R
3000|$|... dip {{within a}} {{reasonable}} <b>error</b> <b>range</b> for 9 - and 13 -nm NPs, even though the NPs have different size and concentration. It can be noticed from Figs.  7 and 8 that {{the slope of the}} M [...]...|$|R
30|$|Observing Figure 2, one infers {{that the}} {{estimates}} {{are closely related}} and that the <b>errors</b> <b>range</b> well within EBs stretched by growing p. Inherently, the prediction error is reduced by increasing N {{that can be seen}} by comparing Figure 2 a,b.|$|R
30|$|Random <b>error</b> <b>ranged</b> from 0.11 to 0.41 mm for linear {{measurements}} and from 0.19 ° to 0.60 ° for angular measurements. The coefficient of reliability ranged from 0.90 to 0.99 for linear {{measurements and}} from 0.95 to 0.99 for angular measurements.|$|R
50|$|Using {{an audit}} {{protocol}} tool, it was identified that human entry <b>errors</b> <b>range</b> from 0.01% when entering donors' clinical follow-up details, to 0.53% when entering pathological details, highlighting {{the importance of}} an audit protocol tool in a medical research database.|$|R
40|$|Output {{responses}} of an tin-oxide gas sensor depends on indoor temperature/humidity, {{but not on}} the reacted gas concentrations. The modeling of a gas sensor characteristics curve between gas concentrations and voltage was attempted with respect to a temperature/humidity change, to remove the influence of indoor environment from sensor responses. A characteristics curve was derived as an inverse proportion function and approximated by undecided variables with a plane approximation of temperature/humidity coefficients. The results of this study in a home indicate that each temperature/humidity coefficient is approximate to linear equation in <b>error</b> <b>ranges</b> of 5 % and approximate functions of a characteristics curve are in a mean <b>error</b> <b>range</b> of about 1 % for a reserved region...|$|R
40|$|OBJECTIVEdTo examine state {{differences}} in the reporting of diabetes-related incorrect cause-of-death (COD) causal sequences on death certificates in the U. S. RESEARCH DESIGN AND METHODSdWe conducted a cross-sectional descriptive study to determine the prevalence of two types of incorrect COD causal sequences with data from the Multiple Cause Mortality File of the year 2004. RESULTSdAmong deaths in which diabetes was reported as the first diagnosis on line a, b, c, or d in Part I of the death certificate in the U. S., 21 % had below diabetes placement <b>error</b> (<b>ranged</b> from 30 % in Maryland to 7 % in Hawaii) and 11 % had above diabetes placement <b>error</b> (<b>ranged</b> from 18 % in Kentucky to 5 % in California). The net effects of {{the two types of}} <b>error</b> <b>ranged</b> from 20. 7 % in Nevada to 19. 6 % in the District of Columbia. CONCLUSIONSdBecause the rates of incorrect reporting of diabetes-related COD causal sequence varied across states, the comparability of the diabetes death rate between states may have been compromised. Diabetes Care 35 : 1572 – 1574, 2012 Mortality from diabetes is one of theimportant indicators in the statediabetes surveillance system initi...|$|R
40|$|We discuss two {{different}} integration methods for radar-based quantitative precipitation estimation (QPE) : the echo intensity integral {{and the rain}} intensity integral. Theoretical analyses and simulations were used to test differences between these two methods. Cumulative rainfall calculated by the echo intensity integral is usually greater than that from rain intensity integral. The difference of calculated precipitation using these two methods is generally smaller for stable precipitation systems and larger for unstable precipitation systems. If the echo intensity signal is sinusoidal, {{the discrepancy between the}} two methods is most significant. For stratiform and convective precipitation, the normalized <b>error</b> <b>ranges</b> from − 0. 138 to − 0. 15 and from − 0. 11 to − 0. 122, respectively. If the echo intensity signal is linear, the normalized <b>error</b> <b>ranges</b> from 0 to − 0. 13 and from 0 to − 0. 11, respectively. If the echo intensity signal is exponential, the normalized <b>error</b> <b>ranges</b> from 0 to − 0. 35 and from 0 to − 0. 30, respectively. When both the integration scheme and real radar data were used to estimate cumulative precipitation for one day, their spatial distributions were similar...|$|R
30|$|If r(t) is {{derivable}} for any order, {{its first}} to sth derivatives are selected within <b>error</b> <b>range,</b> {{which is similar}} to the truncation method of signal procession (see [23]). Some desired output may be expanded into power series with limited terms if necessary.|$|R
5000|$|Alkali <b>error</b> <b>range</b> - at low {{concentration}} of hydrogen ions (high values of pH) contributions of interfering alkali metals (like Li, Na, K) are comparable with the one of hydrogen ions. In this situation dependence of the potential on pH become non-linear.|$|R
3000|$|... {{could be}} {{converted}} to 3.242  μmol/g and 19.69  μmol/L. In comparison {{with the results of}} Octet system, the value was closed to each other within the accepted <b>error</b> <b>range.</b> LF isotherm equation was much more suitable for the simulation of this affinity precipitation isotherm.|$|R
50|$|Due to {{volume and}} density ambiguities, a {{different}} approach involves volumetrically measuring the ingredients, then using scales or balances of appropriate accuracy and <b>error</b> <b>ranges</b> to weigh them, and recording the results. With this method, occasionally an error or outlier of some kind occurs.|$|R
5000|$|Acidic <b>error</b> <b>range</b> - at {{very high}} {{concentration}} of hydrogen ions (low values of pH) the dependence of the electrode on pH becomes non-linear {{and the influence of}} the anions in the solution also becomes noticeable. These effects usually become noticeable at pH < -1.|$|R
30|$|In Step 2 we discretize K {{within an}} {{acceptable}} <b>error</b> <b>range</b> of solution. m takes different discrete points m of K in every iterative process. It {{is not hard}} to see that the major part of Algorithm 2 is similar to Algorithm 1. If we use Algorithm 1 to solve the BVI which has more than one solution, Algorithm 1 will stop when we get one solution. In order to get all the solutions, we should choose another initial point again, and reiterate the process of Algorithm 1. So, Step 4 in Algorithm 2 is important. m needs to take all the discrete points of K. Since we discretize K within an acceptable <b>error</b> <b>range</b> of solution, the stopping criterion K=∅ is reasonable.|$|R
30|$|Hafez et al. (2013 b) {{report an}} <b>error</b> <b>ranging</b> between − 30 and 180  s, and our <b>error</b> <b>ranges</b> between − 25 and 195  s. Their average and {{standard}} deviation of detection error were 35 and 44  s, respectively, very similar to our values of 17 and 53  s. In the algorithm of Hafez et al. (2013 b), detection takes 50 – 180  s with the hardware conditions described in section “Detection speed.” Our algorithm requires, on average, 160  s after storm onset before an SSC is detected, so it is comparable in terms of detection delay. As can be seen, both studies result in very similar levels of accuracy with different data sets and programming approaches, underlining the reliability of this method.|$|R
40|$|In this paper, an {{efficient}} error {{analysis of a}} real-time vision-based pointing system is proposed. We use two cameras to implement the pointing system according to a sim-plified 3 D reconstruction scheme {{which is based on}} image feature extraction, homography, and 3 D geometry. To that end, we study the relationship between image noises and the ultimate reconstruction errors, and develop efficient methods to find the <b>error</b> <b>range</b> of the latter given a range of the former. Experimental results show that the proposed approach can find the <b>error</b> <b>range</b> satisfactorily. Accordingly, users of similar pointing systems can get more robust pointing results by selecting a special pointer location, or possibly a special pair of cameras, that will result in minimal <b>range</b> of pointing <b>error...</b>|$|R
50|$|SLIM is Japan's {{first major}} lunar surface mission, and will {{demonstrate}} precise, pinpoint lunar landing. During its descent to the moon, the lander will recognizing lunar craters {{by applying the}} technology used in facial recognition systems, and decipher its current location from utilizing observation data collected by the SELENE (Kaguya) lunar orbiter mission. SLIM aims to soft land with an <b>error</b> <b>range</b> of 100 m. In comparison, the <b>error</b> <b>range</b> of the Apollo 11 Eagle lunar module was an elliptic which was 20 km wide in downrange and 5 km wide in crossrange. According to Yoshifumi Inatani, deputy {{director general of the}} JAXA Institute of Space and Astronautical Science (ISAS), by succeeding in this extremely precise landing, it will lead to enhancing the quality of space exploration.|$|R
40|$|In team sport, {{classifying}} playing position {{based on}} a players' expressed skill sets can provide a guide to talent identification by enabling the recognition of performance attributes relative to playing position. Here, elite junior Australian football players were a priori classified into 1 of 4 common playing positions; forward, midfield, defence, and ruck. Three analysis approaches {{were used to assess}} the extent to which 12 in-game skill performance indicators could classify playing position. These were a linear discriminant analysis (LDA), random forest, and a PART decision list. The LDA produced classification accuracy of 56. 8 %, with class <b>errors</b> <b>ranging</b> from 19. 6 % (midfielders) to 75. 0 % (ruck). The random forest model performed at a slightly worse level (51. 62 %), with class <b>errors</b> <b>ranging</b> from 27. 8 % (midfielders) to 100 % (ruck). The decision list revealed 6 rules capable of classifying playing position at accuracy of 70. 1 %, with class <b>errors</b> <b>ranging</b> from 14. 4 % (midfielders) to 100 % (ruck). Although the PART decision list produced the greatest relative classification accuracy, the technical skill indicators reported were generally unable to accurately classify players according to their position using the 3 analysis approaches. This player homogeneity may complicate recruitment by constraining talent recruiter's ability to objectively recognise distinctive positional attributes...|$|R
30|$|The N, P, and K, {{content of}} BBRDM was 49, 440.64 ± 236.25 : 1, 628.75 ± 322.25 : 9, 367.94 ± 1, 132.06 mg/kg. The N/P/K ratio was {{approximately}} 30.36 : 1 : 5.75. <b>Error</b> <b>ranges</b> indicate {{one standard deviation}} from the mean (n = 6).|$|R
30|$|Figure  23 {{shows the}} {{comparison}} for four gauges {{in the case}} of perpendicular loading (Load Case IA): two located in a compression-loaded main member, and two in a tensile-loaded main member. The FEA results for these locations lie within the <b>error</b> <b>range</b> of the experimental strain values obtained.|$|R
5000|$|In their {{respective}} pages, the Planets are listed {{along with their}} basic properties such as the year of planet’s discovery, mass, radius, orbital period, semi-major axis, eccentricity, inclination, longitude of periastron, time of periastron, maximum time variation, and time of transit, including all <b>error</b> <b>range</b> values.|$|R
30|$|Alzaharni [8] {{implemented}} a nonlinear autoregressive exogenous (NARX) model with external inputs for forecasting the {{global solar radiation}} using meteorological parameters. The data from 1991 to 2005 for Vichy National Airport in Rolla was used. The model achieved a mean square <b>error</b> <b>ranging</b> from 5.7 % to 15.33 %.|$|R
40|$|A reliable, {{real-time}} simultaneous localization and mapping (SLAM) {{method is}} crucial for the navigation of actively controlled capsule endoscopy robots. These robots are an emerging, minimally invasive diagnostic and therapeutic technology {{for use in the}} gastrointestinal (GI) tract. In this study, we propose a dense, non-rigidly deformable, and real-time map fusion approach for actively controlled endoscopic capsule robot applications. The method combines magnetic and vision based localization, and makes use of frame-to-model fusion and model-to-model loop closure. The performance of the method is demonstrated using an ex-vivo porcine stomach model. Across four trajectories of varying speed and complexity, and across three cameras, the root mean square localization <b>errors</b> <b>range</b> from 0. 42 to 1. 92 cm, and the root mean square surface reconstruction <b>errors</b> <b>range</b> from 1. 23 to 2. 39 cm...|$|R
