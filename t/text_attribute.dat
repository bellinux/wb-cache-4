19|509|Public
25|$|Variation {{selectors}} are {{not required}} for Arabic and Latin cursive characters, where substitution of glyphs can occur based on context: glyphs may be connected together {{depending on whether the}} character is the initial character in a word, the final character, a medial character or an isolated character. These types of glyph substitution are easily handled by the context of the character with no other authoring input involved. Authors may also use special-purpose characters such as joiners and non-joiners to force an alternate form of glyph where it would not otherwise appear. Ligatures are similar instances where glyphs may be substituted simply by turning ligatures on or off as a rich <b>text</b> <b>attribute.</b>|$|E
5000|$|To {{represent}} the setuid, setgid and sticky or text attributes, the executable character ('x' or '-') is modified. Though these attributes affect the overall file, not only users in one class, the setuid attribute modifies the executable {{character in the}} triad for the user, the setgid attribute modifies the executable character in the triad for the group and the sticky or <b>text</b> <b>attribute</b> modifies the executable character in the triad for others. For the setuid or setgid attributes, in {{the first or second}} triad, the 'x' becomes 's' and the '-' becomes 'S'. For the sticky or <b>text</b> <b>attribute,</b> in the third triad, the 'x' becomes 't' and the '-' becomes 'T'. Here is an example: ...|$|E
50|$|T-FLEX CAD {{provides}} parametric, adaptive and associative technology {{aimed at}} family-of-parts manufacturers or other design situations that use similar geometry but require many different sizes or permutations. Entities and their parameters in T-FLEX CAD {{can be related}} to each other. Variables can be assigned for component names, visibility, material, any numeric or <b>text</b> <b>attribute</b> of any entity. They can then be processed with algebraic or logical expression to control the behavior of the design.|$|E
5000|$|... #Subtitle level 2: Translations of <b>texts</b> <b>attributed</b> to Confucius ...|$|R
5000|$|<b>Text</b> <b>attributes</b> such as spacing between words, letters, {{and lines}} of text ...|$|R
40|$|Abstract. Relational top-N queries {{with both}} <b>text</b> <b>{{attributes}}</b> and numeric attributes {{are useful in}} many applications, by using the ranking functions based on both semantic distances for <b>text</b> <b>attributes</b> and numeric distances for numeric attributes. In this paper, we propose an approach for processing such type of top-N queries in relational databases. The basic idea of the approach {{is to create an}} index based on WordNet to expand the tuple words semantically for <b>text</b> <b>attributes</b> and on the related information of numeric attributes, meanwhile the size of the index increases linearly with the size of the database. The results of extensive experiments show that our method is efficient and effective...|$|R
50|$|Many {{characters}} map {{to alternate}} glyphs {{depending on the}} context. For example Arabic and Latin cursive characters substitute different glyphs to connect glyphs together {{depending on whether the}} character is the initial character in a word, the final character, a medial character or an isolated character. These types of glyph substitution are easily handled by the context of the character with no other authoring input involved. Authors may also use special-purpose characters such as joiners and non-joiners to force an alternate form of glyph where it would not otherwise appear. Ligatures are similar instances where glyphs may be substituted simply by turning ligatures on or off as a rich <b>text</b> <b>attribute.</b>|$|E
5000|$|Adobe FreeHand (formerly a Macromedia product) {{is mainly}} used by {{professional}} graphic designers. The functionality of FreeHand includes {{flexibility of the}} application in the wide design environment, catering to the output needs of both traditional image reproduction methods and to contemporary print and digital media with its page-layout capabilities and <b>text</b> <b>attribute</b> controls. Specific functions of FreeHand include a superior image-tracing operation for vector editing, page layout features within multiple-page documents, and embedding custom print-settings (such as variable halftone-screen specifications within a single graphic, etc.) to each document independent of auxiliary printer-drivers. User-operation {{is considered to be}} more suited for designers with an artistic background compared to designers with a technical background. When being marketed, FreeHand lacked the promotional backing, development and PR support in comparison to other similar products. FreeHand was transferred to the classic print group after Macromedia was purchased by Adobe in 2005. On May 16, 2007, Adobe announced that no further updates to Freehand would be developed but continues to sell FreeHand MX as a Macromedia product. FreeHand continues to run on Mac OS X Snow Leopard (using an Adobe fix) and on Windows 7. For Mac OS X, Serif (makers of Serif DrawPlus) have created Affinity Designer which is able to open some Freehand files.|$|E
40|$|<b>Text</b> <b>attribute</b> {{transfer}} using non-parallel data requires {{methods that}} can perform disentanglement of content and linguistic attributes. In this work, we propose multiple improvements over the existing approaches that enable the encoder-decoder framework {{to cope with}} the <b>text</b> <b>attribute</b> transfer from non-parallel data. We perform experiments on the sentiment transfer task using two datasets. For both datasets, our proposed method outperforms a strong baseline in two of the three employed evaluation metrics. Comment: NIPS 2017 Workshop on Learning Disentangled Representations: from Perception to Contro...|$|E
5000|$|The Dŗg-Dŗśya-Viveka is an Advaita Vedanta <b>text</b> <b>attributed</b> to Bĥaratī Tīrtha or Vidyaranya Swami(c. 1350) ...|$|R
5000|$|... #Caption: Pages from a 14th-century Arabic {{manuscript}} of the Cyranides, a <b>text</b> <b>attributed</b> to Hermes Trismegistus ...|$|R
5000|$|Purche lo sappi tu, <b>text</b> <b>attributed</b> to S. Baldini (two sopranos, basso continuo; Bologna, Civico Museo Bibliografico Musicale) ...|$|R
40|$|This thesis {{presents}} {{the design and}} implementation of operations on Text attributes in the Relix programming language. We can initialize Text attributes directly, from data files, text files or from HTML documents. We view text as an unordered sequence of strings, choosing different definitions of the string making up the base unit. We define textview as a relation of two attributes. The values of the attributes are strings into which Text is divided and their sequence numbers. We provide four pre-defined textviews: character, word, sentence, and paragraph. We can also define textviews using regular expressions. We allow multiple textviews to be defined for a single <b>Text</b> <b>attribute.</b> We apply search and replacement operations to textviews defined for Text attributes. We use regular expressions to specify the strings to be matched. The result of a search operation is a nested relation which has a Relation attribute that contains the tuples of the corresponding textview which satisfy the search conditions. We store the values of Text attributes in text files outside relations. We use one text file per <b>Text</b> <b>attribute</b> in a relation. We use trie methods, which {{proved to be the}} most efficient with text retrieval on secondary storage, to index text data in relations and to search for patterns in search and replacement operations...|$|E
40|$|In an {{increasingly}} multilingual digital world, {{it is critical}} that information management tools, such as web search engines, e-Commerce portals and e-Governance applications, support the simultaneous use of multiple natural languages. An essential pre-requisite is that the underlying database engines (typically relational), provide the functionality for processing multilingual data seamlessly across languages. As a part of our Mira [1] research initiative focusing on functionality and performance aspects of supporting multilingualism in relational database systems, we propose SemEQUAL, a semantic operator for matching <b>text</b> <b>attribute</b> data across languages based on meaning...|$|E
40|$|News In Preview This newsletter's Q and A section {{describes}} the main {{factors that can}} be behind Permission denied er-rors. The Easily Overlooked Feature section {{describes the}} Align commands {{that can be used}} to align grid <b>text,</b> <b>attribute</b> text, and analysis text. The first article describes using the Tian method to plot loop gain in AC analysis. The Tian method has an advantage over the Middlebrook method due to it taking into account bilateral feedback paths in its calculations. The second article describes how to model skin effect in a lossy transmission line through the new capa-bility that allows the use of F and S within the lossy transmission line model statement parameters. The third article describes how to measure the crest factor of a waveform by using the performanc...|$|E
50|$|Some early medieval <b>texts</b> <b>attributed</b> the Consensoria Monachorum {{concept to}} Saint Augustine, but recent {{attributions}} point to later dates.|$|R
50|$|This volume {{contains}} primarily <b>texts</b> <b>attributed</b> to Roger Bacon, sometimes incorrectly. Roth-Scholtz discusses Bacon and John Dee in the Preface.|$|R
50|$|The Eighth, Ninth, and Tenth Books of Moses are grimoire <b>texts</b> <b>attributed</b> to Moses, and {{popularized by}} pseudo author Henri Gamache.|$|R
40|$|Attribute grammars are {{a formal}} {{notation}} for expressing the static semantics of programming languages — those properties {{that can be}} derived from inspection of the program <b>text.</b> <b>Attribute</b> grammars have become popular as a mechanism for generating language-based programming environments that incrementally perform symbol resolution, type checking, code generation and derivation of other static semantic properties as the program is modified. However, attribute grammars are not suitable for expressing dynamic semantics — those properties that reflect the history of program execution and/or user interactions with the programming environment. This article presents action equations, an extension of attribute grammars suitable for specifying the static and the dynamic semantics of programming languages. It describes how action equations can be used to generate language-based programming environments that incrementally derive static and dynamic properties as the user modifies and debugs the program...|$|E
40|$|In {{this thesis}} we {{introduce}} {{a method of}} storing static text data, and algorithms for operations on the data, in a relational database programming language. We introduce a text data type, and implement relational algebra operations on the text data type. Our method stores the text data in text files external to the relations, and maintains pointers to the text data within the relations. Our algorithms minimize accesses to the actual text data so as to maintain the efficiency of database operations. We also implement a text processing mechanism where a text script can be joined to a relation, producing an individualized text script for each tuple in the relation. Our implementation includes queries involving pattern searches within <b>text</b> <b>attribute</b> values. All operations on text data are relational algebra operations, requiring the text data to be in relations, and returning relations as results...|$|E
30|$|Another {{group of}} classes {{involved}} with a theme and its contributions, as mentioned in the “Requirements” section (p. 3), are the artifact classes, which are composed by Wiki, WikiHistory, File, and the Comment classes. The latter provides a mechanism of interaction between volunteers to discuss the content of a contribution. The classes File and Comment contain {{the identification of the}} user who was responsible for that artifact, and for the contribution and theme to which the contributed file or comment belong to. Each one of these classes contains specific attributes to ensure their purpose. File, for example, contains fields like file name, type and location address, and Comment contains a <b>text</b> <b>attribute.</b> The Wiki class describes the current state of a wiki from a contribution, which should be shown to the application’s users. To enable the possibility of going back in wiki editing, the WikiHistory class was designed. It contains a reference to the editing author and the respective theme and contribution, along with its text.|$|E
5000|$|Izbicki, Thomas M., [...] "Additional <b>Texts</b> <b>Attributed</b> to Bartolus de Saxoferrato in North American Manuscript Collections," [...] Manuscripta 55 (2011): 146-155.|$|R
40|$|In many {{database}} applications, ranking queries may reference both <b>text</b> and numeric <b>attributes,</b> {{where the}} ranking functions {{are based on}} both semantic distances/similarities for <b>text</b> <b>attributes</b> and numeric distances for numeric attributes. In this paper, we propose a new method for evaluating such type of ranking queries over a relational database. By statistics and training, this method builds a mechanism that combines the semantic and numeric distances, and the mechanism {{can be used to}} balance the effects of <b>text</b> <b>attributes</b> and numeric attributes on matching a given query and tuples in database search. The basic idea of the method is to create an index based on WordNet to expand the tuple words semantically for <b>text</b> <b>attributes</b> and on the information of numeric attributes. The candidate results for a query are retrieved by the index and a simple SQL selection statement, and then top-N answers are obtained. The results of extensive experiments indicate that the performance of this new strategy is efficient and effective...|$|R
50|$|The Prologue in the Greek <b>text,</b> <b>attributed</b> to him, is {{generally}} considered the earliest witness to a canon of the books of the prophets.|$|R
40|$|Nebula is a {{file system}} that {{explicitly}} supports information management. It differs from traditional systems in three important ways. First, Nebula implements files as sets of attributes. Each attribute describes some {{property of the}} file such as owner, protection, functions defined, sections specified, project, or file type. The content of the file is represented by a special <b>text</b> <b>attribute.</b> Second, Nebula supports associative access of files within a scoped index. A scoped index restricts associative access to {{a subset of the}} files in one or more file systems. Finally, Nebula replaces traditional directories with database views. A directory implements a naming closure; i. e. the name of a file is assigned by the directories in which it resides. A view is a query that selects file objects from a scoped index. Thus, the name of a file is a property of the file, not the view. Like directories, views can be named and included in other views. When a file (or view) is created, it is placed [...] ...|$|E
40|$|To {{aim at the}} {{evaluation}} task of CLP 2012 named entity recognition and disambiguation in Chinese, a Chinese name disambiguation method based on adaptive clustering with the attribute features is proposed. Firstly, 12 -dimensional character attribute features is defined, and tagged attribute feature corpus are used to train to obtain the recognition model of attribute features by Conditional Random Fields algorithm, {{in order to do}} the attribute recognition of given texts and knowledge bases. Secondly, the training samples are tagged by utilizing the correspondences of the <b>text</b> <b>attribute</b> and answer, and attribute feature weight model is trained based on the maximum entropy model and the weights are acquired. Finally, the fuzzy clustering matrix is achieved by the correlation of Knowledge Base(KB) ID attributes and text attributes for each KB ID, the clustering threshold is selected adaptively based on the F statistic, and clustering texts corresponding to ID are obtained, thus the texts corresponding to each ID are gained followed. For the texts not belong to KB, Out and Other types are obtained by fuzzy clustering to realize name disambiguation. The evaluation result is: P = 0. 7424, R...|$|E
40|$|Today’s {{social and}} {{internet}} networks contain millions or even billions of nodes, and copious amounts of side information (context) such as <b>text,</b> <b>attribute,</b> temporal, image and video data. A thorough {{analysis of a}} social network should consider both the graph and the associated side information, yet we also expect the algorithm to execute in {{a reasonable amount of}} time on even the largest networks. Towards the goal of rich analysis on societal-scale networks, this thesis provides (1) modeling and algorithmic techniques for incorporating network context into existing network analysis algorithms based on statistical models, and (2) strategies for network data representation, model design, algorithm design and distributed multi-machine programming that, together, ensure scalability to very large networks. The methods presented herein combine the flexibility of statistical models with key ideas and empirical observations from the data mining and social networks communities, and are supported by software libraries for cluster computing based on original distributed systems research. These efforts culminate in a novel mixed-membership triangle motif model that easily scales to large networks with over 100 million nodes on just a few cluster machines, and can be readily extended to accommodate network context using the other techniques presented in this thesis...|$|E
5000|$|Besides the {{discussion}} of the historicity of Muhammad as a historical person and the Quranic <b>text</b> <b>attributed</b> to him, Islam faces the following debates: ...|$|R
500|$|Wujastyk, Dominik. (2017). [...] "The Yoga <b>Texts</b> <b>Attributed</b> to Yājñavalkya {{and their}} Remarks on Posture." [...] In Asian Literature and Translation, 4(1), 159-186. doi:http://dx.doi.org/10.18573/j.2017.10192 (Open Access) ...|$|R
5000|$|Siddha Siddhanta Paddhati is a {{very early}} extant hatha yoga Sanskrit <b>text</b> <b>attributed</b> to Gorakshanath by the {{indigenous}} tradition, as Georg Feuerstein (1991: p. 105) relates: ...|$|R
40|$|Abstract: The Information Era has {{witnessed}} {{a huge number}} of sources from websites. The abundance of useful data surrounding us has made it possible for integration systems {{to improve the quality of}} the integrated data. However, how to choose proper data sources efficiently to extract data with high coverage and low redundancy is still a hot topic in the area. Sampling the databases hiding behind the websites makes it possible to obtain the characteristics of the web databases, and further to choose appropriate sources when collecting data for integration and query optimization. In this paper we construct a sampling model to represent data characteristics of web databases based on posing keyword queries on the deep web query interface. The dependency of <b>text</b> <b>attribute</b> keywords within the data source is used to construct the dependent-relational probability matrix, which indicate the sample distribution and is used for keyword extension to fetch more sampling data and get new characteristics of the actual data. Further, we provide an efficiency method to evaluate the similarity between the sample databases and the real web databases. We evaluate the proposed method in real world dataset and the results show that our method can sample the web data sources with high similarity...|$|E
40|$|In this paper, a region-based text {{localization}} that is robust {{for multiple}} languages is presented. Maximally Stable Extremal Regions (MSERs) {{are used for}} detecting candidates of text areas. The MSER components are grouped based on their connectivity in a feature space by using a new proposed rule for assigning the connectivity. The groups of components are classified into three classes that are text regions with high confidence, text region with low confidence, and non-text regions. A chain of <b>text</b> <b>attribute</b> constraint decision with the double-threshold scheme is developed to identify text regions. A sequence of constraint decision is designed to minimize the complexity based on short-circuit evaluation of logic operators. The regions that satisfy all strong constraints will be considered as text regions with high confidence while the regions that fail in some strong constraints but satisfy all weak constraints will be considered as text regions with low confidence. The final text regions are obtained from all text regions with high confidence and text regions with low confidence that have connectivity to text regions with high confidence. The proposed scheme is evaluated by using the natural scene images that consist of totally nine languages with different text alignments and camera views. The experiment shows that our proposed scheme can provide the satisfy results in comparison with baseline method...|$|E
30|$|All models {{based only}} on time and {{topology}} (See Fig.  2 a-e) do not include information about messages, documents or text. A simple extension adding a <b>text</b> <b>attribute</b> to the edges would still be less expressive than our model, because this simpler solution {{would not be able}} to differentiate between different types of communication such as unicast, multicast and broadcast. These are instead allowed in our model exploiting the presence of nodes representing text messages, and thus justifying the adoption of a bipartite model instead of the simple graphs used in contact sequences. Single time annotations are also unable to distinguish between production/consumption or sending/receiving time. In summary, contact sequence models (Fig.  2 a) can be expressed using our model by representing edges as edge-message-edge triples, but contact sequences cannot represent all the information that we can express using our model. Time-slices (Fig.  2 b) and longitudinal models (Fig.  2 c) can also be obtained starting from our model, as we do not make any assumption about how the time is represented on the edges. It is thus possible to represent both time-slices and longitudinal models as temporal text networks by just creating a new message mj and a sequence of edges (vi,mj,l),(mj,vk,l) for each original edge e=(vi,vk,l) in the layer l of the sliced network. Finally, when only time and structure are concerned, memory models (Fig.  2 d-e) are usually constructed from contact sequence models by aggregating the edges conditional on preceding pathways. While the original temporal information is partially preserved during the creation of the memory model, it is impossible to preserve more information from our temporal text network such as messages or network attributes. Therefore, we can think of our model as a way to represent raw and complete information about the temporal interactions and memory models as a way to emphasize information provenance. However, to represent provenance we need to allow edges between messages, and for this reason only our extended temporal text network model is able to express all the information present in memory models (in addition to text, multicasting and production/consumption times, as for all the other models not based on bipartite graphs).|$|E
50|$|Prem Ambodh Pothi, a <b>text</b> <b>attributed</b> to Guru Gobind Singh and {{completed}} in 1693 CE, includes poetry of Mira Bai {{as one of}} sixteen historic bhakti sants important to Sikhism.|$|R
2500|$|Albius Tibullus ( [...] BC19 BC) was a Latin {{poet and}} writer of elegies. His {{first and second}} books of poetry are extant; many other <b>texts</b> <b>attributed</b> to him are of {{questionable}} origins.|$|R
5000|$|The Liezi (...) is a Daoist <b>text</b> <b>attributed</b> to Lie Yukou, a c. 5th century BCE Hundred Schools of Thought philosopher, but Chinese and Western {{scholars}} {{believe it}} was compiled around the 4th century CE.|$|R
