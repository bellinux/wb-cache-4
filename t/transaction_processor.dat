13|25|Public
50|$|MTCS (Minimum Teleprocessing Control System) was a <b>transaction</b> <b>processor</b> {{that ran}} on IBM {{mainframe}} systems under OS/VS1.|$|E
50|$|FASTER (First Automated Teleprocessing Environment Reponder) was a <b>transaction</b> <b>processor</b> {{that ran}} on IBM {{mainframe}} systems under OS/MFT.|$|E
50|$|In {{addition}} to methods employed for transaction security and secrecy, all communications traffic between the ATM and the <b>Transaction</b> <b>Processor</b> {{may also be}} encrypted using methods such as SSL.|$|E
5000|$|... {{components}} {{capable of}} processing and/or local memory <b>transactions</b> (i.e., <b>processors),</b> ...|$|R
50|$|The fees {{charged to}} merchants for offline debit {{purchases}} vs. {{the lack of}} fees charged to merchants for processing online debit purchases and paper checks have prompted some major merchants in the U.S. to file lawsuits against debit-card <b>transaction</b> <b>processors,</b> such as Visa and MasterCard. In 2003, Visa and MasterCard agreed to settle the largest of these lawsuits for $2 billion and $1 billion respectively.|$|R
50|$|In 1994, Fedco {{was one of}} {{the first}} {{membership}} stores to start accepting bank-issued credit cards. Most discount stores of this type did not accept credit cards because transaction fees charged by the credit card <b>transaction</b> <b>processors</b> were quite high in relation to their (single-digit percent range) margins, and they would have to raise prices to compensate, putting them at a competitive disadvantage to stores that did not accept credit cards.|$|R
50|$|In August 2011, MyBitcoin, a {{now defunct}} bitcoin <b>transaction</b> <b>processor,</b> {{declared}} {{that it was}} hacked, which caused it to be shut down, paying 49% on customer deposits, leaving more than 78,000 bitcoins (equivalent to roughly US$800,000 at that time) unaccounted for.|$|E
50|$|BizX {{acts as a}} <b>transaction</b> <b>processor</b> and {{3rd party}} record keeper for all buyers and sellers. Sellers can charge buyers’ BizX {{accounts}} by phone or online portal. Funds are available to the seller immediately when the transaction is run, with zero processing or holding time.|$|E
5000|$|Contributed by Intel, Sawtooth utilises a novel {{consensus}} mechanism known as [...] "Proof of Elapsed Time," [...] a lottery-design consensus protocol that builds on trusted execution environments provided by Intel's Software Guard Extensions (SGX). An effort is underway {{to mount the}} Hyperledger Burrow EVM application engine as a Sawtooth <b>transaction</b> <b>processor.</b>|$|E
50|$|Encryption of {{personal}} information, {{required by law}} in many jurisdictions, is used to prevent fraud. Sensitive data in ATM transactions are usually encrypted with DES, but <b>transaction</b> <b>processors</b> now usually {{require the use of}} Triple DES. Remote Key Loading techniques may be used to ensure the secrecy of the initialisation of the encryption keys in the ATM. Message Authentication Code (MAC) or Partial MAC may also be used to ensure messages have not been tampered with while in transit between the ATM and the financial network.|$|R
50|$|There are 4 <b>processor</b> <b>transactions</b> and 2 bus transactions.|$|R
5000|$|... #Caption: A finite {{state machine}} showing the <b>processor</b> <b>transactions</b> for the MOSI protocol.|$|R
5000|$|SparkBase, LLC (SparkBase or SB) was a stored-value {{and gift}} card <b>transaction</b> <b>processor</b> located in Cleveland, Ohio, United States from 2004 to 2016. It {{provided}} private-label, stored-value, specialty gift cards, customer loyalty, and community rewards programs to Independent Sales Organizations (independent companies used by banks {{to develop new}} merchant relationships on their behalf). [...] ISOs then sold these gift and loyalty products to merchant customers along with credit card services and processing equipment.|$|E
50|$|Amadeus is a {{computer}} reservations system (or global distribution system, since it sells tickets for multiple airlines) owned by the Amadeus IT Group with headquarters in Madrid, Spain. The central database is located at Erding, Germany. The major development centers are located in Bangalore (India), Sophia Antipolis (France) and Boston (United States). In addition to airlines, the CRS {{is also used to}} book train travel, cruises, car rental, ferry reservations, and hotel rooms. Amadeus also provides New Generation departure control systems to airlines. Amadeus IT Group is a <b>transaction</b> <b>processor</b> for the global travel and tourism industry. The company is structured around two key related areas - its global distribution system and its IT Solutions business area.|$|E
50|$|The terms data {{dictionary}} and data repository indicate {{a more general}} software utility than a catalogue. A catalogue is closely coupled with the DBMS software. It provides the information stored in it to the user and the DBA, but it is mainly accessed by the various software modules of the DBMS itself, such as DDL and DML compilers, the query optimiser, the <b>transaction</b> <b>processor,</b> report generators, and the constraint enforcer. On the other hand, a {{data dictionary}} is a data structure that stores metadata, i.e., (structured) data about information. The software package for a stand-alone data dictionary or data repository may interact with the software modules of the DBMS, but it is mainly used by the designers, users and administrators of a computer system for information resource management. These systems maintain information on system hardware and software configuration, documentation, application and users {{as well as other}} information relevant to system administration.|$|E
50|$|Linux is also {{finding some}} {{reception}} in the ATM marketplace. An {{example of this}} is Banrisul, the largest bank in the south of Brazil, which has replaced the MS-DOS operating systems in its ATMs with Linux. Banco do Brasil is also migrating ATMs to Linux. Indian-based Vortex Engineering is manufacturing ATMs which operate only with Linux.Common application layer transaction protocols, such as Diebold 91x (911 or 912) and NCR NDC or NDC+ provide emulation of older generations of hardware on newer platforms with incremental extensions made over time to address new capabilities, although companies like NCR continuously improve these protocols issuing newer versions (e.g. NCR's AANDC v3.x.y, where x.y are subversions). Most major ATM manufacturers provide software packages that implement these protocols. Newer protocols such as IFX have yet to find wide acceptance by <b>transaction</b> <b>processors.</b>|$|R
40|$|Abstract: We {{experimentally}} demonstrate end-to-end memory <b>transactions</b> {{between a}} <b>processor</b> and memory node across the data vortex optical packet switch. Successful {{read and write}} transactions via the network at 4 × 2. 5 Gb/s are verified. © 2010 Optical Society of America OCIS codes: (060. 4259) Networks, packet-switched; (060. 4250) Network...|$|R
30|$|The {{widespread}} use of committees involving individuals from various backgrounds (e.g. bankers, engineering manufacturers, <b>transaction</b> <b>processors,</b> software providers) created platforms to facilitate deliberation (Harper and Batiz-Lazo, 2013). Nevertheless, anticipation was lacking as these discussions were reactive, narrowly focused on security and capability issues identified only after deployment (Harper and Batiz-Lazo, 2013). The development of the PIN/PAN system provides {{a good example of}} this. This innovation came about sometime after the initial deployment of the first Swedish bank machines in 1967. Someone had discovered that the algorithm used to associate card numbers with PIN codes was not resilient and exploited this by withdrawing money from various ATMs around Sweden during Easter vacation in 1968 (Harper and Batiz-Lazo, 2013). Unfortunately, the bank did not catch this until about 50  days after Easter, creating problems that nearly led to the closure of the company (Harper and Batiz-Lazo, 2013). These events produced discussions among stakeholders (banks, manufacturers, and engineering firms), who studied the work of other companies (e.g. Smith Industries’s method for accurate, low-cost, high-security customer access to machines) to create an improved verification/security system (Harper and Batiz-Lazo, 2013). This suggests that although anticipation was lacking, innovators were reflexive and responsive in dealing with identified problems. In another example supporting responsiveness, we find deployment of features of the ATM delayed by about two years after various security issues had been identified through testing (Harper and Batiz-Lazo, 2013). Further, {{it has been shown that}} slow adoption processes in the case of the ATM (Harper and Batiz-Lazo, 2013) allowed for mistakes to be corrected at a lesser cost to society.|$|R
40|$|Tokenless {{biometric}} electronic transactions {{using an}} audio signature {{to identify the}} <b>transaction</b> <b>processor</b> The invention discloses a tokenless biometric identification computer system, comprising at least a database containing registered biometric samples of users. A comparator compares a bid biometric sample of a user {{to at least one}} registered biometric sample, the bid biometric sample obtained directly from the user during an identification process for conducting an electronic transaction by the user. A stored audio signature is associated with a <b>transaction</b> <b>processor</b> entity, which the <b>transaction</b> <b>processor</b> entity is responsible for conducting the electronic transaction. A sound generator generates an analog or digital signal from the stored audio signature, and a transducer converts the analog or digital signal to a play back audio signature. This invention generates a play back audio signature from the stored audio signature that is associated with the <b>transaction</b> <b>processor</b> entity and the play back audio signature is played back to the user to identify the <b>transaction</b> <b>processor</b> entity that conducted the electronic transaction, wherein no man made personal devices such as credit cards, identity cards or the like is used during the identification process for conducting the electronic transaction...|$|E
40|$|The term 'e-commerce ' {{has become}} widespread- {{a force that}} is here to stay. E-commerce and the Internet are {{increasingly}} {{becoming one of the}} most important drivers of strategic change for business and national governments. Yet the insurance industry has been lagging behind other financial services to embrace this new change within its activities. The Internet has enormous potential, as it is a medium that provides cheaper and more efficient communication links. This dissertation analyses the current developments and trends within the insurance industry. It also assesses the extent to which e-commerce affects the day-to-day activities of insurance companies and examines some of the implications of e-commerce on the life insurance industry and associated sectors. As boundaries between businesses are reduced and a greater level of customer empowerment is seen, the very nature of financial services may change. Four postulated strategic business models arising from e-commerce are: intermediary marketplace, work-site marketing, eyeball attractor and <b>transaction</b> <b>processor.</b> Withi...|$|E
40|$|The {{objective}} of this project was to design and test a secure IP-based architecture suitable for short duration transactions. This included {{the development of a}} prototype test-bed in which various operating scenarios (such as cryptographic options, various IP-based architectures and fault tolerance) were demonstrated. A solution based on SIP secured with TLS was tested on two IP based architectures. Total time, CPU time and heap usage was measured for each architecture and encryption scheme to examine the viability of such a solution. The results showed that the proposed solution stack was able to complete transactions in reasonable time and was able to recover from <b>transaction</b> <b>processor</b> failure. This research has demonstrated a possible architecture and protocol stack suitable for IP-based transaction networks. The benefits of an IP-based transaction network include reduced operating costs for network providers and clients, as shared IP infrastructure is used, instead of maintaining a separate IP and X. 25 network...|$|E
50|$|Looking at {{the case}} for <b>{{processor}}</b> <b>transactions,</b> when the block is in the Invalid (I) state, either the cache block was never fetched from the memory or it was invalidated. When there is a processor read (PrRd), the state changes from invalid (I) to shared (S), thereby generating a bus read (BusRd). At the same time, {{if it is a}} processor write request (PrWr), then the state of the block changes to modified (M) along with a snooped write request (BusRdX).|$|R
40|$|Symmetric {{multiprocessor}} (SMP) servers provide superior {{performance for}} the commercial workloads that dominate the Internet. Our simulation results show that over one-third of cache misses by these applications result in cache-to-cache transfers, where the data is found in another processor's cache rather than in memory. SMPs are optimized for this case by using snooping protocols that broadcast address <b>transactions</b> to all <b>processors.</b> Conversely, directory-based shared-memory systems must indirectly locate the owner and sharers through a directory, resulting in larger average miss latencies. This paper proposes timestamp snooping, a technique that allows SMPs to i) utilize high-speed switched interconnection networks and ii) exploit physical locality by delivering address <b>transactions</b> to <b>processors</b> and memories without regard to order. Traditional snooping requires physical ordering of transactions. Timestamp snooping works by processing address transactions in a logical order. Logical time is maintained by adding a few bits per address transaction and having network switches perform a handshake to ensure on-time delivery. Processors and memories then reorder transactions based on their timestamps to establish a total order. We evaluate timestamp snooping with commercial workloads on a 16 -processor SPARC system using the Simics full-system simulator. We simulate both an indirect (butterfly) and a direct (torus) network design. For OLTP, DSS, web serving, web searching, and one scientific application, timestamp snooping with the butterfly network runs 6 - 28 % faster than directories, {{at a cost of}} 13 - 43 % more link traffic. Similarly, with the torus network, timestamp snooping runs 6 - 29 % faster for 17 - 37 % more link traffic. Thus, timestamp snoopi [...] ...|$|R
40|$|In {{this paper}} we propose two new {{parallel}} formulations of the Apriori algorithm that is used for computing association rules. These new formulations, IDD and HD, address the shortcomings of two previously proposed parallel formulations CD and DD. Unlike the CD algorithm, the IDD algorithm partitions the candidate set intelligently among processors to efficiently parallelize the step of building the hash tree. The IDD algorithm also eliminates the redundant work inherent in DD, and requires substantially smaller communication overhead than DD. But IDD suffers from the added cost due to communication of <b>transactions</b> among <b>processors.</b> HD is a hybrid algorithm that combines the advantages of CD and DD. Experimental results on a 128 -processor Cray T 3 E show that HD scales {{just as well as}} the CD algorithm with respect to the number of transactions, and scales as well as IDD with respect to increasing candidate set size. Keywords [...] - Data mining, parallel processing, association rules, load [...] ...|$|R
40|$|Manufacturing Message Specification" (MMS) is an OSI {{application}} layer protocol that allows remote applications (called clients) {{to control and}} supervise various heterogeneous industrial devices (called servers). MMS is becoming widely accepted as the main protocol for open communications between heterogeneous machines in many areas that {{are not limited to}} manufacturing. MMS facilitates the cooperation of heterogeneous devices. But, this is done at the cost of a rather complex and under-utilized standard. The aim of this thesis is to propose an architecture of MMS-based systems that simplifies the use of MMS and extends its capabilities to satisfy more closely the needs of user applications. We start with a detailed analysis of MMS events and semaphores. These two aspects of MMS are still misunderstood and often even ignored. We compare MMS semaphores and events to well-known and similar concepts in fields not related to MMS. This approach allows us to clarify the concept of semaphore and event in MMS. It facilitates the understanding we have of these concepts and encourages their use in MMS applications. We do not know of any MMS server that offers all of the services and functionalities described in the MMS standard. We propose a general architecture of such servers that eases the implementation of all MMS services and integrates more specifically the management of events. A server based on such a generic architecture has been implemented. It is composed of several units. Each unit is responsible for the management of a specific group of MMS services. These units are controlled by the <b>Transaction</b> <b>Processor</b> which constitutes the core of the server. The benefits of this architecture rely in the clarity it provides and the decoupling of the various units. This architecture facilitates server modifications as well as the addition of new services. We provide a deeper analysis of MMS events by defining an extension to MMS event detection. This extension satisfies more closely the needs of industrial applications based on MMS. It allows user applications to provide predicate expressions that can lead to an event occurrence. This is something that is not possible in the current MMS standard. This extension is entirely compatible with existing MMS applications since the MMS protocol is not modified and the server behavior is only extended. We also propose another extension to MMS. This last extension allows users to include priorities to MMS service requests and allows servers to execute these requests based on the priority values. More generally, the problem of requests and tasks scheduling in a server is a major issue for industrial applications. However, it is not addressed at all by MMS. Thus, we analyze the capabilities and limitations of MMS in the domain of real-time systems. We show how requests can be given deadlines without modifying the MMS protocol. We make use of MMS modifiers to satisfy a real-time execution of MMS requests and propose solutions to ensure a real-time detection of MMS events. MMS does not seem to provide application developers with the adequate tools to deal with distributed systems requirements. We study the behavior of MMS systems when applications require the cooperation or competition of multiple clients in the presence of multiple servers. In doing so, we always try to reduce the influence our solutions could have on the MMS protocol. We propose MMS-based solutions for classical problems such as rendez-vous between clients, readers/writers and the dining philosophers problem. We also define two algorithms for accessing data distributed to several MMS sites. These algorithms are based on deadlock detection/resolution techniques and make an abundant use of MMS semaphores and events...|$|E
40|$|One of the {{important}} problems in data mining is discovering association rules from databases. Each transaction contains a set of items. Discovering the frequent itemsets {{require a lot of}} computation power, memory and input/output values, which can only be provided by parallel computer. In this paper, we proposed a new Parallel Partition Prime Multiple Algorithm for association rule mining. Proposed algorithm addresses the shortcoming of previously proposed Parallel Buddy Prima Algorithm. The proposed algorithm divides transaction database equally according to their assignment of variable for each processor. The decision of assignment of next <b>transaction</b> to the <b>processor</b> depends on the value of count variable of itemset per transaction.   It reduces the time and data complexity. </strong...|$|R
40|$|As {{multiprocessor}} sizes {{scale and}} computer architects turn to interconnection networks with non-uniform communication latencies, {{the lure of}} exploiting communication locality to increase performance becomes inevitable. Models that accurately quantify locality effects provide invaluable insight into the importance of exploiting locality as machine sizes and features change. This paper presents a framework for modeling the impact of communication locality on system performance. The framework provides a means for combining simple models of application, processor, and network behavior to obtain a combined model that accurately reflects feedback effects between processors and networks. We introduce a model that characterizes application behavior with three parameters that capture computation grain, sensitivity to communication latency, and amount of locality present at execution time. The combined model is validated with measurements taken from a detailed simulator for a complete multiprocessor system. Using the combined model, we show that exploiting communication locality provides gains which are at most linear in the factor by which average communication distance is reduced {{when the number of}} outstanding communication <b>transactions</b> per <b>processor</b> is bounded. The combined model is also used to obtain rough upper bounds on the performance improvement from exploiting locality to minimize communication distance. ...|$|R
40|$|Software {{transactional}} memory systems {{enable a}} programmer to easily write concurrent data {{structures such as}} lists, trees, hashtables, and graphs, where nonconflicting operations proceed in parallel. Many of these structures take the abstract form of a dictionary, in which each transaction {{is associated with a}} search key. By regrouping transactions based on their keys, one may improve locality and reduce conflicts among parallel transactions. In this paper, we present an executor that partitions <b>transactions</b> among available <b>processors.</b> Our keybased adaptive partitioning monitors incoming transactions, estimates the probability distribution of their keys, and adaptively determines the (usually nonuniform) partitions. By comparing the adaptive partitioning with uniform partitioning and round-robin keyless partitioning on a 16 -processor SunFire 6800 machine, we demonstrate that key-based adaptive partitioning significantly improves the throughput of finegrained parallel operations on concurrent data structures...|$|R
40|$|Computer system IO (with accelerator, network, storage, {{graphics}} components) {{has been}} optimized to use descriptor-based {{direct memory access}} (DMA) operations to move data to and from relatively fast addressable system (or main) memory or cache structures. Traditionally, transactions between slower IO sub-systems and system memory have been done using a host bus/bridge adapter (HBA). Each IO interface has one or more separately instantiated descriptor-based DMA engines optimized for a given IO port. As heterogeneous cores multiply in exascale systems, IO traffic {{can be expected to}} be more complex and will require more resources. This paper measures the descriptor overhead and analyzes its impact on latency and bandwidth. Based on quantifications of the latency and bandwidth overhead, we propose to improve IO performance using an integrated platform IO accelerator. This IO engine localizes IO <b>transactions</b> to the <b>processor</b> CPU, rather than offloading to various remote platform interface controllers. By simplifying hardware control of IO in complex systems that rely on a central system memory, we conclude there are quantifiable benefits of integrated platform IO transactions in terms of bandwidth-per-pin and latency, and other areas...|$|R
40|$|Typical help {{processors}} are invoked explicitly by {{the user}} or implicitly when an error occurs. Often a beginner will not know that he needs help because the inefficient use of commands will {{get the job done}} without raising errors. WIZARD is an expert system that recognizes beginner misbehaviors and can automatically start a help <b>transaction.</b> The WIZARD <b>processor</b> relies on a special purpose, dynamic, pattern matcher directed by a KL–One based knowledge network. An author studies logs of beginner interaction and develops sequence rules which parse and properly identify misbehaviors. Objects that drive the parser to understand VAX DCL commands are coded into the network and a set of semantic programming utilities is used to perform actual goal recognition. This thesis deals primarily with the implementation of such a goal recognizing expert invocation system. It is the WIZARD documentation and final working report. I discuss the motivations for the design of the system and detail the knowledge base and heuristics that support goal recognition. Some issues of generality are taken up and potential topics for later research are presented which will extend WIZARD 2 ̆ 7 S capabilities...|$|R
40|$|We propose signature-accelerated {{transactional}} memory (SigTM), {{a hybrid}} TM system {{that reduces the}} overhead of software transactions. SigTM uses hardware signatures to track the read-set and write-set for pending transactions and perform conflict detection between concurrent threads. All other transactional functionality, including data versioning, is implemented in software. Unlike previously proposed hybrid TM systems, SigTM requires no modifications to the hardware caches, which reduces hardware cost and simplifies support for nested <b>transactions</b> and multithreaded <b>processor</b> cores. SigTM is also the first hybrid TM system to provide strong isolation guarantees between transactional blocks and nontransactional accesses without additional read and write barriers in non-transactional code. Using a set of parallel programs that make frequent use of coarsegrain transactions, we show that SigTM accelerates software transactions by 30 % to 280 %. For certain workloads, SigTM can match {{the performance of a}} full-featured hardware TM system, while for workloads with large read-sets it can be up to two times slower. Overall, we show that SigTM combines the performance characteristics and strong isolation guarantees of hardware TM implementations with the low cost and flexibility of software TM systems...|$|R
50|$|Write Invalidate {{is another}} set of cache {{coherence}} protocols, where once a cache block is modified, the other values of the same block in other caches are not updated, but invalidated. Write invalidate protocols are more efficient in cases where are there are many subsequent writes to the same cache block, as the invalidation happens once and further bus <b>transactions</b> by other <b>processors</b> are avoided. However, the write update protocol is more efficient in cases where a write to a block is followed by multiple reads to the same block. Since we are updating the other cached values once we write it, {{they have access to}} the data immediately. In such a case. the write invalidate protocol is highly disadvantageous because every time a cache block is modified in another cache, the rest of the caches need will encounter a coherence miss, and initiate a bus transaction to read the new value. In contrast, the write update protocol tends to, at times, keep the values of the block updated for longer than necessary, which will lead to an increase in other types of misses, i.e. conflict and capacity misses.|$|R
40|$|As part of {{the trend}} towards Chip Multiprocessors (CMPs) for the next leap in {{computing}} performance, many architectures have explored sharing the last level of cache among different processors for better performance–cost ratio and improved resource allocation. Shared cache management is a crucial CMP design aspect {{for the performance of}} the system. This paper first presents a new classification of cache misses – CII: Compulsory, Inter-processor and Intra-processor misses – for CMPs with shared caches to provide {{a better understanding of the}} interactions between memory <b>transactions</b> of different <b>processors</b> at the level of shared cache in a CMP. We then propose a novel approach, called set pinning, for eliminating inter-processor misses and reducing intra-processor misses in a shared cache. Furthermore, we show that an adaptive set pinning scheme improves over the benefits obtained by the set pinning scheme by significantly reducing the number of off–chip accesses. Extensive analysis of these approaches with SPEComp 2001 benchmarks is performed using a full system simulator. Our experiments indicate that the set pinning scheme achieves an average improvement of 22. 18 % in the L 2 miss rate while the adaptive set pinning scheme reduces the miss rates by an average of 47. 94 % as compared to the traditional shared cache scheme. They also improve the performance by 7. 24 % and 17. 88 % respectively...|$|R
40|$|Abstract—In Symmetric Multiprocessors (SMPs), {{the cache}} {{coherence}} overhead {{and the speed}} of the shared buses limit the address/ snoop bandwidth needed to broadcast <b>transactions</b> to all <b>processors.</b> As a solution, a scalable address subnetwork called Symmetric Multiprocessor Network (SYMNET) is proposed in which address requests and snoop responses of SMPs are implemented optically. SYMNET not only uses passive optical interconnects that increases {{the speed of the}} proposed network, but also pipelines address requests at a much faster rate than electronics. This increases the address bandwidth for snooping, but the preservation of cache coherence can no longer be maintained with the usual snooping protocols. A modified coherence protocol, Coherence in SYMNET (COSYM), is introduced to solve the coherence problem. COSYM was evaluated with a subset of Splash- 2 benchmarks and compared with the electrical bus-based MOESI protocol. The simulation studies have shown a 5 - 66 percent improvement in execution time for COSYM as compared to MOESI for various applications. Simulations have also shown that the average latency for a transaction to complete using COSYM protocol was 5 - 78 percent better than the MOESI protocol. It is also seen that SYMNET can scale up to hundreds of processors while still using fast snooping-based cache coherence protocols, and additional performance gains may be attained with further improvement in optical device technology. Index Terms—SMPs, parallel optical interconnects, cache coherence, scalable optical networks. ...|$|R
40|$|Despite {{significant}} progress in recent years, horizontal and vertical integration of the Lithuanian milk sector is not very much advanced. The primary sector is characterised by small-scale farming, the fragmentation of farmland and a low number of livestock per farms. These features cause severe problems regarding the restructuring and modernisation of agricultural production since only a few farmers possess the capital resources to conduct necessary investments. However, despite the unfavourable conditions Lithuanian milk producers have made significant improvements concerning milk quality. In the last decade, the processing sector was due to drastic concentration processes. These were induced by the strong competition processes on the milk market and fostered by foreign direct investors. Today, the market is dominated by three companies. About ten enterprises supply almost the entire market of dairy products. The main mode of governance {{in the market for}} raw milk is contractual arrangements. The spot market of strong vertical control are unimportant. The basic rules of the contracts like duration or payment scheme are set by the Ministry of Agriculture, others, especially prices, are negotiated individually between farmer and processor. Because of advantages in terms of transport and <b>transaction</b> costs <b>processors</b> provide better conditions to large agricultural producers. Often the processors try to strengthen their relationships with large-scale producers by providing credits for farm modernisation and/or foodstuff. Most small producers do not deliver directly to processors but to milk collection centres. In general, these are owned by processors. So far, only a few farmers co-operatives have been established in order to take this function. Contractual arrangements also dominate in the distribution channel. Small processors supply mainly to wholesalers who supply the retail market. Large processors often circumvent the wholesale stage and supply the retail stage directly. The basic means which allow this forward integration are intensive marketing activities which are intended to improve the consumer perception of their products. However, this type of exchange is mainly observed in urban areas where well established large retail chains exist. The Lithuanian milk sector is highly internationally competitive. The expansion to international markets is in the responsibility of the individual firms. However, the Lithuanian government and the food processors have established a joint marketing agency that provides infrastructure and joint marketing for international trade. [...] Horizontal and vertical integration,Lithuanian milk sector,foreign trade,consumption...|$|R
40|$|This paper {{addresses}} embedded multiprocessor {{implementation of}} iterative, real-time applications, such as digital signal and image processing, that are specified as dataflow graphs. Scheduling dataflow graphs on multiple processors involves assigning tasks to processors (processor assignment), ordering {{the execution of}} tasks within each processor (task ordering), and determining when each task must commence execution. We consider three scheduling strategies: fullystatic, self-timed and ordered transactions, all of which perform the assignment and ordering steps at compile time. Run time costs are small for the fully-static strategy; however it is not robust with respect to changes or uncertainty in task execution times. The self-timed approach is tolerant of variations in task execution times, but pays the penalty of high run time costs, because processors need to explicitly synchronize whenever they communicate. The ordered transactions approach lies between the fully-static and self-timed strategies; in this approach {{the order in which}} processors communicate is determined at compile time and enforced at run time. The ordered transactions strategy retains some of the flexibility of self-timed schedules {{and at the same time}} has lower run time costs than the self-timed approach. In this paper we determine an order of <b>processor</b> <b>transactions</b> that is nearly optimal given information about task execution times at compile time, and for a given processor assignment and task ordering. The criterion for optimality is the average throughput achieved by the schedule. Our main result is that it is possible to choose a transaction order such that the resulting ordered transactions schedule incurs no performance penalty compared to the more flexible self-timed strategy, even when the higher run time costs implied by the self-timed strategy are ignored...|$|R
