0|7965|Public
50|$|In June 2006, the {{developer}} Merck KGaA {{announced that the}} development of sarizotan was discontinued, after two sarizotan Phase III studies (PADDY I, PADDY II) failed to meet the primary efficacy endpoint and neither the Phase II findings nor the results from preclinical studies could be confirmed. No statistically significant difference of the <b>primary</b> <b>target</b> <b>variable</b> between sarizotan and placebo could be demonstrated.|$|R
40|$|The paper {{considers}} alternative {{monetary policy}} regimes within a calibrated macroeconomic {{model with a}} traded and a non-traded sector. Two classes of regimes are considered; inflation targeting and exchange rate targeting. When the target variable is completely stabilized, both rules have poor stabilizing properties for all real variables - nominal exchange rate targeting is even dynamically unstable. When the monetary authority places some weight on output stabilization {{in addition to the}} <b>primary</b> <b>target</b> <b>variable,</b> inflation targeting outperforms exchange rate targeting in terms of output stability in both the traded and the non-traded sectors...|$|R
40|$|We {{study the}} process of {{chemical}} equilibration of strangeness in dynamically evolving QGP fireball formed in relativistic heavy ion collisions at RHIC and LHC. We account for the contribution of direct and explore the thermal-QCD strangeness production mechanisms. The specific yield of strangeness per entropy is the <b>primary</b> <b>target</b> <b>variable.</b> We explore the effect of collision impact parameter, i. e., fireball size, on strangeness chemical equilibration in QGP. Insights gained in study the RHIC data are applied to the study strangeness production at the LHC. We further consider how characteristic hadronic observables {{are influenced by the}} differences in the chemical equilibration, given a specific per entropy strangeness yield...|$|R
40|$|Data {{editing and}} {{imputation}} (E&I) in complex sample business surveys {{is a task}} which is usually split into two steps to gain efficiency {{in terms of time}} and human resources: first selective editing techniques are applied to the <b>primary</b> <b>target</b> estimates <b>variables</b> in order to identify a potential set of influential errors that require usually manual editing and a second part of automatic identification and imputation of inconsistencies and missing values. Within this framework, the present paper reviews the Italian top-down data editing strategy adopted and automated imputation showing the experience applied to 2013 Farm Structure Survey livestock data. In this edition this process has been entirely carried out in the R environment by means of different R packages...|$|R
40|$|We study, in the {{dynamically}} evolving QGP fireball {{formed in}} relativistic heavy ion collisions at RHIC and LHC, {{the growth of}} strangeness yield toward and beyond the chemical equilibrium. We account for {{the contribution of the}} direct strangeness production and evaluate the thermal-QCD strangeness production mechanisms. The specific yield of strangeness per entropy, s/S, is the <b>primary</b> <b>target</b> <b>variable.</b> We explore the effect of collision impact parameter, i. e., fireball size, on kinetic strangeness chemical equilibration in QGP. Insights gained in study the RHIC data with regard to the dynamics of the fireball are applied to the study strangeness production at the LHC. We use these results and consider the strange hadron relative particle yields at RHIC and LHC in a systematic fashion. We consider both the dependence on s/S and directly participant number dependence. Comment: 21 pages, 13 figures, PRC in press. Strangeness production recomputed with K-factor K= 1. 7. Particle yields recomputed with SHARE 2. ...|$|R
40|$|Objective: The aim of {{this study}} was to assess the {{potential}} risk of gadobutrol-enhanced magnetic resonance imaging (MRI) in patients with moderate to severe renal impairment for the development of nephrogenic systemic fibrosis (NSF). Materials and Methods: We performed a prospective, international, multicenter, open-label study in 55 centers. Patients with moderate to severe renal impairment scheduled for any gadobutrol-enhanced MRI were included. All patients received a single intravenous bolus injection of gadobutrol at a dose of 0. 1 mmol/kg body weight. The <b>primary</b> <b>target</b> <b>variable</b> was the number of patients who develop NSF within a 2 -year follow-up period. Results: A total of 908 patients were enrolled, including 586 with moderate and 284 with severe renal impairment who are at highest risk for developing NSF. The mean time since renal disease diagnosis was 1. 83 and 5. 49 years in the moderate and severe renal impairment cohort, respectively. Overall, 184 patients (20. 3...|$|R
40|$|Objective: The {{objective}} {{of this study was}} to assess the risk of gadoxetate disodium in liver imaging for the development of nephrogenic systemic fibrosis (NSF) in patients with moderate to severe renal impairment. Materials andMethods:Weperformed a prospective,multicenter, nonrandomized, open-label phase 4 study in 35 centers from May 2009 to July 2013. The study population consisted of patients with moderate to severe renal impairment sched-uled for liver imaging with gadoxetate disodium. All patients received a single in-travenous bolus injection of 0. 025 -mmol/kg body weight of liver-specific gadoxetate disodium. The <b>primary</b> <b>target</b> <b>variable</b> was the number of patients who develop NSF within a 2 -year follow-up period. creased in cases of prolonged circulation of the Gd-chelate such as in Zech et al 11 have shown that the diagnostic performance of gadoxetate disodiumMRIwas better than that of contrast-enhanced com-ORIGINAL ARTICLENonCommercial-NoDerivatives 3. 0 License, where it is permissible to download and share the work provided it is properly cited. The work cannot be changed i...|$|R
40|$|To {{evaluate}} the effectiveness of targeting monetary policy strategies in a small open economy, we develop a dynamic optimizing model calibrated to recent Korean data. We then explore the conse-quences of alternative specifications of the loss function for society and the central bank, with par-ticular focus on exchange rate volatility. Policy simulations include variations on inflation targeting, nominal income growth targeting and exchange rate targeting. Our results indicate that inflation targeting remains the most preferred policy regime, even when an explicit motive for exchange rate smoothing is introduced. In this case, the optimal inflation targeting and nominal income growth tar-geting policies are characterized by a “conservative ” central bank that places greater weight on both the <b>primary</b> <b>target</b> <b>variable</b> and on the exchange rate than in society’s objective function. However, the optimal policy reacts to changes in certain parameter values,most notably the degree of exchange rate pass-though, in a large and non-linear fashion, complicating the robustness of inflation targeting recommendations for emerging markets...|$|R
3000|$|In this work, we {{have only}} {{considered}} the homogeneous medium, where the <b>primary</b> <b>variables</b> of P and X are always continuous over the entire domain. For some <b>primary</b> <b>variables,</b> their derivatives in the governing Eqs. (13) −(15) are discontinuous at locations where the phase transition happens, i.e., X=X [...]...|$|R
30|$|In the {{analysis}} of seasonal distribution, the <b>primary</b> predictor <b>variable</b> was the date of injury, and the <b>primary</b> outcome <b>variable</b> {{was the number of}} fracture patients. In {{the analysis}} of fracture cause, the <b>primary</b> predictor <b>variable</b> was the cause of fracture, and the <b>primary</b> outcome <b>variable</b> was the region of fracture. In {{the analysis of}} postoperative complications, the <b>primary</b> predictor <b>variables</b> were sex, age, diabetes mellitus, smoking, alcohol intoxication, day of the week, beginning/middle/end of the month, time from injury to treatment, duration of admission, fracture site, and fracture cause; the <b>primary</b> outcome <b>variable</b> was the occurrence of postoperative complication.|$|R
50|$|Insolation is the <b>primary</b> <b>variable</b> {{affecting}} {{equilibrium temperature}} in spacecraft design and planetology.|$|R
5000|$|Embedded RPC is {{lightweight}} RPC implementation {{developed by}} NXP, <b>targeting</b> <b>primary</b> CortexM cores ...|$|R
50|$|When an {{appropriate}} disk boot device is available, the SRM console locates and loads the <b>target</b> <b>primary</b> bootstrap image using information {{written in the}} target disk boot block; in logical block zero. The boot block contains the disk location and block size of the <b>target</b> <b>primary</b> bootstrap image file, and SRM will load that into memory and will then transfer control to it.|$|R
5000|$|If the <b>primary</b> <b>variable</b> is mass {{fraction}} (yi, given, for example, in kg/kg), then the equation changes to: ...|$|R
40|$|Motivation: The {{wealth of}} single {{nucleotide}} polymorphism (SNP) data within candidate genes and anticipated across the genome poses enormous analytic problems for studies of genotype-to-phenotype relationships, and modern data mining methods may be particularly well suited to meet the swelling challenges. In this manuscript we introduce the method of Belief (Bayesian) networks to the domain of genotype-to-phenotype analyses and provide an example application. Results: A Belief network is a graphical model of a probabilistic nature that represents a joint multivariate probability distribution and reflects conditional independences between variables. Given the data, optimal network topology can be estimated {{with the assistance of}} heuristic search algorithms and scoring criteria. Statistical significance of edge strengths can be evaluated using Bayesian methods and bootstrapping. As an example application, the method of Belief networks was applied to twenty SNPs in the apolipoprotein (apo) E gene and plasma apoE levels in a sample of 702 individuals from Jackson, MS. Plasma apoE level was the <b>primary</b> <b>target</b> <b>variable.</b> These analyses indicate that the edge between SNP 4075, coding for well-known 2 allele, and plasma apoE level was strong. Belief networks can effectively describe complex uncertain processes and can both learn from data and incorporate prior knowledge. Availability: Various alternative and supplemental networks (not shown in text), as well as source code extensions, are available from the authors...|$|R
3000|$|From the RVE-problem in (107), σ̅_d is {{obtained}} directly as a <b>primary</b> <b>variable.</b> The volumetric strain e̅ {{is obtained}} by post-processing: [...]...|$|R
30|$|All this {{recommend}} the boundary element method, with boundary formulation which implies <b>primary</b> <b>variables,</b> as an efficient numerical technique to solve boundary value problems.|$|R
30|$|From this equation, {{after the}} {{introduction}} of (3) and taking into account of the differential pressures as <b>primary</b> <b>variables,</b> see [22], we have obtained Eq. (4).|$|R
40|$|In {{this thesis}} a new {{displacement}} based formulation is developed for elasto-plastic deformations in steady state problems. In this formulation the displacements are the <b>primary</b> <b>variables,</b> {{which is in}} contrast to the more common formulations in terms of the velocities as the <b>primary</b> <b>variables.</b> In a steady state process, a transient calculation is not required and only space discretizations are needed, without time discretizations. The evolution of the material variables is expressed as an integration along the streamlines. The resulting differential equation describes steady convection with source terms...|$|R
40|$|This paper {{presents}} the relations that describe thermodynamic equilibrium in a three-phase system. Multiple components, including air, water, and oil components, are considered in three phases: (1) aqueous, (2) oil, and (3) gas. <b>Primary</b> <b>variables</b> are specified {{for each of}} seven possible phase combinations. These <b>primary</b> <b>variables</b> are then {{used to determine the}} necessary secondary variables to completely describe the system. Criteria are also developed to check the stability of each phase configuration and determine possible transitions from one phase configuration to another phase configuration via phase appearances and disappearances...|$|R
50|$|Much {{like the}} shaft's flex, a blade's pattern {{is a very}} {{important}} characteristic of a stick's performance. There are three <b>primary</b> <b>variables</b> in blade design: curve, face angle, and toe.|$|R
40|$|The {{soil and}} crop cover of {{agricultural}} land vary spatially {{in a way}} that is both random and autocorrelated. This enables them to be estimated and mapped from sparse sample data by kriging. These properties (<b>primary</b> <b>variables)</b> are usually related to the radiation they reflect: They are coregionalized with it. In many circumstances the <b>primary</b> <b>variables</b> can be estimated more precisely by measuring, in addition, the radiation sparsely, using a ground-based radiometer and combining the two by cokriging. The coregionalization must be formalized in a coherent set of variograms, one for the <b>primary</b> <b>variable,</b> one for each variable derived from the radiometry, and the cross variograms between all pairs of variables involved in the estimation. Given this set, it is possible to determine estimation variances for any configuration of sampling and to design an optimal scheme that will achieve a desired precision for least effort. The formulae for cokriging are presented, as are the conditions for a coherent model of the coregionalization, and the article shows how these can be used to design sampling schemes that combine survey of the <b>primary</b> <b>variables</b> and radiation to best advantage. Three examples from intensive agriculture in Britain illustrate the technique. In one example where the aim was to estimate and map the cover of clover in pasture, cokriging using measured radiation was nine times as efficient as kriging the cover alone...|$|R
2500|$|Much {{like the}} shaft's flex, a blade's pattern {{is a very}} {{important}} characteristic of a stick's performance. [...] There are three <b>primary</b> <b>variables</b> in blade design: curve, face angle, and toe.|$|R
3000|$|... 2 {{capture and}} storage (Park et al. 2011; Singh et al. 2012). Throughout the process, {{different}} phase zones may exist under different temperature and pressure conditions. At lower temperatures, water flows {{in the form}} of liquid. With the rise of temperature, gas and liquid phases may co-exist. At higher temperature, water is then mainly transported {{in the form of}} gas/vapor. Since the physical behaviors of these phase zones are different, they are mathematically described by different governing equations. When simulating the geothermal convection with phase change phenomena, this imposes challenges to the numerical models. To numerically model the above phase change behavior, there exist several different algorithms so far. The most popular one is the so-called <b>primary</b> <b>variable</b> switching method proposed by Wu and Forsyth (2001). In Wu’s method, the <b>primary</b> <b>variables</b> are switched according to different phase states. For instance, in the two phase region, liquid phase pressure and saturation are commonly chosen as the primary variables; whereas in the single gas or liquid phase region, the saturation of the missing phase will be substituted by the concentration or mass fraction of one light component. This approach has already been adopted by the multiphase simulation code such as TOUGH (Pruess 2008) and MUFTE (Class et al. 2002). Nevertheless, the governing equations deduced from the varying <b>primary</b> <b>variables</b> are intrinsically non-differentiable and often lead to numerical difficulties. To handle this, Abadpour and Panfilov (2009) proposed the negative saturation method, in which saturation values less than zero and bigger than one are used to store extra information of the phase transition. Salimi et al. (2012) later extended this method to the non-isothermal condition, and also taking into account the diffusion and capillary forces. By their efforts, the <b>primary</b> <b>variable</b> switching has been successfully avoided. Recently, Panfilov and Panfilova (2014) has further extended the negative saturation method to the three-component three-phase scenario. As the negative saturation value does not have a physical meaning, further extension of this approach to general multi-phase multi-component system would be difficult. For deep geothermal reservoirs, it requires the <b>primary</b> <b>variables</b> of the governing equation to be persistent throughout the entire spatial and temporal domain of the model. Following this idea, Neumann et al. (2013) chose the pressure of non-wetting phase and capillary pressure as <b>primary</b> <b>variables.</b> The two variables are continuous over different material layers, which make it possible to deal with heterogeneous material properties. The drawback of Neumann’s approach is that it can only handle the disappearance of the non-wetting phase, not its appearance. As a supplement, Marchand et al. (2013) suggested to use mean pressure and molar fraction of the light component as <b>primary</b> <b>variables.</b> This allows both of the <b>primary</b> <b>variables</b> to be constructed independently of the phase status and allows the appearance and disappearance of any of the two phases. Furthermore, this algorithm could be easy to be extended to multi-phases (≥ 3) multi-components (≥ 3) system.|$|R
50|$|His {{over forty}} {{publications}} as author, co-author or consultant have <b>targeted</b> <b>primary</b> and secondary students along with adult learners of English. He {{has also written}} numerous articles in international magazines.|$|R
3000|$|We {{are aware}} of the fact that this issue may be more {{difficult}} to handle for the heterogeneous media, where the <b>primary</b> <b>variable</b> P and X could not be directly applied any more because of the non-continuity over the heterogeneous interface (Park et al. 2011). In that case, choosing the <b>primary</b> <b>variables</b> which are continuous over any interface of the medium is a better option. Based on the analysis by Ern and Mozolevski (2012), if we assume Henry’s law is valid, concentration, or in another word, the molar or mass fraction of the hydrogen in the liquid phase ρ _L^h (X_L^h), gas/liquid phase pressure P [...]...|$|R
40|$|In Part I, two TLM-based {{solutions}} {{were presented}} for the Klein}Gordon Equation in its basic form, with the TLM pulses representing the <b>primary</b> <b>variable.</b> In Part II, two further approaches {{are presented in}} which the TLM pulses now represent derivatives of the <b>primary</b> <b>variable,</b> with respect to either space or time. As in Part I, the two solution schemes were veri"ed symbolically and numerically. They illustrate further ways to extend the power of TLM beyond its traditional application areas. Some of these areas are discussed brie#y. Copyright 2002 John Wiley & Sons, Ltd. KEY WORDS: TLM; transmission line matrix; dispensive wave equation; dispersion; Klein}Gordon equa-tion; numerical methods; forced wave equatio...|$|R
40|$|ABSTRACT The {{magnitude}} of olfactory responses {{can be related}} to three <b>primary</b> <b>variables</b> [number of odorant molecules (N), sniff volume (V), and sniff duration (T) ] and three derived variables [concentration (C = N/V), flow rate (F = V/T), and delivery rate (D = NIT) ]. To evaluate the effects of these interdependent variables upon the olfactory response, the summated multiunit discharges were recorded from the olfactory nerves of nine frogs in response to octane presented at two levels (in 2 : 1 ratio) of each <b>primary</b> <b>variable.</b> This presentation defined eight "sniff " combinations representing three levels of each derived variable. In an ANOVA of the logs of the responses, the effect of each <b>primary</b> <b>variable</b> was highly significant, with no significant interactions. A multiplicative regression model incorporating the effects of the three <b>primary</b> <b>variables</b> represented responses exceedingly well, with positive effects ofNand T and a negative effect of V. When, with this model, the effect of each of the derived variables was isolated from the effects of all other variables, the analysis showed a positive effect for C, a near-zero positive effect for D, and a negative effect for F. Placing certain constraints upon the model parameters generates 13 distinct one- and two-variable models (e. g., the [C, T] model requires N and V to have equal but opposite effects). In ranking these reduced models in terms of their ability to predict the neural response, the predictive ability of [F, N] and [C, T] was at least as good as that of the three-variable model...|$|R
40|$|This paper formulates an {{elementary}} algorithm for resolution of singularities {{in a neighborhood}} of a singular point over a field of characteristic zero. The algorithm is composed of finite sequences of Newton polyhedra and monomial transformations and based on Weierstrass preparation theorem. This approach entails such new methods as canonical reduction and synthesis of monomial transformations as well as latency and revival of <b>primary</b> <b>variables.</b> The orders of <b>primary</b> <b>variables</b> serve as the decreasing singularity invariants for the algorithm albeit with some temporary increases. A finite partition of unity in a neighborhood of the singular point is constructed in an inductive way depending on the topological constraint imposed by Euler characteristic of the normal vector set of Newton polyhedron...|$|R
40|$|Carbon Capture and Storage (CCS) is a {{recently}} dis-cussed new technology, aimed at allowing an ongoing use {{of fossil fuels}} while preventing the produced CO 2 to be released to the atmosphere. CSS can be modeled with two components (water and CO 2) in two phases (liquid and CO 2). To simulate the process, a multi-phase flow equation with equilibrium phase exchange is used. One of the big problems arising in two-phase two-component flow simulations is {{the disappearance of the}} nonwetting phase, which leads to a degeneration of the equations satisfied by the saturation. A standard choice of <b>primary</b> <b>variables,</b> which is the pressure of one phase and the saturation of the other phase, cannot be applied here. We developed a new approach using the pressure of the nonwetting phase and the capillary pressure as pri-mary variables. One important advantage of this ap-proach {{is the fact that we}} have only one set of <b>primary</b> <b>variables</b> that can be used for the biphasic as well as the monophasic case. We implemented this new choice of <b>primary</b> <b>variables</b> in the DUNE simulation framework and present numerical results for some test cases. ...|$|R
30|$|The {{present study}} {{examined}} {{the effectiveness of the}} B.E.S.T. Teen Program, a multi-addiction prevention program <b>targeting</b> <b>Primary</b> 5 and 6 students in Hong Kong. To investigate whether students who participated in the program had changed, objective outcome evaluation was conducted.|$|R
40|$|International audienceIn {{this paper}} two {{different}} formulations for the numerical simulation of laser surface coating processes are presented and analysed. Both {{are based on}} the use of natural neighbour interpolation, but one employs a Galerkin approach and takes temperature as the <b>primary</b> <b>variable</b> while the second one is based on the use of finite differences and enthalpy as <b>primary</b> <b>variable.</b> The main practical difference is thus the description of the interphase of the melted zone during the process. While in the first method the interphase is described by a set of nodes that evolve in time, in the second one it is located somewhere between a string of nodes. Both formulations are described and compared, showing their potential benefits for the simulation of the before mentioned process...|$|R
40|$|<b>Primary</b> <b>variable</b> {{switching}} {{appears as}} a promising numerical technique for variably saturated flows. While the standard pressure-based form of the Richards equation can suffer from poor mass balance accuracy, the mixed form with its improved conservative properties can possess convergence difficulties for dry initial conditions. On the other hand, variable switching can overcome most of the stated numerical problems. The paper deals with variable switching for finite elements in two and three dimensions. The technique is incorporated in both an adaptive error-controlled predictor–corrector one-step Newton (PCOSN) iteration strategy and a target-based full Newton (TBFN) iteration scheme. Both schemes provide different behaviors with respect to accuracy and solution effort. Additionally, a simplified upstream weighting technique is used. Compared with conventional approaches the <b>primary</b> <b>variable</b> switching technique represents a fast and robust strategy for unsaturated problems with dry initial conditions. The impact of the <b>primary</b> <b>variable</b> switching technique is studied {{over a wide range}} of mostly 2 D and partly difficult-to-solve problems (infiltration, drainage, perched water table, capillary barrier), where comparable results are available. It is shown that the TBFN iteration is an effective but error-prone procedure. TBFN sacrifices temporal accuracy in favor of accelerated convergence if aggressive time step sizes are chosen...|$|R
30|$|On a {{technical}} note, {{it should be}} stated that the numerical model {{does not provide a}} converged, steady-state result for Variation  3. Instead, a transient simulation was run until no significant variation of the <b>primary</b> <b>variables</b> over time could be observed in chosen nodes of the model.|$|R
30|$|Once a {{fingerprint}} has been chosen, a subsequent {{principal component analysis}} (PCA, see appendix) can be applied {{in order to obtain}} a further reduction in dimensionality. This allows us to construct more parsimonious classifiers, which can then be compared to those which use the <b>primary</b> <b>variables</b> only.|$|R
50|$|There {{are four}} <b>primary</b> <b>variables</b> {{that can be}} {{adjusted}} to lower monthly payments and help homeowners: 1) Reduce the interest rate; 2) Reduce the loan principal amount; 3) Extend the mortgage term, such as from 30 to 40 years; and 4) Convert variable-rate ARM mortgages to fixed-rate.|$|R
