2|39|Public
40|$|Relational {{learning}} algorithms are {{of special}} interest {{to members of the}} machine learning community; they offer practical methods for extending the representations used in algorithms that solve supervised learning tasks. Five approaches are currently being explored to address issues involved with using relational representations. This paper surveys algorithms embodying these approaches, summarizes their empirical evaluations, highlights their commonalities, and suggests potential directions for future research. Keywords: supervised learning, representation, relational learning 1 Introduction Relational learning algorithms extend the capabilities of propositional or monadic supervised learning algorithms. Supervised learning algorithms input a set of instances, which are described by a set of predictor descriptors and a <b>target</b> <b>descriptor.</b> These algorithms construct a function (i. e., a concept description) that can predict an instance's <b>target</b> <b>descriptor</b> value given its predictor desc [...] ...|$|E
40|$|This {{paper is}} {{concerned}} with the reinforcement learning methods for the discrete time descriptor systems. An algorithm, as well as its theoretical basis, is presented. The algorithm can generate the optimal controller for the <b>target</b> <b>descriptor</b> system only by the measured input and output data, with no need of the information about the system state and system matrices. The algorithm can work well not only when the system index is equal or less than one, but also can work well when the index is greater than one. Simulation indicates that the presented method can solve the optimal control problem well for descriptor systems when the system model is not exactly known, but the input and output data can be measured. © 2013 IEEE...|$|E
40|$|We {{propose a}} {{strategy}} for integrating descriptor-driven transformation into mosaicing sound synthesis, in which samples are selected by taking into account potential distances in the transformed space. <b>Target</b> <b>descriptors</b> consisting of chroma, mel-spaced filter banks, and energy are modeled with respect to windowed bandlimited resampling and mel-spaced filters, and later corrected with gain. These transformations, however simple, allow some adaptation of textural sound material to musical contexts. 1...|$|R
40|$|Entering Football Players from United States when search-ing for American Footballers is {{an example}} of {{vocabulary}} mismatch, which occurs when different words are used to express the same concepts. In order to address this phe-nomenon for entity search <b>targeting</b> <b>descriptors</b> for complex categories, we propose a compositional-distributional seman-tics entity search engine, which extracts semantic and com-monsense knowledge from large-scale corpora to address the vocabulary gap between query and data...|$|R
40|$|A {{procedure}} utilized at Marshall Space Flight Center {{to formulate}} ballistic limit curves for the Space Station Freedom's manned module orbital debris shields is presented. A stepwise linear least squares regression method {{similar to that}} employed by Burch (1967) is used to relate a penetration parameter to various projectile and <b>target</b> <b>descriptors.</b> A stepwise regression was also conducted with the model reduced to lower forms, thus eliminating the effects of generalized assumptions...|$|R
40|$|Abstract: Supervised {{recognition}} of emotions from physiological signals {{has been widely}} accomplished to measure affective interactions. Less attention is, however, placed upon learning descriptive models to characterize physiological responses. In this work we delve on why and how to learn discriminative, complete and usable descriptive models based on physiological signals from emotion-evocative stimuli. By satisfying these three properties, we guarantee that the <b>target</b> <b>descriptors</b> can be expressively adopted to understand the physiological behavior underlying multiple emotions. In particular, we explain why classification and unsupervised learning models do not address these properties, and point new directions on how to adapt existing learners to met them based on theoretical and empirical evidence. ...|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceThe {{adaptation}} {{process is}} an important and complex step of case-based reasoning (CBR) and is {{most of the time}} designed for a specific application. This article presents a domain-independent algorithm for adaptation in CBR. Cases are mapped to a set of numerical descriptors filled with values and local constraint intervals. The algorithm computes every <b>target</b> solution <b>descriptor</b> by combining a source solution, a matching expressed as intervals of variations and dependencies between the source problem and its solution. It determines for every <b>target</b> solution <b>descriptor</b> an interval of the admissible values. In this interval, actual values satisfying global constraints can be chosen. This generic approach to adaptation is operational and introduces general and domain-independent adaptation operators. Therefore, this study is a contribution to the design of a general algorithm for adaptation in CBR...|$|R
40|$|International audienceComputational chemogenomic (or proteochemometric) methods predict target-ligand {{interactions}} {{by training}} {{machine learning algorithms}} on known experimental data in order to distinguish attributes of true from false target-ligand pairs. Many ligand and <b>target</b> <b>descriptors</b> {{can be used for}} training and predicting binary associations or even binding affinities. Several chemogenomic studies have not noticed any real benefit in using 3 -D structural <b>target</b> <b>descriptors</b> with respect to simpler sequence-based or property-based information. To assess whether this observation results from inaccurate target description or from the fact that 3 -D information is simply not required in chemogenomic modeling, we used a target kernel measuring the distance between target-ligand binding sites of known X-ray structures. When used in combination with a standard ligand kernel in a support vector machine (SVM) classifier, the 3 -D target kernel significantly outperforms a sequence-based target kernel in discriminating 2882 target-ligand PDB complexes from 9128 false pairs, whatever the modeling procedure (local or global). The best SVM models could be successfully applied to predict, with very high recall (70 %), precision (99 %), and specificity (99 %), target-ligand associations for an external set of 14 [*] 117 ligands and 531 targets. In most of the cases, pooling all data in a global model gave better statistics than just discretizing specific target-ligand subspaces in local models. The current study clearly demonstrates that chemogenomic models taking both ligand and target information outperform simpler ligand-based models. It also permits one to design good modeling practices in predicting target-ligand pairing for a large array of targets: (i) ligand-based models are precise enough if sufficient ligand information (> 40 - 50 diverse ligands) is known; (ii) if not, structure-based chemogenomic models (associating a ligand kernel to a structure-based target kernel) are recommended for proteins of known holostructures; (iii) sequence-based chemogenomic models (associating a ligand kernel to a sequence-based target kernel) can still be used with a very good accuracy for the remaining targets...|$|R
50|$|From this {{discussion}} it becomes clear, that different shape <b>descriptors</b> <b>target</b> {{different aspects of}} shape {{and can be used}} for a specific application. Therefore, depending on the application, it is necessary to analyze how well a descriptor captures the features of interest.|$|R
40|$|Background: Drug {{side effects}} {{represent}} a common reason for stopping drug development during clinical trials. Improving {{our ability to}} understand drug side effects is necessary to reduce attrition rates during drug development {{as well as the}} risk of discovering novel side effects in available drugs. Today, most investigations deal with isolated side effects and overlook possible redundancy and their frequent co-occurrence. Results: In this work, drug annotations are collected from SIDER and DrugBank databases. Terms describing individual side effects reported in SIDER are clustered with a semantic similarity measure into term clusters (TCs). Maximal frequent itemsets are extracted from the resulting drug x TC binary table, leading to the identification of what we call side-effect profiles (SEPs). A SEP is defined as the longest combination of TCs which are shared by a significant number of drugs. Frequent SEPs are explored on the basis of integrated drug and <b>target</b> <b>descriptors</b> using two machine learning methods: decision-trees and inductive-logic programming. Although both methods yield explicit models, inductive-logic programming method performs relational learning and is able to exploit not only drug properties but also background knowledge. Learning efficiency is evaluated by cross-validation and direct testing with new molecules. Comparison of the two machine-learning methods shows that the inductive-logic-programming method displays a greater sensitivity than decision trees and successfully exploi...|$|R
3000|$|Object {{representation}} {{is one of}} major components for a typical visual tracker. Extensive researches have been done on this topic. Recently Tuzel et al. [13, 14] proposed an elegant and simple solution to integrate multiple features. In this method, covariance matrix was employed to represent the target. Using a covariance matrix to represent the <b>target</b> (region covariance <b>descriptor)</b> has many advantages: ([...] [...]...|$|R
40|$|This thesis {{investigates the}} discursive {{construction}} of gender identities {{through the use}} of abusive language in YouTube comments sections. The study attempts to answer the following overarching research question: How is abusive language used in the construction of gendered identities by Arabic-speaking posters on YouTube? A corpus of more than 2 million words of YouTube comments is constructed to study discourses involving terms of abuse and abusive swearing targeted at males and females. These discourses are analysed by utilising a combination of tools. <b>Target</b> <b>descriptors</b> and activation/passivation are used to examine the roles constructed for men and for women. Differential usage of abusive language is investigated by looking at the (non) existence of corresponding masculine and feminine terms of abuse, the behaviour of gendered terms of abuse in different domains, and contrastive collocation of masculine/feminine-marked words. The pragmatic functions of abusive language are studied by examining cultural scripts of abusive language against men and women. The main method used in this thesis is a qualitative analysis of concordance lines where the terms of abuse occur. However, frequency analysis is also employed, to produce a wordlist of masculine- and feminine-marked terms of abuse and to compare the frequencies of terms of abuse in my corpus. The results show that men and women are represented as having different identities. Men are mainly constructed as the social actors who have and abuse power (especially in relation to politics and religion). On the other hand, sexual morality is discursively constructed as the most integral component of female gender identity...|$|R
40|$|In {{this paper}} we present ongoing work towards a program-ming {{framework}} for heterogeneous hardware- and software environments. Our framework aims at improving programma-bility and portability for heterogeneous many-core systems via a Platform Description Language (PDL) for expressing architectural patterns and platform information. We devel-oped a prototypical code generator that takes as input an an-notated serial task-based program and outputs, parametrized via PDL descriptors, code {{for a specific}} target heterogeneous computing system. By varying the <b>target</b> PDL <b>descriptor,</b> code for different target configurations can be generated with-out the need to modify the input program. We utilize a simple task-based programming model for demonstration of our approach and present preliminary results indicating its applicability on a state-of-the-art heterogeneous system...|$|R
40|$|International audienceSerine proteases, {{implicated in}} {{important}} physiological functions, {{have a high}} intra-family similarity, which leads to unwanted off-target effects of inhibitors with insufficient selectivity. However, the availability of sequence and structure data has now {{made it possible to}} develop approaches to design pharmacological agents that can discriminate successfully between their related binding sites. In this study, we have quantified the relationship between 12 625 distinct protease inhibitors and their bioactivity against 67 targets of the serine protease family (20 213 data points) in an integrative manner, using proteochemometric modelling (PCM). The benchmarking of 21 different <b>target</b> <b>descriptors</b> motivated the usage of specific binding pocket amino acid descriptors, which helped in the identification of active site residues and selective compound chemotypes affecting compound affinity and selectivity. PCM models performed better than alternative approaches (models trained using exclusively compound descriptors on all available data, QSAR) employed for comparison with R 2 /RMSE values of 0. 64 AE 0. 23 / 0. 66 AE 0. 20 vs. 0. 35 AE 0. 27 / 1. 05 AE 0. 27 log units, respectively. Moreover, the interpretation of the PCM model singled out various chemical substructures responsible for bioactivity and selectivity towards particular proteases (thrombin, trypsin and coagulation factor 10) in agreement with the literature. For instance, absence of a tertiary sulphonamide was identified to be responsible for decreased selective activity (by on average 0. 27 AE 0. 65 pChEMBL units) on FA 10. Among the binding pocket residues, the amino acids (arginine, leucine and tyrosine) at positions 35, 39, 60, 93, 140 and 207 were observed as key contributing residues for selective affinity on these three targets...|$|R
40|$|International audienceBackground Drug {{side effects}} {{represent}} a common reason for stopping drug development during clinical trials. Improving {{our ability to}} understand drug side effects is necessary to reduce attrition rates during drug development {{as well as the}} risk of discovering novel side effects in available drugs. Today, most investigations deal with isolated side effects and overlook possible redundancy and their frequent co-occurrence. Results In this work, drug annotations are collected from SIDER and DrugBank databases. Terms describing individual side effects reported in SIDER are clustered with a semantic similarity measure into term clusters (TCs). Maximal frequent itemsets are extracted from the resulting drug x TC binary table, leading to the identification of what we call side-effect profiles (SEPs). A SEP is defined as the longest combination of TCs which are shared by a significant number of drugs. Frequent SEPs are explored on the basis of integrated drug and <b>target</b> <b>descriptors</b> using two machine learning methods: decision-trees and inductive-logic programming. Although both methods yield explicit models, inductive-logic programming method performs relational learning and is able to exploit not only drug properties but also background knowledge. Learning efficiency is evaluated by cross-validation and direct testing with new molecules. Comparison of the two machine-learning methods shows that the inductive-logic-programming method displays a greater sensitivity than decision trees and successfully exploit background knowledge such as functional annotations and pathways of drug targets, thereby producing rich and expressive rules. All models and theories are available on a dedicated web site. Conclusions Side effect profiles covering significant number of drugs have been extracted from a drug ×side-effect association table. Integration of background knowledge concerning both chemical and biological spaces has been combined with a relational learning method for discovering rules which explicitly characterize drug-SEP associations. These rules are successfully used for predicting SEPs associated with new drugs...|$|R
40|$|Tyt. z ekranu tytułowego. Praca doktorska. Akademia Górniczo-Hutnicza im. Stanisława Staszica (Kraków), 2012. Zawiera bibliogr. i indeks. Dostępna także w wersji drukowanej. Tryb dostępu: Internet. Graph analysis, graph {{structural}} properties, <b>descriptor</b> <b>target,</b> domain <b>descriptors,</b> spectral descriptors, local, global descriptors, statistical descriptors, graph matching, general remarks, isomorphism, graph canonization problem, {{overview of}} graph comparison algorithms, graph data, types of graphs, graphs representing patterns, images, shapes, scene organization, structural patterns, applications, graphs in biology, metabolic networks, graphs in medicine, vascular networks, graphs in other disciplines, contribution, invariants of distance k-graphs for graph embedding, distance k-graphs, b-matrices, vertex distance k-graphs, vertex b-matrix, edge distance k-graphs, edge b-matrix, weighted graphs, shortest paths algorithms on GPU, graph descriptors from distance k-graphs, related descriptors, transformations, experiments, controlled structural errors, artificial graphs, metabolic networks, satellite photos, mutagenicity dataset, discussion, Graph Investigator application, related work, program description, Input/Output, graph descriptors, visualization, graph analysis, other features, sample use cases, normal brain vascular network, tracking angiogenesis simulation, efficient graph comparison, visualization using GPU, distance-based graph invariants, short introduction to CUDA, graph algorithms on GPU, All-Pair Shortest-Paths, Breadth-First Search, linear algebra of graph matrices, applications, tumor vascular networks, GPU-enabled computation of graph invariants, graph descriptors, efficiency, Wiener index, Clustering Coefficient, weighted clustering coefficient, average path length, graph diameter, Subgraph Count, Betweenness Centrality, Random Walks Betweenness Centrality, information of vertex degrees, Estrada Index, density, volume, cheeger constant, heat kernel invariants, Graph Investigator, general graph descriptors, vertex descriptors, edge descriptors, clustering validation indices, Davies-Bouldin Index, Rand Index, Commute Time, notatio...|$|R
40|$|We {{consider}} three alternative {{procedures for}} the automatic indexing of medical documents using MeSH thesaurus identifiers as <b>target</b> units (document <b>descriptors).</b> Rather than considering complete words {{as the starting point}} of the indexing procedure, we here propose morphologically plausible subwords as basic units from which MeSH terms are derived. We describe the morphological segmentation and normalization procedures, as well as the mappings from sub-words to MeSH terms, and discuss results from an evaluation carried out on a German-language corpus...|$|R
40|$|This paper {{presents}} a new edge-based technique for image alignment, combining Fourier Descriptors (FD) and the Iterative Closest Point (ICP) computation into an accurate and robust processing pipeline. Once edges are {{identified in the}} reference and <b>target</b> images, Fourier <b>Descriptors</b> are used to simultaneously determine edge correspondence and estimate the transformation parameters. Subsequently, an ICP computation is applied to further improve the alignment results. Using Fourier Descriptors in combination with a reliable distance matrix, corresponding edge pairs can be reliably detected for all identified edges. (C) 2008 Published by Elsevier B. V...|$|R
40|$|The {{introduction}} of the Marine Strategy Framework Directive (MSFD) with its focus on an Ecosystem Approach places {{an emphasis on the}} human dimensions of environmental problems. Human activities may be the source of marine degradation, but may also be adversely affected should degradation compromise the provision of ecosystem services. The MSFD marks a shift away from management aiming to restore past, undegraded states toward management for Good Environmental Status (GEnS) based on delivery of marine goods and services. An example relating ecosystem services to criteria for Good Environmental Status is presented for eutrophication, a long recognised problem in many parts of Europe's seas and specifically <b>targeted</b> by <b>descriptors</b> for GEnS. Taking the North Sea as a case study the relationships between the eutrophication criteria of the MSFD and final and intermediate marine ecosystem services are examined. Ecosystem services are valued, where possible in monetary terms, in order to illustrate how eutrophication affects human welfare (economic externalities) through its multiple effects on ecosystem services. © 2013 Elsevier Ltd...|$|R
40|$|A novel {{approach}} to extract <b>target</b> motion <b>descriptors</b> in multi-camera video surveillance systems is presented. Using two static surveillance cameras with partially overlapped {{field of view}} (FOV), control points (unique points from each camera) are identified in regions of interest (ROI) from both cameras footage. The control points within the ROI are matched for correspondence and a meshed Euclidean distance based signature is computed. A depth map is estimated using disparity of each control pair and the ROI is graded into number of regions {{with the help of}} relative depth information of the control points. The graded regions of different depths will help calculate accurately the pace of the moving target and also its 3 D location. The advantage of estimating a depth map for background static control points over depth map of the target itself is its accuracy and robustness to outliers. The performance of the algorithm is evaluated in the paper using several test sequences. Implementation issues of the algorithm onto the TI DaVinci DM 6446 platform are considered in the paper. 1...|$|R
40|$|In {{the first}} step of the project a program "ChemSpaceShuttle" was {{developed}} which can be used for visualization and data mining of compound libraries during virtual screening. The main functions implemented in this programm were multilayer feedforward neural network, self-organizing net (SOM), and PLS. In the next part of the project the influence and importance of descriptor scaling for the classification of drugs and non-drugs was investigated. The descriptor scaling could improve the classification performance. Multi-space classification was used for prediction of GPCR Ligands. Improved performance could also be observed with this method. Here the prediction results of sub-spaces were collected to a jury net for the last prediction. The prediction of ligands was improved with the next developed method of "Multitarget dependent transformation". With this method a <b>target</b> dependend <b>descriptor</b> vector transformation was performed. New feature were implemented in the program "ChemSpaceShuttle". The main functions were the structure visualization after the classification and the similarity search based on SMARTS fingerprint of the software library OpenBabel. The Implemented neural networks were used for T-cell epitope prediction. Here new T-cell epitopes were predicted...|$|R
40|$|Proteochemometrics (PCM) is a {{predictive}} bioactivity modelling {{method to}} simultaneously model the bioactivity of multiple ligands against multiple targets. Therefore, PCM permits {{to explore the}} selectivity and promiscuity of ligands on biomolecular systems of different complexity, such proteins or even cell-line models. In practice, each ligand-target interaction is encoded by the concatenation of ligand and <b>target</b> <b>descriptors.</b> These descriptors are then used to train a single machine learning model. This simultaneous inclusion of both chemical and target information enables the extra- and interpolation to predict the bioactivity of compounds on targets, which can be not present in the training set. In this thesis, a methodological advance {{in the field is}} firstly introduced, namely how Bayesian inference (Gaussian Processes) can be successfully applied in the context of PCM for (i) the prediction of compounds bioactivity along with the error estimation of the prediction; (ii) the determination of the applicability domain of a PCM model; and (iii) the inclusion of experimental uncertainty of the bioactivity measurements. Additionally, the influence of noise in bioactivity models is benchmarked across a panel of 12 machine learning algorithms, showing that the noise in the input data has a marked and different influence on the predictive power of the considered algorithms. Subsequently, two R packages are presented. The first one, Chemically Aware Model Builder (camb), constitues an open source platform for the generation of predictive bioactivity models. The functionalities of camb include : (i) normalized chemical structure representation, (ii) calculation of 905 one- and two-dimensional physicochemical descriptors, and of 14 fingerprints for small molecules, (iii) 8 types of amino acid descriptors, (iv) 13 whole protein sequence descriptors, and (iv) training, validation and visualization of predictive models. The second package, conformal, permits the calculation of confidence intervals for individual predictions in the case of regression, and P values for classification settings. The usefulness of PCM to concomitantly optimize compounds selectivity and potency is subsequently illustrated in the context of two application scenarios, which are: (a) modelling isoform-selective cyclooxygenase inhibition; and (b) large-scale cancer cell-line drug sensitivity prediction, where the predictive signal of several cell-line profiling data is benchmarked (among others) : basal gene expression, gene copy-number variation, exome sequencing, and protein abundance data. Overall, the application of PCM in these two case scenarios let us conclude that PCM is a suitable technique to model the activity of ligands exhibiting uncorrelated bioactivity profiles across a panel of targets, which can range from protein binding sites (a), to cancer cell-lines (b). Proteochemometrics (PCM) est une bioactivité prophétique la méthode posante de simultanément modeler la bioactivité de ligands multiple contre des objectifs multiples [...] ...|$|R
40|$|This thesis {{picks up}} from the full-wave spectral-domain {{formalism}} developed at ITA's Antenna and Propagation Laboratory (LAP) {{for the analysis of}} electromagnetic radiation, scattering and propagation in structures composed of multiple layers made up of complex media. Besides the analysis and design of planar, cylindrical and spherical microstrip antennas, the methodology has also been successfully extended to remote sensing applications. Either way, a representative model needs to account for the geometric and electromagnetic characteristics of the particular structure, and for the electromagnetic excitation mechanism. Nonetheless, the focus so far had been on applications whose sources were distributed along the layer interfaces. So the goal in Chapters 2 and 3 is to extend the model coverage to vertical electric and magnetic sources embedded in planar structures made up of isotropic dielectric layers. Their spectral Green's functions are calculated using the auxiliary vector potential approach. In addition, horizontal electrical and magnetic sources are analyzed using LAP's technique, thus providing a consistent formalism to handle any combination. The limit case of infinitesimal current elements is derived, {{as well as that of}} a dipole holding a sinusoidal current distribution. Careful analysis of the boundary conditions affecting the tangential field components produces two uncoupled systems, one on the spectral electric field amplitudes, and another on the magnetic field, cutting down the mathematical workload and processing time. Hybrid microstrip antennas provide interesting means to overcome conventional antenna drawbacks, such as the significant H-plane cross-polarization level. Probe-fed hybrid microstrip antennas are analyzed in Chapter 4 via the resonant cavity and surface electric current models. The primary goal of systematically determining adequate design criteria is achieved and proved by predesigning an antenna for operation in 2. 45 GHz. The design criteria are also validated by excellent experimental results for an antenna prototype that was manufactured and tested. As a side benefit, the use of analytical models permits the analysis of effects such as a radiation pattern asymmetry in the E plane, and a systematic study of its cross-polarization. Stratified layered structures containing scattering elements are used for modeling distributed natural targets. Their electromagnetic properties can be synthesized by the scattering matrix, which describes the dependence on signal polarization. From the scattering matrix, mathematical models for natural targets and other polarimetric <b>target</b> <b>descriptors</b> can be derived. Chiral effects and the stratified layer representation for certain natural targets are accounted for in the analysis presented in Chapter 5. From the target modeling, the scattering matrix elements are determined for planar, thin electric and magnetic dipoles embedded in a three-layer planar structure consisting of a chiral layer between free space and an isotropic ground. In addition, the full-wave equivalent circuit technique was efficiently utilized in the determination of the Green's functions of stratified structures...|$|R
40|$|Wide {{availability}} of image processing software makes counterfeiting become an easy and low-cost way to distort or conceal facts. Driven by great needs for valid forensic technique, many {{methods have been}} proposed to expose such forgeries. In this paper, we proposed an integrated algorithm which was able to detect two commonly used fraud practices: copy-move and splicing forgery in digital picture. To achieve this <b>target,</b> a special <b>descriptor</b> for each block was created combining the feature from JPEG block artificial grid with that from noise estimation. And forehand image quality assessment procedure reconciled these different features by setting proper weights. Experimental results showed that, compared to existing algorithms, our proposed method is effective on detecting both copy-move and splicing forgery regardless of JPEG compression ratio of the input image...|$|R
40|$|In many {{applications}} of sound transformation, such as sound design, mixing, mastering, and composition the user interactively searches for appropriate parameters. However, automatic applications of sound transformation, such as mosaicing, may require choosing parameters without user intervention. When the target {{can be specified}} by its synthesis context, or by example (from features of the example), “adaptive effects ” can provide such control. But there exist few general strategies for building adaptive effects from arbitrary sets of transformations and <b>descriptor</b> <b>targets.</b> In this study, we decouple the usually direct link between analysis and transformation in adaptive effects, attempting to include more diverse transformations and descriptors in adaptive transformation, if {{at the cost of}} additional complexity or difficulty. We build an analytic model of a deliberately simple transformation-descriptor (TD) domain, and show some preliminary results. input db descriptors (db) input soun...|$|R
40|$|Abstract. Many {{computer}} vision applications need keypoint correspondence between images under different view conditions. Generally speaking, traditional algorithms target applications with either good performance in invariance to affine transformation or speed of computation. Nowadays, the widely usage of {{computer vision}} algorithms on handle {{devices such as}} mobile phones and embedded devices with low memory and computation capability has proposed a <b>target</b> of making <b>descriptors</b> faster to computer and more compact while remaining robust to affine transformation and noise. To best address the whole process, this paper covers keypoint detection, description and matching. Binary descriptors are computed by comparing the intensities of two sampling points in image patches and they are matched by Hamming distance using an SSE 4. 2 optimized popcount. In experiment results, we will show that our algorithm is fast to compute with lower memory usage and invariant to view-point change, blur change, brightness change, and JPEG compression...|$|R
50|$|An access token is {{generated}} by the logon service when a user logs on to the system and the credentials provided by the user are authenticated against the authentication database. The authentication database contains credential information required to construct the initial token for the logon session, including its user id, primary group id, all other groups it is part of, and other information. The token {{is attached to the}} initial process created in the user session and inherited by subsequent processes created by the initial process. Whenever such a process opens a handle to any resource which has access control enabled, Windows reconciles the data in the <b>target</b> object's security <b>descriptor</b> with the contents of the current effective access token. The result of this access check evaluation is an indication of whether any access is allowed and, if so, what operations (read, write/modify, etc.) the calling application is allowed to perform.|$|R
40|$|Abstract The EU Marine Strategy Framework Directive (MSFD) {{requires}} that Good Environmental Status (GEnS), is achieved for European seas by 2020. These may deviate from GEnS, its 11 <b>Descriptors,</b> <b>targets</b> and baselines, due to endogenic managed pressures (from activities within an area) and externally due to exogenic unmanaged pressures (e. g. climate change). Conceptual models detail the likely or perceived changes expected on marine biodiversity and GEnS Descriptors {{in the light}} of climate change. We emphasise that marine management has to accommodate ‘shifting baselines’ caused by climate change particularly during GEnS monitoring, assessment and management and ‘unbounded boundaries’ given the migration and dispersal of highly-mobile species. We suggest climate change may prevent GEnS being met, but Member States may rebut legal challenges by claiming that this is outside its control, force majeure or due to ‘natural causes’ (Article 14 of the MSFD). The analysis is relevant to management of other global seas...|$|R
40|$|This {{paper is}} about a {{technique}} which generally reduce the dimensionality of data generated automatically, enabling analyzes with more consistent results and optimizing the validation in the field. A Principal Component Analysis {{was used in this}} study to separate and reduce dimensionality of the reflectance values of the <b>targets</b> or <b>descriptors</b> of spectral, spatial and textural extracted from Landsat 5 TM image. In this study, are used images of two landscape units located the hydrographic basin of Pitangui River in the city of Ponta Grossa / PR in order to check the variables with the highest coefficients correlation, since those having higher percentage denote greater similarities with the study units can be made a recognition characteristics as physical forms and locals. The descriptors were coming from Landsat 5 TM in the compositions and spectral R 5 G 4 B 3 R 5 G 4 B 3 with insertion MDT equivalent of band 4. The dimensionality of the data was reduced from 39 (R 5 G 4 B 3 composition) and 35 (composition R 5 G 4 B 3 and band 4 MDT) for 17 variables or descriptors, which quantitatively characterize the landscape units in this study. Of the 17 variables final, 6 are mainly characterized by compact shapes, solid, convex among others, 9 are represented by digital values and 2 are represented by means of textures. Key-words: remote sensing, automatic axtraction, reducing dimensionality, correlation, landscape units, sensoriamento remoto, extração automática, redução de dimensionalidade, correlação, unidades de paisagem. Pages: 3986 - 399...|$|R
40|$|The overall aim of {{this thesis}} is to predict {{biological}} properties of molecules. The thesis first reports {{on the use of}} similarity searching for property prediction. The predictions were made by taking the value of a compound's k-nearest neighbours found from a similarity search. The initial work used structural descriptors, followed by a compound's property values (e. g. activity values across several different <b>targets)</b> as <b>descriptors.</b> The use of property value descriptors instead of classical structural descriptors showed promising results for molecular property prediction, but due to the datasets available a concrete conclusion could not be made about this technique. The use of Turbo Similarity Searching (TSS) was then investigated with the use of k-nearest neighbour predictions based on structural descriptors.. The second part of the thesis investigated the use of Free-Wilson Analysis (FWA) in conjunction with lead-optimisation and library design. It was shown that datasets can be classified into three classes: those which are successful with respect to FWA; those which are not; and those which are partially successful. For the partially successful cases it was demonstrated {{that it is possible to}} identify R-groups which do not have an independent contribution to the property being investigated. It was also found that 30 % of the compounds in a full combinatorial library are sufficient to generate a successful model. Ranking the R-groups at a position on a scaffold according to their property contributions (for several different properties) can be used to generate an R-grollp profile for the R-groups, as long as a FWA is successful for the properties being considered. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
40|$|The European Marine Strategy Framework Directive (MSFD) {{requires}} EU Member States (MS) {{to achieve}} the Good Environmental Status (GEnS) of their seas by 2020. This ambition can only be fulfilled {{if there is a}} common understanding of what GEnS entails. This paper addresses this question especially with regard to the level where <b>targets</b> are set (<b>descriptors,</b> criteria, and indicators), to scales for assessments (i. e. regional, sub-divisions, water bodies, sites specific), and to difficulties in putting into practice the GEnS concept. Accordingly, we propose a refined and more operational definition of GEnS and we indicate the data and information needs related to all parts of that definition. We then indicate the options for determining when GEnS has been met, acknowledge the data and information needs for each option, and recommend a combination of existing quantitative targets and expert judgement. We take the view that the implementation of the MSFD needs to be less-complex than shown for other similar directives, can be based largely on existing data and information and can be centred on the activities of the Regional Seas Conventions. JRC. H. 1 -Water Resource...|$|R
40|$|In this paper, a {{comparison}} of five {{state of the art}} region detectors is presented with regard to localization accuracy in position and region shape. Based on carefully estimated ground truth homographies, correspondences between frames are assigned using geometrical region overlap. Significant differences between detectors exist, {{depending on the type of}} images. Also, it is shown that localization accuracy linearly depends on region scale for some detectors, which may thus be used as a pre-selection criterion for the removal of error-prone regions. The presented results serve as a supplement to existing comparative studies, and can be used to facilitate the selection of an appropriate detector for a specific <b>target</b> application. When <b>descriptor</b> distance is used as assignment criterion instead of region overlap, a different set of correspondences results with lower accuracy. Set differences (and thus localization accuracy) are directly related to the density of regions in a local neighborhood. Based on the latter, a novel measure for the identification of error-prone regions- shape uniqueness- is introduced. In contrast to existing methods that are based on the descriptor distance of region correspondences, the new measure is pre-computed on each image individually. Thus, the complexity of the subsequent matching task can be significantly reduced. 1...|$|R
40|$|The European Marine Strategy Framework Directive (MSFD) {{requires}} EU Member States (MS) {{to achieve}} Good Environmental Status (GEnS) of their seas by 2020. We {{address the question}} of what GEnS entails especially with regard to the level at which <b>targets</b> are set (<b>descriptors,</b> criteria, indicators), to scales for assessments (regional, sub-divisions, site-specific), and to difficulties in putting into practice the GEnS concept. We propose a refined and operational definition of GEnS, indicating the data and information needed to all parts of that definition. We indicate the options for determining when GEnS has been met, acknowledge the data and information needs for each option, and recommend a combination of existing quantitative targets and expert judgement. We think that the MSFD implementation needs to be less complex than shown for other similar directives, can be based largely on existing data and can be centred on the activities of the Regional Seas Conventions. This manuscript has resulted from the DEVOTES (DEVelopment Of innovative Tools for understanding marine biodiversity and assessing Good Environmental Status) project funded by the European Union under the 7 th Framework Programme, ‘The Ocean of Tomorrow’ Theme (Grant Agreement No. 308392), www. devotesproject. eu. This paper is contribution number 654 from AZTITecnalia (Marine Research Division) ...|$|R
40|$|Teixeira, Heliana [...] . et. al. [...] International Council for the Exploration of the Sea (ICES) Annual Science Conference, 21 - 25 September 2015, Copenhagen, Denmark. [...] 2 pages, 1 figureA Catalogue of Biodiversity Indicators {{useful for}} the {{implementation}} of the Marine Strategy Framework Directive (MSFD) was developed by the DEVOTES FP 7 Project with the aim of providing the basis for assessing the environmental status of European seas. It is available online through the DEVOTool 0. 64 software application that allows navigating a database of indicators related to the following MSFD descriptors: biological biodiversity, non-indigenous species, food webs, and seafloor integrity. The catalogue (v. 6) contains over 500 indicators used by different initiatives, in national and international contexts. A comprehensive overview of these indicators is given: descriptions, data requirements, developmental status, geographical coverage and applicable habitats, biodiversity components and <b>descriptors</b> <b>targeted,</b> and related human pressures. The DEVOTool provides a query and analysis function for browsing the metadata, extracting and ranking lists of indicators best fulfilling pre-set criteria; enabling users to search, for example, for indicators suitable to fill in an identified gap or address a particular pressure in a marine area. The major strengths and gaps of the indicator set (at EU level) allow to focus the development of new indicators where it is most urgently needed, and to foster transfer of know-how across marine regions. Peer Reviewe...|$|R
40|$|Absorption, Distribution, Metabolism, Excretion and Toxicity (ADMET) {{properties}} and adverse effects determine {{the success of}} each drug. These factors {{play an important role}} in the late-stage failure of drug candidates and withdrawal of approved drugs from the market. In early drug discovery research, computational methods along with the integration of large, clean and safe compound data are effective approaches to minimizing the risk of late-stage attrition and reducing the number of safety issues. This thesis describes a relational database called Integrated Database of ADMET and Adverse effects for Predictive Modeling based on FDA approved drug data (IDAAPM). This database is designed to integrate approved drug data, including drug approval information, ADMET, adverse effects, chemical structures and molecular <b>descriptors,</b> <b>targets</b> and binding affinity data including their associated scientific literature references. Moreover, the database is connected to a responsive website interface, and coupled with a modern data analytic platform (KNIME). Currently, IDAAPM contains FDA approval applications (19, 226), products (31, 815), active ingredients (2, 505), ADMET properties (1, 076), drug adverse effect pairs (2, 472, 770), molecular structures (1, 629), drug targets (2, 220) and drug target interactions (36, 963). Therefore, IDAAPM is a unique and comprehensive platform that provides safe compound data and enables the researcher to run a predictive analysis of their compounds of interest in terms of ADMET and adverse effect properties. IDAAPM can be accessed through a web browser at [URL] or a downloaded KNIME workflow at [URL]...|$|R
40|$|Many mission {{scenarios}} for nanosatellites and CubeSat hardware {{have already been}} created that will require autonomous target tracking and rendezvous maneuvers {{in close proximity to}} other orbiting objects. While many existing hardware and software designs require the use of rangefinders or laser-based sensors to identify and track nearby objects, the size and power limitations of a CubeSat make a simple monocular system greatly preferable, so long as reliable identification can still be carried out. This presentation details the development and testing of an embedded algorithm for visually identifying the shape of a target and tracking its movement over time, which can include rotation about any axis. A known three-dimensional geometric model is required for use as a reference when identifying a <b>target.</b> First, feature <b>descriptors</b> implemented in the OpenCV framework are used to create a sparse point cloud of features from a nearby object. Using structure-from-motion (SfM) methods, feature points obtained over successive images can be triangulated in three dimensions to obtain a pose estimate. Statistical shape recognition is then used to identify the object based on features from available three-dimensional models. While more feature points make the identification more accurate, more computing power is required, and within the limitations of an embedded system, the balance of speed and accuracy is evaluated. The algorithm is designed to be efficient enough for feasible operation using embedded hardware useable on a CubeSat, and can be used with appropriate hardware for real-time operation. An overview of the algorithm and vision system design is given, and some initial test results for a simulated orbital rendezvous scenario are provided for some indication of the performance of these methods. Applications of interest for this type of algorithm include external monitoring of other spacecraft, robotic capture and docking, and space debris removal...|$|R
