6|346|Public
40|$|A well-designed {{nanostructure}} {{of transition}} metal oxides has {{been regarded as}} a key to solve their problems of large volume changes during lithium insertion-desertion processes which are associated with pulverization of the electrodes and rapid capacity decay. Here we report an effective approach for the fabrication of porous iron oxide ribbons by controlling the nucleation and growth of iron precursor onto the graphene surface and followed by an annealing treatment. The resultant iron oxide ribbons possess large aspect ratio, porous structure, <b>thin</b> <b>feature</b> and enhanced open-edges. These characteristics are favorable for the fast diffusion of lithium ions and electrons, and meanwhile can effectively accommodate the volume change of iron oxides during the cycling processes. As a consequence, the graphene-induced porous iron oxide ribbons exhibit a high reversible capacity and excellent cycle stability for lithium storage...|$|E
40|$|We propose an {{approach}} to the recognition of printed music scores using the inverse process of music writing. A composer would normally write a note head followed by possibly a connected stem and beams and lastly other markings like ties and slurs; we would first pick out long and <b>thin</b> <b>feature</b> like slurs and ties, follow by beams, and then stems. In effect, complex and inter-connected musical symbols such as beamed quaver groups and even crochets and minims are disassembled into primitive such as noteheads, stems and beams before recognition. In this paper, we discuss the strategy in recognising sub-segmented primitives, and the re-assembly process which reconstructs low level graphical primitives back to musical symbols. The sub-segmentation process proves to be worthwhile since many primitives complement each other and high level musical theory can be employed to enhance the recognition process. Keywords: document analysis, OCR, score recognition 1 Introduction Although [...] ...|$|E
40|$|Smoothed {{particle}} hydrodynamics (SPH) is efficient, mass preserving, {{and flexible}} in handling topological changes. However, small-scale thin features {{are difficult to}} simulate in SPH-based free surface flows, due {{to a number of}} robustness and stability issues. In this paper, we address this problem from two perspectives: the robustness of surface forces and the numerical instability of thin features. We present a new surface tension force scheme based on a free surface energy functional, under the diffuse interface model. We develop an efficient way to calculate the air pressure force for free surface flows, without using air particles. Compared with previous surface force formulae, our formulae are more robust against particle sparsity in <b>thin</b> <b>feature</b> cases. To avoid numerical instability on thin features, we propose to adjust the internal pressure force by estimating the internal pressure at two scales and filtering the force using a geometry-aware anisotropic kernel. Our result demonstrates the effectiveness of our algorithms in handling a variety of small-scale thin liquid features, including thin sheets, thin jets, and water splashes...|$|E
5000|$|... #Subtitle level 4: The Fat & The <b>Thin</b> <b>featuring</b> Watson T Brown ...|$|R
60|$|Hetty {{bent over}} her desk for a time. Then {{she looked up}} and her <b>thin</b> <b>features</b> were white and drawn with anxiety.|$|R
40|$|Figure 1 : Our {{algorithm}} efficiently produces detailed thin {{sheets and}} liquid droplets, even with low-resolution fluid simulations — The main corridor {{in this example}} is only 30 fluid cells wide. We propose a mesh-based surface tracking method for fluid animation that both preserves fine surface details and robustly adjusts the topology of the surface {{in the presence of}} arbitrarily <b>thin</b> <b>features</b> like sheets and strands. We replace traditional re-sampling methods with a convex hull method for connecting surface features during topological changes. This technique permits arbitrarily <b>thin</b> fluid <b>features</b> with minimal re-sampling errors by reusing points from the original surface. We further reduce re-sampling artifacts with a subdivision-based mesh-stitching algorithm, and we use a higher order interpolating subdivision scheme to determine the location of any newly-created vertices. The resulting algorithm efficiently produces detailed fluid surfaces with arbitrarily <b>thin</b> <b>features</b> while maintaining a consistent topology with the underlying fluid simulation...|$|R
40|$|Features {{that are}} much wider than they are thick, like thin plates, are numerically {{difficult}} to model with the material models that describe solid material behavior. In Finite Element Analysis, this problem is often handled by using 1 D and 2 D elements that resist bending without explicitly modeling thickness. Peridynamics is an alternate formulation of continuum mechanics that has shown great ability to model solid structures, but reduced-order peridynamic bending models remain underdeveloped. An example proposed by Silling in 2007 suggests a solution: a nonordinary, state-based peridynamic material model that directly resists bending deformation by resisting changes in the angles between peridynamic bonds. Unlike earlier peridynamic models that resist bond extension, this new model resists bending without using several nodes through the thickness of a <b>thin</b> <b>feature.</b> Beginning from the simplest beam, this material model is extended to plates and then the combined in-plane and bending deformation of simple shells. Because failure modeling is the main motivation for peridynamic modeling, a simple mechanism for brittle failure is also presented. The development of thin-feature models promises to extend the usability of peridynamic modeling to a broader class of problems...|$|E
40|$|In this paper, {{we first}} {{investigate}} why typical two-stage methods {{are not as}} fast as single-stage, fast detectors like YOLO and SSD. We find that Faster R-CNN and R-FCN perform an intensive computation after or before RoI warping. Faster R-CNN involves two fully connected layers for RoI recognition, while R-FCN produces a large score maps. Thus, the speed of these networks is slow due to the heavy-head design in the architecture. Even if we significantly reduce the base model, the computation cost cannot be largely decreased accordingly. We propose a new two-stage detector, Light-Head R-CNN, to address the shortcoming in current two-stage approaches. In our design, we make the head of network as light as possible, by using a <b>thin</b> <b>feature</b> map and a cheap R-CNN subnet (pooling and single fully-connected layer). Our ResNet- 101 based light-head R-CNN outperforms state-of-art object detectors on COCO while keeping time efficiency. More importantly, simply replacing the backbone with a tiny network (e. g, Xception), our Light-Head R-CNN gets 30. 7 mmAP at 102 FPS on COCO, significantly outperforming the single-stage, fast detectors like YOLO and SSD on both speed and accuracy. Code will be made publicly available...|$|E
40|$|The {{effect of}} a {{frequency}} dependent shift of the VLBI core position (known as the "core shift") was predicted {{more than three decades}} ago and has since been observed in a few sources, but often within a narrow frequency range. This effect has important astrophysical and astrometric applications. To achieve a broader understanding of the core shift effect and the physics behind it, we conducted a dedicated survey with NRAO's Very Long Baseline Array (VLBA). We used the VLBA to image 20 pre-selected sources simultaneously at nine frequencies in the 1. 4 - 15. 4 GHz range. The core position at each frequency was measured by referencing it to a bright, optically <b>thin</b> <b>feature</b> in the jet. A significant core shift has been successfully measured in each of the twenty sources observed. The median value of the core shift is found to be 1. 21 mas if measured between 1. 4 and 15. 4 GHz, and 0. 24 mas between 5. 0 and 15. 4 GHz. The core position, r, as a function of frequency, n, is found to be consistent with an r n^- 1 law. This behavior is predicted by the Blandford & Koenigl model of a purely synchrotron self-absorbed conical jet in equipartition. No systematic deviation from unity of the power law index in the r(n) relation has been convincingly detected. We conclude that neither free-free absorption nor gradients in pressure and/or density in the jet itself and in the ambient medium surrounding the jet {{play a significant role in}} the sources observed within the 1. 4 - 15. 4 GHz frequency range. These results support the interpretation of the parsec-scale core as a continuous Blandford-Koenigl type jet with smooth gradients of physical properties along it. Comment: 31 pages, 6 figures, 5 tables; accepted to Astronomy & Astrophysic...|$|E
50|$|Milton Johns (born 13 May 1938) is an English actor whose <b>thin</b> <b>features</b> {{and talent}} for obsequious or oily {{characters}} has often influenced the many television parts he has received. He {{trained at the}} Bristol Old Vic Theatre School.|$|R
40|$|Micromilling {{of metal}} {{structures}} with ‘thin’ features represents {{a major challenge}} towards broadening {{the use of this}} technology in a range of microengineering applications, for example in producing multi-channel microstructures, housing for mechanical microdevices, and surgical instruments. The most common <b>thin</b> <b>features</b> seen in microengineering products are ribs and webs. This research identifies the main factors affecting the reliability of micromilling technology when employed for the machining of microcomponents incorporating <b>thin</b> <b>features.</b> The general principles that should be followed in designing machining strategies for such features are discussed in this article. Taking these general principles into account, new strategies are proposed to reduce the negative effects of identified factors on part quality and, at the same time, to overcome some of the problems {{associated with the use of}} conventional machining strategies for micromilling of ribs and webs. To implement and verify them, initially the milling operations were programmed manually, and then a special CAM module was developed for their automatic generation. Finally, this article reports the validation of the proposed strategies for machining <b>thin</b> <b>features,</b> which was carried out on a specially designed test part...|$|R
60|$|He smiled deprecatingly {{but did not}} speak. He was a tall, lean man, quite round-shouldered and of studious appearance. He wore double eyeglasses, {{underneath}} {{which his}} eyes were somewhat watery. The smile upon his <b>thin</b> <b>features</b> was a stationary one, not as if assumed, but molded with the features and lacking geniality.|$|R
5000|$|... #Caption: A {{simulated}} photomask. The thicker {{features are}} the integrated circuit that is desired to be {{printed on the}} wafer. The <b>thinner</b> <b>features</b> are assists that do not print themselves, but help the integrated circuit print better out-of-focus. The zig-zag appearance of the photomask is because optical proximity correction was applied to it to create a better print.|$|R
60|$|He {{searched in}} his pocket and {{produced}} an envelope from which he carefully removed a photograph, which he handed to Uncle John. Patsy examined it, too, with a start of surprise. The <b>thin</b> <b>features,</b> the large serious eyes, even the closely set lips were indeed those of A. Jones. But in the picture he wore a small mustache.|$|R
40|$|A problem often {{encountered}} with multiresolution segmentation algorithms is {{that small}} or <b>thin</b> <b>features</b> {{of an object}} become lost. This is particularly evident in linked-pyramid structures and a method is required to restore these features. This paper shows that simple adaptive isotropic and non-isotropic filtering based on the inter-region signal-to-noise ratio {{can be used to}} iteratively re-establish the lost features. It is also shown that boundary placement is also improved and a balance between class certainty and boundary placement is achieved. A number of results are presented for synthetic and real images. 1. 0. Introduction. Multiresolution pyramid structures have become a popular platform for segmentation algorithms in recent years [1, 3, 6, 7]. However, one major problem with these structures is that small or <b>thin</b> <b>features</b> become lost due to the smoothing effects of the pyramid structure. Because of this problem a lot of research has tended to conside...|$|R
40|$|We {{focus on}} the {{analysis}} of planar shapes and solid objects having <b>thin</b> <b>features</b> and propose a new mathematical model to characterize them. Based on our model, that we call an epsilon-shape, we show how thin parts can be effectively and efficiently detected by an algorithm, and propose a novel approach to thicken these features while leaving all {{the other parts of}} the shape unchanged. When compared with state-of-the-art solutions, our proposal proves to be particularly flexible, efficient and stable, and does not require any unintuitive parameter to fine-tune the process. Furthermore, our method is able to detect <b>thin</b> <b>features</b> both in the object and in its complement, thus providing a useful tool to detect thin cavities and narrow channels. We discuss the importance of this kind of analysis in the design of robust structures and in the creation of geometry to be fabricated with modern additive manufacturing technology...|$|R
60|$|She sat {{perfectly}} listless, with {{a vacant}} yet steadfast {{expression on her}} <b>thin</b> <b>features,</b> {{as if she were}} dreaming with her eyes open. The view before her was such as might indeed arouse the admiration of the most stolid; but it was evident that she took no notice of it, for her eyes were fixed on the clouds above the horizon.|$|R
60|$|Zat Arrras' {{flagship}} {{was close}} to my own. I could see the <b>thin</b> <b>features</b> of the man from where I stood. His Zodangan crew was pouring broadside after broadside into us and we were returning their fire with equal ferocity. Closer and closer came the two vessels until but a few yards intervened. Grapplers and boarders lined the contiguous rails of each. We were preparing for the death struggle with our hated enemy.|$|R
40|$|The {{subject of}} this paper is the {{calculation}} of charge distribution on the surfaces of thin conducting microelectromechanical systems beams, of nearly square cross-section, in electrostatic problems, by the boundary element method (BEM). A line model of a beam is proposed here. This model overcomes the problem of dealing with nearly singular matrices that occur when the standard BEM is applied to very <b>thin</b> <b>features</b> (objects or gaps). This new approach is also very efficient. Numerical results are presente...|$|R
40|$|Morphological {{openings}} and closings {{are useful}} for the smoothing of grayscale images. However, their use for image noise reduction is limited by their tendency to remove important, <b>thin</b> <b>features</b> from an image along with the noise. This paper is a description and analysis of a new morphological image cleaning algorithm (MIC) that preserves <b>thin</b> <b>features</b> while removing noise. MIC is useful for grayscale images corrupted by dense, low-amplitude, random or patterned noise. Such noise is typical of scanned or still-video images. MIC differs from previous morphological noise filters in that it manipulates residual images – {{the differences between the}} original image and morphologically smoothed versions. It calculates residuals on a number of different scales via a morphological size distribution. It discards regions in the various residuals that it judges to contain noise. MIC creates a cleaned image by recombining the processed residual images with a smoothed version. This paper describes the MIC algorithm in detail, discusses the effects of parametric variations, presents the results of a noise analysis and shows a number of examples of its use, including the removal of scanner noise. The paper also demonstrates that MIC significantly improves the JPEG compression of a grayscale image. ...|$|R
50|$|For unknown reasons Ilunga Mbili {{left his}} Kingdom which general belief place {{it to the}} east of Lake Tanganyika. He came out of a lake where he meets Kongolo’s sisters Mabela and Bulala. Contrary to the natives, he was tall and dark complexioned and had <b>thin</b> <b>features</b> accentuated by his sharp nose. He wore a red feather on his head and by his princely garments, Mabela and Bulala {{recognized}} him as nobility so they decided to escort him and his suites to Kongolo.|$|R
40|$|International audiencePurpose – The {{purpose of}} this paper is to focus on the {{characterization}} and classification of parts with respect to the meshing issue, and notably the meshing of thin parts difficulty handled automatically and which often requires adaptation steps. The objective is to distinguish the so-called thin parts and parts with <b>thin</b> <b>features</b> from the other parts. Design/methodology/approach – The concepts of thin part and part with <b>thin</b> <b>features</b> are introduced together with the mechanisms and criteria used for their identification in a CAD models database. The criteria are built on top of a set of shape descriptors and notably the distance distribution which is used to characterize the thickness of the object. To speed up the identification process, shape descriptors are computed from tessellated parts. Findings – A complete modular approach has been designed. It computes shape descriptors over parts stored in a directory and it uses criteria to distinguish three categories: thin parts, parts with <b>thin</b> <b>features</b> and other parts. Being the three categories identified, the user can spend more time on the parts that are considered as more difficulty meshable. Research limitations/implications – The approach is limited to the three above mentioned categories. However, it has been designed so that the values corresponding to the shape descriptors and associated meshing qualities can easily be inserted within a machining learning tool later on. Practical implications – The use of the developed tool can be seen as a pre-processing step during the preparation of finite element (FE) simulation models. It is automatic and can be run in batch and in parallel. Originality/value – The approach is modular, it is simple and easy to implement. Categories are built on top of several shape descriptors and not on a unique signature. It is independent of the CAD modeler. This approach is integrated within a FE simulation model preparation framework and help engineers anticipating difficulties when meshing CAD models...|$|R
40|$|This study {{tested the}} direct effect of {{watching}} thin ideal children's television on body satisfaction in preadolescent girls (6 - 8 years old). A within-subject design {{was used in}} which girls (N[*]=[*] 51) were tested three times. They watched television clips in random order containing either (1) thin ideal animated characters or (2) animated characters with no <b>thin</b> ideal <b>features</b> or (3) ‘real’ human actors with no <b>thin</b> ideal <b>features.</b> After watching, their state body satisfaction was measured. Girls {{with higher levels of}} thin ideal internalisation showed higher body satisfaction after exposure to the thin ideal characters than after exposure to animated or real characters <b>featuring</b> no <b>thin</b> ideal <b>features.</b> No differences on body satisfaction between the exposure conditions were found in girls with lower levels of thin ideal internalisation. The results might suggest that young girls who internalised the thin ideal are inspired by thin ideal characters in children's media...|$|R
5000|$|Since FDTD {{requires}} that the entire computational domain be gridded, and the grid spatial discretization must be sufficiently fine to resolve both the smallest electromagnetic wavelength and the smallest geometrical feature in the model, very large computational domains can be developed, which results in very long solution times. Models with long, <b>thin</b> <b>features,</b> (like wires) are difficult to model in FDTD because of the excessively large computational domain required. Methods such as Eigenmode Expansion can offer a more efficient alternative as they do not require a fine grid along the z-direction.|$|R
60|$|They {{looked at}} the young fellow curiously as he came toward them. He seemed not more than {{eighteen}} {{years of age and}} his <b>thin</b> <b>features</b> wore a tired expression that was not the result of his recent experience but proved to be habitual. His manner was not languid, however, but rather composed; {{at the same time he}} held himself alert, as if constantly on his guard. His dress was simple but in good taste and he displayed no embarrassment as he greeted the party with a low bow.|$|R
60|$|He suffered. He {{was hurt}} {{by the sight of}} his own life, which ought to have been a {{masterpiece}} of aloofness. He remembered always his last evening with his father. He remembered the <b>thin</b> <b>features,</b> the great mass of white hair, and the ivory complexion. A five-branched candlestick stood on a little table {{by the side of the}} easy chair. They had been talking a long time. The noises of the street had died out one by one, till at last, in the moonlight, the London houses began to look like the tombs of an unvisited, unhonoured, cemetery of hopes.|$|R
6000|$|She {{turned away}} with a meek [...] "Thank you," [...] and found herself {{face to face with}} me. My heart smote me when I saw how poor were her clothes, and how <b>thin</b> her <b>features.</b>|$|R
50|$|Two black {{enclosed}} <b>thinner</b> tube slides <b>featuring</b> sharp curves in dark, foggy tunnels.|$|R
40|$|We {{present a}} method for {{contouring}} an implicit function using a grid topologically dual to structured grids such as octrees. By aligning the vertices of the dual grid with {{the features of the}} implicit function, we are able to reproduce <b>thin</b> <b>features</b> of the extracted surface without excessive subdivision required by methods such as Marching Cubes or Dual Contouring. Dual Marching Cubes produces a crackfree, adaptive polygonalization of the surface that reproduces sharp features. Our approach maintains the advantage of using structured grids for operations such as CSG while being able to conform to the relevant features of the implicit function yielding much sparser polygonalizations than has been possible using structured grids. 1...|$|R
60|$|Polly {{looked more}} closely at this last photo, and saw before her a young face, upon which some lasting sorrow seemed already to have left its mark. The face was {{delicate}} and <b>thin,</b> the <b>features</b> pinched, and the eyes seemed almost unnaturally large and prominent.|$|R
60|$|So I {{was forced}} to touch him after all. Nevertheless I kept my eyes as far as {{possible}} from the ghastly face with the long hideous wound across it. I saw now, however, in one swift unwilling glance, what manner of man this was. He had <b>thin</b> <b>features,</b> a high forehead, deep-set eyes too close together, a thin iron-grey moustache. Whatever his station in life may have been, he was not of the labouring classes, for his hands were soft and his nails well cared for. We laid him {{in the bottom of the}} wagon, and covered him over with a couple of sacks. John cracked the whip and strode along by the side of the horses. Blanche Moyat and I followed behind.|$|R
50|$|Furthermore, Myers and Biocca {{found that}} some young women {{actually}} feel thinner after viewing advertisements <b>featuring</b> <b>thin,</b> idealized women.|$|R
40|$|A {{large volume}} of images of {{fingerprints}} are collected and stored {{to be used in}} various systems such as in access control and iden-tification records (ID). Systems for automatic fingerprint recogni-tion perform searches and comparisons with a database. Biometric recognition is based on two fundamental premises: the first is that digital printing must have permanent details, and the second is the information unit. From these premises, a system analyzes the fin-gerprint image to extract the information and then compares the data in the verification mode or identification mode., Extraction techniques must be used to obtain the fingerprint data. These tech-niques use binarization, <b>thinning</b> and <b>features</b> extraction algorithms which are computational methods that can be applied to digital im-age processing used in scientific research and security issues. This paper presents a comparative analysis of four thresholding tech-niques (Niblack, Bernsen, Fisher, Fuzzy), two thinning techniques (Stentiford and Holt) and a feature extraction (Cross Number) tech-nique to evaluate the best performance of the algorithms in finger-print images. To develop this project a set of 160 fingerprint images was used in experiments and analysis. The results point out the pos-itive and negative points of the different algorithms. The system was developed in the C/C++ language. Keywords: Images of fingerprints, Thresholding, <b>Thinning,</b> <b>Feature</b> Extraction...|$|R
5000|$|The {{television}} series In Living Color ran a parody music video of this single titled [...] "Promise of a <b>Thin</b> Me", <b>featuring</b> Kelly Coffield as Abdul. The video's the [...] "stretched out" [...] aspect ratio used referenced in the parody's title. The satire also mocked Abdul's singing.|$|R
5000|$|Boxes for the Mercedes {{trucks were}} orange with windows and <b>featured</b> <b>thin</b> blue and black stripes. They were marked [...] "Production Sablon".|$|R
5000|$|... "Angel of Death" [...] {{is a song}} by {{rock band}} <b>Thin</b> Lizzy <b>featured</b> on their Renegade album, {{released}} as a single in the United States. The tune peaked at No. 38 on the Mainstream Rock chart. It has been covered by death metal group Vader and power metal group Gamma Ray.|$|R
