0|10000|Public
40|$|International audienceDue {{to current}} {{trends in the}} design field towards virtual teams that {{collaborate}} over computer networks <b>to</b> <b>achieve</b> global <b>optima</b> in design, there is an increasing need for design teams to share knowledge and {{to establish and maintain}} a cooperative work through effective communication, coordination and collaboration at the knowledge level. As problems become more complex, teamwork is becoming increasingly important. This paper proposes a web-based multi-agent architecture to support multidisciplinary design teams that collaborate in a distributed design environment. Using ontologies and multi-agent system, the proposed framework addresses communication problem at knowledge level and aims to optimize constraints and conflicts management in concurrent engineering environment. A prototype, based on the Function-Behavior-Structure design framework, was built up to validate this approach...|$|R
40|$|What does it {{mean that}} {{companies}} must "create value", or "be managed" for "all their stakeholders"? In this paper we aim to show what creating economic value and appropriating economic value mean, in order to demonstrate that so long as we confine ourselves to an exclusively economic concept of "value", though it may be possible (at least in theory) <b>to</b> <b>achieve</b> economic <b>optima,</b> we will not achieve sustainable, conflict-free management because we will be omitting important aspects of reality. We therefore propose to broaden the concept of value, based not on criteria external to the company but on the core relationship between the company and its stakeholders. This allows us to identify a whole range of "values" that take stakeholder theory to a higher level. Company; interest groups; income; stakeholders; value;...|$|R
40|$|International audienceToday’s complex design {{projects}} require {{teams of}} designers {{to come together}} to facilitate the sharing of their respective expertise {{in order to produce}} effective design solutions. Due to the increasing need for exchanging knowledge, modern design projects are even more structured to work with virtual distributed teams that collaborate over computer networks <b>to</b> <b>achieve</b> global <b>optima</b> in design. This paper presents an architecture where collaborative design is synchronously and generically achieved. That is, where particular representation models are transformed into ontology instances and merged together in order to accomplish the final product design. It is a synchronous approach because the merging process is undertaken {{at the same time that}} interaction among designers takes place. As supporting technologies, Web Ontology Language (OWL) and Web Services are used to implement such an architecture...|$|R
40|$|Abstract. An {{feedback}} control algorithm based on improved {{particle swarm optimization}} algorithm for adaptive polarization mode dispersion (PMD) compensation has been proposed. In order <b>to</b> <b>achieve</b> the global <b>optima</b> of DOP, the aggregating index has been adjusted to maintain the global searching capability of PSO. The immune clone principle has been adopted to maintain {{the diversity of the}} swarm. Compared the eye diagram before and after compensation, the opening of the eye diagram has been improved obviously, which demonstrated the effectiveness of the IPSO based {{feedback control}} algorithm. ...|$|R
40|$|Successful {{design and}} {{development}} {{of a line of}} products requires balanced consideration of technical and market tradeoffs. Quantitative methods for selecting desirable product attributes based on conjoint survey data are useful, taken on their own, for many product types. However, products with substantial engineering content involve critical tradeoffs in the ability <b>to</b> actually <b>achieve</b> those desired attributes. These technical tradeoffs must be made with an eye toward their market consequences, particularly when heterogeneous market preferences make differentiation and strategic positioning critical to capturing a range of market segments and avoiding cannibalization. We present a methodology for product line optimization that efficiently coordinates positioning and design models <b>to</b> <b>achieve</b> realizable firm-level <b>optima.</b> The approach leverages prior methods where possible, overcoming several shortcomings of current positioning models by incorporating a general (Bayesian) account of consumer preference heterogeneity, alleviating known issues of combinatorial complexity, facilitating efficient parallel computing, and avoiding infeasible solutions. The method is demonstrated for a line of dial-readout scales, using physica...|$|R
40|$|Objective To {{investigate}} the efficacy {{and safety of}} percutaneous intradiscal monopolar pulsed radiofrequency (PRF) in patients with chronic disabling discogenic back pain. Method Twenty-six subjects (7 males; mean age 43. 2 years) with chronic back pain refractory to active rehabilitative management were recruited. All subjects underwent MRI for evaluation of Modic changes, and monopolar PRF (20 min at 60 V) {{at the center of}} target lumbar intervertebral disc confirmed by pressure-controlled provocative discography. Clinical outcomes were measured by the visual analogue scale (VAS), Oswestry disability index (ODI), and sitting tolerance time (ST) for 12 months after treatment. Successful clinical outcome was described as a minimum of 2 point reduction in VAS compared with the baseline at each follow-up period. Results The mean VAS for low back pain reduced significantly from 6. 4 ± 1. 1 at pre-treatment to 4. 4 ± 1. 9 at 12 months (p< 0. 05). The mean ODI score was 47. 3 ± 15. 4 points at pre-treatment and 36. 7 ± 19. 5 at 12 months (p< 0. 001). The ST was 27. 8 ± 20. 4 minutes at pre-treatment and 71. 5 ± 42. 2 at 12 months (p< 0. 001). However, successful clinical outcome was achieved at 58 %, 50 %, and 42 %, measured at 3, 6, and 12 months post-treatment. There were no significant relationship between the clinical outcome and Modic changes; no adverse events were recorded. Conclusion The results demonstrated that the application of intradiscal monopolar PRF might be relatively effective but limited; successful intervention for chronic refractory discogenic back pain is needed. <b>To</b> <b>achieve</b> the <b>optima...</b>|$|R
40|$|We {{explore the}} {{application}} of genetic algorithms (GA) to deformable models through the proposition of a novel method for medical image segmentation that combines GA with non-convex, localized, medial-based shape statistics. We replace the more typical gradient descent optimizer used in deformable models with GA, and the convex, implicit, global shape statistics with non-convex, explicit, localized ones. Specifically, we propose GA to reduce typical deformable model weaknesses pertaining to model initialization, pose estimation and local minima, through the simultaneous evolution {{of a large number}} of models. Furthermore, we constrain the evolution, and thus reduce the size of the search-space, by using statistically-based deformable models whose deformations are intuitive (stretch, bulge, bend) and are driven in terms of localized principal modes of variation, instead of modes of variation across the entire shape that often fail to capture localized shape changes. Although GA are not guaranteed <b>to</b> <b>achieve</b> the global <b>optima,</b> our method compares favorably to the prevalent optimization techniques, convex / nonconvex gradient-based optimizers and to globally optimal graphtheoretic combinatorial optimization techniques, when applied to the task of corpus callosum segmentation in 50 mid-sagittal brain magnetic resonance images...|$|R
40|$|Successful {{product line}} design and {{development}} often require {{a balance of}} technical and market tradeoffs. Quantitative methods for optimizing product attribute levels using preference elicitation (e. g., conjoint) data are useful for many product types. However, products with substantial engineering content involve critical tradeoffs in the ability <b>to</b> <b>achieve</b> those desired attribute levels. Technical tradeoffs in product design must be made {{with an eye toward}} market consequences, particularly when heterogeneous market preferences make differentiation and strategic positioning critical to capturing a range of market segments and avoiding cannibalization. We present a unified methodology for product line optimization that coordinates positioning and design models <b>to</b> <b>achieve</b> realizable firm-level <b>optima.</b> The approach overcomes several shortcomings of prior product line optimization models by incorporating a general Bayesian account of consumer preference heterogeneity, managing attributes over a continuous domain to alleviate issues of combinatorial complexity, and avoiding solutions that are impossible to realize. The method is demonstrated for a line of dial-readout scales, using physical models and conjoint-based consumer choice data. The results show that the optimal number of products in the line is not necessarily equal to the number of market segments, that an optimal single product for a heterogeneous market differs from that for a homogeneous one, and that the representational form for consumer heterogeneity has a substantial impact on the design and profitability of the resulting optimal product line — even for the design of a single product. The method is managerially valuable because it yields product line solutions efficiently, accounting for marketing-based preference heterogeneity as well as engineering-based constraints with which product attributes can be realized...|$|R
40|$|Markov Random Fields (MRFs) are {{ubiquitous}} in lowlevel computer vision. In this paper, we propose {{a new approach}} to the optimization of multi-labeled MRFs. Similarly to α-expansion it is based on iterative application of binary graph cut. However, the number of binary graph cuts required to compute a labelling grows only logarithmically with the size of label space, instead of linearly. We demonstrate that for applications such as optical flow, image restoration, and high resolution stereo, this gives an order of magnitude speed-up, for comparable energies. Iterations are performed by “fusion ” of solutions, done with QPBO which is related to graph cut but can deal with nonsubmodularity. At convergence, the method <b>achieves</b> <b>optima</b> {{on a par with the}} best competitors, and sometimes even exceeds them. 1...|$|R
40|$|Diabetes {{mellitus}} is {{a common}} and costly chronic medical illness that affects more than 16 million Americans (1). Individuals with diabetes {{are at greater risk}} of long-term complications such as kidney disease, peripheral vascular disease, lower extremity ulcers and amputations, retinopathy, and neuropathy. Diabetes is the seventh leading cause of death in the United States, and the total direct and indirect costs in the United States due to diabetes mellitus have been estimated at $ 102 billion per year (2). Diabetes {{is considered one of the}} most psychologically and behaviorally demanding of the chronic medical illnesses (3), and 95 % of diabetes management is conducted by the patient (4). For patients with type 1 and type 2 diabetes, studies have emphasized the importance of <b>achieving</b> <b>optima...</b>|$|R
40|$|The paper {{presents}} the results of the sociological survey and expertise describing the factors of risk reduction and increase of the level of trust in contract relations in food networks. The level of contract discipline is analyzed. It is shown that the insufficient rate of development of the institution of trust restricts the liberty of action for companies operating in a food network, deprives them of the opportunity <b>to</b> <b>achieve</b> the local <b>optima</b> and provides no grounds for setting their economic behavior sure-footed standards. Following the sociological survey the dynamics and structure of the transaction costs in food networks are displayed along with the specific features of their accounting in the companys operations. An expertise of the most important risk factors encountered at the current stage of development of the food networks is presented. Case studies for a number of companies enabled to reveal the advantages and contradictions of pursuing the strategies of diversification and integration as a means to reduce the external risks and uncertainties and overcome the negative impact of the asymmetric market information and underdeveloped institutional trust. A quantitative analysis of the synergetic effects from implementing the diversification strategy was made for a number of food companies to find out that the risks get reduced almost twice. At the same time, it is discovered that the transition of diversified companies from the zone of critical risks to that of minimum risks bears both positive and negative consequences. One the one hand, these are lower operational costs, more efficient distribution of the resources, greater market value of the company. But on the other hand, the above gains are offset by the excessively complicated organizational structure, dissipation of the resources, impediments to restructuring and etc. food complex, economic strategies, risks, Agribusiness,...|$|R
40|$|The {{fundamental}} problem underlying any {{phase of a}} dynamic resource allocation algorithm in a wireless network is to assign transmission powers, forward and reverse channels, and base stations such that every mobile of the system can establish a connection. The author considers the joint resource allocation problem in a system with two base stations. An algorithm that <b>achieves</b> the <b>optima...</b>|$|R
40|$|Achieving a {{significant}} reduction in order-to-shipment lead-time of remanufactured diesel engines can dramatically decrease the amount of finished goods inventory that Caterpillar needs to carry in order to meet its delivery commitments to Cat dealers around the globe. This project was launched to devise ways to hold less finished goods by reducing the order-to shipment lead time for diesel engines. <b>To</b> <b>achieve</b> this goal, a team was formed with representatives of all business units involved in the supply chain. Following the first three steps of a DMAIC methodology, the team used the following techniques and made the consequent findings: (1) Define: using Value Stream Mapping, a first-ever value stream map of the supply chain was developed. This identified gaps and focused efforts on key areas. (2) Measure: using statistical lead time analysis, a Monte Carlo simulation was performed to estimate order-to-shipment lead times for the baseline and optimized scenarios of a build-to-order scheme. This identified an opportunity to reduce lead times by increasing parts inventory. (3) Analyze: an inventory model was developed to quantify the economic implications of reducing lead time by increasing inventories. The results were compared to the savings of holding less finished goods to find out the best lead time reduction scenario. Results show that holding inventories as spare parts to enable a build-to-order strategy is less costly than relying on a build-to-stock strategy, but there is a point of diminishing returns. Our research has shown that having all business units collaborate in the process of overhauling the supply chain is key when looking for results that are optimal for the enterprise as a whole. It has also been observed that, if left unattended, a supply chain can be shaped by decisions that, at best, manage <b>to</b> <b>achieve</b> only local <b>optima.</b> In the worst case, the whole supply chain may evolve into a system that {{has little to do with}} the company's strategic goals. These observations highlight the need, and support the recommendation, to have a "process owner" who is responsible for coordinating efforts across the supply chain. by Diego A. Méndez de la Luz. Thesis (M. B. A.) [...] Massachusetts Institute of Technology, Sloan School of Management; and, (S. M.) [...] Massachusetts Institute of Technology, Engineering Systems Division; in conjunction with the Leaders for Global Operations Program at MIT, 2011. Cataloged from PDF version of thesis. Includes bibliographical references (p. 71) ...|$|R
40|$|In {{the world}} of technology, many {{industrial}} operations such as design of efficient devices, or planning production in a big factory, require optimization approach and the solution of inverse problems[chapter 1]. In this contest, in the last 20 years, the heuristic methods had a primary role considering their capabilities to find out solutions in all those cases in {{which a lot of}} computation time is requested. The present thesis work is mainly based on swarm algorithms, and on their capabilities <b>to</b> <b>achieve</b> global <b>optima</b> without remain trapped into local minima. In particular, in this work we treat high hybridization and integration among the different capabilities in exploitation and exploration, expressed by 3 optimization algorithms which are: Particle Swarm Optimization (PSO), Flock of Starlings Optimization (FSO), Bacterial Chemotaxis Optimization (BCA). The research of high hybridization among different heuristics led to implement a new metaheuristic which has been called MeTEO (Metric Topological Evolutionary Optimization). MeTEO exploits the synergy among the three algorithms already mentioned above. Moreover, in MeTEO a further method called Fitness Modification (FM) has been used. As will be shown, the FM enhance the exploration properties of MeTEO together with benefits in the parallelization. The first problem encountered making a metaheuristics composed of three complex algorithms is the computation time required. For this reason, the thesis work has been focused also in the analysis and synthesis of a parallel structures for supporting calculus. In this context, two different approaches have been studied: 1) the algorithm-based and 2) the fitness-based. Moreover, in order to extend the exploration capability of FSO problems with discrete variable as well, a binary version of FSO has been implemented [chapter 2]. MeTEO has been validated on benchmarks and on inverse problems. The benchmarks used are called hard benchmarks, because they show a structure without preferential tendency towards a particular point, and local minima with depth value, some monomodal, with one global minimum, and multimodal, with many equivalent minima. Afterwards a list of real inverse and optimization problems are proposed: the parameters identifications of Jiles-Atherton parameters, the efficiency improvement of Travelling Wave Tube (TWT) device, taking in account the geometry, the magnetic focusing field, and the voltage of a Multistage Compressed Collector, the harmonic detection in distorted waveforms. The simulation has been made with MATLAB, {{and with the help of}} a FEM simulator called COLLGUN. All results have been compared with those from other algorithms such as random walk, and the also from the use of a single heuristics which MeTEO exploits [chapter 3]. In the Chapter 4 of this thesis the point of view changes toward the hardware, whereas all the discussion done in the previous three chapters were focused on the improvement of the optimization process preformed by numerical algorithms (Software). In fact, we present a method for translating a numerical swarm based algorithm into an electric circuit, that is able to reproduce by mean of voltages and currents the same trajectories shown by the numerical swarm-based algorithms. A circuit, called swarm circuit, has been implemented with Simulink after to have deduced the mathematical relations between the numerical algorithms and their translation into a dynamic system. The swarm circuit has been tested with hard benchmarks and with two inverse problems. The swarm circuit open the road towards a real time optimization, argument that is difficult to be addressed with software approaches...|$|R
30|$|On {{the other}} hand, the {{performance}} of the proposed IBBA-RSS algorithm is compared with six different algorithms that are reported in [37]: NGHS 1 [36], SBHS [37], BHS [38], DBHS [39], ABHS [40] and ABHS 1 [41]. Table  2 shows the comparisons between the proposed algorithm and six algorithms, where best results are highlighted in bold. The obtained results showed that the proposed algorithm could <b>achieve</b> the <b>optima</b> for the low-dimensional knapsack problems, where the proposed IBBA-RSS algorithm is competitive with SBHS, ABHS and DBHS and outperforms BHS, NGHS 1 and ABHS 1.|$|R
40|$|In {{rough milling}} of {{sculptured}} surface parts, decisions on process parameters concern feedrate, spindle speed, cutting speed, width of cut, raster pattern angle {{and number of}} machining slices of variable thickness. In this paper three rough milling objectives are considered: minimum machining time, maximum removed material and maximum uniformity of the remaining volume {{at the end of}} roughing. Owing to the complexity of the modelled problem and the large number of parameters, typical genetic algorithms cannot <b>achieve</b> global <b>optima</b> without defining case-dependent constraints. Therefore, <b>to</b> <b>achieve</b> generality, a hierarchical game similar to a Stackelberg game is implemented in which a typical Genetic Algorithm functions as the leader and micro-Genetic Algorithms as followers. In this game, one of the leader's parameters is responsible for creating a follower's population and for triggering the optimisation. After properly weighing the three objectives, the follower performs single-objective optimization in steps and feeds the leader back with the objective values as they appear prior to weighing. Micro-Genetic Algorithm (follower) chromosome consists of the distribution of machining slice thickness, while the typical Genetic Algorithm (leader) consists of the milling parameters. The methodology is tested on sculptured surface parts with different properties, and a representative case is presented here...|$|R
40|$|The {{manufacturing}} sector {{is becoming more}} important for the Malaysia economy. The contribution of output and employment from this sector is continuously increasing since the 1980 an, except for certain period when an economy experiences recession. Viewing from its capacity to spearhead economic growth the government has given emphasis to the {{manufacturing sector}} in achieving industrialized nation by year 2020. It is a claim that productivity for this sector had not yet <b>achieved</b> <b>optima</b> level and in certain years, the growth of productivity was smaller than the growth of wages. Even though the concept of productivity usually referred to labour productivity, this concept is very much related to total factor productivity (TFP). This paper attempts to analysis trend of, technical efficiency, technological change and TFP growth in the Malaysian manufacturing sector. The analysis is based on data from the Industrial Manufacturing Survey of 1985 to 2000 collected by the Department of Statistics Malaysia using Data Envelopment Analysis (DEA). The results show that during the period under study, TFP growth is increasing and the major contribution of TFP growth in technical efficiency. Nevertheless, technological change show increasing trend over time. The industries that experienced high technical efficiency are food, wood, chemical and iron products. However, for food and wood industries technical progress is higher than technical progress. The other industry that shows larger technical progress than technical efficiency is textile industry but both values are below unity. ...|$|R
50|$|The {{objective}} of economic policies is <b>to</b> <b>achieve</b> efficiency. The {{objective of}} social policies is <b>to</b> <b>achieve</b> equity. The objective of environmental policies is <b>to</b> <b>achieve</b> sustainability (often involving implementing Green infrastructure. The objective of institutional governance is <b>to</b> <b>achieve</b> equilibrium (‘Ethical Equilibrium’) {{among the three}} areas.|$|R
40|$|International audienceThis paper {{studies the}} {{performance}} of Mobile Ad hoc Networks (MANETs) when the nodes, that form a Poisson point process, selfishly choose their Medium Access Probability (MAP). We consider goodput and delay as the performance metric that each node is interested in opt imizing {{taking into account the}} transmission energy costs. We introduce a pricing scheme based on the transmissi on energy requirements and compute the symmetric Nash equilibria of the game in closed form. It is shown that by appropriately pricing the nodes, the selfish behavior of the nodes can be used <b>to</b> <b>achieve</b> the social optimum at equil ibrium. The Price of Anarchy is then analyzed for these games. For the game with delay based utility, we bound t he price of anarchy and study the effect of the price factor. For the game with goodput based utility, it is shown t hat price of anarchy is infinite at the price factor that <b>achieves</b> the global <b>optima...</b>|$|R
40|$|This paper {{studies the}} {{performance}} of Mobile Ad hoc Networks (MANETs) when the nodes, that form a Poisson point process, selfishly choose their Medium Access Probability (MAP). We consider goodput and delay as the performance metric that each node is interested in optimizing {{taking into account the}} transmission energy costs. We introduce a pricing scheme based on the transmission energy requirements and compute the symmetric Nash equilibria of the game in closed form. It is shown that by appropriately pricing the nodes, the selfish behavior of the nodes can be used <b>to</b> <b>achieve</b> the social optimum at equilibrium. The Price of Anarchy is then analyzed for these games. For the game with delay based utility, we bound the price of anarchy and study the effect of the price factor. For the game with goodput based utility, it is shown that price of anarchy is infinite at the price factor that <b>achieves</b> the global <b>optima...</b>|$|R
40|$|Abstract. A {{clustering}} algorithm combining {{particle swarm optimization}} (CPSO) with K-Means (KM-CPSO) is proposed, {{which features}} better search efficiency than K-Means, PSO and CPSO. The K-Means algorithms cannot guarantee convergence to global optima and suffer in local optimal cluster center because they are sensitive to initial cluster centers. Chaotic particle swarm optimization (CPSO) can find global optimal solution; meanwhile K-Means can <b>achieve</b> local <b>optima.</b> The CPSO-KM algorithm utilizes both global search capability of CPSO and local search capability of K-Means. CPSO-KM algorithm has been tested with two synthetic datasets and three classical data sets from UCI. Experimental results show better performance of the CPSO-KM as compared to K-Means, PSO and CPSO...|$|R
5000|$|<b>To</b> <b>achieve</b> this, {{the body}} alters three main things <b>to</b> <b>achieve</b> a constant, normal body temperature: ...|$|R
5000|$|One can tune {{the prism}} {{dispersion}} <b>to</b> <b>achieve</b> greater dispersion linearity or <b>to</b> <b>achieve</b> higher-order dispersion effects.|$|R
3000|$|... 2. <b>To</b> <b>achieve</b> {{a gradual}} {{reduction}} in sedation <b>to</b> <b>achieve</b> spontaneous breathing on the ventilator {{at the earliest}} opportunity.|$|R
30|$|With {{respect to}} the numbers of {{consultant}} WTEs required <b>to</b> <b>achieve</b> 45, 000 crude and net RVUs per WTE (Table  5), among the hospitals sampled, 32.47 additional WTEs would have been required in 2009 <b>to</b> <b>achieve</b> the crude benchmark of 45, 000 RVUs/WTE; 90.71 additional WTEs would have been needed <b>to</b> <b>achieve</b> the net benchmark of 45, 000 RVUs/WTE. A mean of 85.35 % of the required numbers of WTEs was available in 2009 <b>to</b> <b>achieve</b> a crude RVU/WTE figure of 45, 000; a mean of 65.73 % of the required numbers were available <b>to</b> <b>achieve</b> 45, 000 net RVUs/WTE.|$|R
3000|$|... [...]. An AWT {{strategy}} {{will also be}} designed <b>to</b> <b>achieve</b> the minimize ECR, that is <b>to</b> <b>achieve</b> the maximum EE.|$|R
50|$|Nuru {{integrates}} revenue generation models {{into all}} five of its program areas <b>to</b> <b>achieve</b> sustainability and eventually scale <b>to</b> <b>achieving</b> national impact.|$|R
5000|$|A {{campaign}} <b>to</b> <b>achieve</b> Decisive victory, {{in which}} the IDF will operate the at its full strength in order <b>to</b> <b>achieve</b> its goals.|$|R
5000|$|Objective: What did {{you have}} <b>to</b> <b>achieve?</b> The {{interviewer}} will be looking {{to see what you}} were trying <b>to</b> <b>achieve</b> from the situation.|$|R
5|$|The Scout is {{required}} <b>to</b> <b>achieve</b> six different interest badges from the Scout Badge Book. While Scouts are encouraged <b>to</b> <b>achieve</b> as many interest badges as possible, {{they are only}} required <b>to</b> <b>achieve</b> the six that is needed for their Explorer badge. There are three compulsory badges {{for each type of}} Explorer badge.|$|R
50|$|Helps <b>to</b> <b>achieve</b> {{organizational}} goal. Organization {{is employed}} <b>to</b> <b>achieve</b> the overall objectives of business firms. Organization focuses attention of individuals objectives towards overall objectives.|$|R
5000|$|... "Science {{can tell}} you how <b>to</b> <b>achieve</b> certain things if you want <b>to</b> <b>achieve</b> them," [...] Dr. Weinberg told Turk Pipkin during their conversations for Nobelity, [...] "but it can’t tell you what you ought <b>to</b> <b>achieve.</b> There is an unbridgeable gulf between {{questions}} of what is and questions of what ought to happen." ...|$|R
30|$|The above steps {{continue}} <b>to</b> <b>achieve</b> {{the maximum}} number of plants and plants with highest fitness. This is the shortest way <b>to</b> <b>achieve</b> the optimal solution.|$|R
50|$|Although schools {{only have}} to be {{compliant}} with one of the three prongs, many schools have not managed <b>to</b> <b>achieve</b> equality. Many schools attempt <b>to</b> <b>achieve</b> compliance through the first prong; however, in order <b>to</b> <b>achieve</b> that compliance schools cut men's programs, which is not the way the OCR wanted compliance achieved. Equity {{is not the only way}} {{to be compliant with}} Title IX; athletic departments need to show that they are making efforts <b>to</b> <b>achieve</b> parity in participation, treatment, and athletic financial assistance.|$|R
50|$|Risk. A {{measure of}} the {{inability}} <b>to</b> <b>achieve</b> program objectives within defined cost and schedule constraints. Risk is associated with {{all aspects of the}} program, for example, threat, technology, design processes, Work breakdown structure (WBS) elements, etc. It has two components, the probability of failing <b>to</b> <b>achieve</b> a particular outcome, and the consequences of failing <b>to</b> <b>achieve</b> that outcome.|$|R
50|$|Examining the {{formulas}} for buckling and deflection, we {{see that}} the force required <b>to</b> <b>achieve</b> a given deflection or <b>to</b> <b>achieve</b> buckling depends directly on Young's modulus.|$|R
