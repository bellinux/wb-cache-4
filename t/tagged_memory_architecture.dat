1|2800|Public
40|$|Computers are {{notoriously}} insecure, {{in part because}} application security policies do not map well onto traditional protection mechanisms such as Unix user accounts or hardware page tables. Recent work has shown that application policies can be {{expressed in terms of}} information flow restrictions and enforced in an OS kernel, providing a strong assurance of security. This paper shows that enforcement of these policies can be pushed largely into the processor itself, by using tagged memory support, which can provide stronger security guarantees by enforcing application security even if the OS kernel is compromised. We present the Loki <b>tagged</b> <b>memory</b> <b>architecture,</b> along with a novel operating system structure that takes advantage of tagged memory to enforce application security policies in hardware. We built a full-system prototype of Loki by modifying a synthesizable SPARC core, mapping it to an FPGA board, and porting HiStar, a Unix-like operating system, to run on it. One result is that Loki allows HiStar, an OS already designed to have a small trusted kernel, to further reduce the amount of trusted code by a factor of two, and to enforce security despite kernel compromises. Using various workloads, we also demonstrate that HiStar running on Loki incurs a low performance overhead. ...|$|E
50|$|Examples of {{register}} <b>memory</b> <b>architecture</b> are IBM System/360, its successors, and Intel x86. Examples of register plus <b>memory</b> <b>architecture</b> are VAX and the Motorola 68000 family.|$|R
40|$|Abstract. The {{excellent}} {{performance of}} the contemporary x 86 processors is partially due {{to the complexity of}} their <b>memory</b> <b>architecture,</b> which therefore plays a role in performance engineering efforts. Unfortunately, the detailed parameters of the <b>memory</b> <b>architecture</b> are often not easily available, which makes it difficult to design experiments and evaluate results when the <b>memory</b> <b>architecture</b> is involved. To remedy this lack of information, we present experiments that investigate detailed parameters of the <b>memory</b> <b>architecture,</b> focusing on such information that is typically not available elsewhere. ...|$|R
40|$|Today’s feature-rich {{multimedia}} products require {{embedded system}} solution with complex System-on-Chip (SoC) to meet market expectations of high performance at low cost and lower energy consumption. SoCs are complex designs with multiple embedded processors, memory subsystems, and application specific peripherals. The <b>memory</b> <b>architecture</b> of embedded SoCs strongly influences the area, power {{and performance of}} the entire system. Further, the memory subsystem constitutes a major part (typically up to 70 %) of the silicon area for the current day SoC. The on-chip memory organization of embedded processors varies widely from one SoC to another, depending on the application and market segment for which the SoC is deployed. There is {{a wide variety of}} choices available for the embedded designers, starting from simple on-chip SPRAM based architecture to more complex cache-SPRAM based hybrid architecture. The performance of a <b>memory</b> <b>architecture</b> also depends on how the data variables of the application are placed in the memory. There are multiple data layouts for each <b>memory</b> <b>architecture</b> that are efficient from a power and performance viewpoint. Further, the designer would be interested in multiple optimal design points to address various market segments. Hence a <b>memory</b> <b>architecture</b> exploration for an embedded system involves evaluating a large design space in the order of 100, 000 of design points and each design points having several tens of thousands of data layouts. Due to its large impact on system performance parameters, the <b>memory</b> <b>architecture</b> is often hand-crafted by experienced designers exploring a very small subset of this design space. The vast memory design space prohibits any possibility for a manual analysis. In this work, we propose an automated framework for on-chip <b>memory</b> <b>architecture</b> exploration. Our proposed framework integrates <b>memory</b> <b>architecture</b> exploration and data layout to search the design space efficiently. While the memory exploration selects specific <b>memory</b> <b>architectures,</b> the data layout efficiently maps the given application on to the <b>memory</b> <b>architecture</b> under consideration and thus helps in evaluating the <b>memory</b> <b>architecture.</b> The proposed <b>memory</b> exploration framework works at both logical and physical <b>memory</b> <b>architecture</b> level. Our work addresses on-chip <b>memory</b> <b>architecture</b> for DSP processors that is organized as multiple memory banks, with each back can be a single/dual port banks and with non-uniform bank sizes. Further, our work also address <b>memory</b> <b>architecture</b> exploration for on-chip <b>memory</b> <b>architectures</b> that is SPRAM and cache based. Our proposed method is based on multi-objective Genetic Algorithm based and outputs several hundred Pareto-optimal design solutions that are interesting from a area, power and performance viewpoints within a few hours of running on a standard desktop configuration...|$|R
40|$|Parallel {{compositing}} {{techniques have}} traditionally focused on distributed <b>memory</b> <b>architectures</b> with communication of pixel values usually being the main bottleneck. On shared <b>memory</b> <b>architectures,</b> communication is handled through memory accesses, obviating {{the need for}} explicit communication steps. Shared <b>memory</b> <b>architectures</b> with multiple graphics accelerators provide the capability for parallel rendering while combining the partial results from multiple graphics adaptors requires compositing. For this reason, in this paper shared <b>memory</b> <b>architectures</b> are considered for compositing operations. A number of previously introduced parallel compositing algorithms are compared on a shared memory machine, including the binary swap and parallel pipeline techniques...|$|R
40|$|Abstract — Today’s feature-rich {{multimedia}} products require {{embedded system}} solution with complex System-on-Chip (SoC) to meet market expectations of high performance {{at a low}} cost and lower energy consumption. The <b>memory</b> <b>architecture</b> of the embedded system strongly influences these parameters. Hence the embedded system designer performs a complete <b>memory</b> <b>architecture</b> exploration. This problem is a multi-objective optimization problem and can be tackled as a two-level optimization problem. The outer level explores various <b>memory</b> <b>architecture</b> while the inner level explores placement of data sections (data layout problem) to minimize memory stalls. Further, the designer {{would be interested in}} multiple optimal design points to address various market segments. However, tight time-to-market constraints enforces short design cycle time. In this paper we address the multi-level multi-objective <b>memory</b> <b>architecture</b> exploration problem through a combination of Multi-objective Genetic Algorithm (<b>Memory</b> <b>Architecture</b> exploration) and an efficient heuristic data placement algorithm. At the outer level the <b>memory</b> <b>architecture</b> exploration is done by picking memory modules directly from a ASIC memory Library. This helps in performing the <b>memory</b> <b>architecture</b> exploration in a integrated framework, where the memory allocation, memory exploration and data layout works in a tightly coupled way to yield optimal design points with respect to area, power and performance. We experimented our approach for 3 embedded applications and our approach explores several thousand <b>memory</b> <b>architecture</b> for each application, yielding a few hundred optimal design points in a few hours of computation time on a standard desktop. I...|$|R
40|$|Abstract—This paper {{proposes a}} {{combined}} frame <b>memory</b> <b>architecture</b> which is smaller {{in size and}} is potential in reducing power consumption compared to {{the most commonly used}} ping-pong frame memory. The combined frame memory maps both reference frame data and current frame data onto one single frame memory instead of two in ping-pong architecture. Together with the characteristic of high percentage of MBs with zero-valued MVs and no residual, the combined frame <b>memory</b> <b>architectures</b> is evaluated to be able to reduce not only the memory size, but also the average energy consumption and memory access latency for applications like surveillance, video phone, and video conference. According to the statistics and analysis result, the proposed combined frame <b>memory</b> <b>architecture</b> <b>memory</b> size is only 57 % compared to ping-pong architecture. The proposed combined frame <b>memory</b> <b>architecture</b> can reduce up to 83 % of average latency and 39 % of average power consumption compared to ping-pong frame <b>memory</b> <b>architecture.</b> I...|$|R
5000|$|GEM was {{initially}} developed by Intel engineers {{to provide a}} video memory manager for its i915 driver. The Intel GMA 9xx family are integrated GPUs with a Uniform <b>Memory</b> <b>Architecture</b> (UMA) where the GPU and CPU share the physical memory, {{and there is not}} a dedicated VRAM. GEM defines [...] "memory domains" [...] for memory synchronization, and while these memory domains are GPU-independent, they are specifically designed with an UMA <b>memory</b> <b>architecture</b> in mind, making them less suitable for other <b>memory</b> <b>architectures</b> like those with a separate VRAM. For this reason, other DRM drivers have decided to expose to user space programs the GEM API, but internally they implemented a different memory manager better suited for their particular hardware and <b>memory</b> <b>architecture.</b>|$|R
50|$|B5000 {{machines}} with their stack-based <b>architecture</b> and <b>tagged</b> <b>memory</b> also heavily influenced the Soviet Elbrus series of mainframes and supercomputers. The first {{two generations of}} the series featured <b>tagged</b> <b>memory</b> and stack-based CPUs that were programmed only in high-level languages. There existed {{a kind of an}} assembly language for them, called El-76, but it was more or less a modification of ALGOL 60 and supported structured programming and first-class procedures. Later generations of the series, though, switched away from this architecture to the EPIC-like VLIW CPUs.|$|R
5000|$|A zero-copy <b>memory</b> <b>architecture</b> for {{processor}} resource efficiency.|$|R
5000|$|Non-uniform memory access, a {{different}} <b>memory</b> <b>architecture</b> for multiprocessors ...|$|R
5000|$|ScaleMP - {{software}} implementation of cache only <b>memory</b> <b>architecture</b> ...|$|R
50|$|Non-Uniform <b>Memory</b> <b>Architecture</b> (NUMA), which {{involves}} the non-uniform memory access.|$|R
3000|$|When {{a square}} pattern {{is used to}} refine the MV search results, the mapping of the <b>memory</b> <b>architecture</b> is {{important}} {{to speed up the}} performance. In our design, the <b>memory</b> <b>architecture</b> will be mapped onto a 2 D register space for the refined stage. The maximum size of this space is [...]...|$|R
30|$|<b>Memory</b> <b>architecture</b> {{that reduces}} <b>memory</b> interactions, even with complex vector instructions.|$|R
5000|$|<b>Memory</b> <b>Architecture</b> Exploration for Programmable Embedded Systems, Kluwer Academic Publishers, 2003 ...|$|R
40|$|The CoRAM <b>memory</b> <b>architecture</b> for FPGA-based {{computing}} augments traditional reconfigurable fabric with {{a natural}} and effective way for applications to interact with off-chip memory and I/O. The two central tenets of the CoRAM <b>memory</b> <b>architecture</b> are (1) the deliberate separation of concerns between computation versus data marshalling and (2) {{the use of a}} multithreaded software abstraction to replace FSM-based memory control logic. To evaluate the viability of the CoRAM <b>memory</b> <b>architecture,</b> we developed a full RTL implementation of a CoRAM microarchitecture instance that can be synthesized for standard cells or emulated on FPGAs. The results of our evaluation show that a soft emulation of the CoRAM <b>memory</b> <b>architecture</b> on current FPGAs can be impractical for memory-intensive, large-scale applications due to the high performance and area penalties incurred by the soft mechanisms. The results further show that in an envisioned FPGA built with CoRAM in mind, the introduction of hard macro blocks for data distribution can mitigate these inefficiencies—allowing applications {{to take advantage of the}} CoRAM <b>memory</b> <b>architecture</b> for ease of programmability and portability while still enjoying performance and efficiency comparable to RTL-level application development on conventional FPGAs...|$|R
5000|$|Multiple {{arithmetic}} units {{may require}} <b>memory</b> <b>architectures</b> to support several accesses per instruction cycle ...|$|R
5000|$|Scratchpad RAM - {{relevant}} to the distributed <b>memory</b> <b>architecture</b> of the Ageia PhysX PPU ...|$|R
40|$|Shared <b>memory</b> <b>architectures</b> {{are widely}} taking place. Following the {{structured}} parallel programming approach, a cost model is fundamental for performance portability and predictability. This thesis gives a contribution about cost models for multiprocessors and multi-cores {{taking into account}} important characteristics of new generation shared <b>memory</b> <b>architectures,</b> e. g. hierarchical shared memory, and with particular focus {{on the impact of}} the parallel application...|$|R
5000|$|Colbrook A., Smythe C.,« Efficient {{implementations}} {{of search}} trees on parallel distributed <b>memory</b> <b>architectures</b> » (1990) ...|$|R
40|$|This paper {{deals with}} {{alternative}} server <b>memory</b> <b>architecture</b> options in multicore CPU generations using optically-attached memory systems. Thanks to its large bandwidth-distance product, optical interconnect technology enables CPUs and local memory {{to be placed}} meters {{away from each other}} without sacrificing bandwidth. This topologically-local but physically-remote main memory attached via an ultra-high-bandwidth parallel optical interconnect can lead to flexible <b>memory</b> <b>architecture</b> options using low-cost commodity memory technologies. ...|$|R
40|$|Abstract — Quantum-dot Cellular Automata (QCA) {{provides}} a new functional paradigm for information processing and communication. In QCA {{the design of}} memories is substantially different from CMOS; several <b>memory</b> <b>architectures</b> have been proposed for QCA implementation. They have different logic and timing features in their operation. However, these architectures have not been fully verified due to limitations in current QCA design tools. This paper deals with the timing verification of three different <b>memory</b> <b>architectures</b> using simulation in HDL Verilog. Results are presented to confirm the viability and functional correctness of these <b>memory</b> <b>architectures.</b> This paper also shows that HDL based simulation is very effective for verification while allowing flexibility in modeling. I...|$|R
5000|$|Integrated {{graphics}} - also called: shared graphics solutions, integrated graphics processors (IGP), or unified <b>memory</b> <b>architecture</b> (UMA).|$|R
5000|$|Shared <b>memory</b> <b>architecture,</b> where {{multiple}} processors {{share the}} main memory space, {{as well as}} other data storage.|$|R
5000|$|ProVidia 9682 (TGUI9680 {{with video}} in {{and support for}} Unified <b>Memory</b> <b>Architecture</b> with certain core logic chipsets) ...|$|R
50|$|DRAM: {{supported}} up to 6GB of GDDR5 DRAM memory {{thanks to}} the 64-bit addressing capability (see <b>Memory</b> <b>Architecture</b> section).|$|R
50|$|Data {{diffusion}} {{machine is}} a historical virtual shared <b>memory</b> <b>architecture</b> where data is free to migrate through the machine.|$|R
50|$|The MPPA's massive {{parallelism}} and its distributed <b>memory</b> MIMD <b>architecture</b> distinguishes it from multicore and manycore architectures, which have fewer processors and an SMP or other shared <b>memory</b> <b>architecture,</b> mainly intended for general-purpose computing. It's also distinguished from GPGPUs with SIMD architectures, used for HPC applications.|$|R
50|$|As <b>memory</b> <b>architectures</b> {{increase}} in complexity, maintaining cache coherence becomes a greater problem than simple connectivity. Fireplane represents a substantial advance over previous interconnects in this aspect. It combines both snoopy cache and point-to-point directory-based models {{to give a}} two-level cache coherence model. Snoopy buses are used primarily for single buses with small numbers of processors; directory models are used for larger numbers of processors. Fireplane combines both, to give a scalable shared <b>memory</b> <b>architecture.</b>|$|R
5000|$|Sublithographic {{nanoscale}} <b>memory</b> <b>architecture,</b> A Dehon, CM Lieber, PD Lincoln, J Savage, US Patent 6,963,077, 2005 and EP Patent 1,525,586, 2007 ...|$|R
50|$|The Intel Extended Server <b>Memory</b> <b>Architecture</b> {{is defined}} to include two 36-bit {{addressing}} modes {{in the core}} processor: PAE-36 and PSE-36.|$|R
40|$|In this paper, we {{describe}} {{the design of the}} Avalanchemultiprocessor's shared memory subsystem, evaluate its performance, and discuss problems associated with using commodity workstations and network interconnects as the building blocks of a scalable shared memory multiprocessor. Compared to other scalable shared <b>memory</b> <b>architectures,</b> Avalanchehas a number of novel features including its support for the Simple COMA <b>memory</b> <b>architecture</b> and its support for multiple coherency protocols (migratory, delayed write update, and (soon) write invalidate). We describe the performance implications of Avalanche's architecture, the impact of various novel low-level design options, and describe a number of interesting phenomena we encountered while developing a scalable multiprocessor built on the HP PA-RISC platform. Analysis of Avalanche's Shared <b>Memory</b> <b>Architecture</b> Ravindra Kuramkote, John Carter, Alan Davis, Chen-Chi Kuo, Leigh Stoller, Mark Swanson Computer Systems Laboratory University of Ut [...] ...|$|R
40|$|Parallel {{programming}} models {{exist as}} an abstraction of hardware and <b>memory</b> <b>architectures.</b> There are several parallel programming models in commonly use; they are shared memory model, thread model, message passing model, data parallel model, hybrid model, Flynn’s models, embarrassingly parallel computations model, pipelined computations model. These models are not specific {{to a particular}} type of machine or <b>memory</b> <b>architecture.</b> This paper focuses the concurrent approach to Flynn’s MPSD classification in single processing environment through java program...|$|R
40|$|Embedded processor-based systems {{allow for}} the tai-loring of the on-chip <b>memory</b> <b>architecture</b> based on application-specific requirements. We present an {{analytical}} strategy for exploring the on-chip <b>memory</b> <b>architecture</b> for a given application, based on a memory performance esti-mation scheme. The analytical technique has the important advantage of enabling a fast evaluation of candidate mem-ory architectures {{in the early stages}} of system design. Our experiments demonstrate that our estimations closely follow the actual simulated performance, at significantly reduced run times. 1...|$|R
5000|$|... cache-only <b>memory</b> <b>architecture</b> (COMA): {{the local}} {{memories}} for the processors at each node {{is used as}} cache instead of as actual main memory.|$|R
