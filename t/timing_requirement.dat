73|1055|Public
2500|$|While the California Cannabis Coalition {{decision}} {{applied only}} to the election <b>timing</b> <b>requirement</b> for general taxes under Proposition 218, in Altadena Library District v. Bloodgood, 192 Cal. App. 3d 585 (June 1987) the two-thirds voter approval requirement for special taxes under Proposition 13, a different and older constitutional taxpayer protection provision, has previously been applied to a local initiative tax increase proposed by the electorate exercising the local initiative power. [...] That constitutional two-thirds voter approval requirement under Proposition 13 is independent of Proposition 218 tax restrictions. [...] The California Cannabis Coalition decision did not overrule or otherwise disturb the 1987 Altadena Library District appellate court decision.|$|E
2500|$|A Proposition 218 {{specialist}} {{law firm}} representing local governments in California {{concluded that the}} California Cannabis Coalition case was a narrow decision that “leaves the two-thirds-voter-approval requirement for local taxes in place and makes only a very modest change to earlier understandings of Proposition 218 and the law of initiatives.” In support of the foregoing conclusion, the analysis stated: [...] “The Court goes on, however, to make clear the two-thirds-voter-approval requirement for special taxes -- taxes which may be spent only for a stated purpose -- does apply to initiatives: [...] ‘In article XIII C, section 2, subdivision (d), for example, the enactors adopted a requirement providing that, before a local government can impose, extend, or increase any special tax, voters must approve the tax by a two-thirds vote. That constitutes a higher vote requirement than would otherwise apply. … That the voters explicitly imposed a procedural two-thirds vote requirement on themselves in article XIII C, section 2, subdivision (d) is evidence {{that they did not}} implicitly impose a procedural <b>timing</b> <b>requirement</b> in subdivision (b).’” ...|$|E
50|$|A <b>timing</b> <b>requirement</b> {{needs to}} be {{translated}} into a static timing constraint for an EDA tool {{to be able to}} handle it.|$|E
50|$|Most {{synchronous}} {{digital systems}} consist of cascaded banks of sequential registers with combinational logic between {{each set of}} registers. The functional requirements of the digital system are satisfied by the logic stages. Each logic stage introduces delay that affects timing performance, and the timing performance of the digital design can be evaluated relative to the <b>timing</b> <b>requirements</b> by a <b>timing</b> analysis. Often special consideration {{must be made to}} meet the <b>timing</b> <b>requirements.</b> For example, the global performance and local <b>timing</b> <b>requirements</b> may be satisfied bythe careful insertion of pipeline registers into equally spaced time windows to satisfy critical worst-case timing constraints. The proper design of the clock distribution network helps ensure that critical <b>timing</b> <b>requirements</b> are satisfied and that no race conditions exist (see also clock skew).|$|R
40|$|Many safety-critical {{software}} applications are hard real-time systems. They have stringent <b>timing</b> <b>requirements</b> {{that have to}} be met. We present a description of timing behaviour that includes precise definitions as well as analysis of how functional <b>timing</b> <b>requirements</b> interact with performance <b>timing</b> <b>requirements,</b> and how these concepts can be used by software designers. The definitions and analysis presented explicitly deal with tolerances in all timing durations. Preliminary work indicates that some requirements may be met at significantly reduced CPU bandwidth through reduced variation in cycle time...|$|R
40|$|International audienceThe {{engineering}} of real-time distributed {{embedded systems}} {{becomes more and}} more complex today due to the amount of new functionalities, constraints applied on these functions and the diversity of hardware supporting software execution and communication. Modeling and analysis of time is a key issue for the correct development of these systems. From an engineering point of view, there is a need of a development process supporting modeling <b>timing</b> <b>requirements</b> at different abstraction levels. In this paper we present a Domain Specific Language (DSL) for specifying <b>timing</b> <b>requirements</b> at the analysis phase of the software development life-cycle. The DSL provides the following features: the modeling of different types of <b>timing</b> <b>requirements,</b> the modeling of symbolic timing expressions, i. e. able to deal with bounded or unset parameters in <b>timing</b> <b>requirements,</b> and the integration of complex concepts of distributed systems such as multi rate and multi clock systems...|$|R
50|$|In a dissent {{joined by}} Chief Justice Rehnquist, Justice O'Connor, and Justice Thomas, Justice Breyer {{characterized}} {{the case as}} one about relevance and not hearsay. Breyer argued that {{the timing of the}} alleged motive to fabricate should go to the probative force of the testimony, not its reliability. Breyer thought that a post-motive consistent statement could be admitted to rebut a charge of fabrication, but that the probative force of the statement would simply be diminished. Breyer argued that FRE 801(d)(1)(B) could simply be a recognition that juries can have difficulty in separating the impeaching and substantive uses of hearsay statements, and so the rule declared as not hearsay prior consistent statements used to rebut charges of fabrication. In that sense, the usefulness of the Rule did not rest on the majority's <b>timing</b> <b>requirement.</b>|$|E
5000|$|Real-time {{virtualization}} capability {{based on}} open platform: This {{is different from}} the traditional base station built on proprietary hardware, where the software and hardware are closed-sources and provided by one single vendor. C-RAN BBU pool is built on open hardware, like x86/ARM CPU based servers, plus interface cards to handle fiber link to RRH and inter-connection in the pool. Real-time virtualization make sure the resources in the pool can be allocated dynamically to base station software stacks, say 4G/3G/2G function modules from different vendors according to network load. However, to satisfy the strict <b>timing</b> <b>requirement</b> of wireless communication system, the real-time performance for C-RAN is at the level of 10s of micro-seconds, which is two magnitude higher than the milli-second level 'real-time' performance usually seen in Cloud Computing environment.|$|E
40|$|Abstract – This {{paper is}} a part of {{fulfillment}} for the EE 680, Computer Aided-Design for Digital systems, in spring 2003. This paper presents a placement method, which considers <b>timing</b> <b>requirement,</b> congestion minimization, and power dissipation simultaneously. We used a force-directed method and added additional forces to avoid routing congestion. Power dissipation is also minimized while <b>timing</b> <b>requirement</b> is met. This method optimizes placement for low power in early iterations but forces <b>timing</b> <b>requirement</b> to become dominant as iteration increases. Psudo-code of this algorithm is provided. I...|$|E
50|$|The SMM may {{disrupt the}} {{behavior}} of real-time applications with constrained <b>timing</b> <b>requirements.</b>|$|R
50|$|Timing closure is {{the process}} by which an FPGA or a VLSI design is {{modified}} to meet its <b>timing</b> <b>requirements.</b> Most of the modifications are handled by EDA tools based on directives given by a designer. The term is also used for the goal that is achieved, when such a design has {{reached the end of the}} flow and its <b>timing</b> <b>requirements</b> are satisfied.|$|R
40|$|Consumers {{have high}} {{expectations}} about the video and audio quality delivered by media processing devices like TVsets, DVD-players and digital radios. Predictable heterogenous application domain specific multiprocessor systems, which are designed around networks-on-chip, can meet demanding performance, flexibility and power-e#ciency requirements as well as stringent <b>timing</b> <b>requirements.</b> The <b>timing</b> <b>requirements</b> can be guaranteed by making use of resource management techniques and the analytical techniques that are described in this paper...|$|R
30|$|Timing {{constraints}} {{are defined}} by applying the stereotype ResponseTiming for a single action or a complete activity and defining the response timing requirements in terms of worst and best case response times. The <b>timing</b> <b>requirement</b> for an activity {{is defined as the}} time it takes to execute the activity from its initial state to its exit state.|$|E
40|$|Tasks of {{time-schedule}} construction (JSSP) {{in various}} fields of human activities {{have an important}} theoretical and practical significance. The main feature of these tasks is a <b>timing</b> <b>requirement,</b> describing allowed planning time periods and periods of downtime. This article describes implementation variations of the work scheduling algorithm under timing requirements for the tasks of industrial time-schedules construction, and service activities...|$|E
40|$|It is {{generally}} desirable {{to reduce the}} power consumption of embedded systems. Dynamic Voltage and Frequency Scaling (DVFS) is a commonly applied technique to achieve power reduction {{at the cost of}} computational performance. Multiprocessor System on Chips (MPSoCs) can have multiple voltage and frequency domains, e. g. per-core. When DVFS is applied to real-time applications, the effects must be accounted for in the associated formal timing model. In this work, we contribute our distributed multi-core run-time power-management technique for real-time dataflow applications that uses per-core lookup-tables to select low-power DVFS operating points that meet the application's <b>timing</b> <b>requirement.</b> We describe in detail how timing slack is observed locally at run-time on each core and is used to select a local DVFS operating point that meets the application's <b>timing</b> <b>requirement.</b> We further describe our static off-line formal analysis technique to generate these per-core lookup-tables that link timing slack to low-power DVFS operating points. We provide an experimental analysis of our proposed technique using an H. 263 decoder application that is mapped onto an FPGA prototyped hardware platform...|$|E
40|$|Abstract:- In {{developing}} time-critical {{systems such}} as real-time systems and embedded systems, {{it is important to}} check timing conflicts between <b>timing</b> <b>requirements</b> as earlier as possible. For checking timing conflicts, at least, a formal notation should be introduced for a concrete and unambiguous requirements specification. However, in an earlier development phase {{it is not easy to}} describe <b>timing</b> <b>requirements</b> by using formal methods. In this paper, we propose a systematic procedure for transforming and synthesizing timing scenarios of embedded systems into a Petri net-based model. Although our approach is based on the Petri net formalism, users only focus on describing <b>timing</b> <b>requirements</b> in the scenario concepts, since the detailed transformation and integration procedures based on Petri nets are hidden to users. Key-Words:- Embedded system, real-time system. Requirement analysis, scenario composition, Petri net...|$|R
40|$|This paper {{presents}} a systematic approach to designing distributed realtime systems with system-level <b>timing</b> <b>requirements.</b> It is often {{extremely difficult to}} design such a system in a composable fashion, since temporal relationships induced by system-level <b>timing</b> <b>requirements</b> introduce complicated coupling between structurally irrelevant components. As {{a solution to this}} problem, our approach maps systemlevel <b>timing</b> <b>requirements</b> onto component-level <b>timing</b> constraints. More specifically, it first (1) transforms system-level requirements into a set of non-linear intermediate constraints; and then (2) derives task attributes such as periods, phases, and deadlines, with an objective of maximizing the chances of the system being schedulable. The final results preserve desired timing correctness: if the final task set is schedulable, then the original system-level requirements will be satisfied. Our approach is demonstrated and experimentally validated via an example numerical control sys [...] ...|$|R
30|$|We now {{describe}} the hardware parts selection strategy and {{perform an analysis}} of the clock and <b>timing</b> <b>requirements</b> for the proposed solution.|$|R
30|$|To {{generate}} fault-tolerant state-based schedules, we {{formulate a}} number of constraints that are specific to message requirements and characteristics (i.e., non-preemptive). The constraints only refer to the messages for the reachable and schedulable states. The constraints specify that the messages at least get the required computational time units and no two stations get the same time slot in the same state. We also formulate constraints to represent the <b>timing</b> <b>requirement</b> of a checkpoint.|$|E
30|$|Timing {{requirements}} of SoC functions are compared against estimated, simulated, or measured response times. It is typical that timing requirements are given as combined response times of several individual tasks. This is naturally completely {{dependent on the}} granularity used in identifying individual tasks. For instance, a single WLAN data transmission task could be decomposed into data processing, scheduling, and medium access tasks. Then examining if the <b>timing</b> <b>requirement</b> of a single data transmission is met requires examining the response times of the composite tasks in an additive manner.|$|E
30|$|On {{the other}} hand, {{a small number}} of basic {{predictive}} solutions are also available. In these proposals, the system predicts the future changes and executes the appropriate actions before they occur. However, they are based on heavy simulators which are useful in simple scenarios but which fail when used in CPS due to the high number of involved devices. In these cases, the needed time to simulate a certain future situation is higher than remaining time to really reach it. Then, the essential <b>timing</b> <b>requirement</b> of predictive solutions is not fulfilled.|$|E
40|$|Abstract—Software {{with hard}} <b>timing</b> <b>requirements</b> should be {{designed}} using a systematic approach to make its timing properties easier to inspect and verify; otherwise, it may be practically impossible {{to determine whether the}} software satisfies the <b>timing</b> <b>requirements.</b> Preruntime scheduling provides such an approach by placing restrictions on software structures to reduce complexity. A major benefit of using a preruntime scheduling approach is that it makes it easier to systematically inspect and verify the timing properties of the actual software code, not just various high-level abstractions of the code...|$|R
40|$|Mapping, i. e., allocating {{resources}} to applications and finding I/O routes between resources, {{is a crucial}} step in meeting real-time/multi-media applications' end-toend <b>timing</b> <b>requirements.</b> Given a set of real-time applications, {{the order in which}} they are mapped can also greatly impact whether these <b>timing</b> <b>requirements</b> are met. Because the optimal ordering solution is intractable, this paper introduces a logical application stream laxity metric {{that can be used to}} order the application streams in linear time that produces excellent results. We apply this metric to an example audio/video application set to illustrate our approach and to compare our solution to the optimal one. 1. Motivation In designing real-time systems, it is imperative that it meet all of the real-time applications' <b>timing</b> <b>requirements.</b> An important part in the design of such a system is mapping. Given a set of multi-resource applications and a set of available resources, mapping attempts to allocate {{resources to}} [...] ...|$|R
40|$|Given {{a set of}} {{real-time}} tasks scheduled {{using the}} earliest deadline first (EDF) algorithm, we discuss two techniques for reducing power consumption while meeting all <b>timing</b> <b>requirements.</b> Specifically, we proposed a combined Dynamic Voltage Scaling (DVS) and Dynamic Cache Reconfiguration (DCR) technique for low power embedded systems. Toward this goal, we first analyze the potential power savings achievable by each technique (DVS or DCR) alone, then, we present an online algorithm that combines both techniques, reducing the power consumption even more. Our online algorithm gradually constructs a set of pseudo-Pareto-optimal system configurations for each task, which it then uses to determine a low power operating point meeting <b>timing</b> <b>requirements.</b> We evaluate the possible savings and observe that they are highly correlated with the specific <b>timing</b> <b>requirements</b> of the task. We also show {{that the combination of}} voltage and cache reconfiguration provides the best overall power savings, as much as 28 % when considering the total platform power consumption...|$|R
40|$|A bs tr act —As t echnology s cales, t he {{impact of}} proces s variat ion on the maximum {{supported}} frequency (FMAX) of individual cores in a MPSoC becomes more pronounced. Task allocation without variation-aware performance analysis {{can result in}} a significant loss in yield, defined as the number of manufactured chips satisfying the application <b>timing</b> <b>requirement.</b> We propose variation-aware task allocation for real-time streaming applica-tions modeled as task graphs. Our solutions are primarily based on the throughput requirement, which is the most important <b>timing</b> <b>requirement</b> in many real-time streaming applications. The three main contributions of this paper are: 1) Using data flow graphs that are well-suited for modeling and analysis of real-time streaming applications, we explicitly model task execution both in terms of clock cycles (which is independent of variation) and seconds (which does depend on the variation of the resource), which we connect by an explicit binding. 2) We present two approaches for optimizing the yield. The approaches give different results at different costs. 3) We present exhaustive and heuristic algorithms that implement the optimization approaches. Our variation-aware mapping algorithms are tested on models of real applications, and are compared to the mapping methods that are unaware of hardware variation. Our results demonstrate yield improvements of up to 50 % with an average of 31 %, showing the effectiveness of our approaches. Index Terms—Process variation, Multiprocessor System-on...|$|E
40|$|As {{technology}} scales, {{the impact}} of process variation on the maximum supported frequency (FMAX) of individual cores in a MPSoC becomes more pronounced. Task allocation without variation-aware performance analysis {{can result in a}} significant loss in yield, defined as the number of manufactured chips satisfying the application <b>timing</b> <b>requirement.</b> We propose variation-aware task allocation for real-time streaming applications modeled as task graphs. Our solutions are primarily based on the throughput requirement, which is the most important <b>timing</b> <b>requirement</b> in many real-time streaming applications. The three main contributions of this paper are: 1) Using data flow graphs that are well-suited for modeling and analysis of real-time streaming applications, we explicitly model task execution both in terms of clock cycles (which is independent of variation) and seconds (which does depend on the variation of the resource), which we connect by an explicit binding. 2) We present two approaches for optimizing the yield. The approaches give different results at different costs. 3) We present exhaustive and heuristic algorithms that implement the optimization approaches. Our variation-aware mapping algorithms are tested on models of real applications, and are compared to the mapping methods that are unaware of hardware variation. Our results demonstrate yield improvements of up to 50 % with an average of 31 %, showing the effectiveness of our approaches...|$|E
40|$|Abstract—As {{technology}} scales, {{the impact}} of process variation on the maximum supported frequency (FMAX) of individual cores in a MPSoC becomes more pronounced. Task allocation without variation-aware performance analysis {{can result in a}} significant loss in yield, defined as the number of manufactured chips satisfying the application <b>timing</b> <b>requirement.</b> We propose variation-aware task allocation for real-time streaming applica-tions modeled as task graphs. Our solutions are primarily based on the throughput requirement, which is the most important <b>timing</b> <b>requirement</b> in many real-time streaming applications. The three main contributions of this paper are: 1) Using data flow graphs that are well-suited for modeling and analysis of real-time streaming applications, we explicitly model task execution both in terms of clock cycles (which is independent of variation) and seconds (which does depend on the variation of the resource), which we connect by an explicit binding. 2) We present two approaches for optimizing the yield. The approaches give different results at different costs. 3) We present exhaustive and heuristic algorithms that implement the optimization approaches. Our variation-aware mapping algorithms are tested on models of real applications, and are compared to the mapping methods that are unaware of hardware variation. Our results demonstrate yield improvements of up to 50 % with an average of 31 %, showing the effectiveness of our approaches. Index Terms—Process variation, Multiprocessor System-on...|$|E
40|$|Specifying and {{designing}} real-time systems {{is a complex}} matter because real-time systems require logical correctness as well as timing correctness. Over the years several techniques for specifying {{and designing}} real-time systems have been developed, such as Finite State Machines, Petri Nets and Timed CSP. One of the latest notations for object-oriented specification and design is the Unified Modeling Language (UML). The question whether the UML is applicable for developing real-time systems is discussed in this paper. Three notions of time (ordered time, relative time and absolute time) are explained which can appear in real-time systems development. In a general applicable modeling language it must be possible to express <b>timing</b> <b>requirements</b> of all these three forms plus context <b>timing</b> <b>requirements</b> and general <b>timing</b> <b>requirements.</b> Furthermore the object model of the UML and the dynamic model of the UML in combination with {{an example of a}} watchdog timer are explained. The dynamic model [...] ...|$|R
40|$|The {{purpose of}} this paper is to {{investigate}} the issues related to task attribute assignment on an individual processor. The majority of papers on fixed priority scheduling make the assumption that tasks have their attributes (deadline, period, offset and priority) pre-assigned. This makes priority assignment trivial. However in practice, the system 's <b>timing</b> <b>requirements</b> are specified and it is expected that the task attributes are synthesised from these. This paper is to present work that has been developed to solve this problem. 1 Introduction A significant challenge is to derive task attributes for a fixed priority schedule that meet the system's <b>timing</b> <b>requirements</b> in a way that can be understood by a nonspecialist. An approach is proposed for task attribute assignment that caters for all the likely <b>timing</b> <b>requirements</b> of complex control systems imposed on the scheduler. The issue of task attribute assignment for fixed priority scheduled systems is a subject that has received co [...] ...|$|R
40|$|Abstract. In this paper, {{we report}} a robust, efficient, and {{automatic}} method for matching infrared tracked markers for human motion analysis in computer-aided physical therapy applications. The challenges of this task stem from non-rigid marker motion, occlusion, and <b>timing</b> <b>requirements.</b> To overcome these difficulties, we use pair-wise distance constraints for marker identification. To meet the <b>timing</b> <b>requirements,</b> we first reduce the candidate marker labels by proximity constraints before enforcing the pair-wise constraints. Experiments with 38 real motion sequences, our method has shown superior accuracy and significant speedup over a semi-automatic proprietary method and the Iterative Closest Point (ICP) approach. ...|$|R
30|$|The {{computation}} {{time of a}} message in the system is to obtain at least the required number of slots for each message in its period. A boolean variable x_ij^k = 1 if a message i is allocated at a slot j in state k, and 0 if otherwise. Therefore, the summation of x_ij^k {{is greater than the}} {{computation time}} (c_i^k) required by a message i in state k. Transmitted messages are non-preemptive. Therefore, if a message is allocated to a slot in a state, the message will be allocated to the subsequent slots until the <b>timing</b> <b>requirement</b> of that message is met.|$|E
40|$|Abstract Conventional {{synchronous}} design circuits cannot only {{satisfy the}} <b>timing</b> <b>requirement</b> {{of the low}} voltage digital systems, but also they may generate wrong outputs {{under the influence of}} PVT variations and aging effects. Therefore, in this paper, a NCL (Null Convention Logic) design as an asynchronous design method has been proposed, where the NCL method doesn’t require any timing analysis, and it has a very simple design methodology. Base on the NCL method, a new low power reliable ALU has been designed and implemented using MagnaChip-SKhynix 0. 18 um CMOS technology. The experimental results of the proposed NCL ALU have been compared t...|$|E
40|$|The {{continuous}} shrinking of microelectronic device sizes {{with every}} technology generation {{along with the}} reduction in supply voltages is causing {{a significant decrease in}} circuit noise margins. This leads to increased susceptibility of circuits to transient errors. In this paper, we propose a methodology to increase the robustness of combinational circuits to transient errors by sizing the gates of the circuit {{in such a way that}} the number of errors propagated to the primary output is minimized while the <b>timing</b> <b>requirement</b> is met. Using SPICE simulation, we validate that combinational circuits propagate fewer number of transient errors to the circuit output after application of our sizing algorithm. 1...|$|E
40|$|In {{this paper}} 1, {{we present a}} new {{synchronization}} strategy for multimedia applications executed in a distributed environment. This strategy makes the timing properties {{of the system and}} the quality of the media presentations predictable since one is able to determine analytically whether the <b>timing</b> <b>requirements</b> of each multimediaapplicationwillbe met, and if not, which <b>timing</b> <b>requirements</b> willfail. The proposed synchronization protocol provides deterministic guarantees and service reliability that can’t be compromised by resource contention. Thus, the application can maintain the initial quality of service (QoS) level without encountering unpredictable delays and blocking due to synchronization. 1...|$|R
40|$|Multimedia {{applications}} have <b>timing</b> <b>requirements</b> that cannot {{generally be}} satisfied using time-sharing scheduling algorithms and system structures. To effectively support {{these types of}} programs, operating systems must support processor capacity reservation. A capacity reservation and enforcement mechanism isolates programs from the timing and execution characteristics of other programs {{in the same way}} that a memory protection system isolates programs from memory access by other programs. In this paper, we characterize the <b>timing</b> <b>requirements</b> and processor capacity reservation requirements for multimedia applications, we describe a scheduling framework to support reservation and admission control, and we introduce a novel reserve abstraction, specifically designed for the microkemel architecture, for controlling processor usage...|$|R
40|$|In {{the context}} of use-case centric {{development}} and requirements-driven testing, this paper addresses the problem of automatically deriving system test cases to verify <b>timing</b> <b>requirements.</b> Inspired by engineering practice in an automotive software development context, we rely on an analyzable form of use case specifications and augment such functional descriptions with timed automata, capturing <b>timing</b> <b>requirements,</b> following a methodology aiming at minimizing modeling overhead. We automate the generation of executable test cases using a test strategy based on maximizing test suite diversity and building over the UPPAAL model checker. Initial empirical results based on an industrial case study provide evidence {{of the effectiveness of}} the approach...|$|R
