0|141|Public
5000|$|It <b>operated</b> 75,000 <b>spindles</b> in 1887, {{rising in}} 1891 to 87,000 spindles, 348/388 twist, 408/528 weft. In 1951, {{it was an}} all ring mill doing coarse counts ...|$|R
40|$|Hand held {{sewing machine}} in brown painted metal housing with silver metal working parts. Red bobbin holder with metal post/red cap for spools of <b>thread.</b> <b>Operated</b> by {{squeezing}} {{top and bottom}} sections together. Contained in yellow plastic support and original brown cardboard box. Label (on box) : LEROCO. Box contains 22 small spools of different coloured threads [...] Maker: Leroco - from the The Betty Smithers Design Collection at Staffordshire University. ...|$|R
40|$|Showing that {{concurrent}} <b>threads</b> <b>operate</b> {{on separate}} {{portions of their}} shared state {{is a way of}} establishing non-interference. Furthermore, in many useful programs, ownership of parts of the state are exchanged dynamically. Reasoning about separation and ownership of heap-based variables is often conducted using some form of separation logic. This paper examines the issue of separation and investigates the use of abstraction to specify and to reason about separation in program design. Two case studies demonstrate that using separation as an abstraction is a potentially useful approach...|$|R
50|$|Sun Microsystems has {{released}} the Niagara and Niagara 2 chips, {{both of which}} feature an eight-core design. The Niagara 2 supports more <b>threads</b> and <b>operates</b> at 1.6 GHz.|$|R
5000|$|... #Subtitle level 3: Single <b>threaded</b> {{architecture}} (standard <b>operating</b> system) ...|$|R
50|$|A futex {{consists}} of a kernelspace wait queue that is attached to an aligned integer in userspace. Multiple processes or <b>threads</b> <b>operate</b> on the integer entirely in userspace (using atomic operations to avoid interfering with one another), and only resort to relatively expensive system calls to request operations on the wait queue (for example to wake up waiting processes, or to put the current process on the wait queue). A properly programmed futex-based lock will not use system calls except when the lock is contended; since most operations do not require arbitration between processes, this will not happen in most cases.|$|R
30|$|While our {{original}} method {{had worked in}} the context of standards such as GSM which have longer radio frame durations of 120 ms, such a method is not well suited to 3 GPP radio frames, which have durations that are 12 times shorter at 10 ms. Operation within 3 GPP poses further challenges since faster processing is required. The new design presented in this paper maps the PCZ operation more efficiently for practical operation within the context of 3 GPP. The workload is spread across the GPU more evenly such that the GPU has a large number of lightweight <b>threads</b> <b>operating,</b> which helps to improve GPU utilization, as discussed earlier.|$|R
40|$|Operating systems use kernel stacks {{to support}} the {{execution}} of threads. A typical multi <b>threaded</b> <b>operating</b> system uses one kernel stack per thread. This stack per thread model consumes {{a significant amount of}} kernel memory. An alternative model is the use of a single kernel stack that is shared between all threads. This reduces the opersating systems memory consumption. This thesis implements the single stack kernel architecture in the L 4 microkernel to evaluate the performance and memory tradeoffs. It is shown that significant memory savings can be achieved without degrading the kernels performance. Preliminary results show improvement in the kernels performance due to the single stack architecure...|$|R
40|$|Abstract. The {{main idea}} behind UPC is that users {{should be able}} to view the {{underlying}} machine model as a collection of <b>threads</b> <b>operating</b> in a common global address [5]. In such an environment fine-grain algorithms are preferred to coarse-grain algorithms since they are easier to code. While such algorithms, written in UPC, should have similar performance in shared memory environments compared to OpenMP, they are currently slower. In addition they have unacceptably long execution time in a cluster environment compared to coarse-grain algorithms written in MPI and UPC itself. Also UPC lacks the flexibility and functionality of OpenMP and MPI in their respective environments. 1...|$|R
50|$|In 1876, the Mile End <b>Thread</b> Mills started <b>operating,</b> giving {{employment}} {{to several hundred}} operators.|$|R
2500|$|Wren Nest Mill on High Street West {{was built}} c.1800–10, with further {{extensions}} in 1815 and 1818, the latter [...] incorporating an octagonal tower. The present {{building is a}} small part of the original complex, which in its heyday employed 1,400 workers <b>operating</b> 123,000 <b>spindles</b> and 2,541 looms. It ceased trading in 1955.|$|R
40|$|AbstractMultithreaded {{software}} {{systems are}} prone to errors due {{to the difficulty of}} reasoning about multiple interleaved <b>threads</b> <b>operating</b> on shared data. Static checkers that analyze a program's behavior over all execution paths and all thread interleavings are a powerful approach to identifying bugs in such systems. In this paper, we present Calvin, a scalable and expressive static checker for multithreaded programs based on automatic theorem proving. To handle realistic programs, Calvin performs modular checking of each procedure called by a thread using specifications of other procedures and other threads. Our experience applying Calvin to several real-world programs indicates that Calvin has a moderate annotation overhead and can catch common defects in multithreaded programs, such as synchronization errors and violations of data invariants...|$|R
40|$|We {{consider}} Real-Time CORBA 2. 0 (Dynamic Scheduling) distributable <b>threads</b> <b>operating</b> in multi-hop networks. When distributable threads {{are subject}} to time/utility function-time constraints and timeliness optimality criteria such as maximizing accrued, system-wide utility, utility accrual real-time channels must be established. Such channels transport messages that are generated as distributable threads transcend nodes, {{in a way that}} maximizes system-wide, message-level utility. We present a utility accrual channel establishment algorithm called Local Decision for Utility accrual Channel Establishment (or LocDUCE). Since the channel estab-lishment problem is NP-hard, LocDUCE heuristically computes channels. We implement the algorithm in a prototype test-bed and experimentally compare it with the Open Shortest Path First (OSPF) routing algorithm. Our experimental measurements reveal that LocDUCE accrues significantly higher utility than OSPF. ...|$|R
40|$|Multithreaded {{software}} {{systems are}} prone to errors due {{to the difficulty of}} reasoning about multiple interleaved <b>threads</b> <b>operating</b> on shared data. Static checkers that analyze a program's behavior over all execution paths and all thread interleavings are a powerful approach to identifying bugs in such systems. In this paper, we present Calvin, a scalable and expressive static checker for multithreaded programs based on automatic theorem proving. To handle realistic programs, Calvin performs modular checking of each procedure called by a thread using specifications of other procedures and other threads. Our experience applying Calvin to several real-world programs indicates that Calvin has a moderate annotation overhead and can catch common defects in multithreaded programs, such as synchronization errors and violations of data invariants...|$|R
40|$|Spindles {{used for}} recent diamond turning {{machines}} are typically supported by hydrostatic bearings. Especially, air hydrostatic bearings {{are the most}} common because of low viscosity of air. Low viscosity of lubricant fluid is an important requirement for <b>operating</b> the <b>spindle</b> in a range of higher rotational speeds. However, from a stiffness viewpoint of the bearings, higher compressibilit...|$|R
50|$|The {{operating}} system holds {{most of this}} information about active processes in data structures called process control blocks. Any subset of the resources, typically at least the processor state, {{may be associated with}} each of the process' <b>threads</b> in <b>operating</b> systems that support threads or child (daughter) processes.|$|R
40|$|One {{important}} aspect of understanding the behavior of an application with respect to its performance, overhead, and scalability characteristics is knowledge of its control flow. In comparison to sequential applications the situation is more complicated in multithreaded parallel programs because each thread defines its own independent control flow. On the other hand, for the most common usage models of OpenMP the <b>threads</b> <b>operate</b> in a largely uniform way, synchronizing frequently at sequence points and diverging only to operate on different data items in worksharing constructs. This paper presents an approach to capture and visualize the control flow of OpenMP applications in a compact way that {{does not require a}} full trace of program execution events but is instead based on a straightforward extension to the data collected by an existing profiling tool...|$|R
40|$|Memcached is an open-source, multi-threaded, distributed, Key-Value caching {{solution}} {{commonly used}} for delivering software-as-a-service, reducing service latency and traffic to database and computational servers. We introduce optimizations that overcome thread-scaling limitations of memcached, enabling effective utilization of high core-count servers. The approach employs Concurrent data structures and a modified cache replacement strategy to improve scalability. These data structures enable concurrent lockless item retrieval and provide striped lock capability for hash table updates. The replacement strategy imposes a relaxed ordering of items based on relative timestamps. Rules for item insert, delete, and cache maintenance guarantee thread safety. A configurable cleaner <b>thread</b> <b>operates</b> autonomously, reducing lock requirements. The optimized application exhibits linear scalability, overcoming {{the limitations of}} the open-source version. In testing 16 -core servers, throughput improved by 6 X and performance/watt by more than 3 X, while maintaining service-level agreements. Based on core scalin...|$|R
50|$|Screw jacks {{are limited}} in their lifting capacity. Increasing load {{increases}} friction within the screw threads. A fine pitch thread, which would increase {{the advantage of the}} screw, also reduces the size and strength of the <b>threads.</b> Longer <b>operating</b> levers soon reach a point where the lever will simply bend at their inner end.|$|R
40|$|MythOS (Micro-kernel <b>THreads</b> <b>Operating</b> System) is an {{experimental}} operating system for embedded systems. The system kernel {{is a first}} implementation of the POSIX "Minimal Real-Time System Profile". It is based on prior work of a library implementation of Pthreads (POSIX threads). The system is fully preemptive. It supports multi-threading within a single process environment with shared kernel and user space. It exhibits remarkable timing predictability intended for hard real-time requirements. This is achieved by a careful design of only few device drivers. The system has been implemented and tested on the SPARC VME architecture. Also presented is a fast context switching algorithm for the SPARC which outperforms the context switch under SunOS 4. x and matches the performance under Solaris 2. 3. Furthermore, an implementation-defined extension of Pthreads for deadline scheduling is presented. Overall, the system exhibits slightly faster performance than SunOS 4. x and is considerably more [...] ...|$|R
40|$|MiThOS (Micro-kernel <b>Threads</b> <b>Operating</b> System) is an {{experimental}} operating system for embedded systems. The system kernel {{is a first}} implementation of the POSIX "Minimal Real-Time System Profile". It is based on prior work of a library implementation of Pthreads (POSIX threads). The system is fully preemptive. It supports multi-threading within a single process environment with shared kernel and user space, i. e. real-time tasks are mapped onto POSIX threads. It exhibits remarkable timing predictability intended for hard real-time requirements. This is achieved by a careful design of only few device drivers. The system has been implemented and tested on the SPARC VME architecture. The system includes a fast context switching algorithm for the SPARC which outperforms the context switch under SunOS and matches the performance under Solaris. It supports selective enabling and disabling of hardware components (MMU, caches, etc.) since its sources are available. Furthermore, an implementat [...] ...|$|R
40|$|Abstract. Simultaneous {{multithreading}} — put simply, {{the sharing}} of the execution resources of a superscalar processor between multiple execution threads — has recently become widespread via its introduction (under the name “Hyper-Threading”) into Intel Pentium 4 processors. In this implementation, for reasons of efficiency and economy of processor area, {{the sharing of}} processor resources between threads extends beyond the execution units; of particular {{concern is that the}} threads share access to the memory caches. We demonstrate that this shared access to memory caches provides not only an easily used high bandwidth covert channel between threads, but also permits a malicious <b>thread</b> (<b>operating,</b> in theory, with limited privileges) to monitor the execution of another thread, allowing in many cases for theft of cryptographic keys. Finally, we provide some suggestions to processor designers, operating system vendors, and the authors of cryptographic software, of how this attack could be mitigated or eliminated entirely. 1...|$|R
40|$|This paper {{reports on}} the {{implementation}} {{and analysis of the}} MP refiner, the first parallel interactive theorem prover. The MP refiner is a shared memory multi-processor implementation of the inference engine of Nuprl. The inference engine of Nuprl is called the refiner. The MP refiner is a collection of <b>threads</b> <b>operating</b> as sequential refiners running on separate processors. Concurrent tactics exploit parallelism by spawning tactics to be evaluated by other refiner threads simultaneously. Tests conducted with the MP refiner running on a four processor Sparc shared [...] memory multi-processor reveal that parallelism at the inference rule level can significantly decrease the elapsed time of constructing proofs interactively. 1 Introduction An interactive theorem prover is a computer program that employs automated deduction to construct proofs {{with the aid of a}} user. Many interactive theorem provers require users to supply programs, called tactics, to carry out inference. Tacti [...] ...|$|R
5000|$|The {{mathematical}} {{notions of}} trusted {{systems for the}} protection of classified information derive from two independent but interrelated corpora of work. In 1974, David Bell and Leonard LaPadula of MITRE, working under the close technical guidance and economic sponsorship of Maj. Roger Schell, Ph.D., of the U.S. Army Electronic Systems Command (Ft. Hanscom, MA), devised {{what is known as the}} Bell-LaPadula model, in which a more or less trustworthy computer system is modeled in terms of objects (passive repositories or destinations for data, such as files, disks, printers) and subjects (active entities - perhaps users, or system processes or <b>threads</b> <b>operating</b> on behalf of those users - that cause information to flow among objects). The entire operation of a computer system can indeed be regarded a [...] "history" [...] (in the serializability-theoretic sense) of pieces of information flowing from object to object in response to subjects' requests for such flows.|$|R
40|$|In this paper, a {{simulation}} framework that enables distributed numerical computing in multi-core shared-memory environments is presented. Using multiple threads allows a single memory image {{to be shared}} concurrently across cores but potentially introduces race conditions. Race conditions can be avoided by ensuring each core operates on an isolated memory block. This is usually achieved by running a different operating system process on each core, such as multiple MPI processes. However, we show that in many computational physics problems, memory isolation can also be enforced within a single process by leveraging spatial sub-division of the physical domain. A new spatial sub-division algorithm is presented that ensures <b>threads</b> <b>operate</b> on different memory blocks, allowing for in-place updates of state, with no message passing or creation of local variables during time stepping. Additionally, the developed framework controls task distribution dynamically ensuring an events based load balance. Results from fluid mechanics analysis using Smoothed Particle Hydrodynamics (SPH) are presented demonstrating linear performance with number of cores...|$|R
40|$|This paper {{describes}} a translator called Java PathFinder (Jpf), from Java to Promela, the modeling {{language of the}} Spin model checker. Jpf translates a given Java program into a Promela model, which then can be model checked using Spin. The Java program may contain assertions, which are translated to similar assertions in the Promela model. The Spin model checker will then look for deadlocks and violations of any stated assertions. Jpf generates a Promela model with the same state space characteristics as the Java program. Hence, the Java program must have a finite and tractable state space. This work should {{be seen in a}} broader attempt to make formal methods applicable within NASA's areas such as space, aviation, and robotics. The work is a continuation of an effort to formally analyze, using Spin, a multi [...] <b>threaded</b> <b>operating</b> system for the Deep-Space 1 space craft, and of previous work in applying existing model checkers and theorem provers to real applications. Key words: Program [...] ...|$|R
40|$|Recently, {{there has}} been an effort to specify an IEEE {{standard}} for portable operating systems for open systems, called POSIX. One part of it, the POSIX. 4 a threads extension [3], describes the interface for lightweight threads that rely on shared memory and have a smaller context frame than processes. This paper describes the design and implementation of a library of POSIX. 4 a calls that is solely based on UNIX. It shows that a library implementation is feasible. This work can also be used as as a prototyping, testing, and debugging system in the regular UNIX environment. keywords: Ada language, Ada runtime system, C language, concurrency, light-weight <b>threads,</b> <b>operating</b> system, POSIX standard 1 Introduction Some important factors in software engeneering are reuse and portability of software components. Software standards are trying to address these issues. Standards should ffl define the minimal criteria for software interfaces which have to be met across different architectures to fac [...] ...|$|R
5000|$|Thread Control Block (TCB) is a data {{structure}} in the operating system kernel which contains thread-specific information needed to manage it. The TCB is [...] "the manifestation of a <b>thread</b> in an <b>operating</b> system." ...|$|R
40|$|Violations of {{atomicity}} {{are possible}} {{sources of errors}} in parallel programs. A violation occurs if the e#ect of a method execution depends on the execution of concurrent <b>threads</b> that <b>operate</b> on the same or overlapping parts of a shared data structure. All accesses to shared data {{are assumed to be}} ordered through synchronization, hence common techniques for data race and deadlock detection are not able to find such errors...|$|R
5000|$|In BSD, these {{parameters}} are generally objects in a management information base (MIB) that describe tunable limits {{such as the}} size of a shared memory segment, the number of <b>threads</b> the <b>operating</b> system will use as an NFS client, or the maximum number of processes on the system; or describe, enable or disable behaviors such as IP forwarding, security restrictions on the superuser (the [...] "securelevel"), or debugging output.|$|R
40|$|Assertions are a {{powerful}} bug detection technique. Traditional assertion checking, however, is performed synchronously, imposing its full cost on the runtime of the program. As a result, many useful kinds of checks are impractical because they lead to extreme slowdowns. We present {{a solution that}} decouples assertion evaluation from program execution: assertions are evaluated asynchronously while the program continues to execute. Our technique ensures that the assertion checking <b>thread</b> <b>operates</b> on a consistent view of the global state, and that an assertion always produces the same result as it would in a serial execution. We implemented our technique in a system called STROBE, a snapshot-based system for asynchronous assertion checking in both single-and multi-threaded Java applications. STROBE runs inside the Java virtual machine and uses copy-on-write to build snapshots incrementally. We find that asynchronous checking scales almost perfectly over synchronous checking in many cases, indicating that the snapshot overhead is quite low. STROBE provides tolerable overheads (under 2 X) even for heavy-weight assertions that would otherwise result in crushing slowdowns. 1...|$|R
40|$|In SMT processors, {{the complex}} interplay between private and shared {{datapath}} resources {{needs to be}} considered in order to realize the full performance potential. In this paper, we show that blindly increasing the size of the per-thread reorder buffers to provide a larger number of in-flight instructions does not result in the expected performance gains but, quite in contrast, degrades the instruction throughput for virtually all multithreaded workloads. The reason for this performance loss is the excessive pressure on the shared datapath resources, especially the instruction scheduling logic. We propose intelligent mechanisms for dynamically adapting the number of reorder buffer entries allocated to each thread in an effort to avoid such allocations if they detrimentally impact the scheduler. We achieve this goal through categorizing the program execution into issue-bound and commit-bound phases and only performing the buffer allocations to the <b>threads</b> <b>operating</b> in commit-bound phases. Our adaptive technique achieves improvements of 21 % in instruction throughput and 10 % in the fairness metric compared to the best performing baseline configuration with static ROBs. ...|$|R
50|$|During the Depression era, Coltejer bought {{discarded}} looms cheaply {{from the}} United States that {{were brought in}} on muleback. During World War II, Coltejer was <b>operating</b> some 70,000 <b>spindles</b> and 1,900 looms, employing 4,000 workers in its Medellin plant {{in addition to those}} at Envigado.|$|R
50|$|Jinx was {{implemented}} as a hypervisor, {{giving it the}} ability to observe the effects of all elements of the software environment on <b>thread</b> interleaving. Jinx <b>operated</b> independently of any programming language or threading libraries or tools.|$|R
5000|$|The Sauquiot Spinning Company was a Gadsden, Alabama textile {{business}} {{which was}} acquired by the Standard Coosa-Thatcher Companyin March 1930. The firm <b>operated</b> with 20,000 <b>spindles</b> and was purchased for approximately $1,000,000. As {{a subsidiary of the}} Standard Coosa-Thatcher Company, the plant weathered the Great Depression.|$|R
50|$|As it was {{previously}} mentioned, dependencies or conflicts between different threads during execution stops parallelization, and these conflicts appear {{when we have}} read/write conflicting variables. One technique to remove this conflict is Privatization. As the name suggests, the basic principle involves making (Private) copies for each <b>thread</b> to <b>operate</b> on, rather than the shared copy that causes the conflict. Hence, changing the type of the variable from Read/Write conflicting to Read/Write Non conflicting.|$|R
