178|208|Public
50|$|There {{are many}} {{applications}} of this problem. One is as a <b>toy</b> <b>problem</b> for computer science.|$|E
50|$|The monkey {{and banana}} {{problems}} is a famous <b>toy</b> <b>problem</b> in artificial intelligence, particularly in logic programming and planning.|$|E
50|$|The Meissner {{equation}} {{was first}} studied as a <b>toy</b> <b>problem</b> for certain resonance problems. It is also useful for understand resonance problems in evolutionary biology.|$|E
50|$|For instance, while {{engineering}} a large system, {{the large}} problem is often {{broken down into}} many smaller <b>toy</b> <b>problems</b> which have been understood in good detail. Often these problems distill a few important aspects of complicated problems {{so that they can}} be studied in isolation. <b>Toy</b> <b>problems</b> are thus often very useful in providing intuition about specific phenomena in more complicated problems.|$|R
50|$|As an example, in the {{artificial}} intelligence, classical puzzles, games and problems {{are often used}} as <b>toy</b> <b>problems.</b> These include sliding-block puzzles, N-Queens problem, missionaries and cannibals problem, tick-tack-toe, chess, Hanoi tower and others.|$|R
50|$|It was {{a design}} choice {{from the start}} to only include very simple <b>toy</b> <b>problems,</b> each {{providing}} {{a different kind of}} programming challenge.This provides users of the Benchmark Game the opportunity to scrutinize the various implementations.|$|R
50|$|The {{missionaries and}} cannibals problem, and the closely related jealous husbands problem, are classic river-crossing problems. The missionaries and cannibals {{problem is a}} {{well-known}} <b>toy</b> <b>problem</b> in artificial intelligence, where it was used by Saul Amarel {{as an example of}} problem representation.|$|E
50|$|In {{scientific}} disciplines, a <b>toy</b> <b>problem</b> or a puzzlelike {{problem is}} a problem that is not of immediate scientific interest, yet is used as an expository device to illustrate a trait that may be shared by other, more complicated, instances of the problem, or as a way to explain a particular, more general, problem solving technique.|$|E
5000|$|Consider a <b>toy</b> <b>problem,</b> {{of a train}} {{moving along}} a 1D track in the x-direction. Suppose that the train moves either a {{distance}} of +b or −b (b {{is the same for}} each step), depending on whether a coin lands heads or tails when flipped. Lets start by considering the statistics of the steps the toy train takes (where Si is the ith step taken): ...|$|E
40|$|Formal {{research}} in object-level commonsense reasoning (csr) has concentrated on <b>toy</b> <b>problems</b> [...] -problems that require {{only a few}} axioms to formalize. The resulting body of research is often narrow, since scaling down a problem factors out much of the difficulty. This paper aims to reverse this trend. We tackle a substantial problem in csr: the formalization of egg cracking. To do this, we develop theories of shape and material and integrate these with a theory of action and planning. The initial formalization of the egg-cracking domain {{has led to the}} identification of unaddressed problems in csr and has provided a testbed for existing theories of action. We report on these and other results in the paper. Introduction Research in formal AI abounds in metatheory but rarely tackles object-level commonsense problems that require more than a few axioms to formalize. Instead, AI research focusses on <b>toy</b> <b>problems,</b> such as the blocks world. Such problems are useful in highlighting a specific [...] ...|$|R
40|$|The {{problem of}} {{inferring}} parameters of differential quations from noisy data {{is of great}} importance in the dissimination of gene-regulatory networks. In this thesis, we shall look at the problem of parameter estimation. First, three methods are reviewed, where each method is of a different discipline (frequentist, Bayesian, machine learning). Then we propose and research a Bayesian method, which we apply to various <b>toy</b> <b>problems.</b> ...|$|R
40|$|Abstract — Computational time {{complexity}} {{analyses of}} Evolutionary Algorithms (EAs) {{have been performed}} since the midnineties. The first results were related to very simple algorithms, such as the (1 + 1) -EA, on <b>toy</b> <b>problems.</b> These efforts produced {{a deeper understanding of}} how EAs perform on different kinds of fitness landscapes and general mathematical tools that may be extended to the analysis of more complicated EAs on more realistic problems. In fact, in recent years, it has been possible to analyse the (1 + 1) -EA on combinatorial optimization problems with practical applications and more realistic population-based EAs on structured <b>toy</b> <b>problems.</b> This paper presents a survey of the results obtained in the last decade along these two research lines. The most common mathematical techniques are introduced, the basic ideas behind them are discussed and their elective applications are highlighted. Solved problems that were still open are enumerated as are those still awaiting for a solution. New questions and problems arisen in the meantime are also considered. Index Terms — Evolutionary algorithms, computational complexity, combinatorial optimization, evolutionary computation theory. I...|$|R
5000|$|A <b>toy</b> <b>problem</b> {{illustrates}} the basic concepts. For example, consider the differential equation system for two variables :Capital [...] denotes the presumed macroscale variable, and lowercase [...] the microscale variable. This classification {{means that we}} assume a coarse model of the form [...] exists, although we do not necessarily know what it is. Arbitrarily define the lifting from any given macrostate [...] as [...] A simulation using this lifting and the coarse time-stepper {{is shown in the}} figure.|$|E
50|$|Witsenhausen's counterexample, {{shown in}} the figure below, is a deceptively simple <b>toy</b> <b>problem</b> in {{decentralized}} stochastic control. It was formulated by Hans Witsenhausen in 1968. It is a counterexample to a natural conjecture that one can generalize a key result of centralized linear-quadratic-Gaussian control systems—that in a system with linear dynamics, Gaussian disturbance, and quadratic cost, affine (linear) control laws are optimal—to decentralized systems. Witsenhausen constructed a two-stage linear quadratic Gaussian system where two decisions are made by decision makers with decentralized information and showed that for this system, there exist nonlinear control laws that outperform all linear laws. The problem of finding the optimal control law remains unsolved.|$|E
50|$|Burger King has {{received}} criticism {{for what was}} described as a slow start on their part to recall the products. Chairperson Ann Brown commented that a death should be a very grave sign there's a problem, saying that one would not want the deaths of several children before you issue a recall. After they initiated the recall campaign, Brown stated they had come around, though they had to push them to do so. In response to Burger King's abrupt announcement of the recall two days before the planned announcement, industry experts suspected this decision angered the commission and Brown, who uses high-profile media appearances to break the news of recalls. President of the Chicago-based fast food firm Technomic Ron Paul stated these kinds of things are easily forgotten after a matter of weeks, if not days. He added that most people attribute this as a <b>toy</b> <b>problem,</b> not a Burger King problem.|$|E
30|$|As {{a famous}} {{evolutionary}} algorithm, GA shows good performance {{in dealing with}} antenna design problem. This paper attempts to propose a parallel framework based on a three-parent crossover GA. This framework plans to enhance exploitation of GA so that solutions could be refined to a better extent than original algorithm in the later evolutionary stage. The goodness of the proposed framework is studied on both <b>toy</b> <b>problems</b> and nonuniform antenna design problem.|$|R
40|$|This paper {{focuses on}} {{utilizing}} two different Bayesian methods {{to deal with}} a variety of <b>toy</b> <b>problems</b> which occur in data analysis. In particular we implement the Variational Bayesian and Nested Sampling methods to tackle the problems of polynomial selection and Gaussian Mixture Models, comparing the algorithms in terms of processing speed and accuracy. In the problems tackled here it is the Variational Bayesian algorithms which are the faster though both results give similar results...|$|R
40|$|Reinforcement {{learning}} {{agents have}} traditionally been evaluated on small <b>toy</b> <b>problems.</b> With advances in computing power {{and the advent of}} the Arcade Learning Environment, it is now possible to evaluate algorithms on diverse and difficult problems within a consistent framework. We discuss some challenges posed by the arcade learning environment which do not manifest in simpler environments. We then provide a comparison of model-free, linear learning algorithms on this challenging problem set...|$|R
40|$|We give here a {{comparison}} of the expected outcome theory, the expected utility theory, and the Bayesian decision theory, by way of a simple numerical <b>toy</b> <b>problem</b> in which we look at the investment willingness to avert a high impact low probability event. It will be found that for this <b>toy</b> <b>problem</b> the modeled investment willingness under the Bayesian decision theory is minimally three times higher compared to the investment willingness under either the expected outcome or the expected utility theories, where it is noted that the estimates of the latter two theories seem to be unrealistically low. </p...|$|E
40|$|Abstract. This paper {{presents}} {{an approach to}} the joint optimization of neural network structure and weights which {{can take advantage of}} BP as a specialized decoder. The approach is validated on the <b>toy</b> <b>problem</b> of N-Input Parity Function and successfully applied to a real-world engine fault diagnosis problem. ...|$|E
40|$|The {{frequency}} estimation {{from the}} Koopman eigenvalues (phase angles) obtained via Dynamic Mode Decomposition (DMD) is addressed. Since the calculations of the frequencies from the phase angles are nonunique, the modifications of DMD for uniqueness restoration are considered. The nonlinear oscillating mode of supersonic jet, impinging the flat plate, {{is used as}} a <b>toy</b> <b>problem...</b>|$|E
40|$|We {{describe}} a new application {{of an existing}} perfect sampling technique of Corcoran and Tweedie to estimate the self energy of an interacting Fermion model via Monte Carlo summation. Simulations suggest that the algorithm in this context converges extremely rapidly and results compare favorably to true values obtained by brute force computations for low dimensional <b>toy</b> <b>problems.</b> A variant of the perfect sampling scheme which improves {{the accuracy of the}} Monte Carlo sum for small samples is also given. ...|$|R
40|$|In {{this talk}} I will survey several heroic {{as well as}} pathetic {{attempts}} to fight the clock explosion problem, that is, {{to find ways to}} scale-up the automated analysis of timed automata beyond <b>toy</b> <b>problems.</b> The survey will be biased toward efforts I was involved in and will include directions such as BDDs and canonical representations, discretization, search-based techniques, SAT and bounded model-checking, abstraction and partial-order methods. I will also explain why I think this battle is important...|$|R
40|$|The {{problem of}} {{initializing}} phase in a quantum computing system is considered. The initialization of phases {{is a problem}} when the system is initially present in an entangled state {{and also in the}} application of the quantum gate transformations since each gate will introduce phase uncertainty. The accumulation of these random phases will render the recently proposed quantum computing schemes ineffective for all but <b>toy</b> <b>problems.</b> I think I can safely say that nobody understands quantum mechanics. –Richard Feynman...|$|R
40|$|International audienceThis paper {{introduces}} two methods, {{tested on}} a <b>toy</b> <b>problem,</b> which allocate optimal separated 3 D-trajectories to air traffic flows. The first {{approach is a}} 1 vs n strategy which applies an A* algorithm iteratively to each flow. The second is a global approach using a genetic algorithm, applied to a population of trajectory sets...|$|E
40|$|This paper {{provides}} a brief introduction to learning Bayesian networks from gene-expression data. The method is contrasted with other {{approaches to the}} reverse engineering of biochemical networks, and the Bayesian learning paradigm is briefly described. The article demonstrates an application to a simple synthetic <b>toy</b> <b>problem</b> and evaluates the inference performance in terms of ROC (receiver operator characteristic) curves...|$|E
40|$|This paper {{introduces}} two methods, {{tested on}} a <b>toy</b> <b>problem,</b> which allocate optimal separated 3 D-trajectories to air traffic flows. The first {{approach is a}} 1 vs. n strategy which applies an A ∗ algorithm iteratively to each flow. The second is a global approach using a genetic algorithm, applied to a population of trajectory sets. ...|$|E
40|$|We {{propose a}} novel {{activation}} function that implements piece-wise orthogonal non-linear mappings based on permutations. It is straightforward to implement, and very computationally efficient, also {{it has little}} memory requirements. We tested it on two <b>toy</b> <b>problems</b> for feedforward and recurrent networks, it shows similar performance to tanh and ReLU. OPLU activation function ensures norm preservance of the backpropagated gradients, therefore it is potentially good for the training of deep, extra deep, and recurrent neural networks. Comment: Submitted to conference ICANN' 201...|$|R
40|$|In this paper, we {{consider}} a non-linear viscoelastic model with internal variable, thoroughly analyzed by Le Tallec et al. (Comput. Methods Appl. Mech. Engrg 1993; 109 : 233 – 258). Our {{aim is to}} study here the implementation in three dimensions of a generalized version of this model. Computational results will be analyzed to validate our model on <b>toy</b> <b>problems</b> without geometric complexity, for which pseudo-analytical solutions are known. At the end, we present a three-dimensional numerical simulation on a mechanica...|$|R
30|$|The {{proposed}} {{framework is}} instantiated on GA-TPC, denoted as parallel GA-TPC. Tested on both <b>toy</b> <b>problems</b> and antenna design problem, parallel GA-TPC finds better solutions than GA-TPC and a state-of-the-art parallel modification of GA (i.e., parallel GA-MR). Moreover, parallel GA-TPC reaches smaller std of function values of final solutions than GA-TPC and parallel GA-MR. This {{means that the}} proposed framework is effective and stable. Furthermore, computational time of parallel GA-TPC is saved about 80 % compared with the time of GA-TPC under the same simulation environment.|$|R
40|$|The {{computational}} cost {{of large-scale}} multi-agent based simulations (MABS) {{can be extremely}} important, especially if simulations have to be monitored for validation purposes. In this paper, two methods, based on self-observation and statistical survey theory, are introduced in order to optimize the computation of observations in MABS. An empirical comparison of the computational cost of these methods is performed on a <b>toy</b> <b>problem...</b>|$|E
40|$|Decision {{support systems}} require {{a form of}} {{situation}} awareness. to generate situation awareness information is needed. not all available information is necessary or equally influential. this paper proposes a way to determine which and when information is relevant. {{the goal of this}} is to minimize communication and processing of irrelevant information. our system is inspired by a few first responder experiments done in our lab. in these experiments first responders had to respond to a calamity. the information need of responders was analyzed. to have good team performance it was clear that at certain times certain information was important. we modeled a <b>toy</b> <b>problem</b> after this scenario and we use this illustrate our method of reducing irrelevant information. our <b>toy</b> <b>problem</b> consists of a bayesian network with which sensitivity analysis is used to illustrate which information is relevant. a simple tracker scenario with information theoretic techniques is used to illustrate when information is relevant...|$|E
40|$|This {{paper is}} a {{continuation}} of [1] and [2], where two algorithms were introduced, allocating optimal separated 3 D-trajectories to the main traffic flows. The reader may also refer to [3] (PhD thesis, in french) for more details. In [1], these algorithms – an A ∗ algorithm for the sequential strategy, and an evolutionary algorithm for the global optimization – were tried on a <b>toy</b> <b>problem,</b> and the two strategies were compared. In [2], the algorithms were again briefly introduced and illustrated on the same <b>toy</b> <b>problem,</b> and then applied to real traffic data, using operational aircraft performances, but with only one 3 D-trajectory per flow. In this paper, we present more realistic models of 3 D-flows, with several trajectories per origin-destination link. The 3 D-separation concept is then assessed by comparing the conflicts detected in a traffic of reference, with the conflicts detected when the aircraft belonging to the main traffic flows follow separated 3 D-trajectories. I...|$|E
40|$|The {{possibility}} of strong biases in a multicomponent Maximum Likelihood fits with component-dependent templates {{has been demonstrated}} in some <b>toy</b> <b>problems.</b> We discuss here in detail a problem of practical interest, particle identification based on time-of-flight or dE/dx information. We show that large biases can occur in estimating particle fractions in a sample if differences between the momentum spectra of particles are ignored, and we present a more robust fit technique, allowing bias-free estimation even when the particle spectra in the sample are unknown. 1...|$|R
40|$|We {{present an}} axiomatization {{of a problem}} in commonsense reasoning, characterizing the proper {{procedure}} for cracking an egg and transferring its contents to a bowl. The axiomatization is mid-sized, larger than <b>toy</b> <b>problems</b> such as the Yale Shooting Problem or the Suitcase Problem, but {{much smaller than the}} comprehensive axiomatizations associated with CYC and HPKB. This size of axiomatization permits the development of non-trivial, reusable core theories of commonsense reasoning, acts as a testbed for existing theories of commonsense reasoning, and encourages the discovery of new problems in commonsense reasoning...|$|R
40|$|International audienceIn this paper, we {{consider}} a non-linear viscoelastic model with internal variable, thoroughly analyzed by Le Tallec et al. (Comput. Methods Appl. Mech. Engrg 1993; 109 : 233 â 258). Our {{aim is to}} study here the implementation in three dimensions of a generalized version of this model. Computational results will be analyzed to validate our model on <b>toy</b> <b>problems</b> without geometric complexity, for which pseudo-analytical solutions are known. At the end, we present a three-dimensional numerical simulation on a mechanical device. Copyright Â© 2011 John Wiley & Sons, Ltd...|$|R
