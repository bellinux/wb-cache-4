24|189|Public
50|$|Quik-Call I, {{also known}} as 2+2, is a {{selective}} calling method originally used in one-way paging receivers. The Quik-Call name is a trademark of Motorola. It sends a pair of tones followed by 50 to 1,000 milliseconds of silence and then a second pair of tones. Decoders look for a valid first <b>tone</b> <b>pair</b> followed by a valid second <b>tone</b> <b>pair</b> within a defined length of time, (a time window). For example, a decoder detecting a valid first <b>tone</b> <b>pair</b> might allow up to 2 seconds for a valid second <b>tone</b> <b>pair</b> to be decoded. If no valid second tone is decoded within 2 seconds, the decoder resets and waits for another valid first <b>tone</b> <b>pair.</b> The system is less susceptible to falsing because it employs pairs of tone decoders that must detect valid tone pairs simultaneously.|$|E
5000|$|The tritone {{paradox is}} an {{auditory}} illusion {{in which a}} sequentially played pair of Shepard tones [...] separated by an interval of a tritone, or half octave, is heard as ascending by some people and as descending by others. Different populations tend to favor one of a limited set of different spots around the chromatic circle as central to the set of [...] "higher" [...] tones. Roger Shepard in 1963 had argued that such tone pairs would be heard ambiguously as either ascending or descending. However, psychology of music researcher Diana Deutsch in 1986 discovered that when the judgments of individual listeners were considered separately, their judgments depended on {{the positions of the}} tones along the chromatic circle. For example, one listener would hear the <b>tone</b> <b>pair</b> C-F as ascending and the <b>tone</b> <b>pair</b> G-C as descending. Yet another listener would hear the <b>tone</b> <b>pair</b> C-F as descending and the <b>tone</b> <b>pair</b> G-C as ascending. Furthermore, the way these tone pairs were perceived varied depending on the listener’s language or dialect.|$|E
50|$|Canada {{formerly}} used a US-style ACTS {{coin phone}} {{system with a}} <b>tone</b> <b>pair</b> which would beep once for a nickel, twice for a dime and five times on receiving a quarter. These phones did not accept $1 coins (or the later $2 coin) and disappeared with the roll-out of Nortel Millennium payphones in the 1990s. The Millennium sets do not use ACTS in-band signalling tones as all coin-handling is automated in the phone itself.|$|E
40|$|AbstractThe close {{relationship}} between temporal perception and speech processing is well established. The present study focused on the specific question whether the speech environment could influence temporal order perception in subjects whose language backgrounds are distinctively different, i. e., Chinese (tonal language) vs. Polish (non-tonal language). Temporal order thresholds were measured for both monaurally presented clicks and binaurally presented <b>tone</b> <b>pairs.</b> Whereas the click experiment showed similar order thresholds for the two language groups, the experiment with <b>tone</b> <b>pairs</b> resulted in different observations: while Chinese demonstrated better performance in discriminating the temporal order of two “close frequency” <b>tone</b> <b>pairs</b> (600 Hz and 1200 Hz), Polish subjects showed a reversed pattern, i. e., better performance for “distant frequency” <b>tone</b> <b>pairs</b> (400 Hz and 3000 Hz). These results indicate {{on the one hand}} a common temporal mechanism for perceiving the order of two monaurally presented stimuli, {{and on the other hand}} neuronal plasticity for perceiving the order of frequency-related auditory stimuli. We conclude that the auditory brain is modified with respect to temporal processing by long-term exposure to a tonal or a non-tonal language. As a consequence of such an exposure different cognitive modes of operation (analytic vs. holistic) are selected: the analytic mode is adopted for “distant frequency” <b>tone</b> <b>pairs</b> in Chinese and for “close frequency” <b>tone</b> <b>pairs</b> in Polish subjects, whereas the holistic mode is selected for “close frequency” <b>tone</b> <b>pairs</b> in Chinese and for “distant frequency” <b>tone</b> <b>pairs</b> in Polish subjects, reflecting a double dissociation of function...|$|R
40|$|This study {{examined}} the effect of three different body positions on distortion-product otoacoustic emission (DPOAE) amplitude and noise levels with multiple primary <b>tone</b> <b>pairs</b> simultaneously-presented to 36 normal-hearing female human adults. Other studies have demonstrat-ed that the simultaneously presented <b>tone</b> <b>pairs</b> method shows clinical promise as a screener, but the sequential method remains in wide-spread clinical use. Postural changes have been suggested {{to have an effect}} not only on DPOAEs, but also transient-evoked OAEs and stimu-lus-frequency OAEs. DPOAE amplitude and noise levels were recorded in seated, supine, and side-lying positions to the following order of simultaneously-presented <b>tone</b> <b>pairs</b> relative to the f 2 frequencies...|$|R
40|$|Using {{electric}} and magnetic brain responses we tested whether violations of an abstract auditory regularity are processed in auditory cortex and whether abstract auditory regularities are retained {{for at least}} 10 s. The mismatch negativity (MMN) event-related potential and its magnetic counterpart (MMNm) were recorded to infrequent <b>tone</b> <b>pairs</b> of descending pitch (the second tone having a lower frequency than the first one) embedded in a sequence of <b>tone</b> <b>pairs</b> of ascending pitch, whereas the absolute frequency of both ascending and descending <b>tone</b> <b>pairs</b> varied on seven levels. Results showed that the dominant generators of the electromagnetic activity elicited by violations of the pitch-ascension rule lie within auditory cortex. We {{also found that the}} memory representation of pitch-ascension is retained for at least 10 s. When short trains of ascending-pitched <b>tone</b> <b>pairs</b> were followed by a silent period of 8 – 12 s, descending-pitched probe <b>tone</b> <b>pairs</b> elicited the MMN component when a single reminding pair with ascending pitch was presented before the probe. The reactivating effect of the reminder was similar to what has been previously shown for concrete auditory regularities, such as the constancy of tone pitch. The present results support the view that auditory cortical functions can process sensory and categorical information in a similar manner...|$|R
50|$|GE Marc V used a {{two-tone}} sequence {{to identify}} a group: what modern systems call agency-fleet-subfleet or talk groups. Each radio {{had at least one}} <b>tone</b> <b>pair,</b> which identified the group of radios it could talk with. It was similar in format to two-tone sequential paging codes except that, in a GE Marc V system, the first tone was much longer than the second. This long first tone gave a bigger time window for all the scanning radios to find and decode a two-tone sequence. The first tone was lengthened for systems with more channels.|$|E
40|$|Background—The {{processing}} of rapidly presented stimuli {{has been shown}} to be a precursor for the perception of speech in infants, long before they learn to speak. However, the onset and early development of rapid temporal processing (RTP) skills is not yet well understood. The main goal of this study was to assess the development of RTP skills during the prenatal and early postnatal stages of life. Methodology—Tone pairs were presented in two difficulties (long and short) and event-related magnetic fields were recorded using MEG. 22 pregnant women (gestational ages between 29 and 38 weeks’) participated in the fetal study and 15 returned for a neonatal follow-up study between 2 and 38 days after delivery or 38 and 44 weeks gestational age (GA). Results—In the postnatal follow-up study, a trend towards two peaks with increasing chronological and gestational age was observed in the longer <b>tone</b> <b>pair.</b> However, no such trend was evident in neonatal responses to the short tone pairs or in fetal recordings. Conclusions—Neonates showed a gradual trend to successful {{processing of}} the longer <b>tone</b> <b>pair</b> with increasing age. By 22 days of chronological age, the infants processed this <b>tone</b> <b>pair</b> successfully...|$|E
40|$|Event-related {{potentials}} (ERPs) to tone pairs {{and single}} tones were measured for 16 participants with specific language impairment (SLI) and 16 age-matched controls aged from 10 to 19 years The tone pairs {{were separated by}} an inter-stimulus interval (ISI) of 20, 50 or 150 ms. The intraclass correlation (ICC) was computed for each participant between the ERP to a single tone and the ERP to the <b>tone</b> <b>pair.</b> A high ICC indicates that the brain response to a <b>tone</b> <b>pair</b> {{is similar to that}} for a single tone. ICCs were significantly higher at short than at long ISIs. At 50 -ms ISI, ICCs were higher for younger than older participants. Age and ISI interacted with SLI status: ERPs of older participants with SLI differed from age-matched controls, and resembled ERPs of younger controls, consistent with a theory of immature auditory processing in SLI...|$|E
50|$|These {{signals are}} {{distinctive}} when received aurally as a rapid succession of <b>tone</b> <b>pairs</b> with almost musical quality.|$|R
40|$|This study {{examined}} the effect of three different body positions on distortion-product otoacoustic emission (DPOAE) amplitude and noise levels with multiple primary <b>tone</b> <b>pairs</b> simultaneously-presented to 36 normal-hearing female human adults. Other {{studies have demonstrated that}} the simultaneously presented <b>tone</b> <b>pairs</b> method shows clinical promise as a screener, but the sequential method remains in widespread clinical use. Postural changes have been suggested to have an effect not only on DPOAEs, but also transient-evoked OAEs and stimulus- frequency OAEs. DPOAE amplitude and noise levels were recorded in seated, supine, and side-lying positions to the following order of simultaneously-presented <b>tone</b> <b>pairs</b> relative to the f 2 frequencies: 1187, 2375, and 4812 Hz; 1500, 3000, and 6062 Hz; and 1875, 3812, and 7625 Hz. No DPOAE could be detected reliably at 7625 Hz as result of poor signal-to-noise ratio. For remaining DPOAEs, statistical analyses revealed that amplitudes were not significantly different among the three body positions. However, at 1500 Hz and below, body position did have a statistically significant effect on noise levels though they are likely clinically negligible. Except at 7625 Hz, results suggest that DPOAEs recorded using a simultaneously presented <b>tone</b> <b>pairs</b> appear to be comparably recorded regardless of an individual’s body position...|$|R
30|$|In each presentation, the {{reference}} and probe tones {{were presented in}} random order, separated by a gap of 500 [*]ms between each tone. A single test session involved presenting each of the 18 <b>tone</b> <b>pairs,</b> summarized in Table 1, a total of 4 times. The <b>tone</b> <b>pairs</b> were presented from a calibrated loudspeaker (Genelec 1029 A) at 65 [*]dB(A) located 1.5 [*]m {{in front of the}} subject. The loudness of each tone was roved by ± 6 [*]dB to minimize the effects of loudness cues on the pitch-ranking task.|$|R
40|$|Spectra of Stimuli (in dB SPL) In the {{experiment}} we proof the paradoxical perception of pitch. A tone sequence demonstrates this paradox: the sequence {{is perceived as}} descending, although {{the first and last}} tone are identical. The intransitivity of pitch perception generalizes (Shepard 1964). It applies also to harmonic complex tones with variate amplitude envelope and partials that are arranged in intervals different from octaves. The paradox perception in this experiment {{as well as in the}} Shepard scale is modeled by a formula (spectrum of pitch differences) that extends the virtual pitch algorithm (Terhardt 1998) to pitch intervals. Experiment: Judgment on Pitch Comparison Circular structures A relation ‘ ’ is termed circular, if there are elements with. In contrast to a linear order ‘ ’ is not transitive. The paradox of our experiments is based on this circularity and intransitivity of pitch relation. According to common notion any tone is assigned to one pitch on a linear scale. Pitch relation is thus identified with ‘ ’ resp. ‘ ’ for real numbers. But this order is linear and transitive and thereby- as we will see- in contradiction to our experiments. Description of the Experiment The stimuli consist of tone pairs. Six tone pairs form a logical block. To each <b>tone</b> <b>pair</b> there exists another <b>tone</b> <b>pair</b> in reverse order. In addition every <b>tone</b> <b>pair</b> exists in 9 transpositions. One block contains six distinct harmonic complex tones (cf. Figure 1). Those are combined to six tone pairs: 1 with 2; 2 with 3; [...] .; 5 with 6; 6 with 1. Each of the 18 subjects has to give a judgment on pitch comparison to each tone pair: 1) ‘first tone higher’, 2) ‘second tone higher’, 3) ‘both tones are equal’, 4) ‘undecidable’. The sequence of tone pairs is presented in random order. Result A subject has perceived six tones of a block paradoxically, if there is at least one ascending <b>tone</b> <b>pair</b> and all...|$|E
30|$|Initially, the {{original}} unprocessed tones were presented and tested to familiarize the subjects with the task. For this condition, {{the test was}} conducted once, that is, each <b>tone</b> <b>pair</b> was repeated a total of 4 times. Testing the unprocessed tones also served to establish that the test material was not too difficult to begin with. Thereafter, testing proceeded with the AMO outputs for the Std, Smt-MF, and Smt-LF mappings. The order of testing of the three mappings was randomized. For each mapping condition, a training session with correct/wrong feedback was first carried out. Two test sessions without feedback were then carried out, and the results from these two sessions were collected for the final results. Thus, the results consisted {{of a total of}} 8 presentations of each <b>tone</b> <b>pair</b> for each subject. A total of 8 NH subjects were evaluated for this test. A custom test software (MACarena) [12] was used to playback sound files and record the responses.|$|E
40|$|Two same-different {{discrimination}} {{tasks were}} conducted to test whether Mandarin and English native speakers use visual cues to facilitate Mandarin lexical tone perception. In the experiments, the stimuli were presented in 3 modes: audioonly (AO), audio-video (AV) and video-only (VO) under the clear and two levels of signal-to-noise ratio (SNR) - 6 dB and - 9 dB noise condition. If the speakers’ perception of AV is better than that of AO, the extra visual information of lexical tones contributes tone perception. In Experiment 1 and 2, we found that Mandarin speakers had no visual augmentation under clear and noise conditions. For English speakers, on the other hand, extra visual information hindered their tone perception (visual reduction) under SNR - 9 dB noise. This suggests that English speakers rely more on auditory information to perceive lexical tones. Tone pairs analysis in both experiments found that visual reduction in <b>tone</b> <b>pair</b> T 2 - T 3 and visual augmentation in <b>tone</b> <b>pair</b> T 3 -T 4. It indicates that acoustic tone features (e. g. duration, contour) can be seen and {{be involved in the}} process of audiovisual perception. Visual cues facilitate or inhibit tone perception depends on whether the presented visual features of the tone pairs are distinctively recognised or highly confusing to each other...|$|E
50|$|Many dialects of Limburgish (and of Ripuarian) have a pitch accent, {{having two}} {{different}} accents used in stressed syllables. The {{difference between these}} two accents is used for differentiating both various grammatical forms of a single lexeme and minimal <b>tone</b> <b>pairs</b> one from the other.|$|R
40|$|According to {{the rapid}} {{auditory}} processing theory, the ability to parse incoming auditory information underpins learning of oral and written language. There is wide variation in this low-level perceptual ability, which appears to follow a protracted developmental course. We studied the development of rapid auditory processing using event-related potentials (ERPs) elicited by <b>tone</b> <b>pairs</b> presented at varying inter-stimulus intervals (25, 50, 100, 200, and 400 ms) {{in a sample of}} children (N = 103) aged 7 - 9 years initially and again at 9 - 11 years. We also assessed their ability to repeat nonsense words at both time-points. The amount of difference between the ERP to single <b>tones</b> and <b>paired</b> <b>tones</b> (as assessed by the intra-class correlation coefficient, ICC) provided a measure of the brain's capacity to discriminate auditory information delivered at different presentation rates. Results showed that older children showed greater neural discrimination to <b>tone</b> <b>pairs</b> than younger children at rapid presentation rates, although these differences were reduced at slower presentation rates. The ICC at time 1 significantly predicted nonword repetition scores two years later, providing support for the view that rapid auditory temporal processing ability affects oral language development in typically developing children...|$|R
50|$|It was {{possible}} for radios to have several <b>tone</b> <b>pairs</b> or groups. These {{could be used to}} make phone calls over a patch without all other users in the same group having to listen to the call. Some systems had hierarchies: manager groups could talk amongst one another without going out over everyone's radio.|$|R
40|$|Many natural stimuli have perceptual ambiguities {{that can}} be cognitively {{resolved}} by the surrounding context. In audition, preceding context can bias the perception of speech and non-speech stimuli. Here, we develop a neuronal network model that can account for how context affects the perception of pitch change between a pair of successive complex tones. We focus especially on an ambiguous comparison [...] listeners experience opposite percepts (either ascending or descending) for an ambiguous <b>tone</b> <b>pair</b> depending on the spectral location of preceding context tones. We developed a recurrent, firing-rate network model, which detects frequency-change-direction of successively played stimuli and successfully accounts for the context-dependent perception demonstrated in behavioral experiments. The model consists of two tonotopically organized, excitatory populations, Eup and Edown, that respond preferentially to ascending or descending stimuli in pitch, respectively. These preferences are generated by an inhibitory population that provides inhibition asymmetric in frequency to the two populations; context dependence arises from slow facilitation of inhibition. We show that contextual influence depends on the spectral distribution of preceding tones and the tuning width of inhibitory neurons. Further, we demonstrate, using phase-space analysis, how the facilitated inhibition from previous stimuli and the waning inhibition from the just-preceding tone shape the competition between the Eup and Edown populations. In sum, our model accounts for contextual influences on the pitch change perception of an ambiguous <b>tone</b> <b>pair</b> by introducing a novel decoding strategy based on direction-selective units. The model’s network architecture and slow facilitating inhibition emerge as predictions of neuronal mechanisms for these perceptual dynamics. Since the model structure {{does not depend on}} the specific stimuli, we show that it generalizes to other contextual effects and stimulus types...|$|E
3000|$|..., {{allows us}} to {{estimate}} transmitter/receiver IQ imbalance gain parameters in (28) and (29), respectively. The matrix should be well conditioned to obtain reliable estimates of IQ imbalance gain parameters. In general, we consider the coherence bandwidth of the channel to be small enough (or channel dispersion to be long enough) so that the channel response on the desired tone and its mirror tone are linearly independent. If the channel does not vary for a desired tone and its mirror tone over two independent channel realizations in (29), then a joint compensation scheme should be performed on that <b>tone</b> <b>pair</b> as in (15). On the other hand, (28) involves an overdetermined system of equation, thus we require only two pairs of [...]...|$|E
40|$|We {{analyzed}} 64 -‐channel EEG data recorded from 26 typically developing infants at 6 months-‐of-‐age {{and then}} again at 12 months by the Benasich laboratory at CMBN, Rutgers. The aim was to examine developmental changes in auditory response processes that follow unexpected changes in an unaMended audio stream, phenomena typically measured by the amplitude of the Mismatch Response (MMR) por 6 on of the average scalp-‐evoked auditory event-‐related poten 6 al (ERP). Materials and Methods: Twenty-‐six infants par 6 cipated in the same study twice, at 6 months and 12 months of age. The acous 6 c s 6 muli were presented in a passive oddball paradigm using a blocked design Rutgers (Benasich et al., 2006). Complex tone pairs had either a 300 or 70 ms within-‐pair inters 6 mulus interval (ISI). Tones had a fundamental frequency of 100 or 300 Hz with 15 harmonics (6 dB roll-‐off per octave). In both blocks the 100 – 100 Hz (low–low) <b>tone</b> <b>pair</b> comprised 85 % of the s 6 muli and the 100 – 300 Hz (low–high) <b>tone</b> <b>pair</b> comprised the remaining 15 %. The 70 -‐ms ISI s 6 muli were presented first followed by a second block of 300 -‐ms ISI s 6 muli. The onset-‐to-‐onset s 6 mulus onset asynchrony (SOA) was 915 and 1140 ms, and the offset-‐to-‐onset ITI was 705 and 700 ms for the 70 and 300 ISI ms condi 6 ons, respec 6 vely. EEG data were preprocessed using EEGLAB (Delorme and Makeig, 2004) including band-‐pass filtering (1 -‐ 100 Hz FIR), outlier rejec 6 on, and independent component analysis (ICA). The ICA-‐decomposed EEG source ac 6 vi 6 es were then clustered into 15 clusters. For cluster-‐ERP envelope analysis using an EEGLAB plug-‐in, std_envtopo, we used the measure ‘percent variance accounted for ’ (pvaf) in the ERP, defined as follows pva...|$|E
50|$|Autovon was {{replaced}} {{in the early}} 1990s by the Defense Switched Network; much of its infrastructure is now dismantled. Amateur radio equipment continues to be manufactured with 16-key DTMF keypads, keeping extra tones available for on-air use to control remote apparatus such as radio repeater stations. These <b>tone</b> <b>pairs</b> (labelled A, B, C, D) are rarely used.|$|R
40|$|We {{investigated}} {{how different}} psychophysical procedures affect frequency discrimination performance in children. Four studies used a design in which listeners heard two <b>tone</b> <b>pairs</b> {{and had to}} identify whether {{the first or second}} pair contained a higher frequency target tone. Thresholds for 6 - and 7 -year-olds were higher than those for 8 - and 9 -year-olds and adults. Two manipulations led to lower (better) thresholds in young children: (a) moving the standard comparison tone before the target tone and (b) using three target comparison <b>tone</b> <b>pairs.</b> It is suggested that young children benefit from designs that help cue them to when they need to attend to a target tone. The two-interval, forced-choice procedure that is widely used in studies of developmental disorders led to variable performance even in adults and did not give a realistic picture of the perceptual capabilities of children under 8 years of age. ...|$|R
40|$|While {{previous}} {{studies on the}} speaker-discriminatory power of static f 0 parameters abound, few {{have focused on the}} dynamic and linguistically-structured aspects of f 0. Lexical tone offers a case in point for this endeavour. This paper reports an exploratory study on the speaker-discriminatory power of individual lexical tones and of the height relationship of level <b>tone</b> <b>pairs</b> in Cantonese, and the effects of voice level and linguistic condition on their realization. Twenty native Cantonese speakers produced systematically controlled words either in isolation or in a carrier sentence under two voice levels (normal and loud). Results show that f 0 height and f 0 dynamics are separate dimensions of a tone and are affected voice level and linguistic condition in different ways. Moreover, discriminant analyses reveal that the contours of individual tones and the height differences of level <b>tone</b> <b>pairs</b> are useful parameters for characterizing speakers...|$|R
40|$|Distortion product otoacoustic {{emissions}} (DPOAEs) {{are traditionally}} evoked by two-tone stimuli. In this study, emission data from Mongolian gerbils are reported that were obtained with stimuli consisting {{of six to}} 10 tones. The stimuli were constructed by replacing one of the tones of a <b>tone</b> <b>pair</b> by a narrowband multitone complex. This produced rich spectra of the ear canal sound pressure in which many of the third-order DPOAEs originated from the interaction of triplets of stimulus components. A careful choice of the stimulus frequencies ensured {{that none of these}} DPOAE components coincided. Three groups of DPOAEs are reported, two of which are closely related to DPOAEs evoked by tone pairs. The third group has no two-tone equivalent and only arises when using a multitone stimulus. We analyzed the relation between multitone-evoked DPOAEs and DPOAEs evoked by tone pairs, and explored the new degrees of freedom offered by the multitone paradigm...|$|E
40|$|The {{auditory}} {{system has}} been shown to detect predictability in a tone sequence, but does it use the extracted regularities for actually predicting the continuation of the sequence? The present study sought to find evidence for the generation of such predictions. Predict-ability was manipulated in an isochronous series of tones in which every other tone was a repetition of its predecessor. The existence of predictions was probed by occasionally omitting either the first (unpredictable) or the second (predictable) tone of a same-frequency <b>tone</b> <b>pair.</b> Event-related electrical brain activity elicited by the omission of an unpredictable tone differed from the response to the actual tone right from the tone onset. In contrast, early electrical brain activity elicited by the omission of a predictable tonewas quite similar to the response to the actual tone. This suggests that the auditory systempreactivates theneural circuits for expected input, using sequential predictions to specifically prepare for future acoustic events...|$|E
40|$|Abstract Background We {{examined}} {{development of}} auditory temporal integration and inhibition by assessing electrophysiological responses to tone pairs separated by interstimulus intervals (ISIs) of 25, 50, 100, 200, 400, and 800 ms in 28 children aged 7 to 9 years, and 15 adults. Results In adults a distinct neural response was elicited to tones presented at ISIs of 25 ms or longer, whereas in children {{this was only}} seen in response to tones presented at ISIs above 100 ms. In adults, late N 1 amplitude was larger for the second tone of the <b>tone</b> <b>pair</b> when separated by ISIs as short as 100 ms, consistent with the perceptual integration of successive stimuli within the temporal window of integration. In contrast, children showed enhanced negativity only when tone pairs were separated by ISIs of 200 ms. In children, the amplitude of the P 1 component was attenuated at ISIs below 200 ms, consistent with a refractory process. Conclusions These results indicate that adults integrate sequential auditory information into smaller temporal segments than children. These results {{suggest that there are}} marked maturational changes from childhood to adulthood in the perceptual processes underpinning the grouping of incoming auditory sensory information, and that electrophysiological measures provide a sensitive, non-invasive method allowing further examination of these changes. </p...|$|E
50|$|Satellite {{programming}} {{often used}} audible dual-tone multi-frequency (DTMF) signals to trigger events at affiliate stations. This allowed the automatic local insertion of ads and station IDs. Because there are 12 (or 16) <b>tone</b> <b>pairs,</b> and typically four tones were sent {{in rapid succession}} (less than one second), more events could be triggered than by sub-audible tones (usually 25 Hz and 35 Hz).|$|R
40|$|This study {{examines}} {{the perception of}} Cantonese tones in infants learning Hong Kong Cantonese as their native language, with particular focus on the discrimination of level tones. Our findings reveal that infants at the ages of 6 - to 8 -months old were capable of discriminating {{at least some of}} the level tonal contrasts in Cantonese. The results show evidence for a possible relationship between the ease of tone discrimination and the degree of acoustic similarity between the tones. Specifically, among the <b>tone</b> <b>pairs</b> tested in our study, the pair having the greatest F 0 difference, the high-level tone (T 1) and the mid-low level tone (T 6), was best discriminated as compared with the other two <b>tone</b> <b>pairs</b> which were acoustically closer in terms of F 0 values, i. e., the high-level tone (T 1) and the mid-level tone (T 3), the mid-level tone (T 3) and the mid-low level tone (T 6). 1...|$|R
40|$|Traditionally, {{there are}} six lexical tones (T) in Cantonese, but some <b>tone</b> <b>pairs</b> appear to be merging in Hong Kong Cantonese. Some young {{speakers}} do not distinguish the two rising tones T 2 /T 5, or the two level tones T 3 /T 6, or the low falling and low level tones T 4 /T 6. 16 potential mergers and 11 control subjects participated in a perception experiment with an AX discrimination task using monosyllables. Both accuracy rate and reaction time were measured. Results show that the potential mergers generally performed less well {{than the control group}} in having a lower accuracy rate and longer reaction time, but they could still distinguish the merging <b>tone</b> <b>pairs</b> with above 90 % accuracy. Both groups found the T 2 /T 5 pair difficult to distinguish. The results indicate that the merging processing of the tones is still in progress in the language as a whole and in individual speakers. Possible reasons for these patterns are discussed...|$|R
40|$|Temporal {{integration}} is the perceptual process combining sensory stimulation over time into longer percepts that can span over 10 times {{the duration of}} a minimally detectable stimulus. Particularly in the auditory domain, such "long-term" temporal integration has been characterized as a relatively simple function that acts chiefly to bridge brief input gaps, and which places integrated stimuli on temporal coordinates while preserving their temporal order information. These properties are not observed in visual temporal integration, suggesting they might be modality specific. The present study challenges that view. Participants were presented with rapid series of successive tone stimuli, in which two separate, deviant target tones were to be identified. Critically, the target <b>tone</b> <b>pair</b> would {{be perceived as a}} single synthetic vowel if they were interpreted to be simultaneous. During the task, despite that the targets were always sequential and never actually overlapping, listeners frequently reported hearing just one sound, the synthetic vowel, rather than two successive tones. The results demonstrate that auditory temporal integration, like its visual counterpart, truly assembles a percept from sensory inputs across time, and does not just summate time-ordered (identical) inputs or fill gaps therein. This finding supports the idea that temporal {{integration is}} a universal function of the human perceptual system...|$|E
40|$|Animal {{behavioral}} studies make {{a significant}} contribution to hearing research and provide vital information which is not available from human subjects. Animal psychoacoustics is usually extremely time consuming and labor intensive; in addition, animals may become stressed, especially if restraints or negative reinforcers such as electric shocks are used. We present a novel behavioral experimental system that was developed to allow efficient animal training in response to acoustic stimuli. Cats were required to perform a relatively simple task of moving toward and away from the device depending on whether the members of a <b>tone</b> <b>pair</b> were different or the same in frequency (go/no-go task). The experimental setup proved to be effective, with all animals (N =  7) performing at above 90 % correct on an easy task. Animals were trained within 2 - 4 weeks and then generated a total of 150 - 200 trials per day, distributed within approximately 8 self initiated sessions. Data collected using this system were stable over 1 week and repeatable over long test periods (14 weeks). Measured frequency discrimination thresholds from 3 animals at 3 different reference frequencies were comparable with previously published results. The main advantages of the system are: relatively simple setup; large amounts of data can be generated without the need of researcher supervision; multiple animals can be tested simultaneously without removal from home pens; and no electric shocks or restraints are required. Restricted Access: Metadata Onl...|$|E
40|$|In {{everyday}} life, our auditory {{system is}} bombarded with many signals in complex auditory scenes. Limited processing capacities allow {{only a fraction}} of these signals to enter perceptual awareness. This magnetoencephalography (MEG) study used informational masking to identify the neural mechanisms that enable auditory awareness. On each trial, participants indicated whether they detected a pair of sequentially presented tones (i. e., the target) that were embedded within a multi-tone background. We analysed MEG activity for ‘hits’ and ‘misses’, separately for the first and second tones within a target pair. Comparing physically identical stimuli that were detected or missed provided insights into the neural processes underlying auditory awareness. While the first tone within a target elicited a stronger early P 50 m on hit trials, only the second tone evoked a negativity at 150 ms, which may index segregation of the <b>tone</b> <b>pair</b> from the multi-tone background. Notably, a later sustained deflection peaking around 300 and 500 ms (P 300 m) was the only component that was significantly amplified for both tones, when they were detected pointing towards its key role in perceptual awareness. Additional Dynamic Causal Modelling analyses indicated that the negativity at 150 ms underlying auditory stream segregation is mediated predominantly via changes in intrinsic connectivity within auditory cortices. By contrast, the later P 300 m response as a signature of perceptual awareness relies on interactions between parietal and auditory cortices. In conclusion, our results suggest that successful detection and hence auditory awareness of a two-tone pair within complex auditory scenes rely on recurrent processing between auditory and higher-order parietal cortices...|$|E
40|$|Signalled response-independent shocks were {{superimposed}} on rats' wheel-turn responding to avoid shock administered {{to their feet}} through a grid floor or to their tails through fixed electrodes. In Experiment I, a <b>tone</b> <b>paired</b> with response-independent foot shock increased responding in three of four rats; a <b>tone</b> <b>paired</b> with tail shock increased responding in only one of four rats and suppressed responding in two rats. In Experiment II, a tone presented randomly with respect to response-independent shock had no reliable effect on responding to avoid foot shock or tail shock. In Experiment III, tail shock and foot shock were compared in a within-subject design while the temporal pattern of responding during conditioned stimuli was recorded. Responding during the conditioned stimulus preceding foot shock was characterized by initial suppression of responding at tone onset, followed by increased responding just before response-independent shock. Responding was suppressed throughout the conditioned stimulus preceding tail shock. Foot shock elicited bursts of responding, but tail shock did not...|$|R
40|$|The {{perception}} of two simultaneous tones {{was investigated in}} goldfish using classical respiratory conditioning and a stimulus generalization paradigm. <b>Pairs</b> of <b>tones</b> were used {{to make up a}} mixture of 150 Hz and a higher harmonic or a mistuned harmonic. Fish were conditioned to the two-tone mixture and then tested for generalization to several pure tones. The simultaneous tones tended to be segregated in perception, with the generalization gradient for single tones having two peaks corresponding to the frequencies of the <b>tone</b> <b>pairs.</b> There were no consistent differences in the generalization gradients following conditioning to harmonic or inharmonic <b>tone</b> <b>pairs.</b> In addition, experiments were carried out in which the two <b>tones</b> of the <b>pair</b> were heard on alternate trials, always as single tones, followed by generalization tests to single tones. There was more generalization in this experiment, reflecting the fact that conditioning and generalization test stimuli were both single tones. However, the shapes of the generalization gradients were similar to those in which fish were conditioned to two simultaneous tones, indicating that the simultaneity of the tones did not make them harder to segregate. As the frequency separation between the two components narrowed, segregation tended to fail...|$|R
40|$|Abstract: We {{investigated}} {{the effect of}} task difficulty on the dynamics of auditory cortical responses. Whole-scalp magnetoencephalographic (MEG) signals were recorded while subjects performed a same/different frequency discrimination task on equiprobable <b>tone</b> <b>pairs</b> applied in blocks of five, which were separated by a 10 s intertrial interval. Task difficulty was manipulated by the interpair frequency difference. The manipulation of task difficulty affected the amplitude of the N 100 m response to the first tone and the latency of the N 100 m response to the second <b>tone</b> in each <b>pair.</b> The N 100 m responses were smaller and peaked significantly later in the difficult than in the easy condition. The later processing field (PF) responses were longer in duration in the difficult condition. In both conditions, {{the duration of the}} PF response was negatively correlated with the subject’s performance in the task, and was longer in the less successful subjects. The PF response may thus reflect the subjects’ effort to resolve the task. The N 100 m and the PF responses did not differ between the <b>tone</b> <b>pairs</b> along the five-pair trial as a function of task difficulty, suggesting that changes in response along the five-pair trial are not easily affected by high-level manipulations. Hum Brain Mapp 30 : 1592 – 1604...|$|R
