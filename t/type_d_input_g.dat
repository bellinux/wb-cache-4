0|2161|Public
3000|$|The perturbation-based {{technique}} perturbs {{a social}} network by adding, deleting or switching edges {{in a social}} network {{in order to increase}} the difficulty of identifying a node. Most of them are using greedy algorithm guided by an objective function to modify the social network step by step until the anonymized network satisfied some given conditions. Liu and Terzi proposed the K-degree Anonymous Algorithm to ensure that each network node is indistinguishable to other (K- 1) nodes [10]. Starting from the original degree sequence <b>d</b> of <b>input</b> graph <b>G,</b> the algorithm constructs a new degree sequence [...]...|$|R
30|$|Choose <b>d</b> <b>input</b> symbols {{randomly}} and uniformly in k source symbols as {{neighbors of}} the encoding symbol.|$|R
40|$|To {{determine}} {{the importance of}} specific capsule type in the pathogenesis of invasive Haemophilus influenzae disease, we compared the virulence of type b and <b>type</b> <b>d</b> strains isolated from different children with the virulence of transformation-derived type b and <b>type</b> <b>d</b> organisms. In addition, the unencapsulated derivative of these strains was also examined. Virulence was assessed by determining {{the ability of the}} strains to produce bacteremia with intranasal or subcutaneous inoculation. Unencapsulated derivatives were unable to cause bacteremia by any route; all type b strains (whether natural or derived by transformation), a natural <b>type</b> <b>d,</b> and a <b>type</b> <b>d</b> derived by transformation were able to produce bacteremia with similar frequency (42 to 62 %) when 10 (7) colony-forming units was given intranasally. Subcutaneous inoculation of 10 (3) colony-forming units of strains with the type b capsule produced bacteremia at a greater frequency than did the strains with the <b>type</b> <b>d</b> capsule (P less than 0. 002). The <b>type</b> <b>d</b> isolate was more virulent than a mutagenized derivative of the strain. We conclude that the type b strains are more virulent than <b>type</b> <b>d</b> when inoculated subcutaneously...|$|R
3000|$|... [...]. In LT coding, first an output symbol degree d is {{randomly}} {{chosen from}} Ω(.). Next, <b>d</b> <b>input</b> symbols are chosen uniformly and randomly from N [...]...|$|R
40|$|Consider a {{multilayer}} perceptron (MLP) with <b>d</b> <b>inputs,</b> a single hidden sigmoidal layer and a linear output. By adding an additional <b>d</b> <b>inputs</b> {{to the network}} with values set to {{the square of the}} first <b>d</b> <b>inputs,</b> properties reminiscent of higher-order neural networks and radial basis function networks (RBFN) are added to the architecture with little added expense in terms of weight requirements. Of particular interest, this architecture has the ability to form localized features in a d-dimensional space with a single hidden node but can also span large volumes of the input space; thus, the architecture has the localized properties of an RBFN but does not suffer as badly from the curse of dimensionality. I refer to a network of this type as a SQuare Unit Augmented, Radially Extended, MultiLayer Perceptron (SQUARE-MLP or SMLP). 1 Introduction and Motivation When faced with a new and challenging problem, the most crucial decision that a neural network researcher must make is in [...] ...|$|R
5000|$|... (a) Horizontal types (b) Vertical types(c) Annular <b>types</b> (<b>d)</b> The battery condenser.|$|R
40|$|Let B_d be the unital C^*-algebra {{generated}} by the elements u_jk, 0 2 with (d,m) ≠ (2, 2), the matrix-valued generalization of the (tensor product) quantum correlation set of <b>d</b> <b>inputs</b> and m outputs is not closed. Comment: 28 pages. Comments are welcome...|$|R
40|$|The {{problem of}} dirty paper coding (DPC) over the (multi-antenna) fading dirty paper channel (FDPC) Y = H(X + S) + Z is {{considered}} {{when there is}} imperfect knowledge of the channel state information H at the transmitter (CSIT). The case of FDPC with positive definite (p. <b>d.)</b> <b>input</b> covariance matrix was studied by the authors in a recent paper, and here the more general case of positive semi-definite (p. s. <b>d.)</b> <b>input</b> covariance is dealt with. Towards this end, the choice of auxiliary random variable is modified. The algorithms for determination of inflation factor proposed in the p. d. case are then generalized {{to the case of}} p. s. <b>d.</b> <b>input</b> covariance. Subsequently, the largest DPC-achievable high-SNR (signal-to-noise ratio) scaling factor over the no-CSIT FDPC with p. s. <b>d.</b> <b>input</b> covariance matrix is derived. This scaling factor is seen to be a non-trivial generalization of the one achieved for the p. d. case. Next, in the limit of low SNR, it is proved that the choice of all-zero inflation factor (thus treating interference as noise) is optimal in the 'ratio' sense, regardless of the covariance matrix used. Further, in the p. d. covariance case, the inflation factor optimal at high SNR is obtained when the number of transmit antennas is greater than the number of receive antennas, with the other case having been already considered in the earlier paper. Finally, the problem of joint optimization of the input covariance matrix and the inflation factor is dealt with, and an iterative numerical algorithm is developed. Comment: Presented at the 43 rd Annual Conference on Information Sciences and Systems, John Hopkins University, March 200...|$|R
30|$|<b>Input</b> <b>G</b> {{into the}} PTAS {{algorithm}} for TSP, {{and get an}} approximate TSP ring. The length of the TSP ring is |L|.|$|R
3000|$|... is the n_d^th context {{feature of}} word <b>type</b> <b>d.</b> The model {{provides}} {{two types of}} word representations once trained: Each θ [...]...|$|R
40|$|Abstract—We {{consider}} the feedback {{capacity of a}} class of symmetric finite-state Markov channels. Here, symmetry (termed “quasi-symmetry”) {{is defined as a}} generalized version of the symmetry defined for discrete memoryless channels. The symmetry yields the existence of a hidden Markov noise process that depends on the channel’s state process and facilitates the channel description as a function of input and noise, where the function satisfies a desirable invertibility property. We show that feedback does not increase capacity for such class of finite-state channels and that both their nonfeedback and feedback capacities are achieved by an independent and uniformly distributed (i. u. <b>d.)</b> <b>input.</b> As a result, the channel capacity is explicitly given as a difference of output and noise entropy rates, where the output is driven by the i. u. <b>d.</b> <b>input.</b> Index Terms—Channel capacity, channels with memory, dynami...|$|R
40|$|Two {{monoclonal}} antibodies {{against the}} cross-reactive antigens of S. cricetus (type a) and S. sobrinus (<b>type</b> <b>d)</b> were isolated. Galactose and especially melibiose inhibited the precipitin reaction markedly. Inhibition by melibiose was over 200 -fold stronger than that by galactose. This {{may indicate that}} galactose-alpha 1, 6 -glucose is the predominant antigenic determinant of this cross-reactive antigen. This antigen was also found in S. sobrinus type h strains, but no antigen was found in one <b>type</b> <b>d</b> strain (OMZ 176) ...|$|R
40|$|In {{this paper}} we {{construct}} sets of <b>type</b> (<b>d</b> 1, d 2) in the projective Hjelmslev plane. For computational purposes we restrict ourself to planes over Zps with p a prime and s> 1, but {{the method is}} described over general Galois rings. The existence of sets of <b>type</b> (<b>d</b> 1, d 2) {{is equivalent to the}} existence of a solution of a Diophantine system of linear equations. To construct these sets we prescribe automorphisms, which allows to reduce the Diophantine system to a feasible size. At least two of the newly constructed sets are ’good’ u−arcs. The size of one of them is close to the known upper bound...|$|R
40|$|In this paper, {{we study}} the {{behaviour}} of PAC learning algorithms when the input sequence is not i. i. d., but is β-mixing instead. A meta-theorem is proved, showing {{that if an}} algorithm is (i) PAC when the inputs are i. i. d., and (ii) ‘sub-additive’ in a sense defined in the paper, then the same algorithm continues to be PAC even with β-mixing inputs. It is shown that if a function family is distribution-free learnable or consistently learnable with i. i. <b>d.</b> <b>inputs,</b> then every consistent algorithm is PAC even when the input sequence is β-mixing. Explicit quantitative estimates are derived for the learning rates with β-mixing inputs, {{in terms of the}} learning rates with i. i. <b>d.</b> <b>inputs</b> and the β-mixing coefficients of the input sequence. Finally, it is shown that a large of Markov chains have the β-mixing property. Hence the results derived here have wide applicability...|$|R
3000|$|..., and β {{are fixed}} and {{consider}} how to partition and time the <b>input</b> <b>G</b> to yield {{the greatest number}} of threshold crossings, or spikes. Without loss of generality, we take [...]...|$|R
5000|$|... #Caption: Adaptive linear combiner, compact representation. k = sample number, n=input {{variable}} index, x = reference <b>inputs,</b> <b>d</b> = desired <b>input,</b> ε = error output, Σ = summation.|$|R
40|$|We {{consider}} the feedback {{capacity of a}} class of symmetric finite-state Markov channels. Here, symmetry (termed “quasi-symmetry”) {{is defined as a}} generalized version of the symmetry defined for discrete memoryless channels. The symmetry yields the existence of a hidden Markov noise process that depends on the channel’s state process and facilitates the channel description as a function of input and noise, where the function satisfies a desirable invertibility property. We show that feedback does not increase capacity for such class of finite-state channels and that both their non-feedback and feedback capacities are achieved by an independent and uniformly distributed (i. u. <b>d.)</b> <b>input.</b> As a result, the channel capacity is explicitly given as a difference of output and noise entropy rates, where the output is driven by the i. u. <b>d.</b> <b>input.</b> Index Terms Channel capacity, channels with memory, finite-state Markov channels, dynamic programming, feedback capacity. I. INTRODUCTION AND LITERATURE REVIEW Although feedback does not increase the capacity of discrete memoryless channels (DMCs...|$|R
40|$|AbstractA Moore graph of <b>type</b> (<b>d,</b> k) is {{a regular}} graph of degree d, {{diameter}} k, and girth 2 k + 1. By counting the cycles of length 2 k + 1 and 2 k + 2 of a Moore graph, it is shown {{that there are no}} Moore graphs of <b>type</b> (<b>d,</b> k) for d = 3, 4, 5, 6, 8 and 3 < k ≤ 300 except possibly for type (5, 7). It is shown that there are no Moore graphs of type (3, k) when 3 ≤ k < ∞ and 2 k + 1 is prime...|$|R
40|$|One of the {{prominent}} current challenges in complexity theory is {{the attempt to}} prove lower bounds for TC^ 0, the class of constant-depth, polynomial-size circuits with majority gates. Relying {{on the results of}} Williams (2013), an appealing approach to prove such lower bounds is to construct a non-trivial derandomization algorithm for TC^ 0. In this work we take a first step towards the latter goal, by proving the first positive results regarding the derandomization of TC^ 0 circuits of depth d> 2. Our first main result is a quantified derandomization algorithm for TC^ 0 circuits with a super-linear number of wires. Specifically, we construct an algorithm that gets as input a TC^ 0 circuit C over n input bits with depth d and n^ 1 +(-d) wires, runs in almost-polynomial-time, and distinguishes between the case that C rejects at most 2 ^n^ 1 - 1 / 5 <b>d</b> <b>inputs</b> and the case that C accepts at most 2 ^n^ 1 - 1 / 5 <b>d</b> <b>inputs.</b> In fact, our algorithm works even when the circuit C is a linear threshold circuit, rather than just a TC^ 0 circuit (i. e., C is a circuit with linear threshold gates, which are stronger than majority gates). Our second main result is that even a modest improvement of our quantified derandomization algorithm would yield a non-trivial algorithm for standard derandomization of all of TC^ 0, and would consequently imply that NEXP⊆ TC^ 0. Specifically, if there exists a quantified derandomization algorithm that gets as input a TC^ 0 circuit with depth d and n^ 1 +O(1 /d) wires (rather than n^ 1 +(-d) wires), runs in time at most 2 ^n^(-d), and distinguishes between the case that C rejects at most 2 ^n^ 1 - 1 / 5 <b>d</b> <b>inputs</b> and the case that C accepts at most 2 ^n^ 1 - 1 / 5 <b>d</b> <b>inputs,</b> then there exists an algorithm with running time 2 ^n^ 1 -Ω(1) for standard derandomization of TC^ 0. Comment: Changes in this revision: An additional result (a PRG for quantified derandomization of depth- 2 LTF circuits); rewrite of some of the exposition; minor correction...|$|R
40|$|In his seminal paper Cover used {{geometrical}} {{arguments to}} compute the probability of separating two sets of patterns with a perceptron. We extend these ideas to feedforward networks with hidden layers. There are intrinsic limitations {{to the number of}} patterns that a net of this kind can separate and we find quantitative bounds valid far any net with <b>d</b> <b>input</b> and h hidden neurons...|$|R
40|$|Let X be an {{irreducible}} smooth projective curve, of genus {{at least}} two, over an algebraically closed field k. Let M^d_G denote the moduli stack of principal G-bundles over X of fixed topological <b>type</b> <b>d</b> ∈π_ 1 (G), where G is any almost simple affine algebraic group over k. We {{prove that the}} universal bundle over X ×M^d_G is stable with respect to any polarization on X ×M^d_G. A similar result is proved for the Poincaré adjoint bundle over X × M_G^d, rs, where M_G^d, rs is the coarse moduli space of regularly stable principal G-bundles over X of fixed topological <b>type</b> <b>d.</b> Comment: 6 page...|$|R
5000|$|... #Caption: Adaptive Filter, compact representation. k = sample number, x = {{reference}} <b>input,</b> <b>d</b> = desired <b>input,</b> ε = error output, f = filter impulse response, Σ = summation, box=linear {{filter and}} adaption algorithm.|$|R
40|$|We {{study the}} sum-rate of the non-coherent, block Rayleigh fading MAC, with K single-antenna users and a {{receiver}} which employs N>=K antennas. We derive the mutual information I (x_ 1, [...] ., x_K; Y) with independent unitary isotropically distributed (i. <b>d.)</b> <b>input</b> signals, a setup {{motivated by the}} capacity analysis of point-to-point MIMO channels. The results are derived in a semi-analytical form and are valid in the whole SNR region (not only the high-SNR regime) ...|$|R
3000|$|... } are {{constructed}} from c {{which is a}} coded sequence using the information sequence <b>d</b> as <b>input.</b> Hence, all {x [...]...|$|R
5000|$|... #Caption: Adaptive linear {{combiner}} showing the combiner and the adaption process. k = sample number, n=input variable index, x = reference <b>inputs,</b> <b>d</b> = desired <b>input,</b> W = set of filter coefficients, ε = error output, Σ = summation, upper box={{linear combiner}}, lower box=adaption algorithm.|$|R
40|$|A {{feedforward}} neural net with <b>d</b> <b>input</b> neurons {{and with}} a single hidden layer of n neurons is given by [GRAPHICS] where a(j), theta(j), w(ji) {{is an element of}} R. In this paper we study the approximation of arbitrary functions f: R-d [...] > R by a neural net in an L-p(mu) norm for some finite measure mu on R-d. We prove that under natural moment conditions, a neural net with non-polynomial function can approximate any given function. (C) 1998 Elsevier Science Ltd. All rights reserved...|$|R
40|$|In this paper, {{a method}} for MIMO blind {{deconvolution}} is proposed. The method is applicable {{to the case of}} non-Gaussian i. i. <b>d.</b> <b>input</b> signals. The core of the method is an algorithm which extracts one of the input signals from the information of the output signals only. This algorithm is an non-trivial generalization of the Shalvi-Weinstein algorithm for SISO blind deconvolution and converges in super-exponential rate possibly after finite iterations. By recursive use of this algorithm, extraction of all input signals can be achieved...|$|R
40|$|The report {{investigates the}} {{short-term}} memory capacity of echo state recurrent neural networks. A quantitative measure MC of short-term memory capacity is introduced. The main {{result is that}} MC 5 N for networks with linear Output units and i. i. <b>d.</b> <b>input,</b> where N is network size. Conditions under which these maximal memory capacities are realized are described. Several theoretical and practical examples demonstrate how the short-term memory capacities of echo state networks can be exploited for dynamic Pattern recognition and stochastic sequence modeling tasks...|$|R
40|$|Notions of {{asymptotic}} equivalence {{of probability}} distributions {{and some of}} their properties are briefly presented. By applying the results on <b>type</b> () <b>d</b> asymptotic equivalence, asymptotic (3) d joint normality of a set of increasing number of sample quantiles are discussed, which improves and refines the previous work by Ideda and Matsunawa (1972). 1...|$|R
5000|$|... <b>d.</b> giving <b>input</b> to the BPK in {{the matters}} of the annual audit work plan, audit impediments, {{as well as the}} {{presentation}} and quality of reports (Clause 113).|$|R
40|$|We {{consider}} the stochastic input–output properties {{of a simple}} non-linear dynamical system, the so-called Page–Hinkley detector, playing {{a key role in}} change detection, and also in queuing theory. We show that for L-mixing inputs with negative expectation the output process of this system is L-mixing. The result is applied to get an upper bound for the false alarm rate. The proof is then adapted to get a similar result for the case of random i. i. <b>d.</b> <b>inputs.</b> Possible extensions and open problems are given in the discussion...|$|R
40|$|We {{study the}} problem of channel {{resolvability}} for fixed i. i. <b>d.</b> <b>input</b> distributions and discrete memoryless channels (DMCs), and derive the strong converse theorem for any DMCs that are not necessarily full rank. We also derive the optimal second-order rate under a condition. Furthermore, {{under the condition that}} a DMC has the unique capacity achieving input distribution, we derive the optimal second-order rate of channel resolvability for the worst input distribution. Comment: 7 pages, a shorter version will appear in ISIT 2014, this version includes the proofs of technical lemmas in appendice...|$|R
5000|$|Given an <b>input</b> graph <b>G,</b> the {{following}} [...] "algorithm" [...] solves the above problem: ...|$|R
40|$|This {{manuscript}} {{has been}} reprioduced from the mkdÎim master. UMI films the tex! diredty {{from the original}} or ooqy submïtW. Thus, some thesis and dissertation copies are in typewriter face, mile aUms rnay be f m any <b>type</b> <b>d</b> cornputer pfinter. The quality of thk mpmâuctkn k dependent upon the qwlity of the copy submitteâ. Broken or inôiin...|$|R
40|$|This {{manuscript}} has bb(M fCWn the microfilm master. UMI films the iext directly fKHn th original or wpy uiknitteâ. Thus, some thesis and dissertation copies are in typeniriter face, Mi othem may be {{from any}} <b>type</b> <b>d</b> cornputer prinber. The qmlityofthk reproduction kd 8 pmdontupom th. qwlity dth. copy submiüad. Broken or indistinct print, cdomâ or poor quality illustrations and phatographs...|$|R
40|$|A (central) {{arrangement}} is a finite family of one codimensional subspaces of a vector space V. Relations between the module of logarithmic forms of and the module of logarithmic forms of ∖{ H } are studied. It is {{found that the}} logarithmic q-forms of are generated by the logarithmic forms of the <b>type</b> <b>d</b> α α if is k-generic and q ≤ k- 2...|$|R
