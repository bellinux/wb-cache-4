0|27|Public
40|$|Master Thesis Statistical estimators {{and their}} tail {{behavior}} provides description of two type of characteristics of robustness of estimators - tail behavior and <b>break-</b> <b>down</b> point. Description {{is made for}} translation equivariant estimators in general and also for some concrete type of estimators, sample mean, sample median, trimmed mean, Huber estimator and Hodges Lehmann estimator. Tail behavior of these estimator is illustrated for random sample coming from t-distribution with 1 to 5 degrees of freedom. Ilustration is based on simulations made in Mathematica. ...|$|R
40|$|This paper {{studies the}} problem of {{locating}} breakdown mechanic. We consider a public transport network in which it can provide buses failure. The objective is, {{taking into account the}} statistics of breakdowns registered on the network, to locate optimally breakdown mechanics so as to minimize the response time (to ensure the network coverage of <b>break-</b> <b>down</b> mechanics). In this work, we present a binary linear programming model for this location problem which provides assignments-locations of areas served. Once the location made, we discuss dynamic assignment of breakdown mechan- ics depending on their position in the network at a given time t. Numerical simulation results are presented based on real data of urban transportation society of Dakar Dem Dikk...|$|R
40|$|Symbiotic association, ~ {{traditionally}} {{have been treated}} as evolutionary curios {{rather than as a}} major source of evolutionary innovation. Recent research {{on a wide variety of}} organisms i: Â¢ changing this view and is <b>break-ing</b> <b>down</b> the barriers between the traditional categories of parasitism, commensalism and mutualism, to produce a more flexible view of multispecific interactions. An especially abundant, but little discussed, mutualism exists between parasitoid wasps in the superfamily Ich-neumonoidea and a novel form of DNA viruses known as polydnaviruses. Mutualisms between viruses and eukaryotes are not often reported, although as many as I 00 000 species of organisms may exhibit this unusual association. In this review J im Whioq~eld considers what is known about he parasitoid-polydnavirus elationshi...|$|R
5000|$|Adenosine {{triphosphate}} (ATP) is {{the main}} [...] "energy currency" [...] for organisms; the goal of metabolic and catabolic processes are to synthesize ATP from available starting materials (from the environment), and to <b>break-</b> <b>down</b> ATP (into adenosine diphosphate (ADP) and inorganic phosphate) by utilizing it in biological processes. [...] In a cell, the ratio of ATP to ADP concentrations {{is known as the}} [...] "energy charge" [...] of the cell. A cell can use this energy charge to relay information about cellular needs; if there is more ATP than ADP available, the cell can use ATP to do work, but if there is more ADP than ATP available, the cell must synthesize ATP via oxidative phosphorylation.|$|R
40|$|We {{investigate}} {{the performance of}} robust estimates of multi- variate location under non-standard data contamination models such as componentwise outliers (i. e. contamination in each variable is independent from the other variables). This model brings up a possible new source of statistical error that we call "propagation of outliers". This source of error is unusual {{in the sense that}} it is generated by the data processing itself and takes place after the data has been collected. We define and derive the in uence function of robust multivariate location estimates under flexible contamination models and use it to {{investigate the}} effect of propagation of outliers. Furthermore, we show that standard high-breakdown affine equivariant estimators propagate outliers and therefore show poor <b>break-</b> <b>down</b> behavior under componentwise contamination when the dimension d is high. status: publishe...|$|R
40|$|The {{deployment}} of virus-resistant crops {{often leads to}} the emergence of resistance-breaking (RB) pathogens that suppress the yield benefit provided by the resistance [1]. Although <b>break-</b> <b>downs</b> are well known for plant genes conferring total, i. e. qualitative resistance to the virus, they are still poorly understood for plant genetic factors conferring partial, i. e. quantitative resistance. Furthermore, it has been proved for several pathosystems that combining qualita- tive and quantitative resistances can increase the durability of the qualitative resistance [2, 3]. Two mechanisms can explain this result : either (i) an increase of genetic drift in the virus population, or (ii) a decrease of the selection advantage of the RB mutant. Here, we aim at disentangling the role of these two mechanisms on the durability of plant qualitative resistances to viruses...|$|R
40|$|A {{molecular}} dynamics simulation of planar Couette flow is presented for the minimal channel in which turbulence structures can be sustained. Evolution over a single <b>break-</b> <b>down</b> and regeneration cycle is compared to computational fluid dynamics simula- tions. Qualitative similar structures are observed and turbulent statistics show excellent quantitative agreement. The molecular scale {{law of the wall}} is presented in which stick-slip molecular wall-fluid interactions replace the no-slip conditions. The impact of grid resolution is explored and the observed structures are seen to be dependent on averaging time and length scales. The kinetic energy spectra show that a range of scales are present in the molecular system and that spectral content is dependent on the grid resolution employed. The subgrid velocity of the molecules is studied using joint probability density functions, molecular trajectories, di ff usion, and Lagrangian statistics. The importance of sub-grid scales, relevance of the Kolmogorov lengthscale, and implications of molecular turbulence are discussed...|$|R
40|$|Dual-comb {{spectroscopy}} (DCS) has widespread applications. It {{has become}} a more prominent spectroscopic tool because it has broad spectral coverage with high frequency resolution. We demonstrate the broadband and high resolution of DCS to probe transient events, showing the rst use of DCS of laser-induced plasmas (LIPs). Our measurements span absorption features 7 THz wide, simultaneously detecting Rb D 2, K D 1 and D 2 absorption lines {{with the ability to}} resolve the isotope ratios in the Rb D 2 line. This technique is more broadband and faster than tunable laser absorption spectroscopy because it eliminates the requirement to scan across transitions. Additionally, DCS makes higher resolution measurements than laser-induced <b>break-</b> <b>down</b> spectroscopy. Our ultimate goal is to use DCS as a technique to ascertain the chemical composition of unknown samples. Our rst demonstration of this technique illustrates that DCS makes broadband, high-resolution measurements with the ability to measure isotope ratios, which is necessary for determining sample composition...|$|R
40|$|International audiencePlant litter {{breakdown}} {{is a key}} ecological {{process in}} terres- trial and freshwater ecosystems. Streams and rivers, in particular, contribute substantially to global carbon fluxes. However, there is little information available on the relative roles of different drivers of plant litter <b>break-</b> <b>down</b> in fresh waters, particularly at large scales. We present a global-scale study of litter breakdown in streams to compare the roles of biotic, climatic and other environ- mental factors on breakdown rates. We conducted an experiment in 24 streams encompassing latitudes from 47. 88 N to 42. 88 S, using litter mixtures of local species dif- fering in quality and phylogenetic diversity (PD), and alder (Alnus glutinosa) to control for variation in litter traits. Our models revealed that breakdown of alder was driven by climate, with some influence of pH, whereas variation in breakdown of litter mixtures was explained mainly by litter quality and PD. Effects of litter quality and PD and stream pH were more positive at higher temp- eratures, indicating that different mechanisms may operate at different latitudes. These results reflect global variability caused by multiple factors, but unexplained variance {{points to the need}} for expanded global-scale comparisons...|$|R
40|$|Modeling and {{simulation}} of industrial information communication systems and networks {{is one of}} the major concerns of productivity engineers for the establishment of productivity standards in virtually all functional areas of an industrial organization. Maintenance function is one of such areas that have always engaged the attention of engineering productivity practitioners. However, one of the basic prob- lems is the difficulty in setting up integrated but easy and practical measurement schemes. Even where the measures are set up, the approaches to measurement sometimes are conflicting. Therefore the need for an integrated approach to optimize the basket of parameters measured remains. In this chapter the author attempts to identify approaches in integrated and systematic maintenance productivity measurement and create models for optimising total productivity in maintenance systems. Visual yardstick, utility, queuing systems and simulations approaches for measurement of maintenance productivity are all discussed with a particular focus on markov chain approach for stochastic <b>break-</b> <b>downs</b> in repairable systems [...] The chapter also shows how understanding the impact of plant failure and repair/service distributions assists in providing measures for maintenance productivity using discrete event system simulation. ...|$|R
40|$|Recent {{literature}} {{has suggested that}} pyroglutamate (PCA) formation in stratum corneum occurs by spontaneous cyclization of glutamine residues derived from filaggrin <b>break-</b> <b>down.</b> This paper describes an enzymatic alternative. Epidermal homogenates from hairless mice were found to catalyze the formation of PCA from both glutamine and glutamic acid at pH 6. 2. Enzyme activity responsible for {{the first step in}} this reaction, Î³-glutamyl peptide formation, was partially purified using ammonium sulfate precipitation followed by ion exchange, gel filtration, and hydroxylapatite chromatography. Enzyme preparations free of Î³-glutamyl cyclotransferase activity (which forms PCA from certain Î³-glutamyl peptides) catalyzed formation of Î³-glutamyl-glutamine from glutamine and Î³-glutamyl-glutamate from glutamic acid. Enzyme preparations catalyzed hydrolysis of a variety of Î³-glutamyl peptides but did not split non-Î³-glutamyl peptides or the transpeptidase substrate Î³-glutamyl-p-nitroanilide. Ammonium sulfate fractions containing both Î³-glutamyl peptidase and Î³-glutamyl cyclotransferase activity catalyzed linear formation of PCA from glutamic acid for periods of up to 19 h. Using Î³-glutamyl-leucine as a substrate, Î³-glutamyl peptidase activity was found to be much higher in crude extracts from epidermis than in preparations from liver, kidney, spleen, intestine, lung, brain, or heart. This activity has not, to our knowledge, been previously described in mammalian tissues...|$|R
40|$|Epitaxial {{graphene}} on {{silicon carbide}} is a promising {{material for the}} next generation of quantum Hall re- sistance standards. Single Hall bars made of graphene have already surpassed their state-of-the-art GaAs based counterparts as an RK/ 2 (RK = h/e^ 2) standard, showing at least the same precision and higher <b>break-</b> <b>down</b> current density. Compared to single devices, quantum Hall arrays using parallel or series connection of multiple Hall bars can offer resistance values spanning several orders of magnitude and (in case of parallel connection) significantly larger measurement currents, but impose strict requirements on uniformity of the material. To evaluate the quality of the available material, we have fabricated arrays of 100 Hall bars con- nected in parallel on epitaxial graphene. One out of four devices has shown quantized resistance that matched the correct value of RK/ 200 within the measurement precision of 1 e- 4 at magnetic fields between 7 and 9 Tesla. The defective behaviour of other arrays is attributed mainly to non-uniform doping. This result con- firms the acceptable quality of epitaxial graphene, pointing towards the feasibility of well above 90 % yield of working Hall bars...|$|R
40|$|WET LITTER in poultry houses is {{a problem}} of {{considerable}} economic and pathological importance. Charles et al. (1942) reported that water can become a problem in poultry litter management. Eley and Hoffman (1949) suggested that the level of dietary protein may affect the amount of moisture in the droppings which should in turn directly affect the moisture content of the litter. James and Wheeler (1949) and Wheeler and James (1950) showed the amount of water consumed as well as the amount of droppings produced varied almost directly with the percent of protein in the diet. The direct association of the dietary protein content and the amount of water consumed are probably related to the well known fact that greater amounts of water are required for the metabolism of pro-tein than for carbohydrates or fats. A par-tial explanation for the relationship of pro-tein content of the diet to the amount of droppings produced may be that some of the extra weight of the droppings is due to increased elimination of nitrogen as uric acid. Since the fowl is incapable of <b>break-ing</b> <b>down</b> uric acid into urea, an appreci-able amount of water consumed is, there-"This manuscript is published with the permis-sion of the Director of the West Virginia Univer...|$|R
40|$|The {{central issue}} of this thesis is {{investigating}} the eventuality of systemic <b>break-</b> <b>downs</b> in the international financial system through examining systemic depen- dence between bank and insurance sectors. Standard models of systemic risk often use correlation of stock returns to evaluate the magnitude of intercon- nectedness between financial institutions. One of the main drawbacks {{of this approach is}} that it is oriented towards observations occurring along {{the central part of the}} distribution and it does not capture the dependence structure of outlying observations. To account for that, we use methodology which builds on the Extreme Value Theory and is solely focused on capturing dependence in extremes. The analysis is performed using the data on stock prices of the EU largest banks and insurance companies. We study dependencies in the pre- crisis and post-crisis period. The objective is to discover which sector poses a higher systemic threat to the international financial stability. Also, we try to find empirical evidence about an increase in interconnections in recent post- crisis years. We find that in both examined periods systemic dependence in the banking sector is higher than in the insurance sector. Our results also in- dicate that extremal interconnections in the respective sectors increased, [...] ...|$|R
40|$|Cloud {{computing}} has {{paved the}} way to the flexible deployment of software applications. This flexibility offers service providers a number of options to tailor their deployments to the observed and foreseen customer workloads, without incurring in large capital costs. However, cloud deployments pose novel challenges regarding application reliability and performance. Ex- amples include managing the reliability of deployments that make use of spot instances, or coping with the performance variability caused by multiple tenants in a virtualized environment. In this paper we introduce L INE, a tool for performance and reliability analysis of software applications. L INE solves Layered Queueing Network (LQN) models, a popular class of stochastic models in software performance engineering, by setting up and solving an associated system of ordinary differential equations. A key differentiator of L INE compared to existing solvers for LQNs is that L INE incorporates a model of the environment the application operates in. This enables the modeling of reliability and performance issues such as resource failures, server <b>break-</b> <b>downs</b> and repairs, slow start-up times, resource interference due to multi-tenancy, among others. This paper describes the L INE tool, its support for performance and reliability modeling, and illustrates its potential by comparing L INE predictions against data obtained from a cloud deployment. We also illustrate the applicability of L INE with a case study on reliability-aware resource provisioning...|$|R
40|$|Within {{hours after}} Hurricane Sandyâs landfall, doctors and staff {{at one of}} New York Cityâs premier medical centers {{realized}} that something was going terribly wrong. Lights were flickering, critical devices essential to life support for more than 200 patients, many in intensive care units, were malfunctioning. A decision {{had to be made}} by hospital leaders, senior public health officials, and emergency responders: tough it out in a hospital without power or attempt a perilous patient evacuation as an epic disaster unfolded. With little time to lose, the âgoâ order was given, followed by frantic calls to high-ground hospitals identifying beds for receiving New York UniversityâLangone Medical Centerâs critically ill patients. St. LukeâsâRoosevelt, Mt. Sinai, New York Presbyterian at Columbia, and many other hospitals responded immediately, opening beds, readying emergency admission procedures, and briefing staff. But questions about why these extreme measures were necessary will have to be answered in the months ahead. Although the first question may be how to prevent power failure, the nuances of backup and redundant power generation are not generally within the expertise of health professionals. And in fact, the generators themselves were probably fine; the problem appears to have been that fuel pumps supplying the generators were in the basement, highly susceptible to <b>break-</b> <b>down</b> from flooding. Ways of ensuring resiliency of backup power equipment will certainly be investigated later. For now, itâs important to understand what medical and public health challenges are to be expected after mega-disasters such as Hurricane Sandy...|$|R
40|$|Review:This "book" {{is both an}} {{encouraging}} and a discouraging one to re- view: encouraging {{because it is a}} welcome indication of the <b>break-</b> <b>down</b> in parochialism in publications from the different areas producing new literature in English; discouraging because it resembles an issue of a periodical, covering a wide range of only generally related essays, making it difficult to review adequately. The best one can hope to do is to suggest something of the range of material covered and the rather uneven quality of the contributions. Bruce King's opening paper, "Varieties of African Literature," with its reminder of the diversity of cultures so often buried under the umbrella term African, is a particularly timely one. In a period when African nations are rapidly becoming the new ideological and literal battleground for the superpowers, it is more essential than ever that we perceive clearly the wide range of religious, linguistic, and historical forces which have shaped the parts of this complex continent into well-defined and often quite disparate areas. King's essay sets the ground for this exercise by setting out in a series of thumbnail sketches the essential historical formative influences that have led to distinctive national differences perceivable in the literature to which they have given rise. The individual critical insights he derives are not especially pro- found: for example, there is little startingly original in such a comment (found on p. 8) as Review By :Gareth Griffiths, Research in African Literatures Vol. 12, No. 2 (Summer, 1981), pp. 273 - 279...|$|R
40|$|Wavelet {{transformation}} {{is used in}} order to seek for differences in the initial <b>break-</b> <b>down</b> process between negative cloud-to-ground flash (CGâ), positive CG (CG+), cloud flash (IC), and isolated breakdown (IB) processes. 72 waveforms were selected from 885 waveforms recorded between May and August 2010 at the premise of Uppsala University, Uppsala, Sweden. The analysis was conducted only on the first electric field pulse for each lightning process and the output from the wavelet {{transformation is}} plotted as normalized power spectrum. The first pulses in CGâ are found to radiate intensely in average frequency between 186 and 1637 kHz. The energy radiated by the first pulses of CG+ mainly concentrated in the average frequency between 57 and 599 kHz. As for the IC, the first pulses found to be spread out in the average frequency between 461 and 3570 kHz and for IB, the energy spread out between 44 and 279 kHz. The CG+ and IB flashes tend to radiate at lower frequency region within smaller range compared to CGâ and IC. IB has the smallest frequency range around 235 kHz while the frequency range of IC and CGâ are more than 10 times and 6 times larger than IB, respectively. Furthermore, IC and CGâ have comparable initial-to-overshoot peak ratio with 1. 7 and 1. 6, respectively, which higher than CG+ and IB at least with a factor of 1. 4. It can be speculated that the initial breakdown processes of IC and CGâ flashes are most likely initiated from the same discharge process in the thundercloud and differ from the discharge process of CG+ and IB...|$|R
40|$|Assessment of the {{condition}} of ecosystems is a critical prerequisite for alleviating effects of the multiple anthropogenic stresses imposed on them. For stream ecosystems, a multitude of approaches has been proposed for this purpose. However, they all rest on the assessment of structural attributes, {{even though it is}} generally recognized that adequate characterization of ecosystems requires information on both structure (pattern) and function (process). Therefore, we propose a complementary approach to stream assessment based on evaluating ecosystem level processes. Leaf litter breakdown is a prime candidate to consider in this context. This is because of the pivotal role that allochthonous litter plays in streams, the demonstrated effects of anthropogenic perturbations on litter breakdown, and the relative ease of implementation. Leaf breakdown is governed by a variety of internal and external factors that complicate the partitioning of effects due to anthropogenic stress and natural variability (background noise), thus potentially limiting the sensitivity and robustness of litter breakdown assays. However, internal regulation factors can be controlled by standardizing assessment procedures, while variability due to external factors can be accounted for by stream classification and/or a comparative approach (e. g., downstream-upstream comparisons). Composite parameters such as ratios of <b>break-</b> <b>down</b> rates in fine-mesh and coarse-mesh bags may further increase the power of litter breakdown assays. Analyses may also be extended to include both leaf-associated decomposer assemblages (i. e., structural measures) and processes (i. e., additional functional measures). Significant efforts are required for developing standard assessment schemes as refined as extant procedures based on structural stream attributes (e. g., structure of macroinvertebrate assemblages). These efforts are nevertheless worthwhile in view of the new dimension that is added to current assessment procedures when functional elements are incorporated...|$|R
40|$|Breast and {{prostate}} cancer survivors and advocates partici-pated as panelists with scientists in an interactive panel dis-cussion following 2 days of scientific presentations on âEs-trogens as Endogenous Carcinogens in the Breast and Prostate. â Advocates raised several {{issues of concern}} and questions related to the research presented. Concerns in-cluded the following: 1) a global fear of developing either breast or {{prostate cancer}} and recurrence from these tumors, 2) a specific fear that estrogen replacement therapy could enhance {{the development of new}} breast cancers and stimu-late recurrence in breast cancer survivors, and 3) a concern that researchers examining minority communities should have sensitivity to the specific culture under study and an understanding of specific research issues that are relevant in those communities. The questions raised included the follow-ing: 1) What are the implications of resistance to antiestro-gen therapies and what is the appropriate sequencing of hormone therapy for longer-term benefit? 2) Can one iden-tify women and men at risk for cancer who do not have the usual risk factors? 3) Where does the development of blood or urine tests to screen for cancer currently stand? 4) Can research findings be translated into effective therapies more rapidly? 5) Can the status of this translational process be communicated to the public in a meaningful way by <b>break-ing</b> <b>down</b> language barriers? 6) What means are available to develop more creative ways to fund pilot studies that do not require preliminary data and to create new funding mecha-nisms to respond to the needs of scientists, particularly those that work collaboratively from multiple institutions and multidisciplines? 7) How can the need for increased empha-sis on and visibility for prostate cancer be communicated? Following the interactive dialogue, scientists and advocates suggested more collaborative research with sustained fund-ing avenues, continued dialogue and collaboration between scientists and advocates, and more collaborative researc...|$|R
40|$|Candidiasis of {{the oral}} mucosa arises chiefly as a re- sult of {{infection}} with Candida albicans. Many clinico- pathological analyses of macroscopic findings have been described, although the clinical findings of oral candidiasis vary considerably and the conditions are complex. The present study analyzes the distribution, clinical, cytological and histological diagnoses of oral candidiasis, associated complex diseases and the di-agnostic value of cytology. The ratio of Candida in-fection was 28. 9 % among 1551 study participants. Females were infected significantly more often than men (p < 0. 01) and the affected age range was 60 - 79 years (61. 0 %, p < 0. 01). The predominantly affected areas were the tongue (48. 3 %, p < 0. 01) and gingiva (20. 0 %, p < 0. 01), and occurrence at multiple loci was seen in 43 (9. 6 %) patients. The typical clinical find- ings of oral candidiasis were ulcerative/erythematous lesions (33. 2 %, p < 0. 01) and pseudomembranous candidiasis (31. 6 %, p < 0. 01). A histopathological dia- gnosis of candidiasis based on biopsy specimens from 26 lesions in patients with Candida infection indicated by cytology was confirmed from cultures. The <b>break-</b> <b>down</b> of a cytological to a definite diagnosis was 6 positive (SCC 4, verrucous carcinoma 1, moderate to severe dysplasia 1), 6 suspected positive (mild dyspla- sia, 2; moderate to severe dysplasia, 2; papilloma, 1 and SCC, 1) and 14 negative (epulis, 3; papilloma, 3; granulation tissue, 2; fibrosis, 2 and others, 4). Exfo-liative cytology can easily judge the presence of Can-dida species, although experience {{is necessary for the}} presumptive diagnosis of an oral mucosal disease. The application of exfoliative cytology using the Pe- riodic acid-Schiff reaction is helpful for the earlier detection of oral candidiasis with various macrosco- pic findings...|$|R
40|$|International audienceAssessment of the {{condition}} of ecosystems is a critical prerequisite for alleviating effects of the multiple anthropogenic stresses imposed on them. For stream ecosystems, a multitude of approaches has been proposed for this purpose. However, they all rest on the assessment of structural attributes, {{even though it is}} generally recognized that adequate characterization of ecosystems requires information on both structure (pattern) and function (process). Therefore, we propose a complementary approach to stream assessment based on evaluating ecosystem level processes. Leaf litter breakdown is a prime candidate to consider in this context. This is because of the pivotal role that allochthonous litter plays in streams, the demonstrated effects of anthropogenic perturbations on litter breakdown, and the relative ease of implementation. Leaf breakdown is governed by a variety of internal and external factors that complicate the partitioning of effects due to anthropogenic stress and natural variability (background noise), thus potentially limiting the sensitivity and robustness of litter breakdown assays. However, internal regulation factors can be controlled by standardizing assessment procedures, while variability due to external factors can be accounted for by stream classification and/or a comparative approach (e. g., downstream-upstream comparisons). Composite parameters such as ratios of <b>break-</b> <b>down</b> rates in fine-mesh and coarse-mesh bags may further increase the power of litter breakdown assays. Analyses may also be extended to include both leaf-associated decomposer assemblages (i. e., structural measures) and processes (i. e., additional functional measures). Significant efforts are required for developing standard assessment schemes as refined as extant procedures based on structural stream attributes (e. g., structure of macroinvertebrate assemblages). These efforts are nevertheless worthwhile in view of the new dimension that is added to current assessment procedures when functional elements are incorporated...|$|R
40|$|A new {{generation}} of lepton colliders capable of reaching TeV energies is pres- ently under development, and to succeed in this task {{it is necessary to}} show that the technology for such a machine is available. The Compact Linear Collider (CLIC) is a possible design option among the future lepton collider projects. It consists of two normal-conducting linacs. Accelerating structures with a gradient of the order of 100 MV/m are necessary to reach the required high energies within a reasonable machine length. One of the strictest require- ments for such accelerating structures is a relatively low occurrence of vacuum arcs. CLIC prototype structures have been tested in the past, but only in absence of beam. In order to proof the feasibility of the high gradient technology for building a functional collider, it is necessary to understand the effect of the beam presence on the vacuum breakdowns. Tests of this type have never been performed previously. The main goal of this work is to provide a first measurement of the <b>break-</b> <b>down</b> rate with beam in the accelerating cavity. The setup, the experimental procedure and the results of the tests executed on a prototype cavity for the Main Beam of CLIC are described. The test were executed at CERN in the CLIC Test Facility 3 (CTF 3), which houses a 12 GHz X-band Test Stand (XBOX). The XBOX supplies the radio-frequency power to the cavity prototype, while the beam is provided by the electron linac of the CTF 3, reconfigured to produce a Main Beam-like pulse. A comparison between results obtained without beam and with different beam configurations will be presented, in an attempt to understand the beam effect on the breakdown rate. Moreover, future developments to improve the experimental setup and the operation of the tests stand will be proposed, based on the experience gained on high gradient testing with beam. This will be useful in case the experiment is repeated to complement and extend the results of this work...|$|R
40|$|Plasma cloud {{formation}} from arcing is experimentally studied. The arcs are formed {{by a high}} voltage set-up in the space simulation chamber at UiT. The plasma clouds are observed as large structures in the time series recorded by Langmuir probe and reference probe. By using the method of conditional averaging, the structures are accentuated. The electron cloud formed by arcing {{was found to be}} characterized by a steep drop from zero current to a minimum, then relaxation towards zero current. Additionally, we found the magnitude of the amplitude to the electron cloud to be decreasing when the distance between the arc and the movable probe is increased. The average electron cloud velocity was found to be ve = 1 : 32 106 msï¿½ï¿½ï¿½ï¿½ï¿½ 1. The ion cloud formed by arcing was found to be characterized by a current above the steady state, which then increases logarithmically to a maximum, and then relaxes back to the steady state. However, the ion cloud measurement revealed a negative spike before the ion cloud, which indicates the electrons from an arc are energetic enough to be recorded by a negatively biased probe. The average ion cloud velocity was found to be vi = 119 : 2 msï¿½ï¿½ï¿½ï¿½ï¿½ 1, however the uncertainty was large due to high scattering. During the experiment, we discovered that breakdown of gas causes an arc-like be- haviour of the electrons. By applying the method of conditional average, a distortion was revealed. This result led us to a new condition that revealed that a high voltage breakdown gives rise to an electron cloud with the velocity vH = 7694 msï¿½ï¿½ï¿½ï¿½ï¿½ 1, while the low voltage breakdown give rise an electron cloud with the velocity vL = 5441 msï¿½ï¿½ï¿½ï¿½ï¿½ 1. Additionally, the amplitude of the electron cloud from the high voltage breakdown were signi cantly larger than he lower breakdown voltage. It is apparent the higher <b>break-</b> <b>down</b> voltage creates a more energetic electron cloud than a lower breakdown voltage...|$|R
40|$|This {{thesis is}} {{concerned}} with maximising the efficiency of hosting of service provisioning systems consisting of clusters or networks of servers. The tools employed are those of probabilistic modelling, optimization and simulation. First, a system where the servers in a cluster may be switched dynamically and preemptively from one kind of work to another is examined. The demand consists of two job types joining separate queues, with different arrival and service characteristics, and also different relative importance represented by appropriate holding costs. The switching of a server from queue i to queue j incurs a cost which may be monetary or may involve a period of unavail- ability. The optimal switching policy is obtained numerically by solving a dynamic programming equation. Two heuristic policies - one static and one are evaluated by simulation and are compared to the optimal dynamic - policy. The dynamic heuristic is shown to perform well over a range of pa- rameters, including changes in demand. The model, analysis and evaluation are then generalized to an arbitrary number, M, of job types. Next, {{the problem of how}} best to structure and control a distributed com- puter system containing many processors is considered. The performance trade-offs associated with different tree structures are evaluated approximately by applying appropriate queueing models. It is shown that. for a given set of parameters and job distribution policy, there is an optimal tree structure that minimizes the overall average response time. This is obtained numerically through comparison of average response times. A simple heuris- tic policy is shown to perform well under certain conditions. The last model addresses the trade-offs between reliability and perfor- mance. A number of servers, each of which goes through alternating periods of being operative and inoperative, offer services to an incoming stream of demands. The objective is to evaluate and optimize performance and cost metrics. A large real-life data set containing information about server <b>break-</b> <b>downs</b> is analyzed first. The results indicate that the durations of the oper- ative periods are not distributed exponentially. However, hyperexponential distributions are found to be a good fit for the observed data. A model based on these distributions is then formulated, and is solved exactly using the method of spectral expansion. A simple approximation which is accu- rate for heavily loaded systems is also proposed. The results of a number of numerical experiments are reported. EThOS - Electronic Theses Online ServiceBritish Telecom, North-East Regional e-Science CentreGBUnited Kingdo...|$|R
40|$|In {{dielectric}} {{insulating materials}} subjected to alternating electric fields there are energy losses associated with polarization mechanisms and resistivity. A typical dielectric material used for insulation of high voltage sub-marine cables is cross-linked polyethylene (XLPE) produced from polyethylene (PE). Under production, PE can stagnate in high temperature thermal zones and consequently {{be subjected to}} thermal oxidation that introduces polar carbonyl groups to the polyethylene chain, which leads to increased energy losses, inferior insulating properties and subsequent degradation and eventually breakdown and failure of the cable. The oxidized polyethylene can contaminate the insulating material {{in the form of}} microscopic particles embedded in the material, that are difficult to detect and separate from the polyethylene granulate. In this work the focus have been on documenting the fundamental properties of the oxidized XLPE contaminations, such as complex permittivity, associated energy losses and breakdown strengths, compared to that of un-oxidized XLPE. In this thesis the thermal oxidation process of XLPE and PE has been studied {{in order to determine the}} degree of oxidation and carbonyl contents, using Fourier transform infra red spectroscopy. Three real contaminations was found, investigated and categorized. The contaminations was replicated through thermal oxidation of XLPE samples in a ventilated heat cabin at 170 &# 730;C. The electrical properties of replicated contaminations has been investigated using dielectric spectroscopy and breakdown strength-tests. At 50 Hz the real relative per- mittivities is measured to be &# 949;' = 2. 30 for un-oxidized XLPE, &# 949;' = 2. 57 for category 1 samples, &# 949;' = 2. 72 for category 2 samples and &# 949;' = 4. 19 for category 3 samples. The lossy polarization process is characterized by the imaginary part of the permittivity &# 949;''. It is seen that the dielectric losses are indeed increasing with the presence of polar carbonyl group, as expected from theoretical considerations. It is also seen that &# 949;'' in oxidized samples increases as the frequency decreases, which indicates that the conductive process dominates the low frequency domain, and that the DC conductivity is higher in contaminations than in un-oxidized XLPE. <b>Break-</b> <b>down</b> tests was preformed using the ASTM D 149 standard for dielectric breakdown testing. It was observed a decrease in breakdown strength in oxidized XLPE. The breakdown strengths decreased from (55. 31 Â± 31) kV/mm in un-oxidized XLPE to (24. 07 Â± 12. 88) kV/mm in the most oxidized category 3 XLPE sample. As a consequence of the theories and experimental results presented in this work, it can be said that there is a causal relation between dielectric losses and breakdown strengths in oxidized XLPE material which can be sumerized as follows: The intro- duction of polar carbonyl groups through thermal oxidation to polyethylene causes increased permittivities and dielectric losses. Subsequently there will be a decrease in electric breakdown strength of the XLPE insulation. Contaminations of oxidized material embedded in a solid insulation system may pose a reliability issue and may eventually be the cause of breakdown and failure of the cable...|$|R
40|$|Negativ energibalans och fysisk aktivitet resulterar baÌda i ett skifte i energianvaÌndningen i kroppen. Vid nega- tiv energibalans delas detta skifte in i tre faser daÌr den foÌrsta fasen karaktaÌriseras av en oÌkad glukoneogenes, lipolys och ketogenes; den andra fasen av en {{acceleration}} av dessa processer; och den tredje fasen av en haÌm- ning av glukoneogenesen. Vid fysisk aktivitet paÌverkas energiomsaÌttningen av intensiteten och varaktigheten paÌ den fysiska aktiviteten, daÌr en hoÌg intensitet gynnar glykogennedbrytningen och en laÌgre intensitet oÌkar anvaÌndningen av fett som energikaÌlla. Kroppens primaÌra behov aÌr alltid att foÌrse sitt energibehov, vilket bety- der att den anpassar sig efter de raÌdande foÌrhaÌllandena vad avser det aktuella energi- och naÌringsintaget samt den fysiska aktiviteten. Denna studie aÌr baserad paÌ resultat fraÌn ett foÌrsoÌk som gjordes vid Institutionen foÌr FolkhaÌlsa och VaÌrdveten- skap, i samarbete med Laboratory of Human Nutrition, Massachusetts Institute of Technology (MIT) och Cambridge i USA. I foÌrsoÌket deltog sju foÌrsoÌkspersoner som under en vecka (fem instaÌllningsdagar, ett kon- troll- och infusionsdygn) intog en standardiserad hoÌgproteinkost under negativ energibalans och dagligen genomfoÌrde tvaÌ 90 minuters cyklingar, en paÌ foÌrmiddagen och en paÌ eftermiddagen. Denna studie syftar till att undersoÌka hur den fysiska aktiviteten, koncentrationen och motivationen paÌverkas vid negativ energibalans med ett hoÌgt proteinintag. Resultaten fraÌn studien visade att den lokala anstraÌngningen under eftermiddagscyklingarna minskade signifi- kant mellan den foÌrsta och sjaÌtte dagen. Den minskade anstraÌngningen skulle kunna vara resultatet av en traÌ- ningseffekt, detta eftersom en signifikant skillnad aÌven noterades mellan andnings- och hjaÌrtfrekvensen dessa dagar. Fysiologiska och perifera foÌraÌndringar saÌsom hjaÌrtats slagvolym och blodets hemoglobinhalt respektive den mitokondriella- och kapillaÌra taÌtheten, aÌr andra faktorer som kan ha paÌverkat anstraÌngningen. Koncentrat- ionen och motivationen foÌraÌndrades inte under foÌrsoÌksperioden och en hypotetisk foÌrklaring till detta skulle kunna vara den hoÌga proteinandelen i kosten Denna hypotes bygger paÌ "Den centrala troÌtthetshypotesen" som haÌvdar att en hoÌg kvot av grenade aminosyror jaÌmfoÌrt med fritt tryptofan i blodet, uppraÌtthaÌller motivationen och koncentrationen under fasta och fysisk aktivitet. Negative {{energy balance}} and physical activity, both {{result in a}} shift in energy use in the body. During negative energy balance this shift is allocated into three phases, where the first phase is characterized by an increased gluconeogenesis, lipolysis and ketogenesis, the second phase by an acceleration of these processes, and the third phase by an inhibition of the gluconeogenesis. During physical activity the energy metabolism is both affected by the intensity and duration of the physical activity, where a high intensity favors glycogen <b>break-</b> <b>down</b> and a lower intensity the use of fat as an energy source. The body's primary need is always to supply its energy needs, which means that it adapts to the prevailing conditions with regard to physical activity and the current energy and nutrient intake. Physical activity results in several physiological and peripheral changes, a lowered heart rate and respiratory frequency are few examples. This study is based on results from an experiment performed at the Department of Public health and Caring science, {{in collaboration with the}} Laboratory of Human Nutrition, Massachusetts Institute of Technology (MIT) and Cambridge in the United States. In the study lasting one week; five setup days, one control day and one infusion day; seven subjects participated. They were all in negative energy balance during the experiment, received a standardized high protein diet and daily participated in two 90 minute cycling sessions, one during midmorning and one during afternoon. This study aims to investigate how the physical activity, concentration and motivation are affected during negative energy balance with a high protein intake. Results from the study showed that the local (legs) exertion during the afternoon cycling sessions, significant- ly decreased between the first setup day and the control day. The decreased exertion could have been caused by an exercise effect, since the respiratory- and heart frequencies were significantly lower at day six compared to day one. Physiological and peripheral factors such as the hearts beating volume, blood hemoglobin and the mitochondrial- and capillary density, are other factors that might have affected the exertion. The motivation and concentration were unaffected {{during the time of the}} study and a hypothetical explanation for this result could have been the high amount of protein in the diet. This hypothesis is based on âThe Serotonin Hypothe- sisâ which argues that a high quota of branched chain amino acids versus free tryptophan in blood, maintains the motivation and concentration during fasting and exercise...|$|R

