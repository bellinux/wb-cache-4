4|37|Public
5000|$|... "Our {{overriding}} concern {{stems from}} the lack of progress made by the members of the Financial Stability Oversight Council (FSOC) and the Office of Financial Research (OFR) to address several critical issues as mandated by the Dodd-Frank Wall Street Reform and Consumer Protection Act (Dodd-Frank), enacted in 2010. That concern increases each day that the implementation of systemic risk reform languishes. A sense of complacency has made reforms for effective oversight seem less urgent despite escalating problems elsewhere in the global financial system. In many ways, the financial system faces larger potential challenges today than it did {{in the run-up to the}} 2008 crisis, given the troubled state of the European Union and uncertainties at home related to fiscal and monetary policy. It is essential that the FSOC show leadership in coordinating the rule-writing process to promote the development of cohesive, consistent regulations and provide clear and <b>transparent</b> <b>explanations</b> of the reforms in a way that is understandable to the general public. We have created this Council to assist in that effort. [...] " ...|$|E
40|$|Color poster with text, tables, and charts. Effective and {{successful}} transitioning {{of persons with}} traumatic brain injury (TBI) back into their everyday lives and communities {{is linked to the}} presence of supports within that individual's community settings, including close partners such as spouses, siblings, parents, and friends. This study examines effective partner training with <b>transparent</b> <b>explanations</b> and rationales to foster sustainable, generalized treatment outcomes that will provide the necessary long-term suppor for the person with TBI. University of Wisconsin [...] Eau Claire Office of Research and Sponsored Programs...|$|E
40|$|Purpose – The paper revisits the {{intellectual}} roots of grounded theory and aims {{to analyze the}} consistency of the method used in grounded theory research in accounting. About 23 papers are identified and analysed. Design/methodology/approach – The paper is an analytical review of the research literature. It uses four fundamental canons of grounded theory to analyze accounting research. Findings – Some accounting researchers who have used the label “grounded theory” for their research have misunderstood or not applied the core canons of grounded theory established by Glaser and Strauss and developed with diversity in other disciplines. Most claim to follow the specific approach of Strauss and Corbin, but the published research shows limited explication of method. Originality/value – Since Parker and Roffey in 1997, there has been no analysis and re-evaluation of the burgeoning academic accounting literature using grounded theory. While celebrating the growth of this research, the paper does raise concerns about the lack of consistency of grounded theory research in accounting with the central canons of grounded theory, and it provides some directions for future grounded theory research by encouraging accounting researchers who wish to use grounded theory to engage more strongly in understanding the method and providing <b>transparent</b> <b>explanations</b> of their data collection and analysis methods. Accounting research, Accounting theory, Research methods...|$|E
5000|$|In {{transactions}} impacting on {{more than}} one related company (e.g. a group transaction) the administrator should ensure that the disclosure is sufficient to enable a <b>transparent</b> <b>explanation</b> (for instance, allocation of consideration paid) ...|$|R
6000|$|Then, in {{the midst}} of this grave, rather <b>transparent,</b> <b>explanation</b> of changed policy, his eyes twinkled. [...] "This'll astonish Timothy's weak nerves. That {{precious}} young thing will have something to say about this, or I'm a Dutchman!" ...|$|R
40|$|We {{introduce}} some {{applications of}} Stein’s method {{in the high}} temperature analysis of spin glasses. Stein’s method allows the direct analysis of the Gibbs measure without having to create a cavity. Another advantage is that it gives limit theorems with total variation error bounds, although the bounds can be suboptimal. A surprising byproduct of our analysis is a relatively <b>transparent</b> <b>explanation</b> of the Thouless-Anderson-Palmer system of equations. Along the way, we develop Stein’s method for mixtures of two Gaussian densities...|$|R
40|$|Shade plots, simple visual {{representations}} of abundance matrices from multivariate species assemblage studies, are {{shown to be}} an effective aid in choosing an overall transformation (or other pre-treatment) of quantitative data for long-term use, striking an appropriate balance between dominant and less abundant taxa in ensuing resemblance-based multivariate analyses. Though the exposition is entirely general and applicable to all community studies, detailed illustrations of the comparative power and interpretative possibilities of shade plots are given in the case of two estuarine assemblage studies in south-western Australia: (a) macrobenthos in the upper Swan Estuary over a two-year period covering a highly significant precipitation event for the Perth area; and (b) a wide-scale spatial study of the nearshore fish fauna from five divergent estuaries. The utility of transformations of intermediate severity is again demonstrated and, with greater novelty, the potential importance seen of further mild transformation of all data after differential down-weighting (dispersion weighting) of spatially clumped' or schooled' species. Among the new techniques utilized is a two-way form of the RELATE test, which demonstrates linking of assemblage structure (fish) to continuous environmental variables (water quality), having removed a categorical factor (estuary differences). Re-orderings of sample and species axes in the associated shade plots are seen to provide <b>transparent</b> <b>explanations</b> at the species level for such continuous multivariate patterns...|$|E
40|$|We {{introduce}} Floquet {{states in}} quantum electrodynamics and discuss {{their relation to}} dressed states. This comparison leads to an interpretation of higher modes in Floquet states {{as a manifestation of}} an intense 'multi-coloured' fluorescence radiation and, thus, to a <b>transparent</b> <b>explanation</b> of the experimentally observed generation of intense high harmonics by short laser pulses. Intensities are expected to be appreciable fractions of the incoming flux. (orig.) Available from TIB Hannover: RO 5080 (93 - 02) / FIZ - Fachinformationszzentrum Karlsruhe / TIB - Technische InformationsbibliothekSIGLEDEGerman...|$|R
40|$|The Dependency Diagram of a Linear Programme (LP) {{shows how}} the {{successive}} inequalities of an LP depend on former inequalities, when variables are projected out by Fourier–Motzkin Elimination. It is also explained how redundant inequalities can be removed, using the method attributed to Chernikov and to Kohler. Some new results are given. The procedure also leads to a <b>transparent</b> <b>explanation</b> of Farkas’ Lemma, LP Duality, the dual form of Caratheodory’s Theorem as well as generating all vertices and extreme rays of the Dual Polytope...|$|R
40|$|In {{three-dimensional}} QED, {{a quantum}} Hall effect {{occurs in the}} absence of any magnetic field. We give a simple and <b>transparent</b> <b>explanation.</b> In solid-state physics, the Hall conductivity for rational magnetic flux is expected to be given by a Chern number. In our field-free situation, however, the conductivity is ± 1 / 2 in natural units. We explain why the integrality of the conductivity breaks down and explain its quantisation geometrically. For quasi-periodic boundary conditions, we calculate the finite size correction to the Hall conductivity. Our paper establishes an explicit connection between quantum fied theory and solid-state physics. ...|$|R
40|$|Based on a {{combined}} quantum-classical treatment, a complete {{study of the}} strong field dynamics of H 2 +, i. e. including all nuclear and electronic DOF as well as dissociation and ionization, is presented. We find that the ro-vibrational nuclear dynamics enhances dissociation and, at the same time, suppresses ionization, confirming experimental observations by I. Ben-Itzhak et al. [Phys. Rev. Lett. 95, 073002 (2005) ]. In addition and counter-intuitively, it is shown that for large initial vibrational excitation ionization takes place favorably at large angles between the laser polarization and molecular axis. A local ionization model delivers a <b>transparent</b> <b>explanation</b> of these findings. Comment: 10 pages, 5 figure...|$|R
40|$|In QED of two space dimensions, {{a quantum}} Hall effect {{occurs in the}} absence of any {{magnetic}} field. We give a simple and <b>transparent</b> <b>explanation.</b> In solid state physics, the Hall conductivity for non-degenerate ground state is expected to be given by an integer, the Chern number. In our field-free situation, however, the conductivity is ± 1 / 2 in natural units. We fit this half-integral result into the topological setting and give a geometric explanation reconciling the points of view of QFT and solid state physics. For quasi-periodic boundary conditions, we calculate the finite size correction to the Hall conductivity. Applications to graphene and similar materials are discussed...|$|R
40|$|We use {{elementary}} {{methods to}} compute the L 2 -dimension of the eigenspaces of the Markov operator on the lamplighter group and of generalizations of this operator on other groups. In particular, we give a <b>transparent</b> <b>explanation</b> of the spectral measure of the Markov operator on the lamplighter group found by Grigorchuk-Zuk. The latter result was used by Grigorchuk-Linnell-Schick-Zuk to produce a counterexample to a strong version of the Atiyah conjecture about the range of L 2 -Betti numbers. We use our results to construct manifolds with certain L 2 -Betti numbers (given as convergent infinite sums of rational numbers) which are not obviously rational, but we {{have been unable to}} determine whether any of them are irrational. Comment: 14 pages, AMS-LaTe...|$|R
40|$|Let [Sigma] {{denote the}} Coxeter complex of Sn, and let X([Sigma]) denote the {{associated}} toric variety. Since the Betti {{numbers of the}} cohomology of X([Sigma]) are Eulerian numbers, the additional presence of an Sn-module structure permits the definition of an isotypic refinement of these numbers. In some unpublished work, DeConcini and Procesi derived a recurrence for the Sn-character of the cohomology of X([Sigma]), and Stanley later used this to translate the problem of combinatorially describing the isotypic Eulerian numbers into the language of symmetric functions. In this paper, we explicitly solve this problem by developing {{a new way to}} use marked sequences to encode permutations. This encoding also provides a <b>transparent</b> <b>explanation</b> of the unimodality of Eulerian numbers and their isotypic refinements...|$|R
40|$|Recent direct {{numerical}} {{simulations of}} the FENE-P model of non-Newtonian hydrodynamics {{revealed that the}} phenomenon of drag reduction by polymer additives exists (albeit in reduced form) also in homogeneous turbulence. We introduce here a simple shell model for homogeneous viscoelastic flows that recaptures the essential observations of the full simulations. The simplicity of the shell model allows us to offer a <b>transparent</b> <b>explanation</b> of the main observations. It is shown that the mechanism for drag reduction operates mainly on the large scales. Understanding the mechanism allows us to predict how the amount of drag reduction depends of the various parameters in the model. The main conclusion is that drag reduction is not a universal phenomenon, it peaks in a window of parameters like Reynolds number and the relaxation rate of the polymer...|$|R
40|$|We {{investigated}} {{a mechanism}} of rectification in di-block oligomer diode molecules that {{have recently been}} synthesized and showed a pronounced asymmetry in the measured I-V spectrum. The observed rectification effect {{is due to the}} resonant nature of electron transfer in the system and localization properties of bound state wave functions of resonant states of the tunneling electron interacting with asymmetric molecule in an electric field. The asymmetry of the tunneling wave function is enhanced or weakened depending on the polarity of applied bias. The conceptually new theoretical approach, the Green's function theory of sub-barrier scattering, is able to provide a physically <b>transparent</b> <b>explanation</b> of this rectification effect based on the concept of the bound state spectrum of a tunneling electron. The theory predicts the characteristic features of the I-V spectrum in qualitative agreement with experiment...|$|R
40|$|The {{concept of}} local polaritons {{is used to}} {{describe}} optical properties of mixed crystals in the frequency region of their restrahlen band. It is shown that this concept allows for a physically <b>transparent</b> <b>explanation</b> {{of the presence of}} weak features in the spectra of so called one-mode crystals, and for one-two mode behavior. The previous models were able to explain these features only with the use of many fitting parameters. We show that under certain conditions new impurity-induced polariton modes may arise within the restrahlen of the host crystals, and study their dispersion laws and density of states. Particularly, we find that the group velocity of these excitations is proportional to the concentration of the impurities and can be thousands of times smaller then the speed of light in vacuum. Comment: 21 pages, 5 figures, RevTex, Phys. Rev. B, 62, 6301 (2000...|$|R
40|$|We {{introduce}} a grading switching for arbitrary non-associative algebras of prime characteristic p, aimed at producing a new grading of an algebra from a given one. We {{take inspiration from}} a fundamental tool in the classification theory of modular Lie algebras known as toral switching, which relies on a delicate adaptation of the exponential of a derivation. Our grading switching is achieved by evaluating certain generalized Laguerre polynomials of degree p − 1, which {{play the role of}} generalized exponentials, on a derivation of the algebra. A crucial part of our argument is establishing a congruence for them which is an appropriate analogue of the functional equation exp(x) · exp(y) = exp(x+y) for the classical exponential. Besides having a wider scope, our treatment provides a more <b>transparent</b> <b>explanation</b> of some aspects of the original toral switching, which can be recovered as a special case...|$|R
40|$|Spin-orbit {{interaction}} is usefully classified as extrinsic or intrinsic depending on its origin: the potential due to random impurities (extrinsic), or the crystalline potential {{associated with the}} band or device structure (intrinsic). In this paper we will show how by using a SU(2) formulation the two sources of spin-orbit interaction may be described in an elegant and unified way. As a result we obtain a simple description of the interplay of {{the two types of}} spin-orbit interaction, and a physically <b>transparent</b> <b>explanation</b> of the vanishing of the d. c. spin Hall conductivity in a Rashba two-dimensional electron gas when spin relaxation is neglected, and its reinstatement when spin relaxation is allowed. Furthermore, we obtain an explicit formula for the transverse spin polarization created by an electric current, which generalizes the standard formula obtained by Edelstein and Aronov and Lyanda-Geller by including extrinsic spin-orbit interaction and spin relaxation. Comment: 9 page...|$|R
40|$|Strain {{fields in}} {{graphene}} {{giving rise to}} pseudomagnetic fields have received much attention due {{to the possibility of}} mimicking real magnetic fields with magnitudes of greater than 100 Tesla. We examine systems with such strains confined to finite regions ("pseudomagnetic dots") and provide a <b>transparent</b> <b>explanation</b> for the characteristic sublattice polarization occurring in the presence of pseudomagnetic field. In particular, we focus on a triaxial strain leading to a constant field in the central region of the dot. This field causes the formation of pseudo Landau levels, where the zeroth order level shows significant differences compared to the corresponding level in a real magnetic field. Analytic arguments based on the Dirac model are employed to predict the sublattice and valley dependencies of the density of states in these systems. Numerical tight binding calculations of single pseudomagnetic dots in extended graphene sheets confirm these predictions, and are also used to study the effect of the rotating the strain direction and varying the size of the pseudomagnetic dot...|$|R
30|$|Two {{concepts}} were {{central to}} the construction of DEMIG POLICY: policy change and policy restrictiveness. Indeed, the effectiveness of policies can best be assessed in moments of policy change and against a criterion, which, in our case, was restrictiveness: Does a change in migration policy restrictiveness affect migration in the intended way? The main inspiration for this approach were the databases established by Mayda and Patel (2004) and Hatton (2009) which tracked migration policy changes over time instead of trying to capture the characteristics of entire migration policy regimes at a given point of time (which is the aim of comparative databases). Instead of attempting to measure absolute levels of restrictiveness, they assessed whether a given policy change made the existing policy framework more or less restrictive. These databases, as well as the ImPol database (Mezger and Gonzalez-Ferrer 2013), also provided a <b>transparent</b> <b>explanation</b> of coding systems and decisions. DEMIG POLICY builds on these approaches and seeks to improve them by (i) providing an elaborate conceptualisation of migration policies; (ii) expanding the geographical (cross-sectional) and temporal coverage and including both immigration and emigration policies; (iii) disaggregating major policy changes into their individual policy measures; and (iv) specifying the migrant group targeted by each policy measure.|$|R
40|$|Based on {{a general}} theory of {{detonation}} waves with an embedded sonic locus that we have developed in Kasimov (2004) and Stewart & Kasimov (2004), we carry out asymptotic analysis of weakly-curved slowly-varying detonation waves and show that the theory predicts the phenomenon of detonation ignition and failure. The analysis is not restricted to near Chapman??Jouguet detonation speeds and is capable of predicting quasi-steady, normal detonation shock speed, curvature (D??k) curves with multiple turning points. An evolution equation that retains the shock acceleration, D(dot), namely a D(dot) ??D??k relation is rationally derived and its solution for spherical (or cylindrical) detonation is shown to reproduce the ignition/failure phenomenon observed in both numerical simulations of blast wave initiation and in experiments. A simple physically <b>transparent</b> <b>explanation</b> of the ignition phenomenon is given {{in terms of the}} form of the evolution equation. A single-step chemical reaction described by one progress variable is employed, but the kinetics is sufficiently general and is not restricted to Arrhenius form, although most specific calculations in this work are performed for Arrhenius kinetics. As an example, we calculate critical energies of direct initiation for hydrogen??oxygen mixtures and find close agreement with available experimental data. published or submitted for publicationis peer reviewe...|$|R
40|$|We give {{a simple}} {{proof of a}} {{well-known}} theorem of Gál and of the recent related results of Aistleitner, Berkes and Seip [1] regarding the size of GCD sums. In fact, our method obtains the asymptotically sharp constant in Gál's theorem, which is new. Our approach also gives a <b>transparent</b> <b>explanation</b> {{of the relationship between}} the maximal size of the Riemann zeta function on vertical lines and bounds on GCD sums; a point which was previously unclear. Furthermore we obtain sharp bounds on the spectral norm of GCD matrices which settles a question raised in [2]. We use bounds for the spectral norm to show that series formed out of dilates of periodic functions of bounded variation converge almost everywhere if the coefficients of the series are in L^ 2 (1 /L) ^γ, with γ > 2. This was previously known with γ > 4, and is known to fail for γ< 2. We also develop a sharp Carleson-Hunt-type theorem for functions of bounded variations which settles another question raised in [1]. Finally we obtain almost sure bounds for partial sums of dilates of periodic functions of bounded variations improving [1]. This implies almost sure bounds for the discrepancy of {n_k x} with n_k an arbitrary growing sequences of integers. Comment: 16 page...|$|R
40|$|The B_n^(k) poly-Bernoulli numbers [...] - {{a natural}} {{generalization}} of classical Bernoulli numbers (B_n= B_n^(1)) [...] - were introduced by Kaneko in 1997. When the parameter k is negative then B_n^(k) is a nonnegative number. Brewbaker {{was the first}} to give combinatorial interpretation of these numbers. He proved that B_n^(-k) counts the so called lonesum 0 - 1 matrices of size n× k. Several other interpretations were pointed out. We survey these and give new ones. Our new interpretation, for example, gives a <b>transparent,</b> combinatorial <b>explanation</b> of Kaneko's recursive formula for poly-Bernoulli numbersComment: 20 pages, to appear in Studia Scientiarum Mathematicarum Hungaric...|$|R
40|$|The Semantic Web lacks {{support for}} {{explaining}} knowledge provenance. When web applications return answers, many users {{do not know}} what information sources were used, when they were updated, how reliable the source was, or what information was looked up versus derived. The Semantic Web also lacks support for explaining reasoning paths used to derive answers. The Inference Web (IW) aims to take opaque query answers and make the answers more <b>transparent</b> by providing <b>explanations.</b> The explanations include information concerning where answers came from and how they were derived (or retrieved) ...|$|R
40|$|Previous {{experimental}} {{work on a}} two-dimensional (2 D) electron gas in a Sion-sapphire device led {{to the conclusion that}} both conductivity and phonon drag thermopower S g are affected to the same relative extent by weak localization. The present paper presents further experimental and theoretical results on these transport coefficients for two very low mobility 2 D electron gases in δ−doped GaAs/GaxAl 1 −xAs quantum wells. The experiments were carried out in the temperature range 3 - 7 K where phonon drag dominates the thermopower and, contrary to the previous work, the changes observed in the thermopower due to weak localization were found to be an order of magnitude less than those in the conductivity. A theoretical framework for phonon drag thermopower in 2 D and 3 D semiconductors is presented which accounts for this insensitivity of S g to weak localization. It also provides <b>transparent</b> physical <b>explanations</b> of many previous experimental and theoretical results...|$|R
40|$|This paper {{presents}} a theory to link improvements in transparency about monetary policy objectives to improvements in transparency about monetary policy actions {{and then to}} the conditional volatility of market expectations of policy rates. Crucially, policy announcements act not just as an instrument but also as a beacon that can potentially communicate information to agents about the policymakers’ reactions to shocks. When the objectives of policymakers are not made transparent, agents are more likely to interpret any accommodation to price shocks as indicating that policymakers are following their own unobserved suboptimal objectives. Policymakers in these regimes are therefore less inclined to be <b>transparent</b> in their <b>explanations.</b> Conversely when policy objectives are more clearly defined, policymakers become more <b>transparent</b> in their <b>explanations</b> too. Then, the less markets will be surprised by interest rate announcements. I show that happens at a diminishing rate: as transparency is improved further from already high levels, there is less of a reduction in the variance of market surprises. The reason is that agents know that they can rely more on the monetary policy beacon in very transparent regimes. Hence they become more active in their decision-making and policymakers take that extra sensitivity into account. The model illustrates the gains to having clearly defined policy objectives. It also explains how a continued occurrence of market surprises, after an initial large reduction, could be consistent with the greater transparency and more precisely formed inflation expectations. ...|$|R
40|$|Mode of access: World Wide Web. Thesis (Ph. D.) [...] University of Hawaii at Manoa, 2004. Includes bibliographical {{references}} (leaves 112 - 118). Electronic reproduction. Also {{available by}} subscription via World Wide Webxvii, 118 leaves, bound ill. 29 cmThis dissertation investigates corporate financial structure, ownership structure, and {{their relationships with}} economic development. It is composed of three chapters. The first chapter investigates the Modigliani-Miller Irrelevance Theorem under risk-neutrality and positive profit. It models the entrepreneur as the residual risk-bearer {{in a world of}} risk-neutral agents. The percentage of entrepreneurial equity holding increases as the firm issues more debt. Stockholders bear greater risk than debt holders, but both receive the same expected rate of return. Using this framework, I obtain a <b>transparent</b> <b>explanation</b> of the effect of capital structure on the cost of capital. The framework is fully operational and suitable for numerical illustrations. It also lays the groundwork for operational agency models of optimal corporate finance. Chapter 2 examines the relationship between corporate financial structure and economic development (per capita income) using data from four economies: U. S. A., Canada, Australia, and Taiwan. This chapter has two major findings. First, over the last few decades, the corporate financial structure in these four economies did not demonstrate any downward trend during the sample period when all economies experienced income increases. Second, income affects the link between the economic growth rate and the debt-equity ratio. I find that the economic growth rate and the debt-equity ratio move in the same direction in higher-income countries and in opposite directions in lower-income countries. Chapter 3 models the link between corporate financial structure, ownership structure, and economic development. It shows that the under the assumptions of asymmetric information and moral hazard, debt and outside equity are part of the optimal contract paid to an investor by his manager. The manager receives a profit share that equals his marginal cost of effort. The chapter then shows that economic development raises the reservation utility for all managerial types by increasing the opportunity wage for managers. Consequently, lower types drop out of the managerial group and prefer to be workers. As a result, the average percentage of inside equity (averaged over the higher managerial types) increases as an economy develops. The effect of economic development on the average debt-equity ratio is generally indeterminate...|$|R
30|$|As {{listed in}} Table  5, 79 % of RVM {{prediction}} errors {{are less than}} 20  min, while CHAID predictions are with {{the greatest number of}} errors more than 30  min. However the CHAID model exhibits the greatest number of errors less than 5  min, and this result is achieved with only four explanatory variables. The advantage to give a ready-to-use easy tool, with a small number of variables, makes the Decision Tree together with the MLR the methods most used for the incident duration prediction problem. Moreover, unlike “black box” methods such as ANN and RVM, a further advantage of these methods is their statistical approach that allows a <b>transparent</b> and easy-to-understand <b>explanation</b> of their results.|$|R
40|$|In over-imitation, {{children}} copy even {{elements of}} a goal-directed action sequence that appear unnecessary for achieving the goal. We demonstrate in 4 -year olds that the unnecessary action is specifically associated with the goal, not generally associated with the apparatus. The unnecessary action is performed flexibly: 4 -year olds usually omit it if {{it has already been}} performed by an adult. Most 5 -year olds do not verbally report the unnecessary action as necessary when achieving the goal, although most of them report an equivalent but necessary action as necessary. Most 5 -year olds explain the necessary action in functional terms, but are unsure as to the function of the unnecessary action. These verbal measures do not support the hypothesis that children over-imitate primarily because they encode unnecessary actions as causing the goal even in causally transparent systems. In a causally <b>transparent</b> system, <b>explanations</b> for over-imitation fitting the results are that children are ignorant of the unnecessary action's purpose, and that they learn a prescriptive norm that it should be carried out. In causally opaque systems, however, for children and for adults, any action performed before achieving the goal is likely to be inferred as causally necessary—this is not over-imitation, but ordinary causal learning...|$|R
40|$|Applying to {{graphene}} oxides, molecular {{theory of}} graphene {{is based on}} the oxide molecular origin when it is considered as a final product in the succession of a graphene molecule polyderivatives related to a particular oxidation reaction. The graphene oxide structure is created in due course of calculations following the algorithms that take into account the graphene molecules natural radicalization, correlation of odd electrons, an extremely strong influence of structure on properties, a sharp response of the molecule behavior on small action of external factors. Taking together, the theory facilities has allowed for getting a clear, <b>transparent</b> and understandable <b>explanation</b> of hot points of the graphene oxide chemistry and suggesting reliable models of both chemically produced and chemically reduced graphene oxides. Comment: 22 pages, 15 figures, 1 tabl...|$|R
40|$|This paper {{considers}} what olfactory {{experience can}} tell us about the controversy over qualia and, in particular, the debate that focuses on the alleged transparency of experience. The appeal to transparency is supposed to show that there are no qualia—intrinsic, non-intentional and directly accessible properties of experience that determine phenomenal character. It is most commonly used to motivate intentionalism—namely, the view that the phenomenal character of an experience is exhausted by its representational content. Although some philosophers claim that transparency holds for all of the sense modalities, any detailed discussion of it focuses on vision. But transparency seems unintuitive for olfactory experience. This paper argues that olfactory experience is indeed <b>transparent</b> and that <b>explanations</b> of what transparency is have been obscured by a reliance on the visual model. In this way, the paper clarifies and advances the debate about transparency...|$|R
40|$|The Web lacks {{support for}} {{explaining}} information provenance. When web applications return answers, many users {{do not know}} what information sources were used, when they were updated, how reliable the source was, or what information was looked up versus derived. The Web also lacks support for explaining reasoning paths used to derive or retrieve answers. The Inference Web (IW) aims to take opaque query answers and make the answers more <b>transparent</b> by providing <b>explanations.</b> The explanations include information concerning where answers came from and how they were derived (or retrieved). This chapter describes the IW support for explanations on question answering (QA) environments. A characterization of explanation strategies on QA environment is presented. One usage of the Inference Web infrastructure, and in particular of the browser, explainer, and portable proof specification for supporting multiple explanation strategies in the KSL Wine Agent is described in the chapter. Also, a generic architecture for a QA environment incorporating the Inference Web for explaining answers is presented. ...|$|R
40|$|In this seven-part paper, we {{show that}} {{gravitational}} waves (classical and quantum) produce the accelerated de Sitter expansion at the start {{and at the end}} of the cosmological evolution of the Universe. In these periods, the Universe contains no matter fields but contains classical and quantum metric fluctuations, i. e., it is filled with classical and quantum gravitational waves. In such evolution of the Universe, dominated by gravitational waves, the de Sitter state is the exact solution to the self-consistent equations for classical and quantum gravitational waves and background geometry for the empty space-time with FLRW metric. In both classical and quantum cases, this solution is of the instanton origin since it is obtained in the Euclidean space of imaginary time with the subsequent analytic continuation to real time. The cosmological acceleration from gravitational waves provides a <b>transparent</b> physical <b>explanation</b> to the coincidence, threshold and “old cosmological constant” paradoxes of dark energy avoiding recourse to the anthropic principle. The cosmological acceleration from virtual gravitons at the start of the Universe evolution produces inflation, which is consistent with the observational data on CMB anisotropy. Section 1 is devoted to cosmological acceleration from classical gravitational waves. Section 2 is devoted to the theory of virtual gravitons in the Universe. Section 3 is devoted to cosmological acceleration from virtual gravitons. Section 4 discusses the consistency of the theory with observational data on dark energy and inflation. The discussion of mechanism of acceleration and cosmological scenario are contained in Sections 5 and 6. Appendix contains the theory of stochastic nonlinear gravitational waves of arbitrary wavelength and amplitude in an isotropic Universe...|$|R
40|$|Leibnizs {{principles}} {{made for}} an elegant and coherent philosophy. In part meta-physical, in part methodological, they addressed fundamental questions- {{in the treatment}} of symmetry, in the relationship of physics to mathematics, in logic-that are if anything even more pressing today than they were in Leibnizs time. As I shall read them, they also expressed a distinctive and uncompromising form of realism, a commitment to the adequacy of purely descriptive concepts. This doctrine has been called semantic universalismby van Fraassen (1991), and the generalist pictureby OLeary-Hawthorne and Cover (1996) : it will become clearer in due course just what it entails. The principles that I shall consider are the Principle of Su ¢ cient Reason (PSR) and the Principle of Identity of Indiscernibles (PII). In the 8 ̆ 5 rst instance I shall take them both to be methodological principles. The former I shall read as requiring that the concepts of physics be entirely <b>transparent.</b> Analysis and <b>explanation</b> are to proceed without any limits. The perspective is impersonal: any epistemological limitation, to do with our human situation or perceptual ap...|$|R
40|$|The Semantic Web lacks {{support for}} {{explaining}} knowledge provenance. When web applications return answers, many users {{do not know}} what information sources were used, when they were updated, how reliable the source was, or what information was looked up versus derived. The Semantic Web also lacks support for explaining reasoning paths used to derive answers. The Inference Web (IW) aims to take opaque query answers and make the answers more <b>transparent</b> by providing <b>explanations.</b> The explanations include information concerning where answers came from and how they were derived (or retrieved). In this paper we describe an infrastructure for IW explanations. The infrastructure includes: an extensible web-based registry containing details on information sources, reasoners, languages, and rewrite rules; a portable proof specification; and a proof and explanation browser. Source information in the IW registry is used to convey knowledge provenance. Representation and reasoning language axioms and rewrite rules in the IW registry are used to support proofs, proof combination, and semantic web agent interoperability. The IW browser is used to support navigation and presentations of proofs and their explanations. The Inference Web is in use by two Semantic Web agents using an embedded reasoning engine fully registered in the IW. Additional reasoning engine registration is underway in order to help provide input for evaluation of the adequacy, breadth, and scalability of our approach. ...|$|R
