1|20|Public
40|$|WO 2003044769 A UPAB: 20030707 NOVELTY - An {{audio signal}} (12) {{contains}} a tone produced by an instrument. First, a discrete amplitude-time {{representation of the}} audio signal is produced (14) so as to {{have a number of}} successive amplitude values for a number of successive points in time. One point in time is assigned to each amplitude value. An identifier (18) for the audio signal is extracted (16) from the amplitude-time representation. DETAILED DESCRIPTION - An instrument database is created from a number of identifiers for a number of audio signals that contain tones for a number of instruments. This instrument database is utilized to determine the type of test instrument by means of a <b>test</b> <b>identifier</b> for an audio signal that has been produced by an unknown instrument. INDEPENDENT CLAIMS are also included for a device for generating an identifier for an audio signal, for a method for creating an instrument database, for a device for creating an instrument database, for a method for determining the type of instrument and for a device for determining the type of instrument. USE - For acoustic identification of specific musical instruments during a piece of music. ADVANTAGE - Precise instrument identification can be attained, because amplitude-time representation of a tone produced by an instrument is used to identify musical instruments...|$|E
40|$|Many {{laboratories}} use {{electronic message}} standards to transmit results to their clients, If all laboratories used the Same ''universal'' set of <b>test</b> <b>identifiers,</b> electronic transmission of {{results would be}} greatly simplified, The Logical Observation Identifier Names and Codes (LOINC) database aims {{to be such a}} code system, covering at least 98 % of the average laboratory's tests. The LOINC database should be of interest to hospitals, clinical laboratories, doctors' offices, state health departments, governmental healthcare providers, third-party payers, organizations involved in clinical trials, and quality assurance and utilization reviewers, The fifth release of the LOINC database, containing codes, names, and synonyms for similar to 6300 test observations, is now available on the Internet for public use, Here we describe the LOINC database, the methods used to produce it, and how it may be obtained...|$|R
5000|$|... "Vertical interoperability" [...] is a {{situation}} in which SIF agents at different levels of an organization communicate using a SIF Zone. Vertical interoperability involves data collection from multiple agents (upward) or publishing of information to multiple agents (downward). For example, a state-level data warehouse may listen for changes in district-level data warehouses and update its database accordingly. Or a state entity may wish to publish teacher certification data to districts. The three pieces of the SIF specification that deal directly with vertical interoperability are the Student Locator object, the Vertical Reporting object, and the Data Warehouse object.A good example of this would be the Century Consultants SIS Agent working with the Pearson SLF Agent sending student data to the State Agency and getting Student <b>Testing</b> <b>Identifiers</b> in return.|$|R
40|$|This {{position}} paper discusses {{the role of}} Object Identity in object-oriented systems. A distinction is drawn between object identity and object identifier; the former is an intrinsic part of an object-oriented system, while the latter is not. An equality <b>test</b> on object <b>identifiers</b> breaches encapsulation; such a test should therefore only be enabled at the specific request of the implementor of an abstraction...|$|R
30|$|A brief {{questionnaire}} {{consisting of}} eleven questions (Additional file 1) {{was developed by}} the study team of medical (DS, MC), radiation (JMC) and surgical (AA) oncologists as well as experts in epidemiology (BH, IG) and knowledge translation (IG). Participants were asked to answer questions about their cancer characteristics, imaging performed around the time of surgery, and their opinion and perceptions around the use of imaging <b>tests.</b> No patient <b>identifiers</b> were used in the data collection process—all the information gathered was based on patient recall.|$|R
5000|$|The [...] "left" [...] (alpha) {{side of the}} node graph forms a {{discrimination}} network {{responsible for}} selecting individual WMEs based on simple conditional tests which match WME attributes against constant values. Nodes in the discrimination network may also perform tests that compare two or more attributes of the same WME. If a WME is successfully matched against the conditions represented by one node, it is passed to the next node. In most engines, the immediate child nodes of the root node are used to <b>test</b> the entity <b>identifier</b> or fact type of each WME. Hence, all the WMEs which represent the same entity type typically traverse a given branch of nodes in the discrimination network.|$|R
40|$|Real-time {{identifiers}} of {{the rotor}} parameters of an induction motor drive {{are presented in}} the paper. The synthesis procedure of the identifiers {{is based on the}} MRAC system theory. An appropriate choice of the reference model allows a Lyapunov function to be built up by means of which the updating law of one of the above mentioned parameters can be found. A higher order identifier is also synthesised using a hyperstability approach which allows real-time updating of two rotor parameters. The parameters convergence is assured thanks to the persistent exciting propriety of the input vector. A DSP-based system (TMS 320 C 30), having 30 MHz clock frequency, is used for <b>testing</b> the proposed <b>identifiers</b> in a CRPWM inverter supplied driv...|$|R
40|$|The paper {{deals with}} {{real-time}} {{identification of the}} rotor parameters of the induction motor drive. The model reference adaptative control technique {{has been used for}} synthesising two identifiers. An appropriate choice of the reference model allows a Lyapunov function to be built by means of which the updating law of the rotor time constant can be found. A higher order identifier is also synthesised using the hyperstability approach which allows real-time updating of two rotor parameters. The persistent exciting property of the input vector assures the parameters convergence. Using a DSP-based system (TMS 320 C 30), having 30 MHz clock frequency, a few experiments are conducted for <b>testing</b> the proposed <b>identifiers</b> performance {{in the case of a}} CRPWM inverter supplied driv...|$|R
40|$|Abstract—Automatically {{generated}} {{test cases}} are usually evaluated {{in terms of}} their fault revealing or coverage capabil-ity. Beside these two aspects, test cases are also the major source of information for fault localization and fixing. The impact of automatically generated test cases on the debugging activity, compared to the use of manually written test cases, has never been studied before. In this paper we report the results obtained from two con-trolled experiments with human subjects performing debugging tasks using automatically generated or manually written test cases. We investigate whether the features of the former type of test cases, which make them less readable and understandable (e. g., unclear <b>test</b> scenarios, meaningless <b>identifiers),</b> have an impact on accuracy and efficiency of debugging. The empirical study is aimed at investigating whether, despite the lack of readability in automatically generated test cases, subjects can still take advantage of them during debugging...|$|R
40|$|In a {{biometric}} authentication system using protected templates, a pseudonymous identifier {{is the part}} of a protected template that can be directly compared. Each compared pair of pseudonymous identifiers results in a decision <b>testing</b> whether both <b>identifiers</b> are derived from the same biometric characteristic. Compared to an unprotected system, most existing biometric template protection methods cause to a certain extent degradation in biometric performance. Fusion is therefore a promising way to enhance the biometric performance in template-protected biometric systems. Compared to feature level fusion and score level fusion, decision level fusion has not only the least fusion complexity, but also the maximum interoperability across different biometric features, template protection and recognition algorithms, templates formats, and comparison score rules. However, performance improvement via decision level fusion is not obvious. It is influenced by both the dependency and the performance gap among the conducted tests for fusion. We investigate in this paper several fusion scenarios (multi-sample, multi-instance, multi-sensor, multi-algorithm, and their combinations) on the binary decision level, and evaluate their biometric performance and fusion efficiency on a multi-sensor fingerprint database with 71, 994 samples...|$|R
40|$|This paper aims to {{evaluate}} the effectiveness of different crystalline coating materials concerning of chloride ions penetration. The concrete ages at the coating installation and its moisture conditions were addressed; where, these two factors may play a dominant role for the effectiveness of the used materials. Rapid chloride ions penetration test (RCPT) was conducted at different ages and moisture conditions according to the relevant standard. In addition, the contaminated area and the penetration depth of the chloride ions were investigated immediately after the RCPT <b>test</b> using chemical <b>identifier,</b> 0. 1 M silver nitrate AgNO 3 solution. Results have shown that, the very low chloride ions penetrability, for the studied crystallization materials, were investigated only with the old age concrete (G 1). The significant reduction in chloride ions’ penetrability was illustrated after 7 days of installing the crystalline coating layers. Using imageJ is more reliable to describe the contaminated area of chloride ions, where the distribution of aggregate and heterogeneous of cement mortar was considered in the images analysis...|$|R
40|$|A cosmic ray {{particle}} identifier {{consisting of}} a thin film detector (for measuring specific luminescence) and a solid state detector (for measuring residual energy) {{has been designed to}} simultaneously measure the nuclear charge, mass, velocity, energy, and possibly ionic charge of incident particles. A 10 -layer thin film was fabricated and <b>tested</b> in this <b>identifier.</b> The response of both the thin film and the solid-state detectors to Cf- 252 fission fragments was measured. As expected, the thin film detector yielded a very wide peak in its specific luminescence spectrum, resulting in an uncertainty in Z detection of – 2. In contrast, the solid-state detector signal had a much narrower peak and is thus capable of adequately precise energy measurement. Also presented is the design of a rotating scattering chamber used to scatter the particle beam from the Van de Graaff accelerator through a thin foil at an angle between 0 ° and 60 °. The scattering chamber will reduce the intensity of the beam, which at present is too high for the solid-state detector and electronics. Machine drawings have been submitted for its construction, although its fabrication is not yet underway...|$|R
30|$|The {{last step}} is to choose a set of multivariate {{modeling}} approaches {{based on the results}} of the exploratory data analysis and investigate whether including explanatory variables and models that are more complex can improve the accuracy of the forecast. The range of the models should test for linear and non-linear relationships {{based on the results of}} the previous step along with variable selection (pruning), parameter optimization and finding the appropriate lag between variables. The authors suggest using two different variable selection methods and comparing the results to provide further explanatory insight into each variable’s importance. The first method is univariate feature selection using the Granger causality <b>test</b> as an <b>identifier</b> of the appropriate explanatory variables. The second and more robust method is using recursive feature elimination with a greedy optimization algorithm. This iterative method builds models and separates best and worst variables at each step. This process continues until all the variables have been considered. The result is the ranking of the variables based on their order of elimination. It is crucial to embed a cross validation method within the recursive variable selection method to avoid overfitting.|$|R
40|$|Praca broniona w 2005 r. Recenzenci pracy: Tadeusz Czachórski, Andrzej Pach. Praca doktorska. Akademia Górniczo-Hutnicza im. Stanisława Staszica (Kraków), 2005. Bibliogr. k. 149 - 154. Personal devices characterisation, {{mobility}} concepts, data streaming techniques, {{quality of}} service, QoS, application vs. network layer perspective, assumptions, goals, thesis, research contribution, dissertation organisation, background, related work, ubiquitous computing, pervasive communication, wireless networking technologies review, WLAN, computer personal devices, survey of mobility mechanisms, wireless access scenarios, mobility concepts toward All-IP networks', user vs. end-system mobility, IP mobility, IPv 6, impact on mobility, addressing, autoconfiguration, ICMPv 6, performance issues, security, deployment, data streaming in global networking environment, users' applications in ubiquitous computing, multimedia streaming architecture, streaming transport protocols, media data encoding, multimedia sessions control, quality of sentice, QoS parameters, traffic categories, Internet QoS models, {{requirements for the}} Computer Personal Device Mobile Data Streaming, basic design issues, assumptions, mobility definition, streaming architecture, data streaming, IPv 6 protocol, functional system requirements, basic system functions, mobility scenarios, importance, multimedia data traffic, CBR, VBR traffic patterns, BurstCBR, quality, performance requirements, audio transmission requirements, video transmission requirements, networking impact on quality of service, application layer perspective, mobility impact on QoS, security issues, implementation, deployment, system evaluation focus, design of CPDMDS Systems, application vs. Network layer mobility, MIPv 6 based mobility, review of architecture, sample mobility scenario, SIP based mobility, mobility scenarios, comparison of architecture concepts, basic systems functions, quality and performance, security issues, interoperability with Internet QoS models, CPDMDS, prototype implementation evaluation, comparison, laboratory testbed, devices' characteristic, architecture configurations, <b>test</b> configurations' <b>identifiers,</b> data patterns, methods of measurements, generic data transmission issues, IPv 6 6 WIND router delay, interarrival and interval values spread, Wireless Ethernet transmission, communicating nodes order, data streaming reliability, streaming through router, wireless segment, MIPv 6 mobility measurements, Wireless APs mobility, Ethernet switching, in practice mobile streaming, Access Points SSID change, SIPv 6 mobility characteristic, prototype evaluation summary, Cisco Aironet 350 Access Point configuration, MIPL MIPv 6 configuration files for MN, CN, Robust Audio Tool, RAT, configuration file...|$|R
40|$|Familial {{thoracic}} aortic aneurysms and dissections (F-TAADs) are a {{large group}} of autosomal dominant, clinically and genetically heterogeneous diseases sharing TAADs as a common phenotype and comprising variable combinations and recurrence of extra-aortic traits (1 – 11). Genetic aneurysmal syndromes can be suspected in subjects with a positive family history or positive family screening results. See page 397 The clinical screening provides the descriptive diagnosis (aneurysm) of F-TAADs, whereas the specific diagnosis is based on the identification of the genetic defect. Given the genetic heterogeneity of TAAD (more disease genes may cause similar phenotypes), the strategy for genetic testing either could follow screening of all known disease genes or could use extra-aortic clinical markers as a guide for genetic <b>testing.</b> The extra-aortic <b>identifiers</b> include patent ductus arteriosus (caused by mutations of MYH 11) (2, 3), iris flocculi and variable skeletal or smooth muscle dysfunction (mutations of ACTA 2) (4 – 6), gastrointestinal diseases (defects of MYLK) (7), early osteoarthritis and intracranial saccular aneurysms (mutations of SMAD 3) (8 – 10), juvenile polyposis (defects of SMAD 4) (11), and craniofacial abnormalities in Loeys-Dietz syndrome (LDS) 1 or Elhers-Danlos (EDS) -like cutaneous characteristics in LDS 2 *Editorials published in the Journal of the American College of Cardiology reflect the views of the authors and do not necessarily represent the views of JACC or th...|$|R
40|$|Serial Analysis of Gene Expression {{was used}} to define number and {{relative}} abundance of transcripts in the root tip of well-watered maize seedlings (Zea mays cv FR 697). In total, 161, 320 tags represented a minimum of 14, 850 genes, based {{on at least two}} tags detected per transcript. The root transcriptome has been sampled to an estimated copy number of approximately five transcripts per cell. An extrapolation from the data and <b>testing</b> of single-tag <b>identifiers</b> by reverse transcription-PCR indicated that the maize root transcriptome should amount to at least 22, 000 expressed genes. Frequency ranged from low copy number (2 – 5, 68. 8 %) to highly abundant transcripts (100 → 1, 200; 1 %). Quantitative reverse transcription-PCR for selected transcripts indicated high correlation with tag frequency. Computational analysis compared this set with known maize transcripts and other root transcriptome models. Among the 14, 850 tags, 7, 010 (47 %) were found for which no maize cDNA or gene model existed. Comparing the maize root transcriptome with that in other plants indicated that highly expressed transcripts differed substantially; less than 5 % of the most abundant transcripts were shared between maize and Arabidopsis (Arabidopsis thaliana). Transcript categories highlight functions of the maize root tip. Significant variation in abundance characterizes transcripts derived from isoforms of individual enzymes in biochemical pathways...|$|R
40|$|Background: The {{laboratory}} {{request form}} (LRF) is a communication link between laboratories, requesting physicians and users of laboratory services. Inadequate information or errors {{arising from the}} process of filling out LRFs can significantly impact the quality of laboratory results and, ultimately, patient outcomes. Objective: We assessed routinely-submitted LRFs to determine the degree of correctness, completeness and consistency. Methods: LRFs submitted to the Department of Haematology (DH) and Blood Transfusion Services (BTS) of Aminu Kano Teaching Hospital in Kano, Nigeria, between October 2014 and December 2014, were evaluated for completion of all items on the forms. Performance in four quality indicator domains, including patient <b>identifiers,</b> <b>test</b> request details, laboratory details and physician details, was derived as a composite percentage. Results: Of the 2084 LRFs evaluated, 999 were from DH and 1085 from BTS. Overall, LRF completeness was 89. 5 % for DH and 81. 2 % for BTS. Information on patient name, patient location and laboratory number were 100 % complete for DH, whereas only patient name was 100 % complete for BTS. Incomplete information was mostly encountered on BTS forms for physician’s signature (60. 8 %) and signature of laboratory receiver (63. 5 %). None of the DH and only 9. 4 % of BTS LRFs met all quality indicator indices. Conclusion: The level of completion of LRFs from these two departments was suboptimal. This underscores the need to review and redesign the LRF, improve on training and communication between laboratory and clinical staff and review specimen rejection practices. </p...|$|R
40|$|US DOE {{national}} {{laboratories and}} Russian institutes {{are becoming increasingly}} cooperative in support of nonproliferation of nuclear materials. This paper describes completed projects, current work, and areas of possible future cooperation between US laboratories and a Russian Ministry of Atomic Energy (MINATOM) entity, Special Scientific and Production State Enterprise (SNPO). The Kurchatov Institute, SNPO, and the US national laboratories jointly completed a physical protection system (PPS) for a facility housing two reactors at Kurchatov Institute within {{a very short time}} frame in 1994. Spin- off projects from this work resulted in a US-witnessed acceptance test of the new system adhering to a procedure adopted in Russia, and visits by DOE laboratories` personnel to SNPO`s sensor development and test facilities at Dubna and Penza. SNPO was one of the MINATOM sites at which Lawrence Livermore National Laboratory and Sandia National Laboratories (SNL) conducted a vulnerability assessment training course. Current cooperative projects include additional physical protection upgrades at Kurchatov where SNPO is involved as an installer and supplier of sensors, alarm display, video, and fiber optic equipment. Two additional contracts between SNL and SNPO result in information on Russian sensor performance and cost and an exchange of US and Russian sensors. Russian sensors will be tested in the United States,a nd US sensors will be tested in Russia. Pacific Northwest Laboratory administers a contract to document the process of certifying physical protection equipment for use at MINATOM facilities. Recent interest in transportation security has opened a new area of cooperation between the national laboratories and SNPO. Future projects are expected to include SNPO participation in physical protection upgrades at other locations in Russia, pedestrian and vehicle portal development, positive personnel <b>identifier</b> <b>testing,</b> and the exchange and testing of additional equipment...|$|R
40|$|The {{increased}} use of mobile devices has prompted the need for efficient mobility management protocols to ensure continuity of communication sessions as users switch connection between available wireless access networks in an area. Locator/Identifier (LOC/ID) split architectures are designed to, among other functions, enable the mobility of nodes on the Internet. The protocols based on these architectures enable mobility by ensuring that the identifier (IP address) used for creating a communication session is maintained throughout the lifetime of the session and only {{the location of a}} mobile node (MN) is updated as the device moves. While the LOC/ID protocols ensure session continuity during handover, they experience packet loss and long service disruption times as the MN moves from one access network to another. The mobility event causes degradation of throughput, poor network utilisation, and affects the stability of some applications, such as video players. This poor performance was confirmed from the experiments we conducted on a laboratory <b>testbed</b> running Locator <b>Identifier</b> Separation Protocol MN (LISP-MN) and Mobile IPv 6 (MIPv 6). The MIPv 6, as the standardised IETF mobility protocol, was used to benchmark the performance of LISP-MN. The poor performance recorded is owed to the design of the LISP-MN’s architecture, with no specific way of handling packets that arrive during handover events. Our main aim in this thesis is to introduce an Improved Locator/Identifier Split Architecture (ILISA) designed to enhance the mobility of nodes running a LOC/ID protocol by mitigating packet loss and reducing service disruption in handovers. A new network node, Loc-server, is central to the new architecture with the task of buffering incoming packets during handover and forwarding the packets to the MN on the completion of the node’s movement process. We implemented ILISA with LISP-MN on a laboratory testbed to evaluate its performance in different mobility scenarios. Our experimental results show a significant improvement in the mobility performance of MNs as reflected by the different network parameters investigated...|$|R
40|$|Automatic gait {{parameter}} tuning for biped walking robots is {{the subject}} of this thesis. The biped structure is one of the most versatile ones for the employment of mobile robots in the human environment. Their control is challenging because of their many DOFs and nonlinearities in their dynamics. Open loop walking with offline walk pattern generation is one of the methods for walking control. in this method the reference positions of the foot centers with respect to the body center are generated as functionals. Commonly, the tuning process for the trajectory generation is based on numerous trial and error steps. Obviously, this is a time consuming and elaborate process. In this work, online adaptation schemes for one of the trajectory parameters, "z-reference asymmetry", which is used for the compensation of uneven weight distribution of the robot in the sagittal plane, is proposed. In one of the approaches presented, this parameter is tuned online. As an alternative to parameter tuning, a functional learning scheme employing fuzzy <b>identifiers</b> is <b>tested</b> too. Fuzzy <b>identifiers</b> are universal function approximators. Fuzzy system parameters are adapted via back-propagation. An on-line tuning scheme for biped walk parameters however can only be successful if there is sufficient time for training without falling. The training might last hundreds of reference cycles. This implies that a mechanism for keeping the robot in continuous walk, even when the parameter settings are totally wrong, is necessary during training. In this work, virtual torsional springs which resist against deviations of the robot trunk angles from zero, are attached to the trunk center of the biped. The torques generated by the springs serve as the criteria for the tuning and help in maintaining a stable and a longer walk. The springs are removed after training. This novel approach can be applied to a wide range of control systems that involve parameter tuning. 3 -D simulation techniques using C++ are employed for the model of a 12 -DOF biped robot to test the proposed adaptive method. in order to visualize the walking, simulation results are animated using an OpenGL based animation environment. As a result of the simulations, a functional for the desired parameter, keeping the system in balance while walking, is generated...|$|R
40|$|Background: The {{prostate}} specific antigen (PSA) {{test has}} been available for physicians and free of charge to residents in Saskatchewan since 1990. The PSA test witnessed great growth in use indicative of screening but it was unknown who was being tested, how often, which physicians were ordering PSA tests, or what the variation in utilization was in the population. Whether widespread use of the PSA test resulted in a stage shift among newly diagnosed prostate cancers or changed the clinical management of the disease was also unknown. The purpose {{of this research was}} to describe in detail how the PSA test is being used in the Saskatchewan population and investigate the impact of testing on the diagnosis and clinical management of prostate cancer during the PSA era. Methods: Individual records were retrieved from the two labs in Saskatchewan capable of analyzing PSA serum samples. The PSA data represented almost all PSA tests in the population for the five-year period 1997 - 2001. The PSA data included date of the PSA <b>test,</b> a unique <b>identifier</b> of the men tested, test results including total PSA and the free-PSA amount (for November 1999 to December 2001), and an ID of the physician who ordered the test. This data was linked to the population-based Saskatchewan Cancer Registry to determine who had a previous or subsequent prostate cancer diagnosis and to secure tumour characteristics and clinical management data. This combined data was then linked to Saskatchewan Health data files to obtain information about biopsy procedures and to determine the geographic residence of men {{at the time of their}} PSA tests. De-identified data was returned for descriptive analysis. Results: Over 60 % of men aged 50 and over had at least one PSA test during 1997 to 2001. Even among men 40 - 49, 27 % had at least one PSA test and there were over 5, 300 tests done in men under 40 years of age. Sixteen percent of men 40 - 49 who had PSA tests had more than one and this percentage increased with age to 59. 4 % for men in their 70 ’s. Over 80 % of all PSA tests were ordered by general practitioners and there were significant geographic variations in testing patterns. Knowledge of the free-PSA-ratio, which began in 1999, reduced biopsy rates 4. 7 % and increased cancer detection 8. 7 % for men with total PSA test results in the 4. 0 - 10. 0 ng/ml range, however these rates were also very age specific. The age-adjusted incidence rate of organ confined disease increased from 38. 5 per 100, 000 to 108. 8 per 100, 000 from 1985 to 2001. Almost 80 % of prostate cancers were detected by needle biopsy in 2001 compared to only 34 % in 1985, while 20 % of cases in 2001 were treated with radical surgery compared to only 2 % for 1985. Mortality rates have remained stable up to 2001. Conclusion: PSA testing is very common in Saskatchewan consistent with extensive screening activity. Conflicting guidelines and the universal availability of the test has resulted in significant inappropriate testing and considerable variation of use. Most prostate cancers are now found by needle biopsy and are organ confined at the time of diagnosis. No benefit in prostate cancer mortality has yet been realized in Saskatchewan from extensive PSA testing...|$|R

