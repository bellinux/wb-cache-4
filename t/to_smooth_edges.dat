7|10000|Public
50|$|The X-ray Engine is a DirectX 8.1/9 Shader Model 3.0 {{graphics}} engine. Up to {{a million}} polygons can be on-screen at any one time. The engine features HDR rendering, parallax and normal mapping, soft shadows, motion blur, widescreen support, weather effects and day/night cycles. As with other engines that use deferred shading, the X-ray Engine does not support multisample anti-aliasing with dynamic lighting enabled. However, a different form of anti-aliasing can be enabled with dynamic lighting which utilizes an edge detection algorithm <b>to</b> <b>smooth</b> <b>edges</b> between objects. The game {{takes place in a}} thirty square kilometer area, and both the outside and inside of this area are rendered to the same amount of detail. Some textures in the game were photographs of the walls in the developers' studio.|$|E
5000|$|The Seneca Glass Company used European glass {{production}} methods {{learned by}} their founders in Germany. [...] The glass was lead flint glass, {{which is made}} mostly from silica, potash, and oxide of lead. This type of glass has more sparkle and shine than flint glass made from lime. [...] Using technology from the 1890s and earlier, the glassblower’s assistant (the gatherer) used a hollow pipe to extract molten glass from a pot. [...] A pot was about 40 inches in diameter, and Seneca’s pots held 2000 lbs kg of batch. [...] The glass blower and his crew used air, hand tools, and molds to shape the glass into the desired form. The glass appears orange, and then yellow, while it is still being shaped. In some cases, a glazer was used <b>to</b> <b>smooth</b> <b>edges</b> of the glass with small jets of flame. [...] Once the glass had the correct shape, it was then placed in a lehr, which is a long oven used for annealing, a process where the glass is gradually cooled. Without annealing, the glass would easily shatter. In {{the case of the}} glassware made at Seneca's Morgantown plant, it took almost 2 hours for the glass to move through the lehr. [...] Some of the finished glass would be cut, engraved, and/or polished. Glass with gold or silver trim added would be reheated to fuse the trim to the glass.|$|E
40|$|While simple line-drawing {{techniques}} produce "jagged " {{lines on}} raster images, more complex anti-aliasing, or filtering, techniques use gray-scale {{to give the}} appearance of smooth lines and edges. Unfortunately, these techniques are not frequently used because filtering is thought to require considerable computation. This paper presents a simple algorithm {{that can be used to}} draw filtered lines; the inner loop is a variant of the Bresenham point-plotting algorithm. The algorithm uses table lookup to reduce the computation required for filtering. Simple variations of the algorithm can be used to draw lines with different thicknesses and <b>to</b> <b>smooth</b> <b>edges</b> of polygons...|$|E
5000|$|... a GPU-accelerated {{rendering}} engine for display objects, featuring a vector-to-triangle tessellation engine {{with an edge}} anti-aliasing algorithm that uses subpixel triangles <b>to</b> <b>smooth</b> the <b>edges</b> ...|$|R
25|$|The farrier then uses a rasp (large file), <b>to</b> <b>smooth</b> the <b>edge</b> {{where it}} meets the shoe and {{eliminate}} any sharp edges left from {{cutting off the}} nails.|$|R
50|$|The {{leaves are}} opposite, small, 3-15 mm long and 2-8 mm wide, ovate <b>to</b> elliptic, have <b>smooth</b> <b>edges</b> (entire), {{and with a}} very short or nonexistent petiole.|$|R
40|$|International audienceNormal {{estimation}} {{in point}} clouds {{is a crucial}} first step for numerous algorithms, from surface reconstruction and scene understanding to rendering. A recurrent issue when estimating normals is to make appropriate decisions close to sharp features, not <b>to</b> <b>smooth</b> <b>edges,</b> or when the sampling density is not uniform, to prevent bias. Rather than resorting to manually-designed geometric priors, we propose {{to learn how to}} make these decisions, using ground-truth data made from synthetic scenes. For this, we project a discretized Hough space representing normal directions onto a structure amenable to deep learning. The resulting normal estimation method outperforms {{most of the time the}} state of the art regarding robustness to outliers, to noise and to point density variation, in the presence of sharp edges, while remaining fast, scaling up to millions of points...|$|E
40|$|A new {{processing}} {{scheme for}} large high-resolution displays such as Videowalls is proposed in this paper. The scheme consists in a deinterlacing, an interpolation and an optional enhancement algorithm; its hardware implementation requires a low computational cost. The deinterlacing algorithm is motion-adaptive. A simple hierarchical three-level motion detector provides indications of static, slow and fast motion to activate a temporal FIR filter, a three-tap vertico-temporal median operator and a spatial FIR filter respectively. This simple algorithm limits the hardware requirements to three field memories plus a very reduced number of algebraic operations per interpolated pixel. Usually linear {{techniques such as}} pixel repetition or the bilinear method are employed for image interpolation, which however either introduce artifacts (e. g. blocking effects) or tend <b>to</b> <b>smooth</b> <b>edges.</b> A higher quality rendition of the image is obtained by {{the concept of the}} Warped Distance among the pixels o [...] ...|$|E
40|$|In {{this paper}} we present an {{innovative}} interpolator which performs high quality 2 Θ interpolation on both synthetic and real world images. Its structure, {{which is based}} on a rational operator, provides edge sensitive data interpolation, so that sharp and artifacts free images are obtained, notwithstanding a resonable computational cost. Keywords Interpolation and Spatial Transformation, Image Processing, Digital Signal Processing via A. Valerio, 10, 34100 Trieste, Italy tel. : + 39. 040. 6767147; fax: + 39. 040. 6763460, e-mail: tenze@ipl. univ. trieste. it EDICS: SPL. IP. 1. 10 1 Introduction Recently, due to the wide diffusion of multimedia applications and wide area screens (e. g., video-walls), the problem of image format conversion has significantly increased its importance. Usually [1] linear operators such as pixel repetition and bilinear or bicubic convolution [2] are used, which however either introduce artifacts (e. g., blocking effects) or tend <b>to</b> <b>smooth</b> <b>edges,</b> thus providing [...] ...|$|E
5000|$|... #Caption: For sharpening, the {{sharpener}} has to {{be pulled}} two to four times over the cutting edge with pressure. After that, the sharpener {{has to be}} pulled four to six times over the cutting edge with light pressure <b>to</b> <b>smooth</b> the <b>edge.</b>|$|R
50|$|In order <b>to</b> {{maintain}} a <b>smooth</b> <b>edge,</b> shapes can be outlined with back, split or chain stitch before the entire shape including the outline {{is covered with}} satin stitch.|$|R
50|$|Some {{people also}} {{thought that the}} control sticks used in the PS2 & Xbox {{controllers}} made the essential precision {{a little bit harder}} to achieve in the long run due <b>to</b> the <b>smooth</b> <b>edges</b> and deadzone, whereas those of the Gamecube controller had octagonal edges and no deadzones at all.|$|R
40|$|Super-resolution mapping (SRM) is {{a method}} for allocating land cover classes at a fine scale {{according}} to coarse fraction images. Based on a spatial regularization framework, this paper proposes a new regularization method for SRM that integrates multiscale spatial information from the fine scale as a smooth term and from the coarse scale as a penalty term. The smooth term is considered a homogeneity constraint, and the penalty term is used to characterize the heterogeneity constraint. Specifically, the smooth term depends on the local fine scale spatial consistency, and is used <b>to</b> <b>smooth</b> <b>edges</b> and eliminate speckle points. The penalty term depends on the coarse scale local spatial differences, and suppresses the over-smoothing effect from the fine scale information while preserving more details (e. g., connectivity and aggregation of linear land cover patterns). We validated our method using simulated and synthetic images, and compared the results to four representative SRM algorithms. Our numerical experiments demonstrated that the proposed method can produce more accurate maps, reduce differences {{in the number of}} patches, visually preserve smoother edges and more details, reject speckle points, and suppress over-smoothing...|$|E
50|$|Another {{surgical}} {{option for}} {{this stage is}} a titanium, silicon or pyrocarbon implant that takes place of the lunate, though doctors shy from this due to a tendency of the implant <b>to</b> <b>smooth</b> the <b>edges</b> of the surrounding bones, thus causing painful pinched nerves when the bones slip out of place.|$|R
40|$|We {{describe}} a new self-learning framework for parser lexicalisation that requires only a plain-text corpus of in-domain text. The method first creates augmented versions of dependency graphs by applying {{a series of}} modifications designed to directly capture higherorder lexical path dependencies. Scores are assigned to each edge in the graph using statistics from an automatically parsed background corpus. As bilexical dependencies are sparse, a novel directed distributional word similarity measure is used <b>to</b> <b>smooth</b> <b>edge</b> score estimates. Edge scores are then combined into graph scores and used for reranking the topn analyses found by the unlexicalised parser. The approach achieves significant improvements on WSJ and biomedical text over the unlexicalised baseline parser, which is originally trained on {{a subset of the}} Brown corpus. ...|$|R
2500|$|After the molds are removed, workers use {{hand tools}} and sponges <b>to</b> <b>smooth</b> the <b>edges</b> and {{surface of the}} greenware, and to remove the mold joints or roughness: this process is called [...] "fettling". For large scale {{production}} pieces, these steps may be automated. The parts are then left outside or put in a warm room to dry, before going through a dryer at about , for about 20–36 hours.|$|R
40|$|We {{introduce}} {{a family of}} smoothing algorithms that can produce discontinuous output. Unlike most commonly used smoothers, that tend to blur discontinuities in the data, this smoother {{can be used for}} <b>smoothing</b> with <b>edge</b> detection. We cite examples of other approaches <b>to</b> (two-dimensional) <b>smoothing</b> with <b>edge</b> detection in image processing, and apply our onedimensional <b>smoother</b> <b>to</b> sea surface temperature data where the discontinuities arise from changes in ocean currents. (Submitted to Technometrics. ...|$|R
40|$|This {{dissertation}} {{presents a}} method capable of smoothing {{the silhouette of}} a 3 D model using interpolation <b>to</b> find <b>smooth</b> <b>edges.</b> The method has as goal to be used with normal mapping to improve the performance and give a better result with a low polygonal count. To do this the lines located on {{the silhouette of a}} model is interpolated to find a curve that is used as clipping frame in the stencil buffer. This method is able to modify the silhouette for the better. The amount of interpolation is rather limited...|$|R
40|$|Although most of {{existing}} anisotropic diffusion (AD) methods {{are supported by}} prefect mathematical theories, they still lead <b>to</b> <b>smoothed</b> <b>edges</b> and anatomy details (EADs). They are caused by not considering the discrete nature of digital signal. In order to improve the performance of AD in sinogram restoration of low-dosed computed tomography (LDCT), we propose a new AD method, named regularized multidirections and multiscales anisotropic diffusion (RMDMS-AD), by extending AD to regularized AD (RAD) in multidirections and multiscales. Since the multidirections can reduce the discrete errors to the maximum extent, meanwhile multiscales and RAD make searching neighborhood of solution be as large as possible which can get more optimal solution to AD, the new proposed method can improve the performance of AD both in denoising and in stability of solution. Moreover, the discrete errors and ill-posed solutions occur mostly near the EADs; the RMDMS-AD will also preserve EADs well. Comparing the proposed new method to existing AD methods using real sinogram, the new method shows good performance in EADs preserving while denoising and suppressing artifacts...|$|R
50|$|First, {{the shape}} of the {{transmit}} pulse is adjusted <b>to</b> <b>smooth</b> the leading <b>edge</b> and trailing edge so that RF power is increased and decreased without an abrupt change. This creates a transmit pulse with smooth ends instead of a square wave, which reduces ringing phenomenon that is otherwise associated with target reflection.|$|R
5000|$|This is {{an annual}} herb growing an erect, {{branching}} stem up 80 centimeters in maximum height. It is powdery in texture, {{especially on the}} leaves and flowers. The leaves are up to 3 centimeters long, oval <b>to</b> lance-shaped with <b>smooth</b> <b>edges.</b> The inflorescence is a spike or panicle a few centimeters long made up of several clusters of tightly-packed tiny flowers. Each flower has five lobes and coats the developing fruit.|$|R
30|$|From Fig.  2, it {{is shown}} {{that for a}} {{specific}} value of a, error always becomes less and less {{with the increase of}} the minor principle stress toward the direction of compression stress. Meanwhile, if assuming θ T =  29 °, as suggested by Owen and Hinton [19], the closer results <b>to</b> <b>smooth</b> the <b>edges</b> of the M–C hexagonal yield surface pyramid will be obtained. And the examples in this paper will show that fast convergence can still be achieved and the higher precisions than those of Abbo–Sloan [8] and Jia et al. [9] can be obtained as well.|$|R
30|$|Partial {{smoothing}}. A partial smoothing {{program was}} applied <b>to</b> <b>smooth</b> the rock <b>edge</b> without affecting {{detailed information on}} the fractures inside the SRM. This program was accomplished by applying the median filter to the image, which only includes the rock information that was extracted from the multiple-threshold segmented image. Then, the smoothed rock image and multiple-threshold segmented image were combined to obtain the result.|$|R
40|$|This paper {{describes}} {{how to use}} an anisotropic diffusion model with time-dependent diffusion coefficients to denoise a digital image while preserving its edges. Traditional edge detection algorithms, while good for denoising an image, lack in preserving its <b>edges,</b> due <b>to</b> the <b>smoothing</b> process. <b>Edge</b> detection algorithms, based on partial differential equations, or diffusion models, are superior alternatives to solve this kind of problem. Pages: 5957 - 596...|$|R
40|$|This paper {{describes}} {{how to use}} the complex linear diffusion filter for edges detection. A practical Java implementation is also available. Traditional edge detection algorithms, while good for denoising an image, lack in preserving its <b>edges,</b> due <b>to</b> the <b>smoothing</b> process. <b>Edge</b> detection algorithms, based on partial differential equations, or diffusion models, are superior alternatives to solve this kind of problem. Pages: 7580 - 758...|$|R
5000|$|The cane Brooks {{used was}} broken into several pieces, which he {{left on the}} blood soaked floor of the Senate chamber. Some, {{including}} the cane's gold head, were recovered by Edmundson, who gave the portion with the head to Adam John Glossbrenner, the House Sergeant at Arms. [...] This portion of the cane eventually {{ended up at the}} Old State House Museum in Boston; it was worked <b>to</b> <b>smooth</b> the <b>edges</b> and finish, and then put on display. [...] Southern lawmakers made rings out of the other pieces Edmundson recovered from the Senate floor, which they wore on neck chains to show their solidarity with Brooks, who boasted [...] "pieces of my cane are begged for as sacred relics." ...|$|R
40|$|An {{integrated}} high Tc dc-SQUID magnetometer {{is being}} developed. It has in total 10 layers of five different materials. Various materials {{aspects of the}} fabrication process will be discussed, especially the smoothness of the films and the techniques <b>to</b> obtain <b>smooth</b> <b>edges.</b> Cross-overs and superconducting window contacts were fabricated. The critical temperature of the window-contact is 84 K (jc(77 K) = 2 · 105 A/cm 2) and the resistivity of the insulating SrTiO 3 layer in the cross-over is 6 · 105 Ωcm at 77 K. The complete coil often shows a small resistive component down to about 50 K. Ramp type and bi-epitaxial grain boundary dc-SQUIDs show voltage modulation up to 65 K and 79 K, respectively. Efforts to fabricate an integrated high Tc dc-SQUID magnetometer will be discussed...|$|R
5000|$|Booklist USA (Ilene Cooper) wrote, [...] "Typically, Christians {{and others}} have tried <b>to</b> <b>smooth</b> the jagged <b>edges</b> between Christianity as a Jewish sect and as an {{worldwide}} religion by making {{it seem as if}} the latter evolved from the former….Wilson offers long, fascinating…arguments about why this seeming evolution was more church propaganda than fact, which he backs up with descriptions of the kinds of early Judaism that allow Jesus his place as a Torah-loving Jew who would find Paul’s view anathema." ...|$|R
3000|$|... [...]. The {{method used}} to perform MCI is {{a variant of}} the one {{described}} in [37]. First the key frames are mean filtered. The filtered key frames are then used for bidirectional pixel level accuracy block matching (BM) using large blocks and the modified sum of absolute difference (SAD) metric in [37]. These vectors are used as starting points for a BM algorithm using smaller blocks with a fixed search range. The motion vector (MV) field generated with large blocks is quadrupled in density (oversampled by a factor of two in both directions), before being median filtered. By increasing the density, we allow the median filter <b>to</b> produce <b>smoother</b> <b>edges</b> and more precise vectors. The MV field generated with smaller blocks is also quadrupled in density before being median filtered. These two MV fields are then used to create two MCI hypotheses by interpolating from the original key frames.|$|R
40|$|In the {{presence}} of sufficiently strong surface energy anisotropy the equilibrium shape of an isothermal crystal may include corners or edges. Models of edges have, to date, involved the regularisation of the corresponding free boundary problem resulting in equilibrium shapes with <b>smoothed</b> out <b>edges.</b> In this paper we take a new approach and consider how a phase-field model, which provides a diffuse description of an interface, can be extended to the consideration of edges by an appropriate regularisation of the underlying mathematical model. Using the method of matched asymptotic expansions we develop an approximate solution which corresponds <b>to</b> a <b>smoothed</b> out <b>edge</b> from which {{we are able to}} determine the associated edge energy...|$|R
50|$|Material to {{be tested}} must be cut to a {{specific}} shape so as to fit the grips, most usually {{in the form of}} a dog-bone shape when flat sheet is being tested. The sheet is cut or machined to shape, and great care is needed <b>to</b> create a <b>smooth</b> <b>edge.</b> If defects are left, the result may be premature failure from the defect, thus underestimating tensile strength. Different shaped samples need different grip designs to achieve their objective. Fibres for example, require rod grips around which fibre can be wound prior to straining. Product tests may even need special grips to be designed owing to the shape variability of complex products.|$|R
50|$|Its {{leaves are}} glaucous−gray, waxy and woolly <b>to</b> <b>smooth</b> and hairless, with <b>smooth</b> <b>edges.</b> They are base lobed (ariculate), rounded to oval in shape, 1.5 - 2.5 cm wide and 2 - 4 cm long.|$|R
40|$|In many image {{processing}} applications, {{it is often}} important to accurately expand images without loss of clarity. Traditional methods such as bilinear and bicubic spline interpolation tend <b>to</b> <b>smooth</b> out <b>edge</b> regions and result in blurry images. In this work, we propose two methods for image interpolation: a multiresolution approach for enhancing isolated edges, and a texture analysis approach for interpolating non-isolated edges such as those found in a texture image. Edges and textures {{are among the most}} important features of an image. They have, however, very different characteristics, suggesting that they should be enhanced using different techniques. For edges, we propose a novel and theoretically elegant approach which extrapolates the high resolution information needed to sharpen the image. This information is obtained by estimating the wavelet transform of the higher resolution based on the evolution of wavelet transform extrema across the scales. The motivation for this algorit [...] ...|$|R
40|$|Traditional {{radiography}} is a {{non-destructive inspection}} (NDI) process widely {{used for the}} detection of cracks and damage in aircraft structures. However a significant limitation is that it relies on visual assessment by the operator for identification of defects from the radiographic image. Digital radiography allows all the benefits of producing significant increases in magnification and image clarity, as well as efficient management of digital images. Image enhancement allows more accurate interpretation of digital radiography indications. In this paper, image enhancement methods are investigated for NDI inspection of the aircraft. The wavelet thresholding technique is applied to reduce the radiographic image noise. The contrast and brightness of the image is adjusted using gamma correction and contrast limited adaptive histogram equalization to enhance perception of defects. These are used to eliminate noise and background artifacts and <b>to</b> <b>smooth</b> sharp <b>edges,</b> but also tend to remove some of the detail in small objects. 1...|$|R
40|$|When {{designers}} begin {{a product}} design, they create {{their ideas and}} expand them. This process is performed on paper, and designers' hand-drawn lines are called sketches. If the designers' hand-drawn sketches can be realized as real curves, it would be effective in shortening the design period. We have developed a method to extract five degree Bezier curves based on a hand-drawn sketch. The basic techniques to detect curves based on a hand-drawn sketch are described. First, light intensity transformation, binarization of the hand-drawn sketch, and feature based erosion and dilation <b>to</b> <b>smooth</b> the <b>edges</b> of the binary sketch image are described. Then, line segment determination using the detected edges is described. Using the determined line segments a five degree Bezier curve generation is described. A curve shape modification algorithm is described to reconstruct a five degree Bezier curve. Examples of five degree fair curvature Bezier curves based on a sketch are given...|$|R
40|$|This paper {{presents}} DPC++, {{an extension}} of C++ dedicated to object-oriented parallel and distributed programming on clusters of SMPs. DPC++ follows the active object model and provides language constructs for the exploration of both fine- and coarse-grain parallelism. The main goal of the language is to encourage intuitivity in concurrent programming by means of implicit parallelism. We present an overview of its main characteristics and describe {{the implementation of a}} parallel algorithm using the proposed extensions. Keywords: Active objects, Cluster computing, Implicit concurrency 1 Introduction Cluster computing is currently a common practice in the field of parallel processing around the world, thus it is desirable that the use of such computing platforms be accessible to an as wide as possible group of users. This motivation has led, in the last years, to the introduction of concurrency in ordinary programming languages as a means <b>to</b> <b>smooth</b> the <b>edges</b> between sequential and par [...] ...|$|R
