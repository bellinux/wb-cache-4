48|10000|Public
50|$|At {{the behest}} of the Second Vatican Council, Pope Paul VI greatly {{increased}} the amount of Sacred Scripture read at Mass and, to a lesser extent, the prayer formulas. This necessitated a return to having the Scripture readings in a separate book, known as the Lectionary. A separate Book of the Gospels, with <b>texts</b> <b>extracted</b> <b>from</b> the Lectionary, is recommended, but is not obligatory. The Roman Missal continues to include elaborate rubrics, as well as antiphons etc., which were not in sacramentaries.|$|E
30|$|Portuguese Relation Extraction {{has been}} boosted mainly by the HAREM {{evaluation}} contest. The first HAREM dealt with NER mainly whereas the RE task {{appeared in the}} Second HAREM in 2008, in the ReRelEM track. A {{great deal of the}} literature in this area refers to this evaluation contest. [44] deals with the study of target relations for the ReRelEM track [18] (further details in Sect.  5). Such relations were selected from the manual analysis of twelve Portuguese <b>texts</b> <b>extracted</b> <b>from</b> the Second HAREM’s Golden Collection.|$|E
40|$|Colloque avec actes et comité de lecture. internationale. International audienceThis article {{deals with}} the text mining {{activity}} applied to technological watch. We focus on the extraction process of association rules using a Galois lattice and relate our experimentation on a corpora. The corpus is composed of abstracts of scientific <b>texts</b> <b>extracted</b> <b>from</b> a documentary database. The interpretation of the results is based upon {{an analysis of the}} different levels of the lattice as well as an analysis of the different interpretations associations rules can be assigned to...|$|E
30|$|Author: the <b>text</b> <b>extracted</b> <b>from</b> the AUTHOR {{attribute}} in META of the HTML document.|$|R
5000|$|<b>Text</b> <b>extracted</b> <b>from</b> the {{introduction}} to The Journal to Stella by George A. Aitken and from other sources) ...|$|R
5000|$|The example below {{shows an}} XLIFF {{document}} storing <b>text</b> <b>extracted</b> <b>from</b> a Photoshop file (PSD file) and its translation in Japanese: ...|$|R
30|$|To {{build the}} Spanish {{acoustic}} model {{we used the}} Albayzin [34] corpus. The corpus comprises two sub-corpora with 6, 800 utterances each: one based on <b>texts</b> <b>extracted</b> <b>from</b> novels and the other based on queries to a geography database. The utterances were recorded under good acoustic conditions (quiet offices, with {{the same set of}} professional microphones) and were pronounced by 304 speakers (152 female, 152 male), whose age varied from 18 to 55 years. The Albayzin corpus represents 12 h 52 min of annotated speech in 13, 600 gender and phonetically balanced sentences.|$|E
40|$|In {{opposition}} to the courtesan liric, Petrach’s poetry is not characterized by a dialogic and social dimension. It {{does not have the}} loved as its center, but the poet himself, and its fundamentally subj ective. Taking this interpretation as a point of departure, the author analises sonnet n. 272, which is considered extremely modern as far as some symptoms of what is actually called a depression can be discovered in it. <b>Texts</b> <b>extracted</b> <b>from</b> his S e c retum seem to confirm this intuition about Petrach’s complex psicology...|$|E
40|$|This paper {{describes}} ongoing {{research on}} the lexicalNation problem in a nultilingual generation framework. We will focus in particular on two major types of verbal differences observed in a corpus of bilingual (French - English) pro- cedural <b>texts</b> <b>extracted</b> <b>from</b> aircraft mainte- nance manuals. To deal with {{these two types of}} differences, we propose lexicalNation mech- anisms, which proceed from the same semantic representation for both French and English re- alisations. We will however discuss {{at the end of the}} paper other types of lexical differences which may require language-specific inputs...|$|E
50|$|Bach {{composed}} and copied separate movements on a <b>text</b> <b>extracted</b> <b>from</b> the Mass ordinary. He also copied {{and arranged}} larger Mass compositions (mostly Kyrie-Gloria masses).|$|R
25|$|Devi Mahatmya is a <b>text</b> <b>extracted</b> <b>from</b> Markandeya Purana, and {{constitutes}} the latter's chapters 81 through 93. The Purana is dated to the ~3rd century CE, and the Devi Mahatmya {{was added to}} the Markandeya Purana either in the 5th or 6th century.|$|R
30|$|Alternate text: the <b>text</b> entry <b>extracted</b> <b>from</b> the ALT {{attribute}} of the IMG tag.|$|R
40|$|This article {{analyses}} {{the discourse}} on favelas produced by Brazilian society and {{consumed in the}} political field of local administration. The ideological conception of favelas (slums) determines the creation of public policies that reinforce the prejudicial notion of favelas. This work employs critical discourse analysis (CDA) to analyse several <b>texts</b> <b>extracted</b> <b>from</b> mass-media stories and press releases of the Rio government. It shows {{that the state of}} praxis reproduces the understanding of slums as a phenomenon detached from the rest of society. This alienated vision impacts on different utterances blaming the poor (analysis 1); perpetuating poverty (analysis 2); and reinforcing exclusion (analysis 3) ...|$|E
40|$|The present work aims {{to analyze}} the {{construction}} of speciesist representations in graphic press speaking about homeless dogs. We will take {{as a starting point}} the hypothesis that these representations construct the concept of "homeless animal" as a sanitary risk for the human species and, therefore, nonhuman animals are described as the enemy and their resemblance is not the resemblance of a live being. We will analyze three <b>texts,</b> <b>extracted</b> <b>from</b> the digital versions of three different newspapers, published in different countries and written in different languages. We will adopt Social Semiotics by Hodge and Kress [1988] as the main theoretical framewor...|$|E
40|$|International audienceThis paper {{introduces}} {{the concept of}} set deviation as a toolto characterize the deviation {{of a set of}} strings around its setmedian. The set deviation is defined as the set median of thepositive edit sequences between any string and the set median. We show that the set deviation has the same properties as theclassic second-order statistical moment. This approach is generalizedto higher-order moments of a set of strings. We then show how the set deviation can be efficiently used in well-knownstatistical algorithms to improve the computation of the set medianof a set of strings,illustrating this concept with several examples, particularlyin post-processing of <b>texts</b> <b>extracted</b> <b>from</b> video sequences...|$|E
40|$|In this paper, we {{introduce}} a multifaceted approach for question answering on lecture videos. <b>Text</b> <b>extracted</b> <b>from</b> PowerPoint slides {{associated with the}} lecture videos {{is used as a}} source of domain knowledge to boost the answer extraction performance on these domain specific videos. The three steps of this approach are described and the evaluation plan is discussed...|$|R
40|$|Abstract — We {{put forward}} a {{hypothesis}} {{that if there is}} a link from one page to another, it is likely that comprehensibility of the two pages is similar. To investigate whether this hypothesis is true or not, we conduct experiments using existing readability measures. We investigate the relationship between links and readability of <b>text</b> <b>extracted</b> <b>from</b> web pages for two datasets, set of English and Japanese pages. We could find that links and readability of <b>text</b> <b>extracted</b> <b>from</b> web pages are correlated. Based on the hypothesis, we propose a link analysis algorithm to measure comprehensibility of web pages. Our method is based on the TrustRank algorithm which is originally used for combating web spam. We use link structure to propagate readability scores from source pages selected based on their comprehensibility. The results of experimental evaluation demonstrate that our method could improve estimation of comprehensibility of pages. Keywords-comprehensibility; link analysis; readability I...|$|R
50|$|Several <b>texts</b> were <b>extracted</b> <b>from</b> the romancero or {{were written}} by known authors, such as Lope de Vega, Catalina Zamudio, etc.|$|R
40|$|International audienceMost OCR (Optical Character Recognition) systems {{developed}} to recognize texts embedded in multimedia documents segment the text into characters before recognizing them. In this paper, we propose {{a novel approach}} able to avoid any explicit character segmentation. Using a multi-scale scanning scheme, <b>texts</b> <b>extracted</b> <b>from</b> videos are first represented by sequences of learnt features. Obtained representations are then used to feed a connectionist recurrent model specifically designed {{to take into account}} dependencies between successive learnt features and to recognize texts. The proposed video OCR evaluated on a database of TV news videos achieves very high recognition rates. Experiments also demonstrate that, for our recognition task, learnt feature representations perform better than hand-crafted features...|$|E
40|$|Abstract This paper {{introduces}} {{the concept of}} set deviation {{as a tool to}} characterise the deviation of a set of strings around its set median. The set deviation is defined as the set median of the positive edit sequences between any string and the set median. We show that the set deviation has the same properties as the classic second-order statistical moment. This approach is generalised to higherorder-moments of a set of strings. We then show how the set deviation can be efficiently used in well-known statistical algorithms to improve the computation of the set median of a set of strings, illustrating this concept with several examples, particularly in post-processing of <b>texts</b> <b>extracted</b> <b>from</b> video sequences...|$|E
40|$|Abstract. With the Internet {{facing the}} growing problem of {{information}} overload, the large volumes, weak structure and noisiness of Web data make it amenable {{to the application}} of machine learning techniques. After providing an overview of several topics in text categorization, including document representation, feature selection, and a choice of classifiers, the paper presents experimental results concerning the performance and effects of different transformations of the bag-of-words document representation and feature selection, on <b>texts</b> <b>extracted</b> <b>from</b> the dmoz Open Di-rectory of Web pages. Finally, the paper describes the primary motivation for the experiments: a new meta-search engine CatS which utilizes text categorization to enhance the presentation of search results obtained from a major Web search engine...|$|E
5000|$|This {{particular}} koan {{seems to}} have been closely based on a real incident; the following <b>text</b> <b>extract</b> is <b>from</b> Hackers: Heroes of the Computer Revolution (chapter 6): ...|$|R
50|$|Komitas {{was also}} {{the editor of the}} {{collection}} of Armenian translations of patristic <b>texts</b> (including <b>extracts</b> <b>from</b> lost <b>texts,</b> e.g. Timothy Aelurus) known as the Seal of Faith.|$|R
40|$|Amazon’s Mechanical Turk (MTurk) {{service is}} {{becoming}} increasingly popular in Natural Language Processing (NLP) research. In this paper, we report our findings in using MTurk to annotate medical <b>text</b> <b>extracted</b> <b>from</b> clinical trial descriptions with three entity types: medical condition, medication, and laboratory test. We compared MTurk annotations with a gold standard manually created by a domain expert. Based on the good performance results, we conclude that MTurk is a very promising tool for annotating large-scale corpora for biomedical NLP tasks. ...|$|R
40|$|This paper {{introduces}} {{the concept of}} set deviation {{as a tool to}} characterize the deviation of a set of strings around its set median. The set deviation is defined as the set median of the positive edit sequences between any string and the set median. We show that the set deviation has the same properties as the classic second-order statistical moment. This approach is generalized to higherorder moments of a set of strings. We then show how the set deviation can be e#ciently used in well-known statistical algorithms to improve the computation of the set median of a set of strings, illustrating this concept with several examples, particularly in post-processing of <b>texts</b> <b>extracted</b> <b>from</b> video sequences...|$|E
40|$|This paper {{seeks to}} {{contribute}} {{to the study of the}} vernacularisation process in late Middle English by measuring up to what an extent concrete and abstract noun suffixes (in line with Dalton-Puffer 1996) attach to either Germanic or Romance bases in the medical <b>texts</b> <b>extracted</b> <b>from</b> the MEMT (Middle English Medical Texts) corpus. The findings obtained have been further described according to text type or genre and to target audience/readership. The description of these suffixes in relation to all the parameters already mentioned has confirmed the predominance of abstract suffixes of Romance origin although Germanic abstract suffixes are also abundant. More hybrid formations have been found with Germanic noun suffixes than with Romance ones which might be indicative of their versatility towards vernacularisation...|$|E
40|$|In {{this paper}} we present several {{experiments}} {{for the task}} entitled sentiment analysis at global level within the TASS evaluation campaign. The aim of this task is to assess the global polarity of Spanish short <b>texts</b> <b>extracted</b> <b>from</b> Twitter. To tackle this task, an approach based on machine learning by trying different feature combinations was applied. Several in-house built dictionaries and machinetranslated data for training were employed by adapting an approach designed for English to Spanish. Additionally, four separate classifiers were tested in cascade to determine the sentiment from the general to the finer-grained classes of polarity. Although {{this is our first}} participation, the proposed approaches might be considered good strategies to generate learning data for polarity classification systems in Spanish. JRC. G. 2 -Global security and crisis managemen...|$|E
50|$|Liber Floridus ("Book of Flowers") is {{a medieval}} {{encyclopedia}} that was compiled between 1090 and 1120 by Lambert, Canon of Saint-Omer. The <b>text</b> compiles <b>extracts</b> <b>from</b> some 192 or so different works.|$|R
40|$|This paper {{explores the}} {{feasibility}} of automated question answering from lecture video materials {{used in conjunction with}} PowerPoint slides. Two popular approaches to question answering are discussed, each separately tested on the <b>text</b> <b>extracted</b> <b>from</b> videotaped lectures: 1) the approach based on Natural Language Processing (NLP) and 2) a self-learning probabilistic pattern matching approach. The results of the comparison and our qualitative observations are presented. The advantages and shortcomings of each approach are discussed in the context of video applications for e-learning or knowledge management. 1...|$|R
40|$|The Nottingham Corpus of Early Modern German Midwifery and Women’s Medicine (ca. 1500 - 1700), or the GeMi Corpus, is a {{collection}} of digitised, machine-readable <b>text</b> <b>extracts</b> <b>from</b> sixteenth- and seventeenth-century German-language medical texts devoted to midwifery and women’s medicine. The aim of the corpus is to provide a representative sample of the earliest printed German-language Fachsprache, or specialised language, devoted to midwifery and childbirth. Texts are available in two formats: as an untagged diplomatic transcription (the 'raw' version), and as an XML-encoded version (the 'TEI' version) ...|$|R
40|$|In {{this paper}} we present {{the first steps}} toward {{improving}} summarization of scientific documents through citation analysis and parsing. Prior work (Mohammad et al., 2009) argues that citation texts (sentences that cite other papers) {{play a crucial role}} in automatic summarization of a topical area, but did not take into account the noise introduced by the citations themselves. We demonstrate that it is possible to improve summarization output through careful handling of these citations. We base our experiments on the application of an improved trimming approach to summarization of citation <b>texts</b> <b>extracted</b> <b>from</b> Question-Answering and Dependency-Parsing documents. We demonstrate that confidence scores from the Stanford NLP Parser (Klein and Manning, 2003) are significantly improved, and that Trimmer (Zajic et al., 2007), a sentence-compression tool, is able to generate higher-quality candidates. Our summarization output is currentl...|$|E
30|$|This paper draws {{some general}} {{conclusions}} {{from the evidence}} gathered by two recent analyses, which traced the development of advanced literacy by two undergraduate language learner populations: (1) Humanities students of the National Autonomous University of Mexico for whom Spanish is a native language (L 1); and (2) Linguistics students enrolled at the University of California, Davis for whom Spanish is either a heritage (HL) or a second language (L 2). Textual scrutiny of student <b>texts</b> <b>extracted</b> <b>from</b> the Corpus del Lenguaje Académico en Español (or CLAE: <www.lenguajeacademico.info>) documents positive trends in the acquisition of ideational grammatical metaphors both in the monolingual, Spanish-only university setting of Mexico, and in the Spanish-English bilingual context of California. In this analysis, I propose that, regardless of the participants’ native language(s), learners of Spanish undergo parallel developmental stages within Halliday’s model of language acquisition at the advanced level.|$|E
40|$|International audienceThis paper {{presents}} {{results of}} dependency parsing of Old French, a language which is poorly standardized at the lexical level, and which displays a relatively free word order. The work {{is carried out}} on five distinct sample <b>texts</b> <b>extracted</b> <b>from</b> the dependency treebank Syntactic Reference Corpus of Medieval French (SRCMF). Following Achim Stein's previous work, we have trained the Mate parser on each sub-corpus and cross-validated the results. We show that the parsing efficiency is diminished by the greater lexical variation of Old French compared to parse results on modern French. In order to improve {{the result of the}} POS tagging step in the parsing process, we applied a pre-treatment to the data, comparing two distinct strategies: one using a slightly post-treated version of the TreeTagger trained on Old French by Stein, and a CRF trained on the texts, enriched with external resources. The CRF version outperforms every other approach...|$|E
40|$|Introduction à un texte extrait du Kitâb al-‘Ibar, Discours sur l’Histoire Universelle d’Abd-ar-Rahmân Ibn Khaldoun (1332 - 1406), plus précisément du Livre I, La Muqaddima. Ibn Khaldoun and the {{analysis}} of power : the concept of jâhIntroduction to an Abd-ar-Rahmân Ibn Khaldoun’s <b>text,</b> <b>extract</b> <b>from</b> Kitâb al-‘Ibar, Discours sur l’Histoire Universelle, precisely from Book I, The Muqaddima. Ibn Jaldún y el análisis del poder : el concepto jâhIntroducción a un texto contenido en el Kitâb al-‘Ibar, Discurso sobre Historia Universal de Abd ar-Rahâman Ibn Jaldún (1332 - 1406) en especial el Libro I, la Muqaddima...|$|R
40|$|This paper {{describes}} {{the building of}} a digital library collection of historic newspapers. The newspapers (Niupepa in Maori), which were published in New Zealand during the period 1842 to 1933, form a unique historical record of the Maori language, and of events from an historical perspective. Images of these newspapers have been converted to digital form, electronic <b>text</b> <b>extracted</b> <b>from</b> these, and the collection is now being made available over the Internet {{as a part of the}} New Zealand Digital Library (NZDL) project at the University of Waikato...|$|R
5000|$|This work takes {{approximately}} {{two minutes to}} perform. It is scored for a mixed choir which should consist of sopranos, altos, and baritones. The <b>text</b> is <b>extracted</b> <b>from</b> a Hungarian traditional poem, which is as follows: ...|$|R
