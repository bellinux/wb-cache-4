78|868|Public
50|$|Testing {{frameworks}} may accept unit <b>test</b> <b>output</b> in the language-agnostic Test Anything Protocol {{created in}} 1987.|$|E
50|$|In {{supervised}} learning models, there are tests {{that are needed}} to pass to reduce mistakes. Usually, when mistakes are encountered i.e. <b>test</b> <b>output</b> does not match test input, the algorithms use back propagation to fix mistakes. Whereas in un{{supervised learning}} models, the input is classified based on which problems need to be resolved.|$|E
50|$|Straightforward {{application}} of scan techniques {{can result in}} large vector sets with corresponding long tester time and memory requirements. Test compression techniques address this problem, by decompressing the scan input on chip and compressing the <b>test</b> <b>output.</b> Large gains are possible since any particular test vector usually only needs to set and/or examine {{a small fraction of}} the scan chain bits.|$|E
40|$|Background: Recent {{advances}} in experimental and computational technologies have fueled {{the development of}} many sophisticated bioinformatics programs. The correctness of such programs is crucial as incorrectly computed results may lead to wrong biological conclusion or misguide downstream experimentation. Common software testing procedures involve executing the target program {{with a set of}} test inputs and then verifying the correctness of the <b>test</b> <b>outputs.</b> However, due to the complexity of many bioinformatics programs, {{it is often difficult to}} verify the correctness of the <b>test</b> <b>outputs.</b> Therefore our ability to perform systematic software testing is greatly hindered...|$|R
50|$|Initial {{releases}} used blue, orange, {{white and}} black palettes. This was intentional - in a time before cheap high-quality video monitors, Commodore <b>tested</b> <b>output</b> on the worst televisions they could find, {{with the goal of}} obtaining the best possible contrast under these worst-case conditions.|$|R
30|$|The {{standard}} belief propagation (BP) decoding algorithm {{consists of}} initialization, check-node updating, symbol-node updating, stopping criterion <b>test,</b> and <b>output</b> steps [20]. In the proposed decoding algorithms, the initialization, stopping criterion <b>test,</b> and <b>output</b> steps {{remain the same}} as that in the standard BP algorithm, and therefore omitted here.|$|R
50|$|Random {{testing is}} a black-box {{software}} testing technique where programs are tested by generating random, independent inputs. Results of the output are compared against software specifications {{to verify that}} the <b>test</b> <b>output</b> is pass or fail. In case of absence of specifications the exceptions of the language are used which means if an exception arises during test execution then it means there is a fault in the program.|$|E
50|$|The single {{results are}} then {{assessed}} by a Naive Bayes classifier which decides {{whether or not}} their combined effect might be deleterious for the protein. The 'raw' accuracy of MutationTaster is about 90%, with the inclusion of knowledge about common (harmless) polymorphisms and known disease mutations, the actual rate of correct classifications is much higher. The <b>test</b> <b>output</b> explains if the alteration is a known or predicted harmless or disease-causing mutation and gives detailed information about the mutation.|$|E
50|$|The test {{statistic}} for these estimates is denoted by epsilon (ε) {{and can be}} found on Mauchly’s <b>test</b> <b>output</b> in SPSS. Epsilon provides a measure of departure from sphericity. By evaluating epsilon, we can determine the degree to which sphericity has been violated. If the variances of differences between all possible pairs of groups are equal and sphericity is exactly met, then epsilon will be exactly 1, indicating no departure from sphericity. If the variances of differences between all possible pairs of groups are unequal and sphericity is violated, epsilon will be below 1. The further epsilon is from 1, the worse the violation.|$|E
50|$|In the example, a NAND gate {{has been}} shown, {{the set of}} all input values that can <b>test</b> <b>output's</b> SA0 is {00,01,10}. the set of all input values that can check first input's SA1 is {01}. In this case, output SA0 fault is {{dominant}} and can be removed from fault list.|$|R
40|$|ABSTRACT: The {{effects of}} {{long-term}} use and of cleaning on {{the output of}} 30 specimens of DeVilblss 646 nebulizers were investigated {{in order to assess}} their influence on outcome and interpretation of inhalation provocation <b>tests.</b> <b>Output</b> was assessed In a standardized manner based on weight loss on four occasions one year apart...|$|R
25|$|A {{majority}} of {{waste water treatment}} plants (WWTPs) that have been <b>tested</b> <b>output</b> more PFOA than is input, and this increased output {{has been attributed to}} the biodegradation of fluorotelomer alcohols. A current PFOA precursor concern are fluorotelomer-based polymers; fluorotelomer alcohols attached to hydrocarbon backbones via ester linkages may detach and be free to biodegrade to PFOA.|$|R
50|$|Engineers apply {{techniques}} of engineering analysis in testing, production, or maintenance. Analytical engineers may supervise production in factories and elsewhere, determine {{the causes of}} a process failure, and <b>test</b> <b>output</b> to maintain quality. They also estimate the time and cost required to complete projects. Supervisory engineers are responsible for major components or entire projects. Engineering analysis involves the application of scientific analytic principles and processes to reveal the properties and state of the system, device or mechanism under study. Engineering analysis proceeds by separating the engineering design into the mechanisms of operation or failure, analyzing or estimating each component of the operation or failure mechanism in isolation, and recombining the components. They may analyze risk.|$|E
40|$|This article {{presents}} {{a technique that}} enables online testing of sensors through the superposition of the test stimulus onto the measurand. Perturbations due to the surrounding environment can very often introduce fluctuations in the <b>test</b> <b>output</b> creating a major concern {{for this type of}} sensor testing. In this paper, a signal processing technique is proposed where the test stimulus is encoded by a pseudo-random sequence {{in order to reduce the}} <b>test</b> <b>output</b> fluctuations. The trade-off between the level of rejection of a perturbation and the overall test time is studied. In the case of the MEMS accelerometer considered in this paper, it is theoretically demonstrated that the rejection is more than 20 dB for a test time of 2. 55 s. Furthermore, excessively strong perturbations can be monitored so that the test status is updated only if the accuracy of the test signal permits so. The technique has been implemented on a demonstration board and validated on a vibration platform...|$|E
3000|$|... range {{measures}} were recorded for {{each pair of}} connected nodes (i, j) [11]. The Anderson-Darling test, which can be consulted in Appendix 1 and particularized to our application, is a detector to assess whether the set of measurements from i to j follows a normal distribution with unknown mean and variances or not. Let us denote {{the probability that the}} <b>test</b> <b>output</b> is affirmative as [...]...|$|E
5000|$|Minimal {{steps that}} can be {{undertaken}} for purposes of testing or benchmarking are called [...] "tests" [...] in Inquisitor and are implemented as simple Unix shell scripts that run other (binary) programs and collects their results. In its simplest form, <b>test</b> <b>outputs</b> only binary result: success or failure, but more advanced API is supplied for benchmarks that output results.|$|R
5000|$|Output Distinguishability: It must be {{possible}} to distinguish which processing function was invoked from its output value alone, for all memory-input pairs. This ensures that the state machine can be decoupled from the processing functions. To ensure output distinguishability, the codomain of a function φ may be extended with special <b>test</b> <b>outputs</b> that are only relevant during testing.|$|R
50|$|On June 14, 2013, Ford Motor Company {{issued a}} press release {{detailing}} their robotic durability testing program. Each new model that Ford releases must first go through extensive durability and endurance testing {{to ensure that the}} vehicle meets Ford's safety and quality standards. Unfortunately, some of the testing environments were creating health concerns for human test drivers, causing abbreviated shifts and slowdowns in <b>testing</b> <b>output.</b>|$|R
40|$|A {{number of}} authors {{have looked at}} the problem of {{deriving}} a checking experiment from a nondeterministic finite state machine that models the required behaviour of a system. We show that these methods can be extended if it is known that the implementation is equivalent to some (unknown) deterministic finite state machine. When testing a deterministic implementation, the <b>test</b> <b>output</b> provides information about the implementation under test and can thus guide future testing. The use of an adaptive test process is thus proposed...|$|E
40|$|This thesis {{deals with}} the {{knowledge}} testing of the cell biology at pupils in 8 th classes and of tercia lower secondary schools {{by means of the}} didactic <b>test.</b> <b>Output</b> knowledge of natural history was tested with 200 students (100 boys and 100 girls) in Příbram. The respondents from secondary school showed better knowledge than pupils of the natural history of the 8 th classes of the primary school. Results evaluation is presented in words and also illustrated by tables and graphs...|$|E
40|$|FCTESTNET (Fuel Cell Testing and Standardization Network) is {{an ongoing}} European network project within {{framework}} program 5. It is a three-year project that commenced 2003, with 55 partners from European research centers, universities, and industry, working in the fuel cell field. The main objective of FCTESTNET is to promote the harmonization of testing procedures and methodologies within the European Union. The lack of standardized test methods for fuel cell technology is a fact. The development of standardized test methods {{is very important for}} the commercialization of the fuel cell technology. Standardized test methods {{are one of the most}} important instruments in the quality management work of any industrial process. The players that have a common interest to promote and develop harmonized test methods for fuel cell technology are - Standardization bodies (IEC and ISO) - Fuel cell manufacturing industry (type testing and routine testing) - OEMs (acceptance testing) - Research institutes and universities (R&D) The current work presents one of the core results from the FCTESTNET project, namely a proposal of a harmonized testing format for fuel cell techuology. The harmonized testing format has been developed based on a testing model that was proposed in the initial phase of FCTESTNET. The testing model describes the common process steps in testing and has been a valuable tool to communicate testing activities and develop test format within the network. The testing model describes testing in general and fuel cell testing in particular. It is a three-step model. The first step is the planning step and comprises the listing of standardized test methods and other references that are required for the execution of any specific testing activity. The second step of the testing model is the testing execution, which is where the actual testing is carried out. The result of the testing execution is here referred to as <b>test</b> <b>output</b> data or <b>test</b> <b>output.</b> The <b>test</b> <b>output</b> is analysed and compared with input data from the planning step and finally reported in the third step, that is the evaluation step. Some examples of specific test inputs, in the context of fuel cell testing, are temperature, vibration, fuel flow, rain, etc. Examples of specific test outputs are current, voltage, gas emissions, heat, degradation, etc. In professional testing, the internal function of the test object is of secondary importance. The object is to be treated as a "blackbox". It is the <b>test</b> <b>output</b> and the test result that are of primary importance. Based on terminology originating from the testing madel,such as test object, test inputs, test outputs, etc, a harmonized testing format has been developed and proposed. The key terms in the harmonized testing format are test programme and test module. The test programme is defined as a programme comprising two or more test modules. A test module is a test method defined as the variation of one single test input for example the testing of power output as function of ambient temperature. Furthermore, a test module comprises the objectives, the scope, the test input varied, the test outputs tested, test object class (fuel cell, fuel cell stack or fuel cell system), test procedure, test report, etc. JRC. F. 2 -Cleaner energ...|$|E
30|$|The Friedman rank sum <b>test</b> <b>outputs</b> a p-value of 0.0001136 which {{reject the}} null {{hypothesis}} {{that there is no}} significant difference among these models and a post-hoc Nemenyi test is applied. Using RRotSF (A) as the control, we obtain the p-values of Nemenyi test for different pairs: p_BA= 0.35512, p_CA= 0.04505, p_DA= 0.00184, p_EA= 0.61393 and p_FA= 0.00022. It can be seen that there exist significant differences between RRotSF and RSFs, Cox-Lasso or CockTail.|$|R
40|$|The Multiple-breath washout (MBW) and Forced Oscillation Technique (FOT) {{are both}} {{experiencing}} increased uptake as clinical measures of lung function and airway constriction. However, {{due to the}} complex nature of <b>test</b> <b>outputs,</b> there is still uncertainty about exactly how test indices respond to specific types of bronchoconstriction. Through the analysis of hundreds of bronchoconstriction scenarios, we investigated the sensitivity of MBW and FOT indices {{to the degree of}} regionalisation of airway constriction...|$|R
50|$|Many digital designs, {{including}} those of ICs, are simulated to detect defects before the unit is constructed. The simulation usually provides logic analysis displays. Often, complex discrete logic is verified by simulating inputs and <b>testing</b> <b>outputs</b> using boundary scan. Logic analyzers can uncover hardware defects that are not found in simulation. These problems are typically too difficult to model in simulation, or too time consuming to simulate and often cross multiple clock domains.|$|R
30|$|We {{begin by}} {{covering}} {{a member of}} the most naïve class of algorithms, represented by Algorithm 1. This algorithm is worth studying for three reasons. First, this algorithm is trivially generalized to any value of n by introducing an additional loop for each additional vertex and accumulating corresponding information about the new vertex pairings that become possible. Second, this algorithm most transparently describes the goal of the computation and is thus instructive for understanding the nature of VCP vectors. Third, for moderate values of n, the clarity of these algorithms allows for the production of <b>test</b> <b>output</b> with which to write more sophisticated algorithms.|$|E
40|$|It {{is often}} {{difficult}} to verify the solutions of computationally intensive mathematical optimization problems. Metamorphic testing is a technique to verify software <b>test</b> <b>output</b> even when a complete testing oracle is nor present. We apply metamorphic testing to a classic optimization problem, the quadratic assignment problem (QAP). A number of metamorphic relalions for the QAP are described in detail, and their effectiveness in "killing" mutated versions of an exact QAP solver is compared. We show that metamorphic testing can be effectively applied to the QAP {{in the absence of an}} oracle, and discuss the implications for the testing of solvers for other hard optimization problems...|$|E
40|$|In this paper, {{we address}} {{the task of}} active {{learning}} for linear regression models in collaborative settings. The goal of active learning is to select training points that would allow accurate prediction of <b>test</b> <b>output</b> values. We propose a new active learning criterion that is aimed at directly improving {{the accuracy of the}} output value estimation by analyzing the effect of the new training points on the estimates of the output values. The advantages of the proposed method are highlighted in collaborative settings – where most of the data points are missing, and the number of training data points is much smaller than the number of the parameters of the model. ...|$|E
30|$|While in the {{previous}} section we discussed simple decoders for the setting where Θ⃗ is completely known to the decoder, let us now consider the setting which is more common in fingerprinting, where the attack strategy is not assumed known to the decoder. This setting may partially apply to group testing as well (where there may be some unpredictable noise on the <b>test</b> <b>outputs),</b> but the main focus of this section is the uninformed fingerprinting game.|$|R
40|$|In many {{security}} and healthcare systems {{a sequence of}} features/sensors/tests are used for detection and diagnosis. Each <b>test</b> <b>outputs</b> a prediction of the latent state, and carries with it inherent costs. Our objective is to learn strategies for selecting tests to optimize accuracy & costs. Unfortunately it is often impossible to acquire in-situ ground truth annotations and {{we are left with}} the problem of unsupervised sensor selection (USS). We pose USS as a version of stochastic partial monitoring problem with an unusual reward structure (even noisy annotations are unavailable). Unsurprisingly no learner can achieve sublinear regret without further assumptions. To this end we propose the notion of weak-dominance. This is a condition on the joint probability distribution of <b>test</b> <b>outputs</b> and latent state and says that whenever a test is accurate on an example, a later test in the sequence is likely to be accurate as well. We empirically verify that weak dominance holds on real datasets and prove that it is a maximal condition for achieving sublinear regret. We reduce USS to a special case of multi-armed bandit problem with side information and develop polynomial time algorithms that achieve sublinear regret...|$|R
40|$|Regression {{testing is}} used by {{software}} developers to ensure that program modifications have not negatively impacted the correctness of code. While regression testing has been successfully applied in many domains, programs such as web applications, XML processors, and compilers remain expensive to test because harmless program evolutions make the tests appear to fail: in our experiments 82 % of <b>test</b> case <b>output</b> differences are false positives. We present an automated tool that measures syntactic differences in the tree-structured output of such programs {{to reduce the number}} of false positives in, and thus the cost of, regression testing. We model <b>test</b> case <b>outputs</b> that merit human inspection through a set of structural and domainspecific features. We evaluate the performance of our technique on over 20, 000 <b>test</b> case <b>output</b> comparisons, and find that we are three times as accurate as a naive comparator. 1...|$|R
40|$|The term statistical testing is {{used when}} {{statistics}} {{is applied to}} software testing. Statistics provides sampling theory, a sound theoretical foundation for statistical testing. However, two difficult and important issues must be addressed in statistical testing. The first issue is determining an accurate operational profile. Statistical testing of a software component from a users point of view depends largely on {{the manner in which}} the component is used. Characterisation of the population of expected use is referred to as an operational profile. An operational profile is a set of input events and their associated probabilities of occurrence expected in actual operation. The test cases that are executed during a statistical test are a sample from the operational profile. As such, accurate operational profiles are a critical part of statistical testing. Determining an operational profile for the generation of test cases that are representative of actual usage is still a difficult issue despite the considerable research in this area in recent years. Developing an accurate operational profile for software is difficult in general and it is very difficult for many software components because it requires anticipating the future use of the component. The usage behaviour is typically modelled by either Markov models or finite state machines. Previous work has focused on exploring the occurrence of operations and has ignored parameters for operations. This thesis presents a systematic method for deriving operational profiles for software components that uses probabilistic statecharts to model operational profiles and that addresses the issue of parameters for operations. The second issue is development of a test oracle for output evaluation. <b>Test</b> <b>output</b> evaluation is also a difficult and important problem for statistical testing. Most of the potential benefits of testing will be lost if the success or failure of test cases is not assessed. An expected result is needed for each test case to check the <b>test</b> <b>output.</b> The mechanism used for <b>test</b> <b>output</b> evaluation is called a test oracle. A test oracle is an essential part of statistical testing, because a large number of test cases is required to represent the operational usage and the behaviour must be checked for every test case. Test result evaluation using a test oracle is widely acknowledged in the software testing literature as a critical aspect of the testing process. Several methods for developing test oracles, such as those using specifications and documentation, have been reported. Unfortunately development and maintenance of such resources may require considerable effort. A limitation in using such a resource is that the test oracle is only as good as the resource from which it was derived. To address these issues, this thesis presents a technique to develop a test oracle that uses the component to check its own behaviour for <b>test</b> <b>output</b> evaluation. While a number of proposals for statistical testing of software have been made, the execution of test cases and <b>test</b> <b>output</b> evaluation are often not addressed in these proposals. This thesis presents a conceptual framework for statistical testing of software components that supports both test case execution and output evaluation. The framework proposed in this thesis is supported by a prototype tool for test case generation, test case execution and output evaluation. The tool supports a wide range of operational profile approaches for test case generation and a variety of test oracles for output evaluation. This thesis demonstrates the practical viability, flexibility and scalability of the framework and tool support by applying them on several case studies, including a third-party component. Experience with the framework indicates that it can be used successfully for small to medium-sized components, including third-party components such as COTS components. The overall effectiveness of the statistical testing process depends on both the accuracy of the operational profile and the effectiveness of the test oracle to detect and report the errors encountered during testing. This thesis presents an empirical evaluation of different types of operational profiles to determine how accurately the test cases generated from the operational profiles represent the actual usage of the component and different types of test oracles to determine their fault-detection ability...|$|E
3000|$|Research on {{the group}} testing problem started much longer ago, and already in 1985, exact asymptotics on the code length for {{probabilistic}} schemes were derived as ℓ∼ c [...] _ 2 n [18], whereas deterministic schemes require a code length of ℓ∝ c^ 2 n [19, 20]. Later work focused on slight variations of the classical model such as noisy group testing, where a positive result may not always correspond {{to the presence of}} a defective item due to “noise” in the <b>test</b> <b>output</b> [21 – 24]. For noisy group testing, exact asymptotics on the capacities (with leading constants) are yet unknown, and so it is not known whether existing constructions are optimal.|$|E
40|$|Abstract. This paper {{proposes a}} {{conceptual}} framework for the reliability assessment of software components that incorporates test case execution and output evaluation. Determining an operational profile and <b>test</b> <b>output</b> evaluation are two difficult and important problems {{that must be addressed}} in such a framework. Determining an operational profile is difficult, because it requires anticipating the future use of the component. An expected result is needed for each test case to evaluate the test result and a test oracle is used to generate these expected results. The framework combines statistical testing and test oracles implemented as self-checking versions of the implementations. The framework is illustrated using two examples that were chosen to identify the issues that must be addressed to provide tool support for the framework. ...|$|E
3000|$|... is set {{larger than}} the {{possible}} maximal value of the transmitter IFFT size N. Then, we <b>test</b> the <b>output</b> of the FFT for Gaussianity. If strong Gaussianity is shown, which means [...]...|$|R
40|$|Abstract—The {{uniqueness}} (or otherwise) of <b>test</b> <b>outputs</b> {{ought to}} have a bearing on test effectiveness, yet it has not previously been studied. In this paper we introduce a novel test suite adequacy criterion based on output uniqueness. We propose 4 definitions of output uniqueness with varying degrees of strictness. We present a preliminary evaluation for web ap-plication testing that confirms that output uniqueness enhances fault-finding effectiveness. The approach outperforms random augmentation in fault finding ability by an overall average of 280 % in 5 medium sized, real world web applications. Keywords-SBSE; HTML output; Web applications I...|$|R
40|$|In the paper, the {{possibilities}} of application of switched reluctance generators in modern variable-speed drives were discussed. The process of mechanical energy conversion into electric energy was discussed. Based on simulation and laboratory <b>tests,</b> <b>output</b> power profiles, efficiency profiles and profiles of ratio of output power to phase current were determined in the single-pulse mode. The authors showed that proper selection of control parameters allows {{the operation of the}} SRG with maximum power, maximum efficiency or maximum ratio of output power to phase current. Finally, conclusions concerning advantages of using SRGs in variable-speed applications were drawn...|$|R
