2|18|Public
25|$|The first {{match against}} the West Indies, Broad took 2–67 {{in their first}} innings to help {{restrict}} them to 295. However, in the second innings he could only manage to take one wicket as the West Indies held on for a draw. In the second <b>Test</b> <b>ok</b> 4–61 in West Indies first innings to help out England in a strong position. He took another wicket in the second innings as England forced a result to go 1–0 up in the series. In the first Test Broad took 1–31 in West Indies first innings to help England into a lead. However, England collapsed in their second innings and Broad himself was out for a duck. He took 1–29 in the West Indies second innings but it wasn't enough to prevent a five wicket defeat as the West Indies levelled the series at 1–1.|$|E
5000|$|He {{serves as}} a committer to KDE and GNOME, where he helps to {{translate}} [...]po files and fixes bugs related to Chinese. He is a contributor to pyDict, OpenH323, Asterisk, GStreamer etc. He works on a way to leverage the ASUS Eee PC {{with the power of}} the free software community and aims to provide a complete solution for Android on x86 platform. The Eee PC, VirtualBox, and QEMU are <b>tested</b> <b>OK.</b>|$|R
40|$|This paper {{describes}} {{the implementation of}} testing system for control panel of medium voltage switchgear using MATLAB and PIC. The system checks ‘Normally closed’ and ‘Normally open’ status of pin pairs of control panel mentioned in the wiring diagram. The input to MATLAB is wiring diagram {{which is in the}} jpeg format, this jpeg image is used for getting the information, like which pin pairs are ‘NO’ which are ‘NC’ and the components connected between those pins. After finding such information from the jpef image, it is save in text file for further reference. The external hardware is needed for actual connection to socket of control panel and it is also used to sense the status of pins. The necessary information is transferred to external hardware by serial communication which is controlled by MATLAB. This external hardware can be any microcontroller. Here PIC 18 f 877 a is used as external hardware. The PIC shows the result on LCD display connected to it. The results are also transferred to MATLAB by PIC so that MATLAB can print <b>tested</b> <b>ok</b> certificate for the control panel...|$|R
25|$|By comparison, {{the most}} {{efficient}} randomized primality test for general integers, the Miller–Rabin primality <b>test,</b> requires <b>O(k</b> n2 log n log log n) bit operations using FFT multiplication for an n-digit number, where k {{is the number of}} iterations and is related to the error rate. For constant k, this is in the same complexity class as the Lucas-Lehmer test. In practice however, the cost of doing many iterations and other differences leads to worse performance for Miller–Rabin. The most efficient deterministic primality test for any n-digit number, the AKS primality test, requires Õ(n6) bit operations in its best known variant and is dramatically slower in practice.|$|R
40|$|The tests {{reported}} {{were part}} of the DOE Geothermal Reservoir Well Stimulation Program. This East Mesa (Imperial Valley, CA) well was successfully stimulated with two fracture treatments, a dendritic fracture and a planar fracture. The natural flow production of the well increased 114 percent, to 197, 900 lb/hr. These tests were among the few successful attempts of this program to increase flow from geothermal production wells. The general belief is that these <b>tests</b> worked <b>OK</b> primarily because the formation was sedimentary rock (similar to rock in most oil and gas wells that have been stimulated successfully. Similar tests in geothermal hard rock reservoirs did not work very well. (DJE 2005...|$|R
50|$|The {{test machine}} {{consists}} of a standardized bearing race mounted on a tapered arbor rotating at high speed. The race is brought into contact with a square steel test block under a constant load. The contact area is flooded with the lubricant or grease being <b>tested.</b> The Timken <b>OK</b> Load is the highest standard load at which the spinning bearing race produces no scouring mark on the test block, but only a uniform wear scar.|$|R
40|$|We {{study the}} problem of testing {{isomorphism}} (equivalence up to relabeling of the input variables) between Boolean functions. We prove that: • For most functions f: { 0, 1 } n → { 0, 1 }, the query complexity of testing isomorphism to f is Ω(n). Moreover, the query complexity of testing isomorphism to most k-juntas f: { 0, 1 } n → { 0, 1 } is Ω(k). • Isomorphism to any k-junta f: { 0, 1 } n → { 0, 1 } can be <b>tested</b> with <b>O(k</b> log k) queries. • For some k-juntas f: { 0, 1 } n → { 0, 1 }, testing isomorphism to f with one-sided error requires Ω(k log(n/k)) queries. In particular, testing if f: { 0, 1 } n → { 0, 1 } is a k-parity with one-sided error requires Ω(k log(n/k)) queries. • The query complexity of testing isomorphism between two unknown functions f, g: { 0, 1 } n → { 0, 1 } is ˜ Θ(2 n/ 2). These bounds are tight up to logarithmic factors, and they significantly strengthen the bounds proved by Fischer et al. (FOCS 2002) and Blais and O’Donnell (CCC 2010) ...|$|R
40|$|Background To {{evaluate}} short-term (3 months) {{and long-term}} (3 years) accommodative changes produced by overnight orthokeratology (OK). Methods A prospective, longitudinal study on young adult subjects {{with low to}} moderate myopia was carried out. A total of 93 patients {{took part in the}} study. Out of these, 72 were enrolled into the short-term follow-up: 21 were on a control group, 26 on a Paragon CRT contact lenses group, and 25 on a Seefree contact lenses group. The other 21 patients were old CRT wearers on long-term follow-up. Accommodative function was assessed by means of negative and positive relative accommodation (NRA / PRA), monocular accommodative amplitude (MAA), accommodative lag, and monocular accommodative facility (MAF). These values were compared among the three short-term groups at the follow-up visit. The long- and short-term follow-up data was compared among the CRT groups. Results Subjective accommodative results did not suffer any statistically significant changes in any of the accommodative tests for any of the short-term groups when compared to baseline. There were no statistically significant differences between the three short-term groups at the follow-up visit. When comparing the short- and long-term groups, only the NRA showed a significant difference (p[*]=[*] 0. 0006) among all the accommodation <b>tests.</b> Conclusions <b>OK</b> does not induce changes in the ocular accommodative function for either short-term or long-term periods...|$|R
5000|$|These {{points are}} not {{specified}} completely arbitrarily. A cutscore {{should always be}} set with a legally defensible method, such as a modified Angoff procedure. Again, the indifference region represents the region of scores that the <b>test</b> designer is <b>OK</b> with going either way (pass or fail). The upper parameter p2 is conceptually the highest level that the test designer is willing to accept for a Fail (because everyone below it {{has a good chance}} of failing), and the lower parameter p1 is the lowest level that the test designer is willing to accept for a pass (because everyone above it has a decent chance of passing). While this definition may seem to be a relatively small burden, consider the high-stakes case of a licensing test for medical doctors: at just what point should we consider somebody to be at one of these two levels? ...|$|R
40|$|Little {{is known}} about the lay public’s {{awareness}} and attitudes concerning genetic testing and what factors influence their perspectives. The existing literature focuses mainly on ethnic and socioeconomic differences; however, here we focus on how awareness and attitudes regarding genetic testing differ by geographical regions in the US. We compared awareness and attitudes concerning genetic testing for disease risk and ancestry among 452 adults (41 % Black and 67 % female) in four major US cities, Norman, OK; Cincinnati, OH; Harlem, NY; and Washington, DC; prior to their participation in genetic ancestry <b>testing.</b> The <b>OK</b> participants reported more detail about their personal ancestries (p =  0. 02) and valued ancestry testing over disease testing more than all other sites (p <  0. 01). The NY participants were more likely than other sites to seek genetic testing for disease (p =  0. 01) and to see benefit in finding out more about one’s ancestry (p =  0. 02), while the DC participants reported reading and hearing more about genetic testing for African ancestry than all other sites (p <  0. 01). These site differences were not better accounted for by sex, age, education, self-reported ethnicity, religion, or previous experience with genetic testing/counseling. Regional differences in awareness and attitudes transcend traditional demographic predictors, such as ethnicity, age and education. Local sociocultural factors, more than ethnicity and socioeconomic status, may influence the public’s awareness and belief systems, particularly with respect to genetics...|$|R
40|$|Let f: {− 1, 1 }n → R {{be a real}} {{function}} on the hypercube, {{given by}} its discrete Fourier expansion, or, equivalently, represented as a multilinear polynomial. We {{say that it is}} Boolean if its image is in {− 1, 1 }. We show that every function on the hypercube with a sparse Fourier expansion must either be Boolean or far from Boolean. In particular, we show that a multilinear polynomial with at most k terms must either be Boolean, or output values different than − 1 or 1 for a fraction of at least 2 /(k + 2) 2 of its domain. It follows that given oracle access to f, together with the guarantee that its representation as a multilinear polynomial has at most k terms, one can <b>test</b> Booleanity using <b>O(k</b> 2) queries. We show an Ω(k) queries lower bound for this problem. Our proof crucially uses Hirschman’s entropic version of Heisenberg’s uncertainty principle. 1...|$|R
40|$|Nonpathogenic, {{intestinal}} Escherichia coli (commensal E. coli) {{supports the}} physiological intestinal {{balance of the}} host, whereas pathogenic E. coli with typical virulence factor gene profiles can cause severe outbreaks of diarrhea. In many reports, E. coli isolates from diarrheic animals were classified as putative pathogens. Here we describe a broad variety of virulence gene-positive E. coli isolates from swine with no clinical signs of intestinal disease. The isolation of E. coli from 34 pigs from the same population and the testing of 331 isolates for genes encoding heat-stable enterotoxins I and II, heat-labile enterotoxin I, Shiga toxin 2 e, and F 4, F 5, F 6, F 18, and F 41 fimbriae revealed that 68. 6 % of the isolates were positive {{for at least one}} virulence gene, with a total of 24 different virulence factor gene profiles, implying high rates of horizontal gene transfer in this E. coli population. Additionally, we traced the occurrence of hemolytic E. coli over a period of 1 year in this same pig population. Hemolytic isolates were differentiated into seven clones; only three were found to harbor virulence genes. Hemolytic E. coli isolates without virulence genes or with only the fedA gene were found to be nontypeable by slide agglutination <b>tests</b> with <b>OK</b> antisera intended for screening live cultures against common pathogenic E. coli serogroups. The results appear to indicate that virulence gene-carrying E. coli strains are a normal part of intestinal bacterial populations and that high numbers of E. coli cells harboring virulence genes and/or with hemolytic activity do not necessarily correlate with disease...|$|R
40|$|Abstract: Let f: {− 1, 1 }n → R {{be a real}} {{function}} on the hypercube, {{given by}} its discrete Fourier expansion, or, equivalently, represented as a multilinear polynomial. We {{say that it is}} Boolean if its image is in {− 1, 1 }. We show that every function on the hypercube with a sparse Fourier expansion must either be Boolean or far from Boolean. In particular, we show that a multilinear polynomial with at most k terms must either be Boolean, or output values different than − 1 or 1 for a fraction of at least 2 /(k+ 2) 2 of its domain. It follows that given oracle access to f, together with the guarantee that its representation as a multilinear polynomial has at most k terms, one can <b>test</b> Booleanity using <b>O(k</b> 2) queries. We show an Ω(k) queries lower bound for this problem. Our proof crucially uses Hirschman’s entropic version of Heisenberg’s uncertainty principle. Key words and phrases: discrete Fourier analysis, property testing, Boolean functions...|$|R
40|$|Let f: {− 1, 1 } n → R {{be a real}} {{function}} on the hypercube, {{given by}} its discrete Fourier expansion, or, equivalently, represented as a multilinear polynomial. We {{say that it is}} Boolean if its image is in {− 1, 1 }. We show that every function on the hypercube with a sparse Fourier expansion must either be Boolean or far from Boolean. In particular, we show that a multilinear polynomial with at most k terms must either be Boolean, or output values different than − 1 or 1 for a fraction of at least 2 /(k + 2) 2 of its domain. It follows that given black box access to f, together with the guarantee that its representation as a multilinear polynomial has at most k terms, one can <b>test</b> Booleanity using <b>O(k</b> 2) queries. We show an Ω(k) queries lower bound for this problem. We also consider the problem of deciding if a function is Boolean, given its explicit representation as a k term multilinear polynomial. The naïve approach of evaluating it at every input has O(kn 2 n) time complexity. For large k (i. e, exponential) we present a simple randomized O(kn √ 2 n) algorithm. For small k we show how the problem can be solved deterministically in O(k 3 n). Our proofs crucially use Hirschman’s entropic version of Heisenberg’s uncertainty principle...|$|R
40|$|This report {{summarizes}} {{technical progress}} over {{the fourth year}} of the ''Optical Fiber Sensor Technologies for Efficient and Economical Oil Recovery'' program, funded by the Federal Energy Technology Center of the U. S. Department of Energy, and performed by the Center for Photonics Technology of the Bradley Department of Electrical and Computer Engineering at Virginia Tech. During the reporting period, research efforts under the program were focused on the development and evaluation of the fiber optic flow sensor system, and field <b>testing</b> in Tulsa, <b>OK</b> and the second field test of the pressure and temperature sensors in Coalinga, CA. The feasibility of a self-compensating fiber optic flow sensor based on a cantilever beam and interferometer for real-time flow rate measurements in the fluid filled pipes of oil field was clearly demonstrated. In addition, field testing of the pressure and temperature sensors deployed downhole continued. These accomplishments are summarized here: (1) Theoretical analysis and simulations were performed to ensure performance of the design. (2) The sensor fabrication and packaging techniques were investigated and improved. (3) Prototype flow sensors were fabricated based on the fabrication experience of hundreds of test sensors. (4) A lab-scale flow testing system was constructed and used for sensor evaluation. (5) Field-testing was performed in both the indoor and outdoor flow testing facility at the University of Tulsa, <b>OK.</b> (6) <b>Testing</b> of a multimode white light pressure and temperature sensor system continued at the oil site of Chevron/Texaco Company (Coalinga CA) ...|$|R
40|$|We study {{implementation}} {{details for}} dynamic programming over tree decompositions. Firstly, {{a fact that}} is overlooked in many papers and books on this subject {{is that it is}} not clear how to test adjacency between two vertices in time bounded by a function of k, where k is the width of the given tree decomposition. This is necessary to obtain linear time dynamic programming algorithms. We address this by giving a simple O(kn) time and space preprocessing procedure that enables adjacency <b>testing</b> in time <b>O(k),</b> where n is the number of vertices of the graph. Secondly, we show that a large class of NP-hard problems can be solved in time O(q k+ 1 n), where q k+ 1 is the natural size of the dynamic programming tables. The key improvement is that we avoid a polynomial factor in k. This holds for all problems that can be formulated as a Min Weight Homomorphism problem: given a (large) graph G on n vertices and a (small) graph H on q vertices, with integer vertex and edge weights, is there a homomorphism from G to H with total (vertex and edge image) weight at most M? This result implies e. g. O(2 k n) algorithms for Max Independent Set and Max Cut, and a O(q k+ 1 n) algorithm for q-Colorability. The table building techniques we develop are also useful for many other problems...|$|R
40|$|The National Oceanic and Atmospheric Administra-tion’s (NOAA) National Weather Service (NWS) has {{recently}} transitioned to ”storm-based ” warnings from county-based warnings. These warnings are increasingly used by graphical applications for television, the Inter-net, {{and cell phones}} to better communicate specific in-formation about hazardous weather. With the rapid up-dates in technology and communication, the NWS can continue to build upon the storm-based warnings to bet-ter communicate specifics in uncertainty, space, and time to advanced and special-need users. During the 6 week period of 27 April- 7 June 2008, the NOAA Hazardous Weather <b>Testbed</b> in Norman, <b>OK</b> hosted multiple visiting NWS and Environment Canada forecasters for the Experimental Warning Program. The forecasters {{had the opportunity to}} issue probabilistic guidance on several real-time severe weather events across the continental United States and an archive event from 13 August 2007 in northeast North Dakota. Each forecaster was asked to identify areas of a storm where a threat was possible, either at the current time or near future (less than 60 min) and determine a probability as-sociated with that threat (current and at a chosen future time). The project focused on three different threats: Tor-nado, Hail (greater than. 75 in), and Wind (greater than 50 kts). Probabilistic hazard forecasts made throughout the six week period and from the archive event will be compared to storm data as well as the high resolution data from the Severe Hazards Analysis and Verification Experiment (SHAVE) to determine skill and reliability of the forecasts and how this guidance should be updated for future use. In addition, feedback from visiting fore-casters concerning product use and workload as well as societal impacts of such products are discussed...|$|R
40|$|The {{fundamental}} task {{of group}} testing is to recover a small distinguished subset of items {{from a large}} population while efficiently reducing {{the total number of}} tests (measurements). The key contribution of this paper is in adopting a new information-theoretic perspective on group testing problems. We formulate the group testing problem as a channel coding/decoding problem and derive a single-letter characterization for the total number of tests used to identify the defective set. Although the focus of this paper is primarily on group testing, our main result is generally applicable to other compressive sensing models. The single letter characterization is shown to be order-wise tight for many interesting noisy group testing scenarios. Specifically, we consider an additive Bernoulli(q) noise model where we show that, for N items and K defectives, the number of <b>tests</b> T is <b>O(K</b> N/ 1 -q) for arbitrarily small average error probability and O(K^ 2 N/ 1 -q) for a worst case error criterion. We also consider dilution effects whereby a defective item in a positive pool might get diluted with probability u and potentially missed. In this case, it is shown that T is O(K N/(1 -u) ^ 2) and O(K^ 2 N/(1 -u) ^ 2) for the average and the worst case error criteria, respectively. Furthermore, our bounds allow us to verify existing known bounds for noiseless group testing including the deterministic noise-free case and approximate reconstruction with bounded distortion. Our proof of achievability is based on random coding and the analysis of a Maximum Likelihood Detector, and our information theoretic lower bound is based on Fano's inequality. Comment: In this revision: reorganized the paper, added citations to related work, and fixed some bug...|$|R

