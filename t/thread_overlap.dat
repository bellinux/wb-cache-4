1|30|Public
40|$|Several useful {{compiler}} {{and program}} transformation techniques for the superthreaded architectures [8] {{are presented in}} this paper. The superthreaded architecture adopts a thread pipelining execution model to facilitate runtime data dependence checking between threads, and to maximize <b>thread</b> <b>overlap</b> to enhance concurrency. In this paper, we present some important program transformation techniques to facilitate concurrent execution among threads, and to manage critical system resources such as the memory buffers effectively. We {{evaluate the effectiveness of}} those program transformation techniques by applying them manually on several benchmark programs, and using a trace-driven, cycle-by-cycle superthreaded processor simulator. The simulation results show that a superthreaded processor can achieve promising speedup for most of the benchmark programs. 1 Introduction Recently, a number of concurrent multithreaded execution models [5, 7, 9, 3, 2, 8] are proposed {{as an alternative to the}} c [...] ...|$|E
5000|$|In the C {{programming}} language, each thread {{has its own}} stack. However, {{a static}} variable is not kept on the stack; all threads share simultaneous access to it. If multiple <b>threads</b> <b>overlap</b> while running the same function, {{it is possible that}} a static variable might be changed by one thread while another is midway through checking it. This difficult-to-diagnose logic error, which may compile and run properly most of the time, is called a race condition. One common way to avoid this is to use another shared variable as a [...] "lock" [...] or [...] "mutex" [...] (from mutual exclusion).|$|R
5000|$|Layer 5: Programming Interfaces, {{consisting}} of Remote Procedure Call (RPC), Common File System (CFS), UNIX File System (UFS) and Continuous Media File System (CMFS). The Uthread (UNIX-like <b>thread)</b> component <b>overlaps</b> and interfaces with this layer and with Layer 6.|$|R
30|$|Su et al. {{proposed}} a parallel {{implementation of the}} AC algorithm on a multi-core processor [6]. They used a data parallelism technique to improve the performance. The parallel implementation divides the text into n parts, where n equals {{to the number of}} forked <b>threads.</b> The <b>overlap</b> concept was used to guarantee the accuracy of the search algorithm. The results of their parallel AC showed at least two times speedup over the serial AC.|$|R
50|$|The {{division}} between yarn and thread is somewhat arbitrary: crochet thread at its thickest {{is similar in}} diameter and behavior to fine cotton yarn. The largest sizes of <b>thread</b> crochet hooks <b>overlap</b> with the smallest sizes of yarn crochet hooks.|$|R
5000|$|... "Chuck Versus the Tango" [...] is {{the first}} episode in the series to feature the {{separate}} main and Buy More stories, which becomes a staple {{for the rest of}} the show, particularly in Season 2 where the two story <b>threads</b> have less <b>overlap.</b>|$|R
40|$|My {{research}} lies broadly in {{the areas}} of programming languages and verication, with the goal of building reliable soware systems. I am drawn to soware components that are usually characterized by “ugly ” or “subtle” code—places where clean code and condence of correctness {{take a back seat to}} performance. I aim to (1) discover new abstractions for cleanly expressing such code without compromising performance and (2) develop verication techniques to explain why subtle code works. For the past several years I have targeted concurrent programming, where multiple computations (<b>threads)</b> <b>overlap</b> in time. To write reliable concurrent code, a programmer must consider all of the possible interactions between threads whose relative timing is unpredictable. e traditional way to tame concurrency is to disallow it: “critical sections ” of code can be protected by locks, preventing interference from concurrent threads. But if parallelism is a goal—and it increasingly is—critical sections become critical bottlenecks that limit parallel speedup. Unfortunately, alternatives like lock-free synchronization are considered a “black art ” even among concurrency experts. My work focuses on identifying, harnessing, specifying and verifying abstractions in concurrent programming, from low-level systems code to application programs. For example, I have systematically studied lock-free algorithms, showing how to (1) construct them from abstract building blocks; (2...|$|R
40|$|This {{is a book}} of beginnings. It {{consists}} of twelve individual stories, {{each of which is}} re-begun multiple times, and a handful of beginnings that have no ties to anything that come before them or after. A number of the threads have beginnings told at different times from different perspectives; others begin again and again from the same perspective each time. A few of the <b>threads</b> <b>overlap</b> with one another; many remain distinct. The thesis explores {{in the way in which}} stories, ideas, and concepts change as we go about writing pieces of fiction. Those ideas and concepts merge and depart so that what starts as an individual story or concept feeds in to another, or what is part of a larger story leads off into a life of its own. The thesis also plays with the way a story begins. A story can begin anywhere, so what constitutes a beginning and how does a beginning influence the way we read or the way we write? How much is a story dependent upon a beginning? How does the beginning introduce us to a story and therefore color our perception of what the story will be? If the beginning changes, how does that affect the characters or the ideas? And, can a story be told through only beginnings? Do you in fact learn things about these characters? Do you come to know them and their desires? Finally, the thesis explores yearning and what happens when yearning becomes pathological [...] what effect that pathology has on the mental states of those yearning and on others...|$|R
30|$|Atomicity {{violation}} {{refers to}} the situation when the execution of two code blocks (sequences of statements protected by lock, transaction) in one <b>thread</b> is concurrently <b>overlapping</b> with the execution {{of one or more}} code blocks of other threads {{such a way that the}} result is inconsistent with any execution where the blocks of the first thread are executed without being overlapping with any other code block.|$|R
5000|$|The {{artist is}} best known for her light and shadow sculptures {{constructed}} from everyday objects. [...] Constellation Mana is from a series of portraits called [...] "Constellation". Each of the works in this series is created by winding a single black thread around galvanized brads on a white board. The dark areas are produced solely by densely wound and <b>overlapping</b> <b>thread.</b> [...] This technique is seen in the enlarged photograph of Constellation Mana.|$|R
40|$|We {{present a}} {{practical}} system to visualize large datasets interactively on commodity PCs. Interactive visualization has applications in many areas, including computeraided design, engineering, entertainment, and training. Traditionally, visualization of large datasets has required expensive high-end graphics workstations. Recently, with the exponential trend of higher performance and lower cost of PC graphics cards, inexpensive PCs are becoming an attractive alternative to high-end machines. But a barrier in exploiting this potential {{is the small}} memory size of typical PCs. Our system uses new out-of-core techniques to visualize datasets much larger than main memory. In a preprocessing phase, we build a hierarchical decomposition of the dataset using an octree, precompute coefficients used for visibility determination, and create levels of detail. At runtime, we use multiple <b>threads</b> to <b>overlap</b> visibility computation, cache management, and rasterization. The structure of the octree and the visibility coefficients are kept in main memory. The contents of the octree nodes are loaded on demand from disk into a cache. To find the visible set, we use a fast approximate algorithm followed by a hardware-assisted conservative algorithm. T...|$|R
40|$|This paper explores {{planning}} and design processes through a verbal and visual rhetoric approach by examining three case studies of train station area redevelopments in the Netherlands. The paper illustrates how these case study projects were conceived, constructed, transformed and communicated to the stakeholders through stories and pictures. Three threads are discerned, which run through the verbal and visual narratives employed in the case study projects. The first is a longing for identity {{and a return to}} the past. The second is a desire to project an image of progress and success. The third is a shift from grand to piecemeal planning. The three <b>threads</b> are <b>overlapping</b> but also contradictory. While some of the rhetoric appears to be post-rationalization, its employment had a strong ethical basis because, by densifying and revitalizing the areas in the vicinity of main train stations, the three projects sought to advance the public interest. While visually diverse and controversial, all three case study areas represented a response to contemporary problems, such as urban economic decline or automobile dependence...|$|R
5000|$|In {{style and}} plot structure, the comic often {{made use of}} <b>overlapping</b> story <b>threads.</b> According to Hama: [...] We’ve been {{following}} one basic storyline pretty much in the comic for fifty issues. It’s sort of like an extended soap opera, although I {{try to have a}} real solid resolution {{at the end of each}} book. But I like to keep some plot threads going. There's a sort of episodic quality to some of the earlier books, like one episode will last six issues. That will resolve completely, but two issues into it another thread may have started. At any given time there’s probably about three <b>overlapping</b> <b>threads.</b>|$|R
40|$|Chip multiprocessors (CMPs), or {{multi-core}} processors, {{have become}} a common way of reducing chip complexity and power consumption while maintaining high performance. Speculative CMPs use hardware to enforce dependence, allowing a parallelizing compiler to generate multithreaded code without needing to prove independence. In these systems, a sequential program is decomposed into threads to be executed in parallel; dependent threads cause performance degradation, but do not affect correctness. Thread decomposition attempts to reduce the run-time overheads of data dependence, thread misprediction, and load imbalance. Because these overheads depend on the runtimes of the threads that are being created by the decomposition, reducing the overheads while creating the threads is a circular problem. Static compile-time decomposition handles this problem by estimating the run times of the candidate threads, but {{is limited by the}} estimates 2 ̆ 7 inaccuracy. Dynamic execution-time decomposition in hardware has better run-time information, but is limited by the decomposition hardware 2 ̆ 7 s complexity and run-time overhead. We propose a third approach where a compiler instruments a profile run of the application to search through candidate threads and pick the best threads as the profile run executes. The resultant decomposition is compiled into the application so that a production run of the application has no instrumentation and does not incurany decomposition overhead. We avoid static decomposition 2 ̆ 7 s estimation accuracy problem by using actual profile-run execution times to pick threads, and we avoid dynamic decomposition 2 ̆ 7 s overhead by performing the decomposition at profile time. Because we allow candidate threads to span arbitrary sections of the application 2 ̆ 7 s call graph and loop nests, an exhaustive search of the decomposition space is prohibitive, even in profile runs. To address this issue, we make the key observation that the run-time overhead of a thread depends, to the first order, only on <b>threads</b> that <b>overlap</b> with the <b>thread</b> inexecution (e. g., in a four-core CMP, a given <b>thread</b> can <b>overlap</b> with at most three preceding and three following threads). This observation implies that a given thread affects only a few other threads, allowing pruning of the space. Using a CMP simulator, we achieve an average speedup of 3. 51 on four cores for five of the SPEC CFP 2000 benchmarks, which compares favorably to recent static techniques. We also discuss experiments with CINT 2000...|$|R
40|$|This paper {{proposes a}} dynamic cache {{partitioning}} method for simultaneous multi-threading systems. Unlike previous works, our method works for set-associative caches and at any partition granularity. Further, <b>threads</b> can have <b>overlapping</b> partitions in our method. The method collects the miss-rate characteristics of threads that are exe-cuting simultaneously at run-time, and dynamically partitions the cache among those threads. Trace-driven simulation results show a relative {{improvement in the}} L 2 hit-rate up to 40. 5 % over those generated by the standard least recently used replacement pol-icy. The partitioning also improves IPC up to 17 %. Our results show that smart cache management and scheduling is essential for SMT systems to achieve high performance. ...|$|R
40|$|This paper {{describes}} a pipeline for the acquisition and rendering of large real-world environments. In the acquisition phase, {{we use a}} laser rangefinder to capture the geometry of an environment, and a digital camera to capture its colors. In the rendering phase, we use a cluster of commodity PCs to render high-resolution images of the environment at interactive frame rates. In this paper, we describe in detail our scanning hardware, the tools we use to minimize the acquisition artifacts in the 3 D scans, the procedure to register the scans to each other, and how to map colors from a photograph to a scan. We also present a sequential, out-of-core rendering approach that uses multiple <b>threads</b> to <b>overlap</b> rendering, visibility computation, and disk operations. Finally, we show {{how to use the}} sequential rendering approach as a building block for a parallel rendering system that uses a cluster of PCs to drive a high-resolution, multi-projector display wall. Our acquisition approach allows us to capture environments that would be extremely difficult to model by hand, and our rendering approach allows us to use inexpensive PCs, instead of high-end graphics workstations, to visualize those environments at interactive frame rates...|$|R
40|$|We present iWalk, {{a system}} for {{interactive}} out-of-core rendering of large models on an inexpensive PC. The system uses a new outof -core preprocessing algorithm and a new multi-threaded out-ofcore rendering approach. The out-of-core preprocessing algorithm is incremental and fast, and it builds an on-disk hierarchical representation for a model larger than main memory. The out-of-core rendering approach uses multiple <b>threads</b> to <b>overlap</b> rendering, visibility computation, and disk operations. A rendering thread uses a from-point visibility algorithm to find the nodes of the model hierarchy that the user sees, and sends fetch requests to a geometry cache, which reads nodes from disk into memory. To avoid bursts of disk operations, a look-ahead thread guesses the nodes that the user may see next, and sends prefetch requests to the geometry cache. The system can run in approximate mode for interactive rendering, or in conservative mode for rendering with guaranteed accuracy. On a commodity PC, iWalk can preprocess a 13 -million-polygon model in 17 minutes, and then render it in approximate mode with 98 % accuracy at 9 frames per second. Thus, iWalk allows us to use an inexpensive PC to visualize models that would typically require expensive high-end graphics workstations or parallel machines...|$|R
50|$|Before {{the mid-nineteenth}} century, not many corners were designed. For {{commercial}} use straight length were cut and rejoined or gathered to fit around a corner. After the First World War lace-making became a craft and manufacturing {{was no longer}} and issue. To close a square for a handkerchief, still two parts need to be joined. After overlapping and exactly matching the pattern, stitches are oversewn with a thinner thread that exactly matches {{the color of the}} lace. Wherever possible avoid sewing in cloth stitch, in corners and in open ground, in other words: don't sew along a straight line but carefully choose the path for the sewings to make it as little visible as possible. Other methods are needle weaving, and the detour technique with knots or <b>overlapping</b> <b>threads.</b>|$|R
40|$|ABSTRACTThis paper {{proposes a}} dynamic cache {{partitioning}} method for simultaneous multithreading systems. We present ageneral partitioning scheme {{that can be}} applied to setassociative caches at any partition granularity. Further-more, in our scheme <b>threads</b> can have <b>overlapping</b> partitions, which provides more degrees of freedom when par-titioning caches with low associativity. Since memory reference characteristics of threads canchange very quickly, our method collects the miss-rate characteristics of simultaneously executing threads at run-time, and partitions the cache among the executing threads. Partition sizes are varied dynamically to improve hit rates. Trace-driven simulation results show a relative improvement in the L 2 hit-rate of up to 40. 5 % over those gener-ated by the standard least recently used replacement policy, and IPC improvements of up to 17 %. Our results show thatsmart cache management and scheduling is important for SMT systems to achieve high performance. KEY WORDSMemory System, Simultaneous Multithreading, Cache Partitionin...|$|R
40|$|Efficient {{collective}} output of intermediate results to secondary storage {{becomes more and}} more important for scientific simulations as the gap between processing power/interconnection bandwidth and the I/O system bandwidth enlarges. Dedicated servers can offload I/O from compute processors and shorten the execution time, but it is not always possible or easy for an application to use them. We propose the use of active buffering with <b>threads</b> (ABT) for <b>overlapping</b> I/O with computation efficiently and flexibly without dedicated I/O servers. We show that the implementation of ABT in ROMIO, a popular implementation of MPI-IO, greatly reduces the application-visible cost of ROMIO's collective write calls, and improves an application's overall performance by hiding I/O cost and saving implicit synchronization overhead from collective write operations. Further, ABT is high-level, platform-independent, and transparent to users, giving users the benefit of overlapping I/O with other processing tasks even when the file system or parallel I/O library does not support asynchronous I/O...|$|R
40|$|This paper {{proposes a}} dynamic cache {{partitioning}} method for simultaneous multithreading systems. We present a general partitioning scheme {{that can be}} applied to setassociative caches at any partition granularity. Furthermore, in our scheme <b>threads</b> can have <b>overlapping</b> partitions, which provides more degrees of freedom when partitioning caches with low associativity. Since memory reference characteristics of threads can change very quickly, our method collects the miss-rate characteristics of simultaneously executing threads at runtime, and partitions the cache among the executing threads. Partition sizes are varied dynamically to improve hit rates. Trace-driven simulation results show a relative improvement in the L 2 hit-rate of up to 40. 5 % over those generated by the standard least recently used replacement policy, and IPC improvements of up to 17 %. Our results show that smart cache management and scheduling is important for SMT systems to achieve high performance. KEY WORDS Memory System, Simultaneous Multithreading, Cache Partitioning 1...|$|R
40|$|Thesis (Ph. D.) [...] University of Washington, 2012 Programming {{languages}} must {{be defined}} precisely so that programmers can reason carefully about {{the behavior of}} their code and language implementers can provide correct and efficient compilers and interpreters. However, until quite recently, mainstream languages such as Java and C++ did not specify exactly how programs that use shared-memory multithreading should behave (e. g., when do writes by one thread become visible to another thread?). The memory model of a programming language addresses such questions. The recently-approved memory model for C++ effectively requires programs to be "data-race-free": all executions of the program must have the property that any conflicting memory accesses in different threads are ordered by synchronization. To meet this requirement, programmers must ensure that threads properly coordinate accesses to shared memory using synchronization mechanisms such as mutual-exclusion locks. We introduce a new abstraction for reasoning about data-race-free programs: interference-free regions. An interference-free region, or IFR, is a region surrounding a memory access during which no other thread can modify the accessed memory location without causing a data race. Specifically, the interference-free region for a memory access extends from the last acquire call (e. g., mutex lock) before the access to the first release call (e. g., mutex unlock) after the access. Using IFRs, we can reason sequentially about code that contains synchronization operations. IFRs enable entirely thread-local reasoning, meaning {{we do not need}} to have the whole program available in order to make useful inferences. We develop IFRs as a abstract concept, and also present two practical applications of IFRs. First, IFR-based reasoning can be used to extend the scope of compiler optimizations. Compilers typically optimize within synchronization-free regions, since the data-race-freedom assumption permits sequential reasoning in the absence of synchronization. We make the observation that this rule of thumb is overly conservative: it is safe to optimize across synchronization calls as long as the calls are interference-free for the variable in question. (We say that a variable is interference-free at a call if the call falls in the interference-free region for an access to that variable.) We have developed two symmetric compiler analyses for determining which variables are interference-free at each synchronization call, thereby allowing later optimization passes to optimize in larger regions that may include synchronization. Second, we have developed an algorithm for dynamic data-race detection based on the concept of IFRs. Data-race detection is an important problem to the programming languages community: programmers need to eliminate data races during software development in order to avoid costly bugs in production systems. Our algorithm monitors active IFRs for each thread at runtime, reporting a data race if conflicting IFRs in different <b>threads</b> <b>overlap</b> in real time. Conservative approximations of IFRs are inferred using a static instrumentation pass. We compare our algorithm to two precise data-race detectors, and determine that our algorithm catches many data races and provides better performance on most benchmarks. As a final step, we extend the compiler analyses used in both projects to be interprocedural (i. e., analyzing more than one function at a time). Specifically, we classify functions according to their synchronization behavior, making it easier to infer when IFRs propagate through function calls. On the compiler optimization side, this change means that we can optimize across calls that contain internal synchronization. On the data-race detection side, we are able to statically infer longer IFRs, meaning that we are more likely to detect data races...|$|R
40|$|Mons Maiorum argues {{against the}} all-to-common line of {{thinking}} among some scholars of ancient Rome: that house exchange of “ancient families surviving in genetic and property continuity [is] not characteristic of Rome. ” This belief relies fundamentally on evidence from Roman authors after the proscriptions of the first century BC, when long-established aristocratic families {{had been removed from}} the landscape of the Palatine, and Roman memory. It is thus short sighted not to consider the depth of myths, physical monuments, and Roman customs as evidence for a close association of generations of Romans living in family property with a special connection to the Palatine Hill. This paper seeks to delve into exactly those many and <b>overlapping</b> <b>threads</b> to more fully understand how the aristocracy of the ancient Roman Republic was deeply connected to the Palatine Hill. These elites and the people who viewed them influenced the Hill’s memory and in turn generations were influenced by its heritage, forming a collective identity understood by all Romans of the first century BC...|$|R
40|$|AbstractMonterey Phoenix (MP) {{has been}} {{designed}} {{as a framework for}} system and software architecture modeling and verification with focus on modeling the system's and the environment's behaviors. With the development of more case studies, advantages in using MP for business process modeling and analysis applications are beginning to emerge. Models of business processes aim to capture high level operational activities and decision points of an organization, describing processes ranging from product lifecycle to government operations. Businesses and governments seeking to make improvements to their processes may model them for the purpose of seeking improvements in schedule and task execution, product quality, risk reduction, and lifecycle/operating costs. MP enables activities to be modeled as events with two basic relations: precedence and inclusion, making it a candidate modeling language for business process analysis. By offering high level abstractions for interaction behavior modeling and separating component behaviors from the component interactions, MP supports a multidimensional picture of concurrent behaviors, with <b>overlapping</b> <b>threads</b> of process phases and participating actors, including environment behaviors. MP models are executable and may be used to generate an exhaustive set of possible business process scenarios up to a given scope limit...|$|R
50|$|Opening {{in black}} and white with a puzzlingly self-aware narrated scene of Love Torn Within a Dream {{producer}} Paulo Branco welcoming the cast at a celebratory ceremony, the film quickly establishes (with the help of an illustrated configuration upon a chalkboard, one that explicitly references the theories of Ramon Lull’s ars combinatoria, one of Ruiz’s ongoing artistic preoccupations) that there are nine stories that will weave in and out of each other throughout the film: The Meditations, The Robber Mirror, Twenty Two Rings, The Healing Painting, The Discussion, The Pirate’s Treasure, The Prophetic Site, The Castle of Dreams, and The Traveling Companion. Through <b>overlapping</b> <b>threads</b> and exchanged objects, these nine stories form some supposed twelve in total, though the situation becomes increasingly jumbled and less clear as the film goes on. A handful of actors portray different characters across storylines and centuries - Lucrezia, the nun-turned mystical nymph is played by the same woman (Elsa Zylberstein) who portrays modern-day Jessica who interacts with Paul, a student disturbed by a website foretelling his future. Paul is played by the same actor (Melvil Poupaud) who plays the troubled young Catholic who discovers he is Jewish, while many pirates and thieves, corpses and even the devil exchange actors in less pronounced roles throughout the film.|$|R
40|$|Application-level {{checkpointing}} {{has been}} one of the most popular techniques to proactively deal with unexpected fail-ures in supercomputers with hundreds of thousands of cores. Unfortunately, this approach results in heavy I/O load and often causes I/O bottlenecks in production runs. In this pa-per, we examine a new thread-based application-level check-pointing for a massively parallel electromagnetic solver sys-tem on the IBM Blue Gene/P at Argonne National Lab-oratory and the Cray XK 6 at Oak Ridge National Labo-ratory. We discuss an I/O-thread based, application-level, two-phase I/O approach, called “threaded reduced-blocking I/O ” (threaded rbIO), and compare it with a regular version of“reduced-blocking I/O”(rbIO) and a tunedMPI-IO collec-tive approach (coIO). Our study shows that <b>threaded</b> rbIO can <b>overlap</b> the I/O latency with computation and achieve near-asynchronous checkpoint with an application-perceived I/O performance of over 70 GB/s (raw of 15 GB/s) and 50 GB/s (raw I/O bandwidth of 17 GB/s) on up to 32 K pro-cessors of Intrepid and Jaguar, respectively. Compared with rbIO and coIO, the threading approach greatly improves the production performance of NekCEM on Blue Gene/P and Cray XK 6 machines by significantly reducing the total sim-ulation time from checkpoint blocking reduction. We also discuss the potential strength of this approach with the Scal-able Checkpoint Restart library and on other full-featured operating systems such as the upcoming Blue Gene/Q...|$|R
40|$|Haptic icons (brief, tactile stimuli with {{associated}} meanings) are {{a useful}} {{new way to}} convey information through the modality of touch, but they are difficult to create because of our lack of understanding into what makes good haptic stimuli and how people will perceive them. This thesis aims to enlarge our capabilities to design and evaluate haptic icons, despite these problems. We seek to do this via two <b>overlapping</b> <b>threads</b> of research. In the first thread, we introduce the design parameter of rhythm {{as a means of}} extending the expressive capabilities of the simple tactile stimuli used in haptic icons. This allows us to create a set of expressive and perceptually distinguishable haptic stimuli larger by almost an order of magnitude than any previously created. In the second thread of research, we tackle {{the problem of how to}} evaluate the perceptual characteristics of such a large set of stimuli with real people. We develop a means of evaluation that allows us to collect perceived difference data by present each user with only a subset of the total stimulus collection, and then stitch together an aggregate picture of how the stimuli are perceived via data collected from overlapping subsets from different users. To advance these two threads of research, two user studies are run in order to examin...|$|R
40|$|A {{convolution}} is a loop, or a fold, as {{the folds}} of the brain are sometimes termed the cerebral convolutions. But it is a loop in another sense, in the way stories or narratives are often referred to as convolutions (or convoluted) if their plots and themes are complex and resist any linear, straightforward reading. These senses are well established, but in this thesis I propose a new interpretation of convolution (or convolving), as a metaphor for a type of process imbedded in multiple texts, discourses and disciplines, primary amongst which are literature, neuroscience and philosophy of mind. Highlighting this looping, reflexive process means actively engaging in it, as I do, and thus I ultimately promote the heretofore unremarked phenomenon of convolution as a self-conscious practice. The thesis tracks this overarching metaphor of convolutions through a series of sub-metaphors, or instantiations of convolutions, each of which comprises a chapter. The introductory chapter interrogates the revolutionary rhetoric of neuroscience, and proposes a convolutionary approach gleaned from literature to replace it. The first chapter proper explains that science sees itself as a quest with the brain its ultimate goal, but that more often than not, this quest is quixotic - and that if acknowledged, quixotism can actually be illuminating. The second chapter argues that neuroscientists paint themselves in the vein of literary detectives, and in doing so, are as susceptible to the genre's pitfalls as its boons. The third chapter claims that if the brain is a labyrinth, then so too is the brain science that deems it as such, and literature's treatment of the figure of the labyrinth (the treatment itself labyrinthine) can provide a productive framework for analysing this claim. The fourth chapter examines the unchallenged but ubiquitous metaphorical assumption that lies behind the idea of neurons firing, and asks if the overlooked ethical quandary at the nexus of brains and bullets would not benefit from the more self-aware ballistic analyses of literary texts. A concluding chapter brings all these <b>overlapping</b> <b>threads</b> together, suggesting how the notion of convolutions might have important ramifications beyond neuroscience and literature - for new textual methodologies and epistemological categories, for new interdisciplinary endeavours, and above all, for new conceptions of the self...|$|R
40|$|This {{study focused}} on {{exploring}} and creating life pathways {{with a group of}} twelfth graders at West Philadelphia High School. I invited students to inquire into 2 ̆ 7 life pathways, 2 ̆ 7 broadly construed; participants chose to concentrate on transitions to college. Although scholars have investigated many elements of college access, there is limited research that foregrounds students 2 ̆ 7 perspectives and experiences of navigating post-high school transitions (Bloom, 2007; Knight et al., 2004; McDonough, 1997), especially from students of color (Freeman, 1997; Kern, 2000). My research contributes to the literature on college access, adolescent and bureaucratic literacies, and practitioner and participatory action research. It also has local significance, in supporting students 2 ̆ 7 agency and life chances. ^ I used practitioner and participatory action research methodologies, collaborated with students, and reflected on my practice as facilitator. Students and I examined their evolving plans through reading, writing, talking, and drawing activities. Students shared family narratives about pathways, and discussed challenges in engaging institutional bureaucracies and application processes. Our group also became a community with solidarity, and created opportunities to leverage shared knowledge. ^ I argue that students pursued pathways communally, drawing on their social networks, and their local and bureaucratic literacies. The discursive and narrative literacies of students 2 ̆ 7 families surfaced as essential resources for students to make sense of future possibilities. Students positioned their trajectories within and against family narratives, and used a shared discourse of emit concepts, such as 2 ̆ 2 back-up plans, 2 ̆ 2 in their pathways construction. I also learned that students 2 ̆ 7 bureaucratic literacy practices frequently did not match those tacitly required by institutions. Students made a range of choices about how to perform bureaucratic literacies and represent themselves within bureaucratic texts, with consequences for their identities and institutional access. This study also offered a novel participatory action research framework by employing inquiry as its methodology, emphasizing our shared inquiries and my inquiry into practice, and constructing a project with multiple, <b>overlapping</b> <b>threads</b> for individual students. This work highlights the importance of unearthing the local social and cultural capital of students in transition, learning about their strategies of persistence and survival, and partnering with them to develop programming that affects them. ...|$|R
40|$|Traditionally {{metacognition}} {{has been}} theorised, methodologically studied and empirically tested {{from the standpoint}} mainly of individuals and their learning contexts. In this dissertation the emergence of metacognition is analysed more broadly. The aim of the dissertation was to explore socially shared metacognitive regulation (SSMR) as part of collaborative learning processes taking place in student dyads and small learning groups. The specific aims were to extend the concept of individual metacognition to SSMR, to develop methods to capture and analyse SSMR and to validate {{the usefulness of the}} concept of SSMR in two different learning contexts; in face-to-face student dyads solving mathematical word problems and also in small groups taking part in inquiry-based science learning in an asynchronous computer-supported collaborative learning (CSCL) environment. This dissertation is comprised of four studies. In Study I, the main aim was to explore if and how metacognition emerges during problem solving in student dyads and then to develop a method for analysing the social level of awareness, monitoring, and regulatory processes emerging during the problem solving. Two dyads comprised of 10 -year-old students who were high-achieving especially in mathematical word problem solving and reading comprehension were involved in the study. An in-depth case analysis was conducted. Data consisted of over 16 (30 – 45 minutes) videotaped and transcribed face-to-face sessions. The dyads solved altogether 151 mathematical word problems of different difficulty levels in a game-format learning environment. The interaction flowchart was used in the analysis to uncover socially shared metacognition. Interviews (also stimulated recall interviews) were conducted in order to obtain further information about socially shared metacognition. The findings showed the emergence of metacognition in a collaborative learning context in a way that cannot solely be explained by individual conception. The concept of socially-shared metacognition (SSMR) was proposed. The results highlighted the emergence of socially shared metacognition specifically in problems where dyads encountered challenges. Small verbal and nonverbal signals between students also triggered the emergence of socially shared metacognition. Additionally, one dyad implemented a system whereby they shared metacognitive regulation based on their strengths in learning. Overall, the findings suggested that in order to discover patterns of socially shared metacognition, it is important to investigate metacognition over time. However, it was concluded that more research on socially shared metacognition, from larger data sets, is needed. These findings formed the basis of the second study. In Study II, the specific aim was to investigate whether socially shared metacognition can be reliably identified from a large dataset of collaborative face-to-face mathematical word problem solving sessions by student dyads. We specifically examined different difficulty levels of tasks as well as the function and focus of socially shared metacognition. Furthermore, the presence of observable metacognitive experiences at the beginning of socially shared metacognition was explored. Four dyads participated in the study. Each dyad was comprised of high-achieving 10 -year-old students, ranked in the top 11 % of their fourth grade peers (n= 393). Dyads were from the same data set as in Study I. The dyads worked face-to-face in a computer-supported, game-format learning environment. Problem-solving processes for 251 tasks at three difficulty levels taking place during 56 (30 – 45 minutes) lessons were video-taped and analysed. Baseline data for this study were 14 675 turns of transcribed verbal and nonverbal behaviours observed in four study dyads. The micro-level analysis illustrated how participants moved between different channels of communication (individual and interpersonal). The unit of analysis was a set of turns, referred to as an ‘episode’. The results indicated that socially shared metacognition and its function and focus, as well as the appearance of metacognitive experiences can be defined in a reliable way from a larger data set by independent coders. A comparison of the different difficulty levels of the problems suggested that in order to trigger socially shared metacognition in small groups, the problems should be more difficult, as opposed to moderately difficult or easy. Although socially shared metacognition was found in collaborative face-to-face problem solving among high-achieving student dyads, more research is needed in different contexts. This consideration created the basis of the research on socially shared metacognition in Studies III and IV. In Study III, the aim was to expand the research on SSMR from face-to-face mathematical problem solving in student dyads to inquiry-based science learning among small groups in an asynchronous computer-supported collaborative learning (CSCL) environment. The specific aims were to investigate SSMR’s evolvement and functions in a CSCL environment and to explore how SSMR emerges at different phases of the inquiry process. Finally, individual student participation in SSMR during the process was studied. An in-depth explanatory case study of one small group of four girls aged 12 years was carried out. The girls attended a class that has an entrance examination and conducts a language-enriched curriculum. The small group solved complex science problems in an asynchronous CSCL environment, participating in research-like processes of inquiry during 22 lessons (á 45 –minute). Students’ network discussion were recorded in written notes (N= 640) which were used as study data. A set of notes, referred to here as a ‘thread’, was used as the unit of analysis. The inter-coder agreement was regarded as substantial. The results indicated that SSMR emerges in a small group’s asynchronous CSCL inquiry process in the science domain. Hence, the results of Study III were in line with the previous Study I and Study II and revealed that metacognition cannot be reduced to the individual level alone. The findings also confirm that SSMR should be examined as a process, since SSMR can evolve during different phases and that different SSMR <b>threads</b> <b>overlapped</b> and intertwined. Although the classification of SSMR’s functions was applicable in the context of CSCL in a small group, the dominant function was different in the asynchronous CSCL inquiry in the small group in a science activity than in mathematical word problem solving among student dyads (Study II). Further, the use of different analytical methods provided complementary findings about students’ participation in SSMR. The findings suggest that {{it is not enough to}} code just a single written note or simply to examine who has the largest number of notes in the SSMR thread but also to examine the connections between the notes. As the findings of the present study are based on an in-depth analysis of a single small group, further cases were examined in Study IV, as well as looking at the SSMR’s focus, which was also studied in a face-to-face context. In Study IV, the general aim was to investigate the emergence of SSMR with a larger data set from an asynchronous CSCL inquiry process in small student groups carrying out science activities. The specific aims were to study the emergence of SSMR in the different phases of the process, students’ participation in SSMR, and the relation of SSMR’s focus to the quality of outcomes, which was not explored in previous studies. The participants were 12 -year-old students from the same class as in Study III. Five small groups consisting of four students and one of five students (N= 25) were involved in the study. The small groups solved ill-defined science problems in an asynchronous CSCL environment, participating in research-like processes of inquiry over a total period of 22 hours. Written notes (N= 4088) detailed the network discussions of the small groups and these constituted the study data. With these notes, SSMR threads were explored. As in Study III, the thread was used as the unit of analysis. In total, 332 notes were classified as forming 41 SSMR threads. Inter-coder agreement was assessed by three coders in the different phases of the analysis and found to be reliable. Multiple methods of analysis were used. Results showed that SSMR emerged in all the asynchronous CSCL inquiry processes in the small groups. However, the findings did not reveal any significantly changing trend in the emergence of SSMR during the process. As a main trend, the number of notes included in SSMR threads differed significantly in different phases of the process and small groups differed from each other. Although student participation was seen as highly dispersed between the students, there were differences between students and small groups. Furthermore, the findings indicated that the amount of SSMR during the process or participation structure did not explain the differences in the quality of outcomes for the groups. Rather, when SSMRs were focused on understanding and procedural matters, it was associated with achieving high quality learning outcomes. In turn, when SSMRs were focused on incidental and procedural matters, it was associated with low level learning outcomes. Hence, the findings imply that the focus of any emerging SSMR is crucial to the quality of the learning outcomes. Moreover, the findings encourage the use of multiple research methods for studying SSMR. In total, the four studies convincingly indicate that a phenomenon of socially shared metacognitive regulation also exists. This means that it was possible to define the concept of SSMR theoretically, to investigate it methodologically and to validate it empirically in two different learning contexts across dyads and small groups. In-depth micro-level case analysis in Studies I and III showed the possibility to capture and analyse in detail SSMR during the collaborative process, while in Studies II and IV, the analysis validated the emergence of SSMR in larger data sets. Hence, validation was tested both between two environments and within the same environments with further cases. As a part of this dissertation, SSMR’s detailed functions and foci were revealed. Moreover, the findings showed the important role of observable metacognitive experiences as the starting point of SSMRs. It was apparent that problems dealt with by the groups should be rather difficult if SSMR is to be made clearly visible. Further, individual students’ participation was found to differ between students and groups. The multiple research methods employed revealed supplementary findings regarding SSMR. Finally, when SSMR was focused on understanding and procedural matters, this was seen to lead to higher quality learning outcomes. Socially shared metacognition regulation should therefore be taken into consideration in students’ collaborative learning at school similarly to how an individual’s metacognition is taken into account in individual learning...|$|R

