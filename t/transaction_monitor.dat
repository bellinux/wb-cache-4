14|208|Public
50|$|Using cursors in {{distributed}} transactions (X/Open XA Environments), {{which are}} controlled using a <b>transaction</b> <b>monitor,</b> {{is no different}} from cursors in non-distributed transactions.|$|E
50|$|A close {{cousin of}} TPF, the <b>transaction</b> <b>monitor</b> ALCS, was {{developed}} by IBM to integrate TPF services into the more common mainframe operating system MVS, now z/OS.|$|E
50|$|The 1978 {{multiprocessor}} {{technology was}} introduced. The operating system {{had the ability}} to cope with a processor failure. At the same time the new technology considerably extended the performance range of the system.In 1979 a transaction processing monitor, the Universal <b>Transaction</b> <b>Monitor</b> (UTM), was introduced, providing support for online transaction processing as an additional operating mode.|$|E
5000|$|... {{material}} sense, <b>transaction</b> <b>monitoring</b> {{processes and}} their functions.|$|R
5000|$|Feb. 2007: Bristol Technology, Inc., {{business}} <b>transaction</b> <b>monitoring</b> technologies ...|$|R
40|$|<b>Transaction</b> <b>monitors</b> (a. k. a. <b>transaction</b> {{processing}} <b>monitors,</b> a. k. a. TP monitors) {{were the}} first kind of middleware to support distributed transaction processing, and thus also the first kind of application servers. They were (originally) designed for environments with very high processing demands, such as banks or airlines, {{that could not be}} properly supported by 2 -tier architectures and by DBMS alone. Architectures using <b>transaction</b> <b>monitors</b> as middleware for transaction control are also called TP-heavy transaction processing environments, because this solution is much heavier to implement. ...|$|R
5000|$|Network-attached storage (NAS) and Storage area {{networks}} (SANs) {{coupled with}} fast local area networks and Fibre Channel technology enable still larger, more loosely coupled configurations of databases and distributed computing power. The widely supported X/Open XA standard employs a global <b>transaction</b> <b>monitor</b> to coordinate distributed transactions among semi-autonomous XA-compliant database resources. Oracle RAC uses a different model to achieve scalability, {{based on a}} [...] "shared-everything" [...] architecture that relies upon high-speed connections between servers.|$|E
50|$|Two 64-bit {{operating}} systems {{run on the}} server nodes of the appliance: Oracle Linux version 5.5 or Solaris 11. All servers have an installed cluster configuration of Oracle WebLogic Server and distributed memory cache Oracle Coherence. To run Java applications on a machine there is a choice of HotSpot or JRockit. Management of the appliance {{is available in the}} Oracle Enterprise Manager toolset, which is also pre-installed in the appliance. A <b>transaction</b> <b>monitor</b> Tuxedo is optionally supplied.|$|E
50|$|Versant {{supports}} the XA protocol for distributed transactions. This allows participation in online distributed transactions with relational databases. The {{interaction with the}} relational tables can take many forms from custom code to ORM solutions to J2EE application servers (Entity Relationship Modeling) to message passing to ORBs, etc. The XA API allows the Versant database {{to act as a}} resource controlled by an external <b>transaction</b> <b>monitor</b> coordinating changes to both Versant and relational databases in the same transactional context.|$|E
50|$|INETCO Insight is {{real-time}} <b>transaction</b> <b>monitoring</b> and Big Data streaming {{platform that}} captures and correlates multi-protocol transactions across multiple IT-hops while operating {{independently of the}} underlying application or switch being monitored.|$|R
5000|$|HP Business Service Management [...] (BSM) is an {{end-to-end}} management {{solution that}} integrates network, server, application and business <b>transaction</b> <b>monitoring.</b> [...] HP Business Service Management is developed and marketed by the HP Software Division.|$|R
50|$|It uses TmaxSoft’s own {{technologies}} for middleware, frameworks, and databases to minimize overheads for collecting, transmitting, manufacturing, storing, and searching data. It provides integrated, customizable dashboards and reports and detailed <b>transaction</b> <b>monitoring</b> allowing drill-down analysis.|$|R
50|$|Besides the {{traditional}} scientific applications, KSR with Oracle Corporation, addressed the massively parallel database market for commercial applications. The KSR-1 and -2 supported Micro Focus COBOL and C/C++ programming languages, and the Oracle PRDBMS and the MATISSE OODBMS from ADB, Inc. Their own product, the KSR Query Decomposer, complemented {{the functions of}} the Oracle product for SQL uses. The TUXEDO <b>transaction</b> <b>monitor</b> for OLTP was also provided. The KAP program (Kuck & Associate Preprocessor) provided for pre-processing for source code analysis and parallelization. The runtime environment was termed PRESTO, and was a POSIX compliant multithreading manager.|$|E
50|$|The {{capability}} to handle nested transactions properly {{is a prerequisite}} for true component-based application architectures. In a component-based encapsulated architecture, nested transactions can occur without the programmer knowing it. A component function may or may not contain a database transaction (this is the encapsulated secret of the component. See Information hiding). If a call to such a component function is made inside a BEGIN - COMMIT bracket, nested transactions occur. Since popular databases like MySQL do not allow nesting BEGIN - COMMIT brackets, a framework or a <b>transaction</b> <b>monitor</b> is needed to handle this. When we speak about nested transactions, it should be made clear that this feature is DBMS dependent and is not available for all databases.|$|E
5000|$|... 1961: IBM 7030 StretchIBM {{delivers}} {{its first}} 7030 Stretch supercomputer. Stretch {{falls short of}} its original design objectives, {{and is not a}} commercial success. But it is a visionary product that pioneers numerous revolutionary computing technologies which are soon widely adopted by the computer industry.1961: Thomas J. Watson Research CenterIBM moves its research headquarters from Poughkeepsie, NY to Westchester County, NY, opening the Thomas J. Watson Research Center which remains IBM's largest research facility, centering on semiconductors, computer science, physical science and mathematics. The lab which IBM establish at Columbia University in 1945 was closed and moved to the Yorktown Heights laboratory in 1970.1961: IBM Selectric typewriterIBM introduces the Selectric typewriter product line. Later Selectric models feature memory, giving rise to the concepts of word processing and desktop publishing. The machine won numerous awards for its design and functionality. Selectrics and their descendants eventually captured 75 percent of the United States market for electric typewriters used in business. IBM replaced the Selectric line with the IBM Wheelwriter in 1984 and transferred its typewriter business to the newly formed Lexmark in 1991.1961: Report Program GeneratorIBM offers its Report Program Generator, an application that allows IBM 1401 users to produce reports. This capability was widely adopted throughout the industry, becoming a feature offered in subsequent generations of computers. It {{played an important role in}} the successful introduction of computers into small businesses.1962: Basic beliefsDrawing on established IBM policies, Thomas J. Watson, Jr., codifies three IBM basic beliefs: respect for the individual, customer service, and excellence.1962: SABRETwo IBM 7090 mainframes formed the backbone of the SABRE reservation system for American Airlines. As the first airline reservation system to work live over phone lines, SABRE linked high speed computers and data communications to handle seat inventory and passenger records.1964: IBM System/360In the most important product announcement in company history to date, IBM introduces the IBM System/360: a new concept in computers which creates a [...] "family" [...] of small to large computers, incorporating IBM Solid Logic Technology (SLT) microelectronics and using the same programming instructions. The concept of a compatible [...] "family" [...] of computers transforms the industry.1964: Word processingIBM introduces the IBM Magnetic Tape Selectric Typewriter, a product which pioneered the application of magnetic recording devices to typewriting, and gave rise to desktop word processing. Referred to then as [...] "power typing," [...] the feature of revising stored text improved office efficiency by allowing typists to type at [...] "rough draft" [...] speed without the pressure of worrying about mistakes.1964: New corporate headquartersIBM moves its corporate headquarters from New York City to Armonk, New York.1965: Gemini space flightsA 59-pound onboard IBM guidance computer is used on all Gemini space flights, including the first spaceship rendezvous. IBM scientists complete the most precise computation of the Moon's orbit and develop a fabrication technique to connect hundreds of circuits on a silicon wafer.1965: New York World's FairThe IBM Pavilion at the New York World's Fair closes, having hosted more than 10 million visitors during its two-year existence.1966: Dynamic Random-Access Memory (DRAM)IBM invents one-transistor DRAM cells which permit major increases in memory capacity. DRAM chips become the mainstay of modern computer memory systems: the [...] "crude oil" [...] of the information age is born.1966: IBM System/4 PiIBM ships its first System/4Pi computer, designed to meet U.S. Department of Defense and NASA requirements. More than 9000 units of the 4Pi systems are delivered by the 1980s for use in the air, sea, and space.1966: IBM Information Management System (IMS)IBM designed the Information Management System (IMS) with Rockwell and Caterpillar starting in 1966 for the Apollo program, where it was used to inventory the very large bill of materials (BOM) for the Saturn V moon rocket and Apollo space vehicle.1967: Fractal geometryIBM researcher Benoit Mandelbrot conceives fractal geometry - the concept that seemingly irregular shapes can have identical structure at all scales. This new geometry makes it possible to mathematically describe the kinds of irregularities existing in nature. The concept greatly impacts the fields of engineering, economics, metallurgy, art, health sciences, and computer graphics and animation.1968: IBM Customer Information Control System (CICS)IBM introduces the CICS <b>transaction</b> <b>monitor.</b> CICS remains to this day the industry's most popular transactions monitor.|$|E
50|$|Early NonStop {{applications}} {{had to be}} specifically coded for fault-tolerance. That requirement {{was removed}} in 1983 {{with the introduction of}} the <b>Transaction</b> <b>Monitoring</b> Facility (TMF), which handles the various aspects of fault tolerance on the system level.|$|R
50|$|INETCO’s {{experience}} in the banking and payment processing protocol space expanded into the business <b>transaction</b> <b>monitoring</b> space, and the company began developing the INETCO Insight software that offered real-time transaction performance analysis across servers, networks, and applications.|$|R
50|$|The Kuala Lumpur center also handles {{activities}} across {{operations and}} technology including Anti Money Laundering <b>transaction</b> <b>monitoring</b> {{to identify and}} prevent possible money laundering activities; Securities & Funds Services, the Fraud and Authorization Center of Excellence and Global System Entitlement Administration.|$|R
40|$|Networks-on-chip (NoC) are a {{scalable}} interconnect {{solution to}} multiprocessor systems on chip (MPSoC). NoCs transport data in packets which are fragments of transactions, such as {{read and write}} actions of IPs. For debug purposes, reconstructing transactions at run-time is essential. Run-time analysis of the NoC behavior at transaction level makes the complete MPSoC easier to understand. We present a NoC analyzer able to monitor NoC transactions at run-time. The proposed hardware <b>transaction</b> <b>monitor</b> is able to reconstruct on-chip, at run-time, NoC transactions from bit-level intercepted router link communication. Four NoC analyzer modes are detailed raising the abstraction level gradually from physical raw to logical connectionbased, transaction-based and abstract transaction eventbased. Each mode is analyzed for area and bandwidth in an experimental setup based on several Æthereal NoC designs. A <b>transaction</b> <b>monitor</b> has an area cost of 0. 026 mm 2 in a 0. 13 µm CMOS technology, and for several MPEG/audio case studies, the entire monitoring system adds an average of 5 % to the NoC area. We show the versatility of our NoC analyzer by run-time monitoring user connections and the Configuration Master IP in the NoC...|$|E
40|$|The FARGOS/VISTA ™ {{suite of}} {{technologies}} implements an infrastructure for the development, deployment and non-stop operation of transparently distributed, multithreaded, architecture-neutral, object-oriented peer-topeer applications. These capabilities {{can be applied}} {{in a variety of}} paradigms, ranging from simple client/server applications to more sophisticated applications that are dynamically loaded into to a pool of cooperating host systems, as well as fault-tolerant systems that eliminate single points of failure. With little effort, these capabilities can be exploited to provide conventional applications with unprecedented reliability. This is illustrated by the implementation of Byzantine faulttolerant <b>transaction</b> <b>monitor</b> for HTTP-based applications. 1...|$|E
40|$|Automated Teller Machine (ATM) {{has gained}} {{widespread}} acceptance as a convenient medium to facilitate financial transaction without need for human agent. However, ATM deployers are facing challenges in maximizing the uptime of their ATMs {{as a result}} of wide gap in fault detection, notification and correction of the ATMs. One way to ameliorate this situation is through intelligent monitoring of ATM by resident software agents that monitor the device real time and report faulty components real time to facilitate quick response. We proposed an architecture for rule-based, intelligent agent based monitoring and management of ATMs. Agents are used to perform remote monitoring on the ATMs and control function such software maintenance. Such agents can detect basic events or correlate existing events that are stored in a database to detect faults. A system administrator can securely modify the monitoring policies and control functions of agents. The framework presented here includes software fault monitor, hardware fault monitor and <b>transaction</b> <b>monitor.</b> A set of utility support agents: caller agent and log agent are used to alert network operator and log error and transaction information in a database respectively. at- 1, stuck-at- 0 faults in digital circuits validate the point that faulty circuits dissipates more and hence draw more power...|$|E
5000|$|<b>Transaction</b> <b>monitoring</b> systems, which {{focus on}} {{identification}} of suspicious patterns of transactions which {{may result in}} the filing of Suspicious Activity Reports (SARs) or Suspicious Transaction Reports (STRs). Identification of suspicious (as opposed to normal) transactions {{is part of the}} KYC requirements.|$|R
40|$|This article {{evaluates the}} claim that FinTech—a {{portmanteau}} of finance and technology, including blockchain and automated suspicious <b>transaction</b> <b>monitoring</b> technology systems—has the ability to revolutionise financial inclusion and examines whether regulatory technology (RegTech) {{can be used by}} regulators for tracking and monitoring AML/CFT compliance activities...|$|R
50|$|The IBM Storage and Information Retrieval System, {{better known}} by the acronym STAIRS was a program {{providing}} storage and online free-text search of text data. STAIRS ran under the OS/360 operating system under the CICS or IMS <b>transaction</b> <b>monitors,</b> and supported IBM 3270 display terminals.|$|R
40|$|Abstract: Business {{processes}} representing related interactions {{within a}} business organization {{as well as}} e-commerce interactions across multiple independent autonomous organizations span days and weeks in time. The software which supports or automates the activities of a single business is best modeled {{as a set of}} long running applications which interact repeatedly with the outside world. The execution of these long running applications needs to be managed and monitored because of their business value. The monitoring framework must deal with all the different requirements on long running applications: (i) multiple interactions with each autonomous business partner driven by contractual agreements, (ii) execution of multiple application steps in response to an business event (request or response from an business entity, pre-scheduled action or time-out, etc.), (iii) interaction with a specific business role (internal or external) to perform some application steps, (iv) support for extended transactional semantics (e. g., compensation framework) to accommodate activities that are long running and/or across independent business entities, and (v) finally, development and execution framework for ease of programming of business applications. Legacy application monitors (e. g., Workflow, Extended <b>transaction</b> <b>monitor,</b> Conversation monitor) are designed to satisfy specific subset of these requirements. We argue that while proposed as well as legacy long running application monitors satisfy some of these objectives, no single monitor currently supports all of these objectives. This paper discusses a design approach which could lead to a unified monitor and also shows how {{in the absence of a}} unified monitor, long running business applications can be effectively modeled and built using multiple co-operating monitors. 1...|$|E
40|$|As {{companies}} {{expand into}} new business sectors, such as eBusiness, and find themselves having {{to respond to}} new innovations, they often need new IT applications. These applications are expected to meet a number of basic requirements: they must be non-platformspecific, readily extensible, and easy to implement. Enterprise JavaBeans TM (EJB) is a component technology that allows {{for the development of}} cross-platform, multitier, distributed server applications within a modular architecture. Users can create their own components for server applications or incorporate standard EJB components available on the market. By applying EJB technology, new applications can be implemented much more efficiently, allowing developers to concentrate on the actual business logic. The entire infrastructure is provided by the application server. The BeanTransactions application server is a runtime environment for the Enterprise JavaBeans component technology as defined in the EJB 2. 0 specification from Sun Microsystems. Based on the high-end <b>transaction</b> <b>monitor</b> middleware openUTM, it provides infrastructure services which fulfill the requirements of business-critical IT applications, {{particularly when it comes to}} reliability, scalability, and availability. BeanTransactions is part of the openSEAS product range (open Enterprise Application Server Suite), which also includes the following: WebTransactions for web enabling, portal integration and the implementation of mobile end devices BizTransactions for integrating applications Enterprise beans developed with BeanTransactions can be linked on a transactional level to existing openUTM or CICS/IMS applications or to other OLTP applications. When combined with the high-performance Persistency Framework MPF/J from our partner MicroDoc, optimum support is provided for container-managed persistence in entity beans. Bean-managed persistence is also possible via JDBC. Furthermore, as well as meeting the requirements of the EJB 2. 0 specification, BeanTransactions also supports recoverable session beans...|$|E
40|$|The {{increasing}} demand for interoperable systems requires {{the integration of}} traditional mainframe-based <b>transaction</b> processing (TP) <b>monitors</b> with CORBA-based middleware infrastructures. We discuss various integration approaches. The integration of IBM's IMS-TM (Information Management System Transaction Manager) and CORBA is discussed in detail, and up-to-date performance and scalability results are presented. The {{results show that the}} combination of CORBA and mainframe-based TP monitors is significant step towards highly available, highly scalable object <b>transaction</b> <b>monitors</b> (OTMs...|$|R
40|$|Process {{focus in}} {{modeling}} {{and integration of}} information systems – Data focus: e. g. relational data model and federated databases – Functional focus: function interfaces and <b>transaction</b> <b>monitors</b> – Behavioral focus: object models and object <b>transaction</b> <b>monitors</b> – Process focus: process models and workflow management systems • Why focus on processes? – At coarse granularity a business process describes best what a company is doing – Business process re-engineering is a practice to understand and optimize what a company is doing – At a coarse granularity large systems can be best described as processes (programming in the large) – The interaction of many different information systems and human users can be best captured by processes (linking data islands) © 2004, Karl Aberer, EPFL-SSC, Laboratoire de systèmes d'informations rèpartis Part 8 -...|$|R
5000|$|Oversight Systems {{provides}} three-part solution which includes: Continuous Auditing, Continuous Controls <b>Monitoring,</b> and Continuous <b>Transaction</b> <b>Monitoring.</b> Oversight's solution {{searches for}} duplicate payments at the voucher level and generates {{a report of}} errors, leaks, and possible fraud within the system and provides continuous downloads of new transactions, enabling near real-time monitoring.|$|R
50|$|INETCO Systems Limited is a {{software}} {{company based in}} Vancouver, British Columbia, Canada. It develops business <b>transaction</b> <b>monitoring,</b> customer analytics and data forwarding technology for the banking, payment processing and retail industries.In addition to software, INETCO offers advisory and support services in business transaction management, training, transaction analytics and reporting, and software implementation.|$|R
5000|$|These {{software}} applications effectively <b>monitor</b> bank customer <b>transactions</b> {{on a daily}} basis and, using customer historical information and account profile, provide a [...] "whole picture" [...] to the bank management. <b>Transaction</b> <b>monitoring</b> can include cash deposits and withdrawals, wire transfers and ACH activity. In the bank circles, these applications are known as [...] "AML software".|$|R
50|$|VOD handles {{distributed}} {{data processing}} using a distributed two-phase commit protocol across multiply connected databases. In this process, VOD uses an internal resource manager that is handling the distributed transactions. Versant also supports the XA protocol allowing external <b>transaction</b> <b>monitors</b> to control the transactional context, so for example plug into a CORBA or J2EE application server.|$|R
50|$|<b>Transaction</b> {{processing}} <b>monitors</b> provides {{tools and}} an environment {{to develop and}} deploy distributed applications.|$|R
50|$|IBM {{developed}} ACP and its successors because: in {{the mid-1960s}} IBM's standard operating systems (DOS/360 and OS/360) were batch-oriented and could not handle large numbers of short transactions quickly enough; even its <b>transaction</b> <b>monitors</b> IMS and CICS, which run {{under the control of}} standard general-purpose operating systems, are not fast enough for handling reservations on hundreds of flights from thousands of travel agents.|$|R
5000|$|UNIVAC Transaction Interface Package (TIP) - 1970s. A <b>transaction</b> {{processing}} <b>monitor</b> for UNIVAC 1100/2200 series computers.|$|R
5000|$|These {{software}} applications effectively <b>monitor</b> customer <b>transactions</b> {{on a daily}} basis, and using a customer's past transactions and account profile, provide a [...] "whole picture" [...] of the customer to the bank management. <b>Transaction</b> <b>monitoring</b> can include cash deposits and withdrawals, wire transfers and ACH activity. In the banking industry, these applications are known as [...] "BSA software" [...] or [...] "anti-money laundering software".|$|R
