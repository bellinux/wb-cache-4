20|10000|Public
40|$|A {{probabilistic}} approach to conformance <b>testing</b> <b>of</b> <b>protocols</b> containing unobservable transitions is proposed. It {{is said that}} an implementation conforms to its specification if their observable behavior is probabilistically the same, when both {{are subject to the}} same random environment simulated by the tester. Under the randomized inputs, faults in unobservable transitions may manifest themselves in certain statistics measurable from the implementation, and hence can be detected by comparing these measurements against the desirable statistics computed from the specification. The sensitivity of the nonconformance criterion to the uncertainty in our knowledge of desirable statistics is also studied. The conventional <b>testing</b> <b>of</b> <b>protocols</b> without unobservable transitions uses mismatch in outputs to detect faults. Here, one relies, in addition, on mismatch in the dynamics of the protocol under input randomization...|$|E
40|$|We {{present an}} {{implemented}} technique for generating test cases from state machine specifications. The work {{is motivated by}} a need for <b>testing</b> <b>of</b> <b>protocols</b> and services developed by the company Mobile Arts. We have developed a syntax for description of state machines extended with data variables. From such state machines, test cases are generated by symbolic execution. The test cases are symbolically represented; concrete test cases are generated by instantiation of data parameters...|$|E
40|$|This article {{describes}} MobiCS (Mobile Computing Simulator), a distributed protocol simulator for mobile computing that facilitates the prototyping and <b>testing</b> <b>of</b> <b>protocols</b> based on high-level programming abstractions and simulation transparency. The main contribution of MobiCS is {{the implementation of}} a software architecture for simulators that supports interchangeable simulation modes without affecting the distributed protocols being prototyped. Through MobiCS we aim at providing a unified tool both for testing the correctness of a protocol and for evaluating its performance in a simulated environment...|$|E
5000|$|Running <b>tests</b> <b>of</b> Apple's Rendezvous <b>protocol</b> on the MCi200 (2003).|$|R
30|$|<b>Testing</b> <b>of</b> the <b>protocol.</b> <b>Testing</b> was {{undertaken}} by three test coders, all coding the same four plans (one regional policy statement, one CDEM plan, two land use plans).|$|R
40|$|Abstract. The article {{presents}} {{an approach to}} model based <b>testing</b> <b>of</b> complex systems based on a generalization of finite state machines (FSM) and input output state machines (IOSM). The approach presented {{is used in the}} context of UniTesK specification based test development method. The results of its practical applications are also discussed. Practical ex-perience demonstrates the applicability of the approach for model based <b>testing</b> <b>of</b> <b>protocol</b> implementations, distributed and concurrent systems, and real-time systems. This work stems from ISPRAS results of academic research and industrial application of formal techniques in verification and testing [1]. ...|$|R
40|$|ADIOP is an {{application}} for Automated Diagnosis of In-terOperability Problems. Interoperability testing involves checking the degree of compatibility between two network-ing devices that implement the same protocol. In ADIOP, each interoperability test case is first modeled as a Constraint Satisfaction Problem. Object-Oriented Programming is used to implement ADIOP. In this paper, we present the model-ing language we use in ADIOP and how it allows the user to easily and efficiently create test cases and use them for diag-nosis. The specific domain of application is interoperability <b>testing</b> <b>of</b> <b>protocols</b> in ATM (Asynchronous Transfer Mode) networks...|$|E
40|$|ADIOP (Automated Diagnosis of InterOperability Problems) models, diagnoses and debugs {{interoperability}} problems {{using an}} integration of Constraint-Based and Case-Based Reasoning. The specific problem domain is interoperability <b>testing</b> <b>of</b> <b>protocols</b> in ATM (Asynchronous Transfer Mode) networks. Each test case is first modeled as a Constraint Satisfaction Problem (CSP) using an ObjectOriented approach. The CSP models are {{then used to}} diagnose and solve interoperability problems. CSP algorithms are adapted to the OO approach and {{to take advantage of}} the specialized problem structure. These provide a better diagnosis of the interoperability problems including an accurate and concise explanation of the testing performed. These algorithms are evaluated to show their usefulness. A CS...|$|E
40|$|Systematic Testing of Robustness by Evaluation of Synthesized Scenarios STRESS is a {{methodology}} {{developed for the}} systematic <b>testing</b> <b>of</b> <b>protocols,</b> and includes algorithms for generating topologies and event sequences that rigorously test the correctness or performance of a given protocol. In this paper, we apply the STRESS method to Mobile IP (MIP) protocol and the MARS protocol for supporting IP-multicast over ATM. For each protocol, we develop a protocol model and analyze its robustness. We also analyze complexity of the STRESS test generation algorithms. In the process, we identify {{the limitations of the}} existing STRESS models and algorithms, and propose extensions to carry out our case studies...|$|E
40|$|This paper {{examines}} the applicability <b>of</b> OSI conformance <b>test</b> methodology to Internet protocols. It summarizes {{the differences between}} them and introduces the Internet Reference Model along with a new abstract test method, which was designed for the practical purposes <b>of</b> conformance <b>testing</b> <b>of</b> TCP/IP <b>protocols.</b> Some interesting test cases and points, that were chosen from RIP, demonstrate the facilities of the model and give impression <b>of</b> <b>testing</b> Internet <b>protocols...</b>|$|R
40|$|International audienceConformance <b>testing</b> <b>of</b> {{communicating}} <b>protocols</b> is {{a functional}} test which verifies whether the behaviors <b>of</b> the <b>protocol</b> satisfy defined requirements, while the performance <b>testing</b> <b>of</b> communicating <b>protocols</b> is a {{qualitative and quantitative}} test, aiming at checking whether the performance requirements <b>of</b> the <b>protocol</b> have been satisfied under certain conditions. It raises the interesting issue of converging these two kinds <b>of</b> <b>test</b> by using the same formal approach. In this paper, we present a novel logic-based approach to test the protocol performance through real execution traces and formally specified properties. In order to evaluate and assess our methodology, we have developed a prototype and present experiments {{with a set of}} IMS/SIP properties. Finally, the relevant verdicts and discussions are provide...|$|R
40|$|Communication {{protocols}} are {{the rules}} that govern the communication between the different components within a distributed computer system. Since protocols are implemented in software and/or hardware, the question arises whether the existing hardware and software testing methods would be adequate for the <b>testing</b> <b>of</b> communication <b>protocols.</b> The purpose <b>of</b> {{this paper is to}} explain in which way the problem <b>of</b> <b>testing</b> <b>protocol</b> implementations is different from the usual problem <b>of</b> software <b>testing.</b> We review the major results in the area <b>of</b> <b>protocol</b> <b>testing</b> and discuss in which way these methods may also be relevant in the more general context <b>of</b> software <b>testing...</b>|$|R
40|$|An {{overwhelming}} {{large number}} of new protocols are designed in the current software industry. Yet the design is a resource demanding and slow manual process, typically protocols are specified usingpen and paper, and then implemented directly into software. We introduce a formal protocol-centric language for the specification, testing, simulation and analysis of both communication and security. Since the language is formal, {{it can be used}} as a basis for constructing tool support for automated construction, refinement and <b>testing</b> <b>of</b> <b>protocols.</b> In the paper we show how notions like roles, refinement, composition, equivalence, and execution of protocols can be handled, only by considering the protocol syntax. The language is specialized to handle security protocols, illustrated by the Otway-Rees authentication protocol. 1...|$|E
40|$|Abstract — The {{inherent}} {{difficulty in}} faithfully modeling wireless channel characteristics in simulators has prompted researchers to build wireless network testbeds for realistic <b>testing</b> <b>of</b> <b>protocols.</b> While previous testbeds are mostly {{designed to provide}} a research environment of static wireless networks, our work is aimed to assess protocols used for mobile wireless networks (such as an on-board network on public transport vehicles). In this work, we describe our on-going efforts in designing and implementing a network mobility testbed for Network Mobility (NEMO) protocol. This paper attempts to provide an initial reference to identify the feature set necessary for a network mobility testbed. We first describe the architecture of our testbed. Next, we present some preliminary results to demonstrate the use of our testbed in evaluating the performance of NEMO protocol under different scenarios. I...|$|E
40|$|In this paper, {{conformance}} <b>testing</b> <b>of</b> <b>protocols</b> specified as nondeterministic finite {{state machines}} is considered. Protocol implementations {{are assumed to}} be deterministic. In this testing scenario, the conformance relation becomes a preorder, so-called reduction relation between FSMs. The reduction relation requires that an implementation machine produces a (sub) set of output sequences that can be produced by its specification machine in response to every input sequence. A method for deriving tests with respect to the reduction relation with full fault coverage for deterministic implementations is proposed based on certain properties of the product of specification and implementation machines. Keywords Conformance testing, test derivation, fault detection, I/O nondeterministic FSMs, equivalence and reduction relations 1 INTRODUCTION Conformance testing of protocol implementations is often formalized as the FSM equivalence problem (Moore, 1956) and (Hennie, 1964). In particular, we [...] ...|$|E
40|$|Abstract—The {{paper is}} devoted to {{constructing}} a tester for checking student implementations <b>of</b> application-layer <b>protocols.</b> There are two testing modes for checking a protocol implementation: the active testing and the passive testing. We automate the testing process in both modes for checking student protocol implementations through Internet programming labs. Test set that contains test cases for detecting most frequent student faults, is derived for active <b>testing</b> <b>of</b> server <b>protocol</b> implementations. For passive <b>testing</b> <b>of</b> client <b>protocol</b> implementations, the paper uses the invariant approach. The approach is illustrated by a part of Dynamic Host Configuration Protocol (DHCP). The structure of the tester is also described. Index Terms—Active testing, computer applications, passive testing, protocols...|$|R
40|$|Abstract. Communication {{protocols}} are {{the rules}} that govern the communication between the different components within a distributed computer system. Since protocols are implemented in software and/or hardware, the question arises whether the existing hardware and software testing methods would be adequate for the <b>testing</b> <b>of</b> communication <b>protocols.</b> The purpose <b>of</b> {{this paper is to}} explain in which way the problem <b>of</b> <b>testing</b> <b>protocol</b> implementations is different from the usual problem <b>of</b> software <b>testing.</b> We review the major results in the area <b>of</b> <b>protocol</b> <b>testing</b> and discuss in which way these methods may also be relevant in the more general context <b>of</b> software <b>testing.</b> 1...|$|R
30|$|No image {{orientation}} adjustments {{were completed}} prior to <b>testing</b> <b>of</b> the <b>protocols.</b> The sagittal plane was utilized for initial evaluations for each technique, {{as it appeared}} most useful in the visualization and evaluation of the tooth structure of the crown and root simultaneously.|$|R
40|$|In this paper, {{we suggest}} {{diagnosing}} InterOperability Testing problems by integrating Constraint-Based and Case-Based Reasoning. We model {{the problem as}} a Constraint Satisfaction Problem (CSP), then CaseBased Reasoning (CBR) is used to compensate for what is missing in this model. CBR supports {{the process of learning}} by supplying the case-base with new cases {{that can be used to}} solve future similar problems. CBR is also used to update the CSP model, and make it more robust for solving more problems. The domain we are using is InterOperability <b>Testing</b> <b>of</b> <b>protocols</b> in ATM (Asynchronous Transfer Mode) networks. Introduction In this work, we suggest diagnosing interoperability testing problems by integrating two modes of reasoning: constraint-based and case-based. The first step is modeling our system as a Constraint Satisfaction Problem (CSP). CSP has proven very useful in many applications including diagnosis of protocols, and interoperability testing. The model of any syst [...] ...|$|E
40|$|This paper {{describes}} an environment for fault injection based <b>testing</b> <b>of</b> <b>protocols</b> that implement fault tolerance and redundancy management in safety-critical distributed real-time systems. Building {{confidence in the}} correctness of distributed protocols is an intrinsically difficult problem that {{requires the use of}} complementary testing and verification techniques. To this end, we propose a verification approach that involves three steps: i) initial testing in a software simulator, ii) formal verification by model checking and iii) final testing in a hardware prototype. Here, we describe an integrated test environment intended for the first and third step. It allows a tester to expose a protocol to various failure scenarios in both a software simulator and a hardware prototype system. Common data formats for definition of failure scenarios and for storing the protocols’ responses makes it possible run identical tests in the simulator and the hardware prototype and simplifies comparison of test results...|$|E
40|$|Modeling is {{very useful}} in many domains. A {{model can be}} very simple such as a {{mathematical}} equation, or be very complex. But, models are not always perfect and may not represent all {{the information about the}} system. In this paper, we suggest compensating for incompleteness and incorrectness of models by integrating Constraint-Based and Case-Based Reasoning. We model the problem as a Constraint Satisfaction Problem (CSP), then Case-Based Reasoning (CBR) is used to compensate for what is missing in this model. CBR supports the process of learning by supplying the case-base with new cases {{that can be used to}} solve future similar problems. CBR is also used to update the CSP model, and make it more robust for solving more problems. The domain we are using is InterOperability <b>Testing</b> <b>of</b> <b>protocols</b> in ATM (Asynchronous Transfer Mode) networks. Introduction In this work, we suggest compensating for incompleteness and incorrectness by integrating two modes of reasoning: constraint-based and cas [...] ...|$|E
5000|$|TTCN {{is widely}} used, for example; ETSI, ITU for the <b>testing</b> <b>of</b> {{telecommunication}} <b>protocols.</b> Conformance <b>test</b> cases <b>of</b> ETSI standards like ISDN, DECT, GSM, EDGE, 3G, DSRC {{have also been}} written in TTCN. Recently {{it has also been}} used for testing various protocol standards e.g. Bluetooth, IP.|$|R
50|$|The test beds use {{automation}} {{technologies and}} will provide {{demonstration of the}} systems functionality, communication fidelity and reliability, <b>testing</b> <b>of</b> data, <b>protocols,</b> etc. These technologies are AMI-DR models, hardware and software interfaces, software architecture, access control policies, recommended security schemes and algorithms, and desired set of optimizations.|$|R
40|$|The {{focus of}} this {{demonstrator}} is {{on the study of}} algorithms for implementing transactions on peer-to-peer networks. Their visualization contributes to the analysis and <b>test</b> <b>of</b> the <b>protocols,</b> verifying their tolerance to failures. In particular, we show a DHT running two-phase commit and the Paxos consensus algorithm. Anglai...|$|R
40|$|Multihop {{wireless}} networks, such as sensor-, ad hoc- and mesh-networks, although different {{share some}} common char-acteristics. All these networks exhibit link dynamics. Pro-tocols designed for these wireless networks must overcome {{the challenge of}} link dynamics and the resulting churn in network topology. Due to structural and topological sim-ilarities, protocols developed for one class of wireless net-work should also be applicable in the other classes. How-ever, network-layer protocols are usually developed for and tested in only one class of wireless network {{due to the lack}} of a platform that allows <b>testing</b> <b>of</b> <b>protocols</b> across different classes of networks. As a result, we unnecessarily constrain the range of settings and scenarios in which we test network protocols. In this paper, we present TinyWifi, a platform for exe-cuting native sensornet protocols on Linux-driven wireless devices. TinyWifi builds on nesC code base that abstracts from TinyOS and enables the execution of nesC-based pro-tocols in Linux. Using this abstraction, we expand the ap-plicability and means of protocol execution from one class of wireless network to another without re-implementation. We demonstrate the generality of TinyWifi by evaluating four well-established protocols on IEEE 802. 11 and 802. 15. 4 based testbeds using a single implementation...|$|E
40|$|This paper {{reports on}} QoS {{experiments}} and demonstrations {{done in the}} MB-NG and DataTAG EU projects. These are leading edge network research projects involving more that 50 researchers in the UK, Europe and North America, concerned with the development and <b>testing</b> <b>of</b> <b>protocols</b> and standards {{for the next generation}} of high speed networks. We implemented and tested the Differentiated Services Architecture (DiffServ) in a multidomain, 2. 5 Gbits/s network (the first such deployment) defining appropriate Service Level Agreements (SLAs) to be used between administrative domains to guarantee end-to-end Quality of Service. We also investigated the behaviour of DiffServ on High Bandwidth, high delay development networks connecting Europe and North America using a variety of manufacturer’s equipment. These quality of service tests also included innovative MPLS (Multi-Protocol Label Switching) experiments to establish guaranteed bandwidth connections to GRID applications in a fast and efficient way. We finally report on experiences delivering quality of Service networking to high performance applications like Particle Physics data transfer and High Performance Computation. This included implementation and development of middleware incorporated in the Globus toolkit that enables these applications to easily use these network services. I...|$|E
40|$|Syntax-based {{vulnerability}} {{testing is}} a static black-box testing method for protocol implementations. It involves testing the Implementation Under Test (IUT) {{with a large}} number of mutated Protocol Data Units (PDUs), built by intentionally disobeying the protocol’s syntax. Security vulnerabilities can be discovered by detecting anomalous behaviour or crashes in the IUT (e. g. segmentation faults, buffer, heap or stack overflows, etc.) when it attempts to parse and use a mutated PDU. Previous research has {{led to the development of}} a protocol testing framework and methodology for syntax-based <b>testing</b> <b>of</b> <b>protocols,</b> whose abstract syntax is based on ASN. 1 (Abstract Syntax Notation), and whose transfer syntax is based on BER or DER (Basic or Distinguished Encoding Rules). These protocols have syntactic structure information embedded in the PDU. However, many protocols are not specified using such standards and do not include embedded syntactic structure information. Instead the byte sequence of the data in the PDUs is specified using frame-based PDU definitions in the protocol specification. This paper presents research that extends the previous testing tools and techniques to include frame-based protocols. OSPF is such a protocol. Several well-known OSPF protocol implementations are tested for protocol vulnerabilities. Security vulnerabilities have been found in some implementations...|$|E
50|$|The PROTOS was co-operated {{project with}} VTT {{and number of}} {{industrial}} partners. The project developed different approaches <b>of</b> <b>testing</b> implementations <b>of</b> <b>protocols</b> using black-box (i.e. functional) testing methods. The goal was to support pro-active elimination of faults with information security implications, promote awareness in these issues and develop methods to support customer driven evaluation and acceptance <b>testing</b> <b>of</b> implementations. Improving the security robustness of products was attempted through supporting the development process.|$|R
40|$|This {{thesis is}} focused on <b>testing</b> <b>of</b> {{communication}} <b>protocols</b> IEC 60870 - 5 - 103 and IEC 60870 - 5 - 104. Theoretical part of the thesis describes basic principles, services and possibilities <b>of</b> both communication <b>protocols.</b> Practical part <b>of</b> the thesis deals with configuration of the IEC 60870 - 5 - 103 communication standard of protective terminal REF 630. PCVDEW 6 tool {{was used to test}} this communication <b>protocol.</b> Next part <b>of</b> the thesis {{is focused on}} convertion of the communication standard IEC 61850 to IEC 61870 - 5 - 104 using control system COM 600. The <b>testing</b> <b>of</b> both communication <b>protocols</b> was carried out in the laboratory of the protection relays on the testing panels at ABB Brno...|$|R
40|$|This thesis {{presents}} {{different methods}} <b>of</b> analyzing and <b>testing</b> <b>of</b> communication <b>protocols.</b> I have studied {{them in order}} to choose the method that is simple enough {{and at the same time}} sufficiently effective to implement and use for students of FRI. I have also implemented the method as a web application that allows a formal description <b>of</b> <b>protocol</b> analysis and implementation of logical correctness. This is fallowed by describing of how the implementation was carried out. I have chosen appropriate technologies and justified their suitability. Much time was spent for testing, so in this thesis I have described the process and the results <b>of</b> the <b>testing</b> <b>of</b> some <b>protocols.</b> I have introduced a simple test protocol with three states and a complex real protocol. As a real protocol I have chosen TCP, but I have only tested the establishment and the termination. In conclusion I have commented my creation and added some suggestions for improvements, which I will try to achieve in the future. The application is deployed on Heroku, published on GitHub ([URL] and available for users at [URL] web address...|$|R
30|$|As {{primary focus}} of this {{research}} is to investigate transport protocols in data center network topologies therefore an important category of literature review comprises various DCN architectures proposed over the last decade. The design goals for these architectures vary and broadly concern performance or efficiency improvement, data latency reduction, congestion mitigation, meeting application requirements etc. Some of the notable DCN architectures include the legacy three-tier, fat-tree, DCell, BCube etc. (Al-Fares et al. 2008; Greenberg et al. 2009 a; Guo et al. 2009). Greenberg et al. (2009 b) proposed VL 2 to improve scalability and flexibility. Guo et al. (2009) proposed BCube; a high performance server-centric architecture for DCN. Bilal et al. (2012, 2013) carried out a comparative study of three DCN architectures, one from each category; legacy, switch-based and hybrid. They selected the legacy three-tier, switch-based fat-tree and hybrid DCell architectures. They simulated these topologies using the packet level simulator NS 3 (NS- 3 2014) and compared throughput and average packet latencies. They used uniform random distribution and exponential random distribution for computing the communication pattern and traffic generation. Their results show that fat-tree architecture outperforms DCell and three-tier in terms of network throughput and average delay. We conclude that the legacy three-tier and fat-tree architectures are the most promising and widely deployed DCN architectures for implementation and <b>testing</b> <b>of</b> <b>protocols</b> and algorithms proposed for data centers.|$|E
40|$|Aquaculture {{industry}} {{depends on}} development and <b>testing</b> <b>of</b> <b>protocols</b> for rearing and breeding of new aquaculture species as these techniques vary with species. In {{the present study}} {{attempts have been made}} to study the effect oftemperature and salinity on the rate of growth ofthe marine ornamental fish, Pomacenfrus caeruleus under artificial conditions. Results reveal the length and weight of the fish to increase gradually at an average rate of 0. 10 cm and 0. 23 g with decreasing salinity (25 ppt to 5 ppt) at 258 deg;C and 6. 54 condition factor (K). Statistical oufput indicates a significant positive relationship between K at 25 Â°C and K at 30 Â°C (R= 0. 557, P> 0. 05). Correlation indicated growth rate to be higher between 25 Â°C and 30 Â°C. This is in contrast to the hypothesis which states the weight of the fish to be different at different temperatures, F (2, 54) = 5. 713, P> 0. 05. Tukey's test results indicate a significant difference in the weight of the fishes acclimatized at different temperatures. Mortality rate was highest in 20 Â°C followed by 30 Â°C while least in 25 Â°C. The incidence of diseases was highest in 20 Â°C and the acclimatization period highest in 30 Â°C. In conclusion it appears that Pomacentrus caeruleus exhibits allometric growth at lower salinities and at a controlled temperature of 25 Â°C. Â© Triveni Enterprises...|$|E
40|$|This paper {{reports on}} {{different}} {{efforts to provide}} Quality of Service (QoS) Networking to Grid Applications done {{in the context of}} the MB-NG, GRS and DataTAG EU projects. These are leading edge network research projects involving more that 50 researchers in the UK, Europe and North America, concerned with the development and <b>testing</b> <b>of</b> <b>protocols</b> and standards for the next generation of high speed networks. We have implemented and tested the Differentiated Services Architecture (DiffServ) in a multi-domain, 2. 5 Gbit/s network (the first such deployment) defining appropriate Service Level Agreements (SLAs) to be used between administrative domains to guarantee end-to-end Quality of Service. We characterised several hardware implementations of DiffServ and concluded on their appropriateness for several network scenarios. Since current and future Grid applications will have to use modified mechanisms of congestion control we have evaluated old and new TCP implementations over a Differentiated Services Networks. These quality of service tests have also included innovative MPLS (Multi-Protocol Label Switching) experiments to establish guaranteed bandwidth connections to Grid applications in a fast and efficient way. We have also developed a software based bandwidth broker architecture for Grids based on IETF standards which allows applications to transparently request dynamic and advanced reservations and implemented it in a real experimental network. We finally report on experiences delivering quality of Service networking to high performance applications like Particle Physics data transfer and High Performance Computation. This includes quantitative results on the performance improvements that QoS brought to real data transfers in the context of High Performance Computing. I...|$|E
30|$|The {{test cases}} are {{basically}} defined {{according to the}} conformance <b>test</b> <b>of</b> the communication <b>protocol,</b> for example, Flexray physical layer conformance test specification [15] for the Flexray communication system.|$|R
40|$|International audienceComplementary to {{performance}} evaluation, performance <b>testing</b> <b>of</b> communicating <b>protocols</b> is a {{qualitative and quantitative}} <b>test</b> <b>of</b> a system, aiming at checking whether performance requirements <b>of</b> <b>protocols</b> have been satisfied under certain conditions. It raises an interesting issue of accurately formalizing specified performance requirements by taking consideration of data values <b>of</b> the <b>protocol</b> messages. In this paper, we present a novel logic-based testing approach to check protocol performance requirements through real execution traces and formally specified properties. In order to evaluate and assess our methodology, we develop a prototype and present experiments through a set <b>of</b> Session Initiation <b>Protocol</b> (SIP) properties. Finally, a performance benchmark method is proposed and relevant verdicts and discussions are provide...|$|R
5000|$|Michanetzis GPA, Missirlis YF, Rhodes NP, Williams DF, Eloy R, Lemm W (2002). Influence <b>of</b> <b>test</b> <b>protocol</b> in {{determining}} the blood response to model polymers. Journal of Materials Science: Materials in Medicine 13:757-65 ...|$|R
