1215|10000|Public
25|$|Principal {{component}} regression (PCR) is {{used when}} the number of predictor variables is large, or when strong correlations exist among <b>the</b> <b>predictor</b> <b>variables.</b> This two-stage procedure first reduces <b>the</b> <b>predictor</b> <b>variables</b> using principal component analysis then uses the reduced variables in an OLS regression fit. While it often works well in practice, there is no general theoretical reason that the most informative linear function of <b>the</b> <b>predictor</b> <b>variables</b> should lie among the dominant principal components of the multivariate distribution of <b>the</b> <b>predictor</b> <b>variables.</b> The partial least squares regression is the extension of the PCR method which does not suffer from the mentioned deficiency.|$|E
25|$|Under the {{condition}} that the errors are uncorrelated with <b>the</b> <b>predictor</b> <b>variables,</b> LLSQ yields unbiased estimates, but even under that condition NLLSQ estimates are generally biased.|$|E
25|$|The arrangement, or {{probability}} distribution of <b>the</b> <b>predictor</b> <b>variables</b> x {{has a major}} influence on the precision of estimates of β. Sampling and design of experiments are highly developed subfields of statistics that provide guidance for collecting data in such a way to achieve a precise estimate of β.|$|E
30|$|In step three, {{mediation}} {{analysis was}} conducted when a <b>predictor</b> <b>variable</b> was correlated to the proposed outcome variable and another dependent variable. Mediation analysis measures {{the significance of the}} indirect effect {{and the extent to which}} the mediator variable accounts for the relationship between <b>the</b> <b>predictor</b> and <b>the</b> outcome <b>variable.</b> Mediation analysis is particularly appropriate to use when (A) <b>the</b> <b>predictor</b> <b>variable</b> is experimentally manipulated and the mediator variable measured and (B) the dynamic change in <b>the</b> <b>predictor</b> <b>variable</b> precedes <b>the</b> dynamic change in the mediator variable; and both precede the outcome variable [23, 26].|$|R
40|$|Previous {{deception}} {{research on}} repeated interviews found that liars are not less consistent than truth tellers, presumably because liars use a repeat strategy {{to be consistent}} across interviews. The goal {{of this study was}} to design an interview procedure to overcome this strategy. Innocent participants (truth tellers) and guilty participants (liars) had to convince an interviewer that they had performed several innocent activities rather than committing a mock crime. The interview focused on the innocent activities (alibi), contained specific central and peripheral questions, and was repeated after one week without forewarning. Cognitive load was increased by asking participants to reply quickly. The liars’ answers in replying to both central and peripheral questions were significantly less accurate, less consistent, and more evasive than the truth tellers’ answers. Logistic regression analyses yielded classification rates ranging from around 70 % (with consistency as <b>the</b> <b>predictor</b> <b>variable),</b> 85 % (with evasive answers as <b>the</b> <b>predictor</b> <b>variable),</b> to over 90 % (with an improved measure of consistency that incorporated evasive answers as <b>the</b> <b>predictor</b> <b>variable,</b> as well as with response accuracy as <b>the</b> <b>predictor</b> <b>variable).</b> These classification rates were higher than the interviewers’ accuracy rate (54 %) ...|$|R
5000|$|Suppose that <b>the</b> <b>predictor</b> <b>{{variable}}</b> [...] {{takes three}} values, , , or , and outcome variable [...] takes two values, [...] or [...] The table below contains observed combinations of [...] and : ...|$|R
500|$|Reiss {{concluded}} that Sexual Preference [...] "has value for suggesting directions and the likely worth of ideas", but that given its shortcomings {{there was no}} way in which its authors could definitively resolve the issues they explored, despite their claim to [...] "once and for all" [...] discredit some theoretical ideas about homosexuality. Reiss wrote that Bell et al. asked questions that were [...] "vague" [...] and [...] "open-ended", had an [...] "arbitrary and rigid conception" [...] of what could be done with their data and lacked [...] "theoretical development" [...] in its handling, and deliberately minimized the importance of <b>the</b> <b>predictor</b> <b>variables</b> they used to test psychoanalytic and other theories. He found their conclusion that sexual orientation has a biological basis unconvincing. DeLamater wrote that Sexual Preference benefited from Bell et al.′s [...] "eclectic theoretical basis", which drew from the psychodynamic model, social learning theory, sociological models that emphasize the importance of peer relationships, and labeling theory. However, while he accepted Bell et al.′s claim that their study was methodologically superior to prior work on homosexuals, he still found it problematic for many reasons and hesitated to endorse its conclusions. In his view, the path analysis involved [...] "arbitrary classification and sequencing of variables".|$|E
2500|$|Weak exogeneity. [...] This {{essentially}} {{means that}} <b>the</b> <b>predictor</b> <b>variables</b> x {{can be treated}} as fixed values, rather than random variables. [...] This means, for example, that <b>the</b> <b>predictor</b> <b>variables</b> {{are assumed to be}} error-free—that is, not contaminated with measurement errors. Although this assumption is not realistic in many settings, dropping it leads to significantly more difficult errors-in-variables models.|$|E
2500|$|The {{meaning of}} the {{expression}} [...] "held fixed" [...] may depend on how the values of <b>the</b> <b>predictor</b> <b>variables</b> arise. If the experimenter directly sets the values of <b>the</b> <b>predictor</b> <b>variables</b> {{according to a study}} design, the comparisons of interest may literally correspond to comparisons among units whose predictor variables have been [...] "held fixed" [...] by the experimenter. Alternatively, the expression [...] "held fixed" [...] can refer to a selection that takes place in the context of data analysis. In this case, we [...] "hold a variable fixed" [...] by restricting our attention to the subsets of the data that happen to have a common value for the given predictor variable. This is the only interpretation of [...] "held fixed" [...] {{that can be used in}} an observational study.|$|E
30|$|In the {{analysis}} of seasonal distribution, <b>the</b> primary <b>predictor</b> <b>variable</b> was <b>the</b> date of injury, and the primary outcome variable {{was the number of}} fracture patients. In {{the analysis}} of fracture cause, <b>the</b> primary <b>predictor</b> <b>variable</b> was <b>the</b> cause of fracture, and the primary outcome variable was the region of fracture. In {{the analysis of}} postoperative complications, <b>the</b> primary <b>predictor</b> <b>variables</b> were sex, age, diabetes mellitus, smoking, alcohol intoxication, day of the week, beginning/middle/end of the month, time from injury to treatment, duration of admission, fracture site, and fracture cause; the primary outcome variable was the occurrence of postoperative complication.|$|R
40|$|The Cox {{proportional}} hazards {{model is}} {{the most widely used}} survival prediction model for analysing time-to-event data. To measure the discrimination ability of a survival model the concordance probability index is widely used. In this work we studied and compared the performance of two different estimators of the concordance probability when a continuous <b>predictor</b> <b>variable</b> is categorised in a Cox proportional hazards regression model. In particular, we compared the c-index and the concordance probability estimator. We evaluated the empirical performance of both estimators through simulations. To categorise <b>the</b> <b>predictor</b> <b>variable</b> we propose a methodology which considers the maximal discrimination attained for the categorical variable. We applied this methodology to a cohort of patients with chronic obstructive pulmonary disease, in particular, we categorised <b>the</b> <b>predictor</b> <b>variable</b> forced expiratory volume in one second in percentage...|$|R
30|$|The Awareness and Perception {{variables}} {{showed a}} statistical significant relationship with <b>the</b> <b>predictor</b> <b>variable</b> CLAS. These {{results are not}} surprising since {{it is expected that}} upper division students would have had more experiences related to research than freshmen or sophomores.|$|R
2500|$|Errors-in-variables models (or [...] "measurement error models") {{extend the}} {{traditional}} linear regression model to allow <b>the</b> <b>predictor</b> <b>variables</b> X {{to be observed}} with error. This error causes standard estimators of β to become biased. Generally, the form of bias is an attenuation, meaning that the effects are biased toward zero.|$|E
2500|$|Linearity. [...] This {{means that}} {{the mean of the}} {{response}} variable is a linear combination of the parameters (regression coefficients) and <b>the</b> <b>predictor</b> <b>variables.</b> [...] Note that this assumption is much less restrictive than it may at first seem. [...] Because <b>the</b> <b>predictor</b> <b>variables</b> are treated as fixed values (see above), linearity is really only a restriction on the parameters. [...] <b>The</b> <b>predictor</b> <b>variables</b> themselves can be arbitrarily transformed, and in fact multiple copies of the same underlying predictor variable can be added, each one transformed differently. [...] This trick is used, for example, in polynomial regression, which uses linear regression to fit the response variable as an arbitrary polynomial function (up to a given rank) of a predictor variable. This makes linear regression an extremely powerful inference method. [...] In fact, models such as polynomial regression are often [...] "too powerful", in that they tend to overfit the data. [...] As a result, some kind of regularization must typically be used to prevent unreasonable solutions coming out of the estimation process. [...] Common examples are ridge regression and lasso regression. [...] Bayesian linear regression can also be used, which by its nature is more or less immune to the problem of overfitting. (In fact, ridge regression and lasso regression can both be viewed as [...] special cases of Bayesian linear regression, with particular types of prior distributions placed on the regression coefficients.) ...|$|E
2500|$|Standard linear {{regression}} models with standard estimation techniques make {{a number of}} assumptions about <b>the</b> <b>predictor</b> <b>variables,</b> the response variables and their relationship. [...] Numerous extensions have been developed that allow each of these assumptions to be relaxed (i.e. reduced to a weaker form), {{and in some cases}} eliminated entirely. [...] Some methods are general enough that they can relax multiple assumptions at once, and in other cases this can ns. [...] Generally these extensions make the estimation procedure more complex and time-consuming, and may also require more data in order to produce an equally precise model.|$|E
30|$|For the {{categorical}} regression analysis, {{the variables}} GEN, CLAS, ETH, and FG {{were used as}} <b>predictor</b> <b>variables.</b> <b>The</b> response variables were Experience, Awareness, Perception, and Mentoring. To answer the research question, the categorical regression models were run using SPSS CATREG. This section will present {{the results of the}} categorical regression analysis organized by <b>the</b> <b>predictor</b> <b>variable.</b>|$|R
30|$|In Model (2) of Table  4, <b>the</b> <b>predictor</b> <b>variable</b> B 1 has a {{positive}} (+) estimated coefficient β̂_B 1  =  0.514 and Z value =  4.87 ***, which is statistically significant to the response variable B 2. Sales performance creation success probability odds ratio increases 1.67 -fold when B 1 changes from the reference level B 1  =  0 to B 1  =  1 (i.e., exp(β̂_B 1) =  1.67). In Model (3), two <b>predictor</b> <b>variables</b> B 1 and B 2 are statistically significant to the response variable B 3 simultaneously. In particular, <b>the</b> <b>predictor</b> <b>variable</b> B 2 has {{a positive}} (+) estimated coefficient β̂_B 2  =  3.733, Z value =  19.79 *** and exp(β̂_B 2) =  41.79. Therefore, new employment performance creation success probability odds ratio increases drastically as much as 41.79 -fold, when B 2 changes from the reference level B 2  =  0 to B 2  =  1. Also, among <b>the</b> six <b>predictor</b> <b>variables</b> in Model (3), B 2 has the largest values of estimated coefficient, Z value and odds ratio. Even though the influence is diminished slightly compared with B 2, B 1 remains as a significant <b>predictor</b> <b>variable</b> to <b>the</b> response <b>variable</b> B 3. <b>The</b> <b>predictor</b> <b>variable</b> B 1 {{has a positive}} (+) estimated coefficient β̂_B 1  =  0.497 and Z value =  3.40 ***, and exp(β̂_B 1) =  1.64. Hence, new employment performance creation success probability is heavily sensitive to the two predecessor performance success-failure within for-profit-institutions’ GSPs. As described in detail in “Model estimation (3): performance chain” section, the performance chain structure of B 3  ← B 2  ← B 1  ← X 1 is revealed once again.|$|R
40|$|Includes bibliographical {{references}} (pages 36 - 39) An {{investigation of}} situational factors {{was made in}} order to compare the multiple linear and multiple logistic regression models. The study was performed in two phases. During the first phase, an artificially created data set was employed, while in phase two, analysis was performed on a real data set. Phase one of the study involved creation of data sets by using a logistic regression equation obtained from a previous research project for the comparative analysis of the linear model and the logistic model without any residual error. The development of the data sets allowed for investigation of several situational factors which might influence model preference. The first involved holding the parameter estimates of the logistic equations constant, while making the values of <b>the</b> <b>predictor</b> <b>variable</b> more and more extreme. The second investigation was performed in a similar fashion, except that on this occasion, <b>the</b> <b>predictor</b> <b>variable</b> values were held constant, while the parameter values were varied. The {{second phase of the}} study involved the use of a real data set, in order to compare the multiple linear and multiple logistic regression models. This data set consisted of 70 <b>predictor</b> <b>variables</b> in order to evaluate the multiple linear and multiple logistic regression models on the selected criteria. For phase one of the study, it was found for constant parameter values that as the value of <b>the</b> <b>predictor</b> <b>variable</b> became more extreme, the multiple linear model became less accurate in the criterion used to evaluate the models. This difference was even greater when all values for <b>the</b> <b>predictor</b> <b>variable</b> were extreme and of the same sign. For the situation where the values of <b>the</b> <b>predictor</b> <b>variable</b> was constant, and the value of the parameter estimate was varied, it was found that, as compared to the logistic model, the multiple linear regression model became less accurate as the value of the parameter increased. For phase two, few {{differences were found between the}} two models for most of the methods used to select subsets of <b>predictor</b> <b>variables.</b> However, one method did indicate a significant difference between the models on all designated criteria used for phase two. For subset selection using the stepwise logistic regression method, it was found for a number of criteria that the logistic model had a significantly higher level of performance than the multiple linear model. The multiple logistic model had an increase of 10...|$|R
2500|$|The {{notion of}} a [...] "unique effect" [...] is {{appealing}} when studying a complex system where multiple interrelated components influence the response variable. In some cases, it can literally be interpreted as the causal effect of an intervention that {{is linked to the}} value of a predictor variable. However, {{it has been argued that}} in many cases multiple regression analysis fails to clarify the relationships between <b>the</b> <b>predictor</b> <b>variables</b> and the response variable when the predictors are correlated with each other and are not assigned following a study design. A commonality analysis may be helpful in disentangling the shared and unique impacts of correlated independent variables.|$|E
2500|$|Lack {{of perfect}} {{multicollinearity}} in the predictors. [...] For standard least squares estimation methods, the design matrix X must have full column rank p; otherwise, {{we have a}} condition known as perfect multicollinearity in <b>the</b> <b>predictor</b> <b>variables.</b> [...] This can be triggered by having two or more perfectly correlated predictor variables (e.g. if the same predictor variable is mistakenly given twice, either without transforming one of the copies or by transforming one of the copies linearly). It can also happen if there is too little data available compared {{to the number of}} parameters to be estimated (e.g. fewer data points than regression coefficients). In the case of perfect multicollinearity, the parameter vector β will be non-identifiable—it has no unique solution. [...] At most {{we will be able to}} identify some of the parameters, i.e. narrow down its value to some linear subspace of Rp. See partial least squares regression. [...] Methods for fitting linear models with multicollinearity have been developed; some require additional assumptions such as [...] "effect sparsity"—that a large fraction of the effects are exactly zero. Note that the more computationally expensive iterated algorithms for parameter estimation, such as those used in generalized linear models, do not suffer from this problem.|$|E
2500|$|Constant {{variance}} (a.k.a. homoscedasticity). [...] This {{means that}} different {{values of the}} response variable have the same variance in their errors, regardless {{of the values of}} <b>the</b> <b>predictor</b> <b>variables.</b> In practice this assumption is invalid (i.e. the errors are heteroscedastic) if the response variable can vary over a wide scale. In order to check for heterogeneous error variance, or when a pattern of residuals violates model assumptions of homoscedasticity (error is equally variable around the 'best-fitting line' for all points of x), it is prudent to look for a [...] "fanning effect" [...] between residual error and predicted values. This is to say there will be a systematic change in the absolute or squared residuals when plotted against the predictive variables. Errors will not be evenly distributed across the regression line. Heteroscedasticity will result in the averaging over of distinguishable variances around the points to get a single variance that is inaccurately representing all the variances of the line. In effect, residuals appear clustered and spread apart on their predicted plots for larger and smaller values for points along the linear regression line, and the mean squared error for the model will be wrong. Typically, for example, a response variable whose mean is large will have a greater variance than one whose mean is small. For example, a given person whose income is predicted to be $100,000 may easily have an actual income of $80,000 or $120,000 (a standard deviation of around $20,000), while another person with a predicted income of $10,000 is unlikely to have the same $20,000 standard deviation, which would imply their actual income would vary anywhere between -$10,000 and $30,000. (In fact, as this shows, in many cases—often the same cases where the assumption of normally distributed errors fails—the variance or standard deviation should be predicted to be proportional to the mean, rather than constant.) Simple linear regression estimation methods give less precise parameter estimates and misleading inferential quantities such as standard errors when substantial heteroscedasticity is present. However, various estimation techniques (e.g. weighted least squares and heteroscedasticity-consistent standard errors) can handle heteroscedasticity in a quite general way. Bayesian linear regression techniques can also be used when the variance is assumed to be a function of the mean. It is also possible in some cases to fix the problem by applying a transformation to the response variable (e.g. fit the logarithm of the response variable using a linear regression model, which implies that the response variable has a log-normal distribution rather than a normal distribution).|$|E
40|$|The Cox proportionalhazards {{model is}} {{the most widely used}} su rvival {{prediction}} model for analysing time-to-event data. To measure the discrimination ability of a survival model the concordance probability index is widely used. In this work we studied and compared the performance of two different estimators of the concordance probability when a continuous <b>predictor</b> <b>variable</b> is cate- gorised in a Cox proportional hazards regression model. In p articular, we compared the c-index and the concordance probability estimator. We evaluated th e empirical performance of both es- timators through simulations. To categorise <b>the</b> <b>predictor</b> <b>variable</b> we propose a methodology which considers the maximal discrimination attained for th e categorical variable. We applied this methodology to a cohort of patients with chronic obstructiv e pulmonary disease, in particular, we categorised <b>the</b> <b>predictor</b> <b>variable</b> forced expiratory volu me in one second in percentagePeer Reviewe...|$|R
30|$|This section {{presents}} a comprehensive investigation on how closely the time-ordered previous and subsequent performance factors relate to one another. First, {{we try to}} identify {{the relationship between the}} response variable B 2 and <b>the</b> <b>predictor</b> <b>variable</b> B 1 in Model (2) of Table  3. <b>The</b> <b>predictor</b> <b>variable</b> B 1 has a positive (+) estimated coefficient β̂_B 1  =  0.376 and Z value =  3.79 ***, which is statistically significant to the response variable B 2. Sales performance creation success probability odds ratio increases 1.46 -fold when B 1 changes from the reference level B 1  =  0 to B 1  =  1 (i.e., exp(β̂_B 1) =  1.46). Thus, a higher sales performance creation success probability is detected when an observation creates patent registration performance in advance.|$|R
40|$|The {{objective}} {{of this study is}} to identify can waste into three types based on the images by using a probability approach of trinomial distribution in term regression. <b>Predictor</b> <b>variables</b> considered are <b>the</b> color intensity of red, green, and blue of the images taken at the top, down, and side pose successively. From an independence test between each of <b>the</b> <b>predictor</b> <b>variable</b> and can waste type noted that only the color intensity of red which the image taken at top pose that does not correspond to the can waste types. Based on the Nagelkerke value is found that the variance of <b>the</b> <b>predictor</b> <b>variable</b> data in identifying the can waste type is able to explain the variance of the types of 59. 1 percent. The final model show that <b>the</b> significant <b>predictor</b> <b>variables</b> are <b>the</b> colors intensity of green and blue which the image taken at the top pose, the color intensity of red which the image taken at down pose, and the color intensity of red, green and blue which the image taken at side pose successively. The model can identify cans waste into three types based on the images correctly by 73. 13 %...|$|R
5000|$|Principal {{component}} regression (PCR) is {{used when}} the number of predictor variables is large, or when strong correlations exist among <b>the</b> <b>predictor</b> <b>variables.</b> This two-stage procedure first reduces <b>the</b> <b>predictor</b> <b>variables</b> using principal component analysis then uses the reduced variables in an OLS regression fit. While it often works well in practice, there is no general theoretical reason that the most informative linear function of <b>the</b> <b>predictor</b> <b>variables</b> should lie among the dominant principal components of the multivariate distribution of <b>the</b> <b>predictor</b> <b>variables.</b> The partial least squares regression is the extension of the PCR method which does not suffer from the mentioned deficiency.|$|E
5000|$|If all <b>the</b> <b>predictor</b> <b>variables</b> are uncorrelated, {{the matrix}} [...] is the {{identity}} matrix and [...] simply equals , {{the sum of}} the squared correlations with the dependent variable. If <b>the</b> <b>predictor</b> <b>variables</b> are correlated among themselves, the inverse of the correlation matrix [...] accounts for this.|$|E
50|$|Weak exogeneity. This {{essentially}} {{means that}} <b>the</b> <b>predictor</b> <b>variables</b> x {{can be treated}} as fixed values, rather than random variables. This means, for example, that <b>the</b> <b>predictor</b> <b>variables</b> {{are assumed to be}} error-free—that is, not contaminated with measurement errors. Although this assumption is not realistic in many settings, dropping it leads to significantly more difficult errors-in-variables models.|$|E
40|$|The {{argument}} {{proposed by}} Wason et al. that {{the conversion of}} magnitudes from a scale (e. g. Ms or mb) to another (e. g. Mw), using the coefficients computed by the general orthogonal regression method (Fuller) is biased if the observed values of <b>the</b> <b>predictor</b> (independent) <b>variable</b> {{are used in the}} equation as well as the methodology they suggest to estimate the supposedly true values of <b>the</b> <b>predictor</b> <b>variable</b> are wrong for a number of theoretical and empirical reasons. Hence, we advise against the use of such methodology for magnitude conversions...|$|R
30|$|This {{analysis}} used a {{logistic regression}} predicting {{the proportion of}} trials where a participant selected a particular method from a <b>predictor</b> <b>variable</b> coding whether that method was horizontal or reductive. The regression included a random effect of subject on the slope of <b>the</b> <b>predictor</b> <b>variable</b> to account for repeated trials per subject. B =  0.40, SE =  0.07, z =  5.65, p < . 001.|$|R
30|$|When {{looking at}} gender as a {{predictor}} of UREs, data analysis indicates that gender was not a predictor of any of the response variables in this study. However, when looking at the individual coefficient score of GEN and Perception, GEN had the second highest beta coefficient score of 0.490 in the model with a p value of 0.078. The beta value indicates how much change (measured by standard deviation) in <b>the</b> <b>predictor</b> <b>variable</b> is produced by a change in each of the response variables when others remain constant. In categorical regression, the beta value is interpreted as the difference in the predicted value of <b>the</b> <b>predictor</b> <b>variable</b> for each one-unit difference in each response variable when others remain constant. Given these results, a crosstab analysis was deemed appropriate to explore any emergent relationships among the variables.|$|R
50|$|Under the {{condition}} that the errors are uncorrelated with <b>the</b> <b>predictor</b> <b>variables,</b> LLSQ yields unbiased estimates, but even under that condition NLLSQ estimates are generally biased.|$|E
5000|$|The Cox model {{extends the}} logrank test by {{allowing}} the inclusion of additional covariates.This example use the melanom data set where <b>the</b> <b>predictor</b> <b>variables</b> include a continuous covariate, {{the thickness of the}} tumor (variable name = “thick”) ...|$|E
5000|$|The {{choice of}} {{when to stop}} the {{algorithm}} is arbitrary {{and it is hard}} to know a priori how long reaching a specific convergence threshold will take. Also, the final model depends on the order in which <b>the</b> <b>predictor</b> <b>variables</b> [...] are fit.|$|E
40|$|In {{a sample}} of 85 subjects, divided into two {{sub-samples}} (55 boys, 30 girls),there were measured 11 anthropometric variables and assessment of one motoric test. The aim of theresearch {{was to determine the}} relation of morphological characteristics with the factor for excitation duration of the motoricunits, manifested with the motoric variableEndurance in pull-ups. Based on the results of the linear regression analysis for the boys,it can be concluded that <b>the</b> <b>predictor</b> <b>variable</b> system shows a statistically significant effect on the criterion at the value of the coefficient of multiple correlation R= 0. 717 which explained 51. 3 % of the common variance with the criterion. The values of the standardized regression coefficients Beta for the boys indicate that <b>the</b> <b>predictor</b> <b>variable</b> Body height has a statistically significantly positive effect on the criterion, while the variables: Arm length and Shoulder width have a statistically significantly negative effect on the criterion variable. For the girlsthere was not determined statistically significant effect of <b>the</b> <b>predictor</b> system with <b>the</b> criterion...|$|R
5000|$|In {{the case}} where <b>the</b> {{independent}} (<b>predictor)</b> <b>variable</b> [...] is [...] and the dependent (outcome) variable is binary, Somers’ D equals ...|$|R
30|$|There are {{a number}} of {{differences}} between their analytic strategy and ours, aside from their use of IV. In particular, they employ data from the full age distribution, use the average of the plausible values as <b>the</b> <b>predictor</b> <b>variable,</b> and appear to use least squares (rather than logistic regression) for fitting a model with a dichotomous outcome.|$|R
