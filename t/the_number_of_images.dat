557|10000|Public
25|$|Two very {{important}} daguerreotypes (an early photographic process) were purchased in the 1990s. The first was of African American abolitionist and former slave Frederick Douglass, acquired in 1990. It {{is one of}} only four daguerreotypes of Douglass known to exist. That year, <b>the</b> <b>number</b> <b>of</b> <b>images</b> in the museum's photography collection reached 8,500 objects. Six years later, the NPG obtained for $115,000 the earliest known daguerreotype of abolitionist John Brown, whose 1859 raid on Harpers Ferry helped sparked the Civil War. The portrait was created by African American photographer Augustus Washington.|$|E
2500|$|Over {{the next}} 15 days, the school {{district}} captured at least 210 webcam photos and 218 screenshots. [...] They included photos inside his home of Robbins sleeping and of him partially undressed, as well as photos of his father. [...] The district also snapped images of Robbins' instant messages and video chats with his friends, {{and sent them to}} its servers. [...] Those 429 images, however, only reflected <b>the</b> <b>number</b> <b>of</b> <b>images</b> later recovered—during the ensuing litigation the district conceded it had been unable to recover a week's worth of images that it had taken. [...] " ...|$|E
2500|$|In 2007, the British-based Internet Watch Foundation {{reported}} that child pornography on the Internet {{is becoming more}} brutal and graphic, and <b>the</b> <b>number</b> <b>of</b> <b>images</b> depicting violent abuse has risen fourfold since 2003. The CEO stated [...] "The worrying issue is the severity and {{the gravity of the}} images is increasing. We're talking about prepubescent children being raped." [...] About 80 percent {{of the children in the}} abusive images are female, and 91 percent appear to be children under the age of 12. Prosecution is difficult because multiple international servers are used, sometimes to transmit the images in fragments to evade the law. Some child pornographers also circumvent detection by using viruses to illegally gain control of computers on which they remotely store child pornography. In one case, a Massachusetts man was charged with possession of child pornography when hackers used his computer to access pornographic sites and store pornographic pictures without his knowledge. The U.S. Court of Appeals for the Tenth Circuit has ruled that if a user downloads child pornography from a file sharing network and possesses it in his [...] "shared folder" [...] without configuring the software to not share that content, he can be charged with distributing child pornography.|$|E
3000|$|... is <b>the</b> <b>number</b> <b>of</b> <b>imaged</b> {{proteins}} with height h, and N is <b>the</b> total <b>number</b> <b>of</b> <b>imaged</b> proteins. <b>The</b> calculation {{was carried}} out using a step of 0.2 nm.|$|R
3000|$|... by {{adjusting}} <b>the</b> <b>number</b> <b>of</b> data points, which is <b>the</b> <b>number</b> <b>of</b> <b>image</b> blocks by random sampling in our case, and the distortion rate [...]...|$|R
50|$|The design {{decision}} to reduce <b>the</b> <b>number</b> <b>of</b> <b>image</b> pixels from 144 to 100 to lower cost resulted in Optacon II not being successful.|$|R
5000|$|... where [...] is {{the average}} area of the object, in pixels, and [...] is <b>the</b> <b>number</b> <b>of</b> <b>images.</b> Now the value is not {{affected}} by <b>the</b> <b>number</b> <b>of</b> <b>images</b> in the sequence or {{the size of the}} object.|$|E
5000|$|... #Caption: Bar Chart {{created from}} <b>the</b> <b>number</b> <b>of</b> <b>images</b> posted on www.vinylengine.com galleries, per manufacturer.|$|E
5000|$|... where [...] is {{the average}} area of the object, in pixels, and [...] is <b>the</b> <b>number</b> <b>of</b> <b>images.</b>|$|E
50|$|Specialized search engines, like in {{the fields}} <b>of</b> <b>image</b> search, are among the fastest growing search {{services}} on the internet. In 2005 alone <b>the</b> <b>number</b> <b>of</b> <b>image</b> searches increased by 91% (Nielsen/NetRatings 2006-03-31).|$|R
3000|$|... where I{{relevant}} is <b>the</b> total <b>number</b> <b>of</b> relevant <b>images,</b> and Iretrieved is <b>the</b> total <b>number</b> <b>of</b> retrieved <b>images.</b>|$|R
3000|$|... is {{employed}} to represent correlation between two images where ρ(x, y) is a correlation coefficient (CC) between x and y, X {{is an image}} 1, Y is an image 2, and K is <b>the</b> <b>number</b> <b>of</b> <b>image</b> bits.|$|R
50|$|In a Rosetta Stone Language Learning exercise, {{the student}} pairs sound or text {{to one of}} several images. <b>The</b> <b>number</b> <b>of</b> <b>images</b> per screen varies.|$|E
5000|$|The Boolean mode {{function}} [...] of {{the table}} occurs {{when the number of}} 1 entries is larger than half of <b>the</b> <b>number</b> <b>of</b> <b>images</b> such that ...|$|E
5000|$|This {{means that}} [...] <b>The</b> <b>number</b> <b>of</b> <b>images</b> used for {{training}} must {{be less than}} or equal to 30, which is not sufficient for all purposes.|$|E
30|$|The future {{research}} {{will focus on}} developing our segmentation algorithm so as to include the texture feature along with the color feature and reducing the algorithm complexity at O(n log n), where n represents <b>the</b> <b>number</b> <b>of</b> <b>image</b> pixels.|$|R
30|$|Finally, spatial {{filtering}} step requires (4 + (2 K + 1) 2)L additions, 6 L subtractions, 3 L divisions and 4 L multiplications per image, locations, where K is the window size and L is <b>the</b> <b>number</b> <b>of</b> <b>image</b> pixels.|$|R
50|$|Some of {{the steps}} present in the two-pass {{algorithm}} can be merged for efficiency, allowing for a single sweep through the image. Multi-pass algorithms also exist, some of which run in linear time relative to <b>the</b> <b>number</b> <b>of</b> <b>image</b> pixels.|$|R
5000|$|The {{total cost}} of {{operations}} correlates strongly to {{the total number of}} different images, not the total number of computers. To minimize <b>the</b> <b>number</b> <b>of</b> <b>images</b> requires additional discipline: ...|$|E
5000|$|... where [...] {{is again}} <b>the</b> <b>number</b> <b>of</b> <b>images</b> in the sequence, and [...] is the {{intensity}} of the pixel at the point [...] on the unit disc mapped from image [...]|$|E
50|$|Some avatars are animated, {{consisting}} of a sequence of multiple images played repeatedly. In such animated avatars, <b>the</b> <b>number</b> <b>of</b> <b>images</b> {{as well as the}} time in which they are replayed vary considerably.|$|E
40|$|Copyright © 2013 Jin Iwazawa et al. This is an {{open access}} article {{distributed}} under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Purpose. To compare <b>the</b> <b>number</b> <b>of</b> <b>image</b> acquisitions and procedural time required for transarterial chemoembolization (TACE) with and without tumor-feeder detection software in cases of hepatocellular carcinoma (HCC). Materials and Methods. We retrospectively reviewed 50 cases involving software-assisted TACE (September 2011 –February 2013) and 84 cases involving TACE without software assistance (January 2010 –August 2011). We compared <b>the</b> <b>number</b> <b>of</b> <b>image</b> acquisitions, <b>the</b> overall procedural time, and the therapeutic efficacy in both groups. Results. Angiography acquisition per session reduced from 6. 6 times to 4. 6 times with software assistance...|$|R
30|$|However, the {{estimation}} of A and t is non-trivial. In particular, since t varies spatially according to the scene depth, <b>the</b> <b>number</b> <b>of</b> unknowns is equivalent to <b>the</b> <b>number</b> <b>of</b> <b>image</b> pixels. Thus, a direct estimation of t from I is prohibitive without any prior knowledge or assumptions.|$|R
30|$|Female {{breast cancer}} is a common cause of cancer-related deaths in women, {{especially}} in western countries and where statistics are available. Mammographic images are hard to interpret because of the textural morphology information complexity of the breast and <b>the</b> <b>number</b> <b>of</b> <b>image</b> parameters that affect the acquisition of mammograms [1].|$|R
5000|$|The object-part {{score for}} a {{candidate}} label is [...] where [...] and [...] are <b>the</b> <b>number</b> <b>of</b> <b>images</b> in [...] and , respectively, and [...] is a concentration parameter. The authors of LabelMe use [...]|$|E
5000|$|... where [...] and [...] {{are again}} the {{dimensions}} of the image, [...] is <b>the</b> <b>number</b> <b>of</b> <b>images</b> in the sequence, and [...] is the intensity of the pixel at the point [...] in image [...]|$|E
5000|$|Noiseware is {{described}} as [...] "self learning", meaning it improves with <b>the</b> <b>number</b> <b>of</b> <b>images</b> it sees, does not rely on camera profiles, and is not limited only to cameras known {{at the time of}} its release.|$|E
30|$|PC is {{less than}} or equal to <b>the</b> <b>number</b> <b>of</b> {{demonstration}} <b>images.</b>|$|R
50|$|<b>The</b> {{official}} <b>number</b> <b>of</b> <b>images</b> was 1363, but including variations around 2000 stamps are known.|$|R
40|$|The {{absorption}} {{of the light}} by sea water and light scattering by small particles of underwater environment has become an obstacle of underwater vision researches with camera. It gives impact to the limitation of visibility distances camera in the sea water. The research of 3 D reconstruction requires image matching technique {{to find out the}} keypoints <b>of</b> <b>image</b> pairs. SIFT is one <b>of</b> the <b>image</b> matching technique where the quality <b>of</b> <b>image</b> matching depends on the quality <b>of</b> the <b>image.</b> This research proposed HSV conversion image with auto level color correction to increase <b>the</b> <b>number</b> <b>of</b> SIFT <b>image</b> matching. <b>The</b> experimental results show <b>the</b> <b>number</b> <b>of</b> <b>image</b> matching is increase until 4...|$|R
50|$|The {{range of}} {{deliverables}} that a wedding photographer presents is varied. There is no standard {{as to what}} is included in a wedding coverage or package, so products vary regionally and from across photographers, as do <b>the</b> <b>number</b> <b>of</b> <b>images</b> provided.|$|E
50|$|The service {{partners}} with SmugMug to display contents in their default collections. Users {{may be able}} to customize their display settings such as <b>the</b> <b>number</b> <b>of</b> <b>images,</b> the display order, when the images are published, and the content's expiry date.|$|E
50|$|As an {{incentive}} to increase coverage, participants are awarded a point each time they contribute the first photograph classified as a geograph to a grid square.There is, however, no limit to <b>the</b> <b>number</b> <b>of</b> <b>images</b> per square, and some squares have over 1000 images.|$|E
40|$|We {{introduce}} a new method to automatically annotate and retrieve images using a vocabulary <b>of</b> <b>image</b> semantics. Our main contribution resides {{in the use of}} a hierarchical description of the density of each <b>of</b> the <b>image</b> classes in the database of classes. This method {{has been shown to be}} well suited to problems involving large databases where groups <b>of</b> <b>images</b> can be combined into higher-level groups. Compared to current methods <b>of</b> <b>image</b> annotation and retrieval, ours has a significantly smaller time complexity for a better recognition performance. Specifically, the recognition complexity of our system is O(CxR), where C is <b>the</b> <b>number</b> <b>of</b> classes (or <b>image</b> annotations) and R is <b>the</b> <b>number</b> <b>of</b> <b>image</b> regions, while <b>the</b> best results in the literature are with a system that has complexity O(TxR), where T is <b>the</b> <b>number</b> <b>of</b> training <b>images.</b> Since <b>the</b> <b>number</b> <b>of</b> classes grows substantially slower than <b>the</b> <b>number</b> <b>of</b> training <b>images,</b> our method not only scales better for larger data set, but it also processes a test image faster. We show comparisons in terms of complexity, time, and recognition performance with the state-of-the-art methods proposed in the literature. The results illustrate that our system has a superior performance in terms of recognition accuracy for significantly smaller time complexity. Autho...|$|R
30|$|We stress {{again that}} (i) <b>the</b> <b>number</b> <b>of</b> <b>image</b> pixels used to embed the {{watermark}} signal samples, and (ii) their {{locations in the}} original image can be chosen arbitrarily. Indeed, we can choose to embed all image pixels by just selecting an equal <b>number</b> <b>of</b> samples for <b>the</b> watermark signal. However, this <b>number</b> and <b>the</b> corresponding pixels locations used must be known to the legal user of the data.|$|R
40|$|We {{introduce}} a new method to automatically annotate and retrieve images using a vocabulary <b>of</b> <b>image</b> semantics. The novel contributions include a discriminant formulation of the problem, a multiple instance learning solution that enables the estimation of concept probability distributions without prior image segmentation, and a hierarchical description of the density <b>of</b> each <b>image</b> class that enables very efficient training. Compared to current methods <b>of</b> <b>image</b> annotation and retrieval, the one now proposed has significantly smaller time complexity and better recognition performance. Specifically, its recognition complexity is O(C×R), where C is <b>the</b> <b>number</b> <b>of</b> classes (or <b>image</b> annotations) and R is <b>the</b> <b>number</b> <b>of</b> <b>image</b> regions, while <b>the</b> best results in the literature have complexity O(T×R), where T is <b>the</b> <b>number</b> <b>of</b> training <b>images.</b> Since <b>the</b> <b>number</b> <b>of</b> classes grows substantially slower than that <b>of</b> training <b>images,</b> the proposed method scales better during training, and processes test images faster This is illustrated through comparisons in terms of complexity, time, and recognition performance with current state-of-the-art methods. Gustavo Carneiro, Nuno Vasconcelo...|$|R
