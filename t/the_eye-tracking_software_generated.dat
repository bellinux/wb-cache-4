0|2282|Public
50|$|Some systems rely on {{a camera}} module on a {{rotating}} base that is mounted on the dashboard inside the cab. The device has a large field of view to accommodate operator head movements. <b>The</b> equipment uses <b>eye-tracking</b> <b>software</b> with a structured illumination approach {{that depends on the}} high contrast between the pupils and the face to identify and track the operator's pupils.|$|R
40|$|University of Minnesota M. S. thesis. August 2011. Major: Dentistry. Advisor: Brent Larson. 1 {{computer}} file (PDF); iv, 36 pages. Introduction: Panoramic images {{are an important}} part of a patient’s dental and orthodontic record. They provide broad coverage and are a valuable screening tool for potential abnormalities and normal dental development. Dental students learn much about panoramic image anatomy during dental school but are not usually taught a systematic method of image interpretation. The use of an eye-tracker will allow visualization and statistical analysis of interpretation method to find differences between newer and experienced clinicians. Information gathered can be used to recommend an interpretation method to newer clinicians as they begin their dental career. Methods and Materials: Two groups of clinicians were created: ten clinicians with more than five years clinical experience (experienced clinicians) and ten clinicians with five years or less experience (newer clinicians). Five panoramic images, three which contained no significant findings and two which had significant findings, were used in the study. An eye-tracker and <b>the</b> <b>eye-tracking</b> <b>software</b> were used to record and evaluate the interpretation methods to find differences between the groups. Results: Newer clinician’s interpretation path entered more areas of pathology or abnormality in portions of the image other than the dentition. Areas of abnormality or pathology within the dentition were entered equally by the interpretations paths of both groups. Newer clinicians had longer interpretation times and their interpretations included more fixation points and covered more image area. Experienced clinicians were quicker with interpretation and showed more of an interpretation pattern. Conclusions: Newer clinicians are more complete (interpret the entire image), have more fixation points and spend longer time interpreting. Newer clinicians often had no pattern to interpretation, but had interpretation paths which entered areas of pathology or abnormality due to completeness of interpretation. Experienced clinicians showed much more pattern (systematic approach) to interpretation, but were less complete. In both groups, interpretations times were significantly longer when the entire image was interpreted...|$|R
40|$|Thesis by publication. Bibliography: pages 192 - 211. Chapter 1. Introduction to {{the thesis}} [...] Chapter 2. The first paper [...] Chapter 3. The second paper [...] Chapter 4. The third paper [...] Chpater 5. Thesis conclusion. In the marketplace, {{advertising}} clutter {{refers to the}} high volume of advertising consumers are exposed to daily. This high quantity of advertisements has negative effects on unfamiliar brands which always face difficulties competing with other more familiar brands from the same product category. This thesis shows that unfamiliar brands {{have to work harder}} to overcome advertising clutter. Many academic researchers and marketers find that advertising creativity is an important strategic tool that should be considered when trying to attract consumer attention, increase advertisement and brand liking, and improve advertisement and brand memory. Thus, the thesis investigates “does advertising creativity overcome clutter?” and measuring that effects on attention, affect, and memory. This thesis includes one theoretical and two experimental papers to address the effects of advertising creativity on brand familiarity and competitive advertising interference. It also uses eye-tracking techniques to measure attention. The experiments were designed as realistic experiments, one session time, using a within subjects design. Participants were exposed to a digital magazine which was designed into <b>the</b> <b>eye-tracking</b> <b>software.</b> <b>The</b> ads in this magazine included 24 advertisements which were manipulated to be attributed to both familiar and unfamiliar brands. Of these, eight were highly creative advertisements which won major advertising creativity competitions. Eight control and eight interference advertisements were also selected. A pre-test identified familiar and unfamiliar brands. The data were analysed by using GLM models for attention and affect and also logistic regression models for memory. Four dependent variables used to measure attention, which are total fixation duration toward the advertisement, total fixation duration toward brands, non-fixation duration toward the advertisement, and non- fixation duration toward brands. Memory measures were advertisement recall, brand recall, advertisement recognition, and brand recognition. The results show that advertising creativity for familiar brands has a negative influence on brand affect and brand recognition. However, advertising creativity enhances visual attention for the advertisements of unfamiliar brands, and it also improves affect toward the ad, affect toward the brand and brand recognition for most situations. In addition, brand familiarity moderates the effect of creativity on ad recognition. Creativity enhanced ad recognition more for unfamiliar brands than familiar brands. And there were no significant effects of creativity on either ad or brand recall. The results also show that attention has a strong relationship with affect and memory. And attention itself was influenced by proactive competitive interference. However, competitive advertising interference has no significant effects on affect toward the ad. And there was negative effects of interference on affect toward the brand. The effects of competitive advertising interference on memory was positive in most conditions. Each paper provides implication and future research suggestions. And the thesis conclusion chapter includes implications and future research for both academic and practitioner research. Mode of access: World wide web 1 online resource (v, 312 pages) colour illustration...|$|R
5000|$|The EyeWriter <b>{{software}}</b> {{consist of}} <b>eye-tracking</b> <b>software,</b> and a drawing software {{that allows a}} user to draw with the movement of their eye. The source code for the EyeWriter software is an open source code with an Artistic/GPL License. The software for both parts has been developed using openframeworks, a cross platform C++ library for creative development. Eyewriter 2.0 {{led to the development}} of Livewriter to be used in the 2010 Cinekid festival. In addition to Eyewriter's original parameters, a robot arm was integrated allowing the physical recording of visually created content.|$|R
40|$|This study {{proposes a}} novel {{approach}} to measure the contractile force of eye blink that is generally obtained from the orbicularis oculi activity through Ocular ElectroMyo-Graphy (O-EMG). Here, O-EMG is compared with the eye information acquired through a wearable head-mounted eye-tracking system in order to investigate {{the possibility of using}} <b>the</b> <b>eye-tracking</b> in place of the O-EMG. Eight subjects were simultaneously monitored through an O-EMG and the eye-tracker while they were performing a structured protocol implying a variation in the blink contractile strength. Results showed that eye-tracking features were able to statistically discriminate three kinds of contractile forces similarly to EMG features. The consequent correlation analysis revealed that all the EMG-related features were significantly correlated with <b>the</b> <b>eye-tracking</b> ones with a p-value < 10 - 6. Moreover, considering <b>the</b> extracted <b>eye-tracking</b> features, i. e. Integrated Gaze Path (IGP) and Eye-closed Duration (ECD), IGP reported a higher Spearman's correlation values with eye-blink reflex magnitude (EBM) than ECD. These encouraging results suggest that the ocular information extracted from <b>the</b> <b>eye-tracking</b> could be profitably used in non-invasive ecological environments where wearability and comfortability {{play a crucial role in}} detecting spontaneous response...|$|R
40|$|There {{has been}} an {{exponential}} growth in eye research and concomitant use of <b>eye-tracking</b> methodologies in <b>the</b> last decade. Improvements in eye-tracking technologies, enhancements in <b>the</b> sophistication of <b>eye-tracking</b> data analysis <b>software</b> {{and the development of}} smaller, more portable and mobile eye trackers has immeasurably increased the range and volume of applications. Komorgortsev (2011), using Google Scholar, has demonstrated that eye-tracking-based research publications had reached over 2000 articles and papers in 2011...|$|R
30|$|Before {{beginning}} <b>the</b> <b>eye-tracking</b> tasks, {{participants completed}} a demographics questionnaire that included age, gender, handedness, ethnicity, foreign language knowledge, occupational history, educational history, marital status, health status, {{and level of}} typical physical activity.|$|R
5000|$|The <b>software</b> <b>generates</b> {{remedial}} problems (for {{practice with}} a difficult problem).|$|R
40|$|This study {{provides}} a methodology {{to quantify the}} qualities of visual aesthetics in product design by applying <b>eye-tracking</b> technology. <b>The</b> output data of <b>eye-tracking</b> <b>software,</b> consisting of number, duration, and coordinate of eye fixations, are formulated using the fundamental constituent factors of beauty and attractiveness. This methodology has been developed by conducting three eye-tracking experiments and five experiments applying subjective measures which in total more than 300 participants attended. The results of these experiments contributed {{to the development of}} an aesthetic formula. The output of this formula was then compared with the declared preferences of a further 200 subjects. This comparison confirmed that the proposed methodology was capable of quantifying and predicting aesthetic preference by only monitoring eye behaviour...|$|R
40|$|The aim of {{the paper}} is to present the {{possibilities}} of extending the „intelligence” of financial analysissystems designed for managers of {{small and medium-sized enterprises}} (SMEs). The paper first presentsthe question of obtaining analytical information which is essential for supporting managerial decisions,particularly with regard to SMEs. Next, the nature and use of ontologies as well as eye-tracking in modelingmanagerial knowledge in respect of financial analysis are discussed. In the last section the authorsdepict a research experiment that was conducted using eye-tracking, focusing on technical terms, contentand knowledge that can be obtained thanks to this study. In the research experimental methodology wasapplied based on actual financial data, using the Bilander’s BINOCLE and <b>eye-tracking</b> <b>software</b> TobiiStudioTM by Tobii...|$|R
50|$|Utmost III SPICE {{modeling}} <b>software</b> <b>generates</b> SPICE {{models for}} analog, digital, mixed-signal, and RF applications.|$|R
40|$|Analysis of eye {{movements}} {{recorded with}} a mobile eye-tracker is difficult since <b>the</b> <b>eye-tracking</b> data are severely affected by simultaneous head and body movements. Automatic analysis methods developed for remote-, and tower-mounted eye-trackers {{do not take}} this into account and are therefore not suitable to use for data where also head- and body movements are present. As a result, data recorded with a mobile eye-tracker are often analyzed manually. In this work, we investigate how simultaneous recordings of eye- and head movements can be employed to isolate {{the motion of the}} eye in <b>the</b> <b>eye-tracking</b> data. We recorded eye-in-head movements with a mobile eye-tracker and head movements with an Inertial Measurement Unit (IMU). Preliminary results show that by compensating <b>the</b> <b>eye-tracking</b> data with <b>the</b> estimated head orientation, the standard deviation of the data during vestibular-ocular reflex (VOR) eye movements, was reduced from 8. 0 to 0. 9 in the vertical direction and from 12. 9 to 0. 6 in the horizontal direction. This suggests that a head compensation algorithm based on IMU data can be used to isolate the movements of the eye and therefore simplify the analysis of data recorded using a mobile eye-tracker...|$|R
40|$|Supporting information: Control studies Control study 1 : Effects of task {{order on}} infant visual {{preferences}} (<b>eye-tracking</b> only). In <b>the</b> main study <b>the</b> <b>eye-tracking</b> task was always performed after the ERP task. To {{control for the}} effects of presentation order on <b>the</b> <b>eye-tracking</b> results we also tested an additional nine infants (4 boys, mean age 30. 1 wks) solely in the eye-tracker. We compared <b>the</b> <b>eye-tracking</b> data from both main and control studies in a two-way mixed-model ANOVA with Group (2 levels: main, control) x Condition (4 levels: VbaAba, VgaAga, VbaAga, VgaAba) as factors. The analysis did not yield any significant effect of group (F(1, 24) =. 04; p= [...] 85), or Group x Condition interaction (F(3, 72) =. 10; p=. 96). Control study 2 : Auditory speech sounds only (ERP study). This control study with 6 infants (3 boys, mean age 29. 3 wks) was carried out in order to examine how much of the ERP amplitude {{can be explained by the}} auditory potentials and how much by the visual evoked potentials. The same audiovisual stimuli in an identical to the main study paradigm were presented to the infant...|$|R
5000|$|Some {{media player}} <b>software</b> <b>generates</b> {{animated}} imagery or music visualization {{based on a}} piece of recorded music: ...|$|R
5000|$|Reporting <b>software</b> <b>generates</b> {{aggregated}} {{views of}} data to keep the management informed {{about the state of}} their business.|$|R
40|$|As {{the number}} of Internet users rapidly increases, the {{importance}} of understanding how individuals view an interface display is becoming increasingly important. In this study, <b>eye-tracking</b> <b>software</b> is utilized to examine the differences of cognitive style (Verbalizes and Visualizers) on search time and memory while viewing text and image stimuli of two different layouts. In addition, this study aims to test Nielsen’s (2006) F-pattern theory for both Verbalizers and Visualizers. Results showed {{that there was no}} difference between Verbalizers and Visualizers in terms of search task time or memory regardless of text vs. image or grid vs. block. Results also confirmed Nielsen’s (2006) F-pattern theory by indicating that Verbalizers and Visualizers both spend the majority of time in the F-shaped zone of text stimuli located near the top left corner of the visual display...|$|R
40|$|Survey {{researchers}} since Cannell {{have worried}} that respondents may take various shortcuts {{to reduce the}} effort needed to complete a survey. The evidence for such shortcuts is often indirect. For instance, preferences for earlier versus later response options have been interpreted as evidence that respondents do not read beyond the first few options. This is really only a hypothesis, however, that is not supported by direct evidence regarding the allocation of respondent attention. In the current study, we used a new method to more directly observe what respondents do and do not look at by recording their eye movements while they answered questions in a Web survey. <b>The</b> <b>eye-tracking</b> data indicate that respondents do in fact spend more time looking at the first few options in a list of response options than those {{at the end of}} the list; this helps explain their tendency to select the options presented first regardless of their content. In addition, <b>the</b> <b>eye-tracking</b> data reveal that respondents are reluctant to invest effort in reading definitions of survey concepts that are only a mouse click away or paying attention to initially hidden response options. It is clear from <b>the</b> <b>eye-tracking</b> data that some respondents are more prone to these and other cognitive shortcuts than others, providing relatively direct evidence for what had been suspected based on more conventional measures...|$|R
5000|$|Tanenhaus used <b>eye-tracking</b> <b>software</b> and {{hardware}} {{to record the}} movement of the subjects' eyes as they listened to phrases and manipulated objects in a scene. For critical stimuli, Tanenhaus used phrases that contained syntactic ambiguities, such as [...] "Put the apple on the towel in the box," [...] where the prepositional phrase [...] "on the towel" [...] is initially ambiguous between being a modifier (indicating which apple) or a goal (indicating where to put the apple). [...] "Put the apple that's on the towel in the box" [...] served as the control condition because [...] "that's" [...] signals that [...] "on the towel" [...] is unambiguously a modifier. Similar syntactic ambiguities had been used to provide evidence for modularity within syntactic processing. Tanenhaus speculated that a visual context could be just enough to influence the resolution of these ambiguities.|$|R
40|$|AbstractObjectiveMany preterm {{children}} show {{difficulties in}} attention at (pre) school age. The development of attention capacities of preterm and term toddlers was compared using a longitudinal and multi-method approach at 12, 18 and 24 months. MethodAttention was measured for 123 preterm (32 – 36 weeks gestation) and 101 term born children, using eye tracking (18 months), observations during mother–child interaction (18 months), and mother-reports (12, 18, and 24 months). ResultsPreterm toddlers had lower scores than term children on <b>the</b> <b>eye-tracking</b> measures of orienting and alerting. No group {{differences were found}} with observations, mother-reports, and <b>the</b> <b>eye-tracking</b> measure of executive attention. More preterm than term children had suboptimal scores on measures of the alerting system at 18 months, possibly indicating difficulties in attention development. ConclusionPreterm children showed an increased risk for suboptimal functioning in alerting attention capacities, as early as at a toddler age...|$|R
25|$|Media {{development}} <b>software</b> <b>generates</b> {{print and}} electronic media {{for others to}} consume, most often in a commercial or educational setting. These produce graphics, publications, animations, and videos.|$|R
40|$|Objective Many preterm {{children}} show {{difficulties in}} attention at (pre) school age. The development of attention capacities of preterm and term toddlers was compared using a longitudinal and multi-method approach at 12, 18 and 24 months. Method Attention was measured for 123 preterm (32 – 36 weeks gestation) and 101 term born children, using eye tracking (18 months), observations during mother–child interaction (18 months), and mother-reports (12, 18, and 24 months). Results Preterm toddlers had lower scores than term children on <b>the</b> <b>eye-tracking</b> measures of orienting and alerting. No group {{differences were found}} with observations, mother-reports, and <b>the</b> <b>eye-tracking</b> measure of executive attention. More preterm than term children had suboptimal scores on measures of the alerting system at 18 months, possibly indicating difficulties in attention development. Conclusion Preterm children showed an increased risk for suboptimal functioning in alerting attention capacities, as early as at a toddler age...|$|R
50|$|SoundSpectrum, {{previously}} {{known as}} WhiteCap Technologies is a software company founded in 2000 that develops music visualization software. Using {{properties of the}} music such as its beat and time-varying spectrum, the <b>software</b> <b>generates</b> dynamic visuals to complement the music.|$|R
40|$|<b>The</b> {{emerging}} <b>eye-tracking</b> {{technique has}} opened a window of opportunities not only in medical research but also in Translation and Interpreting Studies. In recent years this research method {{has been used to}} trace the processes of reading, translation and interpreting. Eye-tracking has recently become a popular technique to examine cognitive effort involved in written translation, audiovisual translation and conference interpreting. Thanks to the use of an eye-tracker one is able to investigate the whole process and not limit oneself to analysing the quality of the output. To be more precise, by means of eye-tracking experimenters may investigate moment-by-moment changes in the cognitive effort necessary to perform a given translation/interpreting task. Useful as <b>the</b> <b>eye-tracking</b> technique may be, researchers must often face methodological and apparatus-related challenges. The present paper is intended to discuss <b>the</b> <b>eye-tracking</b> methodology and then to address the potential problems of applying this method to investigate the processes of translation and interpreting. Among the notions to be discussed are: the types of eye-trackers and their usability, accuracy vs. ecological validity, accommodation (O'Brien 2010), sampling, the use of inferential statistics for small experimental groups as well as ethics. I will also refer to my own research on the notion of language-pair specificity in sight translation (Korpal 2012) as well as a collaborative work on numerical data processing in simultaneous interpreting (Korpal and Stachowiak, manuscript in preparation) ...|$|R
5|$|Dark Souls (PS3, Xbox 360) by From <b>Software</b> <b>generated</b> {{universal}} {{critical acclaim}} upon release. Known for its brutally challenging gameplay, critics consider Dark Souls {{to be one}} of the most influential and rewarding video games of the seventh console generation.|$|R
40|$|A bar-code {{system has}} been {{assembled}} for a microbiological laboratory that must examine {{a large number of}} samples. The system includes a commercial bar-code reader, computer hardware and software components, plus custom-designed database <b>software.</b> The <b>software</b> <b>generates</b> a user-friendly, menu-driven interface...|$|R
50|$|Dark Souls (PS3, Xbox 360) by From <b>Software</b> <b>generated</b> {{universal}} {{critical acclaim}} upon release. Known for its brutally challenging gameplay, critics consider Dark Souls {{to be one}} of the most influential and rewarding video games of the seventh console generation.|$|R
5000|$|Treating the {{requirement}} as axioms, testability {{can be treated}} via asserting existence of a function [...] (software)such that input [...] generates output , therefore [...] Therefore, the ideal <b>software</b> <b>generates</b> the tuple [...] which is the input-output set ,standing for specification.|$|R
50|$|InVesalius {{is a free}} medical <b>software</b> used to <b>generate</b> virtual reconstructions of {{structures}} in the human body. Based on two-dimensional images, acquired using computed tomography or magnetic resonance imaging equipment, the <b>software</b> <b>generates</b> virtual three-dimensional models correspondent to anatomical parts of the human body. After constructing three-dimensional DICOM images, the software allows the generation of STL (stereolithography) files. These files {{can be used for}} rapid prototyping.|$|R
40|$|Abstract Survey {{researchers}} since Cannell haveworried that respon-dents {{may take}} various shortcuts {{to reduce the}} effort needed to complete a survey. The evidence for such shortcuts is often indirect. For instance, preferences for earlier versus later response options have been interpreted as evidence that respondents do not read beyond the first few options. This is really only a hypothesis, however, that is not supported by direct evidence regarding the allocation of respondent attention. In the current study, we used a new method to more directly observe what respondents do and do not look at by recording their eye movements while they an-swered questions in a Web survey. <b>The</b> <b>eye-tracking</b> data indicate that respondents do in fact spend more time looking at the first few options in a list of response options than those {{at the end of}} the list; this helps explain their tendency to select the options presented first regardless of their content. In addition, <b>the</b> <b>eye-tracking</b> data reveal that respondents are reluctant to invest effort in reading definitions of survey concept...|$|R
40|$|The {{detection}} of region of interest(ROI) in video content is analyzed by <b>the</b> subjective <b>eye-tracking</b> experiment and Itti's objective model. For <b>eye-tracking</b> experiments, <b>the</b> time synchronization problem between video {{content and the}} data obtained by <b>the</b> <b>eye-tracking</b> experiments is discussed to obtain the subjective weighting matrix of ROI;for Itti's model,the optimization of the number of interesting areas is evaluated to deduce the objective weighting matrix of ROI. These two matrices are integrated into the traditional peak signal-to-noise ratio(PSNR) quality assessment metric, the reliability and improvement are discussed. The experimental results show that by optimizing parameters, the application of the ROI obtained from both eye-tracking experiments and Itti's model improves the correlation between the PSNR and subjective assessment while keeping the simplicity...|$|R
40|$|The {{detection}} of university online learners’ reading ability is generally problematic and time-consuming. Thus <b>the</b> <b>eye-tracking</b> sensors have been employed in this study, to record {{temporal and spatial}} human eye movements. Learners’ pupils, blinks, fixation, saccade, and regression are recognized as primary indicators for detecting reading abilities. A computational model is established according to <b>the</b> empirical <b>eye-tracking</b> data, and applying the multi-feature regularization machine learning mechanism based on a Low-rank Constraint. The model presents good generalization ability with an error of only 4. 9 % when randomly running 100 times. It has obvious advantages in saving time and improving precision, with only 20 min of testing required for prediction of an individual learner’s reading ability. Department of Building and Real Estat...|$|R
5000|$|Media {{development}} <b>software</b> <b>generates</b> {{print and}} electronic media {{for others to}} consume, most often in a commercial or educational setting. This includes graphic-art software, desktop publishing software, multimedia development software, HTML editors, digital-animation editors, digital audio and video composition, and many others.|$|R
40|$|Abstract—In the paper, we {{deal with}} the problem of {{automatic}} determining syntactic complexity of visual stimuli. This problem is important in case of using paintings in eye-tracking based diagnosis and therapy of some kinds of neuropsychological and emotional disorders. Our approach to solving the considered problem is based on the clustering procedure using Self Orga-nizing Feature Maps. The clustering results are compared with the heat maps obtained in <b>the</b> <b>eye-tracking</b> process. I...|$|R
50|$|Automated Insights {{produced}} 300 million {{pieces of}} content in 2013, which Mashable reported {{was greater than}} the output of all major media companies combined. In 2014, the company's <b>software</b> <b>generated</b> one billion stories. In 2016, Automated Insights produced over 1.5 billion pieces of content.|$|R
40|$|A {{simple method}} for <b>the</b> {{calibration}} of <b>eye-tracking</b> systems based on eye-features detection is proposed. Many eye-tracking systems are {{claimed to be}} robust to head movements in some degree, but such robustness is rarely fully quantified. Moving chin-rest and synthetic images have been proposed to investigate head movements. However, both methods have several limitations. The reported calibration method exploits {{for the first time}} ocular imaging eye models (OIEMs) in order to simulate the eye(s), thus allowing to easily investigate the effects due to head movements. Moreover, it can be useful for the development and comparison of <b>eye-tracking</b> hardware, <b>software</b> and whole systems. Differently from human subjects, OIEMs are standardized and time-invariant thus, comparisons can be performed at different times and places, leading OIEMs to be a potential gold standard test for eye-tracking systems. Preliminary verification performed on a basic eye tracking system corroborate the applicability of described method...|$|R
50|$|Irfan Skiljan {{graduated}} from the Vienna University of Technology. In a 2006 interview, 32-year-old Bosnian-born Skiljan {{said that he was}} able to more or less live off the <b>software,</b> <b>generating</b> income with the sale of licenses for commercial users and of special versions for different customers.|$|R
