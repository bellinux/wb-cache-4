6|10000|Public
30|$|Table 4 {{shows the}} execution-time of the {{proposed}} algorithm and compares it to the fixed-SR scheme with the constant BW pattern. The results {{are similar to those}} found with the simple-SR scheme in the variable BW pattern case. Our proposed algorithm slightly improves execution time. However, the saving is not directly proportional to BW saving due to <b>the</b> <b>calculation</b> <b>overhead</b> of the MB-level BW-scalable scheme. These overheads can be reduced with further software optimization or better hardware implementation of the existing ME engine.|$|E
40|$|Thesis (Ph. D.) [...] University of Washington, 2014 An all-digital {{method is}} used to detect {{sinusoidal}} phase noise components while reducing the need for computation intensive post-processing. We use the frequency-selective behavior of a narrow bandwidth infinite impulse response (IIR) digital filter to replace the frequency- domain evaluation of an FFT. This form of digital post-processing reduces <b>the</b> <b>calculation</b> <b>overhead</b> of making frequency-domain observations. We provide {{a model for the}} inherent nonidealities of the relevant quantization processes which will need to be managed in a practical implementation of this technique for manufacturing test...|$|E
40|$|We {{study the}} {{convergence}} of the integrals required to be evaluated in the surface integral equation (SIE) formu-lation (or method of moments) for simulating the optical response of plasmonic nanostructures. We analyze how the numerical quadratures used to compute the integrals affect {{the accuracy of the}} SIE matrix elements and, in turn, that of the relevant physical quantities calculated using the method. Based on these studies, we propose an optimized algorithm for evaluation of the integrals, which improves the accuracy of the results without signifi-cantly increasing <b>the</b> <b>calculation</b> <b>overhead.</b> © 2015 Optical Society of America OCIS codes: (250. 5403) Plasmonics; (050. 1755) Computational electromagnetic methods; (290. 5825) Scat-tering theory...|$|E
30|$|In Section 3, <b>the</b> control <b>overhead</b> <b>calculations</b> are exemplarily {{shown for}} {{different}} deployment scenarios to clearly illustrate {{the impact of}} control signaling on the average and cell-edge user spectral efficiencies.|$|R
30|$|HF-A-MAP: <b>The</b> <b>overhead</b> <b>calculation</b> for <b>the</b> HF-A-MAP {{channel is}} based on <b>the</b> dynamic <b>calculation</b> of <b>the</b> {{required}} ACKs/NACKs from the UL system level simulations for each test environment. Each HF-A-MAP channel is assumed to occupy eight tones in the A-MAP region [13].|$|R
3000|$|Given N facilities, {{calculating the}} nearest {{distance}} for one object requires N <b>calculations.</b> <b>The</b> computation <b>overhead</b> increases {{with the number}} of both objects and facilities. Assume we have N facilities and M objects, Θ(M [...]...|$|R
40|$|We {{investigate}} {{the applicability of}} the synchronous relaxation (SR) algorithm to parallel kinetic Monte Carlo simulations of simple models of thin-film growth. A variety of techniques for optimizing the parallel efficiency are also presented. We find that the parallel efficiency is determined by three main factors $-$ <b>the</b> <b>calculation</b> <b>overhead</b> due to relaxation iterations to correct boundary events in neighboring processors, the (extreme) fluctuations in the number of events per cycle in each processor, and the overhead due to interprocessor communications. Due to the existence of fluctuations and the requirement of global synchronization, the SR algorithm does not scale, i. e. the parallel efficiency decreases logarithmically as the number of processors increases. The dependence of the parallel efficiency on simulation parameters such as the processor size, domain decomposition geometry, and the ratio $D/F$ of the monomer hopping rate $D$ to the deposition rate $F$ is also discussed. Comment: 13 pages, 15 figure...|$|E
30|$|Taking the {{performance}} overhead of the BAE scheme as an example, 4 N[*]+[*]n on the communication overhead means that four messages are exchanged to N external sites and n broadcast authentication messages (see Fig.  5) during the key update, which corresponds to O (N[*]+[*]n). For <b>the</b> <b>calculation</b> <b>overhead,</b> 2 n[*]+[*] 2 {{indicates that the}} MS needs to generate n hash values and n[*]+[*] 1 message authentication codes during the broadcast message authentication phase and needs to complete one encryption operation during the key update phase. Similarly, each PLC needs 4 Nn cryptography; for storage overhead, 2 n[*]+[*] 2 means that the MS stores n indexes (i) and n hash values (Si), and two keys (KE and KH). Similarly, the 8 N at the PLC side means that each PLC stores eight parameters: KH, KE, chalg, Sn, i, Scalc, Sstored, and Nstored. The results of the comparison in Table  1 show that BAE has significantly reduced communication overhead at the minor cost of increasing the computational and processing overhead compared to its corresponding NACR and AGM; {{especially in the case}} of intermediate attacks such as modification, injection and reproduction, BAE communication overhead is also significantly reduced, applied to a wide range of broadcast communications; this advantage will be more significant. In addition, compared with NACR and AGM, the computational overhead of the master station in the BAE scheme is also significantly reduced.|$|E
40|$|Fourth {{generation}} (4 G) {{mobile communication}} networks are characterised by heterogeneous access networks and IP based transport technologies. Different access technologies give users choices to select {{services such as}} levels of Quality of Service (QoS) support, business models and service providers. Flexibility of heterogeneous access {{is compounded by the}} overhead of scanning to discover accessible services, which added to the handoff latency. This thesis has developed mechanisms for service discovery and service selection, along with a novel proposal for mobility management architectures that reduced handoff latency. The service discovery framework included a service advertisement data repository and a single frequency band access mechanism, which enabled users to explore services offered by various operators with a reduced scanning overhead. The novel hierarchical layout of the repository enabled it to categorise information into various layers and facilitate location based information retrieval. The information made available by the repository included cost, bandwidth, Packet Loss (PL), latency, jitter, Bit Error Rate (BER), location and service connectivity information. The single frequency band access mechanism further enabled users to explore service advertisements in the absence of their main service providers. The single frequency access mechanism broadcasted service advertisements information piggybacked onto a router advertisement packet on a reserved frequency band for advertisements. Results indicated that scanning 13 channels on 802. 11 b interface takes 189 ms whereas executing a query with maximum permissible search parameters on the service advertisement data repository takes 67 ms. A service selection algorithm was developed to make handoff decisions utilising the service advertisements acquired from the service discovery framework; based on a user's preference. The selection algorithm reduced <b>the</b> <b>calculation</b> <b>overhead</b> by eliminating unsuitable networks; based on interface compatibility, service provider location, unacceptable QoS (Quality of service) and unacceptable cost; from the selection process. The selection algorithm utilised cost, bandwidth, PL, latency, jitter, BER and terminal power for computing the most suitable network. Results indicated that the elimination based approach has improved the performance of the algorithm by 35...|$|E
40|$|Abstract—The revolutionary {{decentralized}} {{access control}} plan for vulnerable information data storage in clouds that backings unidentified confirmation. In the proposed plan, the clouds check the server's credibility {{without knowing the}} client's uniqueness before putting away information. The proposed configuration concentrates on the full cycle access controlling plan where in the displayed framework it was precluded. With a specific end goal to accomplish secure access controlling plan we proposed fine-gained approach at cloud level, it keeps unapproved access control-ling from clients or foes viably our validation and access control plan is decentralized and solid, {{not at all like}} different access control plans intended for clouds which are incorporated. <b>The</b> correspondence, <b>calculation</b> <b>overheads</b> are like brought together approaches. More over our proposed outline demonstrates that our framework has secure crypt...|$|R
50|$|As a {{decision}} tool it is simple to understand. The {{simplicity of the}} formula allows to freely choose variables, e.g., length of <b>the</b> <b>calculation</b> time, if <b>overhead</b> cost should be included, or details such as what variables are used to calculate income or cost components. To use ROI as an indicator for prioritizing investment projects is risky, since usually little is defined together with the ROI figure that explains what is making up the figure.|$|R
40|$|Abstract — the spearheading {{decentralized}} {{access control}} plan for vulnerable data storage in Cloud that backings un-identified confirmation. In the proposed plan, the Cloud checks the validness of the server {{without knowing the}} client's uniqueness before putting away data. The proposed outline concentrates on the full cycle access controlling plan wherein the displayed framework it was overlooked. Keeping in mind the end goal to accomplish secure access controlling plan we proposed fine-grained approach at cloud level, it keeps unapproved access controlling from clients or foes adequately our validation and access control plan is decentralized and solid, {{not at all like}} different access control plans intended for Cloud which are unified. <b>The</b> correspondence, <b>calculation</b> <b>overheads</b> are like unified methodologies. In addition, our pro-posed plan demonstrates that our framework has secure crypto instrument towards accomplishing data integrity and se-curity...|$|R
30|$|The {{performance}} test shows the time improvements while executing a CPU-intensive mathematical <b>calculation.</b> <b>The</b> transfer <b>overhead</b> mainly {{depends on the}} infrastructure used (e.g., local Eucalyptus or Amazon EC 2), the processing speed depends on the VM-type used (e.g., CPU and available memory). If a given calculation can be parallelized by invoking the same method with different parameter sets, the provided easy to use Code Execution Framework will reduce the total execution time rapidly.|$|R
40|$|In 2000, the European Union (EU) {{launched}} the Water Framework Directive (WFD), {{calling for a}} good ecological status for water bodies by 2015 through integrated river basin management. Despite huge investments, the river Zenne (Belgium) still acquires high loads of pollutants. A multidisciplinary research project was therefore launched to evaluate the effects of river basin wastewater management plans on the river's ecological functioning. Different water quantity and quality processes were considered, and different models were used for each process. For the integration of these models – in view of a holistic analysis – we opted for the Open Modelling Interface (OpenMI). This paper discusses early results of integrated faecal bacteria modelling considering five models. The integrated model is shown to reproduce concentrations of E. coli (used as indicator faecal bacteria) with ‘Very Good’, and ‘Satisfactory’ accuracy for dry weather, and long-term simulations respectively. For both cases, {{it is found that}} the E. coli concentrations in the river are well above EU level for bathing water, with occasional Combined Sewer Overflows (CSOs) from the Brussels' sewer systems making the ecological status even worse. We also found OpenMI-based integration to be very useful. However, <b>the</b> <b>calculation</b> time <b>overhead</b> for such OpenMI integrated models remains significant. SCOPUS: ar. jinfo:eu-repo/semantics/publishe...|$|R
30|$|We next {{turn to the}} {{evaluation}} of the different approaches taking the system overhead into account. Since the transmitted frame duration is set to 1 ms, we assume L= 5 TDD-frames to be used for position, or CSI, acquisition and data transmission for all terminals present in the system. This serves as basic parametrization for <b>the</b> <b>overhead</b> <b>calculations</b> presented in Eqs. 5 and 6. Our goal is to study the impact of overhead on performance of the learning-based and CSI-based RA schemes as the number of terminals in the system (for which the state information needs to be collected) grows. Note that we consider at this step still all state information to be perfectly accurate (i.e., the position information as well as the CSI).|$|R
40|$|<b>The</b> address <b>calculation</b> for {{distributed}} {{data access}} {{plays a major}} role for the performance of fine-grained data-parallel applications. This paper reports about the hardware centrifuge of the Cray T 3 E which enables the shift of <b>the</b> address <b>calculation</b> from software into hardware. This shift minimizes address <b>calculation</b> <b>overhead</b> reducing communication cost of dynamic communication patterns. The centrifuge is compared with complex integer division and modulo and with integer mask and shift operations. The measurements show for a one-dimensional dynamic communication pattern for several distributions a runtime advantage of T 3 E's hardware centrifuge of at least a factor 1. 9 over integer division arithmetic. But, the centrifuge is barely faster compared with integer mask and shift operations...|$|R
40|$|The {{complexity}} {{of a general}} sparse Gaussian elimination algorithm based on the bordering algorithm is analyzed. It {{has been shown that}} this procedure requires less integer overhead storage than more traditional general sparse procedures, but the {{complexity of}} <b>the</b> nonnumerical <b>overhead</b> <b>calculations</b> was not clear. Here the nonnumerical complexity of the original procedure is shown to be comparable to the numerical complexity for an n Θ n grid graph, and an enhancement of the procedure that can reduce the overhead is presented. Key words. sparse Gaussian elimination, bordering, m-tree AMS subject classifications. 65 F 05, 65 N 20 1. Introduction. In this paper, we consider the solution of the N Θ N linear system Ax = b (1. 1) where A is large, sparse, symmetric, and positive definite. We consider the direct solution of (1. 1) by means of general sparse Gaussian elimination. In such a procedure, we find a permutation matrix P, and compute the decomposition PAP t = LDL t where [...] ...|$|R
40|$|This paper {{presents}} {{the possibility of}} using CAD programming tools for customizing, in order to meet specific engineering tasks. The software developed in this work enables the automation of the procedure for mechanical <b>calculation</b> of <b>overhead</b> electric power transmission lines. <b>The</b> <b>calculation</b> includes determination of vertical deformations and stresses of transmission lines, graphical representation of lines at different temperatures and additional loads on columns. Developed programs allow automatic creation of tables with data on normal forces, stresses and deflections of wires for different values of spans, at different temperatures, as well as graphical representation of calculated values for deformations and loads...|$|R
40|$|Masteroppgave informasjons- og kommunikasjonsteknologi - Universitetet i Agder, 2015 Device-to-Device (D 2 D) {{communication}} {{has become}} one of the most popular topic in the 5 th generation (5 G) mobile communication technology. D 2 D offers opportunities for access to services through direct neighbor device connection with or/and without base station (BS) assistance. Some of the possible improvements using D 2 D communication include high data rate, network offloading and range extension, as well as commercial and social proximity services networking. Although a lot of studies exist in the research community, D 2 D communication with one of the end users are located outside the cellular network coverage has not received enough attention. Some of the problems faced in this case are discovering process of neighbor user equipment (UE) and services, as well as designing suitable and secure protocols for D 2 D communication. Toward these problems, two protocols (reactive and proactive) for neighbor and service discovery are proposed in this thesis. Implementation of reactive protocol, proactive protocol, simulation and validation are shown. Furthermore, the proposed protocols are improved with additional security enhancement. <b>The</b> <b>overhead</b> <b>calculation</b> results show that reactive protocol achieves better performance when data traffic load is lower whereas proactive is preferred with higher traffic load in D 2 D communication...|$|R
40|$|Device-to-Device (D 2 D) {{communication}} {{has become}} one of the most popular topic in the 5 th generation (5 G) mobile communication technology. D 2 D offers opportunities for access to services through direct neighbor device connection with or/and without base station (BS) assistance. Some of the possible improvements using D 2 D communication include high data rate, network offloading and range extension, as well as commercial and social proximity services networking. Although a lot of studies exist in the research community, D 2 D communication with one of the end users are located outside the cellular network coverage has not received enough attention. Some of the problems faced in this case are discovering process of neighbor user equipment (UE) and services, as well as designing suitable and secure protocols for D 2 D communication. Toward these problems, two protocols (reactive and proactive) for neighbor and service discovery are proposed in this thesis. Implementation of reactive protocol, proactive protocol, simulation and validation are shown. Furthermore, the proposed protocols are improved with additional security enhancement. <b>The</b> <b>overhead</b> <b>calculation</b> results show that reactive protocol achieves better performance when data traffic load is lower whereas proactive is preferred with higher traffic load in D 2 D communication...|$|R
5000|$|... 1994-present - {{clarified}} {{definition of}} experimental development, broadened eligibility re Qualified Small Businesses, allowed proxy <b>calculation</b> for <b>overhead,</b> conducted major review in 1998, simplified forms, conducted major review in 2010 ...|$|R
40|$|Abstract: Distributed {{computing}} is {{a developing}} processing standard in which {{assets of the}} figuring foundation are given as administrations over the Internet. To keep touchy client information classified against un-trusted servers, existing results generally apply cryptographic routines by revealing information decoding keys just to approved clients. These results inexorably present a substantial <b>calculation</b> <b>overhead</b> on <b>the</b> information manager for key conveyance and information administration when fine grained information access control is sought. Open issue by characterizing and upholding access strategies focused around information characteristics and permitting the information manager to delegate {{the greater part of}} <b>the</b> <b>calculation</b> undertakings included in fine grained information access control to un-trusted cloud servers without revealing the underlying information substance. A few plans utilizing property based encryption (ABE) have been proposed for access control of outsourced information in distributed computing. As Cloud Computing requires extra security which is given utilizing HASBE and this can develop as another security characteristic for different hierarchical stages. It is actualized utilizing figure content approach by encoding and decoding the information in the cloud so the cloud framework gets to be more versatile and adaptable by implementing information managers to impart their information to information shoppers controlled by the space power. 1...|$|R
40|$|Abstract. Hierarchically-blocked {{non-linear}} storage layouts, {{such as the}} Morton ordering, {{have been}} proposed as a compromise between row-major and columnmajor for two-dimensional arrays. Morton layout offers some spatial locality whether traversed row-wise or column-wise. The goal {{of this paper is}} to make this an attractive compromise, offering close to the performance of row-major traversal of row-major layout, while avoiding the pathological behaviour of columnmajor traversal. We explore how spatial locality of Morton layout depends on the alignment of the array’s base address, and how unrolling has to be aligned to reduce address <b>calculation</b> <b>overhead.</b> We conclude with extensive experimental results using five common processors and a small suite of benchmark kernels. ...|$|R
40|$|Good quality {{information}} from data flow analysis {{is a prerequisite}} for code improvement and, in parallelizing compilers, parallelism detection. Typically, compilers do many kinds of data flow analyses and optimizations one after another, which may pose a phase-ordering problem: the analyses may have to be run several times until a fixed point is reached. However, when two related optimizations/analyses are performed in combination, {{it may be possible to}} obtain better results than iterating over the two analyses independently. Combining optimizations/analyses may be beneficial while potentially enforcing little <b>calculation</b> <b>overhead.</b> This paper discusses combining interprocedural conditional constant propagation (CCP) and interprocedural alias analysis (AA) in pointer-supporting languag...|$|R
40|$|Hierarchically-blocked {{non-linear}} storage layouts, {{such as the}} Morton ordering, {{have been}} proposed as a compromise between row-major and columnmajor for two-dimensional arrays. Morton layout offers some spatial locality whether traversed row-wise or column-wise. The goal {{of this paper is}} to make this an attractive compromise, offering close to the performance of row-major traversal of row-major layout, while avoiding the pathological behaviour of columnmajor traversal. We explore how spatial locality of Morton layout depends on the alignment of the array's base address, and how unrolling has to be aligned to reduce address <b>calculation</b> <b>overhead.</b> We conclude with extensive experimental results using five common processors and a small suite of benchmark kernels...|$|R
40|$|Many {{features}} of modern architectures, such as Performance Monitering Units (PMUs), can be leveraged for efficient program profiling. We present several simple heuristics to estimate path profiles from sampled partial paths {{which can be}} collected at runtime. Like recent work [13], we show {{that we can find}} 80 - 90 % of the hot paths within a program using these techniques. However, we also find that despite this high accuracy in identifying hot paths, using estimated paths to perform superblock formation does not necessarily yield an equivalent boost in performance. We evaluate how estimated path profiles impact superblock formation in the CASH compiler. In addition, we compare superblocks to hyperblocks and demonstrate that predicate <b>calculation</b> <b>overhead</b> can cause maximal hyperblocks to have inferior performance. ...|$|R
40|$|This thesis {{evaluated}} the system costing in the chosen company. The two selected products were applied two methods for calculating calculation. It was recommended <b>calculation</b> of <b>overhead</b> surcharge according to purchase prices of selected products. Prices {{of the products}} were compared {{with the price of}} the competition. Finally, it was recommended measures to reduce company costs...|$|R
40|$|Abstract — Certificate Revocation {{mechanisms}} play {{an important}} role in securing a network[6]. Malicious nodes directly threaten the robustness of the network Malicious nodes directly threaten the robustness of the network as well as the availability of nodes. Protecting legitimate nodes from malicious attacks must be considered in MANETs [1]. The main challenge for certificate revocation is to revoke the certificates of malicious nodes promptly and accurately. In this paper additionally uses two concepts: They are fixed window model and sliding window model of which the latter produces the best output with slight increased <b>calculation</b> <b>overhead.</b> In monitoring-based intrusion detection, each node monitors the forwarding behavior of its neighboring nodes. In this paper, proposed scheme is based upon a improved reliable based node classification scheme, which outperforms other techniques in terms of being able to quickly revoke attacker‘s certificates and recover falsely accused certificates...|$|R
40|$|Demands in {{computational}} power, {{particularly in}} the area of computational fluid dynamics (CFD), led NASA Ames Research Center to study advanced computer architectures. One architecture being studied is the static data flow architecture based on research done by Jack B. Dennis at MIT. To improve understanding of this architecture, a static data flow simulator, written in Pascal, has been implemented for use on a Cray X-MP/ 48. A matrix multiply and a two-dimensional fast Fourier transform (FFT), two algorithms used in CFD work at Ames, have been run on the simulator. Execution times can vary by a factor of more than 2 depending on the partitioning method used to assign instructions to processing elements. Service time for matching tokens {{has proved to be a}} major bottleneck. Loop control and array address <b>calculation</b> <b>overhead</b> can double <b>the</b> execution time. The best sustained MFLOPS rates were less than 50 % of the maximum capability of the machine...|$|R
5000|$|Substituting <b>the</b> <b>calculation</b> of [...] into <b>the</b> <b>calculation</b> of [...] {{gives the}} {{combined}} step: ...|$|R
50|$|Peculiarity of mean field methods is <b>the</b> <b>calculation</b> {{of nuclear}} {{property}} by explicit symmetry breaking. <b>The</b> <b>calculation</b> of <b>the</b> mean field with self-consistent methods (e.g. Hartree-Fock), breaks rotational symmetry, and <b>the</b> <b>calculation</b> of pairing property breaks particle-number.|$|R
40|$|The article {{presents}} <b>the</b> <b>calculation</b> of <b>the</b> limit depth of cracks in <b>the</b> dam, <b>the</b> <b>calculation</b> of step cracks in <b>the</b> dam, <b>the</b> <b>calculation</b> of full disclosure, <b>the</b> <b>calculation</b> of <b>the</b> {{direction of the}} cracks in the dam, the position of the first crack and their natural clogging. As well in this article has been shown all the necessary formulas for these calculations...|$|R
40|$|Abstract. This {{article is}} based on the concept and <b>the</b> <b>calculation</b> method of polar moment of inertia to derive <b>the</b> <b>calculation</b> formula for polar moment of inertia of {{rectangle}} spline shaft and involute spline shaft. Then verified the correctness of <b>the</b> <b>calculation</b> method and laid the foundation for <b>the</b> strength <b>calculation</b> of spline shaft...|$|R
5000|$|BI practitioner: Use for {{developing}} <b>the</b> <b>calculations,</b> finding <b>the</b> data {{needed to run}} <b>the</b> <b>calculations,</b> and building appropriate data structures ...|$|R
40|$|The bachelor's {{thesis is}} intent on <b>the</b> <b>calculation</b> of a plane frame which is used for {{hydraulic}} press. The theoretical basis for <b>the</b> <b>calculation</b> is mentioned {{in the first part}} of this thesis. <b>The</b> <b>calculation</b> of a concrete exercise according to the task set in the bachelor's thesis is in the second part. As a frame model we used a plane frame with two crossbeams. The load on the plane frame is interpreted by solitary forces which work upon <b>the</b> crossbeams. <b>The</b> <b>calculation</b> uses <b>the</b> Castiglian's theorem to specify the unknown parameters from deformation conditions. <b>The</b> <b>calculation</b> considers flexion energy of tensity. In the next part of <b>the</b> <b>calculation,</b> we consider <b>the</b> energy of tensity caused by vertical and normal shear for comparison. Coordinates of the load position can be changed at will. The final results of the thesis are a concrete frame proposal and an examination of pliability of <b>the</b> frame. <b>The</b> <b>calculation</b> was carried out in MAPLE 11 software...|$|R
3000|$|... where F_i(X_k)'∇ _X_kf(X_k;i)'. The {{complexity}} of <b>the</b> <b>calculation</b> of (41) is of order [...] O(N_a). However, <b>the</b> <b>calculation</b> of F(X [...]...|$|R
