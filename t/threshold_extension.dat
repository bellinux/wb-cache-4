16|41|Public
2500|$|Phase-locked loops {{are widely}} used for {{synchronization}} purposes; in space communications for coherent demodulation and <b>threshold</b> <b>extension,</b> bit synchronization, and symbol synchronization. Phase-locked loops {{can also be used}} to demodulate frequency-modulated signals. [...] In radio transmitters, a PLL is used to synthesize new frequencies which are a multiple of a reference frequency, with the same stability as the reference frequency.|$|E
40|$|The {{characteristics}} of three postdetection <b>threshold</b> <b>extension</b> techniques are evaluated {{with respect to}} the ability of such techniques to improve the performance of a phase lock loop demodulator. These techniques include impulse-noise elimination, signal correlation for the detection of impulse noise, and delta modulation signal processing. Experimental results from signal to noise ratio data and bit error rate data indicate that a 2 - to 3 -decibel <b>threshold</b> <b>extension</b> is readily achievable by using the various techniques. This threshold improvement is in addition to the <b>threshold</b> <b>extension</b> that is usually achieved {{through the use of a}} phase lock loop demodulator...|$|E
40|$|<b>Threshold</b> <b>extension</b> device {{connected}} between {{demodulator output}} and filter output minimizes clicking noise. Device consists of click-eliminating signal transfer channel with follow-and-hold circuit and detector for sensing click impulses. Final output consists of signal plus low level noise without high amplitude impulses...|$|E
40|$|We discuss Bayesian {{analysis}} of {{multivariate time series}} with dynamic factor models that exploit time-adaptive sparsity in model parametrizations via the latent threshold approach. One central {{focus is on the}} transfer responses of multiple interrelated series to underlying, dynamic latent factor processes. Structured priors on model hyper-parameters are key to the efficacy of dynamic latent thresholding, and MCMC-based computation enables model fitting and analysis. A detailed case study of electroencephalographic (EEG) data from experimental psychiatry highlights the use of latent <b>threshold</b> <b>extensions</b> of time-varying vector autoregressive and factor models. This study explores a class of dynamic transfer response factor models, extending prior Bayesian modeling of multiple EEG series and highlighting the practical utility of the latent thresholding concept in multivariate, non-stationary time series analysis. Comment: 27 pages, 13 figures, link to external web site for supplementary animated figure...|$|R
40|$|International audienceWe study {{analytically}} {{the behavior}} of a viscoelastic brittle solid loaded in tension, in which fractures may grow or not depending on the amount of dissipation allowed by the viscous behavior. We highlight a <b>threshold</b> in <b>extension</b> rate, below which the solid will not be fractured. Applied to sedimentary rocks, this model shows how viscous effects can prevent fracture growth in geological formations. © 2013 Elsevier Ltd. All rights reserved...|$|R
40|$|Abstract. We {{present a}} 1 -out-of-n group {{signature}} scheme that satisfies three major properties. (1) Anonymity, or signer-indistinguishability. (2) Linkability: That two signatures {{by the same}} signer can be linked. (3) Spontaneity: No group manager or TTP, no setup stage such as in secret sharing. The scheme has many applications where maximum privacy is protected, copycatting is prevented, and impromptu linkup is prerogative. For example: whistle blowing, e-voting, anonymous membership authentication, and digital rights management. We show under the random oracle model that our scheme satisfies all the three properties. Additionally, we present an e-voting system based on our scheme. In the system, there is no involvement of voters in the registration phase and the voting phase is only one-round. We also present a new proof of the core lemma in rewind simulation. This is the literature’s third such proofs, after the forking lemma [30] and the heavy-row lemma [28]. Our proof is the most accessible of the three, relying on only the moment inequality from elementary probability theory. And our proof has the best simulation efficiency of the three. <b>Threshold</b> <b>extensions</b> of our scheme are also proposed. ...|$|R
40|$|Besides {{results of}} European Broadcasting Union tests at the Telecommunications and Microwave Laboratory, the authors present {{researches}} carried {{out there to}} improve the quality of satellite links. They deal mainly with a prototype <b>threshold</b> <b>extension</b> demodulator which could be tested with the aid of the OTS satellite. Francai...|$|E
40|$|An all digital {{phase-locked loop}} (DPLL) is designed, analyzed, and tested. Three {{specific}} configurations are considered, generating first, second, and third order DPLL's; {{and it is}} found, using a computer simulation of a noise spike, and verified experimentally, that of these configurations the second-order system is optimum {{from the standpoint of}} <b>threshold</b> <b>extension.</b> This substantiates results obtained for analog PLL's...|$|E
40|$|The design, development, and {{analysis}} are reported of a digital phase-locked loop (DPLL) for FM demodulation and <b>threshold</b> <b>extension.</b> One {{of the features}} of the developed DPLL is its synchronous, real time operation. The sampling frequency is constant and all the required arithmetic and logic operations are performed within one sampling period, generating an output sequence which is converted to analog form and filtered. An equation relating the sampling frequency to the carrier frequency must be satisfied to guarantee proper DPLL operation. The synchronous operation enables a time-shared operation of one DPLL to demodulate several FM signals simultaneously. In order to obtain information about the DPLL performance at low input signal-to-noise ratios, a model of an input noise spike was introduced, and the DPLL equation was solved using a digital computer. The spike model was successful in finding a second order DPLL which yielded a five db <b>threshold</b> <b>extension</b> beyond that of a first order DPLL...|$|E
40|$|We {{propose a}} test for a high-dimensional {{covariance}} being banded with possible diverging bandwidth. The test is adaptive to the 2 ̆ 2 large p, small n 2 ̆ 2 situations without assuming a specific parametric distribution for the data. For covariance estimation, we propose a band width selector for the banding covariance estimator of Bickel and Levina (2008 a) by minimizing an empirical estimate of the expected squared Frobenius norms of the estimation error matrix. The ratio consistency of the band width selector to the underlying band width is established. We provide a lower bound for the coverage probability of the underlying band width being contained in an interval around the band width estimate. Extensions to the band width selection for the tapering estimator and threshold level selection for the thresholding covariance estimator are made. We also consider the detection of rare and faint signals in high-dimensional count data. Under Generalized Linear Models, a thresholding statistic based on the maximum likelihood estimators (MLEs) is proposed. A multi-threshold test is constructed by maximizing the standardized thresholding statistic over a set of <b>thresholds.</b> <b>Extensions</b> to Generalized Linear Mixed Models are made, where Gauss quadratures and data cloning are used to approximate the MLEs of such models. Numerical simulations and three case studies are conducted to confirm and demonstrate the proposed approaches...|$|R
40|$|The {{treatment}} of pressure effects on bimolecular recombinations and unimolecular dissociations is discussed. The analysis of recombination and dissociation reactions {{is made by}} showing how the nonequilibrium energy (E) and angular momentum (J) -dependent steady-state population distribution functions for the two reactions are {{related to each other}} and to the equilibrium population distribution function at the given E and J. As a special case a strong collision model is then used for the collisional rotational angular momentum transfer, and a ladder model for the collisional energy transfer. An analytical result is obtained for states below the dissociation <b>threshold.</b> The <b>extension</b> to recombinations with two exit channels is described, for application to ozone formation and isotopic effects...|$|R
40|$|A {{technique}} for detecting errors made by Hidden Markov Model taggers is described, based on comparing observable {{values of the}} tagging process with a threshold. The resulting approach allows {{the accuracy of the}} tagger to be improved by accepting a lower efficiency, defined as the proportion of words which are tagged. Empirical observations are presented which demonstrate the validity of the technique and suggest how to choose an appropriate <b>threshold.</b> An <b>extension</b> of the technique to improving BaumWelch re-estimation is proposed, although the results are less good. Keywords: Corpus-based NLP, Statistical MT/NLP. 1 Introduction Tagging by Hidden Markov Model (HMM) is a successful {{technique for}} assigning grammatical information to words in a corpus. In outline, the tagger picks the most probable grammatical category, or tag, for each word by combining the probability of possible tag sequences with the probability of each hypothesised tag for the words, considered in isolation f [...] ...|$|R
40|$|Expressions for {{the output}} {{signal-to-noise}} power ratio of a bandpass soft limiter {{followed by a}} coherent detection device are presented and discussed. It is found that a significant improvement in the output signal-to-noise ratio (SNR) at low input SNR's {{can be achieved by}} such soft limiters as compared to hard limiters. This indicates that the soft limiter may be of some use in the area of <b>threshold</b> <b>extension.</b> Approximation methods for determining output signal-to-noise spectral densities are also presented...|$|E
40|$|We {{report a}} {{wavelength}} <b>threshold</b> <b>extension,</b> from the designed value of 3. 1 to 8. 9 μm, in a -type heterostructure photodetector. This {{is associated with}} the use of a graded barrier and barrier offset, and arises from hole–hole interactions in the detector absorber. Experiments show that using long-pass filters to tune the energies of incident photons gives rise to changes in the intensity of the response. This demonstrates an alternative approach to achieving tuning of the photodetector response without the need to adjust the characteristic energy that is determined by the band structure...|$|E
40|$|This paper derives the {{asymptotic}} {{null distribution}} of a quasilikelihood ratio test statistic for an {{autoregressive moving average}} model against its <b>threshold</b> <b>extension.</b> The null hypothesis is that of no threshold, and the error term could be dependent. The asymptotic distribution is rather complicated, and all existing methods for approximating a distribution in the related literature fail to work. Hence, a novel bootstrap approximation based on stochastic permutation is proposed in this paper. Besides being robust to the assumptions on the error term, our method enjoys more flexibility and needs less computation when compared with methods currently used in the literature. Monte Carlo experiments give further support to the new approach, and an illustration is reported. © 2011 Biometrika Trust. link_to_subscribed_fulltex...|$|E
40|$|This paper {{presents}} three {{systems that}} are fully implemented and {{a proposal for a}} fourth one. KASIMIR is a knowledge based-system using an ad hoc formalism similar to a simple description logic with concrete domains which is used for representing decision protocols in oncology. FUZZY-KASIMIR is an extension of KASIMIR with fuzzy concrete domains taking into account discontinuities in the decision that are due to numerical <b>thresholds.</b> Another <b>extension</b> of KASIMIR has led to embed it into a semantic portal for oncology, which has been motivated by the need to share knowledge for geographically distributed physicians and has led to change the ad hoc formalism to the standard OWL DL. A combination of these two extensions of KASIMIR is currently under implementation and will lead to a semantic portal for oncology with fuzzy datatypes. Key words: fuzzy description logics, semantic portal for oncology, OWL DL, fuzzy datatypes...|$|R
40|$|This is an {{introductory}} review of deterministic mutation-selection models for asexual populations (i. e., quasispecies theory) and related topics. First, the basic concepts of fitness, mutations, and sequence space are introduced. Different types of mutation-selection dynamics are defined and {{their relation to}} problems of statistical physics are outlined. Then the stationary population distribution in simple, single peak fitness landscapes is discussed at length, with particular emphasis on the error <b>threshold</b> phenomenon. <b>Extensions</b> of the theory covering e. g. epistatic interactions, diploid organisms, semiconservative replication and time-dependent fitness peaks are briefly described. A further section is devoted to randomly rugged fitness landscapes, which may display fitness correlations of various degree as well as extended neutral networks. The final two sections address evolutionary dynamics in both rugged and smooth fitness landscapes, and provide {{a brief overview of}} pertinent experiments. Comment: To appear in "Structural approaches to sequence evolution: Molecules, networks and populations", ed. by U. Bastolla, M. Porto, H. E. Roman and M. Vendruscol...|$|R
40|$|In {{order to}} select for image {{thresholding}} an optimal threshold that is relatively robust {{to the presence}} of skew or heavy-tailed class-conditional distributions, we propose in this paper two median-based approaches: one is an extension of Otsu’s method, and the other is an extension of Kittler and Illingworth’s minimum error <b>thresholding.</b> The two <b>extensions</b> preserve the methodological simplicity and computational efficiency of their original methods. Experiments on some real images and simulated data sets show that the two extensions can accomplish robust performance. In addition, theoretical interpretation of the new approaches, based on the mixture of Laplace distributions, is given...|$|R
40|$|Recently, {{observations}} by PAMELA, the Fermi Gamma Ray Space Telescope, {{and other}} cosmic ray experiments have generated {{a great deal}} of interest in dark matter (DM) particles which annihilate at a high rate to leptons. In this letter, we explore the possibility of using large volume neutrino telescopes, such as IceCube, to constrain such models; specifically we consider signals due to DM annihilation in the inner Milky Way. We find that, if Dark Matter annihilations are responsible for the signals observed by PAMELA and FGST, then IceCube (in conjunction with the planned low <b>threshold</b> <b>extension,</b> DeepCore) should detect or exclude the corresponding neutrino signal from the inner Milky Way with a few years of observation. Comment: 4 pages, 1 Figure, and 2 Table...|$|E
40|$|The {{theoretical}} principles lying behind phase-shift {{analysis and}} its ambiguities are explained, {{first in the}} inelastic {{and then in the}} elastic cases. Fixed-point theorems are used to show the existence of solutions, while an iterative method is employed to construct alternative solutions. Argand diagrams of some numerical results are presented and references to the literature are given, in particular a complete list of the author's work in the field. OVERVIEW Principles of inelastic phase-shift analysis Continuum ambiguities Practical application to ff-ff above p-Li 7 <b>threshold</b> <b>Extension</b> to spin- 0 [...] spin- 1 2 scattering Practical application to N above N threshold The moral: energy-dependent analyses! Discrete ambiguities in elastic scattering: Generalized Crichton amplitudes TOOLS Banach and Schauder existence theorems in Banach spaces. Newton-Kantorovitch iteration: local uniqueness or bifurcations. Fortran and Mathematica programs on a 486 Personal Computer. 1 Inelastic phas [...] ...|$|E
40|$|Phase locked loops (PLL's) {{are well}} known as a <b>threshold</b> <b>extension</b> {{demodulator}} for analogue FM signals. This capability {{may lead to the}} low bit error rate demodulation for digital FM signals. A PLL has also its native frequency tracking ability and is suited to the demodulation of the signals having large Doppler shifts, for example signals from Low Earth Orbit (LEO) satellites. In this paper, we study the demodulation scheme of Continuous Phase FSK (CPFSK) and Gaussian filtered MSK (GMSK) signals using a Digital Signal Processing type Digital PLL (DSP DPLL). First we propose a DSP DPLL completely equivalent to an Analog PLL (APLL). Next we adopt the sequence estimation scheme to compensate the Inter-Symbol Interference (ISI) associated with the finite loop bandwidth of the DSP DPLL. Through computer simulations it is clarified that the proposed DSP DPLL with sequence estimator can achieve better BER performance compared with the conventional Limiter Discriminator (LD) detection on the AWGN channel. We have also shown that the DSP DPLL with sequence estimator has excellent BER characteristics on Rician fading channels having actual large Doppler shifts...|$|E
40|$|The {{crack growth}} {{behavior}} of D 6 AC steel {{as a function}} of stress intensity, stress and corrosion history and test technique, under sustained load in natural seawater, 3. 3 percent NaCl solution, distilled water, and high humidity air was investigated. Reported investigations of D 6 AC were considered with emphasis on thermal treatment, specimen configuration, fracture toughness, crack-growth rates, initiation period, <b>threshold,</b> and the <b>extension</b> of corrosion fatigue data to sustained load conditions. Stress history effects were found to be most important in that they controlled incubation period, initial crack growth rates, and apparent threshold...|$|R
5000|$|Lab Zero Games {{launched}} a crowdfunding campaign on Indiegogo on October 5, 2015, {{with a goal}} of [...] A playable prototype of the game was released {{in tandem with the}} launch. If Lab Zero Games met or exceeded their goal, publisher 505 Games would contribute their remaining development budget. The campaign's initial 40-day contribution period faced relatively sluggish fundraising, earning approximately $764,000 by November 8, 2015. However, on November 13, 2015, the campaign was extended for an additional 20 days after the game received roughly $963,000 in pledges, above Indiegogo's required 60% <b>threshold.</b> Following the <b>extension,</b> the goal was eventually reached on December 2, 2015.|$|R
30|$|Finally, we {{examined}} the dependence of acquisition duration on the algorithm’s metric of waveform quality. Part way through a patient acquisition, the algorithm makes {{an assessment of the}} magnitude of respiratory motion based on this metric, from which it may trigger (above some <b>threshold)</b> an <b>extension</b> to the acquisition duration for the current bed position. This automatic extension of the scanning duration for bed positions where respiratory motion is detected is expected to be useful, as it allows the application of quiescent period gating for these bed positions while maintaining an adequate number of counts in the retained dataset. When the magnitude of the respiratory motion, as inferred from the quality metric, is below the threshold, it is assumed that there is little benefit and hence no need for respiratory gating. The scan duration is then not extended, and a non-gated image will be generated making use of all the acquired coincidences; patient throughput is hence improved while image quality is retained. In combination, our evaluation aimed to enable a threshold value of R to be selected based on the expected veracity of the waveform.|$|R
40|$|This {{thesis is}} focused on the design, analysis, {{simulation}} and implementation of new improved architectures of the Time Delay Digital Tanlock Loop (TDTL) based digital phase-locked loop (DPLL). The proposed architectures overcome some fundamental limitations exhibited by the original TDTL. These limitations include the presence of nonlinearity in the phase detector (PD), the non-zero phase error of the first-order loop, the restricted locking range, particularly of the second-order loop, the limited acquisition speed and the noise performance. Two approaches were adopted in this work to alleviate these limitations: the first involved modifying the original TDTL through the incorporation of auxiliary circuit blocks that enhance its performance, whilst the second involved designing new tanlock-based architectures. The proposed architectures, which resulted from the above approaches, were tested under various input signal conditions and their performance was compared with the original TDTL. The proposed architectures demonstrated an improvement of up to fourfold in terms of the acquisition times, twofold in noise performance and a marked enhancement in the linearity and in the locking range. The effectiveness of the proposed tanlock-based architectures was also assessed and demonstrated by using them in various applications, which included FM demodulation, FM <b>threshold</b> <b>extension,</b> FM demodulation with improved THD (total harmonic distortion), and Doppler effect improvement. The results from these applications showed that the performance of the new architectures outperformed the original TDTL. Real-time performance of these architectures was evaluated through implementation of some of them on an FPGA (field-programmable gate array) based system. Practical results from the prototype FPGA based implementations confirmed the simulation results obtained from MATLAB/Simulink. ...|$|E
40|$|This {{dissertation}} {{is concerned}} with problems in statistical processing of Radar, Sonar and optical signals including model order selection, parameter estimation, power spectral density estimation, signal detection and classification. ^ It is proved that the exponentially embedded families (EEF), which is a recently proposed model order selection criterion, is consistent. It {{is also found in}} computer simulations that the EEF works well in difficult situations. ^ A method is proposed to evaluate the CRLB via the characteristic function. With the proposed method, the CRLBs of the scale parameter and the shape parameter of the K-distribution are successfully computed. It is also proved in general, that the Cramer-Rao lower bound of the shape parameter does not depend on the scale parameter. ^ A prewhitened PSD estimator based on matrix prewhitening is proposed. Compared to the traditional prewhitened PSD estimators, the proposed estimator has smaller overall mean square error for short data records. ^ For composite hypothesis testing, the generalized likelihood ratio test (GLRT) and the Bayesian approach are two widely used methods. These two methods are investigated for signal detection with distributed sensors. It is proved that the performance of the GLRT can be poor and two types of improved GLRTs are proposed. The improved GLRT of the second type is in fact an approximate Bayesian detector. ^ The performance analysis of the GLRT for composite detection with distributed sensors led to a conjectured property of the noncentral chi-squared distribution. For the special case of complex data and a weak signal, the conjecture is proved. The implications of the conjectured property are discussed. ^ From the assumption of a stationary background and based on the autoregressive (AR) spectrum modeling, a two-step approach for chemical identification in Raman spectra is proposed. Some practical problems are also discussed, such as setting the detection <b>threshold,</b> <b>extension</b> to non-stationary backgrounds, and the identifiability of chemicals. ...|$|E
40|$|Constant Envelope OFDM {{provides}} {{a solution to}} the issue of a high peak-to-average power ratio in OFDM by using angle modulation to transform the OFDM signal to a constant envelope signal. However, Constant Envelope OFDM is based on nonlinear angle modulation and therefore presents its own unique set of challenges. These challenges are studied in this dissertation and addressed through the application of signal reception, equalization and error correction coding techniques to enable robust Constant Envelope OFDM performance. The impact of the threshold effect on Constant Envelope OFDM is studied. More specifically, the impact of cycle slip noise, both due to the threshold effect and phase wrapping issues, on Constant Envelope OFDM performance is considered. A novel cycle slip mitigation technique is developed which results in significant <b>threshold</b> <b>extension.</b> Novel receivers for Constant Envelope OFDM are also developed which allow for a lower complexity receiver implementation. These receivers alleviate the need to employ a phase demodulator at the receiver also resulting in immunity from the threshold effect and phase wrapping issues. The performance of these linear receivers is studied in additive white Gaussian noise (AWGN) and multipath fading channels and they are shown to perform well compared to the conventional arctangent based receiver. In frequency selective fading channels, a frequency domain equalizer is applied to Constant Envelope OFDM and shown to provide good performance in all cases. Since the performance of the frequency domain equalizer depends {{on the quality of the}} channel estimate, the effect of the amplifier nonlinearities on the channel estimate is studied for the case of alternate channel estimation training symbols. Furthermore, the application of error correction coding to Constant Envelope OFDM is also studied for the alternate receivers in AWGN and multipath fading channels. Finally, the impact of narrowband interference on Constant Envelope OFDM is studied. A prediction error filter (PEF) is employed to mitigate the narrowband interference resulting in significant performance improvement at low signal to interference ratio...|$|E
40|$|The entropy {{method for}} image {{thresholding}} suggested by Kapur et al. has been modified {{and a more}} pertinent information measure of the image is obtained. Essentially this consists of viewing the image as a compositum of two fuzzy sets correponding of the two classes with membership coefficient associated with each gray level a function of its frequency of occurrence {{as well as its}} distance from the intermediate <b>threshold</b> selected. An <b>extension</b> of this technique to consider the semantic content of the image is also discussed. The superiority of the suggested method over artificial histograms modelled by Gaussian distributions is demonstrated. Experimental results on several images are also presented to support the validity of the concepts used. (C) 1994 Academic Press, Inc...|$|R
40|$|We {{describe}} a generalization of the Lellouch-Lüscher formula {{to the case}} of multiple strongly-coupled decay channels. As in the original formula, our final result is a relation between weak matrix elements in finite and infinite volumes. Our extension is limited to final states with two scalar particles, with center of mass energies below the lowest three- or four-particle <b>threshold.</b> Otherwise the <b>extension</b> is general, accommodating any number of channels, arbitrary strong coupling between channels, as well as any form of weak decay operators in the matrix elements. Among many possible applications, we emphasize that this is a necessary first step {{on the way to a}} lattice-QCD calculation of weak decay rates for D -> pi pi and D -> K K-bar. Our results allow for arbitrary total momentum and hold for degenerate or non-degenerate particles. Comment: Conference proceeding...|$|R
40|$|This paper {{presents}} a report {{dealing with the}} potential impact of outsourcing on health care processes. By referring to a wider scope of industries and sectors, as they have been the experimental fields of most of the studies on outsourcing, we highlight {{the pros and cons of}} the outsourcing of activities related to patient care. Although the lack of empirical evidence, this paper intend to show and contextualize the (yet) ambiguous effects of relying on external partners in delivering services which are related to the health of patients. We argue that the seek for efficiency might sometimes hinder the global outcome of care; further we state that given the peculiar nature of the healthcare, outsourcing need to be used within a wider strategic analysis of the activities and thus organizations should carefully identify the <b>threshold</b> for its <b>extension...</b>|$|R
40|$|We {{show that}} the Langevin {{equation}} for a nonlinear-optical system may be obtained directly from the Heisenberg equation of motion for the annihilation operators, provided a certain linearization procedure is valid. We apply the technique to the parametric oscillator used to generate squeezed light and compare our results to those obtained from Fokker-Planck-type equations. We argue that, only when the Wigner, {{as opposed to the}} P or Q, representation of quantum optics is used, do we get a correct description of the underlying stochastic process. We show how the linearization procedure may be carried out to describe the operation of the parametric oscillator both below threshold, where a squeezed vacuum state results, and above threshold, where we find a squeezed coherent state. In the region of the <b>threshold</b> a heuristic <b>extension</b> of the method leads to a possible description of the system by means of a nonlinear Langevin equation...|$|R
40|$|The strong {{interaction}} of elementary particles {{is described by}} Quantum Chromodynamics (QCD). Utilizing this theory to describe and predict experimental data requires a number of concepts and techniques. Three of these, namely factorization, resummation and numerical phase space integration, are first reviewed and then applied here. Factorization into perturbative and non-perturbative contributions is an essential tool in understanding scattering processes involving hadrons. After reviewing factorization in a general context the concept is particularized and applied to derive resummation. Observables in {{strong interaction}}s are usually expressed as series in the strong coupling constant. Resummation allows one to derive all-order, albeit still perturbative information on such observables. It is explained in which way such resummation calculation are closely related, and indeed dependent on factorization. Deep-inelastic charm production {{is presented as a}} process into which valuable insights can be gained through resummation, taking into account also the polarizations of the initial state particles. Whereas up to now resummation has been limited to those terms in the perturbation series kinematically dominant in some specific regions of phase space (e. g. near production <b>thresholds),</b> an <b>extension</b> of the method will be presented here to include also constant terms. In this context the discussion focusses on the Drell-Yan process. Finally, numerical phase space integrations are investigated for a process involving the production of strongly interacting heavy final state particles. Here two methods, namely the phase space slicing and the dipole subtraction methods, are explained and compared as to their numerical performances...|$|R
40|$|This paper {{deals with}} the service parts {{end-of-life}} inventory problem in a circumstance that demands for service parts are differentiated. Customer differentiation {{might be due to}} criticality of the demand or based on various service contracts. In both cases, we model the problem as a finite horizon stochastic dynamic program and characterize the structure of the optimal policy. We show that when customers are differentiated based on the demand criticality then the optimal structure consists of time and state dependent threshold levels for inventory rationing. In case of differentiation based on service contracts, we show that in addition to rationing thresholds we also need contract <b>extension</b> <b>thresholds</b> by which the system decides whether to offer an extension to an expiring contract or not. By numerical experiments in both cases, we identify the value of incorporating such decisions in service parts end-of-life inventory management with customer differentiation. Moreover, we show that these decisions not only result in cost efficiency but also decrease the risk of part obsolescence drastically...|$|R
40|$|We {{develop a}} novel {{approach}} to chiral meson-baryon dynamics incorporating unitarity constraints and explicit resonance fields. It {{is based on the}} most general structure of any pion-nucleon partial wave amplitude neglecting the unphysical cuts as derived from the N/D method. This amplitude is then matched to the one-loop heavy baryon chiral perturbation theory result at third order and to tree level exchanges of baryon and meson states in the s,t and u channels. This generates the left-hand cuts. The unitarization procedure does not involve form factors or regulator functions. The resonance parameters are determined from fits to the S- and P-wave pion-nucleon partial wave amplitudes for energies up to 1. 3 GeV. In particular, the Delta(1232) is accurately reproduced whereas scalar and vector meson couplings are less precisely pinned down. We also obtain a satisfactory description of the pi-N <b>threshold</b> parameters. Further <b>extensions</b> of this method to coupled channels and the three-flavor case are briefly discussed...|$|R
40|$|Thresholding {{is one of}} {{the most}} widely used image {{segmentation}} operations; one application is foreground-background separation. Multilevel <b>thresholding</b> is the <b>extension</b> to segmentation into more than two classes. In order to find the thresholds, which separate the classes, the histogram of the image is analyzed. In most cases, the optimal thresholds are found by the minimazing or maximazing an objective function, which depends on the positions of the thresholds. We identify a class of objective functions for which the optimal thresholds can be found using algorithms with low time complexities. We also show, that two well known objective functions are members of this class. By implementing the algorithms and comparing their execution times, we can make a quantitative statement about their performance. Acknowledgements We gratefully thank Professor Guido M. Schuster and Professor Aggelos K. Katsaggelos for giving us the great opportunity to write our diploma thesis at Northwestern University. Our special thank goes to Professor Aggelos K. Katsaggelos, for his hospitality and for hi...|$|R
40|$|International audienceInvestment {{decision}} {{rules in}} risk situations have been extensively analyzed for firms. Most research focus on financial options {{and the wide}} range of methods based on dynamic programming currently used by firms to decide on whether and when to implement an irreversible investment under uncertainty. The situation is quite different for public investments, which are decided and largely funded by public authorities. These investments are assessed by public authorities, not through market criteria, but through public Cost Benefit Analysis (CBA) procedures. Strangely enough, these procedures pay little attention to risk and uncertainty. The present text aims at filling this gap. We address the classic problem of whether and when an investment should be implemented. This stopping time problem is established in a framework where the discount rate is typically linked to GDP, which follows a Brow-nian motion, and where the benefits and cost of implementation follow linked Brownian motions. We find that the decision rule depends on a threshold value of the First Year Ad-vantage/Cost ratio. This threshold can be expressed in a closed form including the means, standard deviations and correlations of the stochastic variables. Simulations with sensible current values of these parameters show that the systemic risk, coming from the correlation between the benefits of the investment and economic growth, is not that high, and that more attention should be paid to risks relating to the construction cost of the investment; furthermore, simple rules of thumb are designed for estimating the above mentioned <b>threshold.</b> Some <b>extensions</b> are explored. Others are suggested for further research...|$|R
