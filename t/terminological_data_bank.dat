3|7086|Public
40|$|AbstractThe {{increasing}} demand of terminographic support {{as a language}} tool in the research projects of international consortia in the scientific-technical area has prompted {{the need to develop}} specific glossaries of a given domain or sub-domains that would supply a common unified bilingual or multilingual terminological framework of a specific field of knowledge. Bearing this in mind, the TEMPUS Project entitled ‘Observatoire de Formations en Logistique OFL & de Plateformes d’Excellence en Logistique’ is also focused on creating a <b>terminological</b> <b>data</b> <b>bank</b> that would contribute to facilitate communication and knowledge transfer among the specialists in the maritime transport area in the English and Spanish languages. The main aim of this work is to describe the corpus design and compilation process in logistics and maritime transport that shall be the terminological basis for the LogisTRANS bilingual glossary formalization. Besides this, it shall be outlined the filter preparation tool for terminology extraction which has been especially designed for this work as well as the corpus representativeness measurement method employed...|$|E
40|$|The {{articles}} {{focuses on}} one of the fundamental choices to be made prior {{to the creation of a}} translation-oriented <b>terminological</b> <b>data</b> <b>bank,</b> namely, its position between absolute prescription and absolute description in order to find the right balance between pragmatics and harmonisation. Both the traditional outlook on terminology, which emphasises the importance of standardisation, and some recent approaches, that lay stress on single texts, are unsuitable. The most promising solution seems to be an intermediate one, based on the analysis of a significant corpus of texts in order to determine the privileged characteristics and other prototypical factors: on the one hand, the importance for the specialised translator to obtain the pragmatic equivalent even on a terminological level, on the other, the contribution the translator can make towards harmonisation of terminology. The latter does not imply a prescriptive approach, but entails paying greater attention to the self-regulating attempts (either conscious or unconscious) of specialists...|$|E
40|$|A {{description}} of a model linguistic data bank (LDB) for a British market will be given, {{based on the results}} of a continuing feasibility study. A LDB represents an economical and highly efficient way of organizing Britain’s efforts in the field of terminology, both with respect to English and the many foreign languages through which contact is maintained with non-English speaking countries. The institutional and organizational structure will be outlined. Emphasis will be placed on services to be provided to various groups, and in particular to translators, and on the important role these groups will play in assuring the continued viability and relevance of the LDB, not only as users, but as contributors and advisers. Data acquisition policy and financial aspects will be considered. A multilingual, multidisciplinary British LDB will provide translators with a valuable service, whose applications are many, whose products are varied to cater for a wide range of needs, whose terminology is continually revised and updated and whose modes of consultation are several. THIS PAPER IS based on results obtained from a continuing feasibility study of the establishment of a <b>terminological</b> <b>data</b> <b>bank</b> in the United Kingdom, a study bein...|$|E
40|$|INFORMATION TECHNOLOGY IS a new {{interdisciplinary}} field combining infor-mation science, computing, {{telecommunications and}} electronics. As it establishes links across national and linguistic boundaries it also acquires a multilingual dimension requiring translators as links in the interlingual communication process. The translator thus {{can no longer}} be considered in isolation; he is simply another mediator, generally between natural languages, similar in function to information scientists who mediate between natural and artificial languages, be they documentation languages or command languages to access databases, and similar also to those computational linguists who mediate between natural languages and computer languages. Interlingual communi-cation is expanding and its means and methods are changing. This is not only reflected in two major Aslib Conferences on this topic in two years, but in Action Plans of the Commission of the EC, the activities of INFOTERM in Vienna, ISO, FID, and UNESCO involvement in this work, the growth of <b>terminological</b> <b>data</b> <b>banks,</b> as well as new organizations and studies in every developed country, some of which were mentioned during this conference...|$|R
40|$|Traditionally, terminological {{products}} such as glossaries {{have been used to}} find suitable equivalents in the coding stage of translation, i. e. in the reformulation of the message in the target language. Developments in terminology have {{led to the creation of}} glossaries and <b>terminological</b> <b>data</b> <b>banks</b> which now often include background information on terms. On these grounds, an experiment has been conducted with fourth-year students of the translation course at the Scuola Superiore di Lingue Moderne per Interpreti e Traduttori of the University of Trieste to ascertain whether terminological products can also be of service in the preliminary stage of translation, i. e. in message decoding through text analysis. A model of terminological text analysis for the purposes of specialised translation was devised and a group of students was asked to adopt it for the experiment, while a control group of students was given a list of translation equivalents and was allowed to use other reference material. Although further tests are needed to confirm the authors' hypotheses, the results of the experiment suggest that terminological products including background information on terms may partially make up for lack of subject-specific knowledge when conducting text analysis in the preliminary stage of translation of highly specialised texts...|$|R
40|$|This paper {{discusses}} the changes {{brought by the}} communication revolution {{in teaching and learning}} in the scope of LSP. Its aim is to provide an insight on how teaching which was bi-dimensional, turned into a multidimensional system, gathering other complementary resources that have transformed, in a incredibly short time, the ways we receive share and store information, for instance as professionals, and keep in touch with our peers. The increasing rise of electronic publications, the incredible boom of social and professional networks, search engines, blogs, list servs, forums, e-mail blasts, Facebook pages, YouTube contents, Tweets and Apps, have twisted the way information is conveyed. Classes ceased to be predictable and have been empowered by digital platforms, innumerous and different data repositories (TILDE, IATE, LINGUEE, and so many other <b>terminological</b> <b>data</b> <b>banks)</b> that have definitely transformed the academic world in general and tertiary education in particular. There is a bulk of information to be digested by students, who are no longer passive but instead responsible and active for their academic outcomes. The question is whether they possess the tools to select only what is accurate and important for a certain subject or assignment, due to that overflow? Due to the reduction of the number of course years in most degrees, after the implementation of Bologna and the shrinking of the curricula contents, have students the possibility of developing critical thinking? Both teaching and learning rely on digital resources to improve the speed of the spreading of knowledge. But have those changes been effective to promote really communication? Furthermore, with the increasing Apps that have already been developed and will continue to appear for learning foreign languages, for translation among others, will the students feel the need of learning them once they have those Apps. These are some the questions we would like to discuss in our paper...|$|R
50|$|The two are {{mutually}} interdependent, since the standardization of terminologies would {{not result in}} high-quality <b>terminological</b> <b>data,</b> if certain common principles, rules and methods are not observed. On the other hand, these standardized terminological principles, rules and methods must reflect the state-of-the-art of theory and methodology development in those domains, in which <b>terminological</b> <b>data</b> have to be standardized {{in connection with the}} formulation of subject standards.|$|R
50|$|The above {{indicates}} that <b>terminological</b> <b>data</b> (comprising {{various kinds of}} knowledge representation) possibly {{have a much more}} fundamental role in domain-related information and knowledge than commonly understood.|$|R
40|$|Achieving {{goals of}} healthy people and populations is {{dependent}} on available and relevant data for health care decisions. New technologies enable reuse of data for deci-sions, however {{it is clear that}} uniform data standards and in particular standards around <b>terminological</b> <b>data</b> will be required to achieve reuse. <b>Terminological</b> <b>data</b> related to functioning and disability presents unique challenges because of the conceptual ambiguity within the field. The International Classification of Functioning, Disability, and Health (ICF) provides a clarifying conceptual foundation for func-tioning and disability data, but is not struc-tured as a formal terminology. The need for a concerted and coordinated ef for t is emphasized...|$|R
40|$|A terminological thesis {{written in}} the Department of Modern Languages at the University of Applied Sciences Cologne {{contains}} descriptive terminology of a limited domain. These systematic, concept-oriented <b>terminological</b> <b>data</b> are available in electronic form (MultiTerm database format). The WebTerm Project aims to consolidate and convert the <b>terminological</b> <b>data</b> to a web-based system allowing efficient and free access to these terminologies. Special {{attention is paid to}} the dynamic representation of the system of con-cepts and the ontological relations of these data collections. The paper describes the structure and content of the terminological theses and the terminology contained, as well as the web-based dynamic interface to the ontologies and terminologies developed in the framework of the WebTerm Project. 1...|$|R
40|$|Colloque avec actes et comité de lecture. internationale. International audienceThis {{paper is}} {{intended}} to provide {{a description of the}} functionalities of the Dhydro platform for the editing and consultation of multilingual <b>terminological</b> <b>data</b> bases. Initially, this platform was developed to allow the updating and computerized accessibility of the International Hydrographic Dictionary (IHD). Published by the International Hydrographic Bureau (IHB), this dictionary initially consisted of three monolingual volumes (English, French, and Spanish) containing hydrography-related terminology. These dictionaries were maintained by editors specialized in each of the languages. However, the geographical distance between them adversely affected the actual development of the dictionaries, whereas the printed format restricted the dissemination of terminology vital to the maritime community. The Dhydro project has two major objectives: - To provide the editors with the necessary communication tools to enable them effectively to interact with each other, to edit <b>terminological</b> <b>data,</b> to ensure quick access to the data base and to publish it in various formats (bilingual or trilingual glossaries, monolingual dictionaries, etc.). - To ensure the widest possible access to the <b>terminological</b> <b>data</b> base, with the IHB having agreed to publicize the data resulting from the project...|$|R
40|$|International audienceTermBase eXchange (TBX) has {{provided}} a successful mechanism for exchanging complex <b>terminological</b> <b>data.</b> Because TBX defines a family of related formats for representing <b>terminological</b> <b>data</b> rather than a single format, it {{can be adapted to}} many needs. However, use within commercial production environments has remained limited due to the perception that TBX is too complex for particular use cases. This paper describes {{the development of a new}} derivative of TBX, called TBX-Min, that is designed to represent the sorts of columnar tables of terms in two languages widely used by practicing translators, in a TBX-compatible fashion. Through TBX-Min, translators will be able to send and receive simple, machine-processable bilingual terminology while still gaining access to the wider ecosystem of TBX-compliant tools...|$|R
30|$|Finally, in {{the stage}} of {{interchange}} and diffusion of terms, the entries are edited and the diffusion, interchange, and query of the terminological products may be performed {{with the help of}} applying <b>terminological</b> <b>data</b> exporting tools, making it possible for the users to query the entries.|$|R
40|$|This {{paper is}} {{intended}} to provide {{a description of the}} functionalities of the Dhydro 1 platform for the editing and consultation of multilingual <b>terminological</b> <b>data</b> bases. Initially, this platform was developed to allow the updating and computerized accessibility of the International Hydrographic Dictionary (IHD). Published by the International Hydrographic Bureau (IHB), this dictionary initially consisted of three monolingual volumes (English, French, and Spanish) containing hydrography-related terminology. These dictionaries were maintained by editors specialized in each of the languages. However, the geographical distance between them adversely affected the actual development of the dictionaries, whereas the printed format restricted the dissemination of terminology vital to the maritime community. The Dhydro project has two major objectives: • To provide the editors with the necessary communication tools to enable them effectively to interact with each other, to edit <b>terminological</b> <b>data,</b> to ensure quick access to the data base and to publish it in various formats (bilingual or trilingual glossaries, monolingual dictionaries, etc.). • To ensure the widest possible access to the <b>terminological</b> <b>data</b> base, with the IHB having agreed to publicize the data resulting from the project 2. While this clearly identified the thematic field, we also sought to ensure that the tools used would be independent of, on the one hand, any particular area of specialization, and, on the 1 DHYDR...|$|R
40|$|International audienceTermBase eXchange (TBX), the ISO {{standard}} for the representation and interchange of <b>terminological</b> <b>data,</b> is currently undergoing revision and will {{for the first time}} formalize overarching structural constraints regarding the definition and validation of dialects and XML styles. The paper describes the design of an ODD architecture, which allows for a complete specification of presentday TBX...|$|R
40|$|The paper {{describes}} an emerging trend {{for the next}} generation of terminology platforms. These platforms will serve not only as a source of semantically rich consolidated multilingual <b>terminological</b> <b>data</b> but will also provide a va-riety of online terminological services becom-ing part of a multifaceted global cloud-based service infrastructure. As an example demon-strating this trend we describe the develop-ment of terminology services for the Eu-roTermBank database. ...|$|R
50|$|TermBase eXchange (TBX) is an {{international}} standard (ISO 30042:2008) for the representation of structured concept-oriented <b>terminological</b> <b>data,</b> copublished by ISO and the Localization Industry Standards Association (LISA). Originally released in 2002 by LISA’s OSCAR special interest group, TBX was adopted by ISO TC 37 in 2008. It is currently available as an ISO standard and as an open, industry standard, available at no charge.|$|R
40|$|Dictionaries, thesauri, {{nomenclatures}} {{are among}} the conventional tools for the systematic organization of terms and concepts of medicine. Computer support provides new functions for them, mainly because it allows for the co-existence in the same system of different views and approaches, until now in alternative. We analyze and model the general (language independent) features of both linguistic-terminological aspects and conceptual aspects of an integrated <b>terminological</b> <b>data</b> base of medicine...|$|R
40|$|Using {{computers}} for terminology management has an almost 50 years old history. At {{the beginning of}} the sixties of the last century main frame computers were programmed to elaborate, maintain and retrieve <b>terminological</b> <b>data</b> collections. Later mini computers and (networking) personal computers were used to manage terminology for certain subject fields and the way of supporting terminological activities changed. Today the internet provides not only a medium for terminological research but also an online platform for world-wide cooperative terminology work. The paper describes the different stages of computational terminology management with special attention to the possibilities how the software solutions can support (and impede) the terminologist. In particular it is explained in detail how specific principles and methods of terminology theory were influenced by the technology and how terminological working methods have changed over the time. Special attention is drawn to ISO standards for <b>terminological</b> <b>data</b> modelling and the possibilities the world wide web offers to terminologists. Εξελίξεις της υπολογιστικής διαχείρισης ορολογίας και επίδρασή της στην επιστήμη Ορολογία και στην ορολογική εργασί...|$|R
50|$|The Dortmund <b>Data</b> <b>Bank</b> is {{distributed}} by DDBST GmbH as in-house software. Many {{parts of the}} Dortmund <b>Data</b> <b>Bank</b> are also distributed {{as part of the}} DETHERM <b>data</b> <b>bank</b> which is also available online.|$|R
40|$|This manual {{details the}} input {{instructions}} to the <b>data</b> <b>bank,</b> and explanation {{of the program and}} its output. The <b>data</b> <b>bank</b> was developed in satisfaction of two of the study tasks, the equipment thermal requirement catalog and the equipment characteristics and constraints catalog. The <b>data</b> <b>bank</b> contains 109 components within space tug avionics system. Other systems {{were not included in the}} <b>data</b> <b>bank</b> due to the available information, however, with some program modification, other systems could be incorporated into the <b>data</b> <b>bank</b> program. The <b>data</b> <b>bank</b> was developed and checked out and is compatible with the Univac 1108, and the CDC 6500 operating systems. The data contained in the <b>data</b> <b>bank</b> is general in content with emphasis on the component thermal design. The data is applicable to any spacecraft program where the components contained in the <b>data</b> <b>bank</b> can be applied in satisfaction of the system and subsystem requirements...|$|R
50|$|The <b>Data</b> <b>Bank</b> {{was created}} by Congress with the primary goals of {{improving}} health care quality, protecting the public and reducing health care fraud and abuse. The <b>Data</b> <b>Bank</b> is managed by the Bureau of Health Workforce of the Health Resources and Services Administration in the U.S. Department of Health and Human Services. Before May 6, 2013, the <b>Data</b> <b>Bank</b> comprised the National Practitioner <b>Data</b> <b>Bank</b> and the Healthcare Integrity and Protection <b>Data</b> <b>Bank.</b> The two were consolidated by Section 6403 of the Affordable Care Act of 2010, Public Law 111-148.|$|R
40|$|The biophysical {{differences}} between {{different kinds of}} DNA <b>data</b> <b>banks</b> are described. The different ethical implications of DNA fingerprint <b>data</b> <b>banks,</b> <b>data</b> <b>banks</b> of known gene sequences, and <b>data</b> <b>banks</b> of total genomic sequences are considered. Ethical approaches using {{the concept of the}} common good and those based on human rights are evaluated in the context of DNA data. Additional theological considerations are discussed. In conclusion, a 'one size fits all' approach to bioethics in this area is rejected...|$|R
5000|$|In telecommunications, a <b>data</b> <b>bank</b> is a {{repository}} of information on one or more subjects that is organized {{in a way that}} facilitates local or remote information retrieval. A <b>data</b> <b>bank</b> may be either centralized or decentralized.In computers the <b>data</b> <b>bank</b> is the same as in telecommunication (i.e. it is the repository of data. The data in the <b>data</b> <b>bank</b> can be things such as credit card transactions or it can be any data base of a company where large quantities of queries are being processed on daily bases). [...] <b>Data</b> <b>bank</b> may also refer to an organization primarily concerned with the construction and maintenance of a database.|$|R
50|$|Gmehling {{began in}} the 1970s with the {{systematic}} evaluation of the scientific literature, aiming to build a <b>data</b> <b>bank</b> for vapor-liquid equilibria. These data were needed {{for the development of}} a new method for the prediction of activity coefficients named UNIFAC. This <b>data</b> <b>bank</b> is still named the Dortmund <b>Data</b> <b>Bank.</b>|$|R
40|$|OBJECTIVES: This study {{examined}} hospital administrators' {{experiences with the}} National Practitioner <b>Data</b> <b>Bank.</b> METHODS: One hundred forty-nine rural hospital administrators completed questionnaires assessing {{their perceptions of the}} <b>data</b> <b>bank.</b> RESULTS: Nearly 90 % of respondents rated the <b>data</b> <b>bank</b> as an important source of information for credentialing. Three percent indicated it had directly affected privileging decisions; 43 % and 34 %, respectively, believed the costs exceeded or equaled the benefits. Twenty percent reported changes that could decrease disciplinary action reports to the <b>data</b> <b>bank.</b> CONCLUSIONS: While the National Practitioner <b>Data</b> <b>Bank</b> is an important source of information to rural hospitals, it may, affect few credentialing decisions and motivate behavioral changes that could have a paradoxical effect on quality assurance...|$|R
50|$|The Healthcare Integrity and Protection <b>Data</b> <b>Bank</b> was {{merged into}} the National Practitioner <b>Data</b> <b>Bank</b> as of May 6, 2013, in {{accordance}} with 78 FR 20473.|$|R
40|$|The modern <b>data</b> <b>bank</b> {{emphasizes}} {{immediate access}} by a user community {{which may be}} large in number, widespread, and having varied needs. Electronic computers have been found very useful in the processing of stored information. The key {{to the design of}} a <b>data</b> <b>bank</b> is the optimum mix of human intellectual effort and mechanized processing. The elements of the NASA <b>data</b> <b>bank</b> are presented as one approach to the many trade-off decisions involved {{in the development of a}} <b>data</b> <b>bank</b> and integrated information system...|$|R
50|$|Group {{contributions}} are obtained from known experimental data of well defined pure components and mixtures. Common sources are thermophysical <b>data</b> <b>banks</b> like the Dortmund <b>Data</b> <b>Bank,</b> Beilstein database, or the DIPPR <b>data</b> <b>bank</b> (from AIChE). The given pure component and mixture properties are then {{assigned to the}} groups by statistical correlations like e. g. (multi-)linear regression.|$|R
50|$|The {{worldwide}} Protein <b>Data</b> <b>Bank</b> (wwPDB) is {{an excellent}} source of protein and nucleic acid molecular coordinate data. The data is three-dimensional and provided in Protein <b>Data</b> <b>Bank</b> (PDB) format.|$|R
50|$|The data {{behind this}} {{software}} largely originated from the Forensic <b>Data</b> <b>Bank,</b> which is contributed {{to by the}} University of Tennessee and other contributing institutions. The Forensic <b>Data</b> <b>Bank</b> was created in 1986, {{through the use of}} a National Institute of Justice grant, and has gathered over 3400 cases.The Forensic <b>Data</b> <b>Bank</b> is a currently ongoing effort to record information about modern populations, primarily from forensic cases.|$|R
50|$|Gerard Jacob Kleywegt (born 5 June 1962, Rozenburg) is a Dutch X-ray {{crystallographer}} and {{the former}} team leader of the Protein <b>Data</b> <b>Bank</b> in Europe at the EBI; {{a member of the}} Worldwide Protein <b>Data</b> <b>Bank.</b>|$|R
40|$|Abstract. Recent {{developments}} in computational terminology {{call for the}} design of multiple and complementary tools for the acquisition, the structuring and the exploitation of <b>terminological</b> <b>data.</b> This paper proposes {{to bridge the gap between}} term acquisition and thesaurus construction by offering a framework for automatic structuring of multi-word candidate terms with the help of corpus-based links between single-word terms. Hypernym links acquired through an information extraction procedure are projected on multi-word terms through the recognition of semantic variations. The induced hierarchy is incomplete but provides an automatic generalization of singleword terms relations to multi-word terms that are pervasive in technical thesauri and corpora...|$|R
50|$|The Worldwide Protein <b>Data</b> <b>Bank,</b> wwPDB, is an {{organization}} that maintains the archive of macromolecular structure. Its mission is to maintain a single Protein <b>Data</b> <b>Bank</b> Archive of macromolecular structural data that is freely and publicly available to the global community.|$|R
50|$|The PDBbind {{database}} is updated on {{an annual}} basis {{to keep up with the}} growth of the Protein <b>Data</b> <b>Bank.</b> The current release, i.e. version 2014, is based on the contents of Protein <b>Data</b> <b>Bank</b> released on Jan 1st, 2014.|$|R
50|$|Protein <b>Data</b> <b>Bank</b> (PDB) files can be {{downloaded}} for visualization {{from members of the}} Worldwide Protein <b>Data</b> <b>Bank</b> (wwPDB). These have been uploaded by researchers who have characterized the structure of molecules usually by X-ray crystallography, protein NMR spectroscopy, or cryo-electron microscopy.|$|R
