30|1626|Public
40|$|This {{document}} {{describes the}} SEC performance estimator (PE). The calculation strategy and the formulae {{applied for the}} calculation of the TerraSAR-X performance parameters are here reported and explained. The task of the PE is to estimate the overall SAR system performance and to support the generation of parameter tables required in the commanding and processing of TS-X data takes. This report explains how the commitments of the IOCS Functional Requirements Document (TX-IOCS-RS- 4101) w. r. <b>t.</b> <b>performance</b> estimation and control will be fulfilled...|$|E
40|$|A b s t r a c <b>t</b> <b>Performance</b> on {{specialized}} {{diagnostic tests}} for platelet disorders, including dense-granule deficiency, is rarely evaluated by external quality assessment (EQA). Members of the North American Specialized Coagulation Laboratory Association that evaluate platelet dense-granule deficiency commonly use whole-mount electron microscopy (EM) methods. This observation {{led us to}} develop a pilot EQA survey with standardized EM images and clinical samples on grids from a healthy control subject and a subject with dense-granule deficiency. The survey participants were 8 centers, including 2 with no experience in platelet whole mount EM. All participants, including inexperienced sites, correctly interpreted finding...|$|E
40|$|Abstract: Building the Semantic Web {{requires}} {{the use of}} powerful tools to create, manage and extend domain ontologies represented with Semantic Web languages. Though many tools have been already developed, unfortunately {{there is a lack of}} practice using them in real-world applications. The suitability of these tools and the underlying technologies, especially w. r. <b>t.</b> <b>performance</b> and scalability parameters, is still an open issue. This paper focuses on problems and experiences gained in the project ”A Semantic Web for Pathology”, a research project using domain ontologies and ontology-driven natural language processing to support a content-based storage and retrieval for text and image-based medical information. ...|$|E
5000|$|... #Subtitle level 3: <b>Test</b> <b>performance</b> {{for primary}} and {{secondary}} schools ...|$|R
5000|$|... "Lookin' On" [...] (Old Grey Whistle <b>Test</b> <b>performance,</b> 10/01/81) - 5:10 ...|$|R
5000|$|... #Subtitle level 4: Test Anxiety and Situational Factors Affecting <b>Test</b> <b>Performance</b> ...|$|R
40|$|Cache {{memory has}} {{shown to be}} the most {{important}} technique to bridge the gap between the processor speed and the memory access time. The advent of high-speed RISC and superscalar processors, however, calls for small on-chip data caches. Due to physical limitations, these should be simply designed and yet yield good performance. In this paper, we present new cache architectures that ad-dress the problems of conflict misses and non-optimal line sizes in the context of direct-mapped caches. Our cache architectures can be reconfigured by software in a way that matches the reference pattern for array data structures. We show that the implementation cost of the reconfiguration capability is neglectable. We also show simulation results!M demons tratc sign i fican <b>t</b> <b>performance</b> improvements for both methods. ...|$|E
40|$|Non-standard {{database}} systems {{become available}} now, even as commercial products. They overcome {{a lot of}} de#ciencies of relational systems w. r. t. their use in engineering applications like computer-aided design or software engineering. Their rather sophisticated functionality especially concerning the manipulation of complex objects makes them highly attractive for engineering applications. If being used as the central database of a rather complex application they could however still become a bottleneck w. r. <b>t.</b> <b>performance.</b> This paper presents a new way how to de#ne a special purpose benchmark which enables to select the fastest database system for a particular software engineering application. It is argued that existing benchmarks are not appropriate to support such a selection, because they neglect important application speci#c characteristics which signi#cantly in#uence the database performance. 1 Introduction Integrated Software Development Environments #SDEs# include a number of to [...] ...|$|E
40|$|A b s t r a c <b>t.</b> <b>Performance</b> {{evaluation}} {{is a central}} issue {{in the design of}} complex real-time systems. In this work, we propose an extension of so-called &quot;Max-Plus &quot; algebraic techniques to handle more realistic types of real-time systems. In particular, our framework encompasses graph or partial order automata, and more generally abstract models of real-time computations (including synchronous programs running over distributed architectures). To achieve this, we introduce a new dioid of partially commutative power series (transductions), whose elements encode timed behaviors. This formalism extends the traditional representation of timed event graphs by (rational) commutative transfer series with coefficients in the Max-Plus semiring. We sketch how this framework can be used to symbolically solve several problems of interest, related to real-time sys-tems. Then we illustrate the use of this framework to encode a nontrivial mixed formalism of dataliow diagrams and automata. 1 M o t i v a t i o n...|$|E
5000|$|... "Sweet Little Mystery" [...] (Old Grey Whistle <b>Test</b> <b>performance,</b> 10/01/81) - 4:56 ...|$|R
2500|$|Cardus {{also wrote}} that Taylor's {{performance}} was [...] "perhaps the most skilful of all <b>Test</b> <b>performances</b> by a batsman".|$|R
25|$|VVS Laxman's knock of 281 against Australia in Eden Gardens in 2001 {{has been}} rated as the {{greatest}} <b>Test</b> <b>performance</b> of the last 50 years.|$|R
40|$|We model an {{industry}} {{in which a}} discrete number of 8 ̆ 5 rms choose the output of their di¤erentiated products deciding {{whether or not to}} consider the impact of their decisions on aggregate output. We show that two threshold numbers of 8 ̆ 5 rms exist such that: below the lower one there is a unique equilibrium in which all 8 ̆ 5 rms consider their ag-gregate impact as in standard oligopoly; above the higher threshold there is a unique equilibrium in which all 8 ̆ 5 rms disregard that impact as in standard monopolistic competition; between the two thresholds there are two equilibria, one in which all 8 ̆ 5 rms consider their aggregate impact and the other in which they do not. We then show that our model of strategic inattention is isomorphic to a model of strate-gic delegationwith managerial compensation based on relative pro 8 ̆ 5 <b>t</b> <b>performance...</b>|$|E
40|$|The {{changes in}} {{curvature}} in single and double helices {{as they are}} bent into circular arcs are derived from first principles. This analysis is applied to wire ropes to examine the bending strains in the wires of a frictionless rope as it is bent over a sheave. It is shown that the free bending strains in the wires in the innermost layer of a strand in a rope taken as an example are higher {{than those in the}} outer layer wires, while the second wire layer has the lowest bending strains. K e y words: wire curvature, wire rope, bending strains, sheave 1 INTRODYCTION When a wire rope runs over a sheave, its static and fatigue (l) <b>t</b> <b>performance</b> is influenced by: (a) relative movements at the contacts between the strands of the rope, between the various wires forming those strands and between the rope and the groove; (b) stress variations in the wires, within or close to the various contact patches, an...|$|E
40|$|A {{widespread}} implementation {{approach for}} the join point mechanism of aspect-oriented languages is to instrument areas in code that match the static part of pointcut designators, inserting dynamic checks for {{that part of}} matching that depends on run-time conditions, if needed. For performance reasons, such dynamic checks should be avoided whenever possible. One way {{to do so is}} to postpone weaving of advice calls until run-time, when conditions determining the emergence of join points hold. This calls for fluid code [...] -code that adapts itself to the join point emergence at run-time, and suggests that AOP concepts should be integrated into the execution model underlying a VM. In this paper, we present first steps toward such an integration in Steamloom, an extension of IBM's Jikes Research Virtual Machine. Steamloom is fairly restricted, but our initial experimental results indicate that aspect-aware VMs and fluid code are promising w. r. <b>t</b> <b>performance.</b> While the focus in this paper is on performance, there are other advantages of aspect-aware VMs to be investigated in the future...|$|E
25|$|Following Campese's first <b>Test</b> <b>performance,</b> Alec Evans, the {{assistant}} coach of Australia's 1984 Grand Slam side, went public suggesting that Campese should be {{dropped from the}} Australian side.|$|R
25|$|After {{a series}} of poor <b>Test</b> <b>performances</b> {{following}} the resignation of several senior players, the Zimbabwean team was voluntarily suspended from Test cricket in late 2005 by its cricket board, with ICC encouragement.|$|R
25|$|Zimbabwe's early <b>Test</b> <b>performances</b> were {{consistently}} weak, leading to suggestions {{that they had}} been granted Test status prematurely. Of their first 30 Test matches, they won just one, at home against Pakistan in early 1995.|$|R
40|$|We {{propose a}} novel, generic {{definition}} of probabilistic schedulers for population protocols. We then identify the consistent probabilistic schedulers, and prove that any consistent scheduler that assigns a non-zero probability to any transition i → j, where i and j are configurations satisfying i ≠ j, is fair with probability 1. This {{is a new}} theoretical framework that aims to simplify proving specific probabilistic schedulers fair. In this paper we propose two new schedulers, the State Scheduler and the Transition Function Scheduler. Both possess the significant capability of being protocol-aware, i. e. they can assign transition probabilities based on information concerning the underlying protocol. By using our framework we prove that the proposed schedulers, and also the Random Scheduler that was defined by Angluin et al. [2], are all fair with probability 1. Finally, we define and study equivalence between schedulers w. r. <b>t.</b> <b>performance</b> and correctness and prove that there exist fair probabilistic schedulers that are not equivalent w. r. t. to performance and others that are not equivalent w. r. t. correctness. © 2009 Springer-Verlag...|$|E
40|$|Cable Networks, Services, and Management is {{the first}} book to cover cable networks, services, and their management, in-depth, for network operators, engineers, researchers, and students. Thirteen experts in various fields have contributed their {{knowledge}} of network architectures and services, Operations, Administration, Maintenance, Provisioning, Troubleshooting (OAMPT) for residential and business services, cloud, Software Defined Networks (SDN), as well as virtualization concepts and their applications {{as part of the}} future directions of cable networks. The book begins by introducing architecture and services for Data Over Cable Service Interface Specification (DOCSIS) 3. 0 / 3. 1, Converged Cable Access Platform (CCAP), Content Distribution Networks (CDN, IP TV, and Packet Cable and Wi-Fi for Residential Services. Topics that are discussed in proceeding chapters include: operational systems and management architectures, service orders, provisioning, fault manageme <b>t,</b> <b>performance</b> management, billing systems and formats, and security for residential services. Similar to residential services, functions for business services as DOCSIS Provisioning of EPON (DPoE), EPON Protocol over Coax (EPOC), IP Multimedia Subsystem (IMS), fault management, billing systems, and formats are explained...|$|E
40|$|Due t o the complex, {{dynamic and}} {{fast-moving}} na ture of t he a i r combat t a sk, performance A combined ana ly t i ca l Nearly a l l of assessment during a i r- to-a i r combat provides many unique measurement problems. and empirical t echnica l approach was used t o develop a candidate measurement s t r u c t u r e and algorithm f o r t he measurement of p i l o <b>t</b> <b>performance</b> during one-versus-one a i r combat maneuvering. 28 candidate measures were found t o d iscr imina te {{between high and}} low s k i l l e d p i l o t s during f r e e engagements on the Simulator f o r Air-to-Air Combat. algorithm cons is t ing of 13 measures which accounted f o r 51 % of t h e variance i n the performance da ta and which predic ted membership i n high o r low skill groups with 9 % accuracy. Discriminant analyses provided a measuremen...|$|E
5000|$|... "Pick It Up and Kick It"/"Smouldering" [...] was {{released}} {{as the lead}} single in January 1977 which they promoted on their debut Old Grey Whistle <b>Test</b> <b>performance.</b> Less than eight months later Harvey came back.|$|R
50|$|Zimbabwe's early <b>Test</b> <b>performances</b> were {{consistently}} weak, leading to suggestions {{that they had}} been granted Test status prematurely. Of their first 30 Test matches, they won just one, at home against Pakistan in early 1995.|$|R
5000|$|... #Caption: [...] "The Effects of Stereotype Threat on the Standardized <b>Test</b> <b>Performance</b> of College Students (adjusted {{for group}} {{differences}} on SAT)". From J. Aronson, C.M. Steele, M.F. Salinas, M.J. Lustina, Readings About the Social Animal, 8th edition, ed. E. Aronson ...|$|R
40|$|To {{determine}} whether hearing loss in sonar technicians presents {{a potential problem}} for job performance, both for current sonar systems and for future sonar systems incorporating r 2 ew signal-presentation and signal-processing techniques. FINDINGS The hearing threshold levels of sonar technicians were higher (worse) thin the International Standards Organization (ISO) norms, {{which are based on}} people with no history of noise exposure or otologic disease. The audiometric configuration was consistent with noise exposure. Nevertheless, the hearing levels of most sonar technicians are adequate to perform their job. Hearing levels exceeded the Navy's table of limits, however, in five percent of the sonar technicians. APPLICATION "Because few sonar technicians have hearing losses great enough to affec <b>t</b> <b>performance,</b> auditory sonar channels can be designed independently of hearing levels of the users. ! Better tests are needed to determine which sonar technicians ýith hearing loss have decreased job performance. Auditory channels in sonar systems should be designed with high-quality output limiting so that hearing is protected without degradation of the signal...|$|E
40|$|Our {{experience}} of the world depends on integration of cues from multiple senses to form unified percepts. How the brain merges information across sensory modalities has been the object of debate. To measure how rats bring together information across sensory modalities, we devised an orientation categorization task that combines vision and touch. Rats encounter an object–comprised of alternating black and white raised bars–that looks and feels like a grating and can be explored by vision (V), touch (T), or both (VT). The grating is rotated to assume one orientation on each trial, spanning a range of 180 degrees. Rats learn to lick one spout for orientations of 0 ± 45 degrees (“horizontal”) and the opposite spout for orientations of 90 ± 45 ° (“vertical”). Though training was in VT condition, rats could recognize the object and apply {{the rules of the}} task on first exposure to V and to T conditions. This suggests that the multimodal percept corresponds to that of the single modalities. Quantifying their performance, we found that rats have good orientation acuity using their whiskers and snout (T condition); however under our default conditions, typically performance is superior by vision (V condition). Illumination could be adjusted to render V and <b>T</b> <b>performance</b> equivalent. Independently of whether V and <b>T</b> <b>performance</b> is made equivalent, performance is always highest in the VT condition, indicating multisensory enhancement. Is the enhancement optimal with respect to the best linear combination? To answer this, we computed the performance expected by optimal integration in the framework of Bayesian decision theory and found that most rats combine visual and tactile information better than predicted by the standard ideal–observer model. To confirm these results, we interpreted the data in two additional frameworks: Summation of mutual information for each sensory channel and probabilities of independent events. All three analyses agree that rats combine vision and touch better than could be accounted for by a linear interaction. Electrophysiological recordings in the posterior parietal cortex (PPC) of behaving rats revealed that neuronal activity is modulated by decision of the rats as well as by categorical or graded modality-shared representations of the stimulus orientation. Because the population of PPC neurons expresses activity ranging from strongly stimulus-related (e. g. graded in relation to stimulus orientation) to strongly choice-related (e. g. modulated by stimulus category but not by orientation within a category) we suggest that this region is involved in the percept-to-choice transformation...|$|E
40|$|Abstract—Traditional {{database}} management systems (DBMSs) running on powerful single-node servers are usually over-provisioned {{for most of}} their daily workloads and, because they do not show good-enough energy proportionality, waste a lot of energy while underutilized. A cluster of small (wimpy) servers, where its size can be dynamically adjusted to the current workload, offers better energy characteristics for those workloads. Yet, data migration, necessary to balance utilization among the nodes, is a non-trivial and time-consuming task that may consume the energy saved. For this reason, a sophisticated and easy to adjust partitioning scheme fostering dynamic reorganization is needed. In this paper, we adapt a technique originally created for SMP systems, called physiological partitioning, to distribute data among nodes that allows to easily repartition data without interrupting transactions. We dynamically partition DB tables based on the nodes ’ utilization and given energy constraints and compare our approach with physical partitioning and logical partitioning methods. To quantify possible energy saving and its conceivable drawback on query runtimes, we evaluate our implementation on an experimental cluster and compare the results w. r. <b>t.</b> <b>performance</b> and energy consumption. Depending on the workload, we can substantially save energy without sacrificing too much performance. I...|$|E
25|$|Hoad {{was born}} in Richmond, Saint Michael, Barbados. Although he had modest <b>Test</b> <b>performances,</b> he had some {{impressive}} results in first class matches against English sides in both the 1928 and 1929-30 tours, scoring 149* against Worcestershire in 1928 and 147 for Barbados in 1930.|$|R
30|$|<b>Test</b> <b>performance</b> {{data from}} 6 years (2006 – 2011) {{were used to}} conduct EFA to {{establish}} a baseline structure. Factors were identified from EFA by first eliminating factors with eigenvalues of less than one, and then under-factoring and over-factoring {{to determine the best}} factor structure.|$|R
50|$|Hoad {{was born}} in Richmond, Saint Michael, Barbados. Although he had modest <b>Test</b> <b>performances,</b> he had some {{impressive}} results in first class matches against English sides in both the 1928 and 1929-30 tours, scoring 149* against Worcestershire in 1928 and 147 for Barbados in 1930.|$|R
40|$|Abstract: Traditional DBMS servers {{are often}} over-provisioned {{for most of}} their daily workloads and, because they do not provide energy proportionality, waste more energy than necessary. A cluster of wimpy servers, where the number of nodes can dynami-cally adjust to the current workload, might offer better energy {{characteristics}} for these workloads. Yet, clusters suffer from friction losses and cannot quickly adapt to the workload, whereas a single server delivers maximum performance instantaneously. Designed for a cluster of nodes, our WattDB system primarily aims at energy pro-portionality {{for a wide range of}} DB applications. In this paper, we check this system under OLTP and OLAP workloads against a single-server DBMS in terms of through-put/response time and energy efficiency. To test the system’s ability to adjust to chang-ing workloads, we execute several benchmark at differing system activity levels. To quantify possible energy saving and its conceivable drawback on query runtime, we evaluate our WattDB implementation—to obtain maximum accuracy possible—on a cluster of wimpy nodes as well as on a single, brawny server and compare the results w. r. <b>t.</b> <b>performance</b> and energy consumption. Our findings confirm that—especially for OLAP workloads—energy can be saved without sacrificing too much performance. ...|$|E
40|$|Abstract. We {{propose a}} novel, generic {{definition}} of probabilistic sched-ulers for population protocols. We design two new schedulers, the State Scheduler and the Transition Function Scheduler. Both possess the sig-nificant capability of being protocol-aware, i. e. they can assign transition probabilities {{based on information}} concerning the underlying protocol. We prove that the proposed schedulers, and also the Random Scheduler that was defined by Angluin et al. [1], are all fair with probability 1. We also define and study equivalence between schedulers w. r. <b>t.</b> <b>performance</b> and correctness and prove that there exist fair probabilistic schedulers that are not equivalent w. r. t. to performance and others that are not equivalent w. r. t. correctness. We implement our schedulers using a new tool for simulating population protocols and evaluate their performance {{from the viewpoint of}} experimental analysis and verification. We study three representative protocols to verify stability, and compare the ex-perimental time to convergence with the known complexity bounds. We run our experiments from very small to extremely large populations (of up to 108 agents). We get very promising results both of theoretical and practical interest...|$|E
40|$|Traditional DBMS servers {{are usually}} over-provisioned {{for most of}} their daily workloads and, because they do not show good energy proportionality, waste a lot of energy while underutilized. A cluster of small (wimpy) servers, where the number of nodes can {{dynamically}} adjust to the current workload, might offer better energy characteristics for these workloads. Yet, clusters suffer from "friction losses" and {{may not be able to}} quickly adapt to the workload, whereas a single, brawny server delivers performance instantaneously. In this paper, we compare a small cluster of lightweight nodes to a single server in terms of performance and energy efficiency. We run several benchmarks, consisting of OLTP and OLAP queries at variable utilization to test the system's ability to adjust to the workloads. To quantify possible energy saving and its conceivable drawback on query runtime, we evaluate our implementation on a cluster as well as on a single, brawny server and compare the results w. r. <b>t.</b> <b>performance</b> and energy consumption. Our findings confirm that - based on the workload - energy can be saved without sacrificing too much performance. Comment: arXiv admin note: substantial text overlap with arXiv: 1407. 012...|$|E
40|$|This {{research}} {{was designed to}} investigate Neisser’s (1997) hypothesis that the Flynn effect (rising intelligence scores during the 20 th century) is related to increased exposure to the complex visual environment. In Study 1, 35 participants completed a test of mental rotation along with a survey of their exposure to various media activities. <b>Test</b> <b>performance</b> {{was positively related to}} 3 -D video game exposure but not to the other predictors. In Study 2, 172 participants completed the Culture Fair Intelligence Test (CFIT) and the Wide Range Vocabulary Test (WRVT) along with another media survey. <b>Test</b> <b>performance,</b> particularly on the CFIT, was not related to any of the visual media variables. These nonsignificant results are inconsistent with Neisser’s explanation of the Flynn effect. 2...|$|R
40|$|Heat-Related Mortality - Chicago, July 1995 [...] Translocation of Coyote Rabies - Florida, 1994 [...] Laboratory Practices for Diagnosis of Tuberculosis - United States, 1994 [...] Notice to Readers Recommendations for <b>Test</b> <b>Performance</b> and Interpretation {{from the}} Second National Conference on Serologic Diagnosis of Lyme Disease...|$|R
2500|$|United States. United States Army Test and Evaluation Command, Headquarters, US Army Aviation Test Activity. Report of the Engineering Flight <b>Test</b> <b>Performance</b> Phase of the OH-5A Helicopter Unarmed (Clean) and Armed {{with the}} XM-7 and XM-8 Weapon Subsystem, Part II. [...] Edwards AFB, CA: Headquarters, US Army Aviation Test Activity, 1964 ...|$|R
