2732|10000|Public
25|$|Researchers have {{reported}} that the JP and the SN scales correlate with one another. One factor-analytic study based on (N=1291) college-aged students found six different factors instead of the four purported dimensions, thereby raising doubts as to <b>the</b> <b>construct</b> <b>validity</b> of the MBTI.|$|E
2500|$|There is some ongoing {{scientific}} doubt concerning <b>the</b> <b>construct</b> <b>validity</b> {{and reliability}} of psychiatric diagnostic categories and criteria {{even though they have}} been increasingly standardized to improve inter-rater agreement in controlled research. In the United States, there have been calls and endorsements for a congressional hearing to explore {{the nature and extent of}} harm potentially caused by this [...] "minimally investigated enterprise".|$|E
2500|$|As {{with any}} use of {{mathematical}} models, {{it is important}} to assess the fit of the data to the model. [...] If item misfit with any model is diagnosed as due to poor item quality, for example confusing distractors in a multiple-choice test, then the items may be removed from that test form and rewritten or replaced in future test forms. If, however, a large number of misfitting items occur with no apparent reason for the misfit, <b>the</b> <b>construct</b> <b>validity</b> of the test will need to be reconsidered and the test specifications may need to be rewritten. Thus, misfit provides invaluable diagnostic tools for test developers, allowing the hypotheses upon which test specifications are based to be empirically tested against data.|$|E
50|$|<b>Construct</b> <b>validity</b> is {{essential}} to the perceived overall <b>validity</b> of <b>the</b> test. <b>Construct</b> <b>validity</b> is particularly important in the social sciences, psychology, psychometrics and language studies.|$|R
5000|$|Around {{this time}} <b>the</b> term <b>construct</b> <b>validity</b> was first coined by Paul Meehl and Lee Cronbach in their seminal article [...] " [...] Validity In Psychological Tests". They noted <b>the</b> idea of <b>construct</b> <b>validity</b> was not new at that point. Rather, {{it was a}} {{combinations}} of {{many different types of}} validity dealing with theoretical concepts. They proposed the following three steps to evaluate construct validity: ...|$|R
30|$|In {{order to}} analyse the {{strength}} of association among <b>the</b> variables, <b>the</b> <b>constructs</b> <b>validity</b> was tested using the Bartlett’s Test of Sphericity and the Kaiser-Mayer-Olkin (KMO) for the measure of sampling adequacy [61]. The result for Bartlett’s test of Sphericity and the KMO value was 0.000 and 0.688 respectively (see Table  4). The latter value is more than 0.5, which shows {{a high level of}} sampling adequacy.|$|R
2500|$|Addition {{of the new}} {{category}} to the DSM-system was recognized by the psychiatric press, and the New York Times. Several commentators have also offered their viewpoints. Chinen notes that the inclusion marks [...] "increasing professional acceptance of transpersonal issues", while Sovatsky sees the addition as an admittance of spiritually oriented narratives into mainstream clinical practice. Smart and Smart recognizes {{the addition of the}} category, and similar improvements in the fourth version, as a step forward for the cultural sensitivity of the DSM manual. Greyson, representing the field of Near-death studies, concludes that the diagnostic category of Religious or spiritual problem [...] "permits differentiation of near-death experiences and similar experiences from mental disorders". In a study from 2000 Milstein and colleagues reported that their findings provided empirical evidence for <b>the</b> <b>construct</b> <b>validity</b> of the new DSM-IV category religious or spiritual problem (V62.89).|$|E
5000|$|Pennings, Joost ME, and Ale Smidts. [...] "Assessing <b>the</b> <b>construct</b> <b>validity</b> of risk attitude." [...] Management Science 46.10 (2000): 1337-1348.|$|E
50|$|Saville, P. & Blinkhorn, S. (1981). Reliability, {{homogeneity}} and <b>the</b> <b>construct</b> <b>validity</b> of Cattell's 16 Personality Factor Questionnaire (16PF). Personality and Individual Differences, 2, 325-333.|$|E
50|$|An {{in-depth}} {{exploration of}} <b>the</b> threats to <b>construct</b> <b>validity</b> {{is presented in}} Trochim.|$|R
30|$|Factor {{analysis}} was implemented to determine <b>the</b> instrument <b>construct</b> <b>validity.</b> All {{items in the}} instrument have to meet the following criteria: the threshold of factor loading is 0.5 and eigenvalue is larger than 1.|$|R
40|$|Discusses the {{development}} of a questionnaire designed to render profiles of employment expectations. Factor analysis suggested that job knowledge/production skills, socialization and emotional coping skills, trainability/task flexibility, dependability, and motivation/satisfaction underlay <b>the</b> questionnaire. <b>Construct</b> <b>validity</b> revealed moderate and positive correlations among all factors except motivation/satisfaction...|$|R
50|$|By {{focusing}} on general skills rather than domain knowledge and specialization, the instrument may lack <b>the</b> <b>construct</b> <b>validity</b> {{to measure the}} specialized knowledge that students go to college to obtain.|$|E
5000|$|Moore, W. S. (1989). The {{learning}} environment preferences: Exploring <b>the</b> <b>construct</b> <b>validity</b> of an objective {{measure of the}} Perry scheme of intellectual development. Journal of College Student Development, 30, 504-514.|$|E
50|$|Orbe & Lapinski (2007) {{published}} {{the design of}} a self-report measure of the two components of co-cultural theory, preferred outcome and communication approach, and provides evidence from two studies for <b>the</b> <b>construct</b> <b>validity</b> and reliability of the co-cultural theory scales (C-CTS).|$|E
30|$|The aim of {{this study}} is to {{determine}} <b>the</b> face and <b>construct</b> <b>validity</b> of this VR training module for the hysteroscopic placement of tubal sterilization micro-inserts.|$|R
5000|$|Other {{researchers}} as {{well have}} raised concerns about <b>the</b> strange situation's <b>construct</b> <b>validity</b> and questioned its terminology as a [...] "gold standard" [...] measure of attachment.|$|R
50|$|<b>Construct</b> <b>validity</b> {{refers to}} <b>the</b> {{extent to which}} the {{independent}} and dependent variables in a study represent the abstract hypothetical variables of interest. In other words, {{it has to do with}} whether the manipulated and/or measured variables in a study accurately reflect the variables the researcher hoped to manipulate. <b>Construct</b> <b>validity</b> also reflects <b>the</b> quality of one’s operational definitions. If a researcher has done a good job of converting the abstract to <b>the</b> observable, <b>construct</b> <b>validity</b> is high.|$|R
50|$|Researchers have {{reported}} that the JP and the SN scales correlate with one another. One factor-analytic study based on (N=1291) college-aged students found six different factors instead of the four purported dimensions, thereby raising doubts as to <b>the</b> <b>construct</b> <b>validity</b> of the MBTI.|$|E
50|$|In 1950 {{several studies}} found {{results from the}} {{analysis}} of Blacky Pictures consistent with Freudian psychoanalytic theory, providing some support for <b>the</b> <b>construct</b> <b>validity</b> of the test. Experimental techniques found that Blacky Pictures were accurate in predicting behavior associated with the psychosexual personality types, in both individual and group settings.|$|E
5000|$|Campbell and Fiske (1959) {{developed}} the Multitrait-Multimethod Matrix to assess <b>the</b> <b>construct</b> <b>validity</b> {{of a set}} of measures in a study. [...] The approach stresses the importance of using both discriminant and convergent validation techniques when assessing new tests. In other words, in order to establish construct validity, you have to demonstrate both convergence and discrimination.|$|E
30|$|<b>Construct</b> <b>validity</b> {{threat is}} <b>the</b> {{extent to which}} the studied {{operational}} measures reflect what the researcher intended to study according to the research goals. In this research study, <b>the</b> main <b>construct</b> <b>validity</b> relates to our assumption that the terms “support entity,” “organization” and “foundation” are used interchangeably. Indeed, different data sources use different terms when describing the FLOSS ecosystem. Our approach has been rather inclusive with respect to the used terms.|$|R
30|$|Cross-sectional {{data from}} 3083 {{adolescents}} aged 13 to 15  years from the Danish {{contribution to the}} cross-national study Health Behaviour in School-aged Children (HBSC) were used. We identified and developed items, addressed content and face validity through interviews, and examined <b>the</b> criterion-related <b>construct</b> <b>validity</b> of <b>the</b> scales using graphical loglinear Rasch models (GLLRM).|$|R
50|$|One {{common use}} is for {{diagnosis}} of executive impairment. The {{performance of the}} examinee is compared to representative samples of individuals {{of the same age}} to derive hypotheses about the person's executive cognitive ability, especially as it may relate to brain damage. A certain degree of controversy surrounds <b>the</b> test's <b>construct</b> <b>validity.</b>|$|R
50|$|Although a few {{scholars}} have questioned <b>the</b> <b>construct</b> <b>validity</b> of the Bar-On model, {{findings indicate that}} the Bar-On model of emotional intelligence has a significantly impact on: (1) physical health; (2) cognitive functioning, didactic effectiveness, academic performance and career decision-making; (3) occupational performance and leadership, job satisfaction and organizational effectiveness; (4) creativity and innovative thinking; and (5) psychological health and well-being.|$|E
5000|$|In psychology, {{the concept}} of {{intelligence}} is meant to explain correlations in performance on certain cognitive tasks. Recent models suggest several cognitive processes {{may be involved in}} tasks that have been associated with intelligence. However, overall the [...] "g" [...] or general intelligence factor is relatively supported by research. With increasing challenges, <b>the</b> <b>construct</b> <b>validity</b> of a theoretical definition can be questioned.|$|E
5000|$|There is some ongoing {{scientific}} doubt concerning <b>the</b> <b>construct</b> <b>validity</b> {{and reliability}} of psychiatric diagnostic categories and criteria {{even though they have}} been increasingly standardized to improve inter-rater agreement in controlled research. In the United States, there have been calls and endorsements for a congressional hearing to explore {{the nature and extent of}} harm potentially caused by this [...] "minimally investigated enterprise".|$|E
30|$|The aim of {{this study}} was to examine <b>the</b> {{cross-cultural}} and <b>construct</b> <b>validity</b> of <b>the</b> Dutch-Flemish PROMIS® Upper-extremity (UE) item bank v 2.0 in a Dutch population of patients with musculoskeletal upper-extremity disorders.|$|R
50|$|Meehl {{with his}} {{colleague}} Lee J. Cronbach introduced <b>the</b> notion of <b>construct</b> <b>validity</b> in psychology, {{as well as}} the application of nomological networks to understand psychological test properties and scientific theorizing and practice.|$|R
40|$|The Profiles of Occupational Engagement {{in people}} with Severe mental illness (POES) {{instrument}} was developed to study time use profiles of occupations and measure the extent they are characterized by engagement. However, the dimensional factors are not known. The aim {{of the present study}} was to establish <b>the</b> internal <b>construct</b> <b>validity</b> of <b>the</b> POES using the Rasch measurement model...|$|R
50|$|Construct {{validity}} {{was assessed}} by correlating {{the results of the}} Kinsey Summary with the results Kinsey-type questions of sexual attraction, sexual contact and sexual identity included in the questionnaire. The Kinsey Summary refers to a classification of the subjects into the 7 categories of the Kinsey scale based on their results in the Sell Assessment. Results show correlations upwards from 0.85 which indicate <b>the</b> <b>construct</b> <b>validity</b> of Sell’s scale.|$|E
50|$|A third {{study was}} {{conducted}} to examine <b>the</b> <b>construct</b> <b>validity.</b> By comparing two different groups of people, researchers would {{be able to see the}} different levels of self-compassion. Forty-three Buddhist practitioners completed the Self-compassion Scale as well as a self-esteem scale. The sample of 232 undergraduate students from the second study was used as the comparison group. As expected by Neff, the Buddhist practitioners had significantly higher self-compassion scores than the students.|$|E
50|$|<b>The</b> <b>construct</b> <b>validity</b> can be {{measured}} by {{the degree to which}} the developers’ assessment data agrees with the actual performance of managers at work. But participants are also concerned with face validity, {{the degree to which the}}y can identify with the video episodes and accept their proficiency profile as accurate. On the post-assessment evaluation sheet, 92% said they had no difficulty relating to the episodes, and 86% said that the scores they received were probably accurate.|$|E
40|$|PURPOSE: To {{examine the}} psychometric {{properties}} of the 14 -item Warwick-Edinburgh Mental Well-being Scale (WEMWBS) in the UK veterinary profession by the application of Rasch analysis, and to assess <b>the</b> external <b>construct</b> <b>validity</b> of <b>the</b> derived interval scale measurements. METHODS: Data sets were derived from two independent cross-sectional surveys of the veterinary profession (n = 8, 829 and n = 1, 796). Rasch analysis (n = 500) included response option thresholds ordering, tests of fit, differential item functioning, targeting, response dependency, and person separation index (PSI). Unidimensionality was evaluated by principal component analysis of residuals. The findings were validated across further subsamples from both data sets. <b>The</b> external <b>construct</b> <b>validity</b> of <b>the</b> Rasch-fitting item set was evaluated by associations with other measures of psychological health or psychosocial work characteristics. RESULTS: Data for the original 14 items deviated significantly from Rasch model expectations (chi-square = 558. 2, df = 112, P = < 0. 001, PSI = 0. 918). A unidimensional 7 -item scale (Short WEMWBS, SWEMWBS) with acceptable fit to the model (chi-square = 58. 8, df = 56, P = 0. 104, PSI = 0. 832) was derived by sequential removal of the most misfitting items. <b>The</b> external <b>construct</b> <b>validity</b> of SWEMWBS was supported. CONCLUSIONS: SWEMWBS has robust interval-level measurement properties which support its suitability as an indicator of population mental health and well-being in this occupational group with elevated suicide risk. <br/...|$|R
40|$|The present work aims at the {{description}} of <b>the</b> evidence of <b>construct</b> <b>validity</b> and internal consistency of the"Instrument for Sport Competition Emotions" (INECOD), newly created instrument that evaluates the perception of physiological and cognitive dimensions of emotion during the competition. Using a sample of 411 athletes from nine disciplines, obtein a three-dimensional factor structure (positive affect, negative affect and anxiety) in the two subscales. The results confirm <b>the</b> evidence of <b>construct</b> <b>validity</b> (explained variance of 59. 8 % and 62. 3 %) and reliability (from α =. 538 and. 822) presenting a tool {{that can be used}} in sport populations, and should be confirmed in future works...|$|R
30|$|<b>The</b> {{establishment}} of <b>construct</b> <b>validity</b> demands that a variable {{operate according to}} its definition; {{the extent to which}} empirical evidence goes against this definition threatens the variable’s viability as an explanation of behavior. (King and King 1986).|$|R
