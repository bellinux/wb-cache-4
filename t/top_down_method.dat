17|3903|Public
5000|$|Natural {{language}} {{programming is}} a <b>top</b> <b>down</b> <b>method</b> of writing software. Its stages are as follows: ...|$|E
5000|$|This {{method is}} {{computationally}} high and inefficient. It keeps an entire templates list {{during the whole}} process {{and the number of}} combinations is extremely high. For a [...] pixel image, there could be a maximum of [...] combinations, which leads to high computation. This method is a <b>top</b> <b>down</b> <b>method</b> and often called table look-up or dictionary look-up.|$|E
50|$|The minimum {{constituent}} {{parts of}} a chromosome (centromere, telomere and DNA replication sequences) are assembled This is done by using molecular cloning techniques to construct the desired chromosomal contents in vitro. Next, the desired contents of the minichromosome must {{be transformed into a}} host which is capable of assembling the components (typically yeast or mammalian cells) into a functional chromosome. This approach has been attempted for the introduction of minichromosomes into maize for the possibility of genetic engineering, but the success was limited and questionable. In general, the de novo approach is more difficult than a <b>top</b> <b>down</b> <b>method</b> due to species incompatibility issues and the heterochromatic nature of centromeric regions.|$|E
40|$|This Working Paper {{reviews the}} {{literature}} {{and the experience of}} other tax administrations to assess the value of <b>top</b> <b>down</b> <b>methods</b> for estimating the UK direct tax gap. • The key insights are: a <b>top</b> <b>down</b> approach to the entire UK tax gap is impractical, as previous less detailed analysis has also concluded; but <b>top</b> <b>down</b> <b>methods</b> can potentially support the estimation of some elements of the direct tax gap. • The reasons that a <b>top</b> <b>down</b> approach to the entire direct tax gap is impractical are: (i) The absence of suitable data (in contrast to indirect taxes where consumption data from the national accounts is independent); and (ii) The uncertain calculation of theoretical liability. • <b>Top</b> <b>down</b> approaches can potentially support the estimation of some elements of the direct tax gap through surveys that approach undeclared income indirectly or infer income from spending. Matching with taxpaye...|$|R
50|$|Edsger Dijkstra's {{shunting}} yard algorithm {{is commonly used}} to implement operator precedence parsers. Other algorithms include the precedence climbing <b>method</b> and the <b>top</b> <b>down</b> operator precedence <b>method.</b>|$|R
40|$|In this {{technical}} report I present {{a method to}} reconstruct a surface representation from a a set of EBF's, and in addition present an efficient <b>top</b> [...] <b>down</b> <b>method</b> to build an EBF representation from a point cloud representation of a surface. I also discuss {{the advantages and disadvantages}} of this approach...|$|R
50|$|This {{attitude}} to planning continued beyond colonialism and {{spread throughout the}} modernist movement in the 1920s. During this time, designers and planners were given opportunities to conceive a vision for utopian cities. These designs were {{a response to the}} rise of industrialisation in cities, which led to the working class living in dirty and often overcrowded slums. Although the vision and intention of these utopian cities was to create a society that sought to protect and preserve humanity through the built environment, this <b>top</b> <b>down</b> <b>method</b> of planning assumes that the values and beliefs held by the planner are the same as those that they are planning for. Many of these projects failed to achieve expectations and were instead discarded or set aside.|$|E
40|$|A simple <b>top</b> <b>down</b> <b>method</b> to {{fabricate}} {{an array of}} vertically stacked nanowires is presented. By {{taking advantage of the}} non-uniformity of the Inductive Coupled Plasma (ICP) etching process to form a scalloped sidewall followed by a subsequent stress limited oxidation step, a narrow silicon fin can be vertically patterned to form stacked nanowires with different cross-sectional shapes. The stacked nanowires have been used {{to fabricate}}d Gate-All-Around (GAA) MOSFETs that show excellent characteristics. © 2010 IEEE...|$|E
40|$|Basement {{construction}} is done sequentially {{from the bottom}} to the top. This method known as bottom-up method. In this method, the work began on the foundation work, excavation work then forwarded to the manufacture of columns, beams and plates are constantly up to the roof. This research explains on studies of top down basement construction method on high rise building as innovation of construction method. Nowadays, {{in the world of}} construction there are varies of innovations; one of them is <b>top</b> <b>down</b> <b>method</b> for basement construction. Howard Johnson Hotels is a project of 18 levels building and 3 levels of basement located in the middle of large city where there are already many buildings and activities surrounding. PT. PP (Persero) Tbk, the main contractor of thi project decided to apply <b>top</b> <b>down</b> <b>method</b> for the 3 levels of basement. This research was compare the construction method of bottom-up and top-down in terms of time. For both of these methods involved the literature study and data collection, analysis methods of implementation, amt the calculation of the duration of the work. With comparative analysis method of bottom-up and top-down is obtained, bottom-up method requires the execution time for 472 days and the top-down method requires the execution time for the 423 days...|$|E
40|$|Among many {{techniques}} of modern mass spectrometry, the <b>top</b> <b>down</b> <b>methods</b> are becoming continuously more {{popular in the}} overall strive to describe the proteome. These techniques are based on fragmentation of ions inside mass spectrometers instead of being proteolytically digested. In some of these techniques, the fragmentation is induced by electron transfer. It can trigger several concurring reactions: electron transfer dissociation, electron transfer without dissociation, and proton transfer reaction. The evaluation {{of the extent of}} these reactions is important for the proper understanding of the functioning of the instrument and, what is even more important, to know if {{it can be used to}} reveal important structural information. We present a workflow for assigning peaks and interpreting the results of electron transfer driven reactions. We also present software written in Python and available under GNU v 3 license...|$|R
40|$|I {{propose to}} write a thesis on new methods in mesh {{generation}} to build low complexity simplicial complexes for applications in computational geometry and topology. Quality meshes {{can be used to}} approximate the distance function dP: R d → R such that dP(x) is the shortest distance from x to the points cloud P. This distance function is fundamental to many computational problems but we will focus on two, Voronoi diagrams and persistent homology. My recent work has shown that this approach yields an improvement in the worst-case running time of persistent homology computation from n O(d) down to 2 O(d 2) n 3. Some problems I intend to look at include • computing persistence of inputs with topological prior (i. e. going beyond point sets), • <b>top</b> <b>down</b> <b>methods</b> for persistent homology, • developing new approaches for topological simplification for mesh filtrations, and • approximating Voronoi diagrams...|$|R
40|$|Graphene, {{the first}} {{two-dimensional}} crystal ever studied, has made such {{an impact in}} a myriad of fields ranging from physical science to engineering that its discovery earned Nobel recognition in 2010. Although it was initially lauded {{as the answer to}} the Moore's law limitation of silicon electronics, what really captivated scientists was the fact that it opened countless avenues of exploration. From a synthetic chemists perspective, it became imperative to find a more sensible way to isolate graphene if it were ever to become practical for industrial use. This thesis demonstrates several fascinating routes to synthesize graphene, such as: <b>top</b> <b>down</b> <b>methods</b> involving the solution processing of graphitic materials through redox chemistry and bottom-up approaches mainly using chemical vapor deposition (CVD). In addition, several device architectures were developed to exploit intrinsic properties of the derived graphene. These applications include: transparent electrodes, Flash memory devices and bio-electrodes for cell stimulation...|$|R
40|$|The thesis {{deals with}} the {{technology}} of top down construction method. The basic types of protection of excavation pit are presented. Details of classic <b>top</b> <b>down</b> <b>method,</b> nonshored formwork system for top down construction, strut as permanent system, bracket supported R/C downward and strut top down are explained. Two examples from Slovenia, parking house Kongresni trg in Ljubljana and The National and University Library of Slovenia designed by the architect Jože Plečnik, are described. The focus of this work is the description and comparison of individual methods, their advantages and disadvantages and conditions of use...|$|E
40|$|Abstract. Barium hexaferrite is {{categorized}} as hexagonal ferrite material with ferrimagnet properties. Barium hexaferrite has high coercivity, curie temperature, anisotropy magnetic field, and chemical stability {{that is often}} used as permanent magnet. It can be synthesized by using bottom up or <b>top</b> <b>down</b> <b>method.</b> The bottom up method of sol-gel has potential advantages in industry application compared to the <b>top</b> <b>down</b> <b>method</b> because of low energy requirement, more homogeneous product, and low time consuming to achieve nanometer size. The development of sol-gel method by using tapioca and chitosan as surfactant increases {{the quality of the}} product. Tapioca is used to increase anisotropy properties of particles by changing the particles shape into rodlike shape whereas chitosan is used to stabilize them at small size. Molar ratio of Fe 3 +/Ba 2 + is set on 12 and the ratio of tapioca/chitosan is set on 1 / 3, 1 / 2, and 1. Iron(III) nitrate is used as Fe 3 + source whereas barium nitrate is used as Ba 2 + source. Condensation is done by heating up the sol system in the oven at 100 OC. The product then is calcined at 1000 OC with holding time of 3 hours. The calcined product is then characterized by X-Ray Diffraction (XRD), Scanning Electron Microscope (SEM), and Vibrating Sample Magnetometer (VSM). XRD result shows that the hematite phase has still been formed. The occurrence of the phase indicates that the reaction between iron and bariu...|$|E
40|$|Abstract — Large-scale {{classification}} taxonomies {{have thousands}} of classes, deep hierarchies and skewed category distribution over documents. Hierarchical classification can speed up the classification process because problem is sub divided into smaller sub problems, and each {{of which can be}} efficiently and effectively managed. Most commonly used method for multiclass classification is one versus rest method. It is inflexible due to computational complexity. The <b>top</b> <b>down</b> <b>method</b> is usually accepted, but it has an error propagation problem. The metaclassification method solves error propagation problem. In this paper, several challenges for hierarchical document classification such as scalability, complexity, and misclassification are reviewed. The questions concerning about the learning and the classification processes are reviewed...|$|E
40|$|Abstract Visual {{computing}} environments {{continue to}} grow in importance, yet fast, general parsing algorithms for visual languages remain elusive. In this paper we present an incremental parsing algorithm for a broad class of visual languages which do not contain overlapping elements. Our algorithm {{is based on the}} concept of adjacency grammars, where adjacencies are defined so as to encompass both spatial and logical constraints. Our approach combines bottom up and <b>top</b> <b>down</b> <b>methods</b> to support incremental parsing of visual input, allowing for measurably efficient online parsing of diagram-like visual languages, with observed linear run times for large visual sentences. 1 Introduction In recent years there has been rapidly growing interest among systems designers (and consumers) in new kinds of user interfaces where visual elements, which may contain both text and graphical components, and the spatial relationships among them, take precedence over concatenation and temporal sequence, which are the main organizing principles in string languages [1]...|$|R
40|$|Templated {{growth and}} {{properties}} of iron nanowires: anisotropic electron {{states of the}} quasi 1 D copper substrate, and morphological and magnetic properties of the iron adsorbate. PhD Student: Carlos Eduardo Viol Barbosa Advisor: Giorgio Rossi, Alberto Morgante. Low dimensional and nano-scale material systems display quantum behavior due to the confinement {{in one or more}} dimensions of the electron states. The goal of nanoscience is to understand and exploit such behavior. Reaching such goal implies growing or fabricating nano-scale systems with atomic precision, not achievable by statistical <b>top</b> <b>down</b> <b>methods.</b> Self-organized and self-assembled systems on single crystal surfaces are prototypical atomically precise systems since they can be reduced to 1 (quantum wire) or 0 (quantum dot) dimension, maintaining the atomic precision of crystal. The surface reconstruction of stepped surfaces, induced by locally selective chemical reactions, is exploited in the present work to produce: a) a quasi 1 D stripes array of single crystal terraces that can be studied both by local probes to establish the morphology and the local density of states as well as by means of extended electronic structure technique...|$|R
40|$|This diploma thesis {{focuses on}} the problematics of eGovernment and open data. Thesis assesses the {{situation}} in the Czech Republic as well as in countries of European Union. The opendata and eGovernment history, its developments, current state and outlook for future are described. The thesis aims to analyze the characteristics of opendata and compares eGovernment in the Czech Republic with other countries of European Union according to Open Data index. In the last section of this work, selection of the proper data for publication in the open format data is discussed. Its implementation and validation is demonstrated with the example of selected instution in the Czech Republic. In the theoretical part of this thesis problematics of eGovernment in the Czech Republic is discussed. The analytical part assesses the open data publication by the Czech ministry of social security administration. Analysis is conducted using bottom up and <b>top</b> <b>down</b> <b>methods.</b> The benefits of this diploma thesis is the overview of the eGovernment and open data format publications in the Czech Republic and its comparison with other European countries and creation of the methodical framework for choosing the correct data for open data format publication...|$|R
40|$|The {{objective}} of this research study was to optimize formulation and process variables affecting characteristic of nanosuspension in bead milling process. In this study, the practically water-insoluble telmisartan was nanoground by using <b>top</b> <b>down</b> <b>method</b> i. e. media milling method. Here the media used is ZnO 2 beads. A variety of surface active agents were tested for their stabilizing effects. Formulation factors evaluated were ratio of polymer to drug, whereas process parameters were milling time and concentration of ZnO 2 beads. Different concentration of stabilizers such as poloxamer 188, poloxamer 407, HPMC E 15, PVP K 30 and combination of stabilizers were used for preparation of telmisartan nanosuspension. Responses measured in this study include particle size measurement, particle size distribution and zeta potential...|$|E
40|$|In 1857, Manchester {{held the}} largest British fine-arts {{exhibition}} to date. In all, {{one and a}} half million people visited the exhibition. Many employers arranged for their workers to visit. Titus Salt brought 2, 500 workers from his textile works. Salt created a spectacle as he entered the gallery: striding in front of his brass band, who were leading the mill’s employees into the exhibition. Salt was using his band - his employees- as a statement of his status in the country. The reasons for this theatrical act are the influences behind this chapter. This chapter examines how rational recreation, perceived as a <b>top</b> <b>down</b> <b>method</b> of social control, helped reinforce this a musical working-class identity that was created by brass bands. How did bands take rational recreation,and reinforce their own cultural, and class identit...|$|E
40|$|In {{this paper}} we present top down and bottom up methods for {{generating}} coarse grain dataflow or multithreaded code, and evaluate their effectiveness. The top down technique generates clusters {{directly from the}} intermediate data dependence graph used for compiler optimizations. Bottom up techniques coalesce finegrain dataflow code into clusters. We measure the resulting number of clusters executed, cluster size, and number of inputs per cluster, for Livermore and Purdue benchmarks. The <b>top</b> <b>down</b> <b>method</b> executes less clusters and instructions, but incurs a higher number of matches per cluster, which exemplifies the need for efficient matching {{of more than two}} inputs per cluster. Keywords: Hybrid von Neumann/Dataflow, threads, clusters, code generation strategies, performance evaluation 1 Introduction Experience from the first generation of dataflow machines has shown that the classical fine-grain dataflow model does not take advantage of program or data locality. To alleviate some of [...] ...|$|E
5|$|Aligned ZnO {{nanowires}} on pre-seeded silicon, glass, and {{gallium nitride}} substrates have been grown using aqueous zinc salts such as zinc nitrate and zinc acetate in basic environments. Pre-seeding substrates with ZnO creates sites for homogeneous nucleation of ZnO crystal during the synthesis. Common pre-seeding methods include in-situ thermal decomposition of zinc acetate crystallites, spincoating of ZnO nanoparticles {{and the use}} of physical vapor deposition methods to deposit ZnO thin films. Pre-seeding can be performed in conjunction with <b>top</b> <b>down</b> patterning <b>methods</b> such as electron beam lithography and nanosphere lithography to designate nucleation sites prior to growth. Aligned ZnO nanowires can be used in dye-sensitized solar cells and field emission devices.|$|R
40|$|The {{objective}} {{of this paper is}} to describe how qualitative methods can be used in the development of descriptive systems of preference based measures (PBM) of health related quality of life. The requirements of NICE and other agencies together with increasing use of patient reported outcome measures has lead to an increase in the demand for PBM. Recently, interest has grown in developing new PBM and whilst previous research on PBM has mainly focused on the methods of valuation, research into the methods of developing descriptive systems is an emerging field. Traditionally, descriptive systems of PBMs were developed using <b>top</b> <b>down</b> <b>methods,</b> where content was derived from existing measures, the literature, or health surveys. A contrasting approach is a bottom up methodology, which takes the views of patients or lay people on how their life is affected by their health. This approach generally requires the use of qualitative methods. Qualitative methods lend themselves well to the development of PBMs. They also ensure the measure has appropriate language, content validity and responsiveness to change. Whilst the use of qualitative methods in the development of non PBMs is fairly standard, their use in developing PBMs was until recently nonexistent. In this paper, we illustrate the use of qualitative methods by presenting two case studies of recently developed PBMs; one generic and one condition specific. We outline the stages involved, discuss the strengths and weaknesses of the approach and compare with the <b>top</b> <b>down</b> approach used in the majority of PBMs to date...|$|R
40|$|In {{this paper}} we have {{addressed}} {{the problem that we}} overcome in data mining applications i. e. mining frequent patterns in large databases efficiently in less time with less memory requirement. We are proposing a computational model for finding frequent patterns in large datasets with less number of scans. We have also proposed methodology which would help in storing large database compactly and thus help in improving the storage space requirement. Our model would help in generating less patterns and thus improving the mining time required in large databases. Our computational model is an amalgamation of three approaches i. e. bottom up counting inference and <b>top</b> <b>down</b> intersection <b>method</b> for generating the frequent sets and tree based approach for storing the databases compactl...|$|R
40|$|This paper {{seeks to}} {{determine}} {{the scope of the}} ECJ’s decision of 23 March 2010 and its impact upon the laws of Member state. Thereby it attempts to stress the different sources of conflicts that can arise when national judges {{have to deal with the}} tricky issue of Internet intermediaries’ liability. At the same time this paper tries to give a sense of what is the institutional function of European private law in a multilevel system of governance. Whereas the first begins with examining the means used by the Court to bring national laws closer through a uniform interpretation of key European provisions, the second part highlights the significant regulatory leeway granted to Member states. This leeway explains why horizontal and diagonal conflicts are likely to persist until a constructive inter-normative dialogue between national courts takes place, following in step with traditional <b>top</b> <b>down</b> <b>method</b> of harmonisatio...|$|E
40|$|In {{this paper}} {{we present a}} model of coarse grain {{dataflow}} execution. We present a <b>top</b> <b>down</b> <b>method</b> for generating machine independent multithreaded code, called MIDC. We define MIDC. We discuss the relevant phases in the Sisal to MIDC compilation process, and present some example compilations. We quantify the number of threads, number of inputs per thread, and average thread size for Livermore and Purdue benchmarks. Keywords: Hybrid von Neumann/Dataflow, threads, code generation algorithm. 1 Introduction Hybrid dataflow machines execute threads of von Neumann RISC code, where the threads are enabled by the availability of data. Thread enabling is either implemented by efficient matching using explicit token storage and presence bits, or by pools of "waiting " and "ready" threads with hardware support to move threads from and to these pools. A strict firing rule allows a thread to execute only when all its inputs are available, avoiding threads to block but potentially increasing laten [...] ...|$|E
40|$|The aim of {{the current}} paper is to propose a {{bottom-up}} approach as a complement in risk return analyses, particularly suitable for private firms and divisional evaluation. In those countries where private firms are more common than public firms, firm’s economic fundamentals are more significant than market data. In this case, {{the use of a}} bottom up approach for the beta estimation is more suitable than a <b>top</b> <b>down</b> <b>method,</b> because it allows to consider both environmental and business drivers of risk and to study the systematic risk as a function of firm fundamentals. The paper is structured in three sections: in the first section, there is the literature review on the CAPM and the beta estimation; in the second section, there is the explanation of the model -a bottom up approach to unlevered risk - considering the role of the intrinsic business risk and of the operating leverage; finally, it is presented the analysis of the unlevered beta, according the bottom up model, both in stationary and the dynamic states...|$|E
40|$|This paper {{presents}} an integrated approach to design an assembly, fixture schemes and an assembly sequence, {{such that the}} dimensional integrity of the assembly is insensitive to the dimensional variations of individual parts. The adjustability of critical dimensions and the proper constraining of parts during assembly process are the keys in achieving the dimensional integrity of the final assembly. A <b>top</b> <b>down</b> design <b>method</b> is developed which recursively decomposes a lump of initial product geometry and fixture elements matching critical dimensions, into parts and fixtures. At each recursion, joints are assigned to the interfaces between two subassemblies to ensure parts and fixtures are properly constrained at every assembly step. A case study on a simple frame structure is presented to demonstrate the method...|$|R
40|$|Silicon nanochannel {{field effect}} {{transistor}} (FET) biosensors {{are one of the}} most promising technologies in the development of highly sensitive and label-free analyte detection for cancer diagnostics. With their exceptional electrical properties and small dimensions, silicon nanochannels are ideally suited for extraordinarily high sensitivity. In fact, the high surface-to-volume ratios of these systems make single molecule detection possible. Further, FET biosensors offer the benefits of high speed, low cost, and high yield manufacturing, without sacrificing the sensitivity typical for traditional optical <b>methods</b> in diagnostics. <b>Top</b> <b>down</b> manufacturing <b>methods</b> leverage advantages in Complementary Metal Oxide Semiconductor (CMOS) technologies, making richly multiplexed sensor arrays a reality. Here, we discuss the fabrication and use of silicon nanochannel FET devices as biosensors for breast cancer diagnosis and monitoring...|$|R
40|$|This work {{goes through}} the mindset and ways of {{analyzing}} the problem of realizing 2 D concept art into the 3 D game model used in game. Specifically targeted for <b>top</b> <b>down</b> games and the effects the <b>top</b> <b>down</b> view have on the 3 D game model. Studies in Principles and design concepts are {{used to create a}} 3 D game character that works well for the <b>top</b> <b>down</b> view. The <b>method</b> used where an experimental study which resulted in a 3 D model and implementation of principles and design concepts.  Based on the results it is concluded that it could be a useful tool. In the discussion a deeper analysis is conducted and it´s concluded that further research are necessary and the purpose and questions were answered...|$|R
40|$|The {{objective}} {{of this study was}} to investigate the effect of different types of Seaweed (Kappaphycus sp) and depth variation on the growth, production and carrageenan content of Seaweed using a top down cultivation method. <b>Top</b> <b>down</b> <b>method</b> combined the two methods of cultivation, the method of surface and off-bottom method. The types of Seaweed used were Kappaphycus alvarezii (Brown Maumere and Local Maumere) and Bali Seaweed (Kappaphycus striatum). This study was designed using a factorial experimental design, where is comprised of two factors: the types and water depth. Parameters measured were daily growth rate, production and carrageenan content of Seaweeds. The results showed that different types of Seaweed gave a significant effect (P 0. 05). A combination of Seaweed types and depth variation did not give a significant effect on daily growth rate and production of Seaweeds (P> 0. 05). The highest carrageenan content was found in Local Seaweed (42. 15 %). Brown Seaweed produced 40. 59 % of carrageenan content while Bali Seaweed produced 35. 80 %...|$|E
40|$|The new {{revolution}} in materials science is {{being driven by}} our ability to manipulate matter {{at the molecular level}} to create structures with novel functions and properties. The aim {{of this paper is to}} explore new strategies to obtain plasmonic metal nanostructures through the combination of a <b>top</b> <b>down</b> <b>method,</b> that is electron beam lithography, and a bottom up technique, that is the chemical electroless deposition. This technique allows a tight control over the shape and size of bi- and three-dimensional metal patterns at the nano scale. The resulting nanostructures can be used as constituents of Surface Enhanced Raman Spectroscopy (SERS) substrates, where the electromagnetic field is strongly amplified. Our results indicate that, in electroless growth, high quality metal nanostructures with sizes below 50 nm may be easily obtained. These findings were explained within the framework of a diffusion limited aggregation (DLA) model, that is a simulation model that makes it possible to decipher, at an atomic level, the rules governing the evolution of the growth front; moreover, we give a description of the physical echanisms of growth at a basic level. In the discussion, we show how these findings can be utilized to fabricate dimers of silver nanospheres where the size and shape of those spheres is controlled with extreme precision and can be used for very large area SERS substrates and nano-optics, for single molecule detection. 2014 by the authors; licensee MDPI, Basel, Switzerland...|$|E
40|$|We {{describe}} a Context Free Grammar (CFG) for Bangla language and hence we propose a Bangla parser {{based on the}} grammar. Our approach is very much general to apply in Bangla Sentences and the method is well accepted for parsing a language of a grammar. The proposed parser is a predictive parser and we construct the parse table for recognizing Bangla grammar. Using the parse table we recognize syntactical mistakes of Bangla sentences {{when there is no}} entry for a terminal in the parse table. If a natural language can be successfully parsed then grammar checking from this language becomes possible. The proposed scheme is based on <b>Top</b> <b>down</b> parsing <b>method</b> and we have avoided the left recursion of the CFG using the idea of left factoring. Comment: 13 pages, 13 figure...|$|R
50|$|Tree series. For the Tree series, Balog {{wanted to}} {{photograph}} some of world’s tallest trees in their full grandeur, but {{he realized that}} his subjects were far too large to capture in a single frame. He devised a multi-frame approach of photographing the trees from the <b>top</b> <b>down.</b> The <b>method</b> was inspired {{by some of the}} lunar landing pictures from the NASA missions during the 1960s. Balog climbed each tree, and then photographed it in sections as he rappelled downward. Later, he created digital mosaics by stitching the images together using computer imaging software. Some images required up to four days of shooting, plus as many as six weeks of computer work to assemble the final composition. The tree images eventually became a 2004 book, Tree: A New Vision of the American Forest.|$|R
40|$|Communities are emergent, {{holistic}} living systems. Understanding {{the impact}} of social complex systems through spatial interactions via the lens of scalability requires {{the development of new}} methodological behavioural approaches. The evolution of social complex systems of cities and their regions can be investigated through the evolution of spatial structures. The clustering of entities within cities, regions and beyond presents behavioural elements for which methodological approaches need to be considered. The emergent aspect of complex entities by their very nature requires an understanding that can embrace unpredictability through emergence. Qualitative methodological approaches can be holistic with the ability to embrace bottom up and <b>top</b> <b>down</b> <b>methods</b> for analysis. Social complex systems develop structures by connecting "like minded" behaviour through scalability. How "mobile" these interactions are, is a concept that can be understood via "inter-organizational" and "interstructural" comparative approaches. How do we indeed convey this adequately or appropriately? Just as a geographical area may contain characteristics that can help to support the formation of an emergent industry cluster, similar behaviours occur through emergent characteristics of complex systems that underpin the sustainability of an organization. The idea that complex systems have tacit structures, capable of displaying emergent behaviour, is not a common concept. These tacit structures can in turn, impact the structural sustainability of physical entities. More often than not, there is a focus on how these concepts of complex systems work, but the "why" questions depends upon scalability. Until recently, social complex adaptive systems were largely over looked due to the tacit nature of these network structures...|$|R
40|$|EU {{legislation}} {{requires that}} European infrastructure managers set access charges {{based on the}} marginal cost of running trains on their networks. Two methods {{have been used in}} the literature for this purpose. Top-down methods relate actual costs to traffic volumes. Bottom-up methods use engineering models to simulate damage and then translate damage into costs based on assumptions about interventions and their unit costs. Whilst <b>top</b> <b>down</b> <b>methods</b> produce sensible results for marginal cost overall, they have struggled to differentiate between traffic types. The challenge for bottom-up approaches is how to translate damage into cost, with numerous assumptions being required which may be invalid. This paper proposes a new, two stage approach to estimating the marginal cost of rail infrastructure usage. The first stage uses engineering models to simulate damage caused by vehicles on the network. The second stage seeks to establish a statistical relationship between actual costs and damage. It is thus possible to convert damage estimates into costs using actual cost data, rather than through a set of potentially invalid assumptions as in previous approaches. Only the first stage is implemented in this paper. We show that it possible to produce total (annualised) damage measures for three damage mechanisms on five actual track sections in Sweden. Once extended, {{it will be possible to}} model the relationship between damage and actual costs for the first time; and thus better understand the relative costs of the different damage mechanisms and in turn inform the level and structure of track access charges...|$|R
