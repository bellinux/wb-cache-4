0|10000|Public
40|$|This paper {{reports the}} {{extension}} of <b>the</b> <b>key</b> <b>words</b> <b>method</b> for <b>the</b> comparison of corpora. Using automatic tagging software that assigns part-of-speech and semantic field (domain) tags, a method is described which permits <b>the</b> extraction of <b>key</b> domains by applying the keyness calculation to tag frequency lists. The combination of <b>the</b> <b>key</b> <b>words</b> and <b>key</b> domains <b>methods</b> is shown to allow macroscopic analysis (the study {{of the characteristics of}} whole texts or varieties of language) to inform the microscopic level (focussing on the use of a particular linguistic feature) and thereby suggesting those linguistic features which should be investigated further. The resulting 'data-driven' approach presented here combines elements of both the 'corpus-based' and 'corpus-driven' paradigms in corpus linguistics. A web-based tool, Wmatrix, implementing the proposed method is applied in a case study: the comparison of UK 2001 general election manifestos of the Labour and Liberal Democratic parties...|$|R
40|$|Abstract. In {{this paper}} {{we report on}} the design and {{analysis}} of a multilevel method for the solution of the Ornstein-Zernike Equations and related systems of integro-algebraic equations. Our approach is based on an extension of the Atkinson-Brakhage method, with Newton-GMRES used as the coarse mesh solver. We report on several numerical experiments to illustrate the effectiveness of <b>the</b> <b>method.</b> <b>Key</b> <b>words.</b> Multilevel <b>method,</b> Newton-GMRES, Ornstein-Zernike equations, nonlinear equation...|$|R
40|$|Abstract. This work {{presents}} an adaptive block Lanczos method for large-scale non-Hermitian Eigenvalue problems (henceforth the ABLE method). The ABLE method is a block {{version of the}} non-Hermitian Lanczos algorithm. There are three innovations. First, an adaptive blocksize scheme cures (near) breakdown and adapts the blocksize {{to the order of}} multiple or clustered eigenvalues. Second, stopping criteria are developed that exploit the semiquadratic convergence property of the method. Third, a well-known technique from the Hermitian Lanczos algorithm is generalized to monitor the loss of biorthogonality and maintain semibiorthogonality among the computed Lanczos vectors. Each innovation is theoretically justified. Academic model problems and real application problems are solved to demonstrate the numerical behaviors of <b>the</b> <b>method.</b> <b>Key</b> <b>words.</b> <b>method</b> non-Hermitian matrices, eigenvalue problem, spectral transformation, Lanczos AMS subject classifications. 65 F 15, 65 F 10 PII. S 089547989731780...|$|R
40|$|The {{main goal}} of this bachelor's thesis is to carry out a strategic {{analysis}} of construction company Metrostav a. s. The thesis is divided into four parts, one being introduction, second theoretically methodological part, third practical part and conclusion in the end. Goals of the thesis are described in introduction, theoretically methodological part defines <b>the</b> <b>key</b> <b>words</b> and explains <b>methods</b> applied in the practical part. Analysis is divided into external and internal analysis. External analysis describes the company's environment and it's influence on the company. It includes PEST analysis, Porter's five forces analysis and map of strategic groups. Internal analysis identifies company's resources and it's relations. SWOT analysis represents connection of both analysis. Conclusion includes a summary and suggestions for the future course of the company...|$|R
40|$|We {{propose a}} family of {{directions}} that generalizes many directions proposed so far in interiorpoint methods for the SDP (semidefinite programming) and for the monotone SDLCP (semidefinite linear complementarity problem). We derive the family from the Helmberg-Rendl-Vanderbei-Wolkowicz/KojimaShindoh -Hara/Monteiro direction by relaxing its "centrality equation" into a "centrality inequality. " Using this family, we present a predictor-corrector infeasible-interior-point method to provide a theoretical basis for inexact computation of directions in primal-dual interior-point <b>methods</b> for <b>the</b> SDP. <b>Key</b> <b>words</b> Interior-Point <b>Methods,</b> Semidefinite Programming, Semidefinite Linear Complementarity Problem, Inexact Computation, Search Direction y Dept. of Mathematical and Computing Sciences, Tokyo Institute of Technology, 2 - 12 - 1 OhOkayama, Meguro-ku, Tokyo 152, Japan. e-mail: kojima@is. titech. ac. jp z Dept. of Mathematics, Faculty of Engineering, Kanagawa University, Rokkakubashi, Kanagawaku, Yo [...] ...|$|R
40|$|Abstract. We {{consider}} two-level {{finite element}} discretization methods for the stream function {{formulation of the}} Navier-Stokes equations. The two-level method consists of solving a small nonlinear system on the coarse mesh, then solving a linear system on the fine mesh. The basic result states that the errors between the coarse and fine meshes are related superlinearly. This paper demonstrates that the two-level method can be implemented to approximate efficiently solutions to the Navier-Stokes equations. Two fluid flow calculations are considered to test problems which have a known solution and the driven cavity problem. Stream function contours are displayed showing the main features of <b>the</b> flow. <b>Key</b> <b>words.</b> Two-level <b>method,</b> Navier-Stokes equations, finite element, stream function formulation, Reynolds number AMS subject classifications. 65 N 35, 76 M 30, 76 D 05 1. Introduction. Th...|$|R
40|$|Abstract. Generalized {{quadrature}} {{rules are}} derived which {{assist in the}} selection of collocation points for the pseudospectral solution of differential equations. In particular, it is shown that for an nth-order differential equation in one space dimension with two-point derivative boundary conditions, an ideal choice of interior collocation points is the set of zeros of a Jacobi polynomial. The pseudospectral solution of a third-order initial-boundary value problem is considered and accuracy is assessed by examining how well the discrete eigenproblem approximates the continuous one. Convergence is established for a special choice of collocation points and numerical results are included to demonstrate the viability of <b>the</b> approach. <b>Key</b> <b>words,</b> pseudospectral <b>method,</b> third-order differential equation, generalized quadrature rules, Jacobi polynomials AMS(MOS) subject classifications. 65 D 05, 65 D 32, 65 N 3...|$|R
40|$|This article {{describes}} the design and implementation of a variable timestep method for simulating time-reversible constrained dynamical systems. Based on the Adaptive Verlet method of Huang and Leimkuhler [13], and the SHAKE [20] and RATTLE [1] discretizations, the new method VRATTLE defines a mapping of the constraint manifold which preserves the reversible structure. It achieves this through the solution of a single scalar nonlinear equation at each timestep, together with the equations of constraint. As a nontrivial application, we simulate the dynamics of an elastic (inextensible, unshearable) rod undergoing large deformations and collisions with the sides of a bounding box. Numerical experiments indicate that adapting the stepsize using VRATTLE can smooth the numerical energy and improve the overall efficiency of <b>the</b> simulation. <b>Key</b> <b>words.</b> symplectic <b>methods,</b> time-reversible methods, adaptive timestepping, variable stepsize methods, nonlinear elastic dynamics, rod models, holon [...] ...|$|R
40|$|In {{this paper}} we discuss the design and {{implementation}} of a Newton-Krylov-Schwarz solver for the implicit temporal integration on an unstructured three-dimensional spatial mesh of Richards' equation for groundwater flow in unsaturated porous media. We use aggregation techniques from the algebraic multigrid literature to construct a coarse mesh for two-level Schwarz methods. Our coarse mesh differs from other constructions in that no coarse mesh geometry need be created {{and we do not}} need geometric information about the subdomains. We report on a computational example to illustrate the performance of <b>the</b> preconditioner. <b>Key</b> <b>words.</b> Newton-Krylov-Schwarz <b>methods,</b> Richards' equation, nonlinear equations, unstructured mesh AMS subject classifications. 65 H 10, 65 N 55, 76 S 05, 76 T 05, 86 A 05 1. Introduction. In this {{paper we discuss}} the design and implementation of a Newton-KrylovSchwarz solver for the implicit temporal integration on an unstructured three-dimensional spatial mesh of Richards' [...] ...|$|R
40|$|Gibbs {{demonstrated}} that truncating a Fourier {{representation of a}} discontinuous function produces a highly oscillatory function. New techniques can now obtain exponentially accurate expansions from a truncated Fourier representation. But many of these techniques require accurate knowledge of the shock locations. The Prony method provides such an estimation, but this method requires an a priori knowledge {{of the number of}} shocks. The method presented here will not need to know how many shocks exist, and still provide an accurate estimation of the shock location. Another concern was to make this method find the shock locations with the same accuracy whether or not there are contact discontinuities (discontinuities in the derivatives) in <b>the</b> data. <b>Key</b> <b>words.</b> Spectral <b>Methods,</b> Shock Location, Filtering AMS subject classifications. 42 a 16, 42 [...] 04, 65 T 10, 65 [...] 04 1. Introduction. Edge detection has been a problem of great interest in the field of pattern recognition for many years. The problem [...] ...|$|R
40|$|This thesis {{deals with}} the {{question}} of prestige of subject Geography. Its aim is to explain how much prestige university students attach to Geography, with the help of semantic differential method, and where they place this term in the semantic field of terms. The research was conducted with questionnaire survey which focused on the comparison between the perception of Geography and other subjects, {{and at the same time}} the comparison of value judgement of Geography students and students of different programmes. The first part of the thesis explains <b>the</b> <b>key</b> <b>words</b> and <b>the</b> <b>methods</b> of the research into prestige conducted so far. They were analysed and on the basis of this analysis notional parameters of prestige attached to a subject were set. The following part is the main part. It consists of the questionnaire survey, including the evaluation and interpretation of the results, which is followed by suggestions for improvement of the prestige of Geography, with the use of chosen marketing tools. Key words: prestige; social status; value judgement; attitude; geography; semantic differential; marketin...|$|R
40|$|We {{investigate}} the conditions which guarantee that RungeKutta methods preserve asymptotic {{values of the}} systems of ordinary differential equations. A complete characterization of such methods is given and examples of methods with these properties are presented for s = p = 2; 3 and 4, where s {{is the number of}} stages and p is the order of <b>the</b> <b>method.</b> <b>Key</b> <b>Words.</b> Runge-Kutta <b>method,</b> ordinary differential equation, asymptotic values. Department of Mathematics, Arizona State University, Tempe, Arizona 85287. The work of this author was partially supported by the National Science Foundation under grant NSF DMS [...] 9208048 and by the Italian Government. y Dipartimento di Matematica e Informatica, Universit`a di Udine, I [...] 33100 Udine, Italy. The work of this author was supported by the Italian M. U. R. S. T., funds 40 %. z Dipartimento di Scienze Matematiche, Universit`a di Trieste, I [...] 34100 Trieste, Italy. The work of this author was supported by the Italian M. U. R. S. T., funds 40 %. 1 Introdu [...] ...|$|R
40|$|Abstract. We {{construct}} {{a family of}} root- nding algorithms which combine knowledge of the branched covering structure of a polynomial with a path-lifting algorithm for nding individual roots. In particular, the family includes an algorithm that; computes an-factorization of a polynomial of 2 2 2 degree d which has an arithmetic complexity ofO d(log d) j log j + d (log d). At the present time, this complexity isthebestknown in terms of <b>the</b> degree. <b>Key</b> <b>words.</b> Newton's <b>method,</b> approximate zeros, arithmetic complexity, path-lifting method, branched covering. AMS subject classi cations. 68 Q 25 � Secondary 58 C 10, 65 H 05, 30 C 15, 58 F 08 Introduction. The problem of devising optimal methods for numerically approximating the roots of a polynomial has been of interest for several centuries, and is far from solved. There are numerous recent works on root- nding algorithms and their cost, for example, the work of Jenkins and Traub [JT 70], Renegar [Ren 87], Schonhage [Sch 82], and Shub and Smale [SS 85, SS 86, Sma 85]. This list is far from complete � th...|$|R
40|$|Conditions are {{investigated}} which {{guarantee that}} RungeKutta methods preserve the asymptotic values of systems of delay differential equations. Such methods {{are said to}} be strongly regular. A constructive test for strong regularity is derived and examples of such methods are presented for s = p = 2 and s = p = 3, where s is the number of stages and p is the order of <b>the</b> <b>method.</b> <b>Key</b> <b>Words.</b> Runge-Kutta <b>method,</b> delay differential equation, asymptotic values. Department of Mathematics, Arizona State University, Tempe, Arizona 85287. The work of this author was partially supported by the National Science Foundation under grant NSF DMS [...] 9208048 and by the Italian Government. y Dipartimento di Matematica e Informatica, Universit`a di Udine, I [...] 33100 Udine, Italy. The work of this author was supported by the Italian M. U. R. S. T., funds 40 %. z Dipartimento di Scienze Matematiche, Universit`a di Trieste, I [...] 34100 Trieste, Italy. The work of this author was supported by the Italian M. U. R. S [...] ...|$|R
40|$|Abstract. A new {{adaptive}} {{approach for}} one–dimensional scalar conservation laws with convex flux is proposed. The initial data are approximated on an adaptive grid by a problem dependent, monotone interpolation procedure {{in such a}} way, that the multivalued problem of characteristic transport can be easily and explicitly solved. The unique entropy solution is chosen {{by means of a}} selection criterion due to Hopf and Lax. For arbitrary times, the solution is represented by an adaptive monotone spline interpolation. The spatial approximation is controlled by local L 1 –error estimates. As a distinctive feature of the approach, there is no discretization in time. The method is monotone on fixed grids. Numerical examples are included, to demonstrate <b>the</b> predicted behavior. <b>Key</b> <b>Words.</b> <b>method</b> of characteristics, adaptive grids, monotone interpolation, L 1 –error estimates AMS(MOS) subject classification. 65 M 15, 65 M 25, 65 M 50 Introduction. A fundamental idea for supporting the development of robust, re-liable, and efficient software is adaptivity. In the field of ordinary differential equations, and more recently, elliptic and parabolic partial differential equations much {{progress has been made in}} this direction. For inherent structural reasons, the situation is much more difficult for hyper...|$|R
40|$|Adapting trained {{detectors}} to unseen scenes is {{a critical}} problem in pedestrian detection. The performance of trained detector may drop quickly when scenes vary significantly. Retraining a detector with labeled samples from the new scenes may improve its performance. However, {{it is difficult to}} obtain enough labeled samples in real applications. In this paper, a novel bag of visual <b>words</b> based <b>method</b> is proposed to detect pedestrians in unseen scenes by dynamically updating <b>the</b> <b>key</b> <b>words.</b> <b>The</b> proposed <b>method</b> achieves its adaptability by using three strategies covering <b>key</b> <b>word</b> selection, detector invariance, and codebook update: (1) In order to select typical words representing pedestrians, a low dimensional model of visual words is built to describe their distribution and select <b>key</b> <b>words</b> using manifold learning. (2) Matching confidence vector (MCV), a novel visual words measurement is proposed, which aims to generate a uniform input vector for the fixed detector applied to different pedestrian codebooks. (3) When detecting pedestrians under changing road conditions, <b>the</b> <b>key</b> <b>word</b> set will be dynamically adjusted according to the matching frequency of each word to adapt the detector to the new scenes. By employing the above strategies, the proposed method is able to detect pedestrians in different scenes without retraining the detector. Experiments in different scenes showed that our proposed method can achieve better adaptability to various scenes and get better performance than other existing methods in unseen scenes. (C) 2013 Elsevier B. V. All rights reserved...|$|R
40|$|Abstract. In general, when a quasi-Newton {{method is}} applied to solve a system of {{nonlinear}} equations, the quasi-Newton direction {{is not necessarily a}} descent direction for the norm function. In this paper, we show that when applied to solve symmetric nonlinear equations, a quasi-Newton method with positive definite iterative matrices may generate descent directions for the norm func-tion. On the basis of a Gauss–Newton based BFGS method [D. H. Li and M. Fukushima, SIAM J. Numer. Anal., 37 (1999), pp. 152 – 172], we develop a norm descent BFGS method for solving symmetric nonlinear equations. Under mild conditions, we establish the global and superlinear con-vergence of the method. The proposed method shares some favorable properties of the BFGS method for solving unconstrained optimization problems: (a) the generated sequence of the quasi-Newton matrices is positive definite; (b) the generated sequence of iterates is norm descent; (c) a global convergence theorem is established without nonsingularity assumption on the Jacobian. Preliminary numerical results are reported, which positively support <b>the</b> <b>method.</b> <b>Key</b> <b>words.</b> BFGS <b>method,</b> norm descent direction, global convergence, superlinear convergence AMS subject classifications. 65 H 10, 90 C 53 PII. S 003614290139742...|$|R
40|$|Attention deficit {{hyperactivity}} disorder (ADHD) {{is the most common}} neurobehavioral disorder of childhood. ADHD is also among the most prevalent chronic health conditions affecting school-aged children"(American Academy of Pediatrics, 2000). Too many young girls are not getting the help they need because of hidden symptoms and late diagnosis. The {{purpose of this study is}} to determine the effect of focus strategies on vocabulary learning of ADHD students at two junior high schools. To this end, eight female ADHD and eight normal students from two public schools were assigned to the both control group and the experimental one. The quantitative data was gathered from each student and was analyzed through 2 -way analysis of variance (ANOVA) in a factorial arrangement with two repetitions. An orthogonal test was used to compare the strategies that were used in the control group (word list) and <b>the</b> experimental group (<b>key</b> <b>word</b> <b>method,</b> concentration, making sentences and fold overs). The instrument of this study contained a questionnaire sent to the parents and English teachers, an interview with a psychologist, a pre-test and a post-test. The results indicated that the four focus strategies in the experimental group increased the vocabulary learning in ADHD students for the short term retention and this increase was significant in the first focus strategy (<b>key</b> <b>word</b> <b>method)</b> and mostly <b>the</b> last one (fold overs) in the normal and ADHD students. The mean scores of control group were lower than the treatment group both in the normal and ADHD students. The results of delayed post-test revealed that although focus strategies improved the scores of the normal students compared to the ADHD students, this difference was not significant...|$|R
5000|$|Political Inclusiveness: <b>The</b> <b>Key</b> <b>Word</b> for Arab Spring Nations ...|$|R
40|$|PURPOSE: To {{evaluate}} <b>the</b> <b>key</b> <b>words</b> used in Acta Cirurgica Brasileira from 1997 to 2012. METHODS: All <b>the</b> <b>key</b> <b>words</b> of all {{articles published}} in regular issues between 1997 and 2012 were analyzed, ensuring that these <b>key</b> <b>words</b> were in <b>the</b> MeSH database (Medical Subjects Headings) and the most used subject headings and most wrong repeated <b>key</b> <b>words</b> were ranked. RESULTS: > 4230 <b>key</b> <b>words</b> used in 990 articles were analyzed. Only 579 <b>key</b> <b>words</b> (13. 68 %) {{were not in the}} MeSH database, considering that there was a statistically significant decrease over the years (p< 0. 001). The three most used <b>key</b> <b>words</b> were Rats, Dogs and Wound healing. Among the wrong ones, <b>the</b> <b>key</b> <b>words</b> were Adhesions, Experimental surgery and Anatomosis. CONCLUSION: There was a gradual improvement in <b>the</b> amount of <b>key</b> <b>words</b> used that belonged to the MeSH database, and there were 618 articles (62. 42 %) with all <b>key</b> <b>words</b> correct...|$|R
40|$|Abstract. A second {{scheme for}} the sagitta method is presented. This method uses a “global ” {{viewpoint}} of the linear problem, and, in this feasible-point version, {{it also takes}} advantage of the additional “local” information that a feasible point supplies. The computational results obtained are highly encouraging. <b>Key</b> <b>Words.</b> <b>methods.</b> Linear programming, active set methods, range space 1...|$|R
40|$|Abstract. This paper {{continues}} {{the development of}} the least-squares methodology for the solution of the incompressible Navier-Stokes equations started in Part I. Here we again use a velocityflux first-order Navier-Stokes system, but our focus now is on a practical algorithm based on a discrete negative norm. <b>Key</b> <b>words.</b> <b>methods.</b> Navier-Stokes equations, least-squares principle, negative norm, finite elemen...|$|R
5000|$|The entire {{problem is}} codified using <b>the</b> <b>key</b> <b>words,</b> cost, dynamics, events and path: ...|$|R
30|$|The {{data was}} curated {{recognising}} first from each dyad (as reported by students) <b>the</b> <b>key</b> <b>words,</b> and second, forming {{a list of}} closely synonymous words {{in order to reduce}} the irrelevant variations in <b>the</b> <b>key</b> <b>words</b> (<b>the</b> language was Finnish, which has many different flexions for same <b>words).</b> Eventually, all <b>key</b> <b>words,</b> which were considered synonymous, were merged to one <b>key</b> <b>word.</b> In total, about 700 synonymous words were found and resulted to 1613 different <b>key</b> <b>words,</b> which were used as basis to construct the networks.|$|R
40|$|Thesaurus of <b>key</b> <b>words</b> used in <b>the</b> annual subject indexes (valid from January 1997) The list {{is common}} to Astronomy and Astrophysics, The Astrophysical Journal and Monthly Notices of the Royal Astronomical Society. In order to ease <b>the</b> search, <b>the</b> <b>key</b> <b>words</b> are {{subdivided}} into broad categories. No more than six codes all together should be listed for a paper as this is the limit fixed by the computer program. <b>The</b> <b>key</b> <b>words</b> in boldface listed under the code number...|$|R
30|$|<b>The</b> <b>key</b> <b>words</b> used to {{identify}} the corresponding studies in the other databases were: “open bite” and “mixed dentition”.|$|R
5000|$|Children {{pass through}} several phases as they acquire a language: {{gathering}}, <b>key</b> <b>word,</b> and sentence. In the gathering phase, {{when children are}} exposed to the new language they start to hear and distinguish sounds. In <b>the</b> <b>key</b> <b>word</b> phase they start to identify and use <b>key</b> content <b>words.</b> For example, to express [...] "I am hungry", they would simply use <b>the</b> <b>key</b> <b>word</b> [...] "hungry". In the sentence phase, children begin to use phrases and complete sentences. There is a long delay from starting to distinguish sounds to being able to use complete sentences.|$|R
50|$|In {{the eighties}} {{diversification}} was <b>the</b> <b>key</b> <b>word.</b> A logical {{step in this}} process was to start assembling professional coffee machines in Turnhout.|$|R
30|$|Therefore, future {{analysis}} {{could be}} carried out to analyse a more extensive {{period of time and}} to run <b>the</b> <b>key</b> <b>words</b> through more databases.|$|R
40|$|Abstract. Wederivelocalized pointwiseerrorestimates forNitsche’smethod appliedtoan {{elliptic}} second order {{problem in}} R n (n = 2, 3). Using these results, we also prove quasi-optimal global L p error estimates as well. Numerical experiments are provided which back up <b>the</b> theoretical findings. <b>Key</b> <b>words.</b> Nitsche’s <b>method,</b> pointwise error estimates, L p error estimates 1. 1. Introduction. We {{consider the following}} second order elliptic problem: (1. 1 a) (1. 1 b) Lu: = −∇·(A∇u) +b·∇u+cu = f in Ω, u =...|$|R
5000|$|AppleSearch also {{included}} {{the ability to}} [...] "summarize" [...] documents into a shorter form. It did this by selecting sentences from the document that contained a higher than normal number of [...] "key words", <b>the</b> <b>key</b> <b>words</b> being <b>the</b> same set {{that would be used}} for search tuning, as above. The user could request a version of the document some percentage of the original size, and the engine would then remove sentences it considered less important (those with less of <b>the</b> <b>key</b> <b>words)</b> until it reached the requested size.|$|R
40|$|Abstract. In {{this paper}} we propose a general method for a posteriori error {{estimation}} in the solution of initial value problems in ordinary differential equations (ODEs). With the help of adjoint sensitivity software, this method can be implemented efficiently. It provides a condition estimate for the ODE system. We also propose an algorithm for global error control, based on the condition of the system and the perturbation due to <b>the</b> numerical approximation. <b>Key</b> <b>words.</b> adjoint <b>method,</b> ordinary differential equation, global error contro...|$|R
25|$|In August 2014, Nokia redefined {{its values}} {{again after the}} sale of its Devices business. The new values were defined with <b>the</b> <b>key</b> <b>words</b> respect, achievement, renewal and challenge.|$|R
30|$|Then, {{we started}} our {{detailed}} literature analysis by searching for <b>the</b> <b>key</b> <b>words</b> “complexity driver” or “driver of […] complexity” and analyzed the content around <b>the</b> <b>key</b> <b>words.</b> <b>The</b> <b>key</b> <b>words</b> were highlighted in the text, and we made notes about our first impressions and thoughts. Afterward, we read all data repeatedly to achieve {{an overview of the}} whole content and separated the text in different parts regarding their content. The parts with relevant information about complexity drivers were assigned to the previously defined categories in our synthesis matrix. The assignment of a specific information to a certain category (coding) was induced by the particular text passage (coding unit). Parts without relevant information were ignored. As a result of our extraction process, a vast amount of data from 235 different literature sources were collected in a table to answer our research questions. For information evaluation, we compared the found information in each category to identify communalities or differences.|$|R
50|$|<b>The</b> <b>Key</b> <b>Words</b> Reading Scheme, {{taking his}} ideas, was first {{published}} in 1964, with Peter and Jane, and went on to sell over 80 million copies of the books in the series.|$|R
40|$|This study {{presents}} a methodology for {{the identification of}} coherent word sets. Eight sets were initially identified and further grouped into two main sets: a `company' set and a `non-company' set. These two sets shared very few collocates, and therefore they seemed to represent distinct topics. The positions of {{the words in the}} `company' and `non-company' sets across the text were computed. The results indicated that the `non-company' sets referred to `company' implicitly. Finally, <b>the</b> <b>key</b> <b>words</b> were compared to an automatic abridgment of the text which revealed that nearly all <b>key</b> <b>words</b> were present in the ahridgment. This was interpreted as suggesting that <b>the</b> <b>key</b> <b>words</b> may indeed represent the main contents of the text...|$|R
