11|65|Public
5000|$|The {{evolutionary}} history is finished. The endeavour is complete. If youd asked me 20 years ago whether wed be attempting such a mammoth <b>task,</b> <b>Id</b> have said [...] "Dont be ridiculous!" [...] These programmes tell a particular story and Im sure others will {{come along and}} tell it much better than I did, but I do hope that if people watch it in 50 years time, it will still {{have something to say}} about the world we live in.|$|E
40|$|A set of {{programs}} was written {{to test the}} functionality and performance of the Alsys Ada implementation of the Catalogue of Interface Features and Options (CIFO), a set of optional Ada packages for real-time applications. No problems were found with the <b>task</b> <b>id,</b> preemption control, or shared-data packages. Minor problems were found with the dispatching control, dynamic priority, events, non-waiting entry call, semaphore, and scheduling packages. The Alsys implementation is derived mostly from Release 2 of the CIFO standard, but includes some {{of the features of}} Release 3 and some modifications unique to Alsys. Performance measurements show that the semaphore and shared-data features are an order-of-magnitude faster than the same mechanisms using an Ada rendezvous. The non-waiting entry call is slightly faster than a standard rendezvous. The existence of errors in the implementation, the incompleteness of the documentation from the published standard impair the usefulness of this implementation. Despite those short-comings, the Alsys CIFO implementation might be of value in the development of real-time applications...|$|E
40|$|Abstract: {{the main}} {{objective}} {{of this paper is}} to develop a new scheduling algorithm for scheduling of task in Real-Time operating systems. The proposed architecture is a modified version of Round-Robin architecture which is used for scheduling of tasks in Real-Time operating systems. It is observed that the proposed architecture solves the drawbacks of simple Round-Robin architecture in Real-Time operating system by decreasing the number of context switches waiting time and response time thereby improving the system performance. This paper also explains the development of a new CLI simulation framework: to study and evaluate the performance of various uniporcessor real-time scheduling algorithm for Real-Time system. <b>Task</b> <b>ID,</b> Deadline, Priority, period, Computation time, and Phase are the input task attributes to the scheduler simulator and chronograph imitating the real-time execution of the input task set and computational statistics of the schedule are the output. The proposed framework for the scheduler simulator is mainly developed to be used as a teaching tool. The CLI deployment of the simulator enables the user a platform, machine and software-independent utilization of the technical resource...|$|E
50|$|At all NZDF facilities, {{civilian}} {{staff are}} used to augment physical security manpower, particularly for relatively simple <b>tasks</b> like <b>ID</b> checking and security patrols.|$|R
5000|$|A/ROSE was {{a message}} passing system, and the main calls made by {{programs}} running under it were [...] and [...] Messages were short, including only 24 bytes of user data, and sent asynchronously. To find the appropriate endpoint, A/ROSE included a name server that allowed the applications to bind their names to their <b>task</b> <b>IDs,</b> allowing them {{to move in the}} system and be found dynamically. The OS also supported a number of routines for finding, starting and stopping tasks on other cards, one of those [...] "cards" [...] being the host computer.|$|R
30|$|When the Schedule module {{receives}} the task, {{according to the}} content of the <b>task</b> (program <b>ID,</b> program location), it downloads the procedures to be tested from a specified location to the local and hands the program over to TaintChaser for analysis.|$|R
40|$|Any system (whether in {{the area}} of finance, manufacturing, administration, etc.) that {{operates}} in a dynamic environment needs to be adaptive to changes; it should also anticipate possible adverse events to remain competitive. In our previous research in this area we experimented with one particular approach: Mapping of <b>Task</b> <b>ID</b> for Centroid-Based Adaptation with Random Immigrants (McBAR) to address problems of environmental changes for Resource-Constrained Project Scheduling (RCPS) problem, especially when the latter involves changes in task numbers. However, at that time, McBAR was applied as reactive tool only. In this paper we extend McBAR approach to the RCPS problem in a proactive-reactive way. The system handles also three competing objectives: cost, makespan, and the risk of failure. We have not found any papers that deal with risk on the RCPS problem and utilize the attributes of plans from the past environmental changes. This particular aspect is incorporated in McBAR – experimental results indicate the efficiency of such approach in finding optimal solutions for a current change. In this paper we also analyze, under the effects of environmental dynamics, the variation of risk computed via McBAR and of parameters related to optimization. Further, we compare McBAR to other Evolutionary Algorithm approach in the same problem. Manuel Blanco Abello, Zbignew Michalewicz and Lam Thu Bu...|$|E
40|$|Changes in {{environment}} {{is common in}} daily activities and usually introduce new problems. To be adaptive to these changes, new {{solutions to the problems}} are to be found every time change occur. Our previous publication showed that centroid of nondominated solutions associated with Multi-Objective Evolutionary Algorithm (MOEA) from previous changes enhances the search quality of solutions for the current change. However, the number of tasks in the test environment employed was fixed. In this two-part paper, we address the dynamic adaptation with time-varying task number. To cope with this variability, new components of the solution, corresponding to the new tasks, are inserted appropriately to all solutions of the previous changes. Then centroid of these modified solutions is recomputed. Further, to avoid confusion in solution presentation, the insertion of new tasks obliged the use of <b>task</b> <b>ID</b> number greater than the largest of the previous IDs. The first part of this paper will show that the resulting task numbering system will alter the centroid significantly which will degrade MOEA’s search quality. To circumvent, task IDs are mapped to new values in order to minimize difference in IDs between adjacent solution components; an approach which significantly upgraded the search performance despite changes in task number as supported by the obtained results. Manuel Blanco Abello, Lam Thu Bui and Zbignew Michalewicz[URL]...|$|E
40|$|This study {{investigated}} whether auditory, speech perception and phonological skills are tightly interrelated or independently contributing to reading. We assessed {{each of these}} three skills in 36 adults with a past diagnosis of dyslexia and 54 matched normal reading adults. Phonological skills were tested by the typical threefold tasks, i. e. rapid automatic naming, verbal short term memory and phonological awareness. Dynamic auditory processing skills were assessed by means of a frequency modulation (FM) and an amplitude rise time (RT); an intensity discrimination <b>task</b> (<b>ID)</b> was included as a non-dynamic control task. Speech perception was assessed by means of sentences and words in noise tasks. Group analysis revealed significant group differences in auditory tasks (i. e. RT and ID) and in phonological processing measures, yet no differences were found for speech perception. In addition, performance on RT discrimination correlated with reading but this relation was mediated by phonological processing and not by speech in noise. Finally, inspection of the individual scores revealed that the dyslexic readers showed an increased proportion of deviant subjects on the slow-dynamic auditory and phonological tasks, yet each individual dyslexic reader does not display a clear pattern of deficiencies across the levels of processing skills. Although our results support phonological and slow-rate dynamic auditory deficits which relate to literacy, they suggest that at the individual level, problems in reading and writing cannot be explained by the cascading auditory theory. Instead, dyslexic adults seem to vary considerably in the extent to which each of the auditory and phonological factors are expressed and interact with environmental and higher-order cognitive influences...|$|E
5000|$|GlobalPlatform members {{drive the}} {{organization}} through a Board of Directors, an Advisory Council, three technical committees, five strategic <b>task</b> forces (<b>ID,</b> internet-of-things, [...] mobile, premium content, and security) and two regional task forces (China and Japan.) Day-to-day activity is managed by an executive team comprising an executive director, technical director, operations secretariat and compliance secretariat.|$|R
30|$|Having found {{evidence}} that the LST can predict performance on lineup <b>ID</b> <b>tasks,</b> we next sought to increase the real-world utility of the test. The police often cannot conduct a lineup {{on the same day}} as a crime, as was done in Experiment 1, and the police probably would not want to expose witnesses to many new faces before showing them a lineup. With this in mind, we designed Experiment 2 to include a 2 -day delay between exposure to the crime videos and the <b>ID</b> <b>task,</b> and to have participants complete the lineup skills test after, rather than before, the lineups.|$|R
40|$|This paper {{presents}} the preparation, resources, results {{and analysis of}} the Infectious Diseases (<b>ID)</b> information extraction <b>task,</b> a main task of the BioNLP Shared <b>Task</b> 2011. The <b>ID</b> <b>task</b> represents an application and extension of the BioNLP’ 09 shared task event extraction approach to full papers on infectious diseases. Seven teams submitted final results to the task, with the highest-performing system achieving 56 % F-score in the full task, comparable to state-of-the-art performance in the established BioNLP’ 09 task. The results indicate that event extraction methods generalize well to new domains and full-text publications and are applicable to the extraction of events relevant to the molecular mechanisms of infectious diseases. ...|$|R
40|$|Problem statement: A Real-Time System (RTS) is {{one which}} {{controls}} an environment by receiving data, processing it, and returning the results {{quickly enough to}} affect {{the functioning of the}} environment at that time. The main objective of this research was to develop an architectural model for the simulation of real time tasks to implement in distributed environment through web, and to make comparison between various scheduling algorithms. The proposed model can be used for preprogrammed scheduling policies for uniprocessor systems. This model provided user friendly Graphical User Interface (GUI). Approach: Though a lot of scheduling algorithms have been developed, just a few of them are available to be implemented in real-time applications. In order to use, test and evaluate a scheduling policy it must be integrated into an operating system, which is a complex task. Simulation is another alternative to evaluate a scheduling policy. Unfortunately, just a few real-time scheduling simulators have been developed to date and most of them require the use of a specific simulation language. Results: <b>Task</b> <b>ID,</b> deadline, priority, period, computation time and phase are the input task attributes to the scheduler simulator and chronograph imitating the real-time execution of the input task set and computational statistics of the schedule are the output. Conclusion: The Web-enabled framework proposed in this study gave the developer to evaluate the schedulability of the real time application. Numerous benefits were quoted in support of the Web-based deployment. The proposed framework can be used as an invaluable teaching tool. Further, the GUI of the framework will allow for easy comparison of the framework of existing scheduling policies and also simulate the behavior and verify the suitability of custom defined schedulers for real-time applications...|$|E
40|$|Abstract: Problem statement: A Real-Time System (RTS) is {{one which}} {{controls}} an environment by receiving data, processing it, and returning the results {{quickly enough to}} affect {{the functioning of the}} environment at that time. The main objective of this research was to develop an architectural model for the simulation of real time tasks to implement in distributed environment through web, and to make comparison between various scheduling algorithms. The proposed model can be used for preprogrammed scheduling policies for uniprocessor systems. This model provided user friendly Graphical User Interface (GUI). Approach: Though a lot of scheduling algorithms have been developed, just a few of them are available to be implemented in real-time applications. In order to use, test and evaluate a scheduling policy it must be integrated into an operating system, which is a complex task. Simulation is another alternative to evaluate a scheduling policy. Unfortunately, just a few real-time scheduling simulators have been developed to date and most of them require the use of a specific simulation language. Results: <b>Task</b> <b>ID,</b> deadline, priority, period, computation time and phase are the input task attributes to the scheduler simulator and chronograph imitating the real-time execution of the input task set and computational statistics of the schedule are the output. Conclusion: The Webenabled framework proposed in this study gave the developer to evaluate the schedulability of the real time application. Numerous benefits were quoted in support of the Web-based deployment. The proposed framework can be used as an invaluable teaching tool. Further, the GUI of the framework will allow for easy comparison of the framework of existing scheduling policies and also simulate the behavior and verify the suitability of custom defined schedulers for real-time applications. Key words: Real-time, scheduler, simulator, preemptions and context switc...|$|E
40|$|Iron {{deficiency}} (ID) is {{the most}} common nutritional deficiency in humans, affecting more than two billion people worldwide. Early-life ID can lead to irreversible deficits in learning and memory. The pig represents a promising model animal for studying such deficits, because of its similarities to humans during early development. We investigated long-term effects of pre-weaning dietary iron deficiency in piglets on growth, blood parameters, cognitive performance and brain histology. Ten male sibling pairs of piglets were removed from the sow 4 - 6 days after birth. Ten piglets were given an iron dextran injection and were fed a control milk diet for 28 days (100 mg Fe/kg); their ten siblings were given a saline injection and fed an iron deficient milk diet (10 mg Fe/kg). Then, all piglets were fed a balanced commercial pig diet (190 - 240 mg Fe/kg). From 8 weeks of age, piglets were tested in a spatial cognitive holeboard task. In this task, 4 of 16 holes contain a hidden food reward, allowing measurement of working (short-term) memory and reference (long-term) memory (RM) simultaneously. All piglets received 40 - 60 acquisition trials, followed by a 16 -trial reversal phase. ID piglets showed permanently retarded growth and a strong decrease in blood iron parameters during dietary treatment. After treatment, ID piglets blood iron values restored to normal levels. In the holeboard <b>task,</b> <b>ID</b> piglets showed impaired RM learning during acquisition and reversal. Iron staining at necropsy at 12 weeks of age showed that ID piglets had fewer iron-containing cells in hippocampal regions CA 1 and dentate gyrus. The number of iron-containing cells in CA 3 correlated positively with acquisition RM performance for all animals. Our results support the hypothesis that early ID leads to lasting cognitive deficits. The piglet as a model animal, tested in the holeboard, can be useful in future research for assessing long-term cognitive effects of early-life diets or diet-induced deficiencies...|$|E
30|$|Therefore, we here {{investigated}} the Fitts’ task {{performed in a}} discrete {{as well as a}} cyclic <b>task</b> under seven <b>IDs</b> obtained either by scaling target width under constant amplitude or by scaling target distance under constant target width.|$|R
40|$|A listener’s {{ability to}} utilize indexical {{information}} in the speech signal can enhance their performance {{on a variety of}} speech perception tasks. It is unclear, however, whether such information plays a similar role for spectrally reduced speech signals, such as those experienced by individuals with cochlear implants. The present study compared the effects of training on linguistic and indexical tasks when adapting to cochlear implant simulations. Listening to sentences processed with an eight-channel sinewave vocoder, three separate groups of subjects were trained on a transcription task (transcription), a talker identification <b>task</b> (talker <b>ID),</b> or a gender identification <b>task</b> (gender <b>ID).</b> Pre- to posttest comparisons demonstrated that training produced significant improvement for all groups. Moreover, subjects from the talker ID and transcription training groups performed similarly at posttest and generalization, and significantly better than the subjects from the gender ID training group. These results suggest that training on an indexical task that requires high levels of controlled attention can provide equivalent benefits to training on a linguistic task. When listeners selectively focus their attention on the extralinguistic {{information in the}} speech signal, they still extract linguistic information, {{the degree to which they}} do so, however, appears to be task dependent...|$|R
40|$|Purpose – This is {{the first}} part of a two-part paper. The {{purpose of this paper is}} to report on methods that use the Response Surface Methodology (RSM) to {{investigate}} an Evolutionary Algorithm (EA) and memory-based approach referred to as McBAR – the Mapping of <b>Task</b> <b>IDs</b> for Centroid-Based Adaptation with Random Immigrants. Some of the methods are useful for investigating the performance (solution-search abilities) of techniques (comprised of McBAR and other selected EA- based techniques) for solving some multi-objective dynamic resource-constrained project scheduling problems with time-varying number of tasks. Design/methodology/approach – The RSM is applied to: determine some EA parameters of the techniques, develop models of the performance of each technique, legitimize some algorithmic components of McBAR, manifest the relative performance of McBAR over the other techniques and determine the resiliency of McBAR against changes in the environment. Findings – The results of applying the methods are explored in the second part of this work. Originality/value – The models are composite and characterize an EA memory-based technique. Further, the resiliency of techniques is determined by applying Lagrange optimization that involves the models. Manuel Blanco Abello and Zbigniew Michalewic...|$|R
3000|$|A {{walkthrough}} of mapJobHelper (...), which {{performs the}} allocation and scheduling of job j onto {{the set of}} resources in the system, is provided next. The input required by mapJobHelper (...) includes the following: a job j to map, a Boolean isRootJob, which is set to true {{if this is the}} first time job j is being mapped; otherwise, it is set to false, and a Boolean checkDeadline, which is set to true if the method should try to map job j to meet its deadline; otherwise, it is set to false and the method has to map job j on the system, but it does not have to schedule job j to meet its deadline. The mapJobHelper (...) method starts by initializing the local variable isJobMapped to true (line 1). Next, all of job j’s tasks that need to be mapped are sorted in non-increasing order of their respective execution times (line 2), where ties are broken in favour of the task with the earlier sub-deadline. If the tasks also have the same sub-deadline, the task with the smaller <b>task</b> <b>id</b> (a unique value) is placed ahead of the task with the larger id. The method then attempts to map each of job j’s tasks (lines 3 – 4) by performing the following operations for each task t in job j. First, the startTime variable is initialized by invoking the task t’s getEarliestStartTime (...) method (line 5), which returns the time that task t can start to execute while considering any precedence relationships that t has. If getEarliestStartTime (...) returns − 1, it means that an earliest start time for task t cannot be determined as yet because not all of task t’s parent tasks have been scheduled. In this case, mapJobHelper (...) stops processing task t for the moment and attempts to map the next task in job j (line 6). On the other hand, if startTime is not − 1, the processing of task t continues. If RM-DCWF’s taskSchedulingPolicy field is set to TSP 2 (line 7), the expected start time of the task is updated and set as shown in line 8. The expected completion time of the task is then calculated using the expected start time of the task (line 9).|$|E
40|$|Iron {{deficiency}} is {{the most}} common nutritional deficiency in humans, affecting more than two billion people worldwide. Early-life iron deficiency can lead to irreversible deficits in learning and memory. The pig represents a promising model animal for studying such deficits, because of its similarities to humans during early development. We investigated the effects of pre-weaning dietary iron deficiency in piglets on growth, blood parameters, cognitive performance, and brain histology later in life. Four to six days after birth, 10 male sibling pairs of piglets were taken from 10 different sows. One piglet of each pair was given a 200 mg iron dextran injection and fed a control milk diet for 28 days (88 mg Fe/kg), whereas the other sibling was given a saline injection and fed an iron deficient (ID) milk diet (21 mg Fe/kg). Due to severely retarded growth of two of the ID piglets, only eight ID piglets were tested behaviorally. After dietary treatment, all piglets were fed a balanced commercial pig diet (190 - 240 mg Fe/kg). Starting at 7. 5 weeks of age, piglets were tested in a spatial cognitive holeboard task. In this task, 4 of 16 holes contain a hidden food reward, allowing measurement of working (short-term) memory and reference (long-term) memory (RM) simultaneously. All piglets received 40 - 60 acquisition trials, followed by a 16 -trial reversal phase. ID piglets showed permanently retarded growth and a strong decrease in blood iron parameters during dietary treatment. After treatment, ID piglets' blood iron values restored to normal levels. In the holeboard <b>task,</b> <b>ID</b> piglets showed impaired RM learning during acquisition and reversal. Iron staining at necropsy at 12 weeks of age showed that ID piglets had fewer iron-containing cells in hippocampal regions CA 1 and dentate gyrus (DG). The number of iron-containing cells in CA 3 correlated positively with the average RM score during acquisition across all animals. Our results support the hypothesis that early-life iron deficiency leads to lasting cognitive deficits. The piglet as a model animal, tested in the holeboard, can be useful in future research for assessing long-term cognitive effects of early-life diets or diet-induced deficiencies...|$|E
40|$|Purpose – This is {{the second}} part of a two-part paper. The {{purpose of this paper is}} to report the results on the {{application}} of the methods that use the Response Surface Methodology to investigate an evolutionary algorithm (EA) and memory-based approach referred to as McBAR – the Mapping of <b>Task</b> <b>IDs</b> for Centroid-Based Adaptation with Random Immigrants. Design/methodology/approach – The methods applied in this paper are fully explained in the first part. They are utilized to investigate the performances (ability to determine solutions to problems) of techniques composed of McBAR and some EA-based techniques for solving some multi-objective dynamic resource-constrained project scheduling problems with a variable number of tasks. Findings – The main results include the following: first, some algorithmic components of McBAR are legitimate; second, the performance of McBAR is generally superior to those of the other techniques after increase in the number of tasks in each of the above-mentioned problems; and third, McBAR has the most resilient performance among the techniques against changes in the environment that set the problems. Originality/value – This paper is novel for investigating the enumerated results. Manuel Blanco Abello and Zbigniew Michalewic...|$|R
40|$|Changes in {{environment}} {{are common in}} daily activities and can introduce new problems. To be adaptive to these changes, new solutions {{are to be found}} every time change occur. This two-part paper employs a technique called Centroid Based Adaptation (CBA) which utilize centroid of non-dominated solutions found through Multi-objective Optimization with Evolutionary Algorithm (MOEA) from previous environmental change. This centroid will become part of MOEA's initial population to find the solutions for the current change. The first part of our paper deals mainly on the extension of CBA, called Mapping <b>Task</b> <b>IDs</b> for CBA (McBA), to solve problems resulting from time-varying number of tasks. This second part will show the versatility of McBA over a portfolio of algorithms with respect to the degree of changes in environment. This demonstration was accomplished by finding a model relating the degree of changes to the performance of McBA using Nonlinear Principal Component Analysis. From this model, the degree of change at which McBA's performance becomes unacceptable can be found. Results showed that McBA, and its variant called Random McBA, can withstand larger environmental changes than those of other algorithms in the portfolio. Manuel Blanco Abello, Lam Thu Bui and Zbignew Michalewicz[URL]...|$|R
40|$|In resource-constrained project {{scheduling}} (RCPS) problems, ongoing tasks {{are restricted to}} utilizing a fixed number of resources. This paper investigates a dynamic version of the RCPS problem where the number of tasks varies in time. Our previous work investigated a technique called mapping of <b>task</b> <b>IDs</b> for centroid-based approach with random immigrants (McBAR) {{that was used to}} solve the dynamic problem. However, the solution-searching ability of McBAR was investigated over only a few instances of the dynamic problem. As a consequence, {{only a small number of}} characteristics of McBAR, under the dynamics of the RCPS problem, were found. Further, only a few techniques were compared to McBAR with respect to its solution-searching ability for solving the dynamic problem. In this paper, (a) the significance of the subalgorithms of McBAR is investigated by comparing McBAR to several other techniques; and (b) the scope of investigation in the previous work is extended. In particular, McBAR is compared to a technique called, Estimation Distribution Algorithm (EDA). As with McBAR, EDA is applied to solve the dynamic problem, an application that is unique in the literature. Manuel Blanco Abello and Zbigniew Michalewic...|$|R
40|$|Attribution License, which permits {{unrestricted}} use, distribution, {{and reproduction}} in any medium, provided the original work is properly cited. In resource-constrained project scheduling (RCPS) problems, ongoing tasks {{are restricted to}} utilizing a fixed number of resources. This paper investigates a dynamic version of the RCPS problem where the number of tasks varies in time. Our previous work investigated a technique called mapping of <b>task</b> <b>IDs</b> for centroid-based approach with random immigrants (McBAR) {{that was used to}} solve the dynamic problem. However, the solution-searching ability of McBAR was investigated over only a few instances of the dynamic problem. As a consequence, {{only a small number of}} characteristics of McBAR, under the dynamics of the RCPS problem, were found. Further, only a few techniques were compared to McBAR with respect to its solution-searching ability for solving the dynamic problem. In this paper, (a) the significance of the subalgorithms of McBAR is investigated by comparing McBAR to several other techniques; and (b) the scope of investigation in the previous work is extended. In particular, McBAR is compared to a technique called, Estimation Distribution Algorithm (EDA). As with McBAR, EDA is applied to solve the dynamic problem, an application that is unique in the literature. 1...|$|R
5000|$|A Stellar Patrol [...] "Special Assignment <b>Task</b> Force" [...] <b>ID</b> card (about {{the size}} and shape of a credit card). The ID number printed on the card is the {{telephone}} number of MIT's student newspaper, The Tech, which was in the way of a prank by Meretzky.|$|R
50|$|The ALEC Public Safety and Elections Task Force, which {{promoted}} stand your ground gun laws and voter identification requirements, was disbanded in April 2012. Thereafter, the National Center for Public Policy Research announced {{the creation of}} a voter <b>ID</b> <b>task</b> force to replace the one discontinued by ALEC.|$|R
40|$|The {{relative}} {{contributions of}} bottom-up versus top-down sensory inputs to auditory learning {{are not well}} established. In our experiment, listeners were instructed to perform either a frequency discrimination (FD) task (“FD-train group”) or an intensity discrimination (<b>ID)</b> <b>task</b> (“ID-train group”) during training {{on a set of}} physically identical tones that were impossible to discriminate consistently above chance, allowing us to vary top-down attention whilst keeping bottom-up inputs fixed. A third, control group did not receive any training. Only the FD-train group improved on a FD probe following training, whereas all groups improved on ID following training. However, only the ID-train group also showed changes in performance accuracy as a function of interval with training on the <b>ID</b> <b>task.</b> These findings suggest that top-down, dimension-specific attention can direct auditory learning, even when this learning is not reflected in conventional performance measures of threshold change...|$|R
40|$|We {{present the}} preparation, resources, results and {{analysis}} of three tasks of the BioNLP Shared Task 2011 : the main tasks on Infectious Diseases (ID) and Epigenetics and Post-translational Modifications (EPI), and the supporting task on Entity Relations (REL). The two main tasks represent extensions of the event extraction model introduced in the BioNLP Shared Task 2009 (ST' 09) to two new areas of biomedical scientific literature, each motivated by the needs of specific biocuration <b>tasks.</b> The <b>ID</b> <b>task</b> concerns the molecular mechanisms of infection, virulence and resistance, focusing in particular on the functions of a class of signaling systems that are ubiquitous in bacteria. The EPI task {{is dedicated to the}} extraction of statements regarding chemical modifications of DNA and proteins, with particular emphasis on changes relating to the epigenetic control of gene expression. By contrast to these two application-oriented main tasks, the REL task seeks to support extraction in general by separating challenges relating to part-of relations into a subproblem that can be addressed by independent systems. Seven groups participated in each of the two main tasks and four groups in the supporting task. The participating systems indicated advances in the capability of event extraction methods and demonstrated generalization in many aspects: from abstracts to full texts, from previously considered subdomains to new ones, and from the ST' 09 extraction targets to other entities and events. The highest performance achieved in the supporting task REL, 58 % F-score, is broadly comparable with levels reported for other relation extraction <b>tasks.</b> For the <b>ID</b> <b>task,</b> the highest-performing system achieved 56 % F-score, comparable to the state-of-the-art performance at the established ST' 09 task. In the EPI task, the best result was 53 % F-score for the full set of extraction targets and 69 % F-score for a reduced set of core extraction targets, approaching a level of performance sufficient for user-facing applications. In this study, we extend on previously reported results and perform further analyses of the outputs of the participating systems. We place specific emphasis on aspects of system performance relating to real-world applicability, considering alternate evaluation metrics and performing additional manual analysis of system outputs. We further demonstrate that the strengths of extraction systems can be combined to improve on the performance achieved by any system in isolation. The manually annotated corpora, supporting resources, and evaluation tools for all tasks are available from [URL] and the tasks continue as open challenges for all interested parties...|$|R
30|$|The {{second case}} study is a complex DFG which {{contains}} different classical structures (Fork, join, sequential). This DFG is depicted in Figure 12. It contains twenty tasks. Each task can be implemented on the Software computation unit (Master or Slave processor) or on the Reconfigurable RCU. The original DFG is the model of an image processing application: motion detection on a fixed image background. This application is composed of 10 sequential <b>tasks</b> (from <b>ID</b> 1 to ID 10 in Figure 12). We added 10 others virtual tasks to obtain a complex DFG containing the different possible parallel structures. This type of parallel program paradigm (Fork, join, etc.) arises in many application areas.|$|R
40|$|Abstract We {{present the}} preparation, resources, results and {{analysis}} of three tasks of the BioNLP Shared Task 2011 : the main tasks on Infectious Diseases (ID) and Epigenetics and Post-translational Modifications (EPI), and the supporting task on Entity Relations (REL). The two main tasks represent extensions of the event extraction model introduced in the BioNLP Shared Task 2009 (ST' 09) to two new areas of biomedical scientific literature, each motivated by the needs of specific biocuration <b>tasks.</b> The <b>ID</b> <b>task</b> concerns the molecular mechanisms of infection, virulence and resistance, focusing in particular on the functions of a class of signaling systems that are ubiquitous in bacteria. The EPI task {{is dedicated to the}} extraction of statements regarding chemical modifications of DNA and proteins, with particular emphasis on changes relating to the epigenetic control of gene expression. By contrast to these two application-oriented main tasks, the REL task seeks to support extraction in general by separating challenges relating to part-of relations into a subproblem that can be addressed by independent systems. Seven groups participated in each of the two main tasks and four groups in the supporting task. The participating systems indicated advances in the capability of event extraction methods and demonstrated generalization in many aspects: from abstracts to full texts, from previously considered subdomains to new ones, and from the ST' 09 extraction targets to other entities and events. The highest performance achieved in the supporting task REL, 58 % F-score, is broadly comparable with levels reported for other relation extraction <b>tasks.</b> For the <b>ID</b> <b>task,</b> the highest-performing system achieved 56 % F-score, comparable to the state-of-the-art performance at the established ST' 09 task. In the EPI task, the best result was 53 % F-score for the full set of extraction targets and 69 % F-score for a reduced set of core extraction targets, approaching a level of performance sufficient for user-facing applications. In this study, we extend on previously reported results and perform further analyses of the outputs of the participating systems. We place specific emphasis on aspects of system performance relating to real-world applicability, considering alternate evaluation metrics and performing additional manual analysis of system outputs. We further demonstrate that the strengths of extraction systems can be combined to improve on the performance achieved by any system in isolation. The manually annotated corpora, supporting resources, and evaluation tools for all tasks are available from [URL] and the tasks continue as open challenges for all interested parties. </p...|$|R
40|$|Think about a {{time when}} you have {{designed}} something – a computer program, a garden, a class project, etc. Chances are that while you were designing, you followed a series of steps and thought carefully about what you were doing in order to accomplish the <b>task.</b> Instructional design (<b>ID)</b> is very similar since it also involves a systematic set of steps and a reflective process. The biggest difference i...|$|R
40|$|The {{present study}} aimed to {{determine}} whether the general slowing hypothesis could be extended to the motor domain by comparing cognitive and motor age-related slowing. To achieve this objective, we compared the slopes of Hick-Hyman’s law and Fitts’ law, in young and older adults. The general hypothesis was that, due to the dedifferentiation of cognitive and motor neural resources during aging, the slopes of Hick-Hyman&# 39;s law and Fitts’ law should become closer, if not similar, in older adults. Ten young adults (mean age = 26 &# 177; 3 years) and fourteen older adults (mean age = 78 &# 177; 7 years) participated in the experiment. They had to perform a discrete rapid-aiming task and a reaction time task. In the aiming <b>task,</b> five <b>ID</b> levels were used (from 3 to 7 bits by increments of 1. 0 bit). Task difficulty was scaled via the manipulation of target distance from home position. In the reaction time <b>task,</b> 5 <b>IDs</b> were selected: 0, 1, 2, 3 and 4 bits, with incompatible S-R associations. Reaction time and movement times were recorded. Efficiency and Brinley regression functions were calculated. Age-related slowing ratios were estimated. Response times increased in both tasks in older adults. The slopes of Hick-Hyman’s law and Fitts’ law were steeper in older adults than in young participants. In young participants, the slope of Hick-Hyman’s law was smaller than that of Fitts’ law. In older adults, no difference was found. Slowing ratios observed in both tasks were equivalent. The present results extended the general slowing hypothesis to the motor domain. They suggested that, due to dedifferentiation of cognitive and motor neural resources, decrease in processing speed acts as a common cause to behavioral slowing in both cognitive and motor tasks...|$|R
40|$|Some of {{the first}} {{applications}} of ontologies to support elearning were to generalize adaptive in-terfaces. Thus ontologies were used to search and suggest among conceptually structured learning objects. More recently ontologies have been ex-tended to describe pedagogical structures in or-der to base selection on ID principles, and to support course designers in their tasks. But to generalize further, another level of ontology is needed describing applications and the interac-tion between the user and the system, {{the model of the}} interface. This paper presents our work to generalize the ExploraGraph system, in order to offer generic adaptive support. The extraction and specification of formal ontologies for differ-ent models makes it possible to describe axioms and boolean reasoning linking <b>task,</b> user, <b>ID</b> and interactions models, in general terms and for dif-ferent simultaneous applications...|$|R
40|$|To {{investigate}} {{the processing of}} visual form in human cerebral cortex, we used the PET (positron emission tomography) activation technique to compare the human brain regions {{that are involved in}} a visual detection task and two orientation discrimination tasks: the temporal same-different (TSD) task, which includes a short-term memory component, and the identification (<b>ID)</b> <b>task,</b> which is without this component. As a control task we used passive viewing. Stimuli were identical in all four tasks. Subtraction of passive viewing from detection showed that the detection task activates early visual cortical regions (areas 17 / 18) as well as several motor brain regions, while decreasing activity in several higher order frontal, temporal, and parietal regions. Comparing the <b>ID</b> <b>task</b> to the detection task revealed no further visual cortical activation, while comparison of the TSD task to the detection task revealed an activation of several right visual cortical regions, one of which remained significant after the subtraction of ID from TSD (right area 19). These experiments demonstrate the task dependence of visual processing, even for very closely related tasks, and the localization of the temporal comparison component involved in orientation discrimination in human area 19. status: publishe...|$|R
40|$|In 2011, a Researcher <b>ID</b> <b>Task</b> and Finish Group was convened by JISC {{to analyse}} {{the need for}} {{identifiers}} for researchers and to propose a solution for the UK. In their recommendations, the group named the Open Researcher and Contributor Identifier (ORCID) project as the best available fit to the UK HE sector's requirements. As part of a wider consultation process, JISC commissioned a study to undertake a broad, sector-wide validation of the group's recommendations. After reviewing the consultation report, the group has agreed to endorse the following statement...|$|R
40|$|To {{pursue the}} goal of {{developing}} the described system, authors offer a relational database tables’ design and an algorithm for collecting and managing data about electric transport virtual laboratory environment students’ attendance by sections or pages and students’ actual work progress. Upon laboratory task results production or leaving particular section a set of variables is produced, such as student <b>ID,</b> <b>task</b> or section, passed time, task input data and results, and inserted into the specifically designed database. These records are ready for later use to build detailed statistics, charts and run analysis tools...|$|R
