0|10000|Public
50|$|The {{fields that}} are {{generally}} considered <b>the</b> core of <b>theoretical</b> <b>linguistics</b> are phonology, morphology, syntax, and semantics. Although phonetics often guides phonology, {{it is often}} excluded from <b>the</b> purview of <b>theoretical</b> <b>linguistics,</b> along with sociolinguistics. <b>Theoretical</b> <b>linguistics</b> also involves <b>the</b> search for an explanation of linguistic universals, that is, properties that all, or many languages have in common.|$|R
50|$|Generative grammar is a {{linguistic}} theory that regards grammar {{as a system}} of rules that generates exactly those combinations of words that form grammatical sentences in a given language. Noam Chomsky first used the term in relation to <b>the</b> <b>theoretical</b> <b>linguistics</b> of grammar that he developed in the late 1950s. Linguists who follow the generative approach have been called generativists. The generative school {{has focused on the}} study of syntax, but has also addressed other aspects of a language's structure, including morphology and phonology.|$|R
50|$|Manfred Krifka (born 1956) is {{director}} of the Center for General Linguistics (Zentrum für Allgemeine Sprachwissenschaft, ZAS) in Berlin, a professor at the Humboldt University of Berlin, and editor of <b>the</b> academic journal <b>Theoretical</b> <b>Linguistics.</b>|$|R
50|$|The Research Institute for Linguistics of the Hungarian Academy of Sciences (Magyar Tudományos Akadémia Nyelvtudományi Intézete) {{was created}} in 1949, is under {{supervision}} of the Hungarian Academy of Sciences since 1951. Its primary tasks include research in Hungarian <b>linguistics,</b> general, <b>theoretical</b> and applied <b>linguistics,</b> Uralic linguistics, and phonetics, {{as well as the}} preparation of a comprehensive dictionary of the Hungarian language, and the maintenance of its archive materials. Other research projects investigate various aspects and different variants of Hungarian. Further tasks include the assembly of linguistic corpora and databases, and laying the linguistic groundwork for computational software and applications. The Institute also operates a public advice service on language and linguistics, prepares expert reports on relevant affairs on demand, and runs <b>the</b> <b>Theoretical</b> <b>Linguistics</b> Undergraduate and Doctoral Program jointly with Eötvös Loránd University.|$|R
50|$|Language is a peer-reviewed {{quarterly}} academic journal {{published by}} the Linguistic Society of America since 1925. It covers all aspects of linguistics, focusing on <b>the</b> area of <b>theoretical</b> <b>linguistics.</b> Its current editor-in-chief is Andries Coetzee (University of Michigan).|$|R
40|$|Luigi Rizzi {{has contributed}} {{significantly}} {{not only to}} <b>the</b> study of <b>theoretical</b> <b>linguistics,</b> but also to establishing robust relations between linguistic theory and psycholinguistic and neurolinguistic phenomena, and to demonstrating the importance of linguistic theory {{as the basis for}} psych- and neuro-linguistic research. One of <b>the</b> main <b>theoretical</b> domain...|$|R
5000|$|Situation semantics, {{pioneered by}} Jon Barwise and John Perry {{in the early}} 1980s, {{attempts}} to provide a solid theoretical foundation for reasoning about common-sense and real world situations, typically in <b>the</b> context of <b>theoretical</b> <b>linguistics,</b> philosophy, or applied natural language processing, ...|$|R
40|$|This paper {{shows that}} {{incorporating}} linguistically motivated features to ensure correct animacy and number agreement in an averaged perceptron ranking model for CCG realization helps improve a state-ofthe-art baseline even further. Traditionally, these features have been modelled using hard constraints in the grammar. However, given the graded nature of grammaticality judgements {{in the case}} of animacy we argue a case for the use of a statistical model to rank competing preferences. Though subject-verb agreement is generally viewed to be syntactic in nature, a perusal of relevant examples discussed in <b>the</b> <b>theoretical</b> <b>linguistics</b> literature (Kathol, 1999; Pollard and Sag, 1994) points toward the heterogeneous nature of English agreement. Compared to writing grammar rules, our method is more robust and allows incorporating information from diverse sources in realization. We also show that the perceptron model can reduce balanced punctuation errors that would otherwise require a post-filter. The full model yields significant improvements in BLEU scores on Section 23 of the CCGbank and makes many fewer agreement errors. ...|$|R
50|$|Constantin George Sandulescu (born 11 February 1933) is a Joycean scholar, but in {{the first}} place, he is a {{linguist}} with twelve years' experience in <b>the</b> Department of <b>Theoretical</b> <b>Linguistics</b> of <b>the</b> University of Stockholm in the 1970s and 1980s, specializing in Discourse Analysis. In that capacity he read {{a dozen or so}} papers at various international congresses (see texts below).|$|R
5000|$|Dirk Geeraerts (born 24 October 1955, PhD 1981) holds <b>the</b> {{chair of}} <b>theoretical</b> <b>linguistics</b> at <b>the</b> University of Leuven, Belgium. He {{is the founder}} of the {{research}} unit Quantitative Lexicology and Variational Linguistics (QLVL). [...] His main research interests involve the overlapping fields of lexical semantics, lexicology, and lexicography, with a theoretical focus on cognitive semantics. His publications include the following monographs: ...|$|R
30|$|To {{the best}} of my knowledge, not much {{research}} has been done to examine and explain the various interpretations of hai in <b>the</b> <b>theoretical</b> <b>linguistics</b> literature. In this section, I review one of the previous analyses. Liu (2000) adopts the scalar model proposed by Fillmore et al. (1988) to account for the semantics of hai (also see Kay 1990). Different from Krifka (1999), who takes the focused denotation and alternatives to be ordered along the scale of likeliness, the scale model ranks them in terms of informativeness. Along this line, Liu proposes that hai is a scalar particle with the meaning of persistence (also see Michaelis 1993), ranking two propositions. One refers to the proposition uttered with hai, which is called the text proposition (tp). The other one, known as the context proposition (cp), is the proposition already presented in the context. As a scalar particle, hai specifically requires tp to be ranked higher than cp in the scale model. The more informative proposition entails, the less informative one, so tp should entail cp.|$|R
40|$|The series Trends in Applied Linguistics {{meets the}} {{challenges}} of the rapidly growing field of applied linguistics. In a very broad sense, applied linguistics is understood by focusing on <b>the</b> application of <b>theoretical</b> <b>linguistics</b> to current problems arising in different contexts of human society. Given the interdisciplinary character of applied linguistics, the series includes cognitive, psycholinguistic, sociolinguistic and educational perspectives. The following topics are included in the series: Second language acquisition and the acquisition of additional languages Bilingual and multiling...|$|R
40|$|Verb Phrase Ellipsis (VPE) {{has been}} studied in great depth in <b>theoretical</b> <b>linguistics,</b> but {{empirical}} studies of VPE are rare. We extend the few previous corpus studies with an annotated corpus of VPE in all 25 sections of the Wall Street Journal corpus (WSJ) distributed with the Penn Treebank. We annotated the raw files using a stand-off annotation scheme that codes the auxiliary verb triggering the elided verb phrase, the start {{and end of the}} antecedent, the syntactic type of antecedent (VP, TV, NP, PP or AP), and the type of syntactic pattern between the source and target clauses of the VPE and its antecedent. We found 487 instances of VPE (including predicative ellipsis, antecedent-contained deletion, comparative constructions, and pseudo-gapping) plus 67 cases of related phenomena such as do so anaphora. Inter-annotator agreement was high, with a 0. 97 average F-score for three annotators for one section of the WSJ. Our annotation is theory neutral, and has better coverage than earlier efforts that relied on automatic methods, e. g. simply searching the parsed version of the Penn Treebank for empty VP's achieves a high precision (0. 95) but low recall (0. 58) when compared with our manual annotation. The distribution of VPE source-target patterns deviates highly from the standard examples found in <b>the</b> <b>theoretical</b> <b>linguistics</b> literature on VPE, once more underlining the value of corpus studies. The resulting corpus will be useful for studying VPE phenomena as well as for evaluating natural language processing systems equipped with ellipsis resolution algorithms, and we propose evaluation measures for VPE detection and VPE antecedent selection. The stand-off annotation is freely available for research purposes...|$|R
40|$|AAC English-speakers {{using an}} {{engineered}} word user-interface Speech errors among native speakers {{of a language}} can reflect the internal phonological or morphological structure of the linguistic unit of word. But what about speakers who produce language using an engineered structural unit of ‘word’? In this paper we present data on the speaking errors made by such a population, and show how they are organized around an artificial morphological structure. Users of Augmentative and Alternative Communication (AAC) devices present a population of language users with normal grammatical competence, but with an artificially engineered ‘phonetic’ representation for the motor production of a word. These are persons with a severe physical disability such as cerebral palsy, which does not hinder their comprehension of spoken English, but compels them to produce speech using a keyboard (user interface with icons) and voice synthesizer. They may interact with the keyboard using a finger, head-pointer, or other method. To {{the best of our}} knowledge, the language of AAC users has not been discussed in <b>the</b> <b>theoretical</b> <b>linguistics</b> literature, although some research is available in the speech pathology literature (Binger and Light 2008). In this paper we present data from interviews with 20 adult English-speaking AAC users of normal intelligence and education, who are using a keyboard language representation system that incorporates a full grammar (Minspeak). (Fig. 1 shows a...|$|R
50|$|Historical {{languages}} (also {{known as}} historic languages) are languages that were spoken {{in a historical}} period, but that are distinct from their modern form; that is, they are forms of languages historically attested to from the past which have evolved into more modern forms. Thus, historical languages contrast with dead languages (languages which have become extinct, or undergone language death). Also, historical languages contrast with reconstructed languages (that is, <b>the</b> proto-languages) of <b>theoretical</b> <b>linguistics.</b> One of <b>the</b> approaches to defining and using the concept of historical languages is implemented in the ISO 639 standards.|$|R
50|$|Since 1998, she has {{directed}} major collaborative research projects {{funded by the}} Social Sciences and Humanities Research Council of Canada and by the Fonds de recherche du Québec. She has received numerous research awards, among which the Research Award of the Board of Directors of the University of Quebec in 2001. In 2004 she founded the Federation on Natural Language Processing, bringing together the main actors in <b>the</b> area of <b>theoretical</b> <b>linguistics,</b> computational linguistics and information technology, and in 2007 she founded the International Network on Biolinguistics, bridging biology, linguistics and bioinformatics.|$|R
40|$|<b>Theoretical</b> <b>{{linguistics}}</b> and corpus linguistics Corpus analyses {{have had}} a considerable influence on the ways linguists think about language data {{and the way in}} which they view language in use. In this paper we explore <b>the</b> relation between <b>theoretical</b> <b>linguistics</b> and corpus linguistics. The main contributions of corpus analyses are: (i) highlighting the pervasiveness and the range of functions of collocations and other syntagmatic units with a lexical component; (ii) the provision of frequency information; and (iii) quantifying the extent of variability in language. We will explore <b>the</b> <b>theoretical</b> consequences of these findings, exploring the role of frequency information in particular. <b>The</b> principal <b>theoretical</b> contribution of corpus linguistics within what we might loosely call the British tradition has been the elaboration of phraseology as an important component of grammar. Associated with the detailing of the work at the phraseological level has been the highlighting of the extent of the formulaic or collocational component of language. One important strand of this work can be traced from Firth (1957) to Sinclair (1991) and Hunston and Francis (2000). In Ver...|$|R
50|$|His main {{academic}} {{interests are}} proper names (both from {{the historical and}} <b>the</b> <b>theoretical</b> perspective), historical <b>linguistics</b> in general, the philology of the Germanic, Romance and Celtic languages, regional variation in language, and local history. He {{is editor of the}} Survey of English Place-Names for Hampshire and principal investigator of the AHRC-funded project Family Names of the United Kingdom (FaNUK), running from 2010-16, of which Patrick Hanks is lead researcher.|$|R
40|$|In this paper, {{we present}} an {{analysis}} of nominal anaphora along with a probabilistic model of nominal anaphora resolution. Throughout this work we focus on non-pronominal anaphora. The goal of this work is to present a viable probabilistic model {{that is consistent with}} <b>the</b> ideas of <b>theoretical</b> <b>linguistics</b> and <b>the</b> results of experimental psycholinguistics. Where applicable, we present research which motivated the model derivation. This work differs from previous work in that it is completely statistical and isolates the task of non-pronominal noun-phrase coreference. Finally, we present the experimental results of an implementation of the proposed probabilistic model. ...|$|R
40|$|Koro is an {{endangered}} Tibeto-Burman {{language of the}} Sino-Tibetan Family, spoken by a few hundred speakers in Arunachal Pradesh, India. This thesis builds on the fieldwork of the Living Tongues/Enduring Voices team by using their data to begin to describe the sound system of Koro. A phonetic inventory of the language is proposed, and possible features such as tone and vowel length are discussed. A description of the syllable structure of Koro is also included. The goal of this project is {{to lay the groundwork}} for future research on Koro, both for <b>the</b> benefit of <b>theoretical</b> <b>linguistics</b> as well as for the benefit of Koro-Ianguage preservation, education, and vitalization efforts...|$|R
40|$|Chomsky’s {{principle}} of epistemological tolerance {{says that in}} <b>theoretical</b> <b>linguistics</b> contradictions between <b>the</b> data and the hypotheses may be temporarily tolerated {{in order to protect}} the explanatory power of the theory. The paper raises the following problem: What kinds of contradictions may be tolerated between the data and <b>the</b> hypotheses in <b>theoretical</b> <b>linguistics?</b> First a model of paraconsistent logic is introduced which differentiates between week and strong contradiction. As a second step, a case study is carried out which exemplifies that the {{principle of}} epistemological tolerance may be interpreted as the tolerance of week contradiction. The third step of the argumentation focuses on another case study which exemplifies that the principle of epistemological tolerance must not be interpreted as the tolerance of strong contradiction. The reason for the latter insight is the unreliability and the uncertainty of introspective data. From this finding the author draws the conclusion that it is the integration of different data types that may lead to the improvement of current <b>theoretical</b> <b>linguistics</b> and that <b>the</b> integration of different data types requires a novel methodology which, for the time being, is not available...|$|R
40|$|The goal of {{this article}} is to {{familiarize}} the reader who has background in <b>theoretical</b> <b>linguistics</b> with some of the recent research in aphasiology. Needless to say, it is far beyond the space limitation, and my capacity, to present all work carried out in the field of language impairment, even during the last decade. My goal is more modest: I will attempt to demonstrate how <b>the</b> interaction of <b>theoretical</b> <b>linguistics</b> and aphasiology can inform both disciplines; what impact the development of linguistics as a field has had on our understanding of language breakdown, and how studies of aphasia can be beneficial for our understanding of the human unimpaired linguistic capacity. In this article therefore I will focus, primarily, on the psycholinguistic research that approached investigation of aphasia from a linguistic, theory-based perspective. It is my hope that the results presented below will further encourage linguists to view aphasiology as an important source for our understanding of the human linguistic capacity, and that aphasiologists will be further inspired to view <b>theoretical</b> <b>linguistics</b> as an important, if not necessary, tool for obtaining a better picture of language impairment...|$|R
40|$|This paper {{tries to}} {{construct}} a bridge between <b>the</b> concerns of <b>theoretical</b> <b>linguistics</b> and those of multilingualism and code-switching (CS) research. It argues that the primary special point of interaction between these fields lies in the question of potential equivalence between elements or categories, bridging across languages. After giving an overview of some major findings in recent CS research, these findings are interpreted in a constraint- or strategy-based framework. Then I explore the notion of categorical equivalence, starting with the observation that the insertion of single functional categories is highly restricted in CS contexts. Subsequently a number of concrete questions are formulated for research in this domain based on available data for Afrikaans-English and isiXhosa-English CS...|$|R
40|$|In 1959, Lucien Tesnière {{wrote his}} main work Éléments de syntaxe structurale. While <b>the</b> impact on <b>theoretical</b> <b>{{linguistic}}s</b> {{was not very}} strong at first, 50 years later there exist a variety of linguistic theories based on Tesnière's work. In computational <b>linguistics,</b> as in <b>theoretical</b> <b>linguistics,</b> dependency grammar was not very influential at first. The last 10 – 15 years, however, have brought a noticeable change and dependency grammar has {{found its way into}} computational linguistics. Syntactically annotated corpora based on dependency representations are available for a variety of languages, as well as statistical parsers which give a syntactic analysis of running text describing the underlying dependency relations between word tokens in the text. This article gives an overview of relevant areas of computational linguistics which have been influenced by dependency grammar. It discusses {{the pros and cons of}} different types of syntactic representation used in natural language processing and their suitability as representations of meaning. Finally, an attempt is made to give an outlook on the future impact of dependency grammar on computational linguistics...|$|R
40|$|This paper {{deals with}} the {{annotation}} of Sentence Topics/Aboutness Topics in naturally occurring data. We report on a corpus study in which relatively poor inter-rater agreement was attained for the annotation of topics, although both coders were adhering to the same annotation instructions. Tokens that were particularly difficult to assess are identified, systematized, and discussed in some detail. In sum, the cases that {{are most likely to}} lead to non-matching annotations are those that either require a decision between “thetic ” or “topic-comment”, or involve an overlap between Focus and Topic. The findings raise a number of issues that may contribute to <b>the</b> discussion in <b>theoretical</b> <b>linguistics,</b> and they also may alert other researchers planning a similar enterprise to some pitfalls they may encounter. ...|$|R
40|$|This article {{illustrates}} {{the search for}} a theory of second language acquisition. It is the task of the applied linguist to investigate any discipline which can shed light on this problem. The article investigates <b>the</b> field of <b>theoretical</b> <b>linguistics,</b> in particular Chomsky 's Universal Grammar, fUnctional linguistics, and cognitive learning theory for answers {{to the question of how}} a second language is acquired. Hierdie anikel illustreer die soeke na 'n teorie van tweedetaalverwerwing. Dit is die taak van die toegepaste linguis om enige dissipline te ondersoek wat lig op hierdie probleem kan werp. Daar word gekyk na die teoretiese linguistiek, en veral na Chomsky se Universele Grammatika, die fonksionele linguistiek, en kognitiewe leerteorie vir antwoorde op die vraag hoe 'n tweede taal verwerjword...|$|R
40|$|This {{dissertation}} {{provides a}} psycholinguistic {{investigation of the}} influence of discourse on language comprehension. It examines factors that allow comprehenders to follow a discourse, to form representations of the events being described, and to make predictions about how subsequent utterances will relate to prior linguistic material. Previous work has recognized the importance of prediction in sentence-internal processing: transition probabilities at the phonemic level, semantic associations in lexical access, and structural frequencies at the syntactic level. The work presented here investigates whether learnable statistical regularities also exist at the discourse level, a topic that has remained largely unexplored in the psycholinguistics literature. The dissertation presents a series of experiments testing the extent to which comprehenders use various pragmatic cues to make predictions about how a discourse will be continued. In order to quantify discourse-level information, the experiments use an inventory of coherence relations adopted from <b>the</b> <b>theoretical</b> <b>linguistics</b> and artificial intelligence literatures. The experimental results demonstrate that comprehenders do indeed make use of available pragmatic cues to generate expectations about upcoming coherence relations. Furthermore, the results show that the mechanisms for establishing coherence relations can inform our understanding of two well studied sentence-internal phenomena: coreference and syntactic ambiguity. The online results establish the importance of these pragmatic cues in comprehenders incremental sentence processing. The coherence-based approach taken here provides a lens through which to view previous results in the domains of both coreference and syntactic ambiguity. The fact that phenomena in both these domains appear to be sensitive to coherence-driven biases suggests that these biases may be more pervasive than has been previously acknowledged. This work indicates that future processing models of sentence and discourse processing must take into account effects that emerge from discourse coherenc...|$|R
40|$|A general {{introduction}} to <b>the</b> area of <b>theoretical</b> <b>linguistics</b> known as cognitive linguistics, this textbook provides up-to-date coverage of {{all areas of}} the field, including recent developments within cognitive semantics (such as Primary Metaphor Theory, Conceptual Blending Theory, and Principled Polysemy), and cognitive approaches to grammar (such as Radical Construction Grammar and Embodied Construction Grammar). The authors offer clear critical evaluations of competing formal approaches within <b>theoretical</b> <b>linguistics.</b> For example, cognitive linguistics is compared to Generative Grammar and Relevance Theory. In the selection of material and in the presentations the authors have aimed for a balanced perspective. Part II, Cognitive Semantics, and Part III, Cognitive Approaches to Grammar, have been created to be read independently. The authors have kept in mind that different instructors and readers will need to use the book in different ways tailored to their own goals. The coverage is suitable for a number of courses. While all topics are presented in terms accessible to both undergraduate and graduate students of linguistics, cognitive linguistics, psycholinguistics, cognitive science, and modern languages, this work is sufficiently comprehensive and detailed to serve as a reference work for scholars who wish {{to gain a better understanding}} of cognitive linguistics...|$|R
40|$|Institute for Communicating and Collaborative SystemsThis thesis {{investigates the}} mental {{representation}} of syntactic structure. It takes an interdisciplinary approach which exploits methods and insights from both experimental psychology and <b>theoretical</b> <b>linguistics</b> to explore <b>the</b> claim that syntactic representation {{can be the}} subject of empirical psychological study. The thesis makes use of corpus analysis and two experimental methods, agreement error elicitation and syntactic priming, to examine syntactic structure in both language production and language comprehension. I argue that assumptions about syntactic representation are fundamental to all models of language processing. However, processing models have largely assumed the representations proposed by <b>theoretical</b> linguists in <b>the</b> belief that that syntactic representation is <b>the</b> province of <b>theoretical</b> <b>linguistics.</b> I propose that the mental representation of syntactic structure is a legitimate area of study for psycholinguists and that it can be investigated using experimental methods. The remainder of this thesis presents empirical evidence to support this claim. The main conclusion of this thesis is that syntactic representation is amenable to psychological study. The evidence which is gathered in this way is in principle relevant not only to theories of language processing but also to any linguistic theory which claims to characterise knowledge of language...|$|R
40|$|Zipf’s law {{seems to}} be {{ubiquitous}} in human languages {{and appears to be}} a universal property of complex communicating systems. Following the early proposal made by Zipf concerning the presence of a tension between the efforts of speaker and hearer in a communication system, we introduce evolution by means of a variational approach to the problem based on Kullback’s Minimum Discrimination of Information Principle. Therefore, using a formalism fully embedded in the framework of information theory, we demonstrate that Zipf’s law is the only expected outcome of an evolving communicative system under a rigorous definition of the communicative tension described by Zipf. This work has been supported by NWO research project Dependency in Universal Grammar, <b>the</b> Spanish MCIN <b>Theoretical</b> <b>Linguistics</b> 2009 SGR 1079 (JF), the James S. McDonnell Foundation (BCM), and by the Santa Fe Institute (RS) ...|$|R
40|$|<b>The</b> {{field of}} <b>theoretical</b> <b>linguistics</b> is broad and diversified but a {{direction}} is developing {{which seems to}} affiliate with a more ‘Bakhtinian’ view on language, mainly because of its interest in notions Bakhtin caught under the concept of ‘otherness’. After briefly sketching some main oppositions within current linguistic thinking, I identify the approaches with which a meaningful discourse with the Bakhtinian view on language could be opened. I then turn to two topical theories of grammar and apply the notions of ‘intentionality’ and ‘thematisation’ to the models the theories propose. I will conclude that the Bakhtinian approach to language may help us to understand these models and the differences between them in a more profound way. A second conclusion I will draw is that they might help us to bring the related Bakhtinian notions into perspective and make them more concrete. status: publishe...|$|R
50|$|The early {{accounts}} of agrammatism involved cases of German and French participants. The greater {{sophistication of the}} German school of aphasiology {{at the turn of}} the 20th century and also the fact that both German and French are highly inflected languages, might have been triggers for that situation (Code, 1991). Nowadays, the image has slightly changed: grammatical impairment has been found to be selective rather than complete, and a cross-linguistic perspective under the framework of Universal Grammar (UG) together with a shift from morphosyntax to morphosemantics is à la page. Now the focus of study in agrammatism embraces all natural languages and the idiosyncrasies scholars think a specific language has are put in relation to other languages so as to better understand agrammatism, help its treatment, and review and advance in <b>the</b> field of <b>theoretical</b> <b>linguistics.</b>|$|R
40|$|Grammar {{is central}} to {{language}} description and a posteriori construct vali-dation of language tests consistently identifies grammar as {{a significant factor in}} differentiating between score levels and characterizing overall proficiency. However, there is currently no model of grammatical compe-tence robust enough to be operationalized in tests. Critical to describing grammatical competence is complexity of form and structure, yet grammat-ical complexity is poorly defined in linguistics and its sub-disciplines, including language assessment. This article argues that the inherent subjec-tiveness of complexity can be much reduced by a research methodology that combines input from corpora with expert intuition of the linguistic status of the grammatical items retrieved. The significance of the discussion is that, in addition to contributing to the on-going process of construct validity, a corpus-informed study of complexity has the potential to reconcile <b>the</b> ten-sion in <b>theoretical</b> <b>linguistics</b> between grammar as being sentence-bound and grammar as discourse. ...|$|R
2500|$|In 1945, Chomsky, aged 16, {{embarked}} on a general program of study at the University of Pennsylvania, where he explored philosophy, logic, and languages and developed a primary interest in learning Arabic. Living at home, he funded his undergraduate degree by teaching Hebrew. However, he was frustrated with his experiences at the university, and considered dropping out and moving to a kibbutz in Mandatory Palestine. His intellectual curiosity was reawakened through conversations with the Russian-born linguist Zellig Harris, whom he first met in a political circle in 1947. Harris introduced Chomsky to <b>the</b> field of <b>theoretical</b> <b>linguistics</b> and convinced him to major in the subject. Chomsky's B.A. honors thesis was titled [...] "Morphophonemics of Modern Hebrew", and involved his applying Harris's methods to the language. Chomsky revised this thesis for his M.A., which he received at Penn in 1951; it would subsequently be published as a book. He also developed his interest in philosophy while at university, in particular {{under the tutelage of}} his teacher Nelson Goodman.|$|R
40|$|Abstract: The article {{proposes a}} reinterpreted model of Proto-Indo-European consonantism that differs {{considerably}} {{from the traditional}} one. In {{the light of the}} proposed model of Proto-Indo-European the basic “Phonetic Laws ” of Classical I. -E. Comparative Linguistics receive a totally different meaning. All this may be viewed as a New Paradigm in Comparative I. -E. Comparative Linguistics. The last decades of the previous century were marked in <b>the</b> development of <b>theoretical</b> <b>linguistics</b> by enhanced interest in diachronic linguistic studies, in Historical-Comparative Linguistics in general, and by a return to the traditional problems of nineteenth-century Comparative Indo-European Studies. This growing concern with problems of Diachronic Linguistics derives from the general development of linguistic thought over the past decades. Overcoming the Saussurean antinomy between synchronic and diachronic linguistics, it strives to build a linguistic theory that would have more explanatory power than purely synchronic theories of taxonomic grammar built strictly on the basis of empirical linguistic data. The ultimate goal of Diachronic Linguistics is the reconstruction of early linguisti...|$|R
5000|$|In 1945, Chomsky, aged 16, {{embarked}} on a general program of study at the University of Pennsylvania, where he explored philosophy, logic, and languages and developed a primary interest in learning Arabic. Living at home, he funded his undergraduate degree by teaching Hebrew. However, he was frustrated with his experiences at the university, and considered dropping out and moving to a kibbutz in Mandatory Palestine. His intellectual curiosity was reawakened through conversations with the Russian-born linguist Zellig Harris, whom he first met in a political circle in 1947. Harris introduced Chomsky to <b>the</b> field of <b>theoretical</b> <b>linguistics</b> and convinced him to major in the subject. Chomsky's B.A. honors thesis was titled [...] "Morphophonemics of Modern Hebrew", and involved his applying Harris's methods to the language. Chomsky revised this thesis for his M.A., which he received at Penn in 1951; it would subsequently be published as a book. He also developed his interest in philosophy while at university, in particular {{under the tutelage of}} his teacher Nelson Goodman.|$|R
