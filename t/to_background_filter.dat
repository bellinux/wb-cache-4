0|10000|Public
40|$|Nowadays, large {{databases}} of ornaments of the hand-press period {{are available}} and need efficient retrieval tools for history specialists and general users. This article deals with document images analysis. The purpose of our work is to automatically determine the letter represented in an ornamental letter image. Our process {{is divided into two}} parts: Wavelet transformation: Segmentation of the ornamental letter followed by a recognition step. The segmentation process uses multi-resolution analysis <b>to</b> <b>filter</b> <b>background</b> decorations followed by binarisation and morphologic reconstruction of the expected letter...|$|R
40|$|This article {{describes}} a new method for ancient books ornamental letters segmentation and recognition. The {{purpose of our}} work is to automatically determine the letter represented in an ornamental letter image. Our process is divided in two parts: a segmentation step of the ornamental letter {{is followed by a}} recognition step. The segmentation process uses multiresolution analysis <b>to</b> <b>filter</b> <b>background</b> decorations followed by a binarisation step and a morphologic reconstruction of the expected letter. The recognition process use the previously obtained reconstruction and compares it with capital letters images used as a dictionary of shapes with the Local Dissimilarity Map (LDM) distance. ...|$|R
40|$|In {{this paper}} we {{consider}} data on underwater sounds of differing types. Our objective is <b>to</b> <b>filter</b> <b>background</b> noise and achieve {{an acceptable level}} of reduction in the raw data, whilst {{at the same time}} maintaining the main features of the original signal. In particular, we consider data compression through the use of wavelet analysis followed by a thresholding of small coefficients in the resulting multiresolution decomposition. Various methods to threshold the wavelet representation are discussed and compared using recordings of dolphin sounds. An empirical modification to one of them is also proposed which shows promise in better preserving certain structures in our particular sound data...|$|R
30|$|The aim here is {{to connect}} {{multilevel}} explanations from perceptual organization with global and local percept, <b>to</b> the <b>background</b> low-level <b>filtering</b> explanations. There is a similar connection of low-level retinal/cortical processing to high-level Gestalt grouping principles stated by other researchers in the field. For instance, Craft et al. [90] propose a neural mechanism of ‘figure–ground organization’ based on border ownership to model complex cells in the primary visual cortex (V 1). In their investigation of grouping cell connections, they linked their findings to Gestalt grouping principles such as ‘connectivity’, and ‘convexity’ by applying connection weights based on different sizes of receptive fields in the cortex which was modelled based on multiscale and orientated DoG filters. Similarly, Roelfsema’s [91] findings {{in the perception of}} ‘pathfinder’ suggest that the Gestalt principle of ‘good continuation’ can be understood in terms of the anatomical and functional structure of the visual cortex.|$|R
40|$|Abstract—Moving object {{detection}} is {{very important}} for video surveillance. In this paper, we present a new real time motion detection algorithm that is based on the integration of accumulative optical flow and double <b>background</b> <b>filtering</b> method (long-term <b>background</b> and short-term <b>background)</b> <b>to</b> achieve better performance. The accumulative optical flow method is used to obtain and keep a stable <b>background</b> image <b>to</b> cope with variations on environmental changing conditions and the double <b>background</b> <b>filtering</b> method is used <b>to</b> eliminate the <b>background</b> information and separate the moving object from it. The biggest advantage of this algorithm {{is that it does not}} need <b>to</b> learn the <b>background</b> model from hundreds of images and can handle quick image variations without prior knowledge about the object size and shape. The algorithm has high capability of anti-interference and preserves high accurate rate detection at the same time. The effectiveness of the proposed algorithm for motion detection is demonstrated in a simulation environment and the evaluation results are reported in this paper. Index Terms—Background filtering, motion detection, optical flow, region-based matching. I...|$|R
40|$|The two-path {{algorithm}} {{is a well-known}} approach for overcoming the dead-lock problem in echo cancellation systems. Typically, a fixed foreground filter is producing the echo cancelled output while a continuously updating <b>background</b> <b>filter</b> adapts <b>to</b> the echo-path. When the <b>background</b> <b>filter</b> is considered <b>to</b> perform better than the foreground filter, the coefficients of the <b>background</b> <b>filter</b> are copied into the foreground filter. To determine which filter is better adjusted to the true echo-path, a filter deviation measure can be used. Recently, a method which introduces a delay in the calculation of the filter deviation measure, yielding a more reliable estimate has been proposed. However, a thorough evaluation {{of the effect of}} different delay settings has not yet been performed. Thus, in this paper a number of simulations with different delay parameter settings are carried out to show how this parameter affects the overall performance of the filter deviation measure...|$|R
40|$|Colour {{classification}} vision systems face difficulty when a scene contains {{both very}} bright and dark regions. An indistinguishable colour at one exposure may be distinguishable at another. The {{use of multiple}} cameras with varying levels of sensitivity is explored in this thesis, aiding the classification of colours in scenes with high illumination ranges. Titled the Multiple Image Dynamic Exposure Colour Classification (MIDECC) System, pie-slice classifiers are optimised for normalised red/green and cyan/magenta colour spaces. The MIDECC system finds a limited section of hyperspace for each classifier, resulting in a process which requires minimal manual input with the ability <b>to</b> <b>filter</b> <b>background</b> samples without specialised training. In experimental implementation, automatic multiple-camera exposure, data sampling, training and colour space evaluation to recognise 8 target colours across 14 different lighting scenarios is processed in approximately 30 seconds. The system provides computationally effective training and classification, outputting an overall true positive score of 92. 4 % with an illumination range between bright and dim regions of 880 lux. False positive classifications are minimised to 4. 24 %, assisted by heuristic <b>background</b> <b>filtering.</b> The limited search space classifiers and layout of the colour spaces ensures the MIDECC system {{is less likely to}} classify dissimilar colours, requiring a certain ‘confidence’ level before a match is outputted. Unfortunately the system struggles to classify colours under extremely bright illumination due to the simplistic classification building technique. Results are compared to the common machine learning algorithms Naïve Bayes, Neural Networks, Random Tree and C 4. 5 Tree Classifiers. These algorithms return greater than 98. 5 % true positives and less than 1. 53 % false positives, with Random Tree and Naïve Bayes providing the best and worst comparable algorithms, respectively. Although resulting in a lower classification rate, the MIDECC system trains with minimal user input, ignores background and untrained samples when classifying and trains faster than most of the studied machine learning algorithms. Colour classification vision systems face difficulty when a scene contains both very bright and dark regions. An indistinguishable colour at one exposure may be distinguishable at another. The use of multiple cameras with varying levels of sensitivity is explored in this thesis, aiding the classification of colours in scenes with high illumination ranges. Titled the Multiple Image Dynamic Exposure Colour Classification (MIDECC) System, pie-slice classifiers are optimised for normalised red/green and cyan/magenta colour spaces. The MIDECC system finds a limited section of hyperspace for each classifier, resulting in a process which requires minimal manual input with the ability <b>to</b> <b>filter</b> <b>background</b> samples without specialised training. In experimental implementation, automatic multiple-camera exposure, data sampling, training and colour space evaluation to recognise 8 target colours across 14 different lighting scenarios is processed in approximately 30 seconds. The system provides computationally effective training and classification, outputting an overall true positive score of 92. 4 % with an illumination range between bright and dim regions of 880 lux. False positive classifications are minimised to 4. 24 %, assisted by heuristic <b>background</b> <b>filtering.</b> The limited search space classifiers and layout of the colour spaces ensures the MIDECC system is less likely to classify dissimilar colours, requiring a certain ‘confidence’ level before a match is outputted. Unfortunately the system struggles to classify colours under extremely bright illumination due to the simplistic classification building technique. Results are compared to the common machine learning algorithms Naïve Bayes, Neural Networks, Random Tree and C 4. 5 Tree Classifiers. These algorithms return greater than 98. 5 % true positives and less than 1. 53 % false positives, with Random Tree and Naïve Bayes providing the best and worst comparable algorithms, respectively. Although resulting in a lower classification rate, the MIDECC system trains with minimal user input, ignores background and untrained samples when classifying and trains faster than most of the studied machine learning algorithms...|$|R
3000|$|The {{pipeline}} takes a video feed as an input, subtracts the <b>background,</b> <b>filters</b> each {{frame for}} noise and artifacts, and outputs {{the moving parts}} as binary blobs of pixels. Figure  2 illustrates this process. The following is {{a description of the}} individual steps: [...]...|$|R
40|$|Untargeted {{metabolomics}} aims at obtaining {{quantitative information}} on the highest possible number of low-molecular biomolecules present in a biological sample. Rather small changes in mass spectrometric spectrum acquisition parameters may have a significant influence on the detectabilities of metabolites in untargeted global-scale studies by means of high-performance liquid chromatography-mass spectrometry (HPLC-MS). Employing whole cell lysates of human renal proximal tubule cells, we present a systematic global-scale study {{of the influence of}} mass spectrometric scan parameters and post-acquisition data treatment on the number and intensity of metabolites detectable in whole cell lysates. Ion transmission and ion collection efficiencies in an Orbitrap-based mass spectrometer basically depend on the m/z range scanned, which, ideally, requires different instrument settings for the respective mass ranges investigated. Therefore, we split a full scan range of m/z 50 - 1000 relevant for metabolites into two separate segments (m/z 50 - 200 and m/z 200 - 1, 000), allowing an independent tuning of the ion transmission parameters for both mass ranges. Three different implementations, involving either scanning from m/z 50 - 1000 in a single scan, or scanning from m/z 50 - 200 and from m/z 200 - 1000 in two alternating scans, or performing two separate HPLC-MS runs with m/z 50 - 200 and m/z 200 - 1000 scan ranges were critically assessed. The detected features were subjected <b>to</b> rigorous <b>background</b> <b>filtering</b> and quality control in order to obtain reliable metabolite features for subsequent differential quantification. The most efficient approach in terms of feature number, which forms the basis for statistical analysis, identification, and for generating biological hypotheses, was the separate analysis of two different mass ranges. This lead to {{an increase in the number}} of detectable metabolite features, especially in the higher mass range (m/z greater than 400), by 2. 5 (negative mode) to 6 -fold (positive mode) as compared to analysis involving a single scan range. The total number of features confidently detectable was 560 in positive ion mode, and 436 in negative ion mode...|$|R
40|$|Real-time {{detection}} of moving objects {{is vital for}} video surveillance. Background subtraction serves as a basic method typically used to segment the moving objects in image sequences taken from a camera. Some existing algorithms cannot fine-tune changing circumstances and they need manual calibration in relation to specification of parameters or some hypotheses for dynamic changing background. An adaptive motion segmentation and detection strategy is developed by using motion variation and chromatic characteristics, which eliminates undesired corruption of the background model and it doesn't look on the adaptation coefficient. In this particular proposed work, a novel real-time motion detection algorithm is proposed for dynamic changing background features. The algorithm integrates the temporal differencing along with optical flow method, double <b>background</b> <b>filtering</b> method and morphological processing techniques to achieve better detection performance. Temporal differencing is designed to detect initial motion areas for the optical-flow calculation to produce real-time and accurate object motion vectors detection. The double <b>background</b> <b>filtering</b> method is obtain and keep a reliable <b>background</b> image <b>to</b> handle variations on environmental changing conditions {{that is designed to}} get rid of the background interference and separate the moving objects from it. The morphological processing methods are adopted and mixed with the double <b>background</b> <b>filtering</b> <b>to</b> obtain improved results. The most attractive benefit for this algorithm is that the algorithm does not require to figure out the background model from hundreds of images and can handle quick image variations without prior understanding of the object size and shape...|$|R
40|$|The bi-spectral {{threshold}} (BTH) for {{cloud detection}} and height assignment is now operational at NASA's Global Hydrology and Climate Center (GHCC). This new approach {{is similar in}} principle to the bi-spectral spatial coherence (BSC) method with improvements made to produce a more robust cloud-filtering algorithm for nighttime cloud detection and subsequent 24 -hour operational cloud top pressure assignment. The method capitalizes on cloud and surface emissivity differences from the GOES 3. 9 and 10. 7 -micrometer channels to distinguish cloudy from clear pixels. Separate threshold values are determined for day and nighttime detection, and applied to a 20 -day minimum composite difference image <b>to</b> better <b>filter</b> <b>background</b> effects and enhance differences in cloud properties. A cloud top pressure is assigned to each cloudy pixel by referencing the 10. 7 -micrometer channel temperature to a thermodynamic profile from a locally -run regional forecast model. This paper and supplemental poster will present an objective validation of nighttime cloud detection by the BTH approach in comparison with previous methods. The cloud top pressure will be evaluated by comparing to the NESDIS operational CO 2 slicing approach...|$|R
40|$|Abstract. The use of salient regions is an {{increasingly}} popular approach to image retrieval. For situations where object retrieval is required {{and where the}} foreground and background can be assumed to have different characteristics, it becomes useful to exclude salient regions which are characteristic of the background {{if they can be}} identified before matching is undertaken. This paper proposes a technique to enhance the performance of object retrieval by filtering out salient regions believed {{to be associated with the}} background area of the images. Salient regions from background only images are extracted and clustered using descriptors representing the salient regions. The clusters are then used in the retrieval process to identify salient regions likely to be part of the background in images containing object and background. Salient regions close <b>to</b> <b>background</b> clusters are pruned before matching and only the remaining salient regions are used in the retrieval. Experiments on object retrieval show that the use of salient region <b>background</b> <b>filtering</b> gives an improvement in performance when compared with the unfiltered method...|$|R
40|$|International audienceSmith-Purcell {{radiation}} and Transition Radiation are two radiative phenomenon {{that occur in}} charged particles accelerators. For both the emission can be significantly enhanced with sufficiently short pulses and both {{can be used to}} measure the form factor of the pulse. We compare the yield of these phenomenon in different configurations and look at their application as bunch length monitors, including <b>background</b> <b>filtering</b> and rejection. We apply these calculations to the specific case of the CLIO Free Electron laser...|$|R
40|$|A relic {{density of}} Weakly Interacting Massive Particles (WIMPs) {{remaining}} from the Big Bang constitutes a promising {{solution to the}} Dark Matter problem. It is possible for such WIMPs to be trapped by and accumulate in gravitational potentials of massive dense objects such as the Sun. A perfect WIMP candidate appears in certain supersymmetric extensions to the Standard Model of particle physics, where the lightest supersymmetric particle is a neutralino which can be stable, massive and weakly interacting. The neutralinos may annihilate pair-wise and in these interactions neutrinos with energies ranging up to the neutralino mass can be indirectly produced. Hence, a possible population of dark matter neutralinos trapped in the Sun can give rise to an observable neutrino flux. The Antarctic Muon And Neutrino Detector Array, AMANDA, is a neutrino telescope that detects Cherenkov light emitted by charged particles created in neutrino interactions in the South Pole glacial ice sheet using an array of light detectors frozen into the deep ice. In this work data taken with the AMANDA-II detector during 2003 are analyzed to measure or put upper bounds on the flux of such neutrinos from the Sun. In the analysis detailed signal and background simulations are compared <b>to</b> measurements. <b>Background</b> rejection <b>filters</b> optimized for various neutralino models have been constructed. No excess above the background expected from neutrinos and muons created in cosmic ray interactions in the atmosphere was found. Instead 90 % confidence upper limits have been set on the neutralino annihilation rate in the Sun and the muon flux induced by neutralino signal neutrinos...|$|R
40|$|We {{propose a}} method for {{improving}} object recognition in street scene images by identifying and <b>filtering</b> out <b>background</b> aspects. We analyse the semantic relationships between foreground and background objects and use the information obtained to remove areas of the image that are misclassified as foreground objects. We show that such <b>background</b> <b>filtering</b> improves the performance of four traditional object recognition methods by over 40 %. Our method is independent of the recognition algorithms used for individual objects, and can be extended to generic object recognition in other environments by adapting other object model...|$|R
40|$|The {{observations}} {{have been}} reduced and analyzed; unfortunately they were affected by very high background episodes, which have {{made it difficult to}} get a consistent sensitivity and fully achieve the original goals of the proposal. Nevertheless, after much experimenting with <b>background</b> <b>filtering,</b> etc., we believe we have converged on a good compromise and now expect to be able to recover a significant fraction of the observing time. Work on the part of our European collaborators is continuing and should result in a paper that could be ready for publication in the fall...|$|R
40|$|Abstract. Background {{suppression}} of weak small targets in infrared image {{is the key}} of image tracking and monitoring, especially under the cloud background. In the area of image signal processing, {{there are a lot}} of background suppression methods can be used to image filter by combining the characteristics of infrared image under the cloud background. In this paper, we introduce three typical <b>background</b> <b>filter</b> methods such as pulse median filter, multi-structural morphological filter and wavelet threshold method, realize them using MATLAB, and analyze their performances of background {{suppression of}} weak small targets in infrared image under the cloud background...|$|R
40|$|Abstract — The two-path echo {{cancellation}} technique {{is a popular}} method for handling the double-talk problem in acoustic and line {{echo cancellation}} applications. The method uses two <b>filters.</b> A so-called <b>background</b> adaptive <b>filter</b> adapts its coefficients to predict echo {{all or most of}} the time regardless of signal activity on the near-end. A second foreground filter, that also predicts the echo, receives it coefficients from the <b>background</b> <b>filter,</b> but only when the background is performing better than the foreground. Only the foreground residual echo is sent to the far-end, so any <b>background</b> divergence due <b>to</b> double-talk is not observed by the user. The key to good two-path performance is in the definition of the background-to-foreground coefficient download tests. These typically contain a suite of various measures that attempt to ascertain the convergence state of the two filters. In this paper we present a novel, simple statistic that directly and accurately estimates a filter’s convergence state. With the aid of this new statistic we show significant improvement in the overall performance of the two path echo canceller. I...|$|R
500|$|The digital cel work {{included}} both original illustrations, compositions and manipulation with traditional cel animation {{to create a}} sense of depth and evoke emotion and feelings. Utilized as <b>background,</b> <b>filters</b> like a lens effect were used {{to create a sense}} of depth and motion, by distorting the front background and making the far background out of focus throughout the shot. Ghost in the Shell used a unique lighting system in which light and darkness were integrated into the cels with attention to light and shadow sources instead of using contrast to control the light. Hiromasa Ogura, the art director, described this as [...] "a very unusual lighting technique".|$|R
40|$|We {{report on}} the {{discovery}} of a shell-type supernova remnant in the southern sky. It is a large (8 * 8), low-brightness source with a nonthermal radio spectrum, which requires <b>background</b> <b>filtering</b> <b>to</b> isolate it from the diffuse background emission of the Galaxy. Three 3 EG gamma-ray sources are spatially correlated with the radio structure. We have made 21 -cm line observations of the region and found that two of these sources are coincident with HI clouds. We propose that the gamma-ray emission is the result of hadronic interactions between high-energy protons locally accelerated at the remnant shock front and atomic nuclei in the ambient clouds. Comment: 6 pages, 5 figure...|$|R
5000|$|The digital cel work {{included}} both original illustrations, compositions and manipulation with traditional cel animation {{to create a}} sense of depth and evoke emotion and feelings. Utilized as <b>background,</b> <b>filters</b> like a lens effect were used {{to create a sense}} of depth and motion, by distorting the front background and making the far background out of focus throughout the shot. Ghost in the Shell used a unique lighting system in which light and darkness were integrated into the cels with attention to light and shadow sources instead of using contrast to control the light. Hiromasa Ogura, the art director, described this as [...] "a very unusual lighting technique." ...|$|R
40|$|Traumatic {{brain injury}} to {{the parts of the}} brain {{responsible}} for processing auditory information can result in hearing loss that is difficult to assess and treat. Symptoms can include difficulty in <b>filtering</b> <b>background</b> noises or <b>filtering</b> out specific sounds, confusion, and disorientation or nausea. Treatment of this type of hearing loss varies, but primarily consists of psychological treatment focused around rehabilitation and coping...|$|R
40|$|Receiver for optical {{communications}} uses rough reflector {{instead of}} diffraction-limited reflector customarily thought necessary for such systems. Rough reflector collects and focuses optical signal. Other receiver components include narrow-passband optical <b>filter</b> <b>to</b> reject out-of-band <b>background</b> radiation, spatial <b>filter</b> <b>to</b> limit receiver field of view, optical-detector array (typically two concentric detectors), and postdetection processor to reconstruct transmitted message...|$|R
40|$|Currently, {{there exists}} {{a great deal of}} {{uncertainty}} regarding atmospheric aerosols and the role that they play within the Earth’s atmosphere. It is known that atmospheric aerosols can {{play a role in the}} Earth’s climate by scattering and absorbing solar radiation or acting as a cloud condensation nuclei. The purpose of this work is to obtain an improved understanding of the chemistry of atmospheric aerosols to better determine their impacts the environment, air quality, and climate. This work revolves around one specific type of atmospheric aerosol, i. e. sea spray aerosol. Sea spray aerosol is generated via breaking waves, through wind-driven mechanisms. Ocean water covers roughly 71 % of the Earth’s surface, and from this over 1300 Tg of sea spray aerosols is emitted into the atmosphere every year. However, until recently, the study of sea spray was very challenging and often inconclusive due to the inability <b>to</b> <b>filter</b> <b>background</b> particles out. In this work, the understanding of sea spray aerosol is progressed by taking a two-pronged approach. First, this work focuses on the study of model systems of simple ocean surfactants and NaCl and the change in chemistry that occurs when the two are in the presence of each other. Second, sea spray samples generated during a biological bloom are isolated and analyzed. Using this two pronged approach, it is shown that model systems can provide supporting evidence for hypotheses created from trends discovered in more complex samples. Finally, common aerosol generation, storage, and analysis techniques are studied in order to improve our understanding of their effects on aerosol particles...|$|R
40|$|We {{propose a}} motion {{segmentation}} algorithm for extracting foreground objects with a pan-tilt camera. Segmentation {{is achieved by}} spatio-temporal filtering of the scene <b>to</b> model the <b>background.</b> Temporal <b>filtering</b> is done {{by a set of}} modified AR (Auto-Regressive) filters which model the background statistics for a particular view of the scene. Backgrounds from different views of the pan-tilt camera are stitched together into a planar mosaic using a real-time image mosaicing strategy. Our algorithms work in real-time, require no user intervention, and facilitate high-quality video transmission at low bandwidths. ...|$|R
5000|$|... #Caption: The {{result of}} {{applying}} a generalized Wiener filter to a noisy {{observation of the}} cosmic microwave <b>background.</b> The <b>filter</b> results in an image that is signal-dominated at all scales, {{at the cost of}} introducing a bias (seen as blurring in this example).|$|R
50|$|Virtua Fighter 2 was {{released}} in November 1994, adding two new fighters: Shun Di and Lion Rafale. It was built using the Model 2 hardware, rendering characters and <b>backgrounds</b> with <b>filtered</b> texture mapping and motion capture. A slightly-tweaked upgrade, Virtua Fighter 2.1, followed soon after.|$|R
40|$|Abstract—Real-time {{detection}} of moving objects {{is very important}} for video surveillance. In this paper, a novel real time motion detection algorithm is proposed. The algorithm integrates the temporal differencing method, optical flow method, double <b>background</b> <b>filtering</b> (DBF) method and morphological processing methods to achieve better performance. The temporal differencing is used to detect initial coarse motion areas for the optical flow calculation to achieve real-time and accurate object motion detection. The DBF method is used to obtain and keep a stable <b>background</b> image <b>to</b> cope with variations on environmental changing conditions and is used <b>to</b> eliminate the <b>background</b> interference information and separate the moving object from it. The morphological processing methods are adopted and combined with the DBF to get improved results. The most attractive advantage of this algorithm is that the algorithm does not need <b>to</b> learn the <b>background</b> model from hundreds of images and can handle quick image variations without prior knowledge about the object size and shape. The algorithm has high capability of anti-interference and preserves high accurate rate detection at the same time. It also demands less computation time than other methods for the real-time surveillance. The effectiveness of the proposed algorithm for motion detection is demonstrated in a simulation environment and the evaluation results are reported in this paper. Index Terms—Background filtering, motion detection, optical flow, temporal differencing. I...|$|R
40|$|The {{research}} {{focuses on}} image retrieval problems where the query is formed as {{an image of a}} specific object of interest. The broad aim is to investigate pre-processing for retrieval of images of objects when an example image containing the object is given. The object may be against a variety of backgrounds. Given the assumption that the object of interest is fairly centrally located in the image, the normalized cut segmentation and region growing segmentation are investigated to segment the object from the background but with limited success. An alternative approach comes from identifying salient regions in the image and extracting local features as a representation of the regions. The experiments show an improvement for retrieval by local features when compared with retrieval using global features from the whole image. For situations where object retrieval is required and where the foreground and background can be assumed to have different characteristics, it is useful to exclude salient regions which are characteristic of the background if they can be identified before matching is undertaken. This thesis proposes techniques to filter out salient regions believed {{to be associated with the}} <b>background</b> area. <b>Background</b> <b>filtering</b> using <b>background</b> clusters is the first technique which is proposed in the situation where only the background information is available for training. The second technique is the K-NN classification based on the foreground and background probability. In the last chapter, the support vector machine (SVM) method with PCA-SIFT descriptors is applied in an attempt to improve classification into foreground and background salient region classes. Retrieval comparisons show that the use of salient region <b>background</b> <b>filtering</b> gives an improvement in performance when compared with the unfiltered method. EThOS - Electronic Theses Online ServiceGBUnited Kingdo...|$|R
50|$|Adobe Presenter Video Express {{ships with}} a large number of {{branding}} videos, <b>backgrounds</b> and video <b>filters</b> <b>to</b> help authors create studio quality videos.|$|R
5000|$|... #Subtitle level 2: Chernobyl {{compared}} <b>to</b> <b>background</b> radiation ...|$|R
50|$|On September 7, 2009 the {{programming}} switched <b>to</b> <b>background.</b>|$|R
5000|$|Disappearance of {{all other}} lesions <b>to</b> <b>background</b> blood pool levels.|$|R
30|$|Our {{choice of}} {{training}} features was as follows: Gaussian blur, median (voxel intensity averaging); anisotropic diffusion, bilateral, Kuwahara (edge-preserving averaging functions); Sobel filter, derivatives (edge detection); Hessian, Gabor, structure (orientation detection); membrane projections (extended object detection); difference of Gaussians, Laplacian (object size detection); variance, entropy, neighbours (local noise level). We {{did not use}} the mean, minimum, maximum (voxel intensity) or Lipschitz (smoothly varying <b>background</b> subtraction) <b>filters.</b>|$|R
40|$|For the Portland State University FAGE instrument, laser induced OH is {{calculated}} from (OH) laser = Cl(03) amb(H 2 O) amb. The dominant noise sources are the photon-counting fluctuations {{associated with the}} OH signal and the fluorescence background as well as concentration fluctuations in OH and in the species causing the <b>background.</b> Baric <b>filtering</b> and temporal <b>filtering</b> suppress the <b>background</b> by factors of 10 each...|$|R
5000|$|... is the {{strength}} we give <b>to</b> <b>background</b> information about incoming spam ...|$|R
