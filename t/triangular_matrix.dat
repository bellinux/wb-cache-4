838|942|Public
5|$|If all entries of A {{below the}} main {{diagonal}} are zero, A {{is called a}}n upper <b>triangular</b> <b>matrix.</b> Similarly if all entries of A above the main diagonal are zero, A is called a lower <b>triangular</b> <b>matrix.</b> If all entries outside the main diagonal are zero, A is called a diagonal matrix.|$|E
5|$|Adding a {{multiple}} of any row to another row, or {{a multiple}} of any column to another column, {{does not change the}} determinant. Interchanging two rows or two columns affects the determinant by multiplying it by −1. Using these operations, any matrix can be transformed to a lower (or upper) <b>triangular</b> <b>matrix,</b> and for such matrices the determinant equals the product of the entries on the main diagonal; this provides a method to calculate the determinant of any matrix. Finally, the Laplace expansion expresses the determinant in terms of minors, that is, determinants of smaller matrices. This expansion can be used for a recursive definition of determinants (taking as starting case the determinant of a 1-by-1 matrix, which is its unique entry, or even the determinant of a 0-by-0 matrix, which is 1), that can be seen to be equivalent to the Leibniz formula. Determinants can be used to solve linear systems using Cramer's rule, where the division of the determinants of two related square matrices equates to the value of each of the system's variables.|$|E
25|$|A matrix {{can also}} be factorized into a product of {{matrices}} of special types, for an application in which that form is convenient. One major example of this uses an orthogonal or unitary matrix, and a <b>triangular</b> <b>matrix.</b> There are different types: QR decomposition, LQ, QL, RQ, RZ.|$|E
50|$|Because {{the product}} of two upper <b>triangular</b> <b>matrices</b> is again upper triangular, the set of upper <b>triangular</b> <b>matrices</b> forms an algebra. Algebras of upper <b>triangular</b> <b>matrices</b> have a natural {{generalization}} in functional analysis which yields nest algebras on Hilbert spaces.|$|R
40|$|Problem statement: EEG signals during {{epileptic seizure}} can be {{presented}} as an algebraic structure, namely semigroup of upper <b>triangular</b> <b>matrices.</b> Approach: EEG signals during seizure were recorded and composed into set of matrices. They were transformed into upper <b>triangular</b> <b>matrices</b> using QR-Schur decomposition and finally as a semigroup of upper <b>triangular</b> <b>matrices.</b> Results: EEG signals during epileptic seizure were transformed as a semigroup of upper <b>triangular</b> <b>matrices</b> under matrix multiplication. Conclusion: This study described the procedure to transform signal during epileptic seizure (brainstorm) into an algebraic structure. This {{is the key}} step that {{will enable us to}} further proceed to obtain some pattern out of the seizure data in our future research...|$|R
5000|$|The matrix ring Mn(R) is {{commutative}} if {{and only}} if n = 1 and R is commutative. In fact, this is also true for the subring of upper <b>triangular</b> <b>matrices.</b> Here is an example for 2×2 matrices (in fact, upper <b>triangular</b> <b>matrices)</b> which do not commute: ...|$|R
25|$|The {{exponential}} of a 1×1 matrix is {{just the}} exponential of the one entry of the matrix, so exp(J1(4)) =. The exponential of J2(16) can be calculated by the formula e(λI+N) =eλ eN mentioned above; this yields(a) is an upper <b>triangular</b> <b>matrix</b> with e'a/0! on the main diagonal, e'a/1! on the one above, e'a/2! on the next one, and so on.|$|E
25|$|To perform row {{reduction}} on a matrix, {{one uses}} {{a sequence of}} elementary row operations to modify the matrix until the lower left-hand corner of the matrix is filled with zeros, as much as possible. There are three types of elementary row operations: 1) Swapping two rows, 2) Multiplying a row by a non-zero number, 3) Adding a multiple of one row to another row. Using these operations, a matrix can always be transformed into an upper <b>triangular</b> <b>matrix,</b> and in fact one that is in row echelon form. Once all of the leading coefficients (the left-most non-zero entry in each row) are 1, and every column containing a leading coefficient has zeros elsewhere, the matrix {{is said to be}} in reduced row echelon form. This final form is unique; in other words, it is independent of the sequence of row operations used. For example, in the following sequence of row operations (where multiple elementary operations might be done at each step), the third and fourth matrices are the ones in row echelon form, and the final matrix is the unique reduced row echelon form.|$|E
2500|$|The LU {{decomposition}} expresses A {{in terms}} of a lower <b>triangular</b> <b>matrix</b> L, an upper <b>triangular</b> <b>matrix</b> U and a permutation matrix P: ...|$|E
50|$|The matrix and its inverse are <b>triangular</b> <b>matrices.</b>|$|R
40|$|We use {{elementary}} <b>triangular</b> <b>matrices</b> {{to obtain}} some factorization, multiplication, and inversion properties of <b>triangular</b> <b>matrices.</b> We also obtain explicit expressions for the inverses of strict $k$-Hessenberg matrices and banded matrices. Our {{results can be}} extended to the cases of block triangular and block Hessenberg matrices. Comment: 11 page...|$|R
40|$|Abstract. We {{consider}} wreath product decompositions for semigroups of <b>triangular</b> <b>matrices.</b> We exhibit {{an explicit}} wreath product decomposition for the semigroup of all n×n upper <b>triangular</b> <b>matrices</b> over a given field k, {{in terms of}} aperiodic semigroups and affine groups over k. In the case that k is finite this decomposition is optimal, {{in the sense that}} the number of group terms is equal to the group complexity of the semigroup. We also obtain some decompositions for semigroups of <b>triangular</b> <b>matrices</b> over more general rings and semirings. 1...|$|R
2500|$|A matrix whose {{elements}} {{above the}} main diagonal are all zero {{is called a}} lower <b>triangular</b> <b>matrix,</b> while a matrix whose elements below the main diagonal are all zero is called an upper <b>triangular</b> <b>matrix.</b> [...] As with diagonal matrices, the eigenvalues of triangular matrices are {{the elements of the}} main diagonal.|$|E
2500|$|If A is a <b>triangular</b> <b>matrix,</b> i.e. [...] {{whenever}} [...] or, alternatively, whenever , {{then its}} determinant equals {{the product of}} the diagonal entries: ...|$|E
2500|$|The inverse of this matrix is S, {{the lower}} <b>triangular</b> <b>matrix</b> of Stirling {{numbers of the}} second kind, whose entries are [...] Symbolically, this is written ...|$|E
50|$|Together {{these facts}} {{mean that the}} upper <b>triangular</b> <b>matrices</b> form a subalgebra of the {{associative}} algebra of square matrices for a given size. Additionally, this also shows that the upper <b>triangular</b> <b>matrices</b> {{can be viewed as}} a Lie subalgebra of the Lie algebra of square matrices of a fixed size, where the Lie bracket a,b given by the commutator ab-ba. The Lie algebra of all upper <b>triangular</b> <b>matrices</b> is a solvable Lie algebra. It is often referred to as a Borel subalgebra of the Lie algebra of all square matrices.|$|R
5000|$|More generally, the {{stabilizer}} of a flag (the linear operators on V {{such that}} [...] for all i) is, in matrix terms, the algebra of block upper <b>triangular</b> <b>matrices</b> (with respect to an adapted basis), where the block sizes [...] The stabilizer subgroup {{of a complete}} flag is the set of invertible upper <b>triangular</b> <b>matrices</b> with respect to any basis adapted to the flag. The subgroup of lower <b>triangular</b> <b>matrices</b> with respect to such a basis depends on that basis, and can therefore not be characterized {{in terms of the}} flag only.|$|R
5000|$|Many {{operations}} on upper <b>triangular</b> <b>matrices</b> preserve the shape: ...|$|R
2500|$|If [...] is normal, {{one sees}} that [...] Therefore, [...] must be {{diagonal}} since a normal upper <b>triangular</b> <b>matrix</b> is diagonal (see normal matrix). The converse is obvious.|$|E
2500|$|Positive {{definite}} matrices {{have the}} property {{that they have}} a <b>triangular</b> <b>matrix</b> square root P=S·ST. [...] This can be computed efficiently using the Cholesky factorization algorithm, but more importantly, if the covariance is kept in this form, it can never have a negative diagonal or become asymmetric. An equivalent form, which avoids many of the square root operations required by the matrix square root yet preserves the desirable numerical properties, is the U-D decomposition form, P=U·D·UT, where U is a unit <b>triangular</b> <b>matrix</b> (with unit diagonal), and D is a diagonal matrix.|$|E
2500|$|... where [...] is the Kronecker delta. These two {{relationships}} may {{be understood}} to be matrix inverse relationships. That is, let s be the lower <b>triangular</b> <b>matrix</b> of Stirling numbers of the first kind, whose matrix elements ...|$|E
40|$|International audienceWe {{consider}} {{the intersection of}} the conjugacy class of a nilpotent matrix with the space of upper <b>triangular</b> <b>matrices.</b> We give necessary and sufficient conditions for this intersection to be a union of finitely many orbits for the action by conjugation of the group of invertible upper <b>triangular</b> <b>matrices...</b>|$|R
40|$|AbstractWe use basic {{properties}} of infinite lower <b>triangular</b> <b>matrices</b> and the connections of Toeplitz matrices with generating-functions to obtain inversion formulas for {{several types of}} q-Pascal matrices, determinantal representations for polynomial sequences, and identities involving the q-Gaussian coefficients. We also obtain a fast inversion algorithm for general infinite lower <b>triangular</b> <b>matrices...</b>|$|R
50|$|Matrices {{that are}} similar to <b>triangular</b> <b>matrices</b> are called triangularisable.|$|R
2500|$|... of {{a linear}} {{operator}} on a finite-dimensional vector space is an upper <b>triangular</b> <b>matrix</b> {{of a particular}} form called a Jordan matrix, representing the operator with respect to some basis. Such a matrix has each non-zero off-diagonal entry equal to1, immediately above the main diagonal (on the superdiagonal), and with identical diagonal entries {{to the left and}} below them.|$|E
2500|$|Here, B is {{obtained}} from A by adding −1/2×the first row to the second, so that [...] C {{is obtained}} from B {{by adding the}} first to the third row, so that [...] Finally, D is obtained from C by exchanging {{the second and third}} row, so that [...] The determinant of the (upper) <b>triangular</b> <b>matrix</b> D is the product of its entries on the main diagonal: [...] Therefore, [...]|$|E
2500|$|The {{first step}} {{can be done}} using Householder {{reflections}} for a cost of 4mn2 − 4n3/3 flops, assuming that only the singular values are needed and not the singular vectors. If m is much larger than n then it is advantageous to first reduce the matrix M to a <b>triangular</b> <b>matrix</b> with the QR decomposition and then use Householder reflections to further reduce the matrix to bidiagonal form; the combined cost is 2mn2 + 2n3 flops [...]|$|E
5000|$|The {{product of}} two upper <b>triangular</b> <b>matrices</b> is upper <b>triangular.</b>|$|R
5000|$|The Lie algebra of the Lie {{group of}} {{invertible}} upper <b>triangular</b> <b>matrices</b> is {{the set of}} all upper <b>triangular</b> <b>matrices,</b> not necessarily invertible, and is a solvable Lie algebra. These are, respectively, the standard Borel subgroup B of the Lie group GLn and the standard Borel subalgebra [...] of the Lie algebra gln.|$|R
5000|$|... {{as well as}} solving [...] for <b>triangular</b> <b>matrices</b> , {{among other}} things.|$|R
2500|$|Property 5 {{says that}} the {{determinant}} on [...] matrices is homogeneous of degree n. These properties {{can be used to}} facilitate the computation of determinants by simplifying the matrix {{to the point where the}} determinant can be determined immediately. Specifically, for matrices with coefficients in a field, properties 13 and 14 can be used to transform any matrix into a <b>triangular</b> <b>matrix,</b> whose determinant is given by property6; this is essentially the method of Gaussian elimination.|$|E
50|$|The Crout matrix {{decomposition}} algorithm differs {{slightly from}} the Doolittle method. Doolittle's method returns a unit lower <b>triangular</b> <b>matrix</b> and an upper <b>triangular</b> <b>matrix,</b> while the Crout method returns a lower <b>triangular</b> <b>matrix</b> and a unit upper <b>triangular</b> <b>matrix.</b>|$|E
5000|$|... {{is called}} an upper <b>triangular</b> <b>matrix</b> or right <b>triangular</b> <b>matrix.</b> The {{variable}} L (standing for lower or left) {{is commonly used}} to represent a lower <b>triangular</b> <b>matrix,</b> while the variable U (standing for upper) or R (standing for right) is commonly used for upper <b>triangular</b> <b>matrix.</b> A matrix that is both upper and lower triangular is diagonal.|$|E
40|$|Z=the {{center of}} G T=the group of {{diagonal}} matrices U=the group of upper <b>triangular</b> <b>matrices</b> with {{ones in the}} diagonal B=the group of upper <b>triangular</b> <b>matrices</b> =TU P={() A∈ GL_n- 1 (F), x∈ F^n- 1 } Q=ZP (a maximal parabolic subgroup of G) G 1 H H_v=the group of F_v rational points of H (v∈P) ...|$|R
5000|$|If K is a {{field and}} R is the ring of all upper <b>triangular</b> n-by-n <b>matrices</b> with entries in K, then J(R) {{consists}} of all upper <b>triangular</b> <b>matrices</b> with zeros on the main diagonal.|$|R
50|$|The {{stabilizer}} of {{a partial}} flag obtained by forgetting {{some parts of}} the standard flag can be described as a set of block upper <b>triangular</b> <b>matrices</b> (but its elements are not all <b>triangular</b> <b>matrices).</b> The conjugates of such a group are the subgroups defined as the stabilizer of some partial flag. These subgroups are called parabolic subgroups.|$|R
